{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the less hidden layes didn't work out as per the graph above so using more hidden layers\n",
    "#as per above diagram using only adam and nadam\n",
    "#importing pandas to visualise the dataset in tabular format\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#introducing stable analysis through random seed\n",
    "np.random.seed(42)\n",
    "#importing time function to create animated behaviour\n",
    "import time\n",
    "#importing regExp for data cleaning\n",
    "import re\n",
    "from numpy import NaN\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(patience=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/scaled_train.csv\")\n",
    "test = pd.read_csv(\"../data/scaled_test.csv\")\n",
    "\n",
    "X_train = df.drop(['PRT_ID','SALES_PRICE'],axis=1)\n",
    "y_train = df['SALES_PRICE']\n",
    "\n",
    "X_test = test.drop(['PRT_ID'],axis=1)\n",
    "\n",
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Specify the model\n",
    "predictors = X_train.values\n",
    "target = y_train.values.reshape((-1,1)).astype('int32')\n",
    "\n",
    "n_cols = predictors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model 2\n",
    "model22 = Sequential()\n",
    "model22.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "model22.add(Dense(70, kernel_initializer='normal', activation='relu'))\n",
    "model22.add(Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "model22.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model22.add(Dense(1, kernel_initializer='normal'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model22 loss: mean_squared_error\n",
      "Train on 3554 samples, validate on 3555 samples\n",
      "Epoch 1/7000\n",
      "3554/3554 [==============================] - 1s 149us/step - loss: 133448766387874.7969 - val_loss: 132142962084713.9219\n",
      "Epoch 2/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 129228767477326.6562 - val_loss: 116080320124148.5469\n",
      "Epoch 3/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 76083324177037.4688 - val_loss: 23348170368674.3125\n",
      "Epoch 4/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 10973364451550.4336 - val_loss: 7525716162275.9873\n",
      "Epoch 5/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 7305023241474.7363 - val_loss: 6698762053549.6191\n",
      "Epoch 6/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 6482440902477.3623 - val_loss: 6082766402157.0254\n",
      "Epoch 7/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 5895931572032.6836 - val_loss: 5624546033691.6523\n",
      "Epoch 8/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 5438998950231.4463 - val_loss: 5272571852797.1191\n",
      "Epoch 9/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 5084861624027.2646 - val_loss: 5008366785600.8105\n",
      "Epoch 10/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 4814372731674.0752 - val_loss: 4775451088646.5527\n",
      "Epoch 11/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4576681099688.1211 - val_loss: 4596515892965.7158\n",
      "Epoch 12/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 4381123544220.1641 - val_loss: 4442381108992.7920\n",
      "Epoch 13/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 4227779241646.3159 - val_loss: 4309772718256.2837\n",
      "Epoch 14/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 4080686489364.8892 - val_loss: 4209754087960.9160\n",
      "Epoch 15/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3958119761845.0874 - val_loss: 4094072819293.7588\n",
      "Epoch 16/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 3856134760506.7778 - val_loss: 4020226412351.5859\n",
      "Epoch 17/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3758570985828.1235 - val_loss: 3920415179623.0483\n",
      "Epoch 18/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3673837548670.1992 - val_loss: 3847618782250.9189\n",
      "Epoch 19/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 3591655965676.9839 - val_loss: 3774548941624.3848\n",
      "Epoch 20/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3520141295413.1592 - val_loss: 3707228578665.3525\n",
      "Epoch 21/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3451205067042.4307 - val_loss: 3646031036498.9570\n",
      "Epoch 22/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3386893062593.4766 - val_loss: 3579005755804.4805\n",
      "Epoch 23/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3331501829233.5220 - val_loss: 3556437358307.9878\n",
      "Epoch 24/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 3268998923530.8047 - val_loss: 3466301264509.1558\n",
      "Epoch 25/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3216989580189.4604 - val_loss: 3416060862899.5239\n",
      "Epoch 26/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3156642904406.2935 - val_loss: 3354609254307.8257\n",
      "Epoch 27/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 3105087137638.7173 - val_loss: 3311703930287.2036\n",
      "Epoch 28/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 3041286181184.3960 - val_loss: 3256057885569.5483\n",
      "Epoch 29/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2999253537429.5376 - val_loss: 3196108470310.5981\n",
      "Epoch 30/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2951256008320.2158 - val_loss: 3147208208336.7607\n",
      "Epoch 31/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2901488926738.4399 - val_loss: 3098675682740.3882\n",
      "Epoch 32/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2855765477540.8081 - val_loss: 3038314936224.9453\n",
      "Epoch 33/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2803660563496.9141 - val_loss: 2993229588817.0127\n",
      "Epoch 34/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2757568794640.1348 - val_loss: 2955437519971.3755\n",
      "Epoch 35/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2715637851451.2100 - val_loss: 2901642328070.3369\n",
      "Epoch 36/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2673875995093.0693 - val_loss: 2882098323582.7397\n",
      "Epoch 37/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2629564215989.8076 - val_loss: 2821457758883.7534\n",
      "Epoch 38/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2591552564107.0210 - val_loss: 2772905956117.2432\n",
      "Epoch 39/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2553422149245.9111 - val_loss: 2721482917144.2676\n",
      "Epoch 40/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2529204253882.1294 - val_loss: 2697229153692.7686\n",
      "Epoch 41/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2488152244731.1016 - val_loss: 2708673461737.3887\n",
      "Epoch 42/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2464140229475.8359 - val_loss: 2634000327686.0488\n",
      "Epoch 43/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2414151930517.5376 - val_loss: 2578303857818.6802\n",
      "Epoch 44/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2386003590080.0361 - val_loss: 2586517779472.4185\n",
      "Epoch 45/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 2369567020545.4404 - val_loss: 2515749755294.2085\n",
      "Epoch 46/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2328885723726.0820 - val_loss: 2475114024804.4556\n",
      "Epoch 47/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2292764467206.9150 - val_loss: 2445891223280.0854\n",
      "Epoch 48/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2269811645961.5083 - val_loss: 2416711102154.0635\n",
      "Epoch 49/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2246260941984.7744 - val_loss: 2405452738084.1494\n",
      "Epoch 50/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2218243929015.9683 - val_loss: 2361958282883.2046\n",
      "Epoch 51/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2199745843022.5142 - val_loss: 2359803753829.4639\n",
      "Epoch 52/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2178954247850.8589 - val_loss: 2316001018574.9604\n",
      "Epoch 53/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2156725997713.2153 - val_loss: 2297963412748.1699\n",
      "Epoch 54/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2138686034581.5374 - val_loss: 2338912063940.8066\n",
      "Epoch 55/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2144009748904.1216 - val_loss: 2246103951355.9673\n",
      "Epoch 56/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2099577638642.3142 - val_loss: 2219369843833.8433\n",
      "Epoch 57/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2068910719261.8210 - val_loss: 2215529323071.5142\n",
      "Epoch 58/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2062628325153.5667 - val_loss: 2193187952528.8147\n",
      "Epoch 59/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2039999213660.2002 - val_loss: 2158857082556.8135\n",
      "Epoch 60/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2019597939427.9077 - val_loss: 2139033083021.4302\n",
      "Epoch 61/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2011254738729.6340 - val_loss: 2114606232080.8506\n",
      "Epoch 62/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1983777148925.6948 - val_loss: 2093744167561.2534\n",
      "Epoch 63/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 75us/step - loss: 1974979098698.9128 - val_loss: 2073612691143.1831\n",
      "Epoch 64/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1950545182222.1182 - val_loss: 2086920856374.6565\n",
      "Epoch 65/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1934629094952.6257 - val_loss: 2038282463794.8398\n",
      "Epoch 66/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1918744843943.4014 - val_loss: 2022026940642.9795\n",
      "Epoch 67/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1902513092406.3118 - val_loss: 2012163409475.8347\n",
      "Epoch 68/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1882598618851.3315 - val_loss: 1986537493739.3328\n",
      "Epoch 69/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1866092206454.5637 - val_loss: 1981366752855.4216\n",
      "Epoch 70/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1865442392452.3940 - val_loss: 1950879716909.9431\n",
      "Epoch 71/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1861519964050.5122 - val_loss: 1928615150282.3516\n",
      "Epoch 72/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1813595806789.7263 - val_loss: 1907820468274.1199\n",
      "Epoch 73/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1796621917733.1682 - val_loss: 1892259740907.9089\n",
      "Epoch 74/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1781500112621.7039 - val_loss: 1863532421481.7844\n",
      "Epoch 75/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1757434167987.5024 - val_loss: 1842651302927.8425\n",
      "Epoch 76/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1740429829142.4739 - val_loss: 1840339084008.3083\n",
      "Epoch 77/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1722761691514.0215 - val_loss: 1803996487539.4341\n",
      "Epoch 78/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1699271341214.4692 - val_loss: 1792461674555.3372\n",
      "Epoch 79/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1702477076734.7034 - val_loss: 1797893177560.6099\n",
      "Epoch 80/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1662606718894.1721 - val_loss: 1744234110807.7817\n",
      "Epoch 81/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1644276875927.8425 - val_loss: 1744328719646.6047\n",
      "Epoch 82/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1629167605489.1614 - val_loss: 1708429591924.4421\n",
      "Epoch 83/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1612471077969.2517 - val_loss: 1699081591451.6882\n",
      "Epoch 84/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1588081214315.9033 - val_loss: 1666722546267.7424\n",
      "Epoch 85/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1570751563913.1479 - val_loss: 1646047708126.8748\n",
      "Epoch 86/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1548461664130.3772 - val_loss: 1636289578462.4429\n",
      "Epoch 87/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1538744865401.8774 - val_loss: 1610916202706.2729\n",
      "Epoch 88/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1515130237824.6482 - val_loss: 1593809545843.3621\n",
      "Epoch 89/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1493271528853.1052 - val_loss: 1567471279816.9114\n",
      "Epoch 90/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1476906549930.2827 - val_loss: 1549606032195.3306\n",
      "Epoch 91/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1466962811374.4243 - val_loss: 1534267088386.7363\n",
      "Epoch 92/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1440173099412.5291 - val_loss: 1517578789640.5693\n",
      "Epoch 93/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1425525655910.4290 - val_loss: 1496488162099.2000\n",
      "Epoch 94/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1411941591356.9387 - val_loss: 1477382791368.4792\n",
      "Epoch 95/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1393131158427.1558 - val_loss: 1477352362570.4597\n",
      "Epoch 96/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1380520495600.7292 - val_loss: 1446982078852.2847\n",
      "Epoch 97/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1359500362567.0229 - val_loss: 1428363507169.8994\n",
      "Epoch 98/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1345119906588.3804 - val_loss: 1409536986090.9727\n",
      "Epoch 99/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1341156980239.2708 - val_loss: 1395268979571.1460\n",
      "Epoch 100/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1306406890793.9224 - val_loss: 1386691784771.9785\n",
      "Epoch 101/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1296234237829.8347 - val_loss: 1361807597003.4319\n",
      "Epoch 102/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1280422986308.8623 - val_loss: 1349084897545.0015\n",
      "Epoch 103/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1263339774353.0715 - val_loss: 1334134546821.4368\n",
      "Epoch 104/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1259266065370.5437 - val_loss: 1335012156081.0037\n",
      "Epoch 105/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1241456898566.6270 - val_loss: 1306102070116.1677\n",
      "Epoch 106/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1230324027527.9956 - val_loss: 1311212491223.2417\n",
      "Epoch 107/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1212583867310.7485 - val_loss: 1283492247267.9875\n",
      "Epoch 108/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1199853034104.7249 - val_loss: 1273357098710.7375\n",
      "Epoch 109/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1195731986075.8762 - val_loss: 1259261214503.3901\n",
      "Epoch 110/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1179269940481.5847 - val_loss: 1246863565346.1333\n",
      "Epoch 111/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1177268911860.6189 - val_loss: 1252926831520.0811\n",
      "Epoch 112/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1158919868127.8738 - val_loss: 1225990953973.3423\n",
      "Epoch 113/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1152898079195.9841 - val_loss: 1217777601109.4053\n",
      "Epoch 114/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1143689737429.7896 - val_loss: 1207749638625.0352\n",
      "Epoch 115/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1132896872672.7383 - val_loss: 1200363812980.9463\n",
      "Epoch 116/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1123167520849.8276 - val_loss: 1190410557812.7302\n",
      "Epoch 117/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1116015935939.7817 - val_loss: 1189394764892.4624\n",
      "Epoch 118/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1110974696086.6899 - val_loss: 1173661217121.7192\n",
      "Epoch 119/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1099680708745.1479 - val_loss: 1166994777624.0518\n",
      "Epoch 120/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1093060258145.8187 - val_loss: 1161821292339.4880\n",
      "Epoch 121/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1089271207872.6122 - val_loss: 1164747753659.2292\n",
      "Epoch 122/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1082170772524.3713 - val_loss: 1147714717413.1399\n",
      "Epoch 123/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1076372887945.0039 - val_loss: 1147703113319.5522\n",
      "Epoch 124/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1066805616202.0483 - val_loss: 1165648570995.3621\n",
      "Epoch 125/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1068494426773.5374 - val_loss: 1127507604376.5918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1060635816168.8058 - val_loss: 1161149471023.5994\n",
      "Epoch 127/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1052784588377.0309 - val_loss: 1116391390969.3030\n",
      "Epoch 128/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1044429786515.9528 - val_loss: 1110899524127.8289\n",
      "Epoch 129/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1041756275268.8621 - val_loss: 1109345771420.9126\n",
      "Epoch 130/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1034838998339.2775 - val_loss: 1103568855756.6560\n",
      "Epoch 131/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1026749335809.0084 - val_loss: 1095248814782.8298\n",
      "Epoch 132/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1024338245974.2937 - val_loss: 1106004914598.8501\n",
      "Epoch 133/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1021987129564.1284 - val_loss: 1088950028042.0095\n",
      "Epoch 134/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1014517508606.5593 - val_loss: 1085096319814.2109\n",
      "Epoch 135/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1015538661865.8142 - val_loss: 1082806703385.4199\n",
      "Epoch 136/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1010737750103.5902 - val_loss: 1087079847875.5105\n",
      "Epoch 137/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1010042725776.4952 - val_loss: 1069711231730.1018\n",
      "Epoch 138/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 1003934977676.8937 - val_loss: 1064779925986.1874\n",
      "Epoch 139/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 994787630343.3472 - val_loss: 1063010760631.9888\n",
      "Epoch 140/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 994735161639.0410 - val_loss: 1058060103093.5404\n",
      "Epoch 141/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 991001137462.0237 - val_loss: 1053738006806.2515\n",
      "Epoch 142/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 982496826323.6287 - val_loss: 1055577260949.1353\n",
      "Epoch 143/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 982337140810.9128 - val_loss: 1050339455297.4583\n",
      "Epoch 144/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 982592045959.5632 - val_loss: 1060542716055.5117\n",
      "Epoch 145/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 974579753296.5312 - val_loss: 1040672293656.6998\n",
      "Epoch 146/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 977897483128.5807 - val_loss: 1044556783120.5626\n",
      "Epoch 147/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 971547577535.8920 - val_loss: 1060630622635.4587\n",
      "Epoch 148/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 974140980445.8571 - val_loss: 1031371207889.9849\n",
      "Epoch 149/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 966653277950.9916 - val_loss: 1031406099920.0405\n",
      "Epoch 150/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 962146361533.0107 - val_loss: 1032296989335.6556\n",
      "Epoch 151/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 958843174349.5779 - val_loss: 1022942734424.1417\n",
      "Epoch 152/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 952899922545.8098 - val_loss: 1034363281198.3032\n",
      "Epoch 153/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 954846742139.6060 - val_loss: 1017334168890.2571\n",
      "Epoch 154/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 948091872269.2538 - val_loss: 1013661935727.1854\n",
      "Epoch 155/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 957545653657.7152 - val_loss: 1011450381984.0090\n",
      "Epoch 156/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 947798421349.5645 - val_loss: 1009803637251.0244\n",
      "Epoch 157/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 939836535321.0669 - val_loss: 1007733454043.2023\n",
      "Epoch 158/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 943251767397.4204 - val_loss: 1009590769612.7280\n",
      "Epoch 159/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 935242649643.7952 - val_loss: 1029511854491.9044\n",
      "Epoch 160/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 938921408835.8536 - val_loss: 1020500257072.7516\n",
      "Epoch 161/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 930783953744.2432 - val_loss: 1013023117566.6318\n",
      "Epoch 162/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 931223768421.8525 - val_loss: 993731838919.8312\n",
      "Epoch 163/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 933609198976.3601 - val_loss: 991114798809.6180\n",
      "Epoch 164/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 926175156524.8036 - val_loss: 998450425573.7159\n",
      "Epoch 165/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 926196318088.7158 - val_loss: 1016377593746.5428\n",
      "Epoch 166/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 923840416130.0889 - val_loss: 989598777362.4349\n",
      "Epoch 167/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 920576548075.6871 - val_loss: 982399505076.4602\n",
      "Epoch 168/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 934062537175.3741 - val_loss: 983439872061.0656\n",
      "Epoch 169/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 915810900490.0844 - val_loss: 997669215179.8639\n",
      "Epoch 170/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 917742307963.0298 - val_loss: 979043760171.2068\n",
      "Epoch 171/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 910520725331.1243 - val_loss: 976107221350.3280\n",
      "Epoch 172/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 916672009600.3601 - val_loss: 988343877258.6937\n",
      "Epoch 173/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 911864068244.6731 - val_loss: 968964410162.6239\n",
      "Epoch 174/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 907030691415.8785 - val_loss: 975728430312.4523\n",
      "Epoch 175/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 904991561457.1615 - val_loss: 982804065017.0149\n",
      "Epoch 176/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 903418000201.3280 - val_loss: 962711891395.3666\n",
      "Epoch 177/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 903367404726.6720 - val_loss: 960388494264.8529\n",
      "Epoch 178/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 900568149040.9814 - val_loss: 965406448223.7750\n",
      "Epoch 179/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 894824840865.6388 - val_loss: 958217824809.6226\n",
      "Epoch 180/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 893796683699.9348 - val_loss: 954455058077.7046\n",
      "Epoch 181/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 893305814357.7175 - val_loss: 954937719103.7300\n",
      "Epoch 182/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 891305702429.3889 - val_loss: 951706306535.2281\n",
      "Epoch 183/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 900546886684.2363 - val_loss: 950213085126.9670\n",
      "Epoch 184/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 886696763212.2094 - val_loss: 963116969632.5851\n",
      "Epoch 185/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 884740901001.1481 - val_loss: 955549046635.9448\n",
      "Epoch 186/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 887014712886.4558 - val_loss: 946568817861.8870\n",
      "Epoch 187/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 883785146547.7906 - val_loss: 941501529950.6948\n",
      "Epoch 188/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 886123912547.5475 - val_loss: 940406443503.1494\n",
      "Epoch 189/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 92us/step - loss: 881388242396.5604 - val_loss: 939596426857.2804\n",
      "Epoch 190/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 876760713740.3895 - val_loss: 940050602766.9064\n",
      "Epoch 191/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 877452355255.5363 - val_loss: 943629078284.8900\n",
      "Epoch 192/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 879880088560.4413 - val_loss: 940525432416.0630\n",
      "Epoch 193/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 873583212231.6714 - val_loss: 935878616549.3558\n",
      "Epoch 194/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 875200586184.3917 - val_loss: 931604407629.2681\n",
      "Epoch 195/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 869455993344.8643 - val_loss: 937093731397.4188\n",
      "Epoch 196/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 873875951272.5537 - val_loss: 928916010170.9412\n",
      "Epoch 197/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 868671170130.1158 - val_loss: 943820924610.5745\n",
      "Epoch 198/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 867108925045.8435 - val_loss: 924432551328.8011\n",
      "Epoch 199/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 866491789922.8271 - val_loss: 924059448576.0720\n",
      "Epoch 200/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 871832652134.4288 - val_loss: 942735693210.4641\n",
      "Epoch 201/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 864333063697.5757 - val_loss: 921180613345.9713\n",
      "Epoch 202/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 864633378489.8413 - val_loss: 923865649111.6737\n",
      "Epoch 203/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 859403427863.0500 - val_loss: 919283095837.1646\n",
      "Epoch 204/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 858266512903.2031 - val_loss: 920297538678.9626\n",
      "Epoch 205/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 856666894054.2128 - val_loss: 925981390679.2056\n",
      "Epoch 206/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 859366125293.7040 - val_loss: 913120465639.1561\n",
      "Epoch 207/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 856874402022.5009 - val_loss: 920180632243.8842\n",
      "Epoch 208/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 857909418229.4834 - val_loss: 912335332026.2211\n",
      "Epoch 209/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 853231950530.4851 - val_loss: 909082590577.5618\n",
      "Epoch 210/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 854982487310.2622 - val_loss: 912807210324.7572\n",
      "Epoch 211/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 861427963729.9719 - val_loss: 912190311845.4098\n",
      "Epoch 212/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 850095634230.3118 - val_loss: 906311106394.0861\n",
      "Epoch 213/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 847169282661.1323 - val_loss: 920918132854.0985\n",
      "Epoch 214/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 850961938239.5317 - val_loss: 903643051402.3336\n",
      "Epoch 215/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 846849628276.4030 - val_loss: 903754061975.5117\n",
      "Epoch 216/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 844514698953.9763 - val_loss: 910405789664.3151\n",
      "Epoch 217/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 848587282548.4030 - val_loss: 912147783166.1277\n",
      "Epoch 218/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 847428393933.8660 - val_loss: 900704864927.1449\n",
      "Epoch 219/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 845233492537.3370 - val_loss: 897481417462.1344\n",
      "Epoch 220/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 843306335315.5565 - val_loss: 902779351241.6315\n",
      "Epoch 221/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 837641197941.4114 - val_loss: 895807391078.6161\n",
      "Epoch 222/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 843053372016.6573 - val_loss: 894166891493.2118\n",
      "Epoch 223/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 839115246193.8098 - val_loss: 894578908342.9086\n",
      "Epoch 224/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 845180821646.9105 - val_loss: 891821845453.0160\n",
      "Epoch 225/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 842312400164.1599 - val_loss: 902041091888.6075\n",
      "Epoch 226/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 833141171969.2965 - val_loss: 894193977752.4479\n",
      "Epoch 227/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 835198472180.4750 - val_loss: 925890131273.8115\n",
      "Epoch 228/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 838441949586.2240 - val_loss: 893299791479.6827\n",
      "Epoch 229/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 832321150026.3364 - val_loss: 888915380392.7944\n",
      "Epoch 230/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 831975783304.7158 - val_loss: 890018904816.9497\n",
      "Epoch 231/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 830048546200.5627 - val_loss: 886786941193.0015\n",
      "Epoch 232/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 835511812667.6422 - val_loss: 893218974162.0568\n",
      "Epoch 233/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 833634132802.4131 - val_loss: 896764205341.1646\n",
      "Epoch 234/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 832648065975.9685 - val_loss: 884737929744.8506\n",
      "Epoch 235/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 832636765755.0658 - val_loss: 885621752886.4406\n",
      "Epoch 236/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 828070459411.5925 - val_loss: 906484218954.6036\n",
      "Epoch 237/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 830747993230.3342 - val_loss: 893120069608.9564\n",
      "Epoch 238/7000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 827535904055.7524 - val_loss: 879577928284.8945\n",
      "Epoch 239/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 826082853417.2020 - val_loss: 898306957420.3049\n",
      "Epoch 240/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 823473593487.4868 - val_loss: 878509993909.1083\n",
      "Epoch 241/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 826484056879.9730 - val_loss: 882102933839.8605\n",
      "Epoch 242/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 829610438743.5902 - val_loss: 877237172446.9468\n",
      "Epoch 243/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 821596324540.7225 - val_loss: 874847235887.4554\n",
      "Epoch 244/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 819851636212.7631 - val_loss: 875812525033.2444\n",
      "Epoch 245/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 819649484317.1007 - val_loss: 873075100286.8838\n",
      "Epoch 246/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 820073912510.1632 - val_loss: 874269099048.6144\n",
      "Epoch 247/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 820335512140.9297 - val_loss: 873427621232.9856\n",
      "Epoch 248/7000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 818436389427.5745 - val_loss: 872357800286.8389\n",
      "Epoch 249/7000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 819359428518.1046 - val_loss: 887737253639.1292\n",
      "Epoch 250/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 821829603427.1154 - val_loss: 872110912809.5505\n",
      "Epoch 251/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 816346884818.6201 - val_loss: 874122768590.2402\n",
      "Epoch 252/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 71us/step - loss: 817380128815.2527 - val_loss: 878371689334.0265\n",
      "Epoch 253/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 817560032483.6195 - val_loss: 881064457001.9825\n",
      "Epoch 254/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 818091602871.9685 - val_loss: 867851720039.7682\n",
      "Epoch 255/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 812116366922.0483 - val_loss: 879751754957.3761\n",
      "Epoch 256/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 813348978485.1593 - val_loss: 881945410136.8619\n",
      "Epoch 257/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 818689712787.2324 - val_loss: 866120531516.3455\n",
      "Epoch 258/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 815792330103.1401 - val_loss: 866334309349.2118\n",
      "Epoch 259/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 813288729805.7220 - val_loss: 866215359158.7645\n",
      "Epoch 260/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 815501801473.1526 - val_loss: 870537406409.2715\n",
      "Epoch 261/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 811444189065.2920 - val_loss: 864137940057.5820\n",
      "Epoch 262/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 813000577971.3584 - val_loss: 865151659892.5862\n",
      "Epoch 263/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 810858999201.7827 - val_loss: 865503775188.3612\n",
      "Epoch 264/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 811340634624.8643 - val_loss: 862025628751.2124\n",
      "Epoch 265/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 812031291643.2460 - val_loss: 863656626584.4479\n",
      "Epoch 266/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 806503936442.5616 - val_loss: 860866815198.6588\n",
      "Epoch 267/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 808408066355.7186 - val_loss: 862420965859.3395\n",
      "Epoch 268/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 808944545287.2031 - val_loss: 859419076401.1837\n",
      "Epoch 269/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 806585997492.9432 - val_loss: 859177237076.2532\n",
      "Epoch 270/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 813921140772.8802 - val_loss: 869652098642.2368\n",
      "Epoch 271/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 807127365716.1329 - val_loss: 858579507204.0326\n",
      "Epoch 272/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 807845947745.8187 - val_loss: 857932857463.8268\n",
      "Epoch 273/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 802291775323.1919 - val_loss: 856223658102.6746\n",
      "Epoch 274/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 804457000639.6038 - val_loss: 871956296462.3302\n",
      "Epoch 275/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 806379996067.2234 - val_loss: 857961992050.2819\n",
      "Epoch 276/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 803637538290.4581 - val_loss: 858062629297.7958\n",
      "Epoch 277/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 804068227073.1526 - val_loss: 862899437134.7803\n",
      "Epoch 278/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 803153534445.8480 - val_loss: 853439183172.3386\n",
      "Epoch 279/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 800929604736.5043 - val_loss: 854110221153.2872\n",
      "Epoch 280/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 801253067967.8920 - val_loss: 864780367850.6847\n",
      "Epoch 281/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 802223978663.1130 - val_loss: 853436390592.1260\n",
      "Epoch 282/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 801626376218.5076 - val_loss: 851517229344.6211\n",
      "Epoch 283/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 800227870903.2482 - val_loss: 852269950096.3105\n",
      "Epoch 284/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 802073236956.5604 - val_loss: 849707318378.8647\n",
      "Epoch 285/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 800735930362.2374 - val_loss: 848920905652.5322\n",
      "Epoch 286/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 797989697721.5531 - val_loss: 851194818263.8898\n",
      "Epoch 287/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 797556084106.7327 - val_loss: 849455666406.7240\n",
      "Epoch 288/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 797249524769.9989 - val_loss: 847983527441.1387\n",
      "Epoch 289/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 801693708244.2048 - val_loss: 848382020941.8441\n",
      "Epoch 290/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 800911936012.3895 - val_loss: 850776935361.4943\n",
      "Epoch 291/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 794412621026.4670 - val_loss: 846941266235.6974\n",
      "Epoch 292/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 802186174772.8711 - val_loss: 846713611666.3989\n",
      "Epoch 293/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 795095591487.0996 - val_loss: 845652299735.6737\n",
      "Epoch 294/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 794979520057.9133 - val_loss: 846043519855.6895\n",
      "Epoch 295/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 796106689801.6522 - val_loss: 867561083420.3724\n",
      "Epoch 296/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 796838745380.1599 - val_loss: 854160790500.6357\n",
      "Epoch 297/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 801997449265.5576 - val_loss: 845689333981.7947\n",
      "Epoch 298/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 793786319290.5616 - val_loss: 843906303993.6630\n",
      "Epoch 299/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 803712978729.6343 - val_loss: 845348366885.0138\n",
      "Epoch 300/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 794877138424.2206 - val_loss: 844099286921.9015\n",
      "Epoch 301/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 792304425011.8627 - val_loss: 843812096574.3617\n",
      "Epoch 302/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 798429241735.8513 - val_loss: 842907705894.7421\n",
      "Epoch 303/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 792275023292.2904 - val_loss: 841015675961.3209\n",
      "Epoch 304/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 790232729112.4907 - val_loss: 840541519037.8217\n",
      "Epoch 305/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 790573120005.4744 - val_loss: 851359013162.9907\n",
      "Epoch 306/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 788978618319.5947 - val_loss: 843745386005.1713\n",
      "Epoch 307/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 791196587595.2009 - val_loss: 839975868097.4222\n",
      "Epoch 308/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 791810005956.6461 - val_loss: 856067381814.2965\n",
      "Epoch 309/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 794527264364.6234 - val_loss: 843180817680.7786\n",
      "Epoch 310/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 797947318684.5964 - val_loss: 839282293032.6864\n",
      "Epoch 311/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 798758580678.0867 - val_loss: 839398199596.7190\n",
      "Epoch 312/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 792120576653.4700 - val_loss: 839981975287.5747\n",
      "Epoch 313/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 788284730822.6630 - val_loss: 853379699629.3311\n",
      "Epoch 314/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 798665208990.4694 - val_loss: 839312700566.0714\n",
      "Epoch 315/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 76us/step - loss: 786661612309.4655 - val_loss: 866212373454.7443\n",
      "Epoch 316/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 793862525469.6770 - val_loss: 836488613142.5396\n",
      "Epoch 317/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 789117400038.0686 - val_loss: 837656982424.5918\n",
      "Epoch 318/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 794576307734.1858 - val_loss: 839938332007.7682\n",
      "Epoch 319/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 787567821768.1035 - val_loss: 843189205625.1229\n",
      "Epoch 320/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 788151835699.2864 - val_loss: 838776101162.9907\n",
      "Epoch 321/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 786329709404.9207 - val_loss: 834509896778.6036\n",
      "Epoch 322/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 788337557522.4401 - val_loss: 834604345943.7097\n",
      "Epoch 323/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 785839958176.1981 - val_loss: 834295578093.9972\n",
      "Epoch 324/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 789050397462.6178 - val_loss: 846743799428.3567\n",
      "Epoch 325/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 789790411202.6293 - val_loss: 833887094584.0968\n",
      "Epoch 326/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 790631946503.9235 - val_loss: 835224698197.9094\n",
      "Epoch 327/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 788531804714.3545 - val_loss: 835243633124.4917\n",
      "Epoch 328/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 782848963954.5300 - val_loss: 848896098460.6965\n",
      "Epoch 329/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 786171401093.2583 - val_loss: 832554809387.2068\n",
      "Epoch 330/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 788244532581.8525 - val_loss: 832541176101.8059\n",
      "Epoch 331/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 787122831645.8210 - val_loss: 839594614048.9092\n",
      "Epoch 332/7000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 790812036933.2943 - val_loss: 858308608562.2638\n",
      "Epoch 333/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 782755106371.1334 - val_loss: 830937013730.4753\n",
      "Epoch 334/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 781388930302.1272 - val_loss: 836674617362.4349\n",
      "Epoch 335/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 780935640471.4103 - val_loss: 830796398020.5187\n",
      "Epoch 336/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 782385127142.7889 - val_loss: 831447794641.0487\n",
      "Epoch 337/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 785034559202.1790 - val_loss: 830745255827.6951\n",
      "Epoch 338/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 784889438138.8497 - val_loss: 852526448690.6959\n",
      "Epoch 339/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 788140621104.8373 - val_loss: 830208289579.7108\n",
      "Epoch 340/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 787607240750.1001 - val_loss: 859780278553.7080\n",
      "Epoch 341/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 782659769968.0809 - val_loss: 827749283035.2023\n",
      "Epoch 342/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 784493691682.1429 - val_loss: 829859123975.4171\n",
      "Epoch 343/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 779590980319.2976 - val_loss: 835077324528.0856\n",
      "Epoch 344/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 780772935568.2072 - val_loss: 861408093918.2267\n",
      "Epoch 345/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 781569467783.2751 - val_loss: 831013081282.7184\n",
      "Epoch 346/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 782248649252.5919 - val_loss: 828078183258.3741\n",
      "Epoch 347/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 779335058578.9443 - val_loss: 835875767737.5730\n",
      "Epoch 348/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 778734109114.5616 - val_loss: 839394618611.9741\n",
      "Epoch 349/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 777733673068.3353 - val_loss: 826122851199.2439\n",
      "Epoch 350/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 780510339196.4705 - val_loss: 827346453309.5696\n",
      "Epoch 351/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 779795725026.7552 - val_loss: 830528345641.3345\n",
      "Epoch 352/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 779168533004.3895 - val_loss: 827529309847.3677\n",
      "Epoch 353/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 775645928766.6675 - val_loss: 827046955457.9263\n",
      "Epoch 354/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 780082881927.2751 - val_loss: 826352616147.5691\n",
      "Epoch 355/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 776303621969.9719 - val_loss: 836301559129.9420\n",
      "Epoch 356/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 777293094160.5673 - val_loss: 824279540036.9148\n",
      "Epoch 357/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 780390531274.8407 - val_loss: 830291307109.5359\n",
      "Epoch 358/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 780238653199.1267 - val_loss: 824643348844.6650\n",
      "Epoch 359/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 777930484981.4834 - val_loss: 824061670038.5035\n",
      "Epoch 360/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 777258726558.4694 - val_loss: 827806348926.5958\n",
      "Epoch 361/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 777110542189.6321 - val_loss: 823568301812.6942\n",
      "Epoch 362/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 774562595396.8621 - val_loss: 826534463301.9230\n",
      "Epoch 363/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 775728892529.8098 - val_loss: 831113089144.9789\n",
      "Epoch 364/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 783145573531.0118 - val_loss: 822727119969.0712\n",
      "Epoch 365/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 775513290670.1722 - val_loss: 823191525356.9890\n",
      "Epoch 366/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 776462305426.3679 - val_loss: 822668996164.4106\n",
      "Epoch 367/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 781866526244.0157 - val_loss: 825130062576.3735\n",
      "Epoch 368/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 774467391872.9364 - val_loss: 832389515289.9241\n",
      "Epoch 369/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 777691933422.2803 - val_loss: 820686884943.5004\n",
      "Epoch 370/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 772277590556.5244 - val_loss: 824036257058.0613\n",
      "Epoch 371/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 777064480731.1198 - val_loss: 821952634195.6051\n",
      "Epoch 372/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 772595056676.8802 - val_loss: 830515325278.8389\n",
      "Epoch 373/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 776101078591.6759 - val_loss: 822758109021.5426\n",
      "Epoch 374/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 772052663776.0179 - val_loss: 818975127484.5974\n",
      "Epoch 375/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 773363424639.2076 - val_loss: 825355309550.2853\n",
      "Epoch 376/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 775751489154.5211 - val_loss: 842388669144.1777\n",
      "Epoch 377/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 779034477622.7439 - val_loss: 823930653444.5367\n",
      "Epoch 378/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 77us/step - loss: 776495821871.8289 - val_loss: 829011301611.3328\n",
      "Epoch 379/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 772261444064.5942 - val_loss: 834839094973.9657\n",
      "Epoch 380/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 772866332382.7214 - val_loss: 830554140067.1055\n",
      "Epoch 381/7000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 773088738627.2775 - val_loss: 830323568998.3280\n",
      "Epoch 382/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 774221677714.9443 - val_loss: 821088435352.9519\n",
      "Epoch 383/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 774442451405.0017 - val_loss: 819034482278.4000\n",
      "Epoch 384/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 780139071099.6060 - val_loss: 834299359926.7645\n",
      "Epoch 385/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 771752542678.2217 - val_loss: 834473252374.8995\n",
      "Epoch 386/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 772174642277.9966 - val_loss: 824667608013.5922\n",
      "Epoch 387/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 772391471619.1694 - val_loss: 821149814766.7173\n",
      "Epoch 388/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 770393885509.8705 - val_loss: 817113981681.5258\n",
      "Epoch 389/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 770896776503.7524 - val_loss: 818741136948.2802\n",
      "Epoch 390/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 778711775592.7339 - val_loss: 837206135163.0673\n",
      "Epoch 391/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 770943080582.8429 - val_loss: 816845141902.5103\n",
      "Epoch 392/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 766292773259.3090 - val_loss: 829442830095.1943\n",
      "Epoch 393/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 771306465495.5183 - val_loss: 814348323500.9711\n",
      "Epoch 394/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 772323788300.9657 - val_loss: 828538745858.5924\n",
      "Epoch 395/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 772832344793.5352 - val_loss: 816691452230.6431\n",
      "Epoch 396/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 775266953643.5790 - val_loss: 819508783003.1842\n",
      "Epoch 397/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 770001290294.7439 - val_loss: 834438950297.8881\n",
      "Epoch 398/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 769893698364.6506 - val_loss: 817304295810.5564\n",
      "Epoch 399/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 770006262898.6742 - val_loss: 814527260958.3168\n",
      "Epoch 400/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 772496824754.4941 - val_loss: 820267320936.7043\n",
      "Epoch 401/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 769393191173.6184 - val_loss: 814972231742.2178\n",
      "Epoch 402/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 771753973074.2600 - val_loss: 814019833905.5437\n",
      "Epoch 403/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 769787162257.5037 - val_loss: 861294517827.2585\n",
      "Epoch 404/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 773330630048.6304 - val_loss: 814776544638.2357\n",
      "Epoch 405/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 770398584702.9196 - val_loss: 814749289377.2332\n",
      "Epoch 406/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 772611657532.0742 - val_loss: 812005320239.0953\n",
      "Epoch 407/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 768566439804.0382 - val_loss: 812088014614.6836\n",
      "Epoch 408/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 767593984601.6072 - val_loss: 811421357646.2042\n",
      "Epoch 409/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 766619577411.4215 - val_loss: 814577968438.2245\n",
      "Epoch 410/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 764701904266.7327 - val_loss: 814626287743.8920\n",
      "Epoch 411/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 769907829006.8385 - val_loss: 821833273580.1969\n",
      "Epoch 412/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 767470184725.7535 - val_loss: 837384706540.5570\n",
      "Epoch 413/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 767735196204.6595 - val_loss: 814411695577.8340\n",
      "Epoch 414/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 764973583072.4502 - val_loss: 811845976700.0034\n",
      "Epoch 415/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 766092492090.0574 - val_loss: 810104413606.5620\n",
      "Epoch 416/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 764945526841.6252 - val_loss: 812762902259.5421\n",
      "Epoch 417/7000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 765766147906.9893 - val_loss: 811433869952.6121\n",
      "Epoch 418/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 770037299929.5352 - val_loss: 811784260914.1919\n",
      "Epoch 419/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 768630068783.5408 - val_loss: 818058101113.9150\n",
      "Epoch 420/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 764483889598.0192 - val_loss: 811366411830.5845\n",
      "Epoch 421/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 772522007293.8390 - val_loss: 816520957275.6703\n",
      "Epoch 422/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 764711275140.2499 - val_loss: 811887735179.1978\n",
      "Epoch 423/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 764957464351.2617 - val_loss: 808652153783.7007\n",
      "Epoch 424/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 768784045633.9808 - val_loss: 815303836952.2678\n",
      "Epoch 425/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 769014290032.0809 - val_loss: 810193692654.1412\n",
      "Epoch 426/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 764736263312.6393 - val_loss: 809726963125.5404\n",
      "Epoch 427/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 765148748473.2650 - val_loss: 813324439557.7609\n",
      "Epoch 428/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 764160684117.2853 - val_loss: 808820093443.0244\n",
      "Epoch 429/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 764063881765.7445 - val_loss: 815090415908.0776\n",
      "Epoch 430/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 763101984520.2117 - val_loss: 808292973845.3873\n",
      "Epoch 431/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 763402714988.4795 - val_loss: 816103814441.5505\n",
      "Epoch 432/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 764688412701.9651 - val_loss: 812660333552.7336\n",
      "Epoch 433/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 767168727509.0692 - val_loss: 835994148870.9131\n",
      "Epoch 434/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 771395761301.2493 - val_loss: 812610789737.7845\n",
      "Epoch 435/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 763005073187.8716 - val_loss: 815837784239.7074\n",
      "Epoch 436/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 768041799193.6433 - val_loss: 812600248276.7932\n",
      "Epoch 437/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 762700561210.3455 - val_loss: 812412732387.4835\n",
      "Epoch 438/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 761756396122.7596 - val_loss: 806572983700.7032\n",
      "Epoch 439/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 763836962499.0613 - val_loss: 812368764137.6045\n",
      "Epoch 440/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 765318610999.3202 - val_loss: 807185044369.6787\n",
      "Epoch 441/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 74us/step - loss: 765479339173.3844 - val_loss: 808963910065.7958\n",
      "Epoch 442/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 771165692249.7512 - val_loss: 814746706503.0031\n",
      "Epoch 443/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 765950358575.8289 - val_loss: 823987919391.2529\n",
      "Epoch 444/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 762181009398.7799 - val_loss: 810504468661.4684\n",
      "Epoch 445/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 763263533544.6619 - val_loss: 806434169428.8292\n",
      "Epoch 446/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 759425221115.1018 - val_loss: 816889855271.8223\n",
      "Epoch 447/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 760390304361.7423 - val_loss: 809500467566.3932\n",
      "Epoch 448/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 765765010671.1447 - val_loss: 805708204168.5333\n",
      "Epoch 449/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 765036918377.0220 - val_loss: 805044857219.7086\n",
      "Epoch 450/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 765320089274.9938 - val_loss: 811793467616.0990\n",
      "Epoch 451/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 762348699740.2003 - val_loss: 820913480447.3519\n",
      "Epoch 452/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 762725575581.4609 - val_loss: 808376100113.3547\n",
      "Epoch 453/7000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 759960781970.9443 - val_loss: 823685752537.6180\n",
      "Epoch 454/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 760210107800.5627 - val_loss: 807661430531.0964\n",
      "Epoch 455/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 758630406284.6055 - val_loss: 826784257047.3317\n",
      "Epoch 456/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 761864214874.9038 - val_loss: 805841821647.6084\n",
      "Epoch 457/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 758517398408.7158 - val_loss: 872337960345.8881\n",
      "Epoch 458/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 766818370688.5043 - val_loss: 834826546498.3224\n",
      "Epoch 459/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 758610247228.2184 - val_loss: 807076068951.9978\n",
      "Epoch 460/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 759747326636.5874 - val_loss: 811982575412.6403\n",
      "Epoch 461/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 762123534179.2594 - val_loss: 803255640126.2178\n",
      "Epoch 462/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 765976964495.3427 - val_loss: 816636448455.7592\n",
      "Epoch 463/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 758809227561.3461 - val_loss: 802899101500.7054\n",
      "Epoch 464/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 760130217683.1964 - val_loss: 803726023512.6459\n",
      "Epoch 465/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 760698733263.1627 - val_loss: 803746298701.1240\n",
      "Epoch 466/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 758437266719.5498 - val_loss: 807897789037.0250\n",
      "Epoch 467/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 760724434287.0725 - val_loss: 808928302356.8113\n",
      "Epoch 468/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 760066454437.5284 - val_loss: 823379093804.1429\n",
      "Epoch 469/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 760336934675.7367 - val_loss: 806261969155.2405\n",
      "Epoch 470/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 760793575804.3263 - val_loss: 804686922622.0917\n",
      "Epoch 471/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 758495418899.3044 - val_loss: 801548670132.0281\n",
      "Epoch 472/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 759183750385.4497 - val_loss: 844472827042.1693\n",
      "Epoch 473/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 758633929382.8250 - val_loss: 802099812240.8146\n",
      "Epoch 474/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 769556557651.1243 - val_loss: 806544684656.7697\n",
      "Epoch 475/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 760543135217.3055 - val_loss: 801675227835.3733\n",
      "Epoch 476/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 758310297060.6281 - val_loss: 800436330793.2625\n",
      "Epoch 477/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 758103116069.8887 - val_loss: 820100861570.6284\n",
      "Epoch 478/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 763990923057.7018 - val_loss: 806917134962.2098\n",
      "Epoch 479/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 760742089328.6573 - val_loss: 802140181790.0287\n",
      "Epoch 480/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 754447507552.8103 - val_loss: 807434542207.6039\n",
      "Epoch 481/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 763390667368.5897 - val_loss: 807917859284.9373\n",
      "Epoch 482/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 754397739765.1953 - val_loss: 800863656741.9500\n",
      "Epoch 483/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 755839244745.5442 - val_loss: 817408207867.1033\n",
      "Epoch 484/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 757433709599.6938 - val_loss: 801023231279.3114\n",
      "Epoch 485/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 757052795215.3788 - val_loss: 798949432604.3004\n",
      "Epoch 486/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 755448867759.9010 - val_loss: 801110601487.1943\n",
      "Epoch 487/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 755345434839.5183 - val_loss: 829763546494.2357\n",
      "Epoch 488/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 768457240426.1744 - val_loss: 802439455132.4805\n",
      "Epoch 489/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 760345463133.2089 - val_loss: 798978025684.5773\n",
      "Epoch 490/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 756489416577.2246 - val_loss: 800181742052.4917\n",
      "Epoch 491/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 755478645371.0298 - val_loss: 799778477567.8560\n",
      "Epoch 492/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 753330819046.6450 - val_loss: 820659491476.1991\n",
      "Epoch 493/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 754590100169.4001 - val_loss: 799524535301.4729\n",
      "Epoch 494/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 757749862351.5947 - val_loss: 812847816185.5190\n",
      "Epoch 495/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 758180776266.7687 - val_loss: 804448330287.9595\n",
      "Epoch 496/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 754806331831.1040 - val_loss: 798055770315.3597\n",
      "Epoch 497/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 757156903669.1953 - val_loss: 800152415475.9741\n",
      "Epoch 498/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 755400269441.3685 - val_loss: 810898366816.5671\n",
      "Epoch 499/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 755455090545.0895 - val_loss: 804579208786.2368\n",
      "Epoch 500/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 757474014062.2083 - val_loss: 798082811906.8805\n",
      "Epoch 501/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 755615169361.3956 - val_loss: 799245456375.0706\n",
      "Epoch 502/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 759021335360.1080 - val_loss: 807710216635.5894\n",
      "Epoch 503/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 756343856960.6843 - val_loss: 798649934227.2631\n",
      "Epoch 504/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 77us/step - loss: 756543048997.3123 - val_loss: 808080513737.7755\n",
      "Epoch 505/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 756323858529.9629 - val_loss: 796502421544.3263\n",
      "Epoch 506/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 757151335856.7654 - val_loss: 799086406107.2743\n",
      "Epoch 507/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 757462573659.9122 - val_loss: 797710679510.9536\n",
      "Epoch 508/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 754213686987.1289 - val_loss: 797415090388.5773\n",
      "Epoch 509/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 754179964854.2397 - val_loss: 796671181574.2650\n",
      "Epoch 510/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 751926327970.2150 - val_loss: 800560703405.6191\n",
      "Epoch 511/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 757336389476.4120 - val_loss: 806600989583.9504\n",
      "Epoch 512/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 752012378471.5813 - val_loss: 796430913795.2405\n",
      "Epoch 513/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 756646836796.7946 - val_loss: 795999895183.3024\n",
      "Epoch 514/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 754732988417.1526 - val_loss: 795216007464.1102\n",
      "Epoch 515/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 759125643667.3766 - val_loss: 796987760845.0880\n",
      "Epoch 516/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 751456637543.4373 - val_loss: 795213201832.0022\n",
      "Epoch 517/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 753249957985.9629 - val_loss: 803509695582.7668\n",
      "Epoch 518/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 755032365771.7052 - val_loss: 795497201691.6523\n",
      "Epoch 519/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 759769352038.7169 - val_loss: 798960613691.1212\n",
      "Epoch 520/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 753735563597.0737 - val_loss: 795477183761.9308\n",
      "Epoch 521/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 753893247435.8491 - val_loss: 795335464825.7710\n",
      "Epoch 522/7000\n",
      "3554/3554 [==============================] - 0s 68us/step - loss: 757964098724.2318 - val_loss: 805310097330.2279\n",
      "Epoch 523/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 756203121694.5414 - val_loss: 793911160254.7578\n",
      "Epoch 524/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 754538293952.1802 - val_loss: 810281396385.8813\n",
      "Epoch 525/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 751989158664.7878 - val_loss: 795947518526.3617\n",
      "Epoch 526/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 753952658087.9775 - val_loss: 801009258381.9342\n",
      "Epoch 527/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 753638904727.6984 - val_loss: 795400960527.1223\n",
      "Epoch 528/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 751055240423.0770 - val_loss: 803165201976.3127\n",
      "Epoch 529/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 760475922996.7271 - val_loss: 803227850921.9465\n",
      "Epoch 530/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 750889504046.5323 - val_loss: 795448833800.8574\n",
      "Epoch 531/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 750814949452.0652 - val_loss: 793743837297.4897\n",
      "Epoch 532/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 756126537364.9612 - val_loss: 828391415372.4760\n",
      "Epoch 533/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 757931395338.2285 - val_loss: 795033920997.3558\n",
      "Epoch 534/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 749855701159.1130 - val_loss: 808061698186.2616\n",
      "Epoch 535/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 755138985596.7585 - val_loss: 796133650546.0658\n",
      "Epoch 536/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 755136283094.2217 - val_loss: 801437242644.8113\n",
      "Epoch 537/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 751350639904.7024 - val_loss: 792565615604.1902\n",
      "Epoch 538/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 751693156635.5160 - val_loss: 824582833556.7032\n",
      "Epoch 539/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 757647719562.8768 - val_loss: 793371389655.8898\n",
      "Epoch 540/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 752432115179.5430 - val_loss: 799334451931.0582\n",
      "Epoch 541/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 752166650584.3827 - val_loss: 792094188821.9634\n",
      "Epoch 542/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 762792755190.7799 - val_loss: 792652562648.6099\n",
      "Epoch 543/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 751625282499.4935 - val_loss: 792770460161.2961\n",
      "Epoch 544/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 749749081776.6212 - val_loss: 793771461652.4512\n",
      "Epoch 545/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 748504132315.8401 - val_loss: 801730716401.5258\n",
      "Epoch 546/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 752507049141.5194 - val_loss: 792140471266.9075\n",
      "Epoch 547/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 749457412093.6951 - val_loss: 801393205743.4374\n",
      "Epoch 548/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 751117125510.9871 - val_loss: 803336101779.6951\n",
      "Epoch 549/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 751945896717.3979 - val_loss: 809040274760.6593\n",
      "Epoch 550/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 757805061163.2189 - val_loss: 805179145903.5635\n",
      "Epoch 551/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 748918635234.7552 - val_loss: 793992548666.5452\n",
      "Epoch 552/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 749866091021.5419 - val_loss: 799658830631.1021\n",
      "Epoch 553/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 751580185479.5632 - val_loss: 795578826484.6942\n",
      "Epoch 554/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 752535930049.0444 - val_loss: 793782657173.7834\n",
      "Epoch 555/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 750929283329.0084 - val_loss: 794940709227.5128\n",
      "Epoch 556/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 751535835346.9083 - val_loss: 811148524521.8206\n",
      "Epoch 557/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 752059022585.5172 - val_loss: 803363112142.5283\n",
      "Epoch 558/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 751077386095.3607 - val_loss: 798748539490.0793\n",
      "Epoch 559/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 751252395613.6410 - val_loss: 793306694111.3069\n",
      "Epoch 560/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 753468297481.0759 - val_loss: 791415048655.7524\n",
      "Epoch 561/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 747922986100.9792 - val_loss: 789447993819.2743\n",
      "Epoch 562/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 747978746833.3235 - val_loss: 792588228086.6385\n",
      "Epoch 563/7000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 748239450999.4283 - val_loss: 789208493853.0205\n",
      "Epoch 564/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 750913166267.4260 - val_loss: 797856389663.2529\n",
      "Epoch 565/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 748502332417.7288 - val_loss: 795492039814.5170\n",
      "Epoch 566/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 752997293678.9286 - val_loss: 791504622117.5898\n",
      "Epoch 567/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 81us/step - loss: 748052484683.7771 - val_loss: 790568408700.2914\n",
      "Epoch 568/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 747243023989.8435 - val_loss: 791654356124.9845\n",
      "Epoch 569/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 748598951032.4368 - val_loss: 790183667099.6163\n",
      "Epoch 570/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 749065805077.1772 - val_loss: 792648026340.7078\n",
      "Epoch 571/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 748732559537.4857 - val_loss: 789211672284.4984\n",
      "Epoch 572/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 748578747117.1278 - val_loss: 790725124655.9595\n",
      "Epoch 573/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 751148384597.1414 - val_loss: 789146667347.3170\n",
      "Epoch 574/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 747367721474.0168 - val_loss: 790037148439.5477\n",
      "Epoch 575/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 748174910209.8728 - val_loss: 792800826962.8130\n",
      "Epoch 576/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 747744397624.3286 - val_loss: 789302732178.3989\n",
      "Epoch 577/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 749509709323.8131 - val_loss: 791254242714.4641\n",
      "Epoch 578/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 749744188165.3303 - val_loss: 793663102171.7783\n",
      "Epoch 579/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 746775865273.6973 - val_loss: 812340535385.8700\n",
      "Epoch 580/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 746669863836.3083 - val_loss: 801917601974.6205\n",
      "Epoch 581/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 753899882282.7867 - val_loss: 799344186266.8962\n",
      "Epoch 582/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 750579932635.4081 - val_loss: 791121078014.4878\n",
      "Epoch 583/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 749078047700.7811 - val_loss: 791633991324.5525\n",
      "Epoch 584/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 753935361286.1947 - val_loss: 788474290192.1305\n",
      "Epoch 585/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 749595718445.6680 - val_loss: 790263444173.8081\n",
      "Epoch 586/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 745049173769.3640 - val_loss: 792245748053.0453\n",
      "Epoch 587/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 746189988960.2341 - val_loss: 788547069192.1373\n",
      "Epoch 588/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 745737897955.1874 - val_loss: 788036055181.7181\n",
      "Epoch 589/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 746514895804.7225 - val_loss: 789377845402.9683\n",
      "Epoch 590/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 746488907986.9083 - val_loss: 787564076413.0835\n",
      "Epoch 591/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 749468188524.4795 - val_loss: 814330870314.7747\n",
      "Epoch 592/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 744992181661.1729 - val_loss: 788857389028.3477\n",
      "Epoch 593/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 745058824876.5874 - val_loss: 787418212504.6638\n",
      "Epoch 594/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 746983925403.8762 - val_loss: 819179373276.7865\n",
      "Epoch 595/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 746276407525.3483 - val_loss: 786740314877.0475\n",
      "Epoch 596/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 747014494140.0022 - val_loss: 787291956644.8337\n",
      "Epoch 597/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 747910585091.0253 - val_loss: 785876169255.8943\n",
      "Epoch 598/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 744564063942.5188 - val_loss: 795876068662.8005\n",
      "Epoch 599/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 745415107375.9730 - val_loss: 787948754169.1589\n",
      "Epoch 600/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 746145371004.0382 - val_loss: 798811010755.7266\n",
      "Epoch 601/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 745935220618.4446 - val_loss: 808345820545.6923\n",
      "Epoch 602/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 755433486088.2117 - val_loss: 789050697470.4878\n",
      "Epoch 603/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 748485079595.5071 - val_loss: 791224668557.5021\n",
      "Epoch 604/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 743991356400.4413 - val_loss: 790182794917.7699\n",
      "Epoch 605/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 747942400799.8379 - val_loss: 788369079582.6047\n",
      "Epoch 606/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 743045971424.0179 - val_loss: 798992316440.7719\n",
      "Epoch 607/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 743475353670.3027 - val_loss: 786710619999.2709\n",
      "Epoch 608/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 750063434014.9735 - val_loss: 795585173982.7308\n",
      "Epoch 609/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 746086400175.1807 - val_loss: 786528646510.6813\n",
      "Epoch 610/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 745759466398.6133 - val_loss: 790547764321.0712\n",
      "Epoch 611/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 745277479968.8463 - val_loss: 794618646916.2847\n",
      "Epoch 612/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 746038388518.1768 - val_loss: 787569119182.4563\n",
      "Epoch 613/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 748233398692.6641 - val_loss: 785046838007.8627\n",
      "Epoch 614/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 743310372082.6021 - val_loss: 807170121702.6521\n",
      "Epoch 615/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 750614450634.6967 - val_loss: 785365548443.0403\n",
      "Epoch 616/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 744549102750.4694 - val_loss: 791572743655.6602\n",
      "Epoch 617/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 747013287375.8831 - val_loss: 789695650667.0807\n",
      "Epoch 618/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 744816052241.2876 - val_loss: 787569245313.9083\n",
      "Epoch 619/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 746052072892.2904 - val_loss: 788939235039.9550\n",
      "Epoch 620/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 745769025563.6602 - val_loss: 808749213632.0540\n",
      "Epoch 621/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 750502781310.6315 - val_loss: 787120363385.7710\n",
      "Epoch 622/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 742028422829.1638 - val_loss: 786854812103.6873\n",
      "Epoch 623/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 748117620239.2706 - val_loss: 786367214179.8076\n",
      "Epoch 624/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 742907386682.3455 - val_loss: 792322925767.6152\n",
      "Epoch 625/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 745717633759.2976 - val_loss: 789002438557.4886\n",
      "Epoch 626/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 744316143179.2009 - val_loss: 792504552671.2349\n",
      "Epoch 627/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 740734325923.0793 - val_loss: 787030661248.4680\n",
      "Epoch 628/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 745413897117.4609 - val_loss: 783821174103.6377\n",
      "Epoch 629/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 748771989601.9629 - val_loss: 784101291402.3336\n",
      "Epoch 630/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 73us/step - loss: 747603995097.6793 - val_loss: 783435396153.8971\n",
      "Epoch 631/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 748680796423.9235 - val_loss: 801157446200.6008\n",
      "Epoch 632/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 743786254462.7754 - val_loss: 802604410184.6593\n",
      "Epoch 633/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 744246551002.8317 - val_loss: 793533310566.4000\n",
      "Epoch 634/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 747007264683.8671 - val_loss: 784298423155.7220\n",
      "Epoch 635/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 743037725512.1757 - val_loss: 785576338709.9634\n",
      "Epoch 636/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 741060834167.4283 - val_loss: 783049997511.0391\n",
      "Epoch 637/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 740731594727.7974 - val_loss: 783959634909.7227\n",
      "Epoch 638/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 750453612419.5295 - val_loss: 797728517294.8433\n",
      "Epoch 639/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 759995853032.8058 - val_loss: 782971656578.5564\n",
      "Epoch 640/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 742891155734.9061 - val_loss: 781931728722.0209\n",
      "Epoch 641/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 751796594571.5970 - val_loss: 781551864737.2332\n",
      "Epoch 642/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 745692159791.3969 - val_loss: 797217231757.0701\n",
      "Epoch 643/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 746068431260.5964 - val_loss: 784665456850.8490\n",
      "Epoch 644/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 740888060249.7512 - val_loss: 784805679519.9370\n",
      "Epoch 645/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 741183371283.5925 - val_loss: 782935277332.9553\n",
      "Epoch 646/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 741086769606.0867 - val_loss: 786454396103.0391\n",
      "Epoch 647/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 745089659094.3657 - val_loss: 784543926072.0968\n",
      "Epoch 648/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 739791015712.4142 - val_loss: 780547055263.4329\n",
      "Epoch 649/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 745664729758.7574 - val_loss: 779456636149.7024\n",
      "Epoch 650/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 738522186530.1429 - val_loss: 799641773214.1367\n",
      "Epoch 651/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 744008133468.9207 - val_loss: 788333973339.2383\n",
      "Epoch 652/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 738992470063.2527 - val_loss: 784881771848.6593\n",
      "Epoch 653/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 747261178383.8469 - val_loss: 780653304848.9946\n",
      "Epoch 654/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 744863440043.1470 - val_loss: 800250835578.8512\n",
      "Epoch 655/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 736966247967.4058 - val_loss: 778577294896.2476\n",
      "Epoch 656/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 742533097291.0568 - val_loss: 778769633829.5898\n",
      "Epoch 657/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 741235240289.2426 - val_loss: 780089417633.5212\n",
      "Epoch 658/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 737988480818.8542 - val_loss: 824018922182.3190\n",
      "Epoch 659/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 745150937476.3940 - val_loss: 797362043393.2961\n",
      "Epoch 660/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 743082943390.6133 - val_loss: 791823040737.8273\n",
      "Epoch 661/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 737716571567.6128 - val_loss: 779776436749.9702\n",
      "Epoch 662/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 740287921078.8159 - val_loss: 780110111892.9193\n",
      "Epoch 663/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 737763643841.4767 - val_loss: 778550584008.0472\n",
      "Epoch 664/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 744597279086.4963 - val_loss: 780090630657.8723\n",
      "Epoch 665/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 739847226551.8243 - val_loss: 776139556323.0515\n",
      "Epoch 666/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 740121472639.0636 - val_loss: 777588560251.0673\n",
      "Epoch 667/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 736871552356.7001 - val_loss: 778592883537.1567\n",
      "Epoch 668/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 737526059687.9775 - val_loss: 777294689923.2045\n",
      "Epoch 669/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 734741148950.3297 - val_loss: 776017916151.7188\n",
      "Epoch 670/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 736764403043.5475 - val_loss: 775828024181.4503\n",
      "Epoch 671/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 733587206090.9849 - val_loss: 775340297950.8029\n",
      "Epoch 672/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 733572647178.2285 - val_loss: 780621907625.2264\n",
      "Epoch 673/7000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 741740877838.9825 - val_loss: 777125940276.7123\n",
      "Epoch 674/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 734364671126.4019 - val_loss: 781905006768.2836\n",
      "Epoch 675/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 736959579024.7833 - val_loss: 774306930270.9109\n",
      "Epoch 676/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 742877694891.2909 - val_loss: 773600153790.1097\n",
      "Epoch 677/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 736798076100.5020 - val_loss: 773721158041.0239\n",
      "Epoch 678/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 732531112407.3741 - val_loss: 779976148335.8335\n",
      "Epoch 679/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 738991451950.2443 - val_loss: 773636884976.0135\n",
      "Epoch 680/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 733777155456.3601 - val_loss: 777044007736.3848\n",
      "Epoch 681/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 741193462693.5284 - val_loss: 775734282510.1862\n",
      "Epoch 682/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 733557163560.6259 - val_loss: 776217467902.5598\n",
      "Epoch 683/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 739690110335.2076 - val_loss: 782602473021.4976\n",
      "Epoch 684/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 735608247966.1813 - val_loss: 772930229741.4211\n",
      "Epoch 685/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 732351977145.8413 - val_loss: 773407301417.6945\n",
      "Epoch 686/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 734078550135.8604 - val_loss: 772022012713.4065\n",
      "Epoch 687/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 736078133451.9933 - val_loss: 771380677601.7552\n",
      "Epoch 688/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 732429979497.0220 - val_loss: 770664902304.5851\n",
      "Epoch 689/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 735811288783.7389 - val_loss: 773971023452.0304\n",
      "Epoch 690/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 735422351432.6077 - val_loss: 771472697869.9702\n",
      "Epoch 691/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 731341596402.8904 - val_loss: 773486762029.5111\n",
      "Epoch 692/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 731121828365.5419 - val_loss: 774118031000.5198\n",
      "Epoch 693/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 83us/step - loss: 734944891117.4159 - val_loss: 788151285711.0323\n",
      "Epoch 694/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 735311878205.0826 - val_loss: 786199955385.1409\n",
      "Epoch 695/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 731189329689.4991 - val_loss: 779917530517.8555\n",
      "Epoch 696/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 730341486345.3640 - val_loss: 771582910618.3921\n",
      "Epoch 697/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 730428818025.7423 - val_loss: 775485755144.2812\n",
      "Epoch 698/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 730014791775.6580 - val_loss: 787470934566.7421\n",
      "Epoch 699/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 733166512113.0175 - val_loss: 773346232857.4919\n",
      "Epoch 700/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 726907967715.0433 - val_loss: 776107117496.2767\n",
      "Epoch 701/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 730283376750.6405 - val_loss: 771328261378.9525\n",
      "Epoch 702/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 732788766103.4103 - val_loss: 775291043107.2135\n",
      "Epoch 703/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 728889478658.5931 - val_loss: 771447979432.8663\n",
      "Epoch 704/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 733575745939.3766 - val_loss: 775597307601.5527\n",
      "Epoch 705/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 728260184636.2184 - val_loss: 769030432427.5308\n",
      "Epoch 706/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 730742779860.2048 - val_loss: 774808941722.6802\n",
      "Epoch 707/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 730806267841.7648 - val_loss: 773734233182.7668\n",
      "Epoch 708/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 728732115898.2734 - val_loss: 771591474560.5400\n",
      "Epoch 709/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 725870372406.4558 - val_loss: 768374152826.5631\n",
      "Epoch 710/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 734029670735.3788 - val_loss: 764684582644.6942\n",
      "Epoch 711/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 730677038004.5110 - val_loss: 764633033492.6672\n",
      "Epoch 712/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 731965435800.2747 - val_loss: 768084120815.9415\n",
      "Epoch 713/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 728606141710.2622 - val_loss: 787137809363.9291\n",
      "Epoch 714/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 736832237579.5250 - val_loss: 768308473679.7164\n",
      "Epoch 715/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 730984566477.4340 - val_loss: 766449922378.6757\n",
      "Epoch 716/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 731173047944.2836 - val_loss: 764112823463.3541\n",
      "Epoch 717/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 726714569540.7181 - val_loss: 765995374024.5514\n",
      "Epoch 718/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 730263335734.8881 - val_loss: 766313245497.5370\n",
      "Epoch 719/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 727645165324.8215 - val_loss: 768130146481.4357\n",
      "Epoch 720/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 730185709285.6365 - val_loss: 762556041283.4026\n",
      "Epoch 721/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 721276722282.6066 - val_loss: 769321973167.2034\n",
      "Epoch 722/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 725480772429.9381 - val_loss: 766637315127.5927\n",
      "Epoch 723/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 729720394878.1992 - val_loss: 762927497667.6545\n",
      "Epoch 724/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 724445403206.3027 - val_loss: 765471755118.5372\n",
      "Epoch 725/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 726445894668.1012 - val_loss: 762539514675.7761\n",
      "Epoch 726/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 723270508539.3900 - val_loss: 775322828463.5635\n",
      "Epoch 727/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 727360209989.1503 - val_loss: 765910549268.0912\n",
      "Epoch 728/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 724041760306.9983 - val_loss: 760527085321.4335\n",
      "Epoch 729/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 724745073038.7665 - val_loss: 761451047382.6655\n",
      "Epoch 730/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 721498189614.2443 - val_loss: 759420030493.2366\n",
      "Epoch 731/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 722349325496.9769 - val_loss: 761072322424.6189\n",
      "Epoch 732/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 721544863204.6281 - val_loss: 761807477477.4279\n",
      "Epoch 733/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 720090505838.3522 - val_loss: 759065206048.9092\n",
      "Epoch 734/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 724769382764.1914 - val_loss: 761220599329.8453\n",
      "Epoch 735/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 725733849264.3331 - val_loss: 766370242912.5671\n",
      "Epoch 736/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 720339659585.2605 - val_loss: 761740821940.9642\n",
      "Epoch 737/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 727835868003.8356 - val_loss: 767257763468.9980\n",
      "Epoch 738/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 718697842198.1858 - val_loss: 759836006109.0746\n",
      "Epoch 739/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 722437397499.9663 - val_loss: 766125897798.8591\n",
      "Epoch 740/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 723699519623.9955 - val_loss: 814299012311.1697\n",
      "Epoch 741/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 725974490439.8876 - val_loss: 764970250731.9808\n",
      "Epoch 742/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 717468494601.9404 - val_loss: 770473917777.3007\n",
      "Epoch 743/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 722617406599.4193 - val_loss: 776614141995.7828\n",
      "Epoch 744/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 719872195944.1576 - val_loss: 763926282069.4773\n",
      "Epoch 745/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 722452421028.6641 - val_loss: 774196301530.1941\n",
      "Epoch 746/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 728192125696.7203 - val_loss: 758617675332.9868\n",
      "Epoch 747/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 715343343019.0028 - val_loss: 759636239306.1356\n",
      "Epoch 748/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 719534833196.0833 - val_loss: 756846904346.7882\n",
      "Epoch 749/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 717779785401.8413 - val_loss: 757957419816.8303\n",
      "Epoch 750/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 717369206824.3376 - val_loss: 764468895893.7834\n",
      "Epoch 751/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 725625105567.6218 - val_loss: 805574848810.4147\n",
      "Epoch 752/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 718814787560.3735 - val_loss: 754820364234.4236\n",
      "Epoch 753/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 715175643144.0675 - val_loss: 757725072100.2756\n",
      "Epoch 754/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 716157900105.0399 - val_loss: 756397685889.9083\n",
      "Epoch 755/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 715085034036.7271 - val_loss: 759160212362.1896\n",
      "Epoch 756/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 77us/step - loss: 720532861778.5481 - val_loss: 754651115859.8931\n",
      "Epoch 757/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 717305388295.3472 - val_loss: 753118285502.5417\n",
      "Epoch 758/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 713757907097.2831 - val_loss: 755531557657.2760\n",
      "Epoch 759/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 722570361561.5352 - val_loss: 752153241821.7947\n",
      "Epoch 760/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 716802775622.0146 - val_loss: 752308561441.2692\n",
      "Epoch 761/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 713919912752.5492 - val_loss: 755934998383.9775\n",
      "Epoch 762/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 712427029521.8638 - val_loss: 754773469212.2284\n",
      "Epoch 763/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 715454456116.8711 - val_loss: 754819559607.1967\n",
      "Epoch 764/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 717247523105.2786 - val_loss: 753178362349.1331\n",
      "Epoch 765/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 717736740162.1249 - val_loss: 777172461743.7074\n",
      "Epoch 766/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 713233928203.5250 - val_loss: 751011980994.5745\n",
      "Epoch 767/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 716964075018.6608 - val_loss: 751829293424.1215\n",
      "Epoch 768/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 711626998525.2628 - val_loss: 756537571689.2085\n",
      "Epoch 769/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 715487691978.2645 - val_loss: 761712175731.3621\n",
      "Epoch 770/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 716061815929.5891 - val_loss: 753903747035.1302\n",
      "Epoch 771/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 709517989119.2797 - val_loss: 753611681721.7170\n",
      "Epoch 772/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 712117872127.1357 - val_loss: 755808390851.1505\n",
      "Epoch 773/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 721294583239.8154 - val_loss: 750948399778.6014\n",
      "Epoch 774/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 715537609549.9381 - val_loss: 756007411331.7806\n",
      "Epoch 775/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 711408863848.5897 - val_loss: 749801874327.4397\n",
      "Epoch 776/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 714044804490.7327 - val_loss: 749076773133.0341\n",
      "Epoch 777/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 710113562474.1744 - val_loss: 747905418990.3573\n",
      "Epoch 778/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 709247479118.8025 - val_loss: 752146376833.6202\n",
      "Epoch 779/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 712379878047.9100 - val_loss: 750509365570.0343\n",
      "Epoch 780/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 710259268198.2848 - val_loss: 747322441852.4354\n",
      "Epoch 781/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 709218046447.5768 - val_loss: 759242027550.6768\n",
      "Epoch 782/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 715843609449.5981 - val_loss: 747143698929.1656\n",
      "Epoch 783/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 709863559414.6360 - val_loss: 779533857361.3727\n",
      "Epoch 784/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 711647995160.6349 - val_loss: 744946806414.1503\n",
      "Epoch 785/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 711773557415.9775 - val_loss: 746490976637.9476\n",
      "Epoch 786/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 709324628378.2915 - val_loss: 769435197843.2631\n",
      "Epoch 787/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 716642556804.1057 - val_loss: 746016461805.8531\n",
      "Epoch 788/7000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 706187655869.8751 - val_loss: 746222296541.8667\n",
      "Epoch 789/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 708321459864.4187 - val_loss: 753159086713.6990\n",
      "Epoch 790/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 707647889357.2898 - val_loss: 745201806063.7975\n",
      "Epoch 791/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 708011773387.2729 - val_loss: 753601953340.3455\n",
      "Epoch 792/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 708056786753.8368 - val_loss: 743134955384.6189\n",
      "Epoch 793/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 708262171875.6195 - val_loss: 743824846164.7572\n",
      "Epoch 794/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 706528643614.8295 - val_loss: 747937560029.2905\n",
      "Epoch 795/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 706010567121.6117 - val_loss: 754087742378.4507\n",
      "Epoch 796/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 708175200698.5616 - val_loss: 753202864485.1758\n",
      "Epoch 797/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 712637769915.8582 - val_loss: 741650913772.5570\n",
      "Epoch 798/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 711926762807.7524 - val_loss: 749482654766.9513\n",
      "Epoch 799/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 708643216693.4474 - val_loss: 742219068768.8551\n",
      "Epoch 800/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 711790722979.7997 - val_loss: 740741443822.5012\n",
      "Epoch 801/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 702969846862.9465 - val_loss: 753072749531.9944\n",
      "Epoch 802/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 709467986423.6444 - val_loss: 754597788659.0380\n",
      "Epoch 803/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 705433011042.6832 - val_loss: 742707715572.9103\n",
      "Epoch 804/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 704734109802.0304 - val_loss: 740708364383.6310\n",
      "Epoch 805/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 705544914113.0444 - val_loss: 751391802611.3981\n",
      "Epoch 806/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 709872557872.5492 - val_loss: 750197039571.7850\n",
      "Epoch 807/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 704180479155.2145 - val_loss: 744007458297.5190\n",
      "Epoch 808/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 702421982720.2881 - val_loss: 742799941426.9120\n",
      "Epoch 809/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 709675883930.8677 - val_loss: 786517738522.7882\n",
      "Epoch 810/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 705673768067.9618 - val_loss: 783147296040.3983\n",
      "Epoch 811/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 708060585536.8284 - val_loss: 745947288820.5502\n",
      "Epoch 812/7000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 704134597980.6326 - val_loss: 741708890485.3063\n",
      "Epoch 813/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 707046851730.9443 - val_loss: 746172275530.8197\n",
      "Epoch 814/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 705841300709.9247 - val_loss: 741846082040.6549\n",
      "Epoch 815/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 702038138939.9303 - val_loss: 737701294673.3727\n",
      "Epoch 816/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 704100111071.2976 - val_loss: 758445163224.1777\n",
      "Epoch 817/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 708540055358.3794 - val_loss: 739823245080.9879\n",
      "Epoch 818/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 704798790846.7395 - val_loss: 738246375563.9899\n",
      "Epoch 819/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 74us/step - loss: 702742033843.0703 - val_loss: 750019528545.5752\n",
      "Epoch 820/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 703231341127.1672 - val_loss: 737302595434.7927\n",
      "Epoch 821/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 699643339632.5132 - val_loss: 745724309226.3246\n",
      "Epoch 822/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 705104166884.3398 - val_loss: 742312455259.8864\n",
      "Epoch 823/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 700969970110.0192 - val_loss: 743372544192.9901\n",
      "Epoch 824/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 706910388353.0804 - val_loss: 752401098747.9674\n",
      "Epoch 825/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 703840994473.9944 - val_loss: 768651777010.4619\n",
      "Epoch 826/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 704532657301.2493 - val_loss: 741788905452.4130\n",
      "Epoch 827/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 706227729898.3906 - val_loss: 739631558684.8044\n",
      "Epoch 828/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 703350772336.6573 - val_loss: 735395170154.7927\n",
      "Epoch 829/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 697706226175.7119 - val_loss: 740422453898.4056\n",
      "Epoch 830/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 701688683820.2274 - val_loss: 736181075603.9111\n",
      "Epoch 831/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 704135735880.3196 - val_loss: 734320966831.9955\n",
      "Epoch 832/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 700127560371.5026 - val_loss: 735932208155.9403\n",
      "Epoch 833/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 697438114435.0973 - val_loss: 737045849707.0087\n",
      "Epoch 834/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 700763300969.4541 - val_loss: 739533582533.0228\n",
      "Epoch 835/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 705171397083.9843 - val_loss: 738154257180.7325\n",
      "Epoch 836/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 701815203732.8170 - val_loss: 736985195009.8723\n",
      "Epoch 837/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 701949010782.0731 - val_loss: 734433316625.4988\n",
      "Epoch 838/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 698204348605.0107 - val_loss: 737972264280.2137\n",
      "Epoch 839/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 702244882172.6866 - val_loss: 735931735066.2120\n",
      "Epoch 840/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 698114673339.5701 - val_loss: 750783440799.7930\n",
      "Epoch 841/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 705265039545.5531 - val_loss: 733917129220.7527\n",
      "Epoch 842/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 699712816726.7260 - val_loss: 737515493702.6431\n",
      "Epoch 843/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 696137870089.9404 - val_loss: 740047239543.0345\n",
      "Epoch 844/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 698081663000.2026 - val_loss: 737475313461.2163\n",
      "Epoch 845/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 701371595516.1102 - val_loss: 745240265844.6582\n",
      "Epoch 846/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 697917367530.5345 - val_loss: 743596966353.4807\n",
      "Epoch 847/7000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 698487023222.9961 - val_loss: 734382051601.0667\n",
      "Epoch 848/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 701602123561.6343 - val_loss: 732651715518.0377\n",
      "Epoch 849/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 697693155376.4053 - val_loss: 732817880244.0281\n",
      "Epoch 850/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 697320853732.1959 - val_loss: 734552308112.3826\n",
      "Epoch 851/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 698970589155.1874 - val_loss: 772163524851.6860\n",
      "Epoch 852/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 698627825336.6888 - val_loss: 731398648475.1122\n",
      "Epoch 853/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 697643792357.4924 - val_loss: 735007506077.1285\n",
      "Epoch 854/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 696113309966.8385 - val_loss: 758252489633.2332\n",
      "Epoch 855/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 700342353615.7389 - val_loss: 740276387743.2169\n",
      "Epoch 856/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 702645634858.7867 - val_loss: 733765471409.1477\n",
      "Epoch 857/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 699207521175.6984 - val_loss: 734112115651.7986\n",
      "Epoch 858/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 695772310060.6595 - val_loss: 760158300008.4883\n",
      "Epoch 859/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 699062464671.0455 - val_loss: 732068724205.9972\n",
      "Epoch 860/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 694542633097.1481 - val_loss: 738427968259.3845\n",
      "Epoch 861/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 695723128040.2296 - val_loss: 731340919121.5887\n",
      "Epoch 862/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 695831884036.4659 - val_loss: 735155779265.4222\n",
      "Epoch 863/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 694819494824.9860 - val_loss: 728816898208.1531\n",
      "Epoch 864/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 696089466996.4030 - val_loss: 728401718320.1035\n",
      "Epoch 865/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 701733396853.4114 - val_loss: 728788898913.0712\n",
      "Epoch 866/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 695907816122.4176 - val_loss: 731014059252.5502\n",
      "Epoch 867/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 693436364681.2920 - val_loss: 730191902800.0765\n",
      "Epoch 868/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 694935477575.8876 - val_loss: 730637363087.6625\n",
      "Epoch 869/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 695393578678.3839 - val_loss: 734538150995.2450\n",
      "Epoch 870/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 689937904153.0669 - val_loss: 749174271010.2773\n",
      "Epoch 871/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 695701643093.4294 - val_loss: 728865521030.3010\n",
      "Epoch 872/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 694456095602.8182 - val_loss: 737056620910.3932\n",
      "Epoch 873/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 691495928748.4435 - val_loss: 729213158025.8296\n",
      "Epoch 874/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 695201891189.1232 - val_loss: 727311017157.3108\n",
      "Epoch 875/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 694609599852.7676 - val_loss: 731460604253.1106\n",
      "Epoch 876/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 695447616755.6105 - val_loss: 748324524908.8090\n",
      "Epoch 877/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 691390992446.2352 - val_loss: 728379857494.5575\n",
      "Epoch 878/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 697566185350.9871 - val_loss: 731066941792.5671\n",
      "Epoch 879/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 692613459214.2622 - val_loss: 736441395009.3142\n",
      "Epoch 880/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 692657284391.0410 - val_loss: 737570346744.7268\n",
      "Epoch 881/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 693882247957.4655 - val_loss: 733695919326.6588\n",
      "Epoch 882/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 79us/step - loss: 692422027087.6669 - val_loss: 728695037737.6945\n",
      "Epoch 883/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 691315758667.2009 - val_loss: 729830934699.0988\n",
      "Epoch 884/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 696912411952.8373 - val_loss: 733254806191.2754\n",
      "Epoch 885/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 694960239304.2476 - val_loss: 728494484857.6270\n",
      "Epoch 886/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 692854756247.6984 - val_loss: 726171780998.4449\n",
      "Epoch 887/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 690204826619.9663 - val_loss: 731050007340.8630\n",
      "Epoch 888/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 697825749198.2982 - val_loss: 752176065701.6259\n",
      "Epoch 889/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 693055416009.9763 - val_loss: 730521588473.5909\n",
      "Epoch 890/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 693055637355.3269 - val_loss: 742572437645.7181\n",
      "Epoch 891/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 693086161374.2892 - val_loss: 738475478112.4951\n",
      "Epoch 892/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 701529374692.3398 - val_loss: 737635757403.6703\n",
      "Epoch 893/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 688437799182.8385 - val_loss: 730703082484.7662\n",
      "Epoch 894/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 694388826457.7512 - val_loss: 756458574783.7660\n",
      "Epoch 895/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 692597042584.5627 - val_loss: 728300894294.9896\n",
      "Epoch 896/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 692835457002.1024 - val_loss: 723928853934.6273\n",
      "Epoch 897/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 691117869082.5076 - val_loss: 724339060112.6707\n",
      "Epoch 898/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 690880413013.7175 - val_loss: 727606667234.6194\n",
      "Epoch 899/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 695301392244.5470 - val_loss: 728866303314.4529\n",
      "Epoch 900/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 691185962203.5520 - val_loss: 731062058088.5603\n",
      "Epoch 901/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 691689848702.9196 - val_loss: 725535728072.2633\n",
      "Epoch 902/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 693328049402.6697 - val_loss: 726448155767.5387\n",
      "Epoch 903/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 690984933833.5442 - val_loss: 730320651611.0942\n",
      "Epoch 904/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 690224687089.0175 - val_loss: 772333015087.2394\n",
      "Epoch 905/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 698393254539.1649 - val_loss: 725265853789.9747\n",
      "Epoch 906/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 690011195436.9478 - val_loss: 724303827412.9373\n",
      "Epoch 907/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 691419525869.1278 - val_loss: 727936763561.2264\n",
      "Epoch 908/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 687712704453.2223 - val_loss: 722935190106.5902\n",
      "Epoch 909/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 688779270804.3850 - val_loss: 741405857943.5117\n",
      "Epoch 910/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 692948415618.8092 - val_loss: 740862754707.6951\n",
      "Epoch 911/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 696957359681.9808 - val_loss: 732253369118.4608\n",
      "Epoch 912/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 692656419583.5677 - val_loss: 731002508154.6351\n",
      "Epoch 913/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 691848299389.0466 - val_loss: 732199200098.0073\n",
      "Epoch 914/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 689329413530.8677 - val_loss: 723363667850.4777\n",
      "Epoch 915/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 690681346219.7231 - val_loss: 752021260827.7964\n",
      "Epoch 916/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 687746671573.9336 - val_loss: 757748708460.5930\n",
      "Epoch 917/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 695474450618.7057 - val_loss: 724691616536.6998\n",
      "Epoch 918/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 688003252795.6422 - val_loss: 722349561730.9885\n",
      "Epoch 919/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 687638687423.6038 - val_loss: 721372742966.2245\n",
      "Epoch 920/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 686506199758.5863 - val_loss: 723475347243.4227\n",
      "Epoch 921/7000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 689582901394.3679 - val_loss: 746687060898.3854\n",
      "Epoch 922/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 686492160809.0580 - val_loss: 725634748172.8900\n",
      "Epoch 923/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 688213970840.2747 - val_loss: 721435383752.1193\n",
      "Epoch 924/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 687773405928.5177 - val_loss: 722892047893.7474\n",
      "Epoch 925/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 690239261749.5914 - val_loss: 722168363917.6461\n",
      "Epoch 926/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 687212458318.2262 - val_loss: 721696888981.2073\n",
      "Epoch 927/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 688231808950.2397 - val_loss: 721072696755.2360\n",
      "Epoch 928/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 688581135601.4497 - val_loss: 722612511503.4824\n",
      "Epoch 929/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 693084669499.0658 - val_loss: 729081806838.7826\n",
      "Epoch 930/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 687798289379.7637 - val_loss: 721872275659.3597\n",
      "Epoch 931/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 685197161482.9489 - val_loss: 722100296207.1223\n",
      "Epoch 932/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 694931955707.3900 - val_loss: 721956788764.9485\n",
      "Epoch 933/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 686064345046.5099 - val_loss: 722129581945.7710\n",
      "Epoch 934/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 689311124164.7900 - val_loss: 721843358719.7119\n",
      "Epoch 935/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 687453460780.8036 - val_loss: 720546425334.9266\n",
      "Epoch 936/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 685348939613.4969 - val_loss: 719459072649.2534\n",
      "Epoch 937/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 688399656262.7350 - val_loss: 721781506386.7410\n",
      "Epoch 938/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 686920478473.3640 - val_loss: 728163316957.5066\n",
      "Epoch 939/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 687988246360.8870 - val_loss: 722163541899.0537\n",
      "Epoch 940/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 689475346178.4491 - val_loss: 719972081841.4357\n",
      "Epoch 941/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 686301223092.9432 - val_loss: 720198741139.1910\n",
      "Epoch 942/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 686404770141.2089 - val_loss: 720695899862.1615\n",
      "Epoch 943/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 684105721361.5757 - val_loss: 718494440974.2582\n",
      "Epoch 944/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 683992179928.0945 - val_loss: 720876531909.0228\n",
      "Epoch 945/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 80us/step - loss: 695720172410.8859 - val_loss: 726324431203.4475\n",
      "Epoch 946/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 685830742361.7512 - val_loss: 723505585226.6036\n",
      "Epoch 947/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 686267155879.5453 - val_loss: 727675565795.9877\n",
      "Epoch 948/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 683779125453.1458 - val_loss: 718031708065.5212\n",
      "Epoch 949/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 685903566982.8429 - val_loss: 725783486980.1766\n",
      "Epoch 950/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 686505687151.7928 - val_loss: 721003332480.3961\n",
      "Epoch 951/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 683253152252.2544 - val_loss: 748148922987.2968\n",
      "Epoch 952/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 697378893734.1046 - val_loss: 729248777535.4419\n",
      "Epoch 953/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 687394859666.0798 - val_loss: 717005437876.8203\n",
      "Epoch 954/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 685392933447.1672 - val_loss: 717714367878.8771\n",
      "Epoch 955/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 687684839593.4182 - val_loss: 715133577753.4919\n",
      "Epoch 956/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 681423702088.6077 - val_loss: 732021423715.5195\n",
      "Epoch 957/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 680953601512.0854 - val_loss: 715955859134.5417\n",
      "Epoch 958/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 679440628828.7766 - val_loss: 715140037008.3826\n",
      "Epoch 959/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 678620562735.6849 - val_loss: 716457701372.5435\n",
      "Epoch 960/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 683920462227.3766 - val_loss: 713067656964.2487\n",
      "Epoch 961/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 678192127935.4598 - val_loss: 712888610310.1930\n",
      "Epoch 962/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 676823566869.6094 - val_loss: 714042209630.5508\n",
      "Epoch 963/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 676553391335.0770 - val_loss: 712357559084.8630\n",
      "Epoch 964/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 678506557829.5464 - val_loss: 719723709395.3530\n",
      "Epoch 965/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 676074546834.6562 - val_loss: 709515727823.8965\n",
      "Epoch 966/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 676419426918.2848 - val_loss: 713811300860.1115\n",
      "Epoch 967/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 673996172890.1835 - val_loss: 710516734845.5156\n",
      "Epoch 968/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 671471964821.5374 - val_loss: 705876385326.5193\n",
      "Epoch 969/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 672115189708.1373 - val_loss: 710512707271.1831\n",
      "Epoch 970/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 671047048722.7281 - val_loss: 706288413497.5370\n",
      "Epoch 971/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 669713489187.0073 - val_loss: 702844066563.3845\n",
      "Epoch 972/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 675837986086.4648 - val_loss: 703214058247.9933\n",
      "Epoch 973/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 669378652043.5970 - val_loss: 702365697527.7908\n",
      "Epoch 974/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 673911324570.5796 - val_loss: 702282246672.2745\n",
      "Epoch 975/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 668219293649.8999 - val_loss: 706270213226.2886\n",
      "Epoch 976/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 662079446740.3489 - val_loss: 709126271378.1108\n",
      "Epoch 977/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 662257186476.0112 - val_loss: 732673720022.7375\n",
      "Epoch 978/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 665504922052.9342 - val_loss: 699994950575.0593\n",
      "Epoch 979/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 665112470356.8530 - val_loss: 698237524628.7753\n",
      "Epoch 980/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 671235578092.2633 - val_loss: 694025615400.9023\n",
      "Epoch 981/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 656655048468.8892 - val_loss: 693944528053.7563\n",
      "Epoch 982/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 655408556717.7400 - val_loss: 691451540498.7229\n",
      "Epoch 983/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 656528091554.3590 - val_loss: 691475044473.5551\n",
      "Epoch 984/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 655304416104.4457 - val_loss: 688797524604.0034\n",
      "Epoch 985/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 661364463285.2313 - val_loss: 688708611525.6709\n",
      "Epoch 986/7000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 650096625856.4683 - val_loss: 703922998085.0588\n",
      "Epoch 987/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 649876509868.2993 - val_loss: 684583799333.0138\n",
      "Epoch 988/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 649964120270.2982 - val_loss: 692650150934.7556\n",
      "Epoch 989/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 649709105108.2048 - val_loss: 679079426019.7716\n",
      "Epoch 990/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 645167270338.6293 - val_loss: 687028015635.1550\n",
      "Epoch 991/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 646099441568.3420 - val_loss: 677868648935.9482\n",
      "Epoch 992/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 641745383868.8666 - val_loss: 680430041438.8389\n",
      "Epoch 993/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 638941794189.3258 - val_loss: 671185715107.8256\n",
      "Epoch 994/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 634564278310.0326 - val_loss: 672390833280.1801\n",
      "Epoch 995/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 635726083110.6089 - val_loss: 667941294811.6343\n",
      "Epoch 996/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 633735953611.4170 - val_loss: 697600487789.2411\n",
      "Epoch 997/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 631483028643.0793 - val_loss: 667641967272.9384\n",
      "Epoch 998/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 625113242578.4761 - val_loss: 658672670862.2942\n",
      "Epoch 999/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 623892994417.9539 - val_loss: 655304300681.6855\n",
      "Epoch 1000/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 619540386932.9792 - val_loss: 652205858035.9741\n",
      "Epoch 1001/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 613717129041.9719 - val_loss: 665979505495.4937\n",
      "Epoch 1002/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 619254654463.1356 - val_loss: 662728625935.1943\n",
      "Epoch 1003/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 613110056239.6848 - val_loss: 641619556290.3584\n",
      "Epoch 1004/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 608827304824.5808 - val_loss: 639428816574.5417\n",
      "Epoch 1005/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 607004558612.0248 - val_loss: 653276034149.6799\n",
      "Epoch 1006/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 605895466650.7238 - val_loss: 640203111371.8639\n",
      "Epoch 1007/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 596910399013.1682 - val_loss: 629956279550.3438\n",
      "Epoch 1008/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 86us/step - loss: 597017096083.6646 - val_loss: 626565538320.8506\n",
      "Epoch 1009/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 591486212055.6624 - val_loss: 621918946376.8754\n",
      "Epoch 1010/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 587013243682.1429 - val_loss: 629159274936.7089\n",
      "Epoch 1011/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 587625038801.3236 - val_loss: 615025152646.3730\n",
      "Epoch 1012/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 577628775298.9534 - val_loss: 639887399508.2532\n",
      "Epoch 1013/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 577701556585.8864 - val_loss: 613465939502.5193\n",
      "Epoch 1014/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 573442426749.7670 - val_loss: 609262815386.9683\n",
      "Epoch 1015/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 566696446504.0494 - val_loss: 620591943042.8445\n",
      "Epoch 1016/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 570604089512.2656 - val_loss: 617427173263.0863\n",
      "Epoch 1017/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 561473477627.9663 - val_loss: 605166009109.8195\n",
      "Epoch 1018/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 560663776028.3804 - val_loss: 590824170011.2202\n",
      "Epoch 1019/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 553588831565.6499 - val_loss: 590380538629.6888\n",
      "Epoch 1020/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 550713889245.1367 - val_loss: 583039004258.3673\n",
      "Epoch 1021/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 552533435774.0552 - val_loss: 586083598927.0684\n",
      "Epoch 1022/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 544746693608.3737 - val_loss: 578319350300.9485\n",
      "Epoch 1023/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 539471920368.2971 - val_loss: 575826954104.6189\n",
      "Epoch 1024/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 537384661317.0062 - val_loss: 573294849575.6062\n",
      "Epoch 1025/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 535800250109.8391 - val_loss: 566955909155.7175\n",
      "Epoch 1026/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 528858383811.2054 - val_loss: 563224650617.4830\n",
      "Epoch 1027/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 525933885763.8537 - val_loss: 560264336259.8527\n",
      "Epoch 1028/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 524405202395.4080 - val_loss: 556985620872.3173\n",
      "Epoch 1029/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 522082464511.5679 - val_loss: 561537861055.3339\n",
      "Epoch 1030/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 521104662228.3489 - val_loss: 549237066029.2951\n",
      "Epoch 1031/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 516049185472.1801 - val_loss: 555861872574.3257\n",
      "Epoch 1032/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 514317965004.2814 - val_loss: 544953221977.2219\n",
      "Epoch 1033/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 510803252972.2634 - val_loss: 542317800314.0591\n",
      "Epoch 1034/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 503735894209.6207 - val_loss: 538070293645.4301\n",
      "Epoch 1035/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 503985388175.7749 - val_loss: 536897658053.8869\n",
      "Epoch 1036/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 499966056518.3027 - val_loss: 535494246350.4562\n",
      "Epoch 1037/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 499530076415.8560 - val_loss: 530725570219.5308\n",
      "Epoch 1038/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 495496780242.7642 - val_loss: 551701131283.5870\n",
      "Epoch 1039/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 493501355770.3815 - val_loss: 522402250549.2163\n",
      "Epoch 1040/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 487262252541.9832 - val_loss: 519944657794.1243\n",
      "Epoch 1041/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 489239232825.4811 - val_loss: 520645463129.5820\n",
      "Epoch 1042/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 484013208863.5498 - val_loss: 524025557327.2844\n",
      "Epoch 1043/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 481415088209.8278 - val_loss: 523370498947.2765\n",
      "Epoch 1044/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 483184908763.9843 - val_loss: 509671952055.6287\n",
      "Epoch 1045/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 477670543394.5751 - val_loss: 508632630854.1390\n",
      "Epoch 1046/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 474826494739.1603 - val_loss: 506266381233.3637\n",
      "Epoch 1047/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 470742517150.3253 - val_loss: 507910018463.0729\n",
      "Epoch 1048/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 470584932694.2937 - val_loss: 500455329189.4099\n",
      "Epoch 1049/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 465019932024.2926 - val_loss: 498465056213.2253\n",
      "Epoch 1050/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 463588234356.9792 - val_loss: 495801801592.9069\n",
      "Epoch 1051/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 470287251475.5926 - val_loss: 506566781580.7100\n",
      "Epoch 1052/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 464625118432.1620 - val_loss: 489470625278.7038\n",
      "Epoch 1053/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 458336538979.5475 - val_loss: 494134213617.8858\n",
      "Epoch 1054/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 456769266332.4525 - val_loss: 486611522464.6571\n",
      "Epoch 1055/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 455811680038.1767 - val_loss: 491812162594.2773\n",
      "Epoch 1056/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 455640846554.9758 - val_loss: 484639105674.9817\n",
      "Epoch 1057/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 449845596927.5679 - val_loss: 481491812426.8917\n",
      "Epoch 1058/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 449928894331.4620 - val_loss: 501535177838.3212\n",
      "Epoch 1059/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 448696920325.6185 - val_loss: 480841298908.5704\n",
      "Epoch 1060/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 446521927665.0175 - val_loss: 477483174463.5139\n",
      "Epoch 1061/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 447998248212.0247 - val_loss: 478648238760.9384\n",
      "Epoch 1062/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 445270855254.7260 - val_loss: 478392120759.2686\n",
      "Epoch 1063/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 441831543325.6769 - val_loss: 475277393551.3024\n",
      "Epoch 1064/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 439815674691.5656 - val_loss: 470200917125.3649\n",
      "Epoch 1065/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 440981476054.0777 - val_loss: 479156664032.5311\n",
      "Epoch 1066/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 441201416400.6033 - val_loss: 491561413387.4498\n",
      "Epoch 1067/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 436910529614.9466 - val_loss: 466345020952.6279\n",
      "Epoch 1068/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 436109019761.8098 - val_loss: 463856943139.7176\n",
      "Epoch 1069/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 433907910913.0084 - val_loss: 461333358178.9435\n",
      "Epoch 1070/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 432934482263.4463 - val_loss: 463516277910.6475\n",
      "Epoch 1071/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 75us/step - loss: 430079332414.2352 - val_loss: 461283860577.9353\n",
      "Epoch 1072/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 430279215932.6505 - val_loss: 458439758935.8537\n",
      "Epoch 1073/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 428364646288.2071 - val_loss: 457204669627.5173\n",
      "Epoch 1074/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 426701048000.4682 - val_loss: 463575190712.0607\n",
      "Epoch 1075/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 425396618718.8655 - val_loss: 458593180858.3651\n",
      "Epoch 1076/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 426347847334.2487 - val_loss: 473801455914.9907\n",
      "Epoch 1077/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 424115151378.1519 - val_loss: 450962209333.1443\n",
      "Epoch 1078/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 419481940477.4069 - val_loss: 456199656728.2678\n",
      "Epoch 1079/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 420400581980.6325 - val_loss: 459847393837.6552\n",
      "Epoch 1080/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 416809389164.9116 - val_loss: 456344210626.4304\n",
      "Epoch 1081/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 418814651699.1424 - val_loss: 445665553095.4712\n",
      "Epoch 1082/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 418819967970.6111 - val_loss: 451784075800.3398\n",
      "Epoch 1083/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 418508399205.1323 - val_loss: 446763443225.6360\n",
      "Epoch 1084/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 414344903616.0360 - val_loss: 444561044801.7463\n",
      "Epoch 1085/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 411771441426.2960 - val_loss: 449505237240.2948\n",
      "Epoch 1086/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 417673040524.3174 - val_loss: 439891188448.8192\n",
      "Epoch 1087/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 409639165965.8301 - val_loss: 438007319297.0801\n",
      "Epoch 1088/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 412203991510.2217 - val_loss: 439701281389.6011\n",
      "Epoch 1089/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 413938157880.3287 - val_loss: 435897909682.3719\n",
      "Epoch 1090/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 409006733681.9539 - val_loss: 437266209632.7111\n",
      "Epoch 1091/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 408545732362.5166 - val_loss: 446460260002.8895\n",
      "Epoch 1092/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 406985599177.6883 - val_loss: 433448498349.1151\n",
      "Epoch 1093/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 403476644762.0034 - val_loss: 433099787357.0385\n",
      "Epoch 1094/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 405079138778.8318 - val_loss: 433840321225.1995\n",
      "Epoch 1095/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 406880560740.5560 - val_loss: 433725989721.2219\n",
      "Epoch 1096/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 404157894838.0957 - val_loss: 431703783304.7494\n",
      "Epoch 1097/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 400999232693.5194 - val_loss: 428697870247.2822\n",
      "Epoch 1098/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 400759432610.9352 - val_loss: 428711990350.6363\n",
      "Epoch 1099/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 401547058835.8087 - val_loss: 427998490186.1716\n",
      "Epoch 1100/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 402920489208.9409 - val_loss: 429885212639.1628\n",
      "Epoch 1101/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 397332114794.4626 - val_loss: 432784833014.9266\n",
      "Epoch 1102/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 401790587359.4418 - val_loss: 423329518634.9187\n",
      "Epoch 1103/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 397534155206.0867 - val_loss: 423602853639.7052\n",
      "Epoch 1104/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 398628457765.3123 - val_loss: 422075219621.1938\n",
      "Epoch 1105/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 397679678166.0777 - val_loss: 426662139289.3120\n",
      "Epoch 1106/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 398786598710.3117 - val_loss: 428026692928.5941\n",
      "Epoch 1107/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 394700663128.5988 - val_loss: 433670058144.1530\n",
      "Epoch 1108/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 395410984376.8329 - val_loss: 428681967499.0537\n",
      "Epoch 1109/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 396493829213.9291 - val_loss: 428790791044.4287\n",
      "Epoch 1110/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 392832181888.2161 - val_loss: 420226222479.2304\n",
      "Epoch 1111/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 390221861783.6984 - val_loss: 421071126188.1069\n",
      "Epoch 1112/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 393540727580.3804 - val_loss: 436687852795.4633\n",
      "Epoch 1113/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 387375089095.8154 - val_loss: 424962707233.6293\n",
      "Epoch 1114/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 387397159427.1694 - val_loss: 417284465954.6374\n",
      "Epoch 1115/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 388797183869.7670 - val_loss: 444596994476.6110\n",
      "Epoch 1116/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 386825247703.0861 - val_loss: 418231578885.5449\n",
      "Epoch 1117/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 391561880580.0338 - val_loss: 416970554359.6467\n",
      "Epoch 1118/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 387081050691.7097 - val_loss: 422738721412.6447\n",
      "Epoch 1119/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 384946668552.6438 - val_loss: 412139030364.9666\n",
      "Epoch 1120/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 388035256201.2921 - val_loss: 417956842858.6487\n",
      "Epoch 1121/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 387842431258.3635 - val_loss: 414943963803.6884\n",
      "Epoch 1122/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 384616768737.3146 - val_loss: 411159730244.5547\n",
      "Epoch 1123/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 383676427829.3033 - val_loss: 412382320736.2070\n",
      "Epoch 1124/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 381343797015.1942 - val_loss: 410936074589.1105\n",
      "Epoch 1125/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 384147627893.6995 - val_loss: 412016528676.3657\n",
      "Epoch 1126/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 380163652562.4761 - val_loss: 411511297434.4641\n",
      "Epoch 1127/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 383699181757.0107 - val_loss: 408447952545.1612\n",
      "Epoch 1128/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 381491616902.2667 - val_loss: 409755697021.8036\n",
      "Epoch 1129/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 379317537804.1013 - val_loss: 420104176343.0256\n",
      "Epoch 1130/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 379745964896.3782 - val_loss: 408388229299.7401\n",
      "Epoch 1131/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 384489082481.2335 - val_loss: 409443071735.5747\n",
      "Epoch 1132/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 377234349605.1682 - val_loss: 406714843084.1519\n",
      "Epoch 1133/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 377658021644.8217 - val_loss: 406932225661.4436\n",
      "Epoch 1134/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 79us/step - loss: 378355880966.3388 - val_loss: 435946626242.4304\n",
      "Epoch 1135/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 380712114513.6837 - val_loss: 410218760798.6228\n",
      "Epoch 1136/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 376143897663.9640 - val_loss: 415776638323.2900\n",
      "Epoch 1137/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 374625429249.2966 - val_loss: 403839136764.8315\n",
      "Epoch 1138/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 376344497537.5126 - val_loss: 404874388413.4616\n",
      "Epoch 1139/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 375399813136.1351 - val_loss: 401507598970.8512\n",
      "Epoch 1140/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 372932252254.2172 - val_loss: 402645512657.4807\n",
      "Epoch 1141/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 372482292330.8948 - val_loss: 402047951607.2866\n",
      "Epoch 1142/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 373270930297.7333 - val_loss: 402774500436.3972\n",
      "Epoch 1143/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 371830139127.7884 - val_loss: 400577132550.3370\n",
      "Epoch 1144/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 372701054400.9004 - val_loss: 401427263099.7153\n",
      "Epoch 1145/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 371534665484.8217 - val_loss: 400832807594.0906\n",
      "Epoch 1146/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 373128047452.9207 - val_loss: 400423380887.7277\n",
      "Epoch 1147/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 371901150043.7681 - val_loss: 397803509012.2352\n",
      "Epoch 1148/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 373625630639.3247 - val_loss: 402160649947.9224\n",
      "Epoch 1149/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 371223005441.0084 - val_loss: 404137853618.1558\n",
      "Epoch 1150/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 368972035138.2690 - val_loss: 404200834016.0270\n",
      "Epoch 1151/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 375912210980.5920 - val_loss: 408963400821.8104\n",
      "Epoch 1152/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 374458758763.4710 - val_loss: 396012841894.9941\n",
      "Epoch 1153/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 367432471171.0974 - val_loss: 394833387107.5195\n",
      "Epoch 1154/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 367343079993.3371 - val_loss: 403625451819.5668\n",
      "Epoch 1155/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 367496763141.9066 - val_loss: 420411900422.4810\n",
      "Epoch 1156/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 366931473603.3495 - val_loss: 406126093851.5083\n",
      "Epoch 1157/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 371877245833.8683 - val_loss: 398473158931.3710\n",
      "Epoch 1158/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 368399401264.2611 - val_loss: 403810992057.7170\n",
      "Epoch 1159/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 367843682980.5200 - val_loss: 394641200957.8577\n",
      "Epoch 1160/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 365395821152.5222 - val_loss: 396599583118.6543\n",
      "Epoch 1161/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 363705305916.6505 - val_loss: 394651229033.9285\n",
      "Epoch 1162/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 369467747340.1013 - val_loss: 393455894499.7716\n",
      "Epoch 1163/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 365373662977.2966 - val_loss: 394837259468.2239\n",
      "Epoch 1164/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 365389354691.0613 - val_loss: 391895545460.2261\n",
      "Epoch 1165/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 361857244543.2077 - val_loss: 396823041497.8340\n",
      "Epoch 1166/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 365964945466.7777 - val_loss: 394658732455.4261\n",
      "Epoch 1167/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 367330094119.7614 - val_loss: 406162985721.0149\n",
      "Epoch 1168/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 367911883385.8773 - val_loss: 414142448747.4408\n",
      "Epoch 1169/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 363936570926.3883 - val_loss: 395130994974.8928\n",
      "Epoch 1170/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 362127219339.1649 - val_loss: 395117562918.8860\n",
      "Epoch 1171/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 363194664728.3467 - val_loss: 398323041048.6998\n",
      "Epoch 1172/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 361585973299.8627 - val_loss: 389192686227.6230\n",
      "Epoch 1173/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 359373258641.3596 - val_loss: 400951553309.4526\n",
      "Epoch 1174/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 359419737320.2296 - val_loss: 393766939857.4087\n",
      "Epoch 1175/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 360505697016.6528 - val_loss: 393245748312.4298\n",
      "Epoch 1176/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 364234358673.3596 - val_loss: 389302459622.1479\n",
      "Epoch 1177/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 363511788711.6894 - val_loss: 387101040121.5190\n",
      "Epoch 1178/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 361045248930.0709 - val_loss: 391938986118.8051\n",
      "Epoch 1179/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 361554451276.7856 - val_loss: 389052929557.7474\n",
      "Epoch 1180/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 356260704940.5875 - val_loss: 391171005996.7910\n",
      "Epoch 1181/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 359958659984.7833 - val_loss: 386306367278.3032\n",
      "Epoch 1182/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 359071516763.0478 - val_loss: 388821661391.2484\n",
      "Epoch 1183/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 358561424683.0749 - val_loss: 391342228929.0622\n",
      "Epoch 1184/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 363134629220.7001 - val_loss: 387392115647.1899\n",
      "Epoch 1185/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 356986442979.6196 - val_loss: 390721685623.2506\n",
      "Epoch 1186/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 355519362697.4361 - val_loss: 385211136758.7106\n",
      "Epoch 1187/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 356649197189.9786 - val_loss: 385362217885.2006\n",
      "Epoch 1188/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 356833274809.1210 - val_loss: 403680677067.6478\n",
      "Epoch 1189/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 356109488476.0562 - val_loss: 404250151240.9474\n",
      "Epoch 1190/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 358309598772.1508 - val_loss: 388999578471.0481\n",
      "Epoch 1191/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 352633487101.8391 - val_loss: 385899782052.9778\n",
      "Epoch 1192/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 353130724979.5385 - val_loss: 383163530235.6793\n",
      "Epoch 1193/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 353592345802.2645 - val_loss: 382973780003.1415\n",
      "Epoch 1194/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 354698354296.1486 - val_loss: 384610685739.1348\n",
      "Epoch 1195/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 352079724645.4203 - val_loss: 388403444770.2773\n",
      "Epoch 1196/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 356447758238.0371 - val_loss: 383152231288.3308\n",
      "Epoch 1197/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 75us/step - loss: 356745333518.5504 - val_loss: 382191757120.7381\n",
      "Epoch 1198/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 351151427194.4536 - val_loss: 389598278243.8076\n",
      "Epoch 1199/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 352628291539.0523 - val_loss: 407474833715.0560\n",
      "Epoch 1200/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 359550580239.2707 - val_loss: 382150030623.7570\n",
      "Epoch 1201/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 353752180333.7760 - val_loss: 380651911533.8171\n",
      "Epoch 1202/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 353830573504.9004 - val_loss: 392053947591.6152\n",
      "Epoch 1203/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 355060790001.7378 - val_loss: 384594983718.5260\n",
      "Epoch 1204/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 349060618669.8841 - val_loss: 384815231971.4835\n",
      "Epoch 1205/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 350305518453.1232 - val_loss: 385949640315.1392\n",
      "Epoch 1206/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 350983310168.3106 - val_loss: 379835638991.6804\n",
      "Epoch 1207/7000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 352444706603.9393 - val_loss: 379209047817.4335\n",
      "Epoch 1208/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 353419129636.4480 - val_loss: 377150336022.1794\n",
      "Epoch 1209/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 351444054709.8075 - val_loss: 379502927007.8650\n",
      "Epoch 1210/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 352418998690.3591 - val_loss: 393503917935.4014\n",
      "Epoch 1211/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 349816522013.2448 - val_loss: 379927943452.0124\n",
      "Epoch 1212/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 348799028259.1514 - val_loss: 381091557641.0014\n",
      "Epoch 1213/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 347589440596.7091 - val_loss: 381757947293.3446\n",
      "Epoch 1214/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 353737312161.4946 - val_loss: 378211595681.3772\n",
      "Epoch 1215/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 352019864479.7659 - val_loss: 379328692614.5891\n",
      "Epoch 1216/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 350190111290.4896 - val_loss: 409856291696.2656\n",
      "Epoch 1217/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 351130412155.8942 - val_loss: 377039077454.9243\n",
      "Epoch 1218/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 345688057942.4379 - val_loss: 384418423845.1578\n",
      "Epoch 1219/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 349566182219.6331 - val_loss: 383417585158.1930\n",
      "Epoch 1220/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 344047581627.7142 - val_loss: 378647951592.1642\n",
      "Epoch 1221/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 346370280059.0298 - val_loss: 376215627361.7913\n",
      "Epoch 1222/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 347692169498.3635 - val_loss: 376826478736.5986\n",
      "Epoch 1223/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 346924663586.1429 - val_loss: 380317660239.7885\n",
      "Epoch 1224/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 343437135952.6753 - val_loss: 388701841223.0751\n",
      "Epoch 1225/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 343757652502.7620 - val_loss: 378173031321.7440\n",
      "Epoch 1226/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 346198425461.6995 - val_loss: 379765601530.3111\n",
      "Epoch 1227/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 344248752474.9037 - val_loss: 373346557623.6287\n",
      "Epoch 1228/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 343468182369.5306 - val_loss: 376074299963.4813\n",
      "Epoch 1229/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 345250520484.0878 - val_loss: 378551760266.9097\n",
      "Epoch 1230/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 345033854577.2335 - val_loss: 373325566047.6309\n",
      "Epoch 1231/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 344706022333.7310 - val_loss: 379692487330.6014\n",
      "Epoch 1232/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 346973525357.9200 - val_loss: 371575491708.1474\n",
      "Epoch 1233/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 342641972903.4012 - val_loss: 372397499210.2436\n",
      "Epoch 1234/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 343884360992.7023 - val_loss: 371517249031.9213\n",
      "Epoch 1235/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 343455605653.3934 - val_loss: 372172858470.8321\n",
      "Epoch 1236/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 345218478045.4249 - val_loss: 381963744798.9648\n",
      "Epoch 1237/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 341599690360.1486 - val_loss: 373834222432.7111\n",
      "Epoch 1238/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 345468097404.0383 - val_loss: 370667646057.7125\n",
      "Epoch 1239/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 343131811325.9832 - val_loss: 382157560062.0557\n",
      "Epoch 1240/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 343880782347.2369 - val_loss: 372994641220.6267\n",
      "Epoch 1241/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 340978594070.9060 - val_loss: 373616747080.7314\n",
      "Epoch 1242/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 344074769663.2797 - val_loss: 370297003928.3038\n",
      "Epoch 1243/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 343183171726.9105 - val_loss: 368880793434.0861\n",
      "Epoch 1244/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 343593499501.0557 - val_loss: 371128112257.9083\n",
      "Epoch 1245/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 341543034243.8177 - val_loss: 370612377931.8278\n",
      "Epoch 1246/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 339750678640.9454 - val_loss: 368967376338.9210\n",
      "Epoch 1247/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 343152581627.9662 - val_loss: 389945126649.3030\n",
      "Epoch 1248/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 336763922799.6488 - val_loss: 391949852562.5429\n",
      "Epoch 1249/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 338776821093.8526 - val_loss: 369611182103.0436\n",
      "Epoch 1250/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 336610554703.3787 - val_loss: 371591920905.2894\n",
      "Epoch 1251/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 339979941169.9899 - val_loss: 383450832799.2169\n",
      "Epoch 1252/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 338928701824.9364 - val_loss: 365314176843.6838\n",
      "Epoch 1253/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 337008098880.8284 - val_loss: 368337552815.7795\n",
      "Epoch 1254/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 339530636816.4232 - val_loss: 370007346905.0419\n",
      "Epoch 1255/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 337018595949.1998 - val_loss: 370583922087.7142\n",
      "Epoch 1256/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 343976066629.4384 - val_loss: 366547764845.3131\n",
      "Epoch 1257/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 339906755427.8357 - val_loss: 377949775142.0939\n",
      "Epoch 1258/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 337527117654.5819 - val_loss: 369710542500.6177\n",
      "Epoch 1259/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 337462529805.9741 - val_loss: 376280065011.6141\n",
      "Epoch 1260/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 73us/step - loss: 341450414768.0450 - val_loss: 388848158245.8779\n",
      "Epoch 1261/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 338012201365.6815 - val_loss: 365421762595.1415\n",
      "Epoch 1262/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 337444109275.6962 - val_loss: 365380438292.5232\n",
      "Epoch 1263/7000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 339768304100.0518 - val_loss: 366965889814.9716\n",
      "Epoch 1264/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 336185136327.9595 - val_loss: 366008636971.6388\n",
      "Epoch 1265/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 335781006398.8115 - val_loss: 375567683921.0126\n",
      "Epoch 1266/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 336193751038.8475 - val_loss: 389664999649.2512\n",
      "Epoch 1267/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 344583678241.2786 - val_loss: 364151241098.0456\n",
      "Epoch 1268/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 334121489589.5194 - val_loss: 364497101677.9612\n",
      "Epoch 1269/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 337314303158.6719 - val_loss: 363238397189.2568\n",
      "Epoch 1270/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 333775346730.0665 - val_loss: 367748417679.4464\n",
      "Epoch 1271/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 337479608517.0782 - val_loss: 382708590619.0762\n",
      "Epoch 1272/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 334653253474.1069 - val_loss: 368095099201.4583\n",
      "Epoch 1273/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 332630168029.1367 - val_loss: 369069064016.2925\n",
      "Epoch 1274/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 334624235358.6494 - val_loss: 363447334043.8323\n",
      "Epoch 1275/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 335968758169.1390 - val_loss: 373660563440.4456\n",
      "Epoch 1276/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 334875516195.0073 - val_loss: 363897608166.6520\n",
      "Epoch 1277/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 332018166584.0405 - val_loss: 364599907618.6374\n",
      "Epoch 1278/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 337757425504.9545 - val_loss: 363765464539.5623\n",
      "Epoch 1279/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 331605190207.6758 - val_loss: 362602973076.8472\n",
      "Epoch 1280/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 330991956910.7485 - val_loss: 370170636259.7716\n",
      "Epoch 1281/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 332325935146.6426 - val_loss: 367838398380.4669\n",
      "Epoch 1282/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 331770705967.2527 - val_loss: 365771316452.9958\n",
      "Epoch 1283/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 331250926010.5616 - val_loss: 359203446338.1063\n",
      "Epoch 1284/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 335284323327.4237 - val_loss: 361087662694.6880\n",
      "Epoch 1285/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 329729220833.8908 - val_loss: 361353745205.5043\n",
      "Epoch 1286/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 332934461358.1722 - val_loss: 360803557143.2596\n",
      "Epoch 1287/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 332669723306.2825 - val_loss: 373299613296.1935\n",
      "Epoch 1288/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 330883511519.0096 - val_loss: 360078071230.7578\n",
      "Epoch 1289/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 332661752167.5814 - val_loss: 368187367735.0886\n",
      "Epoch 1290/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 334016802855.1851 - val_loss: 360168566930.9030\n",
      "Epoch 1291/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 331924841512.9139 - val_loss: 363339496560.6256\n",
      "Epoch 1292/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 330707403120.8013 - val_loss: 358817209603.5286\n",
      "Epoch 1293/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 328916130618.3455 - val_loss: 360398504051.7941\n",
      "Epoch 1294/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 331876715352.3106 - val_loss: 364575420205.1511\n",
      "Epoch 1295/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 330620671978.1024 - val_loss: 363385535665.1477\n",
      "Epoch 1296/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 328402407606.0957 - val_loss: 358423487413.3964\n",
      "Epoch 1297/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 328102521941.8616 - val_loss: 360336362144.8731\n",
      "Epoch 1298/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 329033911026.8903 - val_loss: 356804500308.0371\n",
      "Epoch 1299/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 331149520059.2819 - val_loss: 356386879982.8613\n",
      "Epoch 1300/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 329650971449.1931 - val_loss: 364024260527.9235\n",
      "Epoch 1301/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 333172111342.7125 - val_loss: 361832200253.6416\n",
      "Epoch 1302/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 327185308926.1272 - val_loss: 379618927874.3763\n",
      "Epoch 1303/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 328071564986.9938 - val_loss: 374592595704.7269\n",
      "Epoch 1304/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 328036174142.6674 - val_loss: 357040907694.6273\n",
      "Epoch 1305/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 325668432852.7811 - val_loss: 358867657813.5494\n",
      "Epoch 1306/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 327596868432.2431 - val_loss: 362716398811.2023\n",
      "Epoch 1307/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 328803768897.4046 - val_loss: 360684283287.5837\n",
      "Epoch 1308/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 330256244381.0287 - val_loss: 360543440666.7162\n",
      "Epoch 1309/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 328689249236.7811 - val_loss: 361622816486.8681\n",
      "Epoch 1310/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 331385566984.2116 - val_loss: 361380610894.8523\n",
      "Epoch 1311/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 329320893989.7445 - val_loss: 355320762779.9044\n",
      "Epoch 1312/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 324961335559.9235 - val_loss: 354733851686.3100\n",
      "Epoch 1313/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 323901377061.7445 - val_loss: 371852388133.6619\n",
      "Epoch 1314/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 330802316822.1857 - val_loss: 362431331376.1035\n",
      "Epoch 1315/7000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 326315020626.8362 - val_loss: 369320483285.5134\n",
      "Epoch 1316/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 326427667080.8599 - val_loss: 360092426445.0881\n",
      "Epoch 1317/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 326014082809.2291 - val_loss: 356429785987.8526\n",
      "Epoch 1318/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 329393823859.2504 - val_loss: 355510392245.5403\n",
      "Epoch 1319/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 324777428483.7457 - val_loss: 355894151177.2175\n",
      "Epoch 1320/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 327240111709.6409 - val_loss: 360322149952.9542\n",
      "Epoch 1321/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 324595258650.9398 - val_loss: 353551063656.9924\n",
      "Epoch 1322/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 327899459669.2853 - val_loss: 355562686375.8582\n",
      "Epoch 1323/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 70us/step - loss: 327598158089.0760 - val_loss: 357789191811.2045\n",
      "Epoch 1324/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 325893116611.6376 - val_loss: 357383189011.1550\n",
      "Epoch 1325/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 325296876427.0208 - val_loss: 355341589471.4509\n",
      "Epoch 1326/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 325518870821.8885 - val_loss: 357881354464.0990\n",
      "Epoch 1327/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 325389947292.5965 - val_loss: 361576341627.2833\n",
      "Epoch 1328/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 329194743152.2251 - val_loss: 356418847987.3980\n",
      "Epoch 1329/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 322412629414.3928 - val_loss: 355544055960.0878\n",
      "Epoch 1330/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 324310389535.8380 - val_loss: 358838419737.1319\n",
      "Epoch 1331/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 322604519707.5161 - val_loss: 364022263258.4102\n",
      "Epoch 1332/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 320889681681.4316 - val_loss: 357611103208.0923\n",
      "Epoch 1333/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 323873191300.9702 - val_loss: 353157953348.7708\n",
      "Epoch 1334/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 321225212558.6224 - val_loss: 355410967756.2239\n",
      "Epoch 1335/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 326121323419.1559 - val_loss: 352020163613.0925\n",
      "Epoch 1336/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 328935172376.0585 - val_loss: 354393044631.3677\n",
      "Epoch 1337/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 322648565671.2571 - val_loss: 354751270496.0630\n",
      "Epoch 1338/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 320031701223.6533 - val_loss: 357905594192.2925\n",
      "Epoch 1339/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 322487840604.3444 - val_loss: 385344540752.6526\n",
      "Epoch 1340/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 326898883054.4243 - val_loss: 357755821384.0833\n",
      "Epoch 1341/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 319368545380.8441 - val_loss: 360511869197.0341\n",
      "Epoch 1342/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 323011233357.5059 - val_loss: 354349975301.4008\n",
      "Epoch 1343/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 325151553039.2707 - val_loss: 350793491733.3873\n",
      "Epoch 1344/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 323592244296.0315 - val_loss: 351592954565.1668\n",
      "Epoch 1345/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 321016367462.4288 - val_loss: 351858122442.0636\n",
      "Epoch 1346/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 319571758345.6522 - val_loss: 359113842158.5733\n",
      "Epoch 1347/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 324215848840.1395 - val_loss: 351357083967.7300\n",
      "Epoch 1348/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 323971043657.6162 - val_loss: 357715948974.0512\n",
      "Epoch 1349/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 327917742539.8492 - val_loss: 349129473515.1168\n",
      "Epoch 1350/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 320067401696.8824 - val_loss: 368889377560.6998\n",
      "Epoch 1351/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 321355700898.2150 - val_loss: 351280835070.9918\n",
      "Epoch 1352/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 319262391983.4688 - val_loss: 351627338020.6537\n",
      "Epoch 1353/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 321874045226.4986 - val_loss: 350155667585.0442\n",
      "Epoch 1354/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 318310106572.4254 - val_loss: 354297497017.5730\n",
      "Epoch 1355/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 323003469425.2335 - val_loss: 355153395521.8903\n",
      "Epoch 1356/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 321916718613.0332 - val_loss: 348619822568.2363\n",
      "Epoch 1357/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 323058215606.9601 - val_loss: 350045928594.6149\n",
      "Epoch 1358/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 319467446663.8514 - val_loss: 352718667422.8568\n",
      "Epoch 1359/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 321546003220.3129 - val_loss: 349491943912.5244\n",
      "Epoch 1360/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 324395221858.6832 - val_loss: 349121832550.9761\n",
      "Epoch 1361/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 319206701850.0754 - val_loss: 348363671901.1105\n",
      "Epoch 1362/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 318439925993.9584 - val_loss: 351073368879.1674\n",
      "Epoch 1363/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 317448744243.1424 - val_loss: 351972642722.0974\n",
      "Epoch 1364/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 321798531573.3394 - val_loss: 347758705853.2455\n",
      "Epoch 1365/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 323269935131.6601 - val_loss: 381337440357.3918\n",
      "Epoch 1366/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 323026369757.8571 - val_loss: 348402475121.4897\n",
      "Epoch 1367/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 317906928399.7029 - val_loss: 350274427673.8521\n",
      "Epoch 1368/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 318812587627.4710 - val_loss: 361456460286.4158\n",
      "Epoch 1369/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 319298395242.6066 - val_loss: 350894568841.1815\n",
      "Epoch 1370/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 320262325874.3860 - val_loss: 350354655418.6531\n",
      "Epoch 1371/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 323060070843.7142 - val_loss: 367303968530.0748\n",
      "Epoch 1372/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 322640999029.2673 - val_loss: 346245773945.1229\n",
      "Epoch 1373/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 319417304690.3860 - val_loss: 349578912193.3502\n",
      "Epoch 1374/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 320029727786.0665 - val_loss: 349160382386.8040\n",
      "Epoch 1375/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 318923766978.1970 - val_loss: 348432921146.3291\n",
      "Epoch 1376/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 318316113664.1440 - val_loss: 348807707012.2847\n",
      "Epoch 1377/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 317318412676.3939 - val_loss: 345608674749.6057\n",
      "Epoch 1378/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 321253423022.1722 - val_loss: 353474100777.3345\n",
      "Epoch 1379/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 314963871678.3073 - val_loss: 358748495021.6912\n",
      "Epoch 1380/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 316930865060.9522 - val_loss: 345732910667.8998\n",
      "Epoch 1381/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 316594827718.0867 - val_loss: 346332030755.3575\n",
      "Epoch 1382/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 319523000469.8256 - val_loss: 363840155179.6388\n",
      "Epoch 1383/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 316060151321.6432 - val_loss: 347390683048.4343\n",
      "Epoch 1384/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 315276080941.0917 - val_loss: 352737745673.1454\n",
      "Epoch 1385/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 315891172130.1429 - val_loss: 344238595709.4436\n",
      "Epoch 1386/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 73us/step - loss: 315214997332.2769 - val_loss: 348068835234.0974\n",
      "Epoch 1387/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 318972328582.5548 - val_loss: 346959284121.4560\n",
      "Epoch 1388/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 314115721987.0253 - val_loss: 374411806053.4639\n",
      "Epoch 1389/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 315665725100.0112 - val_loss: 345282650144.2610\n",
      "Epoch 1390/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 312710585671.8875 - val_loss: 344344160721.4807\n",
      "Epoch 1391/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 317885119958.7980 - val_loss: 345057078114.4394\n",
      "Epoch 1392/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 315791132245.5734 - val_loss: 351245127583.2169\n",
      "Epoch 1393/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 321464745273.4811 - val_loss: 346000936439.2146\n",
      "Epoch 1394/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 316059583994.5256 - val_loss: 352588024091.4363\n",
      "Epoch 1395/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 320451449585.7378 - val_loss: 349578018614.9446\n",
      "Epoch 1396/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 315448217496.2746 - val_loss: 352969178887.1291\n",
      "Epoch 1397/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 319921431482.2735 - val_loss: 360135120600.4658\n",
      "Epoch 1398/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 319995423843.6917 - val_loss: 344557307798.5755\n",
      "Epoch 1399/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 313941188962.9713 - val_loss: 345683204125.9567\n",
      "Epoch 1400/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 314375718643.4665 - val_loss: 346598196817.0847\n",
      "Epoch 1401/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 314910593058.5751 - val_loss: 348363504782.0062\n",
      "Epoch 1402/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 320293049062.2128 - val_loss: 344893456079.8245\n",
      "Epoch 1403/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 311239749145.6432 - val_loss: 347989717047.3046\n",
      "Epoch 1404/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 315037605818.8497 - val_loss: 346116178634.3516\n",
      "Epoch 1405/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 313089836271.1446 - val_loss: 358119505462.0084\n",
      "Epoch 1406/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 314626879499.5250 - val_loss: 348872283682.4214\n",
      "Epoch 1407/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 313964289079.8964 - val_loss: 346364880338.9210\n",
      "Epoch 1408/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 311174829431.1401 - val_loss: 342390134156.6380\n",
      "Epoch 1409/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 315603261639.3832 - val_loss: 349958543111.1291\n",
      "Epoch 1410/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 316209189590.0776 - val_loss: 348081429120.0360\n",
      "Epoch 1411/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 316239673509.2403 - val_loss: 342483275051.8549\n",
      "Epoch 1412/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 312116881180.9567 - val_loss: 345679849047.4216\n",
      "Epoch 1413/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 317389543365.2223 - val_loss: 342324590280.3353\n",
      "Epoch 1414/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 318990876754.9803 - val_loss: 354196271908.2217\n",
      "Epoch 1415/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 311455153645.8481 - val_loss: 341708398714.7072\n",
      "Epoch 1416/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 311972180818.5481 - val_loss: 362955395323.1752\n",
      "Epoch 1417/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 314481939909.5104 - val_loss: 341672868076.1969\n",
      "Epoch 1418/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 311014379821.9561 - val_loss: 353579447464.5063\n",
      "Epoch 1419/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 310613284046.0101 - val_loss: 348716078242.7454\n",
      "Epoch 1420/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 312077438282.1924 - val_loss: 341758514203.3643\n",
      "Epoch 1421/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 311615807769.2110 - val_loss: 346714046488.1958\n",
      "Epoch 1422/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 307628330314.1924 - val_loss: 348168733332.1992\n",
      "Epoch 1423/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 316089330552.5807 - val_loss: 345501657235.4791\n",
      "Epoch 1424/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 317945455822.8745 - val_loss: 365019648974.7443\n",
      "Epoch 1425/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 321586650900.8892 - val_loss: 352262687273.0464\n",
      "Epoch 1426/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 315724117307.2099 - val_loss: 342209785999.4464\n",
      "Epoch 1427/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 311821016788.3489 - val_loss: 347195090738.3359\n",
      "Epoch 1428/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 315818733812.3309 - val_loss: 351748227901.5696\n",
      "Epoch 1429/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 319422903242.4085 - val_loss: 372677837984.4410\n",
      "Epoch 1430/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 331275168309.8796 - val_loss: 339951119472.6256\n",
      "Epoch 1431/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 307428233822.2172 - val_loss: 353610842131.5870\n",
      "Epoch 1432/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 308439806061.4879 - val_loss: 344231179475.1370\n",
      "Epoch 1433/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 310010274542.8565 - val_loss: 340835091962.0951\n",
      "Epoch 1434/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 308132652875.0568 - val_loss: 340856023037.1196\n",
      "Epoch 1435/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 310557742805.5014 - val_loss: 339030287064.1778\n",
      "Epoch 1436/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 310451932255.0816 - val_loss: 344664170688.4141\n",
      "Epoch 1437/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 310187812111.4147 - val_loss: 352323345595.5173\n",
      "Epoch 1438/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 312490559606.7079 - val_loss: 343626107393.2962\n",
      "Epoch 1439/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 309245779447.0681 - val_loss: 343921223128.1058\n",
      "Epoch 1440/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 313957597525.1412 - val_loss: 355639191066.9322\n",
      "Epoch 1441/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 312397202800.2251 - val_loss: 341519568082.5609\n",
      "Epoch 1442/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 312001235164.1283 - val_loss: 338719975307.0537\n",
      "Epoch 1443/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 308095211359.8019 - val_loss: 342673487850.6847\n",
      "Epoch 1444/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 310776983037.9832 - val_loss: 357159814103.9617\n",
      "Epoch 1445/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 311807781413.7445 - val_loss: 341120381991.4622\n",
      "Epoch 1446/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 308647077070.8745 - val_loss: 342064863079.9122\n",
      "Epoch 1447/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 312943850018.2870 - val_loss: 348371931942.5260\n",
      "Epoch 1448/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 310277948673.5847 - val_loss: 339375573418.3066\n",
      "Epoch 1449/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 76us/step - loss: 308121236749.1097 - val_loss: 339536728990.3527\n",
      "Epoch 1450/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 307697989642.3726 - val_loss: 338899877691.5533\n",
      "Epoch 1451/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 312115135164.7226 - val_loss: 341033733587.4971\n",
      "Epoch 1452/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 315505657709.6320 - val_loss: 353740047546.9412\n",
      "Epoch 1453/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 312005224850.2240 - val_loss: 349509823817.8115\n",
      "Epoch 1454/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 309149460179.1964 - val_loss: 341279573382.8771\n",
      "Epoch 1455/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 311619673028.6460 - val_loss: 360133840062.9738\n",
      "Epoch 1456/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 307161102475.4530 - val_loss: 339702242338.2773\n",
      "Epoch 1457/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 307546493561.8773 - val_loss: 337063208158.6588\n",
      "Epoch 1458/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 307090561499.9843 - val_loss: 349533757835.1978\n",
      "Epoch 1459/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 307040454793.1480 - val_loss: 341445369710.8253\n",
      "Epoch 1460/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 306393266001.9719 - val_loss: 356752883157.8014\n",
      "Epoch 1461/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 316326200969.4362 - val_loss: 344722838023.6332\n",
      "Epoch 1462/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 308556047105.8728 - val_loss: 348938677617.5618\n",
      "Epoch 1463/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 309318904645.8705 - val_loss: 340421325584.0585\n",
      "Epoch 1464/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 309445596535.1401 - val_loss: 338419503390.8928\n",
      "Epoch 1465/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 308943134438.7890 - val_loss: 343988863094.6746\n",
      "Epoch 1466/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 310486033072.3331 - val_loss: 341558885798.5620\n",
      "Epoch 1467/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 307690440778.9128 - val_loss: 341535536130.5924\n",
      "Epoch 1468/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 305034667509.9156 - val_loss: 338528660112.7426\n",
      "Epoch 1469/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 309536912192.1080 - val_loss: 339956822842.1131\n",
      "Epoch 1470/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 304721624424.1576 - val_loss: 339342249843.4340\n",
      "Epoch 1471/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 308187433087.9280 - val_loss: 341936775479.0886\n",
      "Epoch 1472/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 308388219349.0692 - val_loss: 341777345298.3629\n",
      "Epoch 1473/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 308484531310.0641 - val_loss: 348475376782.0062\n",
      "Epoch 1474/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 310266685715.4485 - val_loss: 368867220896.8011\n",
      "Epoch 1475/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 308568449508.0518 - val_loss: 341959220344.6909\n",
      "Epoch 1476/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 312972370625.3326 - val_loss: 337287341362.1918\n",
      "Epoch 1477/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 309337146183.0231 - val_loss: 339992929249.1792\n",
      "Epoch 1478/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 305808245934.6044 - val_loss: 343171633039.6625\n",
      "Epoch 1479/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 309436429940.6910 - val_loss: 342051339714.2144\n",
      "Epoch 1480/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 308360878224.0630 - val_loss: 347276461646.2042\n",
      "Epoch 1481/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 310929255417.6613 - val_loss: 383866485696.9182\n",
      "Epoch 1482/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 313055629272.8149 - val_loss: 345718195715.3125\n",
      "Epoch 1483/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 305819400442.0934 - val_loss: 339023062999.0976\n",
      "Epoch 1484/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 311516328804.9882 - val_loss: 345588940044.7460\n",
      "Epoch 1485/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 307776730279.6894 - val_loss: 361252195242.4506\n",
      "Epoch 1486/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 310412336428.2274 - val_loss: 334927730099.2360\n",
      "Epoch 1487/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 307107948741.0782 - val_loss: 349234567466.9907\n",
      "Epoch 1488/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 304896859021.3258 - val_loss: 335875779220.1992\n",
      "Epoch 1489/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 305463199254.1857 - val_loss: 342771902582.0984\n",
      "Epoch 1490/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 303149080193.3686 - val_loss: 338499414390.4585\n",
      "Epoch 1491/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 303844425359.1987 - val_loss: 335686919386.6262\n",
      "Epoch 1492/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 307636798454.2037 - val_loss: 338298246843.0852\n",
      "Epoch 1493/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 303963122930.6022 - val_loss: 338312995910.5710\n",
      "Epoch 1494/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 304845976291.9077 - val_loss: 336288818502.3550\n",
      "Epoch 1495/7000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 309745543517.2087 - val_loss: 335405498569.0554\n",
      "Epoch 1496/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 307110138157.9561 - val_loss: 338915769852.3994\n",
      "Epoch 1497/7000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 309612188383.2977 - val_loss: 339941552685.0790\n",
      "Epoch 1498/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 304920641692.7406 - val_loss: 349433281722.3651\n",
      "Epoch 1499/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 308435383021.1277 - val_loss: 340678920951.8627\n",
      "Epoch 1500/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 302820738324.0247 - val_loss: 338506342036.4872\n",
      "Epoch 1501/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 303811231836.2003 - val_loss: 349174068337.2017\n",
      "Epoch 1502/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 310385055279.5408 - val_loss: 334923647412.1002\n",
      "Epoch 1503/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 302949546068.1328 - val_loss: 336334727954.3629\n",
      "Epoch 1504/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 302557538754.6292 - val_loss: 354758356349.0836\n",
      "Epoch 1505/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 309494331356.2723 - val_loss: 333146507393.0442\n",
      "Epoch 1506/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 303085179384.7969 - val_loss: 344184896859.6703\n",
      "Epoch 1507/7000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 305844456584.5717 - val_loss: 337103859615.2169\n",
      "Epoch 1508/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 305867474753.8368 - val_loss: 347469074281.6405\n",
      "Epoch 1509/7000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 302198607777.4946 - val_loss: 340066983919.2934\n",
      "Epoch 1510/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 302083398541.3258 - val_loss: 338701580993.7103\n",
      "Epoch 1511/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 304219040328.3196 - val_loss: 338229828329.4604\n",
      "Epoch 1512/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 90us/step - loss: 306322805810.1339 - val_loss: 338183668001.1972\n",
      "Epoch 1513/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 301534734915.7096 - val_loss: 334074975475.3980\n",
      "Epoch 1514/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 301940922465.9628 - val_loss: 333813422323.6861\n",
      "Epoch 1515/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 302520459139.5295 - val_loss: 337349176394.6036\n",
      "Epoch 1516/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 300327961793.0445 - val_loss: 334723334288.5986\n",
      "Epoch 1517/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 305846064647.0591 - val_loss: 335842816521.9376\n",
      "Epoch 1518/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 304531882186.8407 - val_loss: 333102207501.9702\n",
      "Epoch 1519/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 303606417761.8188 - val_loss: 334710817673.0374\n",
      "Epoch 1520/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 302297103240.7158 - val_loss: 337929701029.7699\n",
      "Epoch 1521/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 302961431539.8987 - val_loss: 337496611329.8723\n",
      "Epoch 1522/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 302937639095.2482 - val_loss: 334895215177.8835\n",
      "Epoch 1523/7000\n",
      "3554/3554 [==============================] - 0s 135us/step - loss: 300682582081.6927 - val_loss: 343270844716.1429\n",
      "Epoch 1524/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 304915514533.3843 - val_loss: 334670898939.0312\n",
      "Epoch 1525/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 302095062547.8807 - val_loss: 344990283956.8923\n",
      "Epoch 1526/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 307246389530.3635 - val_loss: 345906142136.8529\n",
      "Epoch 1527/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 315174876410.6697 - val_loss: 336793245129.7035\n",
      "Epoch 1528/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 300572160183.2482 - val_loss: 333814774355.1010\n",
      "Epoch 1529/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 301529957237.1232 - val_loss: 333714900751.1944\n",
      "Epoch 1530/7000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 302458596530.0619 - val_loss: 362332657003.8008\n",
      "Epoch 1531/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 308141779168.7383 - val_loss: 333920259627.0627\n",
      "Epoch 1532/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 305825966037.3574 - val_loss: 338236370624.8461\n",
      "Epoch 1533/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 304115653351.3652 - val_loss: 335318959327.8110\n",
      "Epoch 1534/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 301629410707.9527 - val_loss: 334531976601.8881\n",
      "Epoch 1535/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 302954130969.6432 - val_loss: 335514351838.9468\n",
      "Epoch 1536/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 302251141123.4575 - val_loss: 335270933249.6562\n",
      "Epoch 1537/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 306054902767.2887 - val_loss: 335301801967.8695\n",
      "Epoch 1538/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 304274194201.4991 - val_loss: 347774829084.3724\n",
      "Epoch 1539/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 305514880466.1879 - val_loss: 336475148753.4807\n",
      "Epoch 1540/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 303711859492.4479 - val_loss: 335820960544.7651\n",
      "Epoch 1541/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 301296197590.5098 - val_loss: 334267385593.8790\n",
      "Epoch 1542/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 301706672866.7552 - val_loss: 336593668054.5215\n",
      "Epoch 1543/7000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 300200168732.0923 - val_loss: 336994662410.9457\n",
      "Epoch 1544/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 303261299455.5678 - val_loss: 335496710805.9274\n",
      "Epoch 1545/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 300749072677.8885 - val_loss: 335875254269.1196\n",
      "Epoch 1546/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 299918113296.9995 - val_loss: 334385284982.3145\n",
      "Epoch 1547/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 301124712425.5261 - val_loss: 340798303846.4000\n",
      "Epoch 1548/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 301733328279.4103 - val_loss: 343519409056.6571\n",
      "Epoch 1549/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 301528442865.0175 - val_loss: 343581203409.6248\n",
      "Epoch 1550/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 307473013165.8841 - val_loss: 336821273572.6357\n",
      "Epoch 1551/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 301475673218.8092 - val_loss: 341118876096.7741\n",
      "Epoch 1552/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 302633979748.4119 - val_loss: 337888634481.9218\n",
      "Epoch 1553/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 303453314219.1469 - val_loss: 335707685667.0695\n",
      "Epoch 1554/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 301884961203.6466 - val_loss: 351826991321.1859\n",
      "Epoch 1555/7000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 299402870369.0985 - val_loss: 341329934111.9010\n",
      "Epoch 1556/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 302172204993.7648 - val_loss: 348463796839.2642\n",
      "Epoch 1557/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 300927381218.1790 - val_loss: 333567083933.9207\n",
      "Epoch 1558/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 300775204904.3376 - val_loss: 350359999612.7235\n",
      "Epoch 1559/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 303038365608.4097 - val_loss: 332109397127.6692\n",
      "Epoch 1560/7000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 300684022034.2960 - val_loss: 331312005466.8062\n",
      "Epoch 1561/7000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 298901100688.0630 - val_loss: 344950812156.9755\n",
      "Epoch 1562/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 301121571838.2712 - val_loss: 333259602363.0132\n",
      "Epoch 1563/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 301050628362.2285 - val_loss: 338239777557.8194\n",
      "Epoch 1564/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 302112286326.9960 - val_loss: 333609296728.0698\n",
      "Epoch 1565/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 300211252927.6038 - val_loss: 349035931331.7266\n",
      "Epoch 1566/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 302922513888.0180 - val_loss: 341605300696.9699\n",
      "Epoch 1567/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 301785652376.7068 - val_loss: 342798080159.5769\n",
      "Epoch 1568/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 304534565336.5267 - val_loss: 333321075805.0385\n",
      "Epoch 1569/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 301106933218.3230 - val_loss: 336870135157.5944\n",
      "Epoch 1570/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 303050575805.1547 - val_loss: 340044531921.1207\n",
      "Epoch 1571/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 309022323833.5892 - val_loss: 336847630534.1750\n",
      "Epoch 1572/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 299388786076.0203 - val_loss: 334469615486.9558\n",
      "Epoch 1573/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 298329406252.5154 - val_loss: 331102751819.7559\n",
      "Epoch 1574/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 298605248606.5054 - val_loss: 334115383940.6447\n",
      "Epoch 1575/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 94us/step - loss: 298005461749.1953 - val_loss: 332488889499.8323\n",
      "Epoch 1576/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 297910451827.5386 - val_loss: 331667914075.6703\n",
      "Epoch 1577/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 298195229313.9448 - val_loss: 346220203807.3249\n",
      "Epoch 1578/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 301421041586.7822 - val_loss: 330876665365.1713\n",
      "Epoch 1579/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 301102812167.4913 - val_loss: 329858284380.1024\n",
      "Epoch 1580/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 297250228656.1891 - val_loss: 340117150560.7111\n",
      "Epoch 1581/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 299491778878.0911 - val_loss: 339054466149.6799\n",
      "Epoch 1582/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 297605672316.9026 - val_loss: 333166549080.1418\n",
      "Epoch 1583/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 297497573515.4530 - val_loss: 334438637316.8248\n",
      "Epoch 1584/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 298616547976.8599 - val_loss: 344199169531.2473\n",
      "Epoch 1585/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 302902290988.6595 - val_loss: 332301367628.4039\n",
      "Epoch 1586/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 299171928996.3759 - val_loss: 334053082252.8540\n",
      "Epoch 1587/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 298132611398.1587 - val_loss: 329478473941.7294\n",
      "Epoch 1588/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 295874618823.8154 - val_loss: 333361247128.5919\n",
      "Epoch 1589/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 299761468599.8244 - val_loss: 333494936429.9612\n",
      "Epoch 1590/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 299659101651.3405 - val_loss: 342993829345.3232\n",
      "Epoch 1591/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 300121113710.0641 - val_loss: 349210167992.4928\n",
      "Epoch 1592/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 302906074088.3737 - val_loss: 332822373535.2889\n",
      "Epoch 1593/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 297616256316.3624 - val_loss: 334614492080.7876\n",
      "Epoch 1594/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 297853218919.7254 - val_loss: 332850471465.0464\n",
      "Epoch 1595/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 300357828469.6995 - val_loss: 346709296624.8776\n",
      "Epoch 1596/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 300217109622.1317 - val_loss: 336797081063.0841\n",
      "Epoch 1597/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 296358152449.0084 - val_loss: 338719294347.9178\n",
      "Epoch 1598/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 298218674218.6426 - val_loss: 332266408784.5806\n",
      "Epoch 1599/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 295401861242.1655 - val_loss: 336283067319.7007\n",
      "Epoch 1600/7000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 295683864042.3906 - val_loss: 331889960185.1589\n",
      "Epoch 1601/7000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 295633381637.6185 - val_loss: 341829745331.8841\n",
      "Epoch 1602/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 299781853495.1761 - val_loss: 330112447794.7679\n",
      "Epoch 1603/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 297762954964.3489 - val_loss: 334442986404.6898\n",
      "Epoch 1604/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 301024479610.5977 - val_loss: 361935404331.2787\n",
      "Epoch 1605/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 297579229946.9578 - val_loss: 345776802278.7961\n",
      "Epoch 1606/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 295938237342.6134 - val_loss: 329428656909.1780\n",
      "Epoch 1607/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 295813095382.5098 - val_loss: 330631781585.4087\n",
      "Epoch 1608/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 297147057298.9443 - val_loss: 342956312135.2911\n",
      "Epoch 1609/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 298318340484.6821 - val_loss: 332213200598.1614\n",
      "Epoch 1610/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 298418847568.8193 - val_loss: 346660116374.5755\n",
      "Epoch 1611/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 295557209259.1469 - val_loss: 330552332119.7817\n",
      "Epoch 1612/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 295901611791.1266 - val_loss: 336454201573.2838\n",
      "Epoch 1613/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 297727614464.2881 - val_loss: 332127632012.7100\n",
      "Epoch 1614/7000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 299702907122.0259 - val_loss: 330596724094.2357\n",
      "Epoch 1615/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 296301838529.6207 - val_loss: 334565233326.6993\n",
      "Epoch 1616/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 298882359595.6511 - val_loss: 432498412902.0399\n",
      "Epoch 1617/7000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 300670608563.2144 - val_loss: 329144704506.6711\n",
      "Epoch 1618/7000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 299801080630.8880 - val_loss: 328973973101.3131\n",
      "Epoch 1619/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 292216861789.9291 - val_loss: 331919408935.3901\n",
      "Epoch 1620/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 293122813355.0028 - val_loss: 330251263464.2363\n",
      "Epoch 1621/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 292641695291.0659 - val_loss: 333081765247.9640\n",
      "Epoch 1622/7000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 295845146946.7012 - val_loss: 326834399795.9921\n",
      "Epoch 1623/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 292671303673.0850 - val_loss: 330628881165.7542\n",
      "Epoch 1624/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 296146436722.9623 - val_loss: 326960451404.2599\n",
      "Epoch 1625/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 295555399034.5977 - val_loss: 334718157054.6318\n",
      "Epoch 1626/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 298594669913.1750 - val_loss: 354746043710.8658\n",
      "Epoch 1627/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 294908788173.5779 - val_loss: 326280242517.3333\n",
      "Epoch 1628/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 292601803943.6894 - val_loss: 342826456028.5704\n",
      "Epoch 1629/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 294394460686.6944 - val_loss: 329555306092.1609\n",
      "Epoch 1630/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 292602131865.1390 - val_loss: 333107262718.9199\n",
      "Epoch 1631/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 291910759333.5284 - val_loss: 335315319383.7097\n",
      "Epoch 1632/7000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 298625256589.1818 - val_loss: 325624353655.1786\n",
      "Epoch 1633/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 291003963812.6641 - val_loss: 326960131745.7372\n",
      "Epoch 1634/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 292472082106.9938 - val_loss: 327626900916.9643\n",
      "Epoch 1635/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 300898015385.2831 - val_loss: 325767578193.3727\n",
      "Epoch 1636/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 298005245336.5627 - val_loss: 325826797758.1097\n",
      "Epoch 1637/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 302641133062.0507 - val_loss: 326048925352.0743\n",
      "Epoch 1638/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 99us/step - loss: 292095973566.1632 - val_loss: 330326725080.3938\n",
      "Epoch 1639/7000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 294458982335.4598 - val_loss: 330341611926.1434\n",
      "Epoch 1640/7000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 292481672657.0355 - val_loss: 328791390958.6453\n",
      "Epoch 1641/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 288142249460.7631 - val_loss: 328814932930.0703\n",
      "Epoch 1642/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 288709703374.5864 - val_loss: 327649420014.0692\n",
      "Epoch 1643/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 288646276909.0917 - val_loss: 325564830154.5676\n",
      "Epoch 1644/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 292819476844.1913 - val_loss: 326681939073.9083\n",
      "Epoch 1645/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 292606385461.4474 - val_loss: 323585210064.4006\n",
      "Epoch 1646/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 290442855209.0580 - val_loss: 334112208351.5949\n",
      "Epoch 1647/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 286400674042.0934 - val_loss: 325035207217.6877\n",
      "Epoch 1648/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 292945267525.8705 - val_loss: 334508527869.4796\n",
      "Epoch 1649/7000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 287087350421.5374 - val_loss: 326758185737.1454\n",
      "Epoch 1650/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 287923974764.0473 - val_loss: 319847510340.9148\n",
      "Epoch 1651/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 286362887679.1356 - val_loss: 328004114464.8372\n",
      "Epoch 1652/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 284125373608.8419 - val_loss: 337406195543.2056\n",
      "Epoch 1653/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 288778772023.6083 - val_loss: 323863730026.7927\n",
      "Epoch 1654/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 289549325687.1401 - val_loss: 324743901849.9601\n",
      "Epoch 1655/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 283149031817.0040 - val_loss: 324111582937.6180\n",
      "Epoch 1656/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 282605860948.1328 - val_loss: 314495254276.8248\n",
      "Epoch 1657/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 278439535389.5330 - val_loss: 331929052853.9005\n",
      "Epoch 1658/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 278166249854.6314 - val_loss: 326511733957.8869\n",
      "Epoch 1659/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 277752789250.4761 - val_loss: 310359555924.3252\n",
      "Epoch 1660/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 273917507005.4429 - val_loss: 323481446286.5103\n",
      "Epoch 1661/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 279060244513.4226 - val_loss: 309755184577.6382\n",
      "Epoch 1662/7000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 272977473003.5431 - val_loss: 306082402718.7848\n",
      "Epoch 1663/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 269552426999.9325 - val_loss: 308205100661.9544\n",
      "Epoch 1664/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 272233791386.5796 - val_loss: 326851170695.7412\n",
      "Epoch 1665/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 270599498570.4806 - val_loss: 300852143564.0079\n",
      "Epoch 1666/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 270370908947.1604 - val_loss: 311525424358.1479\n",
      "Epoch 1667/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 268401343001.0670 - val_loss: 299493677416.0563\n",
      "Epoch 1668/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 268170896895.1356 - val_loss: 301027669612.1609\n",
      "Epoch 1669/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 263188270078.2712 - val_loss: 307841502866.7589\n",
      "Epoch 1670/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 264677017655.1761 - val_loss: 291498584704.0360\n",
      "Epoch 1671/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 258530244433.9719 - val_loss: 287537895795.5781\n",
      "Epoch 1672/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 257971547516.9026 - val_loss: 286009887797.8644\n",
      "Epoch 1673/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 254346950011.7502 - val_loss: 287655031292.1114\n",
      "Epoch 1674/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 252293326086.1947 - val_loss: 282770358240.8911\n",
      "Epoch 1675/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 247525709815.9325 - val_loss: 283631324456.9744\n",
      "Epoch 1676/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 247768941203.2324 - val_loss: 283950185545.4515\n",
      "Epoch 1677/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 243421079320.3467 - val_loss: 271311866726.4720\n",
      "Epoch 1678/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 236860134175.8379 - val_loss: 267644146677.9184\n",
      "Epoch 1679/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 234148932108.3894 - val_loss: 266273412537.5730\n",
      "Epoch 1680/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 232532233988.7541 - val_loss: 267567562333.7586\n",
      "Epoch 1681/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 232095546879.1356 - val_loss: 262995597067.1617\n",
      "Epoch 1682/7000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 225482326207.3157 - val_loss: 255637218714.4641\n",
      "Epoch 1683/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 227645380208.0810 - val_loss: 253763594117.2928\n",
      "Epoch 1684/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 224829827610.2195 - val_loss: 265718988647.9122\n",
      "Epoch 1685/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 219443249341.4789 - val_loss: 249869147534.3662\n",
      "Epoch 1686/7000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 216664647674.2375 - val_loss: 245829898950.8951\n",
      "Epoch 1687/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 217494231506.7642 - val_loss: 249654826796.5750\n",
      "Epoch 1688/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 214052185670.5909 - val_loss: 250619435825.4717\n",
      "Epoch 1689/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 217335116783.2887 - val_loss: 251643839495.2011\n",
      "Epoch 1690/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 214396974082.8813 - val_loss: 239825549201.9668\n",
      "Epoch 1691/7000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 211043692537.0850 - val_loss: 244775544231.1381\n",
      "Epoch 1692/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 208914856524.9297 - val_loss: 236586185365.3513\n",
      "Epoch 1693/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 206949463820.8216 - val_loss: 240105338790.7061\n",
      "Epoch 1694/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 205109737293.3618 - val_loss: 240618985754.8602\n",
      "Epoch 1695/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 207272917463.3742 - val_loss: 235766483056.3376\n",
      "Epoch 1696/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 212986446215.8514 - val_loss: 254443518545.9488\n",
      "Epoch 1697/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 202332910224.9274 - val_loss: 236755787279.4104\n",
      "Epoch 1698/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 204515383393.9628 - val_loss: 234058590180.9238\n",
      "Epoch 1699/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 205054315601.2516 - val_loss: 230190230282.2976\n",
      "Epoch 1700/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 201378739708.8306 - val_loss: 228694101414.5620\n",
      "Epoch 1701/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 73us/step - loss: 200840150910.9195 - val_loss: 230477976971.4858\n",
      "Epoch 1702/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 202162914487.8244 - val_loss: 234684524361.3795\n",
      "Epoch 1703/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 200690841794.7732 - val_loss: 225313760452.1587\n",
      "Epoch 1704/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 204043263511.3382 - val_loss: 232156736108.4489\n",
      "Epoch 1705/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 199483370010.2195 - val_loss: 227346350431.4149\n",
      "Epoch 1706/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 198140445916.7046 - val_loss: 227490285667.6636\n",
      "Epoch 1707/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 197515135334.4288 - val_loss: 232478891499.6928\n",
      "Epoch 1708/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 196307062523.5341 - val_loss: 224162775763.5691\n",
      "Epoch 1709/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 198206507753.6702 - val_loss: 224531937769.1004\n",
      "Epoch 1710/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 197817648684.0833 - val_loss: 221684203764.2622\n",
      "Epoch 1711/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 195077754008.7068 - val_loss: 228485081445.7519\n",
      "Epoch 1712/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 194814387496.7698 - val_loss: 220500970474.9727\n",
      "Epoch 1713/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 199731341767.2392 - val_loss: 220380124851.5961\n",
      "Epoch 1714/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 193887632836.3579 - val_loss: 222606114113.1702\n",
      "Epoch 1715/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 196117015458.0709 - val_loss: 221688504154.0861\n",
      "Epoch 1716/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 193792025364.3129 - val_loss: 230184494908.7055\n",
      "Epoch 1717/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 192578114262.0776 - val_loss: 226010645079.1336\n",
      "Epoch 1718/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 193441284815.1627 - val_loss: 219430915671.9977\n",
      "Epoch 1719/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 193582867515.3540 - val_loss: 233471029751.5027\n",
      "Epoch 1720/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 196346958883.1514 - val_loss: 226456707231.0009\n",
      "Epoch 1721/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 193597023986.8903 - val_loss: 222033252910.8073\n",
      "Epoch 1722/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 193391337550.3703 - val_loss: 236953684659.8841\n",
      "Epoch 1723/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 193945543020.1913 - val_loss: 226471830349.7001\n",
      "Epoch 1724/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 196114209428.3849 - val_loss: 221300496657.6428\n",
      "Epoch 1725/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 193153465602.7372 - val_loss: 237376181953.4222\n",
      "Epoch 1726/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 192846909380.6460 - val_loss: 215999768279.3136\n",
      "Epoch 1727/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 191285639233.6927 - val_loss: 246184195966.3798\n",
      "Epoch 1728/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 195192760956.4705 - val_loss: 223137594580.8653\n",
      "Epoch 1729/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 193070601996.8216 - val_loss: 216168917345.1432\n",
      "Epoch 1730/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 191595577014.3838 - val_loss: 215962209934.1502\n",
      "Epoch 1731/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 189977434790.8250 - val_loss: 220978965730.6914\n",
      "Epoch 1732/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 192066729625.5712 - val_loss: 221518112305.3997\n",
      "Epoch 1733/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 190852310720.7563 - val_loss: 217948215136.4231\n",
      "Epoch 1734/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 193081108725.4834 - val_loss: 215369690323.7131\n",
      "Epoch 1735/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 189205706001.1435 - val_loss: 219684003634.9120\n",
      "Epoch 1736/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 189994573874.7102 - val_loss: 231391500400.3376\n",
      "Epoch 1737/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 190118493413.9246 - val_loss: 225827694295.3136\n",
      "Epoch 1738/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 189740980096.0720 - val_loss: 214248434040.1868\n",
      "Epoch 1739/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 190244439855.3967 - val_loss: 218104901743.7615\n",
      "Epoch 1740/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 187573147142.0507 - val_loss: 215660498212.3657\n",
      "Epoch 1741/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 187705747948.1193 - val_loss: 218606333992.3263\n",
      "Epoch 1742/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 190888130976.0540 - val_loss: 216879678671.6805\n",
      "Epoch 1743/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 192250818419.3945 - val_loss: 217802770630.7511\n",
      "Epoch 1744/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 192982834245.7265 - val_loss: 215387190069.5044\n",
      "Epoch 1745/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 189306607723.1829 - val_loss: 220660296358.0580\n",
      "Epoch 1746/7000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 197824779938.7912 - val_loss: 242565572306.7049\n",
      "Epoch 1747/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 188178634914.5031 - val_loss: 216311086495.6490\n",
      "Epoch 1748/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 189714059178.7147 - val_loss: 217211739477.9094\n",
      "Epoch 1749/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 188641092648.9139 - val_loss: 211325631306.8197\n",
      "Epoch 1750/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 186738929445.0242 - val_loss: 211862393102.7623\n",
      "Epoch 1751/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 190798858460.1283 - val_loss: 210134235393.5122\n",
      "Epoch 1752/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 185820713709.1277 - val_loss: 214312203121.4177\n",
      "Epoch 1753/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 186916464329.9764 - val_loss: 217259503400.5423\n",
      "Epoch 1754/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 188734714512.9274 - val_loss: 210406981807.1314\n",
      "Epoch 1755/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 186314229242.5256 - val_loss: 211202943111.3812\n",
      "Epoch 1756/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 185386566613.9336 - val_loss: 211641662762.1266\n",
      "Epoch 1757/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 186801969462.0236 - val_loss: 222281032221.5246\n",
      "Epoch 1758/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 184976271584.7383 - val_loss: 220353806121.6945\n",
      "Epoch 1759/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 184933607976.0495 - val_loss: 210843779788.6560\n",
      "Epoch 1760/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 184126591443.9167 - val_loss: 213864369727.8020\n",
      "Epoch 1761/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 186664146378.1204 - val_loss: 209275079834.1041\n",
      "Epoch 1762/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 186175121558.9781 - val_loss: 211640087849.5505\n",
      "Epoch 1763/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 182737887374.9106 - val_loss: 212366837084.2464\n",
      "Epoch 1764/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 85us/step - loss: 186801344832.3961 - val_loss: 209433758583.7547\n",
      "Epoch 1765/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 185399704963.8177 - val_loss: 211016939825.9038\n",
      "Epoch 1766/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 183621223119.1627 - val_loss: 210193980633.4740\n",
      "Epoch 1767/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 184831840502.6359 - val_loss: 209169030103.3857\n",
      "Epoch 1768/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 183114465602.7012 - val_loss: 211840254765.4391\n",
      "Epoch 1769/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 184161111932.6145 - val_loss: 218526859485.2186\n",
      "Epoch 1770/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 186633064381.1547 - val_loss: 223313410812.4714\n",
      "Epoch 1771/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 189590002038.5639 - val_loss: 212940440734.1367\n",
      "Epoch 1772/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 186412916722.7462 - val_loss: 210396158741.8194\n",
      "Epoch 1773/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 184106721588.8711 - val_loss: 208519232372.2982\n",
      "Epoch 1774/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 183829589797.0242 - val_loss: 209741699101.3806\n",
      "Epoch 1775/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 181270985276.7946 - val_loss: 209956927146.3786\n",
      "Epoch 1776/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 185303684332.8396 - val_loss: 212495182398.3618\n",
      "Epoch 1777/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 187748699481.1750 - val_loss: 210940081910.4225\n",
      "Epoch 1778/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 183810748003.4035 - val_loss: 209959548694.6835\n",
      "Epoch 1779/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 182385399131.4800 - val_loss: 226399812638.8208\n",
      "Epoch 1780/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 183540928666.4356 - val_loss: 216475572695.8177\n",
      "Epoch 1781/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 184943601602.9173 - val_loss: 217503944652.1519\n",
      "Epoch 1782/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 183781912730.4356 - val_loss: 209705346261.4413\n",
      "Epoch 1783/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 181689764640.9904 - val_loss: 208186820166.1389\n",
      "Epoch 1784/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 184496114529.5306 - val_loss: 217139072979.0650\n",
      "Epoch 1785/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 185534050748.8666 - val_loss: 218098383096.2948\n",
      "Epoch 1786/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 187302876664.2206 - val_loss: 210508592220.4624\n",
      "Epoch 1787/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 183154784106.4626 - val_loss: 212094437791.3609\n",
      "Epoch 1788/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 179167173692.5065 - val_loss: 209174264401.9488\n",
      "Epoch 1789/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 182325415061.2493 - val_loss: 241457922656.3510\n",
      "Epoch 1790/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 181150563914.0484 - val_loss: 207673035125.8824\n",
      "Epoch 1791/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 182023096706.0889 - val_loss: 218531657821.9027\n",
      "Epoch 1792/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 187378622634.5706 - val_loss: 210294108082.8039\n",
      "Epoch 1793/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 179993043589.4023 - val_loss: 206021139968.4321\n",
      "Epoch 1794/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 181665986533.4924 - val_loss: 204773882744.9069\n",
      "Epoch 1795/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 179678519664.8014 - val_loss: 207144703315.0290\n",
      "Epoch 1796/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 179964608949.9516 - val_loss: 226070667817.0464\n",
      "Epoch 1797/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 181311996625.4676 - val_loss: 205419643367.3722\n",
      "Epoch 1798/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 178680500212.4750 - val_loss: 207393582800.9767\n",
      "Epoch 1799/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 181927135687.2392 - val_loss: 209278723806.2267\n",
      "Epoch 1800/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 179570543605.0512 - val_loss: 220396509881.6450\n",
      "Epoch 1801/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 179740356179.2684 - val_loss: 203774164436.6492\n",
      "Epoch 1802/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 178581955210.0124 - val_loss: 206316504920.3578\n",
      "Epoch 1803/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 179801513748.8891 - val_loss: 206044368026.1041\n",
      "Epoch 1804/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 179418222834.0259 - val_loss: 208708782407.7952\n",
      "Epoch 1805/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 177311841243.6961 - val_loss: 203529029005.7902\n",
      "Epoch 1806/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 178103139761.9178 - val_loss: 204602968534.6655\n",
      "Epoch 1807/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 179352761668.4299 - val_loss: 205836602102.7105\n",
      "Epoch 1808/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 179393912863.1176 - val_loss: 203243901989.1578\n",
      "Epoch 1809/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 177692521307.7681 - val_loss: 209542814384.4276\n",
      "Epoch 1810/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 175890630166.1857 - val_loss: 205214830881.1972\n",
      "Epoch 1811/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 178086345405.8751 - val_loss: 201767575711.0009\n",
      "Epoch 1812/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 175433737872.3512 - val_loss: 204229210818.2863\n",
      "Epoch 1813/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 173843117841.4316 - val_loss: 205066998281.9376\n",
      "Epoch 1814/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 173288708393.9224 - val_loss: 198672180382.1367\n",
      "Epoch 1815/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 174099440579.4935 - val_loss: 200251514987.1527\n",
      "Epoch 1816/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 171084956118.2217 - val_loss: 200159929674.9637\n",
      "Epoch 1817/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 170285057355.3450 - val_loss: 210738769545.5415\n",
      "Epoch 1818/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 169716156507.0479 - val_loss: 192643825507.3035\n",
      "Epoch 1819/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 164889922604.3714 - val_loss: 190806615821.4661\n",
      "Epoch 1820/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 163799909744.2251 - val_loss: 185086327086.4473\n",
      "Epoch 1821/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 160716008515.4215 - val_loss: 187789181084.6965\n",
      "Epoch 1822/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 158090144826.2014 - val_loss: 182681357549.0610\n",
      "Epoch 1823/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 156420314985.0219 - val_loss: 177694490148.1497\n",
      "Epoch 1824/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 150953902637.8120 - val_loss: 174437259748.4917\n",
      "Epoch 1825/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 148183445478.6449 - val_loss: 171606711008.8191\n",
      "Epoch 1826/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 146931370867.9707 - val_loss: 171399269397.6034\n",
      "Epoch 1827/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 80us/step - loss: 143725324320.9904 - val_loss: 168584575973.2118\n",
      "Epoch 1828/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 142805003476.6370 - val_loss: 172666002083.7536\n",
      "Epoch 1829/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 140927481007.7569 - val_loss: 167622122476.1249\n",
      "Epoch 1830/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 139895240317.9111 - val_loss: 166513129177.6180\n",
      "Epoch 1831/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 140044211058.8182 - val_loss: 162056214892.0889\n",
      "Epoch 1832/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 135075033237.8255 - val_loss: 157529107732.8112\n",
      "Epoch 1833/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 135156794353.5937 - val_loss: 155488039237.4908\n",
      "Epoch 1834/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 131165480163.0433 - val_loss: 154259686357.0813\n",
      "Epoch 1835/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 130012613768.5717 - val_loss: 161911518128.2115\n",
      "Epoch 1836/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 137894239211.8312 - val_loss: 152408123589.0228\n",
      "Epoch 1837/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 127135916215.2482 - val_loss: 159639299108.5817\n",
      "Epoch 1838/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 127947256868.3039 - val_loss: 145700386181.1488\n",
      "Epoch 1839/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 125252739869.5329 - val_loss: 155224128048.5356\n",
      "Epoch 1840/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 122060669485.8120 - val_loss: 143590384503.1786\n",
      "Epoch 1841/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 122114755840.4322 - val_loss: 155657809733.3468\n",
      "Epoch 1842/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 119600885411.9437 - val_loss: 142241601313.6292\n",
      "Epoch 1843/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 120683450983.4373 - val_loss: 139531193380.0056\n",
      "Epoch 1844/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 117262281942.9420 - val_loss: 136950078522.4731\n",
      "Epoch 1845/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 116796910705.5217 - val_loss: 153237805740.6830\n",
      "Epoch 1846/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 119039590750.3613 - val_loss: 140323585527.2146\n",
      "Epoch 1847/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 116477883467.4890 - val_loss: 134338434850.4934\n",
      "Epoch 1848/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 114625074486.5999 - val_loss: 134360789792.1890\n",
      "Epoch 1849/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 112121798384.0090 - val_loss: 143324612254.8568\n",
      "Epoch 1850/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 110815296630.1317 - val_loss: 135045391015.7862\n",
      "Epoch 1851/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 110654164777.6342 - val_loss: 134157778840.8799\n",
      "Epoch 1852/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 111263855548.0022 - val_loss: 130858521496.5918\n",
      "Epoch 1853/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 114417256142.5864 - val_loss: 126330265167.9325\n",
      "Epoch 1854/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 108593041507.1154 - val_loss: 127916180944.0405\n",
      "Epoch 1855/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 107060055015.2212 - val_loss: 126758799106.5204\n",
      "Epoch 1856/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 106098292679.5273 - val_loss: 124124700735.9460\n",
      "Epoch 1857/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 105344261328.0270 - val_loss: 124767670911.7480\n",
      "Epoch 1858/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 103814728159.8739 - val_loss: 120997936217.5820\n",
      "Epoch 1859/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 107305366130.9623 - val_loss: 121136724296.9474\n",
      "Epoch 1860/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 102714840978.5121 - val_loss: 119456049389.9252\n",
      "Epoch 1861/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 101939491150.2262 - val_loss: 119857595111.1561\n",
      "Epoch 1862/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 100973913119.6939 - val_loss: 117314980905.0464\n",
      "Epoch 1863/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 101849538563.3134 - val_loss: 116275214226.2549\n",
      "Epoch 1864/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 98559583060.8531 - val_loss: 117741137629.6506\n",
      "Epoch 1865/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 97860995319.7884 - val_loss: 117096697839.5814\n",
      "Epoch 1866/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 98329724779.3270 - val_loss: 114767737599.0639\n",
      "Epoch 1867/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 95241135486.0552 - val_loss: 116293920715.5758\n",
      "Epoch 1868/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 96526917244.7586 - val_loss: 111949673747.0830\n",
      "Epoch 1869/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 98485346910.2172 - val_loss: 112492221228.5750\n",
      "Epoch 1870/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 97536586927.7569 - val_loss: 110659847760.2205\n",
      "Epoch 1871/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 93595316530.5661 - val_loss: 124838544524.3499\n",
      "Epoch 1872/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 96275362620.0743 - val_loss: 110372833485.3761\n",
      "Epoch 1873/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 93253327526.8250 - val_loss: 120026193263.2574\n",
      "Epoch 1874/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 93179692169.7243 - val_loss: 107857617080.2048\n",
      "Epoch 1875/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 91786918124.2634 - val_loss: 131897475901.5696\n",
      "Epoch 1876/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 92980424503.4643 - val_loss: 110608052200.3803\n",
      "Epoch 1877/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 90839068342.3838 - val_loss: 107172258712.7359\n",
      "Epoch 1878/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 89461585517.7760 - val_loss: 105325440766.1997\n",
      "Epoch 1879/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 91624230372.6280 - val_loss: 105321798997.4053\n",
      "Epoch 1880/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 88121620066.2510 - val_loss: 104365913265.7238\n",
      "Epoch 1881/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 87131974437.6004 - val_loss: 113479051009.0802\n",
      "Epoch 1882/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 91586630026.1564 - val_loss: 103881828270.1952\n",
      "Epoch 1883/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 86497585221.1503 - val_loss: 100248575806.2897\n",
      "Epoch 1884/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 85078938851.6196 - val_loss: 104465144670.5508\n",
      "Epoch 1885/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 83974377930.6967 - val_loss: 98694058768.3466\n",
      "Epoch 1886/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 83202705904.7293 - val_loss: 114902554266.5361\n",
      "Epoch 1887/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 84172222747.5161 - val_loss: 102365979970.8985\n",
      "Epoch 1888/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 83423134306.8272 - val_loss: 96629446807.3676\n",
      "Epoch 1889/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 83481277234.2780 - val_loss: 98469374823.4802\n",
      "Epoch 1890/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 72us/step - loss: 81711986458.6517 - val_loss: 98078378168.0608\n",
      "Epoch 1891/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 82750598156.1013 - val_loss: 95252071102.6858\n",
      "Epoch 1892/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 79381930846.0732 - val_loss: 94664309684.1001\n",
      "Epoch 1893/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 79809502240.8464 - val_loss: 100453917175.0706\n",
      "Epoch 1894/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 78449471702.3658 - val_loss: 95189819370.1086\n",
      "Epoch 1895/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 79113587740.2364 - val_loss: 114313965322.5856\n",
      "Epoch 1896/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 83205466016.9184 - val_loss: 92140792667.3823\n",
      "Epoch 1897/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 78126641276.4705 - val_loss: 91394419740.7325\n",
      "Epoch 1898/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 77573436920.2206 - val_loss: 102304204315.0582\n",
      "Epoch 1899/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 78446337241.2470 - val_loss: 94213086736.8506\n",
      "Epoch 1900/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 77445672339.9527 - val_loss: 92065198943.7030\n",
      "Epoch 1901/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 76289036245.3573 - val_loss: 89870908572.4084\n",
      "Epoch 1902/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 78204081871.7389 - val_loss: 90077424137.0734\n",
      "Epoch 1903/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 75690714196.7091 - val_loss: 92073185840.5356\n",
      "Epoch 1904/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 74831869635.0613 - val_loss: 93652040773.2028\n",
      "Epoch 1905/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 74291887035.4260 - val_loss: 90394874875.3913\n",
      "Epoch 1906/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 73408813744.0450 - val_loss: 99084746128.9586\n",
      "Epoch 1907/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 79245478200.3287 - val_loss: 93402403763.8121\n",
      "Epoch 1908/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 72924127161.6973 - val_loss: 86804985249.9533\n",
      "Epoch 1909/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 71714502403.6016 - val_loss: 85539058147.4115\n",
      "Epoch 1910/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 71495964216.7608 - val_loss: 87950521730.8445\n",
      "Epoch 1911/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 76968454270.1992 - val_loss: 85367783499.1077\n",
      "Epoch 1912/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 71409224664.8148 - val_loss: 83324152020.4332\n",
      "Epoch 1913/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 71225689178.9038 - val_loss: 88676453087.3789\n",
      "Epoch 1914/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 71826174364.5965 - val_loss: 101562903430.4450\n",
      "Epoch 1915/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 72503188333.0557 - val_loss: 82621692411.2473\n",
      "Epoch 1916/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 70209354708.4930 - val_loss: 82808386483.8121\n",
      "Epoch 1917/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 68848331912.5717 - val_loss: 85048473043.6411\n",
      "Epoch 1918/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 71764403227.0838 - val_loss: 82761792840.6593\n",
      "Epoch 1919/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 69613435434.3545 - val_loss: 83569066380.3499\n",
      "Epoch 1920/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 69234786654.3613 - val_loss: 82479564787.9021\n",
      "Epoch 1921/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 68258631700.7451 - val_loss: 82926405583.0323\n",
      "Epoch 1922/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 68344477701.6185 - val_loss: 80697959074.8895\n",
      "Epoch 1923/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 66770494318.2082 - val_loss: 85204060687.4104\n",
      "Epoch 1924/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 68748020317.0647 - val_loss: 79536822540.1699\n",
      "Epoch 1925/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 68745064049.2335 - val_loss: 80321774766.2672\n",
      "Epoch 1926/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 69245813518.5504 - val_loss: 79504821439.2619\n",
      "Epoch 1927/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 66917137447.7614 - val_loss: 81799752245.0003\n",
      "Epoch 1928/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 68094528605.9291 - val_loss: 83808804459.6928\n",
      "Epoch 1929/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 66294566185.9223 - val_loss: 79786500051.2090\n",
      "Epoch 1930/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 67115406849.4406 - val_loss: 78466772682.4956\n",
      "Epoch 1931/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 66489833274.9218 - val_loss: 99239317544.3263\n",
      "Epoch 1932/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 66778390228.3489 - val_loss: 79983656663.3136\n",
      "Epoch 1933/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 67628234255.2707 - val_loss: 81221814075.2653\n",
      "Epoch 1934/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 67408386482.4941 - val_loss: 81775829008.1305\n",
      "Epoch 1935/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 65694753053.8211 - val_loss: 82302092795.8233\n",
      "Epoch 1936/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 65467787463.3832 - val_loss: 78739120536.5918\n",
      "Epoch 1937/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 66460016298.8587 - val_loss: 78325706760.3533\n",
      "Epoch 1938/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 64745894304.6303 - val_loss: 81483855211.8008\n",
      "Epoch 1939/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 63536881539.5295 - val_loss: 77742488734.7128\n",
      "Epoch 1940/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 67960856404.5650 - val_loss: 75747942370.6194\n",
      "Epoch 1941/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 63874785787.4620 - val_loss: 76455540836.8158\n",
      "Epoch 1942/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 62087949932.6235 - val_loss: 76551502257.2917\n",
      "Epoch 1943/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 64160511673.8413 - val_loss: 75494304793.2039\n",
      "Epoch 1944/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 64991103410.4941 - val_loss: 73978925647.0684\n",
      "Epoch 1945/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 65810548398.3163 - val_loss: 77107139287.6737\n",
      "Epoch 1946/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 61122878900.2228 - val_loss: 78055990393.5550\n",
      "Epoch 1947/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 63357089551.1266 - val_loss: 74069096938.2526\n",
      "Epoch 1948/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 62194176407.9865 - val_loss: 74268485820.0934\n",
      "Epoch 1949/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 62659747921.8278 - val_loss: 83357012640.3691\n",
      "Epoch 1950/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 62197135591.6534 - val_loss: 74254492619.8639\n",
      "Epoch 1951/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 61119735275.5431 - val_loss: 73920023392.7111\n",
      "Epoch 1952/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 61698813613.1638 - val_loss: 93340291699.5060\n",
      "Epoch 1953/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 65218189434.1655 - val_loss: 72762444288.7201\n",
      "Epoch 1954/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 78us/step - loss: 60473432371.7186 - val_loss: 72020965866.1086\n",
      "Epoch 1955/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 60433373650.7642 - val_loss: 73685793534.3437\n",
      "Epoch 1956/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 61262416700.6505 - val_loss: 79232740333.2771\n",
      "Epoch 1957/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 61711447219.2144 - val_loss: 74841422676.0371\n",
      "Epoch 1958/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 60375851351.4463 - val_loss: 72443084962.7454\n",
      "Epoch 1959/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 60551689921.9088 - val_loss: 71747660026.8872\n",
      "Epoch 1960/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 60654549647.7749 - val_loss: 71206192543.9370\n",
      "Epoch 1961/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 60710687243.2369 - val_loss: 74839240728.6279\n",
      "Epoch 1962/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 59508798720.7203 - val_loss: 72600634295.5567\n",
      "Epoch 1963/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 61065354662.3928 - val_loss: 76550578834.3989\n",
      "Epoch 1964/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 60386865237.2853 - val_loss: 71351564663.0346\n",
      "Epoch 1965/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 59190070141.1908 - val_loss: 71901583025.2917\n",
      "Epoch 1966/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 60074647480.9769 - val_loss: 70566384713.4515\n",
      "Epoch 1967/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 59270417403.9662 - val_loss: 69809390951.4802\n",
      "Epoch 1968/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 59106723920.6753 - val_loss: 73241737432.0338\n",
      "Epoch 1969/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 59673451511.3562 - val_loss: 71343594707.7131\n",
      "Epoch 1970/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 59256027367.6534 - val_loss: 72923071103.4599\n",
      "Epoch 1971/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 58367937372.9207 - val_loss: 75912554677.4684\n",
      "Epoch 1972/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 58091818929.6297 - val_loss: 69038023299.4925\n",
      "Epoch 1973/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 59379804928.7203 - val_loss: 70866504141.7361\n",
      "Epoch 1974/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 58825590061.3799 - val_loss: 70562146802.3179\n",
      "Epoch 1975/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 58053732991.6398 - val_loss: 70506884928.1620\n",
      "Epoch 1976/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 58393183641.7153 - val_loss: 71076995641.1769\n",
      "Epoch 1977/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 58581258445.1458 - val_loss: 76892231899.4903\n",
      "Epoch 1978/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 58942145046.7620 - val_loss: 75249736252.3454\n",
      "Epoch 1979/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 59106395534.1902 - val_loss: 73589499880.3803\n",
      "Epoch 1980/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 56660267835.4980 - val_loss: 69538658347.2068\n",
      "Epoch 1981/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 55659272170.1024 - val_loss: 70459052598.8726\n",
      "Epoch 1982/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 56810358514.8903 - val_loss: 69298617029.7429\n",
      "Epoch 1983/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 57530124037.9066 - val_loss: 75569126939.2923\n",
      "Epoch 1984/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 57378104927.9460 - val_loss: 68418230120.4883\n",
      "Epoch 1985/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 57172816702.9555 - val_loss: 70367225501.2726\n",
      "Epoch 1986/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 57414264585.3641 - val_loss: 106388044572.7325\n",
      "Epoch 1987/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 60389964533.1953 - val_loss: 71567778835.8751\n",
      "Epoch 1988/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 56562163624.4097 - val_loss: 71542067057.9938\n",
      "Epoch 1989/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 57470867272.7518 - val_loss: 70029174162.6869\n",
      "Epoch 1990/7000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 58192453489.0895 - val_loss: 67233335644.5345\n",
      "Epoch 1991/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 57707979929.2831 - val_loss: 72402270103.4397\n",
      "Epoch 1992/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 56230096225.2425 - val_loss: 71435052354.8985\n",
      "Epoch 1993/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 55502737276.6145 - val_loss: 70969023552.8101\n",
      "Epoch 1994/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 57104516418.1249 - val_loss: 68626786825.9376\n",
      "Epoch 1995/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 56002092092.5065 - val_loss: 71769443784.5513\n",
      "Epoch 1996/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 60064462980.5380 - val_loss: 67089000790.1975\n",
      "Epoch 1997/7000\n",
      "3554/3554 [==============================] - 0s 68us/step - loss: 56157245637.7265 - val_loss: 73718700810.8737\n",
      "Epoch 1998/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 55522388151.2482 - val_loss: 66689439612.6515\n",
      "Epoch 1999/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 56504986640.1351 - val_loss: 66632638808.7899\n",
      "Epoch 2000/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 54859543712.7743 - val_loss: 74485144669.6146\n",
      "Epoch 2001/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 56064790101.5734 - val_loss: 68680233710.3572\n",
      "Epoch 2002/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 55203695364.1778 - val_loss: 66642103716.5457\n",
      "Epoch 2003/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 54893182340.9702 - val_loss: 72787194607.7975\n",
      "Epoch 2004/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 54868055347.1424 - val_loss: 73523937774.2852\n",
      "Epoch 2005/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 55309525153.3506 - val_loss: 66017876474.3831\n",
      "Epoch 2006/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 54861529963.9032 - val_loss: 65818326738.7049\n",
      "Epoch 2007/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 57132860046.6224 - val_loss: 65670986599.3361\n",
      "Epoch 2008/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 57139535844.3399 - val_loss: 69993195844.3387\n",
      "Epoch 2009/7000\n",
      "3554/3554 [==============================] - 0s 68us/step - loss: 55959315395.4935 - val_loss: 71087015039.0278\n",
      "Epoch 2010/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 57205657076.7631 - val_loss: 65427892495.3384\n",
      "Epoch 2011/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 56180780054.4738 - val_loss: 65725948452.7257\n",
      "Epoch 2012/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 55747036952.3466 - val_loss: 70585086320.9857\n",
      "Epoch 2013/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 53789676959.4778 - val_loss: 64983328667.7603\n",
      "Epoch 2014/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 53720045261.1458 - val_loss: 68692667543.7997\n",
      "Epoch 2015/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 54359728934.7530 - val_loss: 77672729293.2321\n",
      "Epoch 2016/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 54886409837.7760 - val_loss: 65396541321.9016\n",
      "Epoch 2017/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 55240170480.4412 - val_loss: 69819290415.5994\n",
      "Epoch 2018/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 82us/step - loss: 54122659408.9634 - val_loss: 70637574376.4523\n",
      "Epoch 2019/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 53594400457.9764 - val_loss: 65045053098.3786\n",
      "Epoch 2020/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 55725456988.4885 - val_loss: 64428146704.1305\n",
      "Epoch 2021/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 53711143631.1626 - val_loss: 69266882874.5452\n",
      "Epoch 2022/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 56210645955.4935 - val_loss: 66783755241.8205\n",
      "Epoch 2023/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 53754346349.0557 - val_loss: 67266782158.7443\n",
      "Epoch 2024/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 54043474522.7597 - val_loss: 65754701568.7921\n",
      "Epoch 2025/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 53282606705.2335 - val_loss: 69718500468.6582\n",
      "Epoch 2026/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 55051654657.4406 - val_loss: 66299230136.5648\n",
      "Epoch 2027/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 56784427889.6657 - val_loss: 68208389580.5840\n",
      "Epoch 2028/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 54624996263.8334 - val_loss: 66678899426.5474\n",
      "Epoch 2029/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 52612336681.2020 - val_loss: 82726895408.8956\n",
      "Epoch 2030/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 54377378421.2673 - val_loss: 66596438300.0124\n",
      "Epoch 2031/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 53609496317.8391 - val_loss: 68013424482.1513\n",
      "Epoch 2032/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 53168453711.5228 - val_loss: 64905242367.0639\n",
      "Epoch 2033/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 52689409636.5560 - val_loss: 64307569333.6124\n",
      "Epoch 2034/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 54082989754.9938 - val_loss: 69767263523.7896\n",
      "Epoch 2035/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 58543785033.1840 - val_loss: 64268827882.4686\n",
      "Epoch 2036/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 54779429096.8059 - val_loss: 64858715539.5511\n",
      "Epoch 2037/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 52739651119.8289 - val_loss: 65090972242.2368\n",
      "Epoch 2038/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 52604964810.9848 - val_loss: 77574548376.0157\n",
      "Epoch 2039/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 54614844037.4024 - val_loss: 63288660621.2861\n",
      "Epoch 2040/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 52709151990.0597 - val_loss: 68377419625.6405\n",
      "Epoch 2041/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 52661645438.7755 - val_loss: 66026515217.2107\n",
      "Epoch 2042/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 53236707369.4902 - val_loss: 64835783272.4163\n",
      "Epoch 2043/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 52331594474.8227 - val_loss: 65236476973.2231\n",
      "Epoch 2044/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 51722855600.0450 - val_loss: 72250085404.8045\n",
      "Epoch 2045/7000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 51912750828.5515 - val_loss: 63738978937.6990\n",
      "Epoch 2046/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 51936703997.9831 - val_loss: 76357830736.0765\n",
      "Epoch 2047/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 52263701834.1925 - val_loss: 72903870892.3229\n",
      "Epoch 2048/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 52245301552.2611 - val_loss: 63931390278.3550\n",
      "Epoch 2049/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 52213121760.1261 - val_loss: 63126383728.6256\n",
      "Epoch 2050/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 51637358184.0135 - val_loss: 64311728630.9266\n",
      "Epoch 2051/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 51995839145.1300 - val_loss: 65939324714.8467\n",
      "Epoch 2052/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 53521091165.0647 - val_loss: 69665817687.8537\n",
      "Epoch 2053/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 52476186787.6556 - val_loss: 70202082686.8118\n",
      "Epoch 2054/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 53950786650.4716 - val_loss: 73471833437.6866\n",
      "Epoch 2055/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 54189267455.7119 - val_loss: 63706834169.1589\n",
      "Epoch 2056/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 53922919233.2606 - val_loss: 69795760690.8400\n",
      "Epoch 2057/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 52023826310.4108 - val_loss: 65980071778.1513\n",
      "Epoch 2058/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 53021824317.5149 - val_loss: 62841581433.1949\n",
      "Epoch 2059/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 52059642055.3832 - val_loss: 62897884104.4073\n",
      "Epoch 2060/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 51783586803.8987 - val_loss: 66703390223.6985\n",
      "Epoch 2061/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 53051691865.4631 - val_loss: 62727275577.3210\n",
      "Epoch 2062/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 51492688853.9336 - val_loss: 71804081181.0925\n",
      "Epoch 2063/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 53025649135.5768 - val_loss: 63225516116.6852\n",
      "Epoch 2064/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 53632295267.5476 - val_loss: 67603557498.7072\n",
      "Epoch 2065/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 51510467222.6899 - val_loss: 63053585772.9530\n",
      "Epoch 2066/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 51775396802.3410 - val_loss: 62581036909.0970\n",
      "Epoch 2067/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 51839703548.2544 - val_loss: 70819405139.6051\n",
      "Epoch 2068/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 52931177843.6826 - val_loss: 67117766012.2194\n",
      "Epoch 2069/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 51325087695.5948 - val_loss: 62142990452.3702\n",
      "Epoch 2070/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 51963630722.8092 - val_loss: 65090536548.5277\n",
      "Epoch 2071/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 51612774577.4856 - val_loss: 62782923601.1567\n",
      "Epoch 2072/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 52762940058.1474 - val_loss: 80415674356.4782\n",
      "Epoch 2073/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 52405597199.5588 - val_loss: 61729212434.4349\n",
      "Epoch 2074/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 54256104449.7288 - val_loss: 71959916085.4323\n",
      "Epoch 2075/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 50983576973.0377 - val_loss: 62994711465.8745\n",
      "Epoch 2076/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 50573355371.0388 - val_loss: 62045367128.6459\n",
      "Epoch 2077/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 51368723333.8345 - val_loss: 69712450027.9809\n",
      "Epoch 2078/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 51032400992.2341 - val_loss: 67194980179.7491\n",
      "Epoch 2079/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 55275735348.8711 - val_loss: 62542878443.1888\n",
      "Epoch 2080/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 50344415448.6708 - val_loss: 63703278879.4689\n",
      "Epoch 2081/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 50475163899.2459 - val_loss: 62334812210.1198\n",
      "Epoch 2082/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 76us/step - loss: 52538175895.9865 - val_loss: 78239628124.1024\n",
      "Epoch 2083/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 53579457866.7687 - val_loss: 63079359318.9176\n",
      "Epoch 2084/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 50077964570.3635 - val_loss: 65007500659.2900\n",
      "Epoch 2085/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 53432631037.8391 - val_loss: 61266724109.3221\n",
      "Epoch 2086/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 50227643582.7394 - val_loss: 63068459318.5125\n",
      "Epoch 2087/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 50265288441.2290 - val_loss: 64164793023.4059\n",
      "Epoch 2088/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 50743165206.9060 - val_loss: 65918869802.4146\n",
      "Epoch 2089/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 49942297566.0011 - val_loss: 61151240259.9786\n",
      "Epoch 2090/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 50030145893.2763 - val_loss: 63164576404.1992\n",
      "Epoch 2091/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 49957658425.7693 - val_loss: 66136773741.7451\n",
      "Epoch 2092/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 51769216166.5369 - val_loss: 62338955240.3803\n",
      "Epoch 2093/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 54276864079.5228 - val_loss: 65884025776.7876\n",
      "Epoch 2094/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 53199276619.7772 - val_loss: 61129449672.4793\n",
      "Epoch 2095/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 51791214016.9004 - val_loss: 62233879504.4726\n",
      "Epoch 2096/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 52674809074.6021 - val_loss: 68832423902.0107\n",
      "Epoch 2097/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 50053855256.2026 - val_loss: 63062259509.7924\n",
      "Epoch 2098/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 49852487718.0326 - val_loss: 63592584384.1260\n",
      "Epoch 2099/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 50148761595.3900 - val_loss: 62743116533.5584\n",
      "Epoch 2100/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 50697575909.7805 - val_loss: 60928938779.8684\n",
      "Epoch 2101/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 53505890581.7535 - val_loss: 61303756664.3308\n",
      "Epoch 2102/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 49637252570.2555 - val_loss: 61558896727.5657\n",
      "Epoch 2103/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 50620416175.1806 - val_loss: 61554509578.0096\n",
      "Epoch 2104/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 50687466704.6033 - val_loss: 61943686342.4630\n",
      "Epoch 2105/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 49732081884.1283 - val_loss: 60828604924.6875\n",
      "Epoch 2106/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 49526368849.5397 - val_loss: 65395302193.7598\n",
      "Epoch 2107/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 49569492962.6111 - val_loss: 60818544090.9862\n",
      "Epoch 2108/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 49019905857.8368 - val_loss: 60375263429.5989\n",
      "Epoch 2109/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 50904460083.4305 - val_loss: 66512446402.0703\n",
      "Epoch 2110/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 51332631069.6770 - val_loss: 61417902857.7215\n",
      "Epoch 2111/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 51353052041.8683 - val_loss: 87469688268.0079\n",
      "Epoch 2112/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 53294911456.8824 - val_loss: 62695101604.4737\n",
      "Epoch 2113/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 50220451797.3573 - val_loss: 64375988651.4588\n",
      "Epoch 2114/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 50819163412.0248 - val_loss: 60794737645.8532\n",
      "Epoch 2115/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 49734501068.8576 - val_loss: 62266030631.0301\n",
      "Epoch 2116/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 50170325584.9634 - val_loss: 62466505130.5947\n",
      "Epoch 2117/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 48613322044.9387 - val_loss: 63967336859.0402\n",
      "Epoch 2118/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 50722095207.7254 - val_loss: 61557216674.5294\n",
      "Epoch 2119/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 48915131200.5402 - val_loss: 62770263313.3547\n",
      "Epoch 2120/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 50337425578.5706 - val_loss: 65872788910.6273\n",
      "Epoch 2121/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 49643748719.0726 - val_loss: 61829817471.0278\n",
      "Epoch 2122/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 48510736775.8514 - val_loss: 60466481722.9052\n",
      "Epoch 2123/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 49561186900.9972 - val_loss: 61343467703.7727\n",
      "Epoch 2124/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 50890939938.8633 - val_loss: 63928705502.1547\n",
      "Epoch 2125/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 48804674947.8177 - val_loss: 60826339870.6768\n",
      "Epoch 2126/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 48155660885.5734 - val_loss: 61740884488.7854\n",
      "Epoch 2127/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 48327000987.1559 - val_loss: 59980282712.0698\n",
      "Epoch 2128/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 48467631849.6702 - val_loss: 60288990148.3747\n",
      "Epoch 2129/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 48981661480.4817 - val_loss: 87128428940.3499\n",
      "Epoch 2130/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 51831228698.3635 - val_loss: 60097387057.6878\n",
      "Epoch 2131/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 49203286239.5858 - val_loss: 63670141012.1091\n",
      "Epoch 2132/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 49514403370.9308 - val_loss: 65054990509.4031\n",
      "Epoch 2133/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 51190210181.9786 - val_loss: 61863332187.3823\n",
      "Epoch 2134/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 50867481933.0737 - val_loss: 59166397070.4383\n",
      "Epoch 2135/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 47692582808.2746 - val_loss: 63862167462.9941\n",
      "Epoch 2136/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 50923465103.9190 - val_loss: 60774376981.7474\n",
      "Epoch 2137/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 48395822498.0709 - val_loss: 63842267819.2428\n",
      "Epoch 2138/7000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 48888729196.6235 - val_loss: 60350375706.1401\n",
      "Epoch 2139/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 48596392764.6505 - val_loss: 60259730053.2208\n",
      "Epoch 2140/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 49464755577.4451 - val_loss: 69333749764.6087\n",
      "Epoch 2141/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 51575125911.1221 - val_loss: 73490521262.8433\n",
      "Epoch 2142/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 49727545961.7423 - val_loss: 59097128081.4627\n",
      "Epoch 2143/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 49298271488.4322 - val_loss: 89825827810.9075\n",
      "Epoch 2144/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 51882975699.1784 - val_loss: 60945645338.1401\n",
      "Epoch 2145/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 47356077431.1401 - val_loss: 61497013213.7226\n",
      "Epoch 2146/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 75us/step - loss: 49597463370.4806 - val_loss: 69531301706.5316\n",
      "Epoch 2147/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 52507101222.0326 - val_loss: 61453273052.8585\n",
      "Epoch 2148/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 49018278166.9060 - val_loss: 67348031749.4008\n",
      "Epoch 2149/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 48383300904.7698 - val_loss: 62727115212.5840\n",
      "Epoch 2150/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 50116307236.1598 - val_loss: 60400403921.1927\n",
      "Epoch 2151/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 47532795412.1688 - val_loss: 59535101808.8416\n",
      "Epoch 2152/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 47093477113.2290 - val_loss: 62437136319.4779\n",
      "Epoch 2153/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 48732324263.8334 - val_loss: 64515616130.8444\n",
      "Epoch 2154/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 47735636386.3590 - val_loss: 59443109222.0399\n",
      "Epoch 2155/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 51307506607.9010 - val_loss: 81533392805.5539\n",
      "Epoch 2156/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 49183874526.9375 - val_loss: 60224846904.4568\n",
      "Epoch 2157/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 49097162545.1255 - val_loss: 62632684563.8751\n",
      "Epoch 2158/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 48968744191.2797 - val_loss: 60251456004.4647\n",
      "Epoch 2159/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 48115108184.5988 - val_loss: 60506715580.4534\n",
      "Epoch 2160/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 47256017753.4631 - val_loss: 60808680558.0332\n",
      "Epoch 2161/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 48193191302.6989 - val_loss: 60565101644.3319\n",
      "Epoch 2162/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 47866321593.2651 - val_loss: 75039497813.6934\n",
      "Epoch 2163/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 54285541804.7316 - val_loss: 73436134779.9314\n",
      "Epoch 2164/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 50059950521.4091 - val_loss: 62466160460.8360\n",
      "Epoch 2165/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 50311828998.0506 - val_loss: 60027754018.4214\n",
      "Epoch 2166/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 51437890793.3821 - val_loss: 59058548054.1975\n",
      "Epoch 2167/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 47565254336.1801 - val_loss: 60199786992.0135\n",
      "Epoch 2168/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 47613234277.9966 - val_loss: 61271981670.9761\n",
      "Epoch 2169/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 48245243205.5824 - val_loss: 63410047863.7547\n",
      "Epoch 2170/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 47603234060.5335 - val_loss: 59552045371.1212\n",
      "Epoch 2171/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 47785138638.1542 - val_loss: 62058604725.1803\n",
      "Epoch 2172/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 48566274526.2893 - val_loss: 61267653624.5108\n",
      "Epoch 2173/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 48906621571.0974 - val_loss: 60553178487.6107\n",
      "Epoch 2174/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 48476248722.0799 - val_loss: 61761888917.3513\n",
      "Epoch 2175/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 48279144866.9353 - val_loss: 61510364823.3677\n",
      "Epoch 2176/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 47631290272.3421 - val_loss: 62063492924.9935\n",
      "Epoch 2177/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 47994046937.1030 - val_loss: 59727765629.0115\n",
      "Epoch 2178/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 48871764099.3855 - val_loss: 60188704413.4166\n",
      "Epoch 2179/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 49788899118.2442 - val_loss: 78705329163.6658\n",
      "Epoch 2180/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 48171675087.8829 - val_loss: 63072329813.9814\n",
      "Epoch 2181/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 46740257084.9387 - val_loss: 61016920814.9333\n",
      "Epoch 2182/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 47222331828.7991 - val_loss: 58378591009.9173\n",
      "Epoch 2183/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 50933346108.0743 - val_loss: 63012342540.6020\n",
      "Epoch 2184/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 49711306758.9150 - val_loss: 61720452780.3949\n",
      "Epoch 2185/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 46987013173.5914 - val_loss: 60240564084.5862\n",
      "Epoch 2186/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 48363679045.5824 - val_loss: 66413863496.1553\n",
      "Epoch 2187/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 48325308046.0461 - val_loss: 63916205607.8942\n",
      "Epoch 2188/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 47740357793.9268 - val_loss: 62087853461.2793\n",
      "Epoch 2189/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 47692312423.0051 - val_loss: 59130877702.8411\n",
      "Epoch 2190/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 48376969912.1125 - val_loss: 77725052661.2703\n",
      "Epoch 2191/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 48860300527.1446 - val_loss: 60847882119.0211\n",
      "Epoch 2192/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 48167057699.5836 - val_loss: 61113036802.5924\n",
      "Epoch 2193/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 49399962156.6595 - val_loss: 60648075149.9342\n",
      "Epoch 2194/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 46767147027.5926 - val_loss: 61695679368.7494\n",
      "Epoch 2195/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 47746438864.3151 - val_loss: 59154569744.2745\n",
      "Epoch 2196/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 46685960665.1030 - val_loss: 58705655954.3269\n",
      "Epoch 2197/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 47313416457.0760 - val_loss: 58301978544.4996\n",
      "Epoch 2198/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 50134964340.4029 - val_loss: 69082447197.9747\n",
      "Epoch 2199/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 49574302827.7591 - val_loss: 58539217737.0914\n",
      "Epoch 2200/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 47397140518.0326 - val_loss: 61355550571.3688\n",
      "Epoch 2201/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 49988248542.8655 - val_loss: 64486620200.9024\n",
      "Epoch 2202/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 48217247761.2876 - val_loss: 64384602081.7553\n",
      "Epoch 2203/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 46510384062.8835 - val_loss: 63040242049.9803\n",
      "Epoch 2204/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 47278817888.5222 - val_loss: 62715165500.7055\n",
      "Epoch 2205/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 47594937800.9679 - val_loss: 75713294295.6737\n",
      "Epoch 2206/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 48253933924.9882 - val_loss: 60195472894.7038\n",
      "Epoch 2207/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 46405200110.5684 - val_loss: 58085145467.7873\n",
      "Epoch 2208/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 46437797595.2639 - val_loss: 59608816122.3831\n",
      "Epoch 2209/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 48940598965.2313 - val_loss: 59558022007.1786\n",
      "Epoch 2210/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 83us/step - loss: 47238724848.2971 - val_loss: 59100738979.6816\n",
      "Epoch 2211/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 51137133651.5566 - val_loss: 63322731047.0301\n",
      "Epoch 2212/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 47317334846.9555 - val_loss: 65341714978.1333\n",
      "Epoch 2213/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 46691366512.0810 - val_loss: 59153328102.0760\n",
      "Epoch 2214/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 48347733140.0968 - val_loss: 62465472039.3181\n",
      "Epoch 2215/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 47039040846.8025 - val_loss: 58918974136.4928\n",
      "Epoch 2216/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 46229888994.0349 - val_loss: 63180318111.0729\n",
      "Epoch 2217/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 47903281573.8165 - val_loss: 71826489645.8712\n",
      "Epoch 2218/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 53544689917.5509 - val_loss: 64715436926.0917\n",
      "Epoch 2219/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 46647321734.2667 - val_loss: 64069390395.9134\n",
      "Epoch 2220/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 46300124862.4513 - val_loss: 58164581007.5904\n",
      "Epoch 2221/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 45916298611.6826 - val_loss: 62762973722.6442\n",
      "Epoch 2222/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 46492973693.3348 - val_loss: 63756578630.4990\n",
      "Epoch 2223/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 46447328828.2183 - val_loss: 59188855716.1136\n",
      "Epoch 2224/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 46292962606.5324 - val_loss: 67216303849.7485\n",
      "Epoch 2225/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 50582708062.6494 - val_loss: 58676761236.1992\n",
      "Epoch 2226/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 46658537219.6016 - val_loss: 60114386746.6892\n",
      "Epoch 2227/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 46687391518.1092 - val_loss: 69209991954.3629\n",
      "Epoch 2228/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 47728353955.3675 - val_loss: 65907201077.2883\n",
      "Epoch 2229/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 47029348742.6989 - val_loss: 58503385394.4799\n",
      "Epoch 2230/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 47614413845.3213 - val_loss: 64357632793.5640\n",
      "Epoch 2231/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 47200561788.3264 - val_loss: 57912719996.2914\n",
      "Epoch 2232/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 46657099717.2223 - val_loss: 57958743459.9696\n",
      "Epoch 2233/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 45631677907.3405 - val_loss: 65775144472.3398\n",
      "Epoch 2234/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 47811711040.2521 - val_loss: 60406161964.5030\n",
      "Epoch 2235/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 47026704568.4007 - val_loss: 61900250415.8875\n",
      "Epoch 2236/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 45876927253.4654 - val_loss: 58665690700.1879\n",
      "Epoch 2237/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 46114699209.8323 - val_loss: 57696672206.0242\n",
      "Epoch 2238/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 45718924525.9921 - val_loss: 88761790757.3738\n",
      "Epoch 2239/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 52089987174.5729 - val_loss: 67224607939.2945\n",
      "Epoch 2240/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 45846976259.0253 - val_loss: 58216604797.8757\n",
      "Epoch 2241/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 44835139972.2499 - val_loss: 60154789495.1066\n",
      "Epoch 2242/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 45168590028.5695 - val_loss: 57376659231.3249\n",
      "Epoch 2243/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 45173327465.1660 - val_loss: 76418660840.0923\n",
      "Epoch 2244/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 47066234826.9848 - val_loss: 61269690073.6180\n",
      "Epoch 2245/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 46340821847.1581 - val_loss: 61154258957.8262\n",
      "Epoch 2246/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 46367787154.3680 - val_loss: 57728496853.7294\n",
      "Epoch 2247/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 45610972461.3799 - val_loss: 58180067767.5567\n",
      "Epoch 2248/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 44855769469.4789 - val_loss: 58803278998.6475\n",
      "Epoch 2249/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 45046143507.3044 - val_loss: 57614199853.2231\n",
      "Epoch 2250/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 46011882632.5718 - val_loss: 59213991850.1626\n",
      "Epoch 2251/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 45184480479.0096 - val_loss: 58045643640.9069\n",
      "Epoch 2252/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 45445096366.7485 - val_loss: 56640819699.4700\n",
      "Epoch 2253/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 46018179560.6618 - val_loss: 57712229408.5491\n",
      "Epoch 2254/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 46682862540.7136 - val_loss: 56952928329.1634\n",
      "Epoch 2255/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 46061475739.7321 - val_loss: 56445816510.5418\n",
      "Epoch 2256/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 44442464654.1902 - val_loss: 61376722367.6219\n",
      "Epoch 2257/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 46298255883.2369 - val_loss: 56520652019.9741\n",
      "Epoch 2258/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 48020301213.1728 - val_loss: 56870123669.2073\n",
      "Epoch 2259/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 45066315835.0658 - val_loss: 57898146120.9474\n",
      "Epoch 2260/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 44487001834.2465 - val_loss: 60793590905.2669\n",
      "Epoch 2261/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 47122969753.8593 - val_loss: 57635383833.4920\n",
      "Epoch 2262/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 47262477040.4412 - val_loss: 58532661578.0996\n",
      "Epoch 2263/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 46419850356.9792 - val_loss: 59031739264.3961\n",
      "Epoch 2264/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 45443693669.9966 - val_loss: 58500028293.1488\n",
      "Epoch 2265/7000\n",
      "3554/3554 [==============================] - 0s 68us/step - loss: 45042893754.2735 - val_loss: 62267123953.0937\n",
      "Epoch 2266/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 45623407324.9927 - val_loss: 58304875089.6608\n",
      "Epoch 2267/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 45015126663.7074 - val_loss: 61451524990.6678\n",
      "Epoch 2268/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 47209537434.5796 - val_loss: 67056268820.0191\n",
      "Epoch 2269/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 46688736792.4907 - val_loss: 58905587842.7724\n",
      "Epoch 2270/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 45101885867.5791 - val_loss: 59629959717.0138\n",
      "Epoch 2271/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 45300100726.9961 - val_loss: 56638438551.7997\n",
      "Epoch 2272/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 44536875053.2358 - val_loss: 61789652343.0346\n",
      "Epoch 2273/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 45379254800.9994 - val_loss: 58861505843.3440\n",
      "Epoch 2274/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 88us/step - loss: 45428932538.8497 - val_loss: 59345391994.2031\n",
      "Epoch 2275/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 44414038188.8756 - val_loss: 58253505763.2675\n",
      "Epoch 2276/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 44831452992.6843 - val_loss: 59441411773.9657\n",
      "Epoch 2277/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 45266058710.7980 - val_loss: 57475024353.3232\n",
      "Epoch 2278/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 44654196744.0675 - val_loss: 56767264785.8588\n",
      "Epoch 2279/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 44818631380.9252 - val_loss: 57239604180.5052\n",
      "Epoch 2280/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 43836207412.8711 - val_loss: 55994562758.1750\n",
      "Epoch 2281/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 45880560202.6246 - val_loss: 65839945151.3339\n",
      "Epoch 2282/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 45340292506.8678 - val_loss: 74063873949.0565\n",
      "Epoch 2283/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 45675797813.4474 - val_loss: 57687577835.3328\n",
      "Epoch 2284/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 44637460169.1120 - val_loss: 56512762545.0037\n",
      "Epoch 2285/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 44206406951.6173 - val_loss: 57866824049.8498\n",
      "Epoch 2286/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 46189283912.3196 - val_loss: 56859956492.1699\n",
      "Epoch 2287/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 46414460712.4817 - val_loss: 60610122601.3525\n",
      "Epoch 2288/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 44374829121.6927 - val_loss: 63658912937.0824\n",
      "Epoch 2289/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 44057304327.3472 - val_loss: 59400605651.9291\n",
      "Epoch 2290/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 46465377885.6410 - val_loss: 56588704837.4188\n",
      "Epoch 2291/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 45927965206.7620 - val_loss: 65005455587.5556\n",
      "Epoch 2292/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 44514958701.9201 - val_loss: 59298153393.9398\n",
      "Epoch 2293/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 45097766401.4406 - val_loss: 55475158593.5302\n",
      "Epoch 2294/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 46037999793.4856 - val_loss: 56563981943.6827\n",
      "Epoch 2295/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 43518021864.8059 - val_loss: 58126055015.2641\n",
      "Epoch 2296/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 44230044761.6072 - val_loss: 57300111741.0835\n",
      "Epoch 2297/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 43231182248.6978 - val_loss: 56835579729.1567\n",
      "Epoch 2298/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 43083342630.7530 - val_loss: 58674421079.0616\n",
      "Epoch 2299/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 44971054489.7153 - val_loss: 55584206462.0197\n",
      "Epoch 2300/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 44984284412.9747 - val_loss: 59763548129.7553\n",
      "Epoch 2301/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 44347220562.6922 - val_loss: 56349128114.6599\n",
      "Epoch 2302/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 43812998123.8312 - val_loss: 61293713735.7952\n",
      "Epoch 2303/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 44512402125.4339 - val_loss: 60113892729.9150\n",
      "Epoch 2304/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 43567843029.5014 - val_loss: 57475228725.2883\n",
      "Epoch 2305/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 45223567793.3416 - val_loss: 59761742037.1533\n",
      "Epoch 2306/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 43540143088.3692 - val_loss: 60000526055.7322\n",
      "Epoch 2307/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 44180452584.2296 - val_loss: 57213578178.0703\n",
      "Epoch 2308/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 43515634311.7074 - val_loss: 63709005369.4650\n",
      "Epoch 2309/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 44088859874.4671 - val_loss: 56842072332.1699\n",
      "Epoch 2310/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 43378668556.9657 - val_loss: 59259152623.9415\n",
      "Epoch 2311/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 44183050575.3787 - val_loss: 61877340397.9252\n",
      "Epoch 2312/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 43847233387.3270 - val_loss: 61215124878.3662\n",
      "Epoch 2313/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 44057130013.3889 - val_loss: 66922629101.5651\n",
      "Epoch 2314/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 45629971504.9814 - val_loss: 55018672238.0332\n",
      "Epoch 2315/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 43220612071.2212 - val_loss: 57094557199.9865\n",
      "Epoch 2316/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 43283532125.2088 - val_loss: 57365912359.9662\n",
      "Epoch 2317/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 45824730462.9375 - val_loss: 55933678639.5274\n",
      "Epoch 2318/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 42846309185.2606 - val_loss: 56154764322.5654\n",
      "Epoch 2319/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 42961673467.8222 - val_loss: 55079522936.5468\n",
      "Epoch 2320/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 43503253389.9021 - val_loss: 61531176184.5828\n",
      "Epoch 2321/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 44167992203.0208 - val_loss: 59836832927.8650\n",
      "Epoch 2322/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 42749577258.6427 - val_loss: 58665229234.5159\n",
      "Epoch 2323/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 44126535426.4491 - val_loss: 60628198762.0726\n",
      "Epoch 2324/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 43306652755.5566 - val_loss: 58072414212.0326\n",
      "Epoch 2325/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 44680155530.7327 - val_loss: 63815191491.7986\n",
      "Epoch 2326/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 43121732406.8880 - val_loss: 57363347985.4267\n",
      "Epoch 2327/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 43805936430.2442 - val_loss: 67059754078.7668\n",
      "Epoch 2328/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 43038991147.3630 - val_loss: 54341148269.6011\n",
      "Epoch 2329/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 44375549063.4193 - val_loss: 54265657507.6096\n",
      "Epoch 2330/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 41979604049.2515 - val_loss: 54092405343.4869\n",
      "Epoch 2331/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 42516750573.4159 - val_loss: 56158910979.8886\n",
      "Epoch 2332/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 41563120618.6787 - val_loss: 61825136717.1961\n",
      "Epoch 2333/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 41644096743.0771 - val_loss: 54015417325.2771\n",
      "Epoch 2334/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 41964998095.8829 - val_loss: 53142528447.9100\n",
      "Epoch 2335/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 41874601196.8396 - val_loss: 76647142843.8773\n",
      "Epoch 2336/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 44121996318.5414 - val_loss: 53972909018.2661\n",
      "Epoch 2337/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 42678101232.2971 - val_loss: 58275773834.9097\n",
      "Epoch 2338/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 80us/step - loss: 43127964934.1947 - val_loss: 52731188684.5840\n",
      "Epoch 2339/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 42533933863.9055 - val_loss: 55342070553.9961\n",
      "Epoch 2340/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 43251614994.8723 - val_loss: 71217983649.8813\n",
      "Epoch 2341/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 42046804177.7558 - val_loss: 56031958874.3741\n",
      "Epoch 2342/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 42722616946.3860 - val_loss: 53755896501.3243\n",
      "Epoch 2343/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 43909338955.0568 - val_loss: 56159816308.5142\n",
      "Epoch 2344/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 42111097389.5239 - val_loss: 54012435418.2661\n",
      "Epoch 2345/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 41706642221.3799 - val_loss: 53729965679.3294\n",
      "Epoch 2346/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 39904598569.2020 - val_loss: 55702110161.0487\n",
      "Epoch 2347/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 40834860810.2285 - val_loss: 53300454518.9626\n",
      "Epoch 2348/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 41041153640.0135 - val_loss: 52408088027.2743\n",
      "Epoch 2349/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 41822407798.1317 - val_loss: 54374518175.9370\n",
      "Epoch 2350/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 41388274338.2150 - val_loss: 52954144505.8790\n",
      "Epoch 2351/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 40402459459.5656 - val_loss: 51941360963.4745\n",
      "Epoch 2352/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 41114544488.7338 - val_loss: 51786576608.2430\n",
      "Epoch 2353/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 38857474941.1908 - val_loss: 53145462193.5077\n",
      "Epoch 2354/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 39902326726.3748 - val_loss: 52461877393.7508\n",
      "Epoch 2355/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 41582166595.7096 - val_loss: 51389400600.3398\n",
      "Epoch 2356/7000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 39062117335.0861 - val_loss: 52855171155.5331\n",
      "Epoch 2357/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 39965428359.3472 - val_loss: 56534596994.8444\n",
      "Epoch 2358/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 40225236935.5273 - val_loss: 51293600988.3544\n",
      "Epoch 2359/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 39629658070.5098 - val_loss: 52949557138.8309\n",
      "Epoch 2360/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 39819662084.1778 - val_loss: 55784718407.7232\n",
      "Epoch 2361/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 39184231190.6179 - val_loss: 59326618624.8641\n",
      "Epoch 2362/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 42669197841.2876 - val_loss: 52290950472.3713\n",
      "Epoch 2363/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 39678817074.2780 - val_loss: 54024698904.9159\n",
      "Epoch 2364/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 39545677447.9955 - val_loss: 61406503047.9572\n",
      "Epoch 2365/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 39936511121.7918 - val_loss: 50628394835.1730\n",
      "Epoch 2366/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 39353812926.3073 - val_loss: 50798071810.8804\n",
      "Epoch 2367/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 38415709821.9111 - val_loss: 51121365971.9291\n",
      "Epoch 2368/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 38232420013.1638 - val_loss: 57961612281.3750\n",
      "Epoch 2369/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 40354886378.8227 - val_loss: 51228227806.0827\n",
      "Epoch 2370/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 38406075172.4479 - val_loss: 50332369176.4118\n",
      "Epoch 2371/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 37265397648.2071 - val_loss: 53773846746.3381\n",
      "Epoch 2372/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 39029014348.2093 - val_loss: 49446767075.0515\n",
      "Epoch 2373/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 37721773703.1311 - val_loss: 58507146549.6484\n",
      "Epoch 2374/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 41568497034.7327 - val_loss: 51780779238.7241\n",
      "Epoch 2375/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 37500864180.0788 - val_loss: 58432567230.9018\n",
      "Epoch 2376/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 38026494366.9015 - val_loss: 54400820490.4416\n",
      "Epoch 2377/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 38352326148.9342 - val_loss: 51595197704.7134\n",
      "Epoch 2378/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 36635750098.0439 - val_loss: 54000051024.8686\n",
      "Epoch 2379/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 39533074458.5076 - val_loss: 48633942015.1359\n",
      "Epoch 2380/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 37379925263.4147 - val_loss: 72915990772.8383\n",
      "Epoch 2381/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 39357377990.6629 - val_loss: 48426991046.8231\n",
      "Epoch 2382/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 36622343080.9859 - val_loss: 65519999001.9240\n",
      "Epoch 2383/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 39279581012.2769 - val_loss: 55280716516.2757\n",
      "Epoch 2384/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 37808163460.2499 - val_loss: 49988557678.8253\n",
      "Epoch 2385/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 36813541666.4311 - val_loss: 49001230661.0588\n",
      "Epoch 2386/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 36176304507.1739 - val_loss: 51246140932.6087\n",
      "Epoch 2387/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 37430439650.1790 - val_loss: 49417397499.1752\n",
      "Epoch 2388/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 37903976488.3376 - val_loss: 55830044834.8895\n",
      "Epoch 2389/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 36611695055.4508 - val_loss: 53660318199.5027\n",
      "Epoch 2390/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 35958115450.7417 - val_loss: 48548249136.3916\n",
      "Epoch 2391/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 36494265196.4795 - val_loss: 50069396450.6194\n",
      "Epoch 2392/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 36307171444.4029 - val_loss: 49295668220.2554\n",
      "Epoch 2393/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 35613737676.8576 - val_loss: 48566474615.1786\n",
      "Epoch 2394/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 35426772718.8565 - val_loss: 49399058377.9916\n",
      "Epoch 2395/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 37171043780.3579 - val_loss: 52389517430.8186\n",
      "Epoch 2396/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 36329050367.8559 - val_loss: 50819734312.2543\n",
      "Epoch 2397/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 36912059260.0383 - val_loss: 49897693114.0051\n",
      "Epoch 2398/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 36153690783.9100 - val_loss: 49465960848.0945\n",
      "Epoch 2399/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 35567848925.7130 - val_loss: 48486558751.3969\n",
      "Epoch 2400/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 36162622986.0844 - val_loss: 48617418020.9418\n",
      "Epoch 2401/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 37077102341.3303 - val_loss: 51818447279.6354\n",
      "Epoch 2402/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 89us/step - loss: 36205148304.0630 - val_loss: 48139828519.8222\n",
      "Epoch 2403/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 36015832891.7862 - val_loss: 51830768329.3435\n",
      "Epoch 2404/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 35117150380.8756 - val_loss: 46840472656.9406\n",
      "Epoch 2405/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 36237352501.3033 - val_loss: 51691561477.3288\n",
      "Epoch 2406/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 35042716310.6899 - val_loss: 55731178914.5294\n",
      "Epoch 2407/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 35842189882.4896 - val_loss: 46892216726.7196\n",
      "Epoch 2408/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 35696419097.7873 - val_loss: 46350791054.9423\n",
      "Epoch 2409/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 36348343366.8790 - val_loss: 50247544758.2605\n",
      "Epoch 2410/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 35173612867.2774 - val_loss: 57416459373.2411\n",
      "Epoch 2411/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 35059055300.7901 - val_loss: 47248580719.7615\n",
      "Epoch 2412/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 34766498975.6218 - val_loss: 46566487918.8253\n",
      "Epoch 2413/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 35890270832.6573 - val_loss: 54589984317.6416\n",
      "Epoch 2414/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 37058460248.4547 - val_loss: 47545092232.2453\n",
      "Epoch 2415/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 35926824360.6978 - val_loss: 46566895968.8551\n",
      "Epoch 2416/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 34462831267.3675 - val_loss: 56996864909.0700\n",
      "Epoch 2417/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 35577844086.5639 - val_loss: 45631800782.8883\n",
      "Epoch 2418/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 34001636479.9280 - val_loss: 47456101447.1471\n",
      "Epoch 2419/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 33575344870.5008 - val_loss: 46466251259.5353\n",
      "Epoch 2420/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 33129240275.1964 - val_loss: 49686755440.6256\n",
      "Epoch 2421/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 34383840190.8835 - val_loss: 45347785774.6633\n",
      "Epoch 2422/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 34008008701.6950 - val_loss: 51015231085.7451\n",
      "Epoch 2423/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 34244486221.7940 - val_loss: 50367982483.1910\n",
      "Epoch 2424/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 33934975934.8835 - val_loss: 46755565661.9027\n",
      "Epoch 2425/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 32753590365.9291 - val_loss: 45078726103.8177\n",
      "Epoch 2426/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 35122485719.3742 - val_loss: 49386348067.5736\n",
      "Epoch 2427/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 34721166310.0687 - val_loss: 44356513706.4506\n",
      "Epoch 2428/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 34598158962.9623 - val_loss: 45799160551.3001\n",
      "Epoch 2429/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 33141519819.2729 - val_loss: 43406878362.1041\n",
      "Epoch 2430/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 33048055058.8723 - val_loss: 44097277137.6968\n",
      "Epoch 2431/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 34297513275.2099 - val_loss: 44813944815.5814\n",
      "Epoch 2432/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 33755051353.1750 - val_loss: 46317109588.4692\n",
      "Epoch 2433/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 33187707233.8188 - val_loss: 43536628297.4515\n",
      "Epoch 2434/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 32116546864.8374 - val_loss: 44179459845.9769\n",
      "Epoch 2435/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 32499669597.0647 - val_loss: 49152339487.6850\n",
      "Epoch 2436/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 33203869086.3253 - val_loss: 49795286595.1145\n",
      "Epoch 2437/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 32857505458.9263 - val_loss: 49122827340.0439\n",
      "Epoch 2438/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 33617103032.4007 - val_loss: 44049349887.9280\n",
      "Epoch 2439/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 32155226496.9364 - val_loss: 42739151823.0323\n",
      "Epoch 2440/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 32403452902.0687 - val_loss: 42920974446.4653\n",
      "Epoch 2441/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 32193933298.1699 - val_loss: 44580619556.0776\n",
      "Epoch 2442/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 35172003522.7732 - val_loss: 47180812102.1390\n",
      "Epoch 2443/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 31283534907.3540 - val_loss: 42872188466.5519\n",
      "Epoch 2444/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 31305115969.5487 - val_loss: 41616666152.7584\n",
      "Epoch 2445/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 31323608065.7288 - val_loss: 42485661393.9848\n",
      "Epoch 2446/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 31193436234.9128 - val_loss: 42164589879.9527\n",
      "Epoch 2447/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 30753057698.0709 - val_loss: 45266276914.8399\n",
      "Epoch 2448/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 31701962830.3703 - val_loss: 42678604350.3617\n",
      "Epoch 2449/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 29178351410.8542 - val_loss: 39645649159.2731\n",
      "Epoch 2450/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 30469317808.3331 - val_loss: 37688298033.1117\n",
      "Epoch 2451/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 28326703675.0658 - val_loss: 39808419618.9255\n",
      "Epoch 2452/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 28004767687.8154 - val_loss: 39212904919.2416\n",
      "Epoch 2453/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 26748794339.4755 - val_loss: 36901914376.1373\n",
      "Epoch 2454/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 26313282423.4282 - val_loss: 36792970503.6332\n",
      "Epoch 2455/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 26193639989.8796 - val_loss: 35975717438.9378\n",
      "Epoch 2456/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 26803259365.2043 - val_loss: 33836452621.6101\n",
      "Epoch 2457/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 24879866389.0332 - val_loss: 44872315119.0774\n",
      "Epoch 2458/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 25040122087.6534 - val_loss: 33534304761.4470\n",
      "Epoch 2459/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 23436324065.3146 - val_loss: 41018987846.2830\n",
      "Epoch 2460/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 24775309261.2898 - val_loss: 31956017252.0956\n",
      "Epoch 2461/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 23731003615.7299 - val_loss: 34885103967.4149\n",
      "Epoch 2462/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 23787871474.6021 - val_loss: 32334106333.6506\n",
      "Epoch 2463/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 22133562196.6010 - val_loss: 31014164327.7682\n",
      "Epoch 2464/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 22379209161.5442 - val_loss: 35317220820.6492\n",
      "Epoch 2465/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 22160529992.3196 - val_loss: 32424053241.2309\n",
      "Epoch 2466/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 83us/step - loss: 22548417195.4350 - val_loss: 32834213081.1859\n",
      "Epoch 2467/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 22735134607.0546 - val_loss: 37988604229.0588\n",
      "Epoch 2468/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 22064577059.4395 - val_loss: 32087896537.8340\n",
      "Epoch 2469/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 20495704943.0726 - val_loss: 29913783733.6124\n",
      "Epoch 2470/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 20767594778.3635 - val_loss: 29822814319.3744\n",
      "Epoch 2471/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 19877313592.0405 - val_loss: 30581260962.0253\n",
      "Epoch 2472/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 20102209605.1503 - val_loss: 29584457176.5378\n",
      "Epoch 2473/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 20356610735.1806 - val_loss: 29197806967.0436\n",
      "Epoch 2474/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 20306714636.6775 - val_loss: 28786551980.4669\n",
      "Epoch 2475/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 19507060622.9105 - val_loss: 28295267142.7150\n",
      "Epoch 2476/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 19302280503.7524 - val_loss: 32763022874.9322\n",
      "Epoch 2477/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 19112628557.0737 - val_loss: 27514189511.3271\n",
      "Epoch 2478/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 20193805030.7890 - val_loss: 29036660518.0219\n",
      "Epoch 2479/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 19415980930.0889 - val_loss: 28593633756.5705\n",
      "Epoch 2480/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 18995513233.3596 - val_loss: 28216609662.0917\n",
      "Epoch 2481/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 19848288226.0349 - val_loss: 29368190543.0684\n",
      "Epoch 2482/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 19311829307.7862 - val_loss: 27719962994.2819\n",
      "Epoch 2483/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 18887287594.2105 - val_loss: 26943241859.2765\n",
      "Epoch 2484/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 18590204090.7057 - val_loss: 34102740643.3935\n",
      "Epoch 2485/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 19249412238.9105 - val_loss: 33899797478.0805\n",
      "Epoch 2486/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 19321676951.5543 - val_loss: 25774801735.0031\n",
      "Epoch 2487/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 18787781107.0343 - val_loss: 26299516499.6771\n",
      "Epoch 2488/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 18106002612.0068 - val_loss: 26295151903.6129\n",
      "Epoch 2489/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 17522858951.3832 - val_loss: 26025424434.9660\n",
      "Epoch 2490/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 17060820455.5093 - val_loss: 26240017724.5525\n",
      "Epoch 2491/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 16568427545.0670 - val_loss: 25392505854.2717\n",
      "Epoch 2492/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 16641147561.4902 - val_loss: 24289739700.8203\n",
      "Epoch 2493/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 16112251254.2757 - val_loss: 25517499633.8858\n",
      "Epoch 2494/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 16301182123.1469 - val_loss: 27189505367.0616\n",
      "Epoch 2495/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 16667337780.4029 - val_loss: 32013636917.3603\n",
      "Epoch 2496/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 16308463749.6905 - val_loss: 30567856725.5494\n",
      "Epoch 2497/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 16871600711.1671 - val_loss: 33271118518.7646\n",
      "Epoch 2498/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 16907976467.7366 - val_loss: 23898522479.2934\n",
      "Epoch 2499/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 16115192146.8362 - val_loss: 30964473782.1885\n",
      "Epoch 2500/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 17248010076.3444 - val_loss: 26723097914.8332\n",
      "Epoch 2501/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 15320162405.9966 - val_loss: 32405969277.3716\n",
      "Epoch 2502/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 16027623434.3725 - val_loss: 24455583394.5654\n",
      "Epoch 2503/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 15101616517.5464 - val_loss: 21929410184.7314\n",
      "Epoch 2504/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 14570813983.4057 - val_loss: 23202219297.4132\n",
      "Epoch 2505/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 13739552320.8284 - val_loss: 22197355987.9291\n",
      "Epoch 2506/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 14687844426.7327 - val_loss: 23306111549.3536\n",
      "Epoch 2507/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 14068266892.7496 - val_loss: 21190343656.6684\n",
      "Epoch 2508/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 15102234297.8413 - val_loss: 21400430986.4056\n",
      "Epoch 2509/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 13405658039.3922 - val_loss: 20216643145.0914\n",
      "Epoch 2510/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 13701425827.9437 - val_loss: 21202435204.7527\n",
      "Epoch 2511/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 13073605047.6804 - val_loss: 31557636881.2107\n",
      "Epoch 2512/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 13612927110.8430 - val_loss: 20068300897.9353\n",
      "Epoch 2513/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 13302792042.1745 - val_loss: 20891289929.6675\n",
      "Epoch 2514/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 13409057061.8886 - val_loss: 19668500671.8380\n",
      "Epoch 2515/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 12349624827.1019 - val_loss: 18809872377.4920\n",
      "Epoch 2516/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 12293213455.4147 - val_loss: 19928348047.2034\n",
      "Epoch 2517/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 12829815623.0231 - val_loss: 24757041319.9662\n",
      "Epoch 2518/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 13429234612.5110 - val_loss: 19527407800.3488\n",
      "Epoch 2519/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 12337542872.3827 - val_loss: 18318145553.9488\n",
      "Epoch 2520/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 12098932382.7575 - val_loss: 19853950906.7972\n",
      "Epoch 2521/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 12157511411.4665 - val_loss: 18220358436.0776\n",
      "Epoch 2522/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 11735922106.7057 - val_loss: 17479660159.1539\n",
      "Epoch 2523/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 11451596854.7439 - val_loss: 17383525415.0661\n",
      "Epoch 2524/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 10757895814.0506 - val_loss: 17328178082.5834\n",
      "Epoch 2525/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 10507615297.4766 - val_loss: 16850660936.1553\n",
      "Epoch 2526/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 10625139446.9240 - val_loss: 16871726670.5103\n",
      "Epoch 2527/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 10665614339.0253 - val_loss: 16104096572.3634\n",
      "Epoch 2528/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 10333044345.4451 - val_loss: 16442990353.0667\n",
      "Epoch 2529/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 9826843061.9516 - val_loss: 16794588197.0858\n",
      "Epoch 2530/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 107us/step - loss: 11438511392.7023 - val_loss: 21825628815.6624\n",
      "Epoch 2531/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 9906924955.7321 - val_loss: 15795543715.0335\n",
      "Epoch 2532/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 9546645201.3236 - val_loss: 15942907847.9752\n",
      "Epoch 2533/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 9487627600.5312 - val_loss: 15660292851.8841\n",
      "Epoch 2534/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 9784067095.9145 - val_loss: 15260731267.8526\n",
      "Epoch 2535/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 9297994626.0889 - val_loss: 14911868353.4312\n",
      "Epoch 2536/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 9205385905.7738 - val_loss: 14876459646.2717\n",
      "Epoch 2537/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 8847173224.5898 - val_loss: 15402846419.6771\n",
      "Epoch 2538/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 8872337856.3241 - val_loss: 15507798298.5722\n",
      "Epoch 2539/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 8744073535.3157 - val_loss: 14600867177.7125\n",
      "Epoch 2540/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 9073558536.9319 - val_loss: 23887452758.5575\n",
      "Epoch 2541/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 9174739967.5678 - val_loss: 13684176119.5927\n",
      "Epoch 2542/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 8217483663.1806 - val_loss: 13949710037.7654\n",
      "Epoch 2543/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 8091498451.6286 - val_loss: 14210044889.8520\n",
      "Epoch 2544/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 8295138718.3253 - val_loss: 15464263363.6186\n",
      "Epoch 2545/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 8421948067.7997 - val_loss: 13779237792.6211\n",
      "Epoch 2546/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 8596927204.7721 - val_loss: 15115662689.7913\n",
      "Epoch 2547/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 8615065942.2938 - val_loss: 18742657327.4554\n",
      "Epoch 2548/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 9747369185.7468 - val_loss: 20783823114.1536\n",
      "Epoch 2549/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 8148195124.0068 - val_loss: 12750994019.4385\n",
      "Epoch 2550/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 7970562651.6241 - val_loss: 13312565488.0045\n",
      "Epoch 2551/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 8061576205.5779 - val_loss: 13296050234.6892\n",
      "Epoch 2552/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 7758411068.4344 - val_loss: 16460049302.2515\n",
      "Epoch 2553/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 7758928978.2600 - val_loss: 12890897162.8737\n",
      "Epoch 2554/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 7157824074.4806 - val_loss: 13139105455.6354\n",
      "Epoch 2555/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 7539730500.4299 - val_loss: 13277939520.8911\n",
      "Epoch 2556/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 7543814414.1182 - val_loss: 12495152292.0236\n",
      "Epoch 2557/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 7816941376.1080 - val_loss: 12480746953.0194\n",
      "Epoch 2558/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 7708449235.3405 - val_loss: 14404326378.6127\n",
      "Epoch 2559/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 6934503249.1075 - val_loss: 11787434096.4726\n",
      "Epoch 2560/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 7942712240.7653 - val_loss: 12025852169.4020\n",
      "Epoch 2561/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 6863504218.0394 - val_loss: 12095187167.5139\n",
      "Epoch 2562/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 7027061020.7406 - val_loss: 11545709389.7541\n",
      "Epoch 2563/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 6896590921.3281 - val_loss: 16324246253.8172\n",
      "Epoch 2564/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 7450180178.9803 - val_loss: 13862574164.2532\n",
      "Epoch 2565/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 6837155459.8177 - val_loss: 11411125015.2236\n",
      "Epoch 2566/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 6598386549.1232 - val_loss: 12652827939.6456\n",
      "Epoch 2567/7000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 7293519402.3545 - val_loss: 15785061950.5778\n",
      "Epoch 2568/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 7825272810.1745 - val_loss: 11138531547.9224\n",
      "Epoch 2569/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 6277691378.4311 - val_loss: 12614809490.2909\n",
      "Epoch 2570/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 6567863478.6719 - val_loss: 12594413867.7738\n",
      "Epoch 2571/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 6719614137.9223 - val_loss: 16532199681.2152\n",
      "Epoch 2572/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 7502289169.4316 - val_loss: 11121191303.4712\n",
      "Epoch 2573/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 6509993773.8120 - val_loss: 14772985400.7449\n",
      "Epoch 2574/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 7365667560.8059 - val_loss: 11078445345.1252\n",
      "Epoch 2575/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 6084972637.4249 - val_loss: 11897509926.1660\n",
      "Epoch 2576/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 6139693223.6353 - val_loss: 10274522093.5201\n",
      "Epoch 2577/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 6077955831.2122 - val_loss: 10619033288.5153\n",
      "Epoch 2578/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 7302674820.6820 - val_loss: 14893895840.2250\n",
      "Epoch 2579/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 6344853310.0461 - val_loss: 11144750710.7646\n",
      "Epoch 2580/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 6220360584.8239 - val_loss: 10224761545.5595\n",
      "Epoch 2581/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 5996604663.2122 - val_loss: 18196452719.8335\n",
      "Epoch 2582/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 7831600929.1345 - val_loss: 10263515465.8115\n",
      "Epoch 2583/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 5747557276.1283 - val_loss: 10026435378.0838\n",
      "Epoch 2584/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 6124834834.7282 - val_loss: 10723476082.0298\n",
      "Epoch 2585/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 6654876257.9629 - val_loss: 12940004813.4481\n",
      "Epoch 2586/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 6317269160.2656 - val_loss: 10388443456.8821\n",
      "Epoch 2587/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 6139097315.3315 - val_loss: 10619103473.3097\n",
      "Epoch 2588/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 5787299352.9949 - val_loss: 10723302330.4371\n",
      "Epoch 2589/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 5518978126.0822 - val_loss: 9945208422.4720\n",
      "Epoch 2590/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 5883375084.6956 - val_loss: 11523169581.9792\n",
      "Epoch 2591/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 5706544466.2600 - val_loss: 10029631757.3581\n",
      "Epoch 2592/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 5349974494.2893 - val_loss: 20586242345.2624\n",
      "Epoch 2593/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 8295947916.8936 - val_loss: 11513783658.3246\n",
      "Epoch 2594/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 75us/step - loss: 5622259497.6342 - val_loss: 24825089654.8186\n",
      "Epoch 2595/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 7994777427.4125 - val_loss: 9715578510.3662\n",
      "Epoch 2596/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 5258555642.6697 - val_loss: 9697916313.7440\n",
      "Epoch 2597/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 5077535913.8503 - val_loss: 10238071274.7387\n",
      "Epoch 2598/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 5354068373.6815 - val_loss: 13946941081.6720\n",
      "Epoch 2599/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 5949312574.8115 - val_loss: 9477282529.7553\n",
      "Epoch 2600/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 5663838303.6579 - val_loss: 10143002355.5060\n",
      "Epoch 2601/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 5749642806.0506 - val_loss: 11249660737.5302\n",
      "Epoch 2602/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 5136240672.3208 - val_loss: 10422327340.3589\n",
      "Epoch 2603/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 4946305717.8075 - val_loss: 11167221614.8253\n",
      "Epoch 2604/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 5712223182.5189 - val_loss: 9379042721.7553\n",
      "Epoch 2605/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 5597490526.9375 - val_loss: 9683819283.9831\n",
      "Epoch 2606/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 5411301262.6224 - val_loss: 9158286451.3620\n",
      "Epoch 2607/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 5569186400.5222 - val_loss: 11876314061.6641\n",
      "Epoch 2608/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 5786410564.6820 - val_loss: 9328866819.6186\n",
      "Epoch 2609/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 5466917115.5340 - val_loss: 9467256479.9010\n",
      "Epoch 2610/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 5194011897.2290 - val_loss: 9337705324.5210\n",
      "Epoch 2611/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 5714413537.7468 - val_loss: 9798733145.0059\n",
      "Epoch 2612/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 5065477514.1564 - val_loss: 14594031112.9294\n",
      "Epoch 2613/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 5923664116.7631 - val_loss: 9298706579.5511\n",
      "Epoch 2614/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 5374067168.1351 - val_loss: 10391380061.8667\n",
      "Epoch 2615/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 5015265943.5543 - val_loss: 10464037514.4056\n",
      "Epoch 2616/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 5327656539.7681 - val_loss: 9137299384.2048\n",
      "Epoch 2617/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 4919727180.3534 - val_loss: 12438795199.3339\n",
      "Epoch 2618/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 5142723807.0096 - val_loss: 9716069790.8928\n",
      "Epoch 2619/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 5278310023.4192 - val_loss: 8678837436.2374\n",
      "Epoch 2620/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 4784169567.6579 - val_loss: 8743616305.9038\n",
      "Epoch 2621/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 4992628467.7546 - val_loss: 13179070719.2079\n",
      "Epoch 2622/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 5446856727.6624 - val_loss: 9243142611.5331\n",
      "Epoch 2623/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 4772353775.4328 - val_loss: 10603406028.0799\n",
      "Epoch 2624/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 4965260625.5037 - val_loss: 9379189960.6954\n",
      "Epoch 2625/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4686241559.7704 - val_loss: 9011986294.7105\n",
      "Epoch 2626/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 4908761696.8104 - val_loss: 8755924798.9378\n",
      "Epoch 2627/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 4678820581.0602 - val_loss: 17025109601.2152\n",
      "Epoch 2628/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 7677218918.0326 - val_loss: 8614998038.0714\n",
      "Epoch 2629/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4652398025.6882 - val_loss: 8849810553.6270\n",
      "Epoch 2630/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4830410248.9319 - val_loss: 10278800596.9733\n",
      "Epoch 2631/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 4783791075.7636 - val_loss: 8792210688.0000\n",
      "Epoch 2632/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 4810354761.4721 - val_loss: 8278287215.1134\n",
      "Epoch 2633/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 4752410483.7546 - val_loss: 8472014961.5257\n",
      "Epoch 2634/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 4841258893.4069 - val_loss: 12593302054.7421\n",
      "Epoch 2635/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 4477658827.3450 - val_loss: 8995443369.4425\n",
      "Epoch 2636/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 4759530702.7304 - val_loss: 8824881354.2436\n",
      "Epoch 2637/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 5145035084.6505 - val_loss: 8285868757.0093\n",
      "Epoch 2638/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 4609897755.5160 - val_loss: 10884177995.1077\n",
      "Epoch 2639/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 4720256700.7946 - val_loss: 8455108641.2332\n",
      "Epoch 2640/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 4566668352.1080 - val_loss: 8865536302.9513\n",
      "Epoch 2641/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4552152792.0945 - val_loss: 8080792967.2371\n",
      "Epoch 2642/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 4348076427.5971 - val_loss: 8635378305.9803\n",
      "Epoch 2643/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 5340195170.0709 - val_loss: 9352587862.9896\n",
      "Epoch 2644/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 4270582578.5661 - val_loss: 9687566470.1570\n",
      "Epoch 2645/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4376343538.7462 - val_loss: 16470217561.0779\n",
      "Epoch 2646/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 6343408108.7316 - val_loss: 8335210064.2565\n",
      "Epoch 2647/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 4251678193.0895 - val_loss: 8208604016.3376\n",
      "Epoch 2648/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 4534521735.8514 - val_loss: 8230808433.4177\n",
      "Epoch 2649/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 4168415836.0563 - val_loss: 9118280615.1381\n",
      "Epoch 2650/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 4516940574.1092 - val_loss: 10351111504.8686\n",
      "Epoch 2651/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 5021632237.7040 - val_loss: 8168759219.6681\n",
      "Epoch 2652/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 4339748498.9623 - val_loss: 9525389911.0076\n",
      "Epoch 2653/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 4191139942.7530 - val_loss: 9130456375.7547\n",
      "Epoch 2654/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 4295104774.7710 - val_loss: 8844576686.1232\n",
      "Epoch 2655/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 4598834407.0771 - val_loss: 8327610640.5626\n",
      "Epoch 2656/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4594615301.1863 - val_loss: 14235319776.7471\n",
      "Epoch 2657/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 5144480546.1429 - val_loss: 8005385688.7539\n",
      "Epoch 2658/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 4288965874.6021 - val_loss: 11017321457.3097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2659/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 5558267799.4102 - val_loss: 8364175039.0459\n",
      "Epoch 2660/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 4446529147.7501 - val_loss: 8252658903.8177\n",
      "Epoch 2661/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 4307627847.3112 - val_loss: 8681813375.4599\n",
      "Epoch 2662/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 4510264409.8953 - val_loss: 9415551725.2051\n",
      "Epoch 2663/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 4402620647.0051 - val_loss: 7949858206.8568\n",
      "Epoch 2664/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 4034754438.8070 - val_loss: 8645459433.4965\n",
      "Epoch 2665/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 4262603102.6494 - val_loss: 8345771215.2484\n",
      "Epoch 2666/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 4074903549.1548 - val_loss: 7964923415.5117\n",
      "Epoch 2667/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 3998323985.9358 - val_loss: 7812128144.4186\n",
      "Epoch 2668/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 4063488181.9786 - val_loss: 8277196222.2537\n",
      "Epoch 2669/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3971696466.5481 - val_loss: 8571203242.3066\n",
      "Epoch 2670/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 4742377358.1182 - val_loss: 8048702115.7896\n",
      "Epoch 2671/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4686400584.8959 - val_loss: 9724328934.5080\n",
      "Epoch 2672/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 4570823523.2594 - val_loss: 8446521331.7221\n",
      "Epoch 2673/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 4035692189.0287 - val_loss: 7608985048.1058\n",
      "Epoch 2674/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 4006789896.6438 - val_loss: 8142031890.7589\n",
      "Epoch 2675/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3873674116.6820 - val_loss: 8111196355.9426\n",
      "Epoch 2676/7000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 4140242471.1851 - val_loss: 8095718374.4000\n",
      "Epoch 2677/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4955690015.6939 - val_loss: 7461465270.1165\n",
      "Epoch 2678/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 4124381989.0962 - val_loss: 8456073382.6340\n",
      "Epoch 2679/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 4196346497.9944 - val_loss: 7512777151.9820\n",
      "Epoch 2680/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3683501714.0799 - val_loss: 11108640516.5367\n",
      "Epoch 2681/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 4678386045.1908 - val_loss: 7436212555.0717\n",
      "Epoch 2682/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 3864727079.7614 - val_loss: 8919746568.3893\n",
      "Epoch 2683/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 3826369376.3421 - val_loss: 7475492967.4082\n",
      "Epoch 2684/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 3816736862.7214 - val_loss: 7882315094.9176\n",
      "Epoch 2685/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3882858711.5183 - val_loss: 7194431901.9567\n",
      "Epoch 2686/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 3855142094.8205 - val_loss: 7876419021.1601\n",
      "Epoch 2687/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 4249408641.9449 - val_loss: 8304585771.8549\n",
      "Epoch 2688/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 3830736893.9831 - val_loss: 8210890285.7271\n",
      "Epoch 2689/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 3563624082.9465 - val_loss: 7621020118.9896\n",
      "Epoch 2690/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3579402162.0439 - val_loss: 7410731556.4377\n",
      "Epoch 2691/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 3831862997.5014 - val_loss: 7708678236.6065\n",
      "Epoch 2692/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 4301233004.9116 - val_loss: 8550569862.4810\n",
      "Epoch 2693/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 4062514343.1131 - val_loss: 7602862132.4242\n",
      "Epoch 2694/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3876736123.8942 - val_loss: 7684273284.0686\n",
      "Epoch 2695/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 4557352140.6415 - val_loss: 7314238962.6419\n",
      "Epoch 2696/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3621675477.5014 - val_loss: 8365679332.9238\n",
      "Epoch 2697/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3992154302.7394 - val_loss: 9543677575.0931\n",
      "Epoch 2698/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 4434395943.5453 - val_loss: 7823908718.4653\n",
      "Epoch 2699/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3509755245.3799 - val_loss: 8313775277.9072\n",
      "Epoch 2700/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 3700117519.5588 - val_loss: 7637094010.1311\n",
      "Epoch 2701/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 3855387227.7681 - val_loss: 8304633536.5581\n",
      "Epoch 2702/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 3966948819.6286 - val_loss: 9105155909.2028\n",
      "Epoch 2703/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 3903218162.8903 - val_loss: 10684495279.1314\n",
      "Epoch 2704/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3924164026.9938 - val_loss: 6926450360.1328\n",
      "Epoch 2705/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3415834514.3680 - val_loss: 6887290646.3955\n",
      "Epoch 2706/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 3610433695.1176 - val_loss: 7500686323.6861\n",
      "Epoch 2707/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 3681146203.6961 - val_loss: 7188387965.5876\n",
      "Epoch 2708/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 3920343028.9792 - val_loss: 7029383892.1451\n",
      "Epoch 2709/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3673653929.8143 - val_loss: 7107732481.4042\n",
      "Epoch 2710/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 3846256096.4502 - val_loss: 7909577788.9935\n",
      "Epoch 2711/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 4241157146.7237 - val_loss: 7377914670.0152\n",
      "Epoch 2712/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3803171357.4609 - val_loss: 7024506348.6290\n",
      "Epoch 2713/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3606520884.7991 - val_loss: 7956838896.0495\n",
      "Epoch 2714/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3526210575.2707 - val_loss: 10178799478.6025\n",
      "Epoch 2715/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 3637361170.8723 - val_loss: 7707033202.4619\n",
      "Epoch 2716/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3285067741.4249 - val_loss: 7612729184.9992\n",
      "Epoch 2717/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3507285941.9516 - val_loss: 8047320690.6059\n",
      "Epoch 2718/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3685448341.8255 - val_loss: 8318795265.0082\n",
      "Epoch 2719/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3577695132.3084 - val_loss: 9223204045.9522\n",
      "Epoch 2720/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3690616064.6483 - val_loss: 7113875356.3364\n",
      "Epoch 2721/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3718631725.2718 - val_loss: 7599207869.6776\n",
      "Epoch 2722/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3203264355.9797 - val_loss: 6705875290.6262\n",
      "Epoch 2723/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3768801169.6027 - val_loss: 6880627852.3499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2724/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 3369449509.0242 - val_loss: 7435990082.2504\n",
      "Epoch 2725/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3333758506.4986 - val_loss: 6957755008.9001\n",
      "Epoch 2726/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3774045307.3180 - val_loss: 7902910694.0039\n",
      "Epoch 2727/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3905512131.2054 - val_loss: 6679473263.5094\n",
      "Epoch 2728/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3359019080.3196 - val_loss: 6819082097.9218\n",
      "Epoch 2729/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3336895253.4654 - val_loss: 17338663132.9305\n",
      "Epoch 2730/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 5443975760.0990 - val_loss: 7114642172.2554\n",
      "Epoch 2731/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3445276315.8762 - val_loss: 7196702769.9758\n",
      "Epoch 2732/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3443991192.7428 - val_loss: 8055202860.2869\n",
      "Epoch 2733/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 3180326958.3883 - val_loss: 8634346586.1581\n",
      "Epoch 2734/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3584146011.9122 - val_loss: 9576160525.3221\n",
      "Epoch 2735/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3794639024.4232 - val_loss: 6437777821.8847\n",
      "Epoch 2736/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3137521371.8402 - val_loss: 8514567299.0605\n",
      "Epoch 2737/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3113740567.9145 - val_loss: 6836750620.0844\n",
      "Epoch 2738/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3424886889.0219 - val_loss: 7179806744.9519\n",
      "Epoch 2739/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3377995576.0405 - val_loss: 6622669638.1390\n",
      "Epoch 2740/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3055471939.2774 - val_loss: 7685523870.4968\n",
      "Epoch 2741/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3061524282.0574 - val_loss: 6612924010.6847\n",
      "Epoch 2742/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 3313815308.1013 - val_loss: 6599894334.9378\n",
      "Epoch 2743/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3096575676.5785 - val_loss: 8562700442.8962\n",
      "Epoch 2744/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3284326229.0332 - val_loss: 6578912165.1938\n",
      "Epoch 2745/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3043058508.7136 - val_loss: 6936727144.7044\n",
      "Epoch 2746/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 3587965255.3112 - val_loss: 6678136345.4920\n",
      "Epoch 2747/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 4168668288.7923 - val_loss: 6798051193.2669\n",
      "Epoch 2748/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3207585946.8678 - val_loss: 6915046695.3181\n",
      "Epoch 2749/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3131903250.4401 - val_loss: 6730557765.4549\n",
      "Epoch 2750/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3276696918.8700 - val_loss: 8059405725.0565\n",
      "Epoch 2751/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3564832790.7620 - val_loss: 6756686692.7797\n",
      "Epoch 2752/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2965947071.0276 - val_loss: 8578274003.2810\n",
      "Epoch 2753/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4415647664.0450 - val_loss: 6320606566.1120\n",
      "Epoch 2754/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2811956306.4041 - val_loss: 10050847866.7792\n",
      "Epoch 2755/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3633807435.5611 - val_loss: 9556866998.3325\n",
      "Epoch 2756/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3114247622.5189 - val_loss: 8438706533.2478\n",
      "Epoch 2757/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3192954290.0619 - val_loss: 6244599245.0160\n",
      "Epoch 2758/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2993110034.4041 - val_loss: 7218354999.0886\n",
      "Epoch 2759/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3077357236.0788 - val_loss: 6439334249.7125\n",
      "Epoch 2760/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2986272457.2200 - val_loss: 7486275100.0484\n",
      "Epoch 2761/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2943483386.2375 - val_loss: 11099166979.9606\n",
      "Epoch 2762/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2992193599.5318 - val_loss: 6432397601.5212\n",
      "Epoch 2763/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3002736739.6916 - val_loss: 8241110111.7750\n",
      "Epoch 2764/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 3747465965.4159 - val_loss: 6541615201.9173\n",
      "Epoch 2765/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 3229101087.1176 - val_loss: 14593332195.1955\n",
      "Epoch 2766/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3444609129.8143 - val_loss: 6513192170.6847\n",
      "Epoch 2767/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 3576914517.2853 - val_loss: 6489588181.0453\n",
      "Epoch 2768/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2742509009.1795 - val_loss: 6748878244.7617\n",
      "Epoch 2769/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2950703597.8481 - val_loss: 6069404344.4568\n",
      "Epoch 2770/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3560901548.4434 - val_loss: 8446191719.6242\n",
      "Epoch 2771/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3027159749.7265 - val_loss: 6038469234.3179\n",
      "Epoch 2772/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2856171236.4840 - val_loss: 6838862425.8880\n",
      "Epoch 2773/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3320583618.6291 - val_loss: 8774871476.7482\n",
      "Epoch 2774/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3070622538.8407 - val_loss: 6704706192.4546\n",
      "Epoch 2775/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2717562764.7496 - val_loss: 6190382631.5702\n",
      "Epoch 2776/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3229805177.9358 - val_loss: 6648378108.2554\n",
      "Epoch 2777/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3166273663.3517 - val_loss: 8313265784.4028\n",
      "Epoch 2778/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 3443627098.7597 - val_loss: 6365651947.9089\n",
      "Epoch 2779/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 3220202055.2392 - val_loss: 6293368498.7679\n",
      "Epoch 2780/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3102360876.4795 - val_loss: 6248630949.0498\n",
      "Epoch 2781/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 2955854071.5723 - val_loss: 6020448487.0121\n",
      "Epoch 2782/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2946337884.4885 - val_loss: 7271330403.3395\n",
      "Epoch 2783/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2885927265.9629 - val_loss: 6133392142.1862\n",
      "Epoch 2784/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2985312692.7462 - val_loss: 6409663625.9015\n",
      "Epoch 2785/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 3049723343.0186 - val_loss: 6425270282.5136\n",
      "Epoch 2786/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 3024072954.6697 - val_loss: 8916644571.4903\n",
      "Epoch 2787/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 2980108712.4817 - val_loss: 6425558368.0270\n",
      "Epoch 2788/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3732975568.5312 - val_loss: 7474625157.1488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2789/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 3104329432.9589 - val_loss: 6746116633.0239\n",
      "Epoch 2790/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2695759387.0118 - val_loss: 6489833992.1373\n",
      "Epoch 2791/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2497503814.5909 - val_loss: 11090268476.8495\n",
      "Epoch 2792/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 3108787130.5616 - val_loss: 5843718225.3007\n",
      "Epoch 2793/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 3228459901.1908 - val_loss: 6520269956.3927\n",
      "Epoch 2794/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2723424768.2881 - val_loss: 8150153239.7637\n",
      "Epoch 2795/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3015222997.6455 - val_loss: 6204119312.4906\n",
      "Epoch 2796/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 3013756980.1508 - val_loss: 5883241848.5828\n",
      "Epoch 2797/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2682853769.5802 - val_loss: 5980890657.0892\n",
      "Epoch 2798/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 2535001110.1857 - val_loss: 6253211630.0332\n",
      "Epoch 2799/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2597122394.9038 - val_loss: 5738755879.9482\n",
      "Epoch 2800/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2719384786.4761 - val_loss: 6561733974.4855\n",
      "Epoch 2801/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 2511214199.5723 - val_loss: 6015163025.6068\n",
      "Epoch 2802/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3001053074.5121 - val_loss: 7852839159.9707\n",
      "Epoch 2803/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 5278991830.7980 - val_loss: 6048178326.0714\n",
      "Epoch 2804/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3225378701.7580 - val_loss: 6035580690.8309\n",
      "Epoch 2805/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2821466442.1925 - val_loss: 7394682977.6473\n",
      "Epoch 2806/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2845793510.5008 - val_loss: 6262789397.3153\n",
      "Epoch 2807/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2530924814.8385 - val_loss: 9884857225.7575\n",
      "Epoch 2808/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3115192319.1356 - val_loss: 5764680763.5893\n",
      "Epoch 2809/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2445421555.0163 - val_loss: 7614276473.1229\n",
      "Epoch 2810/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2991600474.2555 - val_loss: 7697349255.2371\n",
      "Epoch 2811/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2796043773.6950 - val_loss: 6231362036.2622\n",
      "Epoch 2812/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2673669280.6663 - val_loss: 6851223007.3789\n",
      "Epoch 2813/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 2543766075.7862 - val_loss: 5839028636.6245\n",
      "Epoch 2814/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 2821239292.3264 - val_loss: 7702989406.0827\n",
      "Epoch 2815/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 2760091938.0349 - val_loss: 6077988718.6093\n",
      "Epoch 2816/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2632269686.8970 - val_loss: 6825057394.2819\n",
      "Epoch 2817/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2721411008.8284 - val_loss: 6035659384.2588\n",
      "Epoch 2818/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2768618325.1412 - val_loss: 7963294582.9626\n",
      "Epoch 2819/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2912651792.4232 - val_loss: 6040838492.7505\n",
      "Epoch 2820/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2631608590.4063 - val_loss: 7514866221.2951\n",
      "Epoch 2821/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2655211119.1446 - val_loss: 6226618901.6394\n",
      "Epoch 2822/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2638391034.6697 - val_loss: 8444946030.8973\n",
      "Epoch 2823/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 3048895845.1322 - val_loss: 6644362204.0664\n",
      "Epoch 2824/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2884258375.3112 - val_loss: 5966018849.4132\n",
      "Epoch 2825/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2432235811.6196 - val_loss: 5672698104.3308\n",
      "Epoch 2826/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2362728108.1553 - val_loss: 7663717303.4127\n",
      "Epoch 2827/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2644490416.2611 - val_loss: 6507228246.3415\n",
      "Epoch 2828/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2573447212.0833 - val_loss: 6856536143.0684\n",
      "Epoch 2829/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3021866145.3506 - val_loss: 7744355850.9817\n",
      "Epoch 2830/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2827913215.9280 - val_loss: 5919827801.7260\n",
      "Epoch 2831/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2649756748.2814 - val_loss: 8166973877.7564\n",
      "Epoch 2832/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2775776350.9375 - val_loss: 6041572996.2127\n",
      "Epoch 2833/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2726664616.1216 - val_loss: 6218643119.7075\n",
      "Epoch 2834/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2462555276.0293 - val_loss: 6289461203.6771\n",
      "Epoch 2835/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3004853168.9094 - val_loss: 8008586909.8487\n",
      "Epoch 2836/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2570617559.2302 - val_loss: 7790048686.9153\n",
      "Epoch 2837/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 3024831095.5723 - val_loss: 6403242941.2096\n",
      "Epoch 2838/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2562774579.3945 - val_loss: 7311802794.0906\n",
      "Epoch 2839/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2649702791.1491 - val_loss: 6535999697.4087\n",
      "Epoch 2840/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2359107703.9325 - val_loss: 5688770491.0852\n",
      "Epoch 2841/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2565863827.8537 - val_loss: 7075519000.4118\n",
      "Epoch 2842/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2597424102.5008 - val_loss: 7589965166.3932\n",
      "Epoch 2843/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 2864041365.1052 - val_loss: 9336706942.7398\n",
      "Epoch 2844/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3314423858.6382 - val_loss: 6086097968.8956\n",
      "Epoch 2845/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2670580524.5155 - val_loss: 5638654791.0391\n",
      "Epoch 2846/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2618385225.5442 - val_loss: 5751262491.4363\n",
      "Epoch 2847/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2462029444.4299 - val_loss: 5805090477.2591\n",
      "Epoch 2848/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2267090963.4125 - val_loss: 5450998649.3030\n",
      "Epoch 2849/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2547307384.0045 - val_loss: 8263964453.8059\n",
      "Epoch 2850/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3400312867.4395 - val_loss: 5609231060.0011\n",
      "Epoch 2851/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2311596934.0146 - val_loss: 6119401521.7958\n",
      "Epoch 2852/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2466936818.7462 - val_loss: 6314241167.3744\n",
      "Epoch 2853/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2564494030.5864 - val_loss: 10621138795.3688\n",
      "Epoch 2854/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 74us/step - loss: 3395890324.8171 - val_loss: 5544492080.9677\n",
      "Epoch 2855/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2415625489.7198 - val_loss: 9435015813.8689\n",
      "Epoch 2856/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2467841088.5402 - val_loss: 5574497341.3176\n",
      "Epoch 2857/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2366646276.6100 - val_loss: 7125915709.0655\n",
      "Epoch 2858/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2358865321.8503 - val_loss: 6113619713.2962\n",
      "Epoch 2859/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2302077996.3714 - val_loss: 6281194451.7851\n",
      "Epoch 2860/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2861682175.4237 - val_loss: 5681306761.5415\n",
      "Epoch 2861/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2388495182.5143 - val_loss: 11262488289.9713\n",
      "Epoch 2862/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 3480750309.2043 - val_loss: 6702700653.6011\n",
      "Epoch 2863/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2603933732.8801 - val_loss: 9733798862.7443\n",
      "Epoch 2864/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3009669826.4851 - val_loss: 5732609088.5221\n",
      "Epoch 2865/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2296790602.0214 - val_loss: 5663261961.1094\n",
      "Epoch 2866/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2269140433.5397 - val_loss: 6159510637.6011\n",
      "Epoch 2867/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2264968114.2060 - val_loss: 5673708437.8554\n",
      "Epoch 2868/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2621010007.2302 - val_loss: 6185556529.9758\n",
      "Epoch 2869/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2310594312.7878 - val_loss: 6109944916.6852\n",
      "Epoch 2870/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2496601893.7445 - val_loss: 5489197762.8624\n",
      "Epoch 2871/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2321947992.5627 - val_loss: 7226550068.2082\n",
      "Epoch 2872/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2836650684.7226 - val_loss: 5983442196.3972\n",
      "Epoch 2873/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2320824311.3562 - val_loss: 6286436563.7851\n",
      "Epoch 2874/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2806196594.3500 - val_loss: 6887820561.1027\n",
      "Epoch 2875/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2789293888.9004 - val_loss: 5862304780.3859\n",
      "Epoch 2876/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2295147529.9674 - val_loss: 5766024116.8022\n",
      "Epoch 2877/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2377262623.0816 - val_loss: 6301363311.6895\n",
      "Epoch 2878/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2090948558.0101 - val_loss: 5652961756.0304\n",
      "Epoch 2879/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2438831911.3742 - val_loss: 8614561371.1662\n",
      "Epoch 2880/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2459103174.6629 - val_loss: 7442445659.8143\n",
      "Epoch 2881/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2387868351.6759 - val_loss: 6347180210.5879\n",
      "Epoch 2882/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2339198422.1497 - val_loss: 5938908122.0861\n",
      "Epoch 2883/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2264165202.1159 - val_loss: 6455225946.3021\n",
      "Epoch 2884/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2533506289.8098 - val_loss: 8853446484.7572\n",
      "Epoch 2885/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3110972402.3140 - val_loss: 5513865713.8498\n",
      "Epoch 2886/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2295798222.2983 - val_loss: 5627423772.9485\n",
      "Epoch 2887/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2428858576.8194 - val_loss: 7703792481.1432\n",
      "Epoch 2888/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2284808407.3922 - val_loss: 6408103136.0990\n",
      "Epoch 2889/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2285643058.5661 - val_loss: 5491949237.3243\n",
      "Epoch 2890/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2418802668.1193 - val_loss: 5353358482.3629\n",
      "Epoch 2891/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 2398592965.0062 - val_loss: 5468112593.6968\n",
      "Epoch 2892/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2264264612.1238 - val_loss: 9139446376.4163\n",
      "Epoch 2893/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 2282838658.2330 - val_loss: 6536529684.5952\n",
      "Epoch 2894/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 3008686580.1868 - val_loss: 5273786087.5882\n",
      "Epoch 2895/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 2069650951.7794 - val_loss: 8415573469.5426\n",
      "Epoch 2896/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2738043068.1103 - val_loss: 5200299876.8158\n",
      "Epoch 2897/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2162754787.1199 - val_loss: 5374841942.9176\n",
      "Epoch 2898/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2009963042.7912 - val_loss: 5199105831.0661\n",
      "Epoch 2899/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2132535994.5166 - val_loss: 5626562107.3373\n",
      "Epoch 2900/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2354832847.9550 - val_loss: 5443044514.8174\n",
      "Epoch 2901/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2134644728.3647 - val_loss: 5563847006.2267\n",
      "Epoch 2902/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2620500539.7141 - val_loss: 5782072274.2008\n",
      "Epoch 2903/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2308591482.8858 - val_loss: 5802844376.2498\n",
      "Epoch 2904/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2367468200.2656 - val_loss: 5419682962.4709\n",
      "Epoch 2905/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2127691091.0613 - val_loss: 5438645036.2869\n",
      "Epoch 2906/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2298230637.8120 - val_loss: 5747541889.2962\n",
      "Epoch 2907/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2181909956.3219 - val_loss: 5427317003.3598\n",
      "Epoch 2908/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2156846303.6579 - val_loss: 5541925323.2878\n",
      "Epoch 2909/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2175246756.0878 - val_loss: 7820482265.7620\n",
      "Epoch 2910/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2095168534.9420 - val_loss: 5170245984.1710\n",
      "Epoch 2911/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1939894505.6342 - val_loss: 5460207622.8771\n",
      "Epoch 2912/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2034466955.5971 - val_loss: 5222292504.4118\n",
      "Epoch 2913/7000\n",
      "3554/3554 [==============================] - 0s 68us/step - loss: 2094085732.8441 - val_loss: 8936314550.2605\n",
      "Epoch 2914/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2843553887.7974 - val_loss: 5288241075.0200\n",
      "Epoch 2915/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1976643239.3292 - val_loss: 5182331028.9553\n",
      "Epoch 2916/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1951318010.9398 - val_loss: 5822008634.8692\n",
      "Epoch 2917/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 2707893683.6466 - val_loss: 5625227127.1786\n",
      "Epoch 2918/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2198949363.0501 - val_loss: 5531738777.7080\n",
      "Epoch 2919/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 83us/step - loss: 1927899903.9280 - val_loss: 5145619517.3536\n",
      "Epoch 2920/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2295901650.9083 - val_loss: 5253602325.6034\n",
      "Epoch 2921/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2574422984.6798 - val_loss: 7166907653.8329\n",
      "Epoch 2922/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 2761978116.3219 - val_loss: 5123694899.5601\n",
      "Epoch 2923/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2146708969.8863 - val_loss: 5530868983.8627\n",
      "Epoch 2924/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 2436173020.9567 - val_loss: 5174742223.2124\n",
      "Epoch 2925/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2027135194.6742 - val_loss: 5871513536.1980\n",
      "Epoch 2926/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2150168637.7760 - val_loss: 6883843368.1823\n",
      "Epoch 2927/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 2008052636.0203 - val_loss: 5225410563.2405\n",
      "Epoch 2928/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2465378287.0726 - val_loss: 6861546283.9269\n",
      "Epoch 2929/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2090357255.5093 - val_loss: 6288606564.3117\n",
      "Epoch 2930/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2383641710.3523 - val_loss: 6451107335.6332\n",
      "Epoch 2931/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2150673907.6466 - val_loss: 5134045050.0591\n",
      "Epoch 2932/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1944216336.4232 - val_loss: 6616203968.2700\n",
      "Epoch 2933/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2806258604.4434 - val_loss: 6360853201.7688\n",
      "Epoch 2934/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2711528820.2589 - val_loss: 6123814735.7165\n",
      "Epoch 2935/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2380690432.3962 - val_loss: 5417464216.8439\n",
      "Epoch 2936/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2029403579.9122 - val_loss: 5282214670.2942\n",
      "Epoch 2937/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1968158039.7299 - val_loss: 5171694515.3080\n",
      "Epoch 2938/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1879408436.0788 - val_loss: 5049416496.4636\n",
      "Epoch 2939/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2057076659.9347 - val_loss: 5839666480.1395\n",
      "Epoch 2940/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2591011373.0377 - val_loss: 5078678968.5648\n",
      "Epoch 2941/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1894649411.4935 - val_loss: 5323266581.6754\n",
      "Epoch 2942/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1978111681.1885 - val_loss: 5459092580.1316\n",
      "Epoch 2943/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2233090219.1469 - val_loss: 6062063345.9938\n",
      "Epoch 2944/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 2380130204.0203 - val_loss: 5853920443.5533\n",
      "Epoch 2945/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 2010568044.3894 - val_loss: 4952741567.9100\n",
      "Epoch 2946/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1911084014.3523 - val_loss: 5094848189.3176\n",
      "Epoch 2947/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 2640687486.4873 - val_loss: 6469575822.8703\n",
      "Epoch 2948/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 2137687062.1857 - val_loss: 7150509478.9221\n",
      "Epoch 2949/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2308694267.5340 - val_loss: 4944532438.2695\n",
      "Epoch 2950/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2276764783.2887 - val_loss: 6103140974.3932\n",
      "Epoch 2951/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1945404602.4176 - val_loss: 6869954448.0945\n",
      "Epoch 2952/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2392100084.4750 - val_loss: 8982141706.7297\n",
      "Epoch 2953/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2417553952.5582 - val_loss: 6485611960.2768\n",
      "Epoch 2954/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2219560911.2527 - val_loss: 5691475236.0776\n",
      "Epoch 2955/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2253639941.7625 - val_loss: 5367944890.5451\n",
      "Epoch 2956/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1891247230.3793 - val_loss: 5195781520.9586\n",
      "Epoch 2957/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2001123955.0703 - val_loss: 5492141185.6923\n",
      "Epoch 2958/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2160195250.2240 - val_loss: 5574537560.1418\n",
      "Epoch 2959/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1886306350.6764 - val_loss: 6048888668.6785\n",
      "Epoch 2960/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 2166901618.6742 - val_loss: 5237212230.4270\n",
      "Epoch 2961/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2139988409.9854 - val_loss: 5535493255.4532\n",
      "Epoch 2962/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2025112754.2780 - val_loss: 7995195016.5333\n",
      "Epoch 2963/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2277408075.0028 - val_loss: 4878821326.4563\n",
      "Epoch 2964/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1830075436.7046 - val_loss: 4889437791.8830\n",
      "Epoch 2965/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1941975957.3934 - val_loss: 5030246828.6470\n",
      "Epoch 2966/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2094267004.6145 - val_loss: 4997654926.9063\n",
      "Epoch 2967/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1885574585.8953 - val_loss: 5402714033.6518\n",
      "Epoch 2968/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2064201404.7226 - val_loss: 5972115846.0489\n",
      "Epoch 2969/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2176281891.8717 - val_loss: 5256411059.0200\n",
      "Epoch 2970/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2187558744.5988 - val_loss: 5828669413.8599\n",
      "Epoch 2971/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2299577607.7434 - val_loss: 5014461715.3710\n",
      "Epoch 2972/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1849569980.9387 - val_loss: 4864315261.8037\n",
      "Epoch 2973/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1988833186.1429 - val_loss: 4965604550.4270\n",
      "Epoch 2974/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1962693626.9578 - val_loss: 5347082705.3007\n",
      "Epoch 2975/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2436192130.3860 - val_loss: 5343324689.1387\n",
      "Epoch 2976/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1899683762.6382 - val_loss: 6927857744.5806\n",
      "Epoch 2977/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2222660016.3331 - val_loss: 5261336957.2276\n",
      "Epoch 2978/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1999994963.4125 - val_loss: 8040390145.4402\n",
      "Epoch 2979/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2118349352.6258 - val_loss: 5412733916.2824\n",
      "Epoch 2980/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1909587890.9263 - val_loss: 4823394247.6152\n",
      "Epoch 2981/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2142561101.6500 - val_loss: 14038196996.8248\n",
      "Epoch 2982/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2374117301.5824 - val_loss: 4867064194.5564\n",
      "Epoch 2983/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1802235443.6466 - val_loss: 5817022589.1556\n",
      "Epoch 2984/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 71us/step - loss: 1767732417.1165 - val_loss: 5979669083.8864\n",
      "Epoch 2985/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1868337194.0664 - val_loss: 5596214497.2872\n",
      "Epoch 2986/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1981439517.1548 - val_loss: 5620092484.8428\n",
      "Epoch 2987/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2143188627.0163 - val_loss: 5178302000.5716\n",
      "Epoch 2988/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1986442689.1885 - val_loss: 5296098900.3252\n",
      "Epoch 2989/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2289157139.0163 - val_loss: 4933032048.1215\n",
      "Epoch 2990/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2047064593.2876 - val_loss: 6054696615.1381\n",
      "Epoch 2991/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2031414005.8075 - val_loss: 5171950007.1966\n",
      "Epoch 2992/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2312367205.1322 - val_loss: 5569212636.2824\n",
      "Epoch 2993/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2116441741.7940 - val_loss: 4987382759.6602\n",
      "Epoch 2994/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1940221039.0726 - val_loss: 4909042938.9232\n",
      "Epoch 2995/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1999760785.3596 - val_loss: 5442253817.6630\n",
      "Epoch 2996/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1751437587.0163 - val_loss: 6111757032.4523\n",
      "Epoch 2997/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2082249092.7541 - val_loss: 5388731195.4813\n",
      "Epoch 2998/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2014560641.5487 - val_loss: 5058980444.0484\n",
      "Epoch 2999/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1843224085.3934 - val_loss: 5259195676.8405\n",
      "Epoch 3000/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1978362105.8053 - val_loss: 9484448412.2644\n",
      "Epoch 3001/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2402533332.0608 - val_loss: 4744666884.7527\n",
      "Epoch 3002/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1886812978.8542 - val_loss: 5916790809.7800\n",
      "Epoch 3003/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1682598115.4845 - val_loss: 5022611795.4610\n",
      "Epoch 3004/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 2169745679.5588 - val_loss: 6273278048.1710\n",
      "Epoch 3005/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2165416911.0186 - val_loss: 8469101892.5547\n",
      "Epoch 3006/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2549082851.1874 - val_loss: 4894617133.3671\n",
      "Epoch 3007/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1713172743.2032 - val_loss: 9329942025.4335\n",
      "Epoch 3008/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2372190481.2020 - val_loss: 4979694652.8495\n",
      "Epoch 3009/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1968208269.0377 - val_loss: 5105523827.7941\n",
      "Epoch 3010/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1882695353.3371 - val_loss: 5560013722.8962\n",
      "Epoch 3011/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1893249975.7164 - val_loss: 4992741941.4323\n",
      "Epoch 3012/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1560919999.7119 - val_loss: 5864930725.7339\n",
      "Epoch 3013/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2028570264.9949 - val_loss: 5303230253.4391\n",
      "Epoch 3014/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2196279025.5937 - val_loss: 6825201599.1899\n",
      "Epoch 3015/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2330512775.6173 - val_loss: 4918308428.3679\n",
      "Epoch 3016/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1689925536.3421 - val_loss: 5254874426.7972\n",
      "Epoch 3017/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2055189977.3911 - val_loss: 5625077109.6664\n",
      "Epoch 3018/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2048989945.3731 - val_loss: 4929361993.0914\n",
      "Epoch 3019/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2046154535.1851 - val_loss: 5578553359.4104\n",
      "Epoch 3020/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1855689438.1452 - val_loss: 4939557268.0551\n",
      "Epoch 3021/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1695022800.9499 - val_loss: 4839444901.6979\n",
      "Epoch 3022/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1750846182.2127 - val_loss: 5797297861.4549\n",
      "Epoch 3023/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1907041631.2257 - val_loss: 4824233633.9173\n",
      "Epoch 3024/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1912159326.6179 - val_loss: 4796816686.1952\n",
      "Epoch 3025/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1680249208.6528 - val_loss: 4748236703.2889\n",
      "Epoch 3026/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1885072781.6140 - val_loss: 5983386976.7831\n",
      "Epoch 3027/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1759684323.3315 - val_loss: 6950935941.2208\n",
      "Epoch 3028/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2320002079.9100 - val_loss: 8275291817.1544\n",
      "Epoch 3029/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 2182701382.6449 - val_loss: 4631957104.4816\n",
      "Epoch 3030/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1982962419.4665 - val_loss: 11225719821.3941\n",
      "Epoch 3031/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2320191828.2048 - val_loss: 5745398277.0408\n",
      "Epoch 3032/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2026225334.7440 - val_loss: 8906013503.0098\n",
      "Epoch 3033/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1819567722.7507 - val_loss: 4741587008.7741\n",
      "Epoch 3034/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1600134141.5509 - val_loss: 5289039994.3471\n",
      "Epoch 3035/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1841953407.6398 - val_loss: 5026557860.1857\n",
      "Epoch 3036/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1798413294.0642 - val_loss: 4859916535.8627\n",
      "Epoch 3037/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1872577844.7271 - val_loss: 4647106898.0208\n",
      "Epoch 3038/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1772199652.1958 - val_loss: 5005674568.5873\n",
      "Epoch 3039/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2086069048.3647 - val_loss: 4749816015.2124\n",
      "Epoch 3040/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1773209085.9831 - val_loss: 4860228829.7226\n",
      "Epoch 3041/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1969750207.9100 - val_loss: 4783538084.6897\n",
      "Epoch 3042/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1617646296.9589 - val_loss: 4631155946.6487\n",
      "Epoch 3043/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1701984940.5875 - val_loss: 4972341415.6062\n",
      "Epoch 3044/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1864866304.9004 - val_loss: 4893286431.6850\n",
      "Epoch 3045/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1670793912.8329 - val_loss: 5177947650.3764\n",
      "Epoch 3046/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1843335598.1002 - val_loss: 4928380948.8833\n",
      "Epoch 3047/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1675628659.9437 - val_loss: 5317853082.2481\n",
      "Epoch 3048/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1831850105.3911 - val_loss: 5195525627.7513\n",
      "Epoch 3049/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 73us/step - loss: 1821405099.3990 - val_loss: 6523886110.3887\n",
      "Epoch 3050/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1925202133.9336 - val_loss: 4722684726.7286\n",
      "Epoch 3051/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1585847697.3596 - val_loss: 6013690151.8582\n",
      "Epoch 3052/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2062393339.2459 - val_loss: 5260249077.5584\n",
      "Epoch 3053/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2464125869.6230 - val_loss: 5131746811.7873\n",
      "Epoch 3054/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1940613692.5065 - val_loss: 4698430029.1241\n",
      "Epoch 3055/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1675455057.6117 - val_loss: 4896333565.9117\n",
      "Epoch 3056/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1670716434.2960 - val_loss: 6159410042.6352\n",
      "Epoch 3057/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2565789919.5858 - val_loss: 5783309358.7353\n",
      "Epoch 3058/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2278554923.9392 - val_loss: 5276837384.7854\n",
      "Epoch 3059/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2089889543.9415 - val_loss: 4764082520.9699\n",
      "Epoch 3060/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1924821376.2341 - val_loss: 4882892471.0526\n",
      "Epoch 3061/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1626823304.7631 - val_loss: 4867430657.1162\n",
      "Epoch 3062/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1706970056.1035 - val_loss: 5732789294.4113\n",
      "Epoch 3063/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1638600069.9246 - val_loss: 5917852054.8996\n",
      "Epoch 3064/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1719259631.4328 - val_loss: 6153486298.0141\n",
      "Epoch 3065/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1738924826.4716 - val_loss: 4472295146.5046\n",
      "Epoch 3066/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1794660867.1694 - val_loss: 6340316538.1311\n",
      "Epoch 3067/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1766638005.0872 - val_loss: 7316528385.8003\n",
      "Epoch 3068/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2038049456.3331 - val_loss: 4929393981.1015\n",
      "Epoch 3069/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 1650267143.5858 - val_loss: 4565668279.9527\n",
      "Epoch 3070/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1681409286.1587 - val_loss: 5014350349.1781\n",
      "Epoch 3071/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 1725720584.8599 - val_loss: 4671169686.7196\n",
      "Epoch 3072/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1508808393.6882 - val_loss: 5563433617.8588\n",
      "Epoch 3073/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1757630601.7963 - val_loss: 8321044603.7153\n",
      "Epoch 3074/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2179139161.6072 - val_loss: 4880729372.3904\n",
      "Epoch 3075/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 2046965767.9235 - val_loss: 5093224620.8270\n",
      "Epoch 3076/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1825399990.0957 - val_loss: 4936250340.2037\n",
      "Epoch 3077/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1802319241.3641 - val_loss: 5295970942.5958\n",
      "Epoch 3078/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1930636346.1294 - val_loss: 4900400795.1122\n",
      "Epoch 3079/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1696483066.0428 - val_loss: 5135295009.5572\n",
      "Epoch 3080/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1994880575.5318 - val_loss: 5959925586.1648\n",
      "Epoch 3081/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1974966555.5160 - val_loss: 7043790798.8883\n",
      "Epoch 3082/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 2703339579.7141 - val_loss: 4553591678.8838\n",
      "Epoch 3083/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1422949915.7141 - val_loss: 4604141069.1060\n",
      "Epoch 3084/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1753658660.8981 - val_loss: 4639879744.1620\n",
      "Epoch 3085/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 1628350003.0703 - val_loss: 4448369490.5969\n",
      "Epoch 3086/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1975383206.4648 - val_loss: 5013325422.1412\n",
      "Epoch 3087/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1802193025.7288 - val_loss: 4473553788.9035\n",
      "Epoch 3088/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1760319309.3618 - val_loss: 4639739220.4332\n",
      "Epoch 3089/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1568802920.3737 - val_loss: 4896574574.9693\n",
      "Epoch 3090/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1654823973.9539 - val_loss: 4599436197.5539\n",
      "Epoch 3091/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1519023667.1424 - val_loss: 4650384431.9595\n",
      "Epoch 3092/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1701650806.9961 - val_loss: 4551782099.3890\n",
      "Epoch 3093/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1730179030.5459 - val_loss: 7469938126.6723\n",
      "Epoch 3094/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2158182339.0974 - val_loss: 4756924480.0540\n",
      "Epoch 3095/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2038207023.9370 - val_loss: 5505879887.3564\n",
      "Epoch 3096/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2089359357.7670 - val_loss: 5706617796.3747\n",
      "Epoch 3097/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1595328313.8863 - val_loss: 5252815807.4059\n",
      "Epoch 3098/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1477313299.1604 - val_loss: 5497319273.9286\n",
      "Epoch 3099/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2110481772.2273 - val_loss: 5049576545.0712\n",
      "Epoch 3100/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1817171039.7299 - val_loss: 4890919813.1488\n",
      "Epoch 3101/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1445966128.5853 - val_loss: 4546060140.7730\n",
      "Epoch 3102/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1595291925.0152 - val_loss: 5389641302.1975\n",
      "Epoch 3103/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1498269057.5847 - val_loss: 5118852842.3246\n",
      "Epoch 3104/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1856907917.9021 - val_loss: 6270437553.4357\n",
      "Epoch 3105/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2231485244.8666 - val_loss: 5157381269.0993\n",
      "Epoch 3106/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1598897142.0732 - val_loss: 4650038877.6146\n",
      "Epoch 3107/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1659414015.7119 - val_loss: 5036860241.6968\n",
      "Epoch 3108/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1577812641.0264 - val_loss: 4953733662.6768\n",
      "Epoch 3109/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1655858196.0248 - val_loss: 5290184721.5707\n",
      "Epoch 3110/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1663744916.6730 - val_loss: 4633743380.3072\n",
      "Epoch 3111/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1679250775.4102 - val_loss: 5287390027.0717\n",
      "Epoch 3112/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1902188211.1604 - val_loss: 5197123268.3027\n",
      "Epoch 3113/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1577040804.2319 - val_loss: 4885652534.0805\n",
      "Epoch 3114/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 73us/step - loss: 1902795961.9178 - val_loss: 5671458164.0821\n",
      "Epoch 3115/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1517627106.4221 - val_loss: 4783265436.8045\n",
      "Epoch 3116/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1694149964.9116 - val_loss: 4604803079.2011\n",
      "Epoch 3117/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1768275907.8627 - val_loss: 4606578628.9508\n",
      "Epoch 3118/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1534419534.8565 - val_loss: 4884391998.5058\n",
      "Epoch 3119/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1695113540.2499 - val_loss: 4998110584.4748\n",
      "Epoch 3120/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 1552809479.9235 - val_loss: 5063618604.6470\n",
      "Epoch 3121/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1689021826.9533 - val_loss: 5522576980.3972\n",
      "Epoch 3122/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1817969646.1722 - val_loss: 4790645222.5080\n",
      "Epoch 3123/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1781755932.5245 - val_loss: 5983425905.2737\n",
      "Epoch 3124/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2362404705.8638 - val_loss: 4767085570.1603\n",
      "Epoch 3125/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1442855862.2606 - val_loss: 4545817667.0785\n",
      "Epoch 3126/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1511998775.4643 - val_loss: 5365290860.8810\n",
      "Epoch 3127/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1927723261.5509 - val_loss: 4564119733.2163\n",
      "Epoch 3128/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1803252945.1705 - val_loss: 4546390496.9632\n",
      "Epoch 3129/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1580022125.3438 - val_loss: 4997687809.5482\n",
      "Epoch 3130/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1930796344.0045 - val_loss: 4729234129.4087\n",
      "Epoch 3131/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1481395832.9319 - val_loss: 4661094220.8360\n",
      "Epoch 3132/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1692039115.3810 - val_loss: 4752446854.5890\n",
      "Epoch 3133/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1963115403.5250 - val_loss: 4614842554.6892\n",
      "Epoch 3134/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1420189901.6500 - val_loss: 4694664157.2546\n",
      "Epoch 3135/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1681602259.4845 - val_loss: 4871837819.0312\n",
      "Epoch 3136/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1825575911.7974 - val_loss: 4825892682.0276\n",
      "Epoch 3137/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1677446172.0923 - val_loss: 4865002592.4231\n",
      "Epoch 3138/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1802285000.8599 - val_loss: 6131083276.9620\n",
      "Epoch 3139/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1766449177.0670 - val_loss: 5093548277.8824\n",
      "Epoch 3140/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1653704137.1120 - val_loss: 5827471256.4478\n",
      "Epoch 3141/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1590725223.5093 - val_loss: 4461612546.4844\n",
      "Epoch 3142/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1432966842.2735 - val_loss: 5117285145.9241\n",
      "Epoch 3143/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1467780847.3540 - val_loss: 4337955263.9820\n",
      "Epoch 3144/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1815354554.1294 - val_loss: 6556435735.9797\n",
      "Epoch 3145/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2179033621.8976 - val_loss: 5292345085.5516\n",
      "Epoch 3146/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1550732220.2904 - val_loss: 6375239339.6028\n",
      "Epoch 3147/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1751786000.0630 - val_loss: 5899810746.5812\n",
      "Epoch 3148/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1521797749.4834 - val_loss: 4684114003.4610\n",
      "Epoch 3149/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1643511026.6021 - val_loss: 5871815788.1609\n",
      "Epoch 3150/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1737005192.2836 - val_loss: 4387914345.2084\n",
      "Epoch 3151/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1834145125.9831 - val_loss: 4344833105.2647\n",
      "Epoch 3152/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1469140067.0253 - val_loss: 8863812183.4937\n",
      "Epoch 3153/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1976762498.8092 - val_loss: 8000015633.9308\n",
      "Epoch 3154/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2059738767.4147 - val_loss: 5381559276.5570\n",
      "Epoch 3155/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1531376219.6061 - val_loss: 4334796754.8489\n",
      "Epoch 3156/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1500662557.1007 - val_loss: 4563309173.0903\n",
      "Epoch 3157/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1502685573.4384 - val_loss: 4359354840.1778\n",
      "Epoch 3158/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1440867805.2133 - val_loss: 4337810397.2906\n",
      "Epoch 3159/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1458279441.8638 - val_loss: 4899228095.3339\n",
      "Epoch 3160/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1642031985.4857 - val_loss: 8295588172.7640\n",
      "Epoch 3161/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1758145769.8143 - val_loss: 4551235346.2188\n",
      "Epoch 3162/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1387926143.8559 - val_loss: 4832695965.4166\n",
      "Epoch 3163/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1592955792.7293 - val_loss: 4850521396.8923\n",
      "Epoch 3164/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1583370843.6241 - val_loss: 5950362057.7035\n",
      "Epoch 3165/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1731978463.6579 - val_loss: 5960803257.4290\n",
      "Epoch 3166/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1902624980.9972 - val_loss: 4546953461.4143\n",
      "Epoch 3167/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1407198185.0940 - val_loss: 5118514899.8211\n",
      "Epoch 3168/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1746207062.0416 - val_loss: 6152372344.7629\n",
      "Epoch 3169/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1646560811.6511 - val_loss: 5654093664.5671\n",
      "Epoch 3170/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1561558206.5954 - val_loss: 4655001587.0380\n",
      "Epoch 3171/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1659795520.3962 - val_loss: 5098880906.2616\n",
      "Epoch 3172/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1631796529.0400 - val_loss: 4532563597.9342\n",
      "Epoch 3173/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1501991038.7755 - val_loss: 4596658268.8945\n",
      "Epoch 3174/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1763643018.6066 - val_loss: 4706311588.4377\n",
      "Epoch 3175/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1516230150.6989 - val_loss: 6070998952.7224\n",
      "Epoch 3176/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1689106246.4108 - val_loss: 4504560731.5263\n",
      "Epoch 3177/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1709798290.8002 - val_loss: 5756533877.8104\n",
      "Epoch 3178/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1688272100.0028 - val_loss: 4474855984.5716\n",
      "Epoch 3179/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 76us/step - loss: 1354351145.6342 - val_loss: 4411830727.5792\n",
      "Epoch 3180/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1461836446.7935 - val_loss: 5429220455.2641\n",
      "Epoch 3181/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1700904483.8717 - val_loss: 4803122024.2003\n",
      "Epoch 3182/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 1775944139.2009 - val_loss: 4466943386.9682\n",
      "Epoch 3183/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1426448730.2375 - val_loss: 4536822787.3845\n",
      "Epoch 3184/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1547239646.2893 - val_loss: 4423091652.7167\n",
      "Epoch 3185/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1363611661.8661 - val_loss: 4557275609.0419\n",
      "Epoch 3186/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1545563015.2752 - val_loss: 5243081295.1404\n",
      "Epoch 3187/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1634233651.7186 - val_loss: 5672493169.9578\n",
      "Epoch 3188/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1761438431.5858 - val_loss: 4585526172.1204\n",
      "Epoch 3189/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1751053754.8497 - val_loss: 8940214274.3044\n",
      "Epoch 3190/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1681837968.8059 - val_loss: 4261447575.1516\n",
      "Epoch 3191/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2165684109.3258 - val_loss: 8618190270.1817\n",
      "Epoch 3192/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2068295346.0619 - val_loss: 4381614263.1966\n",
      "Epoch 3193/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1615453670.9330 - val_loss: 5553212423.1291\n",
      "Epoch 3194/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1695931922.6201 - val_loss: 4475341453.1421\n",
      "Epoch 3195/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1388513287.2392 - val_loss: 4421168216.1058\n",
      "Epoch 3196/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 1576665694.5774 - val_loss: 4394477685.3783\n",
      "Epoch 3197/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1513007447.4463 - val_loss: 4370406701.1150\n",
      "Epoch 3198/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1785645462.0416 - val_loss: 5694957654.1615\n",
      "Epoch 3199/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1466112948.1148 - val_loss: 5017571139.0425\n",
      "Epoch 3200/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1435295152.2611 - val_loss: 5402552479.2889\n",
      "Epoch 3201/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 1835581543.2212 - val_loss: 4232177464.2768\n",
      "Epoch 3202/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1469003622.7169 - val_loss: 5533212319.3969\n",
      "Epoch 3203/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1709321229.4699 - val_loss: 4902567443.3710\n",
      "Epoch 3204/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1451032131.2234 - val_loss: 4383229346.6014\n",
      "Epoch 3205/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1571559073.1345 - val_loss: 4541768348.6245\n",
      "Epoch 3206/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1491985136.8734 - val_loss: 4326917472.2790\n",
      "Epoch 3207/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1366475414.9781 - val_loss: 9155766485.9454\n",
      "Epoch 3208/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 2624108114.6922 - val_loss: 5055411478.8276\n",
      "Epoch 3209/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1436254935.6263 - val_loss: 4466971826.9840\n",
      "Epoch 3210/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1242143398.0895 - val_loss: 4386114777.2219\n",
      "Epoch 3211/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1371210002.8723 - val_loss: 5847482718.5508\n",
      "Epoch 3212/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1670547558.2127 - val_loss: 4613250843.8684\n",
      "Epoch 3213/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1682999628.8036 - val_loss: 4387309589.9994\n",
      "Epoch 3214/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1535475284.2769 - val_loss: 4474028848.3556\n",
      "Epoch 3215/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1680716432.3376 - val_loss: 4555273603.9966\n",
      "Epoch 3216/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1385233241.4631 - val_loss: 4405073181.6326\n",
      "Epoch 3217/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 1472604710.9690 - val_loss: 4687441229.4121\n",
      "Epoch 3218/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1475016056.8329 - val_loss: 5060724836.6717\n",
      "Epoch 3219/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1525233621.3033 - val_loss: 5111928046.9333\n",
      "Epoch 3220/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1677337849.5172 - val_loss: 5480755291.2023\n",
      "Epoch 3221/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2263923885.7400 - val_loss: 4787162047.1539\n",
      "Epoch 3222/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1494277386.2285 - val_loss: 5228193501.1105\n",
      "Epoch 3223/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1451666119.2842 - val_loss: 4500663366.7871\n",
      "Epoch 3224/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1294938855.7254 - val_loss: 4196615486.1457\n",
      "Epoch 3225/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1432005028.3039 - val_loss: 4164224490.2166\n",
      "Epoch 3226/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1373364004.4479 - val_loss: 10570837723.0582\n",
      "Epoch 3227/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1823053036.1193 - val_loss: 7792077998.2312\n",
      "Epoch 3228/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1884811998.7214 - val_loss: 4530474819.3665\n",
      "Epoch 3229/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1955132498.9083 - val_loss: 4440284379.9224\n",
      "Epoch 3230/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1246626379.1289 - val_loss: 4577848626.6599\n",
      "Epoch 3231/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1258745659.1739 - val_loss: 4682269938.4619\n",
      "Epoch 3232/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1396609099.9212 - val_loss: 4939801510.5620\n",
      "Epoch 3233/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1674728748.5155 - val_loss: 4827742874.3921\n",
      "Epoch 3234/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1410505820.7766 - val_loss: 10074914125.2681\n",
      "Epoch 3235/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1928450972.3084 - val_loss: 5029826129.5167\n",
      "Epoch 3236/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1829558058.8588 - val_loss: 4538961153.2242\n",
      "Epoch 3237/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1398316467.7907 - val_loss: 5983131045.3378\n",
      "Epoch 3238/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1525107315.6826 - val_loss: 4443303594.4866\n",
      "Epoch 3239/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1520858231.7164 - val_loss: 4979103341.8172\n",
      "Epoch 3240/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1538300477.6590 - val_loss: 4606085040.4276\n",
      "Epoch 3241/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1519470184.4457 - val_loss: 4625259909.0768\n",
      "Epoch 3242/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1407927093.7355 - val_loss: 4545354272.1890\n",
      "Epoch 3243/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1352822925.3528 - val_loss: 4140854805.5674\n",
      "Epoch 3244/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 88us/step - loss: 1321692984.9769 - val_loss: 4313468980.4242\n",
      "Epoch 3245/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1322253655.3742 - val_loss: 5180025843.3260\n",
      "Epoch 3246/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1696601901.1638 - val_loss: 4421381364.1181\n",
      "Epoch 3247/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1408110127.2527 - val_loss: 4700157056.5401\n",
      "Epoch 3248/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1512691921.3236 - val_loss: 4854505382.6700\n",
      "Epoch 3249/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1612239477.5194 - val_loss: 5122791446.3235\n",
      "Epoch 3250/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1463730795.1829 - val_loss: 4126358863.1044\n",
      "Epoch 3251/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1579944713.5802 - val_loss: 5544441857.4402\n",
      "Epoch 3252/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1471088440.4097 - val_loss: 4312190132.2442\n",
      "Epoch 3253/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1422515213.5419 - val_loss: 4910666908.1564\n",
      "Epoch 3254/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1641166629.3123 - val_loss: 6113316749.2141\n",
      "Epoch 3255/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1641555102.1812 - val_loss: 4947804163.1685\n",
      "Epoch 3256/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1697862080.6123 - val_loss: 4556871777.2872\n",
      "Epoch 3257/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1350839106.0529 - val_loss: 4436839878.0669\n",
      "Epoch 3258/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1410313161.3371 - val_loss: 4366206445.2771\n",
      "Epoch 3259/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1378832795.8762 - val_loss: 4779004907.5128\n",
      "Epoch 3260/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 1486315475.9167 - val_loss: 4508072552.6684\n",
      "Epoch 3261/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1994121133.9561 - val_loss: 6409799777.4312\n",
      "Epoch 3262/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1766605405.2088 - val_loss: 4304392789.7114\n",
      "Epoch 3263/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1317979588.9342 - val_loss: 4539289611.0897\n",
      "Epoch 3264/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1873142903.2842 - val_loss: 5599084782.2132\n",
      "Epoch 3265/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1775732749.4339 - val_loss: 4095354446.6363\n",
      "Epoch 3266/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1329409980.7766 - val_loss: 4059976986.1761\n",
      "Epoch 3267/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1507903002.3995 - val_loss: 4542049214.6138\n",
      "Epoch 3268/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1318508883.5205 - val_loss: 4385749778.0028\n",
      "Epoch 3269/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 1502264996.2319 - val_loss: 4857108026.1131\n",
      "Epoch 3270/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1380398873.6950 - val_loss: 4828451327.5679\n",
      "Epoch 3271/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1358398831.5768 - val_loss: 4600116025.0329\n",
      "Epoch 3272/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1522617343.4958 - val_loss: 4313563099.3103\n",
      "Epoch 3273/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1676208745.7423 - val_loss: 4642962176.9361\n",
      "Epoch 3274/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2225915729.0355 - val_loss: 4420364485.5989\n",
      "Epoch 3275/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1254769500.4885 - val_loss: 5530039904.0630\n",
      "Epoch 3276/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1296896848.3151 - val_loss: 4827683798.1255\n",
      "Epoch 3277/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1623027349.8976 - val_loss: 4312172401.3457\n",
      "Epoch 3278/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1195378062.1902 - val_loss: 4410754556.2914\n",
      "Epoch 3279/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1550181227.3990 - val_loss: 4315657780.2802\n",
      "Epoch 3280/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1280751733.3393 - val_loss: 4140069974.4135\n",
      "Epoch 3281/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1303507524.4299 - val_loss: 6880588419.4925\n",
      "Epoch 3282/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1352828277.1232 - val_loss: 4574130084.2937\n",
      "Epoch 3283/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1580820495.6308 - val_loss: 5012086445.1871\n",
      "Epoch 3284/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1542656469.0332 - val_loss: 5047846567.7502\n",
      "Epoch 3285/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1625964641.0715 - val_loss: 4301837174.3865\n",
      "Epoch 3286/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1286241904.0810 - val_loss: 4775395136.4501\n",
      "Epoch 3287/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1383549929.3821 - val_loss: 6135053013.5854\n",
      "Epoch 3288/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1352188999.6714 - val_loss: 4089883507.2720\n",
      "Epoch 3289/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1397409623.1401 - val_loss: 4537029564.6335\n",
      "Epoch 3290/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1530375081.2741 - val_loss: 4781615576.6098\n",
      "Epoch 3291/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1348381157.5644 - val_loss: 4434868191.0188\n",
      "Epoch 3292/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1300895050.6246 - val_loss: 6049098084.3117\n",
      "Epoch 3293/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1657951967.1536 - val_loss: 11437288867.1055\n",
      "Epoch 3294/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1806263980.2273 - val_loss: 4577865144.4208\n",
      "Epoch 3295/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1271254302.6314 - val_loss: 4065599666.5519\n",
      "Epoch 3296/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1393611495.5453 - val_loss: 4220495312.8686\n",
      "Epoch 3297/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1363805612.3714 - val_loss: 4285613089.4132\n",
      "Epoch 3298/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1320475109.3483 - val_loss: 4692975605.7744\n",
      "Epoch 3299/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1611350401.6567 - val_loss: 5214962130.7769\n",
      "Epoch 3300/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1674092184.8509 - val_loss: 4714379853.1241\n",
      "Epoch 3301/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1635361109.5374 - val_loss: 4237863657.1724\n",
      "Epoch 3302/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1235766916.7541 - val_loss: 4321106271.6669\n",
      "Epoch 3303/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1281094178.8633 - val_loss: 5530396700.5885\n",
      "Epoch 3304/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1688654055.5093 - val_loss: 5022953484.7100\n",
      "Epoch 3305/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1546914821.7625 - val_loss: 4340383996.2914\n",
      "Epoch 3306/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1624695323.0838 - val_loss: 4529624480.9812\n",
      "Epoch 3307/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1436463202.7732 - val_loss: 4008029534.1547\n",
      "Epoch 3308/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1350609062.6089 - val_loss: 4106149111.8267\n",
      "Epoch 3309/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 75us/step - loss: 1521138953.2290 - val_loss: 4552977520.3376\n",
      "Epoch 3310/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1421622177.9268 - val_loss: 5414750321.5977\n",
      "Epoch 3311/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2048628502.1677 - val_loss: 5498611176.3263\n",
      "Epoch 3312/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1297943533.8481 - val_loss: 3994024278.1975\n",
      "Epoch 3313/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1321898317.6500 - val_loss: 4339794825.0014\n",
      "Epoch 3314/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1355287469.7400 - val_loss: 5302425579.8368\n",
      "Epoch 3315/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1264718243.7817 - val_loss: 4359970593.0892\n",
      "Epoch 3316/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1254219197.2988 - val_loss: 7871601853.9657\n",
      "Epoch 3317/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1398935091.4586 - val_loss: 4369132766.5148\n",
      "Epoch 3318/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1219897434.6877 - val_loss: 5068846124.1429\n",
      "Epoch 3319/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2042531036.6607 - val_loss: 4461563173.3018\n",
      "Epoch 3320/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1422419285.4294 - val_loss: 9666177128.5603\n",
      "Epoch 3321/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2201121659.2369 - val_loss: 4142778438.5710\n",
      "Epoch 3322/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1363063688.4997 - val_loss: 4827462874.9862\n",
      "Epoch 3323/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1600298537.9854 - val_loss: 5192948237.2861\n",
      "Epoch 3324/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1326963410.9083 - val_loss: 4928760440.5468\n",
      "Epoch 3325/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1580061753.5532 - val_loss: 4905090787.8436\n",
      "Epoch 3326/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1261925711.3067 - val_loss: 4687437906.2368\n",
      "Epoch 3327/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1311344729.1750 - val_loss: 6024106703.4644\n",
      "Epoch 3328/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1987509919.4778 - val_loss: 4409509083.5263\n",
      "Epoch 3329/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1391648908.7496 - val_loss: 4269849154.8444\n",
      "Epoch 3330/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1532740455.0051 - val_loss: 4852075770.8872\n",
      "Epoch 3331/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1349490034.9623 - val_loss: 4891528232.0383\n",
      "Epoch 3332/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1478716636.2724 - val_loss: 7642055163.2473\n",
      "Epoch 3333/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1618728753.5577 - val_loss: 4387598283.2518\n",
      "Epoch 3334/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1277085213.1367 - val_loss: 3936673640.8844\n",
      "Epoch 3335/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1178600362.1182 - val_loss: 4322221124.7347\n",
      "Epoch 3336/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1383667758.6764 - val_loss: 4068680632.2768\n",
      "Epoch 3337/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1306031784.6168 - val_loss: 4187563143.2011\n",
      "Epoch 3338/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1202151202.2870 - val_loss: 4305035659.1257\n",
      "Epoch 3339/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1408684896.3782 - val_loss: 4504509029.0678\n",
      "Epoch 3340/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1394223726.9285 - val_loss: 4428495200.8191\n",
      "Epoch 3341/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 1494395370.8227 - val_loss: 6584434552.4748\n",
      "Epoch 3342/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1449568739.7636 - val_loss: 4070577013.8464\n",
      "Epoch 3343/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1242806790.9871 - val_loss: 4473693614.7713\n",
      "Epoch 3344/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1310489939.0163 - val_loss: 5812702244.6537\n",
      "Epoch 3345/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1528912087.8424 - val_loss: 4604461004.6740\n",
      "Epoch 3346/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1425044933.9426 - val_loss: 4183347557.7519\n",
      "Epoch 3347/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1370781502.6674 - val_loss: 4100824240.9677\n",
      "Epoch 3348/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1196291019.4890 - val_loss: 4461764783.2034\n",
      "Epoch 3349/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1595955484.3804 - val_loss: 4113206122.5046\n",
      "Epoch 3350/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1332345811.7006 - val_loss: 4555335268.5997\n",
      "Epoch 3351/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1303982371.8357 - val_loss: 6912934116.2757\n",
      "Epoch 3352/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1487073185.0625 - val_loss: 4158819107.9696\n",
      "Epoch 3353/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1226075429.8165 - val_loss: 4738507144.3533\n",
      "Epoch 3354/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1399143377.1075 - val_loss: 4405816272.3826\n",
      "Epoch 3355/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1321213288.1035 - val_loss: 4352629087.3429\n",
      "Epoch 3356/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1828545732.7901 - val_loss: 4183627702.1525\n",
      "Epoch 3357/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1359103190.6539 - val_loss: 5286130554.0951\n",
      "Epoch 3358/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1313919592.7338 - val_loss: 4561754545.6878\n",
      "Epoch 3359/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1382417025.7288 - val_loss: 4348906467.7356\n",
      "Epoch 3360/7000\n",
      "3554/3554 [==============================] - 0s 67us/step - loss: 1549696333.2538 - val_loss: 4482355709.1916\n",
      "Epoch 3361/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1729096191.7119 - val_loss: 5240586743.1786\n",
      "Epoch 3362/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1332180507.3720 - val_loss: 4434745678.7803\n",
      "Epoch 3363/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1376111095.1761 - val_loss: 4231384711.8492\n",
      "Epoch 3364/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 1197778167.5363 - val_loss: 4458468937.0914\n",
      "Epoch 3365/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1420244677.0782 - val_loss: 5184594813.2276\n",
      "Epoch 3366/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1361839287.3922 - val_loss: 4094169826.6194\n",
      "Epoch 3367/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1354463091.7907 - val_loss: 4294603713.2062\n",
      "Epoch 3368/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1225911674.8858 - val_loss: 7244435326.9918\n",
      "Epoch 3369/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2357162501.6905 - val_loss: 4953130654.6768\n",
      "Epoch 3370/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1131768819.5025 - val_loss: 4149904783.4464\n",
      "Epoch 3371/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1268430366.8295 - val_loss: 4150434414.8793\n",
      "Epoch 3372/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1257076589.5599 - val_loss: 4152384322.5924\n",
      "Epoch 3373/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1287378392.0945 - val_loss: 4640741474.4034\n",
      "Epoch 3374/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 73us/step - loss: 1535932629.5914 - val_loss: 4750739553.0712\n",
      "Epoch 3375/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1384940317.8931 - val_loss: 5832134570.9907\n",
      "Epoch 3376/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1530962041.0490 - val_loss: 4608644306.4169\n",
      "Epoch 3377/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1376244915.7907 - val_loss: 4552775404.0529\n",
      "Epoch 3378/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1463404819.1739 - val_loss: 4942713354.8737\n",
      "Epoch 3379/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1233957821.0107 - val_loss: 4366003332.8248\n",
      "Epoch 3380/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1209437426.6021 - val_loss: 4144644016.2475\n",
      "Epoch 3381/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1137495158.3838 - val_loss: 4860150125.3851\n",
      "Epoch 3382/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1410916316.9567 - val_loss: 4260877302.9266\n",
      "Epoch 3383/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1307237093.6365 - val_loss: 4029858060.0619\n",
      "Epoch 3384/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1659464993.1525 - val_loss: 4450460121.0059\n",
      "Epoch 3385/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1447330016.8824 - val_loss: 4930026847.5229\n",
      "Epoch 3386/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1475182693.9966 - val_loss: 6671823159.2326\n",
      "Epoch 3387/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2258165721.5352 - val_loss: 6017147533.7181\n",
      "Epoch 3388/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1527251683.7636 - val_loss: 5424270881.5572\n",
      "Epoch 3389/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1222698285.3078 - val_loss: 3962168157.2546\n",
      "Epoch 3390/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1083713048.3827 - val_loss: 3976002168.9069\n",
      "Epoch 3391/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1176937798.1587 - val_loss: 4370281630.2087\n",
      "Epoch 3392/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1692166996.6370 - val_loss: 4204602230.8546\n",
      "Epoch 3393/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1288100097.4924 - val_loss: 4957892545.7463\n",
      "Epoch 3394/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1174306303.4237 - val_loss: 4472733732.9958\n",
      "Epoch 3395/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1289427055.2167 - val_loss: 8791689326.6093\n",
      "Epoch 3396/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1739371766.2938 - val_loss: 4055092240.3105\n",
      "Epoch 3397/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1256640853.7175 - val_loss: 5831097861.4008\n",
      "Epoch 3398/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1325424684.0833 - val_loss: 5323687007.5589\n",
      "Epoch 3399/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1842935879.9865 - val_loss: 4771474870.1885\n",
      "Epoch 3400/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1187339152.0450 - val_loss: 6352581017.5280\n",
      "Epoch 3401/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 1391467073.1885 - val_loss: 4411333770.6577\n",
      "Epoch 3402/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1409027884.7822 - val_loss: 4317954015.5229\n",
      "Epoch 3403/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1249211870.1452 - val_loss: 4616839405.9792\n",
      "Epoch 3404/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1355442261.4724 - val_loss: 8489679005.2006\n",
      "Epoch 3405/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1488213898.4446 - val_loss: 3973939971.8886\n",
      "Epoch 3406/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1114302555.8402 - val_loss: 4033398829.4751\n",
      "Epoch 3407/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1062776861.2448 - val_loss: 7939354847.9550\n",
      "Epoch 3408/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1384571024.7113 - val_loss: 4378230657.9083\n",
      "Epoch 3409/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1281142056.6258 - val_loss: 4326783037.7136\n",
      "Epoch 3410/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1176983204.0518 - val_loss: 4110654326.0264\n",
      "Epoch 3411/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1136696919.1041 - val_loss: 4101400917.5494\n",
      "Epoch 3412/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1687050545.1975 - val_loss: 4560855816.7854\n",
      "Epoch 3413/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1513320958.7034 - val_loss: 4310476892.1204\n",
      "Epoch 3414/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1213615247.0546 - val_loss: 5521966047.9910\n",
      "Epoch 3415/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1490246072.2566 - val_loss: 5440622074.0951\n",
      "Epoch 3416/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1415874946.9533 - val_loss: 4097047542.1525\n",
      "Epoch 3417/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1437750607.5228 - val_loss: 3942884791.8627\n",
      "Epoch 3418/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1229699081.2943 - val_loss: 4965586713.5640\n",
      "Epoch 3419/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1269897767.2932 - val_loss: 6407257834.3606\n",
      "Epoch 3420/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1798065059.8357 - val_loss: 4139818987.7828\n",
      "Epoch 3421/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1287213930.4626 - val_loss: 4115791800.2048\n",
      "Epoch 3422/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1247564683.5070 - val_loss: 4021112353.2872\n",
      "Epoch 3423/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1095169634.7282 - val_loss: 4250991233.9443\n",
      "Epoch 3424/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1097397807.7569 - val_loss: 4030719906.9075\n",
      "Epoch 3425/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1406600036.9522 - val_loss: 4055833374.8748\n",
      "Epoch 3426/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1344798109.4969 - val_loss: 4241448916.2532\n",
      "Epoch 3427/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1154787643.3180 - val_loss: 3808053431.2146\n",
      "Epoch 3428/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1083135094.9060 - val_loss: 4416588155.8954\n",
      "Epoch 3429/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1112189734.3208 - val_loss: 3875886604.5480\n",
      "Epoch 3430/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1185587249.6432 - val_loss: 4079460410.5271\n",
      "Epoch 3431/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1322799621.5464 - val_loss: 4017490759.1831\n",
      "Epoch 3432/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1175700676.0068 - val_loss: 6150789219.5196\n",
      "Epoch 3433/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1244808723.6646 - val_loss: 4254955956.7482\n",
      "Epoch 3434/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1448695763.4485 - val_loss: 4191062967.1066\n",
      "Epoch 3435/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1192517914.6877 - val_loss: 6248782225.6068\n",
      "Epoch 3436/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1554784374.5459 - val_loss: 4613410022.7241\n",
      "Epoch 3437/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1074972376.7428 - val_loss: 4967562598.6880\n",
      "Epoch 3438/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1280007025.3056 - val_loss: 3944783683.5826\n",
      "Epoch 3439/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 121us/step - loss: 1462245852.9927 - val_loss: 5652069804.3589\n",
      "Epoch 3440/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1280635219.3405 - val_loss: 4094805685.6124\n",
      "Epoch 3441/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1418146017.5577 - val_loss: 4031504343.0796\n",
      "Epoch 3442/7000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 1200039645.4969 - val_loss: 3997558889.6585\n",
      "Epoch 3443/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1279326934.2217 - val_loss: 5468282105.7350\n",
      "Epoch 3444/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1157285587.1424 - val_loss: 4102028951.8717\n",
      "Epoch 3445/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1282741298.7102 - val_loss: 4112436870.4450\n",
      "Epoch 3446/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1221582041.9674 - val_loss: 10687106522.6982\n",
      "Epoch 3447/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2667619008.5402 - val_loss: 3925647450.6622\n",
      "Epoch 3448/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1471407851.1829 - val_loss: 4470918347.5038\n",
      "Epoch 3449/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1335047367.5273 - val_loss: 3866639789.4931\n",
      "Epoch 3450/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1138932999.7614 - val_loss: 4849213958.7150\n",
      "Epoch 3451/7000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 1055417727.7479 - val_loss: 4296804466.7499\n",
      "Epoch 3452/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1279927504.3151 - val_loss: 4091763061.3783\n",
      "Epoch 3453/7000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1492222977.4406 - val_loss: 4662070942.4968\n",
      "Epoch 3454/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1548206812.1148 - val_loss: 4431018879.2169\n",
      "Epoch 3455/7000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 1112276023.6083 - val_loss: 4417004818.5249\n",
      "Epoch 3456/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1327778410.1384 - val_loss: 4106170205.5426\n",
      "Epoch 3457/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1058161221.5785 - val_loss: 3966153605.6169\n",
      "Epoch 3458/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1096496129.7648 - val_loss: 3977530756.5727\n",
      "Epoch 3459/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1164298503.1311 - val_loss: 4245409578.4326\n",
      "Epoch 3460/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1251734223.6579 - val_loss: 4325140286.7038\n",
      "Epoch 3461/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1748190090.4806 - val_loss: 4616373341.4706\n",
      "Epoch 3462/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1361928338.4401 - val_loss: 4776748889.2219\n",
      "Epoch 3463/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1489459017.4001 - val_loss: 4238172442.1401\n",
      "Epoch 3464/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1264162691.4575 - val_loss: 5162345954.2594\n",
      "Epoch 3465/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1184648873.1750 - val_loss: 4296932743.8852\n",
      "Epoch 3466/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1228431368.6798 - val_loss: 4037661278.6588\n",
      "Epoch 3467/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 1162279281.5037 - val_loss: 4217575824.1665\n",
      "Epoch 3468/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1128845653.5734 - val_loss: 4192361525.3243\n",
      "Epoch 3469/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1194823237.7625 - val_loss: 6144481804.6020\n",
      "Epoch 3470/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1369968834.0529 - val_loss: 4667868115.3890\n",
      "Epoch 3471/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1171494060.9837 - val_loss: 4944036369.5707\n",
      "Epoch 3472/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1396935202.8633 - val_loss: 4741517185.6203\n",
      "Epoch 3473/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1516422929.3236 - val_loss: 4383511789.7812\n",
      "Epoch 3474/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1203467670.5459 - val_loss: 3803430034.9840\n",
      "Epoch 3475/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1359679249.4316 - val_loss: 4496690887.7952\n",
      "Epoch 3476/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1247922679.9325 - val_loss: 7395087537.0037\n",
      "Epoch 3477/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1348267715.5656 - val_loss: 3951606484.8653\n",
      "Epoch 3478/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1199312122.2375 - val_loss: 4689055265.0532\n",
      "Epoch 3479/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1751408530.2060 - val_loss: 4864809104.5986\n",
      "Epoch 3480/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1228515282.4401 - val_loss: 3909465094.3370\n",
      "Epoch 3481/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1054320544.4862 - val_loss: 4005550558.1367\n",
      "Epoch 3482/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1184295941.6905 - val_loss: 3857631936.8101\n",
      "Epoch 3483/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1198403164.2364 - val_loss: 4698935126.5575\n",
      "Epoch 3484/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1190226980.1598 - val_loss: 4052366930.9570\n",
      "Epoch 3485/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1176165060.9342 - val_loss: 3958422485.0723\n",
      "Epoch 3486/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1456259205.4789 - val_loss: 4286882967.0076\n",
      "Epoch 3487/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1112794150.6449 - val_loss: 3915112925.0745\n",
      "Epoch 3488/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1185053591.4823 - val_loss: 4199854387.7761\n",
      "Epoch 3489/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1256275908.6246 - val_loss: 4273456412.5165\n",
      "Epoch 3490/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1246590406.9510 - val_loss: 6237233843.3800\n",
      "Epoch 3491/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1308452396.8396 - val_loss: 4645014836.3162\n",
      "Epoch 3492/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1235977571.5476 - val_loss: 4863649906.0658\n",
      "Epoch 3493/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1770968910.0822 - val_loss: 4441615350.0624\n",
      "Epoch 3494/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1170344648.1035 - val_loss: 4276582636.1249\n",
      "Epoch 3495/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1156854038.4558 - val_loss: 3770572377.9421\n",
      "Epoch 3496/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1298205971.8897 - val_loss: 4553385870.2942\n",
      "Epoch 3497/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 1172232982.6179 - val_loss: 6849572719.1854\n",
      "Epoch 3498/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1269698298.1294 - val_loss: 6837019218.2368\n",
      "Epoch 3499/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1647493529.1390 - val_loss: 6547874964.2352\n",
      "Epoch 3500/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 1285353857.1525 - val_loss: 4213506700.5300\n",
      "Epoch 3501/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1403243732.2589 - val_loss: 4022621072.3466\n",
      "Epoch 3502/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1140214418.2600 - val_loss: 4248208543.7750\n",
      "Epoch 3503/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1179165524.3512 - val_loss: 3835948022.6475\n",
      "Epoch 3504/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 80us/step - loss: 1120729275.7141 - val_loss: 6472103471.6714\n",
      "Epoch 3505/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1364109841.2515 - val_loss: 4004283021.3401\n",
      "Epoch 3506/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1056789778.9983 - val_loss: 4148514971.1302\n",
      "Epoch 3507/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1152139151.6308 - val_loss: 4195227435.0537\n",
      "Epoch 3508/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1129503092.1868 - val_loss: 4312124722.1738\n",
      "Epoch 3509/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1190382361.5532 - val_loss: 7238059775.4959\n",
      "Epoch 3510/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1382050529.6927 - val_loss: 6218217096.5333\n",
      "Epoch 3511/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1529343554.6292 - val_loss: 4161404876.7640\n",
      "Epoch 3512/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1154070561.3506 - val_loss: 4116964441.9601\n",
      "Epoch 3513/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1137782596.7721 - val_loss: 5092075520.0720\n",
      "Epoch 3514/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1200789240.0225 - val_loss: 4360375170.4124\n",
      "Epoch 3515/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1320623741.8030 - val_loss: 4162626966.3595\n",
      "Epoch 3516/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1284497326.1002 - val_loss: 4258114741.8824\n",
      "Epoch 3517/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1053819642.5616 - val_loss: 4716184935.8402\n",
      "Epoch 3518/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1609502817.8188 - val_loss: 4456160175.5634\n",
      "Epoch 3519/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1030334371.6196 - val_loss: 3829944999.2101\n",
      "Epoch 3520/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1133508825.1030 - val_loss: 3909183209.7575\n",
      "Epoch 3521/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1056185880.9229 - val_loss: 3822113811.0110\n",
      "Epoch 3522/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1255835103.1176 - val_loss: 4444250935.7367\n",
      "Epoch 3523/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1285002870.0597 - val_loss: 3848452225.0622\n",
      "Epoch 3524/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1075054794.1925 - val_loss: 4069483544.5918\n",
      "Epoch 3525/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1093555756.3354 - val_loss: 4781025318.4720\n",
      "Epoch 3526/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1448627545.8233 - val_loss: 5278962807.9707\n",
      "Epoch 3527/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1203134832.5132 - val_loss: 4207841178.7162\n",
      "Epoch 3528/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1069552777.8683 - val_loss: 4490051038.1547\n",
      "Epoch 3529/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1488353738.6967 - val_loss: 6008958775.5927\n",
      "Epoch 3530/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1386779188.2228 - val_loss: 4622912639.4599\n",
      "Epoch 3531/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1157474990.5594 - val_loss: 4094061051.9674\n",
      "Epoch 3532/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1103404733.0647 - val_loss: 3801399628.1159\n",
      "Epoch 3533/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1365225804.2814 - val_loss: 3744641312.7651\n",
      "Epoch 3534/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1491529878.2217 - val_loss: 4562144977.8768\n",
      "Epoch 3535/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1426432193.3146 - val_loss: 4009016777.9916\n",
      "Epoch 3536/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1215519654.6719 - val_loss: 3830547936.5671\n",
      "Epoch 3537/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 940694088.0315 - val_loss: 4225655640.3938\n",
      "Epoch 3538/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1033180003.9797 - val_loss: 6622822816.3691\n",
      "Epoch 3539/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1765128007.5993 - val_loss: 6748019368.4703\n",
      "Epoch 3540/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1319317663.4418 - val_loss: 4026355375.1674\n",
      "Epoch 3541/7000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 1473567983.4508 - val_loss: 3865531575.2326\n",
      "Epoch 3542/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1028172080.0788 - val_loss: 4143797440.0270\n",
      "Epoch 3543/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1029851321.7333 - val_loss: 3835191386.6442\n",
      "Epoch 3544/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1026968897.9088 - val_loss: 4082504031.8470\n",
      "Epoch 3545/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1601476095.7119 - val_loss: 5495812231.2011\n",
      "Epoch 3546/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2050769916.6866 - val_loss: 3822920540.1024\n",
      "Epoch 3547/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1065987495.6173 - val_loss: 4689161457.0937\n",
      "Epoch 3548/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1183927117.9381 - val_loss: 5129779027.0650\n",
      "Epoch 3549/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1303367020.6956 - val_loss: 5635947503.8335\n",
      "Epoch 3550/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1339871803.2819 - val_loss: 3708385864.7314\n",
      "Epoch 3551/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1060993106.9803 - val_loss: 5391478249.3345\n",
      "Epoch 3552/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1860036144.4052 - val_loss: 3799129588.8923\n",
      "Epoch 3553/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1050667590.0236 - val_loss: 3688149461.2253\n",
      "Epoch 3554/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1114885421.7040 - val_loss: 4055880556.6830\n",
      "Epoch 3555/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1352217874.8993 - val_loss: 3721089868.6560\n",
      "Epoch 3556/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 953219735.2662 - val_loss: 5885285335.2416\n",
      "Epoch 3557/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1366698936.3286 - val_loss: 5161521617.7328\n",
      "Epoch 3558/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1177123748.9522 - val_loss: 3854881675.8278\n",
      "Epoch 3559/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1008834005.0692 - val_loss: 3923806586.4911\n",
      "Epoch 3560/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1127450574.9826 - val_loss: 5666821072.4006\n",
      "Epoch 3561/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1383031950.0461 - val_loss: 6072796935.4892\n",
      "Epoch 3562/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1169195211.9212 - val_loss: 3806000806.2380\n",
      "Epoch 3563/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1091558562.6111 - val_loss: 3758345471.8020\n",
      "Epoch 3564/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1029939277.5779 - val_loss: 4446383634.6509\n",
      "Epoch 3565/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1241632257.1525 - val_loss: 4802449300.6672\n",
      "Epoch 3566/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1423745585.6657 - val_loss: 5026015648.9091\n",
      "Epoch 3567/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1091646213.4384 - val_loss: 3835714208.1440\n",
      "Epoch 3568/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1691358569.7423 - val_loss: 5284791998.1457\n",
      "Epoch 3569/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 77us/step - loss: 1399224424.7338 - val_loss: 5236368658.5429\n",
      "Epoch 3570/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1246163419.8402 - val_loss: 4727803724.9440\n",
      "Epoch 3571/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1211516852.3669 - val_loss: 3787060918.9266\n",
      "Epoch 3572/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 963830093.3618 - val_loss: 3889686610.4529\n",
      "Epoch 3573/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1120187606.3281 - val_loss: 3732098681.2129\n",
      "Epoch 3574/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1220091435.0929 - val_loss: 3826801617.7328\n",
      "Epoch 3575/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1419679017.8143 - val_loss: 3954061309.9657\n",
      "Epoch 3576/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1122699293.6770 - val_loss: 4776748898.3854\n",
      "Epoch 3577/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1216494850.3230 - val_loss: 3798537198.4473\n",
      "Epoch 3578/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 991443388.6550 - val_loss: 4008879770.4641\n",
      "Epoch 3579/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1135856819.4305 - val_loss: 3837981878.4765\n",
      "Epoch 3580/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1230174707.0343 - val_loss: 5672711636.0731\n",
      "Epoch 3581/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1228583231.5678 - val_loss: 3883514346.5406\n",
      "Epoch 3582/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1251619496.6618 - val_loss: 3804532580.6897\n",
      "Epoch 3583/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1083045239.8965 - val_loss: 4589018914.7814\n",
      "Epoch 3584/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1203897705.4541 - val_loss: 4387101812.1541\n",
      "Epoch 3585/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1056026961.8998 - val_loss: 5838767211.4048\n",
      "Epoch 3586/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1495216035.9077 - val_loss: 3753728639.3519\n",
      "Epoch 3587/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1062966267.6061 - val_loss: 3796911013.6979\n",
      "Epoch 3588/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1086642263.2662 - val_loss: 4748583873.0982\n",
      "Epoch 3589/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1227987020.6415 - val_loss: 7984765981.1646\n",
      "Epoch 3590/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2022218832.8194 - val_loss: 5077381102.2492\n",
      "Epoch 3591/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1181427786.4806 - val_loss: 4422561582.3032\n",
      "Epoch 3592/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1129283059.7546 - val_loss: 4958676821.1533\n",
      "Epoch 3593/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1183883866.2015 - val_loss: 5003418775.7997\n",
      "Epoch 3594/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1025979396.9162 - val_loss: 3905521422.6543\n",
      "Epoch 3595/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1182871395.1154 - val_loss: 4168153712.7696\n",
      "Epoch 3596/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1143787948.0833 - val_loss: 4881511642.0501\n",
      "Epoch 3597/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1130035570.2780 - val_loss: 3974753077.3783\n",
      "Epoch 3598/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1160353139.8267 - val_loss: 4739509536.9091\n",
      "Epoch 3599/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1226570712.0945 - val_loss: 4106598324.3522\n",
      "Epoch 3600/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1308440225.7828 - val_loss: 4342210832.5086\n",
      "Epoch 3601/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1186235990.5819 - val_loss: 5262182185.0104\n",
      "Epoch 3602/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1386858556.0023 - val_loss: 4224768601.7620\n",
      "Epoch 3603/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1148123497.7423 - val_loss: 4804230969.3750\n",
      "Epoch 3604/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1344068660.1508 - val_loss: 3900630825.0824\n",
      "Epoch 3605/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1103124848.7293 - val_loss: 4905279581.7406\n",
      "Epoch 3606/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1200781957.4204 - val_loss: 4438621798.6880\n",
      "Epoch 3607/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1089131519.5678 - val_loss: 4914469848.8619\n",
      "Epoch 3608/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1134298705.3776 - val_loss: 3709309198.4743\n",
      "Epoch 3609/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1067673345.9449 - val_loss: 3648705040.4006\n",
      "Epoch 3610/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1047604605.3348 - val_loss: 3995040595.9921\n",
      "Epoch 3611/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1193965991.0028 - val_loss: 4119143787.3508\n",
      "Epoch 3612/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1121528027.1469 - val_loss: 4442037329.8048\n",
      "Epoch 3613/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1028538756.8261 - val_loss: 4324441285.3468\n",
      "Epoch 3614/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1224075292.0923 - val_loss: 3871800647.7232\n",
      "Epoch 3615/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1087036379.1649 - val_loss: 4098340156.1654\n",
      "Epoch 3616/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1191208767.9640 - val_loss: 6287461044.1001\n",
      "Epoch 3617/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1216655100.3984 - val_loss: 3679564273.1297\n",
      "Epoch 3618/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1169094616.3241 - val_loss: 6241463947.6658\n",
      "Epoch 3619/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1231806988.3894 - val_loss: 4137782181.7159\n",
      "Epoch 3620/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 990151303.0231 - val_loss: 3739193758.2627\n",
      "Epoch 3621/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 942221813.2223 - val_loss: 4156657769.4785\n",
      "Epoch 3622/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1016451282.0619 - val_loss: 4156394066.3179\n",
      "Epoch 3623/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1207153794.5211 - val_loss: 3725047553.3052\n",
      "Epoch 3624/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1100844375.1581 - val_loss: 5033117566.0917\n",
      "Epoch 3625/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1654313145.9854 - val_loss: 3842263878.4720\n",
      "Epoch 3626/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1300385454.9105 - val_loss: 4587554168.2588\n",
      "Epoch 3627/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 992970917.3844 - val_loss: 4379971000.7449\n",
      "Epoch 3628/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1043566627.8627 - val_loss: 6179606495.2349\n",
      "Epoch 3629/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1457394888.7158 - val_loss: 3964881953.3502\n",
      "Epoch 3630/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1039097783.3922 - val_loss: 4041377986.6104\n",
      "Epoch 3631/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1075429707.2009 - val_loss: 3785113114.0501\n",
      "Epoch 3632/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1048451607.9865 - val_loss: 3761547988.2352\n",
      "Epoch 3633/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1328774205.2628 - val_loss: 5581162130.9750\n",
      "Epoch 3634/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 73us/step - loss: 1244491550.2532 - val_loss: 3973016787.2090\n",
      "Epoch 3635/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1060735452.9747 - val_loss: 3903792750.3932\n",
      "Epoch 3636/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1055011668.8711 - val_loss: 5958275590.0129\n",
      "Epoch 3637/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1064238000.2611 - val_loss: 4219349643.9179\n",
      "Epoch 3638/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1154184722.7282 - val_loss: 4069338079.6309\n",
      "Epoch 3639/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 1347833190.1407 - val_loss: 3969951656.7224\n",
      "Epoch 3640/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1355225632.9184 - val_loss: 4126772043.3958\n",
      "Epoch 3641/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1376033171.0884 - val_loss: 5300110642.4799\n",
      "Epoch 3642/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1476013607.0681 - val_loss: 3840298357.3783\n",
      "Epoch 3643/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1243629641.4226 - val_loss: 3596556869.4188\n",
      "Epoch 3644/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1031017596.5763 - val_loss: 3663683249.4807\n",
      "Epoch 3645/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1002747982.3703 - val_loss: 5491532978.9480\n",
      "Epoch 3646/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1275041214.5594 - val_loss: 3522011557.4459\n",
      "Epoch 3647/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1036591659.9392 - val_loss: 4866237651.4070\n",
      "Epoch 3648/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1348047308.4254 - val_loss: 5034323123.5241\n",
      "Epoch 3649/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1188620572.9567 - val_loss: 3565065625.3210\n",
      "Epoch 3650/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 999924619.3360 - val_loss: 4151607269.3558\n",
      "Epoch 3651/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1220518273.3686 - val_loss: 7514640365.8532\n",
      "Epoch 3652/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1660431214.0822 - val_loss: 3777834746.1311\n",
      "Epoch 3653/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1007585286.4828 - val_loss: 4162394443.5398\n",
      "Epoch 3654/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 972615380.4885 - val_loss: 3748355009.9443\n",
      "Epoch 3655/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1005062398.8475 - val_loss: 4531549785.7080\n",
      "Epoch 3656/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1314642220.3557 - val_loss: 5374570276.0776\n",
      "Epoch 3657/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 955151129.5982 - val_loss: 3592964276.6042\n",
      "Epoch 3658/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 954912771.1334 - val_loss: 4016285951.6399\n",
      "Epoch 3659/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1054449973.7344 - val_loss: 3738428967.8942\n",
      "Epoch 3660/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 923732852.2048 - val_loss: 3690813728.3015\n",
      "Epoch 3661/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1036134577.3866 - val_loss: 4031011313.9938\n",
      "Epoch 3662/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1285240835.7817 - val_loss: 4480851628.9710\n",
      "Epoch 3663/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1168067947.7591 - val_loss: 4090520142.3032\n",
      "Epoch 3664/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1244020967.9415 - val_loss: 6450364100.0866\n",
      "Epoch 3665/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1425631202.1069 - val_loss: 3921796428.5300\n",
      "Epoch 3666/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 922985585.1615 - val_loss: 4264895620.7167\n",
      "Epoch 3667/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1106463459.9077 - val_loss: 3907427847.5972\n",
      "Epoch 3668/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1208364570.1474 - val_loss: 4902814050.3314\n",
      "Epoch 3669/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1066000983.0501 - val_loss: 4292076748.8720\n",
      "Epoch 3670/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1276862470.9150 - val_loss: 3959958516.8923\n",
      "Epoch 3671/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1031080439.8604 - val_loss: 3745114300.2914\n",
      "Epoch 3672/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 984595297.3067 - val_loss: 3606285154.2414\n",
      "Epoch 3673/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1292387943.4913 - val_loss: 4228499276.7640\n",
      "Epoch 3674/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1482011438.4963 - val_loss: 3802278710.3595\n",
      "Epoch 3675/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 939170847.8379 - val_loss: 4366636686.3842\n",
      "Epoch 3676/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 954619154.3883 - val_loss: 4764053697.3142\n",
      "Epoch 3677/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1235353017.1210 - val_loss: 4461716813.7722\n",
      "Epoch 3678/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1147106273.7648 - val_loss: 3586391575.7997\n",
      "Epoch 3679/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1125294171.5521 - val_loss: 3897670207.5319\n",
      "Epoch 3680/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1011886783.2797 - val_loss: 4192262606.1682\n",
      "Epoch 3681/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1177123353.9133 - val_loss: 3558617949.5606\n",
      "Epoch 3682/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1066772200.1576 - val_loss: 4510556841.9466\n",
      "Epoch 3683/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1054073951.9460 - val_loss: 3902748272.8956\n",
      "Epoch 3684/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1050142359.6894 - val_loss: 3914329940.8473\n",
      "Epoch 3685/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1800909448.8239 - val_loss: 3989470293.4413\n",
      "Epoch 3686/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1113242883.1244 - val_loss: 3926193479.0031\n",
      "Epoch 3687/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1044177091.3495 - val_loss: 3761019615.4149\n",
      "Epoch 3688/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 992241958.4468 - val_loss: 3996808066.8444\n",
      "Epoch 3689/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1067094011.7501 - val_loss: 5353170986.0186\n",
      "Epoch 3690/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1374492940.7136 - val_loss: 3752114192.3015\n",
      "Epoch 3691/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1068587288.0765 - val_loss: 4262437736.1283\n",
      "Epoch 3692/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 869186416.0003 - val_loss: 3622260674.7184\n",
      "Epoch 3693/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 892285836.6055 - val_loss: 4129705860.5367\n",
      "Epoch 3694/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1289953142.8160 - val_loss: 5549528411.3823\n",
      "Epoch 3695/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1100212416.1261 - val_loss: 3771189694.3617\n",
      "Epoch 3696/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1024576093.3528 - val_loss: 3787599370.7612\n",
      "Epoch 3697/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1077124783.1086 - val_loss: 3816470743.4667\n",
      "Epoch 3698/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1015725688.4367 - val_loss: 3930378712.3218\n",
      "Epoch 3699/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 73us/step - loss: 1212247161.6612 - val_loss: 3817707984.9046\n",
      "Epoch 3700/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1125606645.9156 - val_loss: 3945186342.3460\n",
      "Epoch 3701/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1096694922.7822 - val_loss: 4783729172.7392\n",
      "Epoch 3702/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1117036611.5656 - val_loss: 5251695469.3851\n",
      "Epoch 3703/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1344957237.9741 - val_loss: 3661886189.5966\n",
      "Epoch 3704/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 990444881.0715 - val_loss: 6330028753.1927\n",
      "Epoch 3705/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1556534701.2718 - val_loss: 3529290335.0684\n",
      "Epoch 3706/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1200895012.7631 - val_loss: 4041775590.1120\n",
      "Epoch 3707/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1147439655.3292 - val_loss: 5039696468.2532\n",
      "Epoch 3708/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1419984193.2606 - val_loss: 4075377049.4740\n",
      "Epoch 3709/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 960175333.7085 - val_loss: 5635624255.8740\n",
      "Epoch 3710/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1137657637.7805 - val_loss: 3897516859.0672\n",
      "Epoch 3711/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 896047845.6005 - val_loss: 3998837332.1992\n",
      "Epoch 3712/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 981544046.1362 - val_loss: 3727444573.8307\n",
      "Epoch 3713/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 963412146.8903 - val_loss: 4052005374.4518\n",
      "Epoch 3714/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1079187565.2718 - val_loss: 3740187088.6706\n",
      "Epoch 3715/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1154459926.6899 - val_loss: 3514680835.1685\n",
      "Epoch 3716/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1234163415.4463 - val_loss: 3784599839.4779\n",
      "Epoch 3717/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1043583764.9702 - val_loss: 4031537486.6723\n",
      "Epoch 3718/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1006027101.9291 - val_loss: 4090197922.5294\n",
      "Epoch 3719/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1220493606.7530 - val_loss: 4982606186.8467\n",
      "Epoch 3720/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1985227450.8497 - val_loss: 3935111130.4101\n",
      "Epoch 3721/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1106504479.5543 - val_loss: 3759444002.2143\n",
      "Epoch 3722/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1063077475.7997 - val_loss: 3655112070.2380\n",
      "Epoch 3723/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 918655987.7907 - val_loss: 3582552389.7249\n",
      "Epoch 3724/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 967664880.2791 - val_loss: 3585188993.7643\n",
      "Epoch 3725/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 900590585.9133 - val_loss: 3846412843.7918\n",
      "Epoch 3726/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1080309035.3540 - val_loss: 3578227343.3384\n",
      "Epoch 3727/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 990637161.6342 - val_loss: 3766450427.3283\n",
      "Epoch 3728/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 961983700.3399 - val_loss: 4010289543.8852\n",
      "Epoch 3729/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 836698494.3973 - val_loss: 3834967333.8059\n",
      "Epoch 3730/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1025248008.7698 - val_loss: 4052303977.1994\n",
      "Epoch 3731/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1338746987.9032 - val_loss: 3621537405.0295\n",
      "Epoch 3732/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 957712468.0968 - val_loss: 3628571342.6993\n",
      "Epoch 3733/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 999047411.3225 - val_loss: 3760941536.5671\n",
      "Epoch 3734/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1177499304.9634 - val_loss: 3702571114.2886\n",
      "Epoch 3735/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1015401803.3089 - val_loss: 4135123098.7162\n",
      "Epoch 3736/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1356233741.7130 - val_loss: 3570344758.4045\n",
      "Epoch 3737/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 959913098.8768 - val_loss: 5546425452.3049\n",
      "Epoch 3738/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1938932794.5616 - val_loss: 3743532773.8779\n",
      "Epoch 3739/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1049539107.6916 - val_loss: 3875624742.7060\n",
      "Epoch 3740/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1223452856.2566 - val_loss: 4449486730.5857\n",
      "Epoch 3741/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 955512946.2600 - val_loss: 4101367770.8782\n",
      "Epoch 3742/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 918017385.9223 - val_loss: 3638687477.2163\n",
      "Epoch 3743/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1025267478.4018 - val_loss: 4628888684.6830\n",
      "Epoch 3744/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 967966471.5273 - val_loss: 3824700398.5643\n",
      "Epoch 3745/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1033890398.5774 - val_loss: 4178380800.5131\n",
      "Epoch 3746/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 994999890.3680 - val_loss: 4511880968.1733\n",
      "Epoch 3747/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 939200803.6916 - val_loss: 3566867911.8942\n",
      "Epoch 3748/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1182831593.5622 - val_loss: 4126848859.5983\n",
      "Epoch 3749/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1056422490.2555 - val_loss: 3879030074.6532\n",
      "Epoch 3750/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 947831273.5262 - val_loss: 3479347376.2790\n",
      "Epoch 3751/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 917611192.0405 - val_loss: 5486430700.6650\n",
      "Epoch 3752/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1206136700.0563 - val_loss: 4069909709.2681\n",
      "Epoch 3753/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1218784739.3315 - val_loss: 4534779371.8368\n",
      "Epoch 3754/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1458966451.3585 - val_loss: 3914296247.2686\n",
      "Epoch 3755/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1117420260.2679 - val_loss: 4069323173.2658\n",
      "Epoch 3756/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 996614114.5301 - val_loss: 3604098506.9277\n",
      "Epoch 3757/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 912244085.9336 - val_loss: 3646102801.4065\n",
      "Epoch 3758/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 942791120.7293 - val_loss: 3935663119.3024\n",
      "Epoch 3759/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 962747941.7085 - val_loss: 5025443070.7848\n",
      "Epoch 3760/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1114053683.7907 - val_loss: 6563807326.4068\n",
      "Epoch 3761/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1436479982.6021 - val_loss: 4204730177.4852\n",
      "Epoch 3762/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1259317991.7974 - val_loss: 4230569446.1120\n",
      "Epoch 3763/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1037316976.7293 - val_loss: 3620966469.6709\n",
      "Epoch 3764/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 80us/step - loss: 910152639.2077 - val_loss: 4899973194.8197\n",
      "Epoch 3765/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1094708392.5898 - val_loss: 4933999795.8841\n",
      "Epoch 3766/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1010624135.6714 - val_loss: 3764709413.2118\n",
      "Epoch 3767/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 890642178.5931 - val_loss: 4239214705.5167\n",
      "Epoch 3768/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 979326884.6325 - val_loss: 4145101168.6886\n",
      "Epoch 3769/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 928847716.1958 - val_loss: 3972348980.0281\n",
      "Epoch 3770/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1048841728.9724 - val_loss: 3694198753.5212\n",
      "Epoch 3771/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1084190988.4975 - val_loss: 4192991354.9142\n",
      "Epoch 3772/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1401260721.8458 - val_loss: 3650601308.3364\n",
      "Epoch 3773/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1113177675.3450 - val_loss: 4046282542.4833\n",
      "Epoch 3774/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1266405724.3444 - val_loss: 3727906121.4695\n",
      "Epoch 3775/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1094112434.1339 - val_loss: 3645946437.8509\n",
      "Epoch 3776/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1083022565.2504 - val_loss: 3703955454.9378\n",
      "Epoch 3777/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1069591770.1114 - val_loss: 3700161688.7719\n",
      "Epoch 3778/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1150567599.0366 - val_loss: 6410333828.2847\n",
      "Epoch 3779/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1177836968.9139 - val_loss: 4857527303.3451\n",
      "Epoch 3780/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1277775449.3911 - val_loss: 5804360763.0132\n",
      "Epoch 3781/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 888170809.3371 - val_loss: 3643493689.9511\n",
      "Epoch 3782/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 999950020.0698 - val_loss: 3742320722.9030\n",
      "Epoch 3783/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1021317340.5965 - val_loss: 4965741421.8892\n",
      "Epoch 3784/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1078733989.3483 - val_loss: 4371087292.4354\n",
      "Epoch 3785/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1141456971.4980 - val_loss: 3841058512.4096\n",
      "Epoch 3786/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1298512826.8497 - val_loss: 3937475029.9409\n",
      "Epoch 3787/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1059505411.2414 - val_loss: 4657839267.8436\n",
      "Epoch 3788/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2314831167.6714 - val_loss: 3712659991.7547\n",
      "Epoch 3789/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 908764873.1120 - val_loss: 3791685753.2354\n",
      "Epoch 3790/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 943429994.1294 - val_loss: 3574179804.9755\n",
      "Epoch 3791/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 835023267.7276 - val_loss: 4818507921.0667\n",
      "Epoch 3792/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1290118592.4682 - val_loss: 3668581849.1859\n",
      "Epoch 3793/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1066814119.8694 - val_loss: 4951904711.1111\n",
      "Epoch 3794/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 941925272.5627 - val_loss: 5842000040.1463\n",
      "Epoch 3795/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1063247223.5858 - val_loss: 3684847404.6020\n",
      "Epoch 3796/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 877366369.2786 - val_loss: 4684405656.2318\n",
      "Epoch 3797/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 971547525.5464 - val_loss: 3550454471.3992\n",
      "Epoch 3798/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 952842939.3180 - val_loss: 3588621197.2681\n",
      "Epoch 3799/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1097243442.8002 - val_loss: 3484841158.3955\n",
      "Epoch 3800/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1145248180.4209 - val_loss: 4413045208.3218\n",
      "Epoch 3801/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1036276822.2938 - val_loss: 3804348392.2363\n",
      "Epoch 3802/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1139872281.9133 - val_loss: 3519961444.7077\n",
      "Epoch 3803/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 822438571.0929 - val_loss: 4653318870.4495\n",
      "Epoch 3804/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1170934674.9443 - val_loss: 4717975909.3198\n",
      "Epoch 3805/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1170300541.5509 - val_loss: 6315234644.1812\n",
      "Epoch 3806/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1096047004.3084 - val_loss: 4315791753.0554\n",
      "Epoch 3807/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 965274165.3033 - val_loss: 7997984720.5086\n",
      "Epoch 3808/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2042943188.3489 - val_loss: 3787364459.0807\n",
      "Epoch 3809/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 985861856.3782 - val_loss: 3818556529.9398\n",
      "Epoch 3810/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1072204737.2966 - val_loss: 4007230535.9032\n",
      "Epoch 3811/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 954965185.8368 - val_loss: 4324683196.0574\n",
      "Epoch 3812/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 958749882.0214 - val_loss: 3539406075.1932\n",
      "Epoch 3813/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 891483404.6235 - val_loss: 4013522470.7421\n",
      "Epoch 3814/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1090473756.8059 - val_loss: 3943939323.1392\n",
      "Epoch 3815/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1036891927.9955 - val_loss: 4812104714.5677\n",
      "Epoch 3816/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1165466070.5923 - val_loss: 3543396983.2776\n",
      "Epoch 3817/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 916637387.6331 - val_loss: 3490313442.5564\n",
      "Epoch 3818/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1212408787.3044 - val_loss: 4017838051.3035\n",
      "Epoch 3819/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 880748294.8790 - val_loss: 3453916904.6278\n",
      "Epoch 3820/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 823327277.3078 - val_loss: 4145314338.2053\n",
      "Epoch 3821/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1296819558.4288 - val_loss: 5220613353.1904\n",
      "Epoch 3822/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1522281562.4716 - val_loss: 3776085015.2236\n",
      "Epoch 3823/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 943496411.8402 - val_loss: 3617862304.2250\n",
      "Epoch 3824/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1041549704.7158 - val_loss: 3856343098.6397\n",
      "Epoch 3825/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1254781398.8610 - val_loss: 3970098256.1485\n",
      "Epoch 3826/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 899707683.0073 - val_loss: 4444615256.8079\n",
      "Epoch 3827/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 1096387111.1851 - val_loss: 3997024008.7134\n",
      "Epoch 3828/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1033533944.5087 - val_loss: 4950292104.9654\n",
      "Epoch 3829/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 78us/step - loss: 911783114.4986 - val_loss: 3718427490.4934\n",
      "Epoch 3830/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 876319788.7946 - val_loss: 3542709720.6999\n",
      "Epoch 3831/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1055799431.5993 - val_loss: 4096546325.9994\n",
      "Epoch 3832/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 888854246.5729 - val_loss: 4141364121.2399\n",
      "Epoch 3833/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 942478869.1953 - val_loss: 4288143764.6492\n",
      "Epoch 3834/7000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1038460978.8903 - val_loss: 3609171016.2633\n",
      "Epoch 3835/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1015490572.9657 - val_loss: 9161237341.5426\n",
      "Epoch 3836/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2690787306.7102 - val_loss: 3955274755.7311\n",
      "Epoch 3837/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 964106813.6590 - val_loss: 3585394492.3634\n",
      "Epoch 3838/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1061493558.6179 - val_loss: 4180951274.1266\n",
      "Epoch 3839/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1201260226.5301 - val_loss: 3782229648.9226\n",
      "Epoch 3840/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 865179238.9871 - val_loss: 3385702821.1758\n",
      "Epoch 3841/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 925730458.5796 - val_loss: 4652355115.4228\n",
      "Epoch 3842/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1377440945.5577 - val_loss: 4629254144.2520\n",
      "Epoch 3843/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1096263674.8497 - val_loss: 4061828230.0850\n",
      "Epoch 3844/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1024243839.0636 - val_loss: 3524882110.7218\n",
      "Epoch 3845/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1016213638.3568 - val_loss: 3630092998.1525\n",
      "Epoch 3846/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 931619162.1114 - val_loss: 4009777958.0940\n",
      "Epoch 3847/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 990917018.7327 - val_loss: 3363401472.1350\n",
      "Epoch 3848/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 938478258.1699 - val_loss: 3621065071.7390\n",
      "Epoch 3849/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 979559580.7406 - val_loss: 4119871763.9291\n",
      "Epoch 3850/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 888360382.0191 - val_loss: 3760337486.4203\n",
      "Epoch 3851/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1001014754.0349 - val_loss: 10052132443.4543\n",
      "Epoch 3852/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2052798885.4204 - val_loss: 3915829772.3229\n",
      "Epoch 3853/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 881013360.4772 - val_loss: 3517180385.0082\n",
      "Epoch 3854/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 809479129.1390 - val_loss: 3653111928.9969\n",
      "Epoch 3855/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1093852015.4440 - val_loss: 3613504560.6436\n",
      "Epoch 3856/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 803291414.3298 - val_loss: 6131944570.6352\n",
      "Epoch 3857/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1369083092.0248 - val_loss: 3934472645.6709\n",
      "Epoch 3858/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 935363333.6095 - val_loss: 3628630525.0385\n",
      "Epoch 3859/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 792565595.5881 - val_loss: 3498132175.1044\n",
      "Epoch 3860/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1130583491.6016 - val_loss: 3493568380.2374\n",
      "Epoch 3861/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1000158744.5627 - val_loss: 3694129496.3038\n",
      "Epoch 3862/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 912741721.8953 - val_loss: 5887481027.7266\n",
      "Epoch 3863/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1236619729.1795 - val_loss: 3596406374.7961\n",
      "Epoch 3864/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 914010313.7963 - val_loss: 3609786752.7021\n",
      "Epoch 3865/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 877916707.5836 - val_loss: 3835728617.4605\n",
      "Epoch 3866/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 988320251.7501 - val_loss: 3821474889.3795\n",
      "Epoch 3867/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 962860404.1868 - val_loss: 3483298055.5612\n",
      "Epoch 3868/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 912025211.9617 - val_loss: 3493423482.7837\n",
      "Epoch 3869/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 847597825.7107 - val_loss: 4808587507.7041\n",
      "Epoch 3870/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 978639986.3500 - val_loss: 3459007633.0667\n",
      "Epoch 3871/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 982835844.3219 - val_loss: 4029669214.3887\n",
      "Epoch 3872/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1047631896.0585 - val_loss: 3828293438.3707\n",
      "Epoch 3873/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1400827790.7665 - val_loss: 5035169980.3454\n",
      "Epoch 3874/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1209238830.3523 - val_loss: 3889708941.3581\n",
      "Epoch 3875/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 903409782.0597 - val_loss: 3577954473.6585\n",
      "Epoch 3876/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1022793865.8683 - val_loss: 3748641061.3513\n",
      "Epoch 3877/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 928168367.4508 - val_loss: 4818604014.4293\n",
      "Epoch 3878/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1061245774.2622 - val_loss: 3770319219.0200\n",
      "Epoch 3879/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1133242478.2802 - val_loss: 4930599727.0954\n",
      "Epoch 3880/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1273634048.7023 - val_loss: 3547798899.0830\n",
      "Epoch 3881/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 894889606.6989 - val_loss: 3657359826.1108\n",
      "Epoch 3882/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 956813295.1806 - val_loss: 4440129148.4354\n",
      "Epoch 3883/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1013053072.6393 - val_loss: 6916903056.4186\n",
      "Epoch 3884/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1389477457.6837 - val_loss: 3674733842.6509\n",
      "Epoch 3885/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 826955781.1953 - val_loss: 3684998722.6014\n",
      "Epoch 3886/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1258771301.4024 - val_loss: 5635623894.9536\n",
      "Epoch 3887/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1008917717.2853 - val_loss: 3522903766.4135\n",
      "Epoch 3888/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 813924016.5312 - val_loss: 3364185278.2447\n",
      "Epoch 3889/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 947733604.9162 - val_loss: 3563126412.4219\n",
      "Epoch 3890/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 975162237.4789 - val_loss: 3752220876.8180\n",
      "Epoch 3891/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1263372980.3669 - val_loss: 4461014261.4143\n",
      "Epoch 3892/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1584163010.9173 - val_loss: 3682350108.4444\n",
      "Epoch 3893/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 976389994.0079 - val_loss: 4359253229.0610\n",
      "Epoch 3894/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 79us/step - loss: 853423691.6691 - val_loss: 3663622733.9342\n",
      "Epoch 3895/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 921613363.5611 - val_loss: 5209977711.7615\n",
      "Epoch 3896/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1011462985.5442 - val_loss: 4850544460.0079\n",
      "Epoch 3897/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 1042016062.1452 - val_loss: 3505929161.7665\n",
      "Epoch 3898/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 902922396.1283 - val_loss: 3400737909.0543\n",
      "Epoch 3899/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 887395823.5408 - val_loss: 4043510811.3463\n",
      "Epoch 3900/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 866549902.9826 - val_loss: 3549500511.5139\n",
      "Epoch 3901/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 999744650.7957 - val_loss: 3413760604.7482\n",
      "Epoch 3902/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 886321626.9758 - val_loss: 7621038490.5001\n",
      "Epoch 3903/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1211011674.4716 - val_loss: 4213298290.5699\n",
      "Epoch 3904/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1028174645.0512 - val_loss: 3442775926.9311\n",
      "Epoch 3905/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 867938217.7603 - val_loss: 3688986811.7243\n",
      "Epoch 3906/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 983115545.9313 - val_loss: 4581277615.0594\n",
      "Epoch 3907/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1321070806.4378 - val_loss: 3870654802.6329\n",
      "Epoch 3908/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1007688349.0287 - val_loss: 5422164050.8489\n",
      "Epoch 3909/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1170172931.8897 - val_loss: 3862642536.7944\n",
      "Epoch 3910/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1060562134.7259 - val_loss: 3403134123.4858\n",
      "Epoch 3911/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 768818945.5307 - val_loss: 3546112925.7406\n",
      "Epoch 3912/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 876264641.9088 - val_loss: 4036306792.6864\n",
      "Epoch 3913/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1171250504.6168 - val_loss: 3580634751.1179\n",
      "Epoch 3914/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 874412449.9449 - val_loss: 3471594744.3173\n",
      "Epoch 3915/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 850621603.5476 - val_loss: 5476877250.2864\n",
      "Epoch 3916/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 925227693.2223 - val_loss: 3784550214.5350\n",
      "Epoch 3917/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 926624279.0501 - val_loss: 3653625458.1918\n",
      "Epoch 3918/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 842947233.6387 - val_loss: 5586452606.2357\n",
      "Epoch 3919/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1029115560.8419 - val_loss: 4563097682.2368\n",
      "Epoch 3920/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1068793953.6747 - val_loss: 4337733964.8360\n",
      "Epoch 3921/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1040395302.5729 - val_loss: 3429043845.3468\n",
      "Epoch 3922/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 944751489.3326 - val_loss: 3527403770.1581\n",
      "Epoch 3923/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1114467790.4423 - val_loss: 3531104933.7789\n",
      "Epoch 3924/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 775320882.8903 - val_loss: 4033267234.3134\n",
      "Epoch 3925/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 996525872.5492 - val_loss: 4018398717.7767\n",
      "Epoch 3926/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1076304645.5554 - val_loss: 3536892444.0484\n",
      "Epoch 3927/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 967764361.7243 - val_loss: 5359105596.3814\n",
      "Epoch 3928/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 947578740.2409 - val_loss: 3389003066.4776\n",
      "Epoch 3929/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 841715964.7586 - val_loss: 6784186976.0630\n",
      "Epoch 3930/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1477892389.3303 - val_loss: 3511681035.3688\n",
      "Epoch 3931/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 827049254.3568 - val_loss: 7638673443.5736\n",
      "Epoch 3932/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1037104894.0551 - val_loss: 4478197528.4838\n",
      "Epoch 3933/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1062679286.5639 - val_loss: 5073035568.6436\n",
      "Epoch 3934/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 943293632.3737 - val_loss: 4492647522.9075\n",
      "Epoch 3935/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 969111623.4012 - val_loss: 3582297524.4602\n",
      "Epoch 3936/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 873868659.0343 - val_loss: 4350497055.1449\n",
      "Epoch 3937/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1054610651.4620 - val_loss: 3871771330.2504\n",
      "Epoch 3938/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1143667715.9977 - val_loss: 5589176056.6909\n",
      "Epoch 3939/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1022973602.5391 - val_loss: 3743970122.9367\n",
      "Epoch 3940/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 898584917.2853 - val_loss: 3581293073.3322\n",
      "Epoch 3941/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 947156485.2583 - val_loss: 4175388955.2563\n",
      "Epoch 3942/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1143723198.2082 - val_loss: 3725576019.3530\n",
      "Epoch 3943/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 988823932.2544 - val_loss: 6576249567.0188\n",
      "Epoch 3944/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1258012002.5391 - val_loss: 3514861470.1187\n",
      "Epoch 3945/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1278766726.4603 - val_loss: 3722432691.7401\n",
      "Epoch 3946/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 811234325.4114 - val_loss: 3490350162.1828\n",
      "Epoch 3947/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 810399107.9617 - val_loss: 5397866760.2813\n",
      "Epoch 3948/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 950530146.3590 - val_loss: 3463113799.9415\n",
      "Epoch 3949/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 881789730.0709 - val_loss: 3845735131.6343\n",
      "Epoch 3950/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 975198058.6246 - val_loss: 3660814719.8740\n",
      "Epoch 3951/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 859771981.0737 - val_loss: 4345654840.4388\n",
      "Epoch 3952/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1137291346.9668 - val_loss: 3447891067.1032\n",
      "Epoch 3953/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 728158530.1249 - val_loss: 3544693095.5544\n",
      "Epoch 3954/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1045868889.0670 - val_loss: 3594523223.1156\n",
      "Epoch 3955/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 843851901.9471 - val_loss: 4289000602.6442\n",
      "Epoch 3956/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1204448556.6595 - val_loss: 3500847162.6172\n",
      "Epoch 3957/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 890170534.3568 - val_loss: 3546093713.6968\n",
      "Epoch 3958/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 972718851.9257 - val_loss: 3491828179.6771\n",
      "Epoch 3959/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 77us/step - loss: 791506379.1829 - val_loss: 3684149616.2115\n",
      "Epoch 3960/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1130239342.7124 - val_loss: 4138629112.0068\n",
      "Epoch 3961/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1161292196.7721 - val_loss: 3640840171.2788\n",
      "Epoch 3962/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 884062308.3759 - val_loss: 3573367610.5271\n",
      "Epoch 3963/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 932858034.7102 - val_loss: 3728368895.9820\n",
      "Epoch 3964/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 837039303.2392 - val_loss: 3548864270.9063\n",
      "Epoch 3965/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 983491970.9533 - val_loss: 3645463516.0304\n",
      "Epoch 3966/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1218282774.4738 - val_loss: 4492376681.9286\n",
      "Epoch 3967/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1250620997.1503 - val_loss: 9236223046.2110\n",
      "Epoch 3968/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1392705971.0400 - val_loss: 3534539299.6186\n",
      "Epoch 3969/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 874905293.2898 - val_loss: 3344403015.0346\n",
      "Epoch 3970/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 991759087.0096 - val_loss: 3665682311.9032\n",
      "Epoch 3971/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 805190676.9274 - val_loss: 3372933031.4577\n",
      "Epoch 3972/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1103231022.1722 - val_loss: 3604612798.5688\n",
      "Epoch 3973/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 782400782.6944 - val_loss: 3589753406.5710\n",
      "Epoch 3974/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 967670932.9612 - val_loss: 3702103431.5027\n",
      "Epoch 3975/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1367235460.3219 - val_loss: 3854806421.9994\n",
      "Epoch 3976/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 805424734.2172 - val_loss: 3722114500.2667\n",
      "Epoch 3977/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 834207218.7034 - val_loss: 3561625974.6565\n",
      "Epoch 3978/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 978173727.5858 - val_loss: 4401702341.8329\n",
      "Epoch 3979/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1079965621.6635 - val_loss: 4444392406.5575\n",
      "Epoch 3980/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 868771676.7406 - val_loss: 3330338154.1761\n",
      "Epoch 3981/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 913628223.6398 - val_loss: 3394459171.8706\n",
      "Epoch 3982/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 963243840.9724 - val_loss: 3871797027.8256\n",
      "Epoch 3983/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 875009152.2161 - val_loss: 3850872496.6886\n",
      "Epoch 3984/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1031636719.0006 - val_loss: 4664916172.6560\n",
      "Epoch 3985/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1015086452.4502 - val_loss: 3883484733.1376\n",
      "Epoch 3986/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1082281251.8447 - val_loss: 4480039606.0444\n",
      "Epoch 3987/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 982119699.3405 - val_loss: 3646500740.8608\n",
      "Epoch 3988/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1105659196.2544 - val_loss: 3425417888.4141\n",
      "Epoch 3989/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 813658185.2560 - val_loss: 3522852856.8709\n",
      "Epoch 3990/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 823648726.8340 - val_loss: 3490008363.1977\n",
      "Epoch 3991/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 812978091.3044 - val_loss: 4984933643.7063\n",
      "Epoch 3992/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 852347398.8070 - val_loss: 4526791721.4065\n",
      "Epoch 3993/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 803301281.2065 - val_loss: 3345635472.3826\n",
      "Epoch 3994/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 917459941.8706 - val_loss: 3902182090.0883\n",
      "Epoch 3995/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1234865368.2386 - val_loss: 3552357531.1302\n",
      "Epoch 3996/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1084454885.6815 - val_loss: 3525678857.9556\n",
      "Epoch 3997/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 802434402.6832 - val_loss: 4880263924.4062\n",
      "Epoch 3998/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1315237674.8588 - val_loss: 3842528964.4467\n",
      "Epoch 3999/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 845486512.8014 - val_loss: 3611890714.4641\n",
      "Epoch 4000/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 853763210.8768 - val_loss: 4489676300.2059\n",
      "Epoch 4001/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1076205582.4063 - val_loss: 4412959535.7885\n",
      "Epoch 4002/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 978957288.6978 - val_loss: 3279646402.4844\n",
      "Epoch 4003/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1211872478.1452 - val_loss: 3810673904.0158\n",
      "Epoch 4004/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1024700371.3585 - val_loss: 3274811731.5612\n",
      "Epoch 4005/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1025164189.8931 - val_loss: 4112331833.7215\n",
      "Epoch 4006/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 861061446.1227 - val_loss: 3754296991.9370\n",
      "Epoch 4007/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 848311074.2870 - val_loss: 3672406684.1924\n",
      "Epoch 4008/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 960868228.4660 - val_loss: 3325805781.4729\n",
      "Epoch 4009/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1017712219.4800 - val_loss: 3464861452.4940\n",
      "Epoch 4010/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 922357338.8137 - val_loss: 3674303535.7435\n",
      "Epoch 4011/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 716858778.7597 - val_loss: 4038965501.7316\n",
      "Epoch 4012/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 839593261.0197 - val_loss: 3874335660.0349\n",
      "Epoch 4013/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 929983400.8419 - val_loss: 4355217107.5511\n",
      "Epoch 4014/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 860758087.5273 - val_loss: 3368487010.8805\n",
      "Epoch 4015/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 944245914.2195 - val_loss: 3561780687.3564\n",
      "Epoch 4016/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1102145512.5898 - val_loss: 4102256500.8023\n",
      "Epoch 4017/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 934061474.2150 - val_loss: 6635557991.5522\n",
      "Epoch 4018/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1099947017.8008 - val_loss: 3350506254.8883\n",
      "Epoch 4019/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 760067047.7254 - val_loss: 3617111369.2264\n",
      "Epoch 4020/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 877950995.8087 - val_loss: 3782284315.3643\n",
      "Epoch 4021/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 882053472.3782 - val_loss: 3756161601.8543\n",
      "Epoch 4022/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 943064638.3073 - val_loss: 3875505606.7826\n",
      "Epoch 4023/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1083788708.9972 - val_loss: 3357265852.3859\n",
      "Epoch 4024/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 81us/step - loss: 807928921.5712 - val_loss: 3637056902.9131\n",
      "Epoch 4025/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 905980455.9055 - val_loss: 3700803632.8709\n",
      "Epoch 4026/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1365462779.8222 - val_loss: 3710866537.7845\n",
      "Epoch 4027/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 902088618.9308 - val_loss: 3536146384.2228\n",
      "Epoch 4028/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 970872445.9831 - val_loss: 3827279879.7772\n",
      "Epoch 4029/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1110340134.8430 - val_loss: 3315078604.2059\n",
      "Epoch 4030/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 820844134.8610 - val_loss: 9129520521.4695\n",
      "Epoch 4031/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1479684945.0895 - val_loss: 4849218474.2526\n",
      "Epoch 4032/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 966024209.8784 - val_loss: 3493224883.9201\n",
      "Epoch 4033/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 849780287.6759 - val_loss: 4242326535.2371\n",
      "Epoch 4034/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 850253633.3326 - val_loss: 3827595896.2273\n",
      "Epoch 4035/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 849395036.6325 - val_loss: 3691023128.8079\n",
      "Epoch 4036/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 834533027.8717 - val_loss: 3389348852.4872\n",
      "Epoch 4037/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 838958946.1429 - val_loss: 3430119751.8312\n",
      "Epoch 4038/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 901935529.1840 - val_loss: 4632323135.8200\n",
      "Epoch 4039/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1020932775.6624 - val_loss: 3562888206.9783\n",
      "Epoch 4040/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 922751320.5627 - val_loss: 3758641514.9187\n",
      "Epoch 4041/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 906064910.4783 - val_loss: 4114245359.3474\n",
      "Epoch 4042/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 996793293.4564 - val_loss: 3605029009.6124\n",
      "Epoch 4043/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 927410382.4963 - val_loss: 3789334125.8937\n",
      "Epoch 4044/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 803276317.3168 - val_loss: 3721230155.0357\n",
      "Epoch 4045/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 928916483.4575 - val_loss: 3375939580.6425\n",
      "Epoch 4046/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 809221362.9668 - val_loss: 3388649120.3646\n",
      "Epoch 4047/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1027385746.5121 - val_loss: 3614999472.8686\n",
      "Epoch 4048/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1129573898.0304 - val_loss: 3897933342.5688\n",
      "Epoch 4049/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 969650777.4631 - val_loss: 3300593201.1612\n",
      "Epoch 4050/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 833144367.0366 - val_loss: 3359511834.4461\n",
      "Epoch 4051/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 952272290.5751 - val_loss: 5129220894.8208\n",
      "Epoch 4052/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 932820568.7428 - val_loss: 3617495701.6304\n",
      "Epoch 4053/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 855604428.4615 - val_loss: 3303342012.4940\n",
      "Epoch 4054/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1162280366.4603 - val_loss: 3676467969.8363\n",
      "Epoch 4055/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 791732022.7530 - val_loss: 3330394166.2245\n",
      "Epoch 4056/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 978388330.6066 - val_loss: 3506637358.6093\n",
      "Epoch 4057/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 877738813.2268 - val_loss: 3532696814.6453\n",
      "Epoch 4058/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 968072616.2656 - val_loss: 6076004786.0838\n",
      "Epoch 4059/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 923771086.1902 - val_loss: 3958927668.9643\n",
      "Epoch 4060/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 813791166.9375 - val_loss: 4609534076.0394\n",
      "Epoch 4061/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1044271785.5892 - val_loss: 3311094678.6475\n",
      "Epoch 4062/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 762490037.0872 - val_loss: 3437561504.2790\n",
      "Epoch 4063/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 916683782.1227 - val_loss: 8658123213.3041\n",
      "Epoch 4064/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1297628904.5177 - val_loss: 3891203415.2776\n",
      "Epoch 4065/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1263445294.1002 - val_loss: 3897763236.1226\n",
      "Epoch 4066/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 819927555.2054 - val_loss: 3995374787.4205\n",
      "Epoch 4067/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 1280678975.0996 - val_loss: 3362372402.8399\n",
      "Epoch 4068/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 817499337.6522 - val_loss: 3282194720.7381\n",
      "Epoch 4069/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 740715289.0670 - val_loss: 3944945024.2453\n",
      "Epoch 4070/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 763024534.2577 - val_loss: 3269070416.8416\n",
      "Epoch 4071/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 784944991.6579 - val_loss: 3425307796.4782\n",
      "Epoch 4072/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 994488274.1519 - val_loss: 3485961743.3744\n",
      "Epoch 4073/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1100381112.5267 - val_loss: 3482042984.4163\n",
      "Epoch 4074/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 783025900.9927 - val_loss: 3423978379.6478\n",
      "Epoch 4075/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 753518787.6196 - val_loss: 3379985163.8098\n",
      "Epoch 4076/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 842493270.3298 - val_loss: 3496988482.8456\n",
      "Epoch 4077/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 833990054.3717 - val_loss: 3270771751.6782\n",
      "Epoch 4078/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 851803948.1486 - val_loss: 3682075464.5873\n",
      "Epoch 4079/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 902226187.2549 - val_loss: 3790045900.8900\n",
      "Epoch 4080/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 774033072.8374 - val_loss: 3371335920.9496\n",
      "Epoch 4081/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1032069321.2560 - val_loss: 3312634235.8053\n",
      "Epoch 4082/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1020622262.9600 - val_loss: 3862108441.0959\n",
      "Epoch 4083/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1536720184.9049 - val_loss: 3321423259.8864\n",
      "Epoch 4084/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 869716270.8205 - val_loss: 4019483789.0160\n",
      "Epoch 4085/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1413474594.7912 - val_loss: 3885148174.3302\n",
      "Epoch 4086/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1103568303.1491 - val_loss: 3687308013.9612\n",
      "Epoch 4087/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 751002308.6100 - val_loss: 3248108639.6309\n",
      "Epoch 4088/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 917014922.7710 - val_loss: 3885828189.8127\n",
      "Epoch 4089/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 72us/step - loss: 842398174.0011 - val_loss: 3769488252.7235\n",
      "Epoch 4090/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 900826552.5898 - val_loss: 3518760004.0146\n",
      "Epoch 4091/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 745374667.0929 - val_loss: 3348491820.9530\n",
      "Epoch 4092/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 850083454.1992 - val_loss: 3385693846.5665\n",
      "Epoch 4093/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 852531085.7940 - val_loss: 3462118173.8937\n",
      "Epoch 4094/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 1105198175.3697 - val_loss: 6443963097.5820\n",
      "Epoch 4095/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 868267252.4389 - val_loss: 4265922914.3854\n",
      "Epoch 4096/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 981821652.2409 - val_loss: 3324647615.5814\n",
      "Epoch 4097/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 728757747.7546 - val_loss: 3475888009.0554\n",
      "Epoch 4098/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1005958077.9111 - val_loss: 4310860327.2101\n",
      "Epoch 4099/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1031429133.0017 - val_loss: 3589757801.5505\n",
      "Epoch 4100/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 829524187.9496 - val_loss: 3358847821.1601\n",
      "Epoch 4101/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 859951573.2133 - val_loss: 3968176696.2228\n",
      "Epoch 4102/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1000342113.6387 - val_loss: 3317860984.5288\n",
      "Epoch 4103/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 717690945.1165 - val_loss: 3203986775.4127\n",
      "Epoch 4104/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 964217421.6140 - val_loss: 3391130450.5384\n",
      "Epoch 4105/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1129555654.3388 - val_loss: 4089330911.9010\n",
      "Epoch 4106/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 953272248.0045 - val_loss: 3513999708.0405\n",
      "Epoch 4107/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1002172971.8312 - val_loss: 5976374610.7769\n",
      "Epoch 4108/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1175242099.3945 - val_loss: 3645435479.8537\n",
      "Epoch 4109/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1015749133.6860 - val_loss: 6262464406.5755\n",
      "Epoch 4110/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1015743883.5971 - val_loss: 3588030298.8242\n",
      "Epoch 4111/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 875802917.3483 - val_loss: 3719240213.1893\n",
      "Epoch 4112/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 970041390.2442 - val_loss: 3905728474.1941\n",
      "Epoch 4113/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 788450841.9313 - val_loss: 3950001996.6020\n",
      "Epoch 4114/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 822408618.2825 - val_loss: 4965451931.2923\n",
      "Epoch 4115/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 862421003.4080 - val_loss: 3433390863.2799\n",
      "Epoch 4116/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 710215809.3641 - val_loss: 3535981399.7997\n",
      "Epoch 4117/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 782895415.7884 - val_loss: 3495540814.6363\n",
      "Epoch 4118/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 858846141.5869 - val_loss: 3626973860.0011\n",
      "Epoch 4119/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 864536550.6809 - val_loss: 4093629657.0419\n",
      "Epoch 4120/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 835593576.6438 - val_loss: 3358315540.6042\n",
      "Epoch 4121/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 814570954.8895 - val_loss: 3436280324.0326\n",
      "Epoch 4122/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 801950945.3056 - val_loss: 4754541172.8383\n",
      "Epoch 4123/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 859722622.3793 - val_loss: 4183270492.6425\n",
      "Epoch 4124/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 853091654.5999 - val_loss: 3549947336.3713\n",
      "Epoch 4125/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 779331534.6584 - val_loss: 3449005929.2444\n",
      "Epoch 4126/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 951484390.3658 - val_loss: 3899538340.6357\n",
      "Epoch 4127/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 744596018.6021 - val_loss: 3705437100.1969\n",
      "Epoch 4128/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 911176883.3945 - val_loss: 3524272708.5817\n",
      "Epoch 4129/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 892309679.9010 - val_loss: 3697507499.7918\n",
      "Epoch 4130/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1483437967.4868 - val_loss: 4316524448.7246\n",
      "Epoch 4131/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 924995109.2403 - val_loss: 3702859970.7364\n",
      "Epoch 4132/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1120955028.6730 - val_loss: 4634141940.7302\n",
      "Epoch 4133/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1328774448.2003 - val_loss: 3417009579.2608\n",
      "Epoch 4134/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 954432944.4862 - val_loss: 3318056822.0624\n",
      "Epoch 4135/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 738857382.3748 - val_loss: 3235979368.9564\n",
      "Epoch 4136/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 829642914.0709 - val_loss: 3689308669.7091\n",
      "Epoch 4137/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 827731712.8464 - val_loss: 3983809529.2759\n",
      "Epoch 4138/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 828471820.8216 - val_loss: 3337793048.7426\n",
      "Epoch 4139/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 978691837.6230 - val_loss: 4015442776.6819\n",
      "Epoch 4140/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1135462417.1885 - val_loss: 3214963919.8425\n",
      "Epoch 4141/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 845646518.8880 - val_loss: 3814884249.7530\n",
      "Epoch 4142/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 821079384.7428 - val_loss: 3611051093.4774\n",
      "Epoch 4143/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 818947798.0777 - val_loss: 3367493070.1862\n",
      "Epoch 4144/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 814485171.5746 - val_loss: 3334803447.3767\n",
      "Epoch 4145/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 961087698.6922 - val_loss: 4265379883.4948\n",
      "Epoch 4146/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 838847632.2431 - val_loss: 3268045211.8323\n",
      "Epoch 4147/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 718618268.2003 - val_loss: 3178816072.3162\n",
      "Epoch 4148/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 774713064.5898 - val_loss: 4456534324.5322\n",
      "Epoch 4149/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 834718588.9409 - val_loss: 3331435908.7167\n",
      "Epoch 4150/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 787309124.5200 - val_loss: 4087923723.4498\n",
      "Epoch 4151/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 853903993.6612 - val_loss: 4106341098.5046\n",
      "Epoch 4152/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1020902444.9837 - val_loss: 3349454189.7451\n",
      "Epoch 4153/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 851679039.1176 - val_loss: 3491454838.6025\n",
      "Epoch 4154/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 75us/step - loss: 968649041.2696 - val_loss: 3687506057.6135\n",
      "Epoch 4155/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 956719479.0681 - val_loss: 3561948524.3589\n",
      "Epoch 4156/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 995673666.9398 - val_loss: 3642518264.8709\n",
      "Epoch 4157/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 757182408.9437 - val_loss: 3284364768.9541\n",
      "Epoch 4158/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 761150761.0580 - val_loss: 3346022497.8273\n",
      "Epoch 4159/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1054432406.9781 - val_loss: 4229102355.0470\n",
      "Epoch 4160/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1173022711.6443 - val_loss: 3788388698.8062\n",
      "Epoch 4161/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 818381643.6331 - val_loss: 7220001389.3131\n",
      "Epoch 4162/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1248626312.2836 - val_loss: 3527538382.1232\n",
      "Epoch 4163/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 740769811.5115 - val_loss: 3646776747.2968\n",
      "Epoch 4164/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 982726680.8509 - val_loss: 4073489856.8101\n",
      "Epoch 4165/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 989703367.1311 - val_loss: 3264448689.4897\n",
      "Epoch 4166/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 777752964.0338 - val_loss: 3474634276.7977\n",
      "Epoch 4167/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 753971499.0208 - val_loss: 3425495708.0304\n",
      "Epoch 4168/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 855439559.8154 - val_loss: 4509421243.6523\n",
      "Epoch 4169/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 882969308.4885 - val_loss: 3882874639.2664\n",
      "Epoch 4170/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 822875063.3922 - val_loss: 3422841199.4734\n",
      "Epoch 4171/7000\n",
      "3554/3554 [==============================] - 0s 68us/step - loss: 730901588.9612 - val_loss: 3463717030.9041\n",
      "Epoch 4172/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1070131749.3483 - val_loss: 3385134040.1845\n",
      "Epoch 4173/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 788703204.2769 - val_loss: 4090655108.6267\n",
      "Epoch 4174/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 866414240.8284 - val_loss: 3698030791.0391\n",
      "Epoch 4175/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 848733662.3613 - val_loss: 4202268004.0956\n",
      "Epoch 4176/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 798447012.2476 - val_loss: 3264475907.2585\n",
      "Epoch 4177/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 949871665.5577 - val_loss: 5896139600.6526\n",
      "Epoch 4178/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1259762581.6815 - val_loss: 3254209085.3941\n",
      "Epoch 4179/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 955077253.0422 - val_loss: 3597002226.6239\n",
      "Epoch 4180/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1338060125.6410 - val_loss: 3683056299.2248\n",
      "Epoch 4181/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1093098821.0062 - val_loss: 4988853861.3558\n",
      "Epoch 4182/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1125195085.2268 - val_loss: 3840500963.7986\n",
      "Epoch 4183/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 747026584.4907 - val_loss: 3384867625.9286\n",
      "Epoch 4184/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 853401918.1632 - val_loss: 3363849220.0371\n",
      "Epoch 4185/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 860166044.1283 - val_loss: 4250840207.7004\n",
      "Epoch 4186/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 863885241.3011 - val_loss: 3617230807.5117\n",
      "Epoch 4187/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 848713921.9088 - val_loss: 3503146082.1513\n",
      "Epoch 4188/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 838857661.8503 - val_loss: 3531035731.1910\n",
      "Epoch 4189/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 692624554.5526 - val_loss: 3873791853.0610\n",
      "Epoch 4190/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 857423751.7074 - val_loss: 3402143158.2065\n",
      "Epoch 4191/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 725683713.7017 - val_loss: 3211767966.8658\n",
      "Epoch 4192/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 760729636.4479 - val_loss: 5751094316.2149\n",
      "Epoch 4193/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 970754061.3979 - val_loss: 3767576059.0132\n",
      "Epoch 4194/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 886687623.9235 - val_loss: 3685341931.0537\n",
      "Epoch 4195/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1057748154.8182 - val_loss: 3318442403.9966\n",
      "Epoch 4196/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 693331324.4164 - val_loss: 3218690539.6838\n",
      "Epoch 4197/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 799887449.2290 - val_loss: 3400136965.2748\n",
      "Epoch 4198/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 793316909.0917 - val_loss: 3731656862.6138\n",
      "Epoch 4199/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 970541941.1953 - val_loss: 3758639529.5505\n",
      "Epoch 4200/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1069807453.6410 - val_loss: 3748131479.1966\n",
      "Epoch 4201/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1062182575.3967 - val_loss: 3554759549.3536\n",
      "Epoch 4202/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1113872825.6252 - val_loss: 3712987790.0692\n",
      "Epoch 4203/7000\n",
      "3554/3554 [==============================] - 0s 66us/step - loss: 1021708623.5318 - val_loss: 3880440128.3601\n",
      "Epoch 4204/7000\n",
      "3554/3554 [==============================] - 0s 68us/step - loss: 832370008.5988 - val_loss: 3748574835.8233\n",
      "Epoch 4205/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 783600256.5853 - val_loss: 3946241754.0501\n",
      "Epoch 4206/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 853578517.7535 - val_loss: 4169848769.9263\n",
      "Epoch 4207/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 852925849.1390 - val_loss: 3905860716.9350\n",
      "Epoch 4208/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 859077432.5087 - val_loss: 3153581429.6866\n",
      "Epoch 4209/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 723350724.0338 - val_loss: 4103104723.2270\n",
      "Epoch 4210/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1382857385.9944 - val_loss: 3295413499.8954\n",
      "Epoch 4211/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 750094091.8582 - val_loss: 3679562510.7083\n",
      "Epoch 4212/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 717716293.2853 - val_loss: 3285762434.6194\n",
      "Epoch 4213/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 748463204.4119 - val_loss: 4449303156.0101\n",
      "Epoch 4214/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 808705652.3579 - val_loss: 3449735527.0661\n",
      "Epoch 4215/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 836277802.0664 - val_loss: 3730473277.2433\n",
      "Epoch 4216/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1117424723.1964 - val_loss: 3684064741.6529\n",
      "Epoch 4217/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 716475720.8959 - val_loss: 3554157934.7173\n",
      "Epoch 4218/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 749113282.4851 - val_loss: 4012071817.0374\n",
      "Epoch 4219/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 74us/step - loss: 917413949.2988 - val_loss: 3913141184.0180\n",
      "Epoch 4220/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 915535010.0934 - val_loss: 3697286033.6068\n",
      "Epoch 4221/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 801550904.7068 - val_loss: 3396630861.9882\n",
      "Epoch 4222/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 759290706.9600 - val_loss: 3440154247.8560\n",
      "Epoch 4223/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 990283016.2836 - val_loss: 3316481657.5550\n",
      "Epoch 4224/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 755662826.3365 - val_loss: 3524146637.1601\n",
      "Epoch 4225/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 882872376.3286 - val_loss: 3754615599.7975\n",
      "Epoch 4226/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1059318210.5616 - val_loss: 3226060122.1581\n",
      "Epoch 4227/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 752528060.2409 - val_loss: 3178094034.3989\n",
      "Epoch 4228/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 719124487.9482 - val_loss: 3286885153.3187\n",
      "Epoch 4229/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 788890786.4671 - val_loss: 6986351842.5834\n",
      "Epoch 4230/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 1133888224.2341 - val_loss: 3301436977.1477\n",
      "Epoch 4231/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 808640628.9792 - val_loss: 4361917661.4886\n",
      "Epoch 4232/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 955740605.8751 - val_loss: 4310320814.9153\n",
      "Epoch 4233/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 808763307.1109 - val_loss: 4413757870.3032\n",
      "Epoch 4234/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 900599027.6106 - val_loss: 3932115056.4456\n",
      "Epoch 4235/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 771194308.5020 - val_loss: 5782567373.1781\n",
      "Epoch 4236/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 948296617.2020 - val_loss: 3915970393.9241\n",
      "Epoch 4237/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 903319010.2150 - val_loss: 5359621983.7030\n",
      "Epoch 4238/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 853005457.8728 - val_loss: 3142340521.5595\n",
      "Epoch 4239/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 943338263.7704 - val_loss: 5264396346.1356\n",
      "Epoch 4240/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2064499814.2870 - val_loss: 3852903066.8062\n",
      "Epoch 4241/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 793334858.8047 - val_loss: 3464575422.5958\n",
      "Epoch 4242/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 756073567.1626 - val_loss: 3316651336.4073\n",
      "Epoch 4243/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 721335670.3478 - val_loss: 3911150030.0242\n",
      "Epoch 4244/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1006743258.4716 - val_loss: 3375119574.1795\n",
      "Epoch 4245/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 865298438.4378 - val_loss: 3635516084.3792\n",
      "Epoch 4246/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 891357487.3247 - val_loss: 4308896981.0813\n",
      "Epoch 4247/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 953356002.9713 - val_loss: 3331921145.2489\n",
      "Epoch 4248/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 802235252.7631 - val_loss: 3360266539.6388\n",
      "Epoch 4249/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 740915346.5121 - val_loss: 3463527441.9848\n",
      "Epoch 4250/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 694347901.5059 - val_loss: 3169846261.0543\n",
      "Epoch 4251/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1143496447.3517 - val_loss: 4290113232.4006\n",
      "Epoch 4252/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 884554538.8703 - val_loss: 3217602006.4810\n",
      "Epoch 4253/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 673143422.1452 - val_loss: 3520933138.4169\n",
      "Epoch 4254/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 818545230.1902 - val_loss: 3276177589.7564\n",
      "Epoch 4255/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 740449752.7428 - val_loss: 3241434241.3142\n",
      "Epoch 4256/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 820264107.1469 - val_loss: 3429329804.2059\n",
      "Epoch 4257/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 908015159.9325 - val_loss: 3326276871.6917\n",
      "Epoch 4258/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 891110574.1722 - val_loss: 3634968168.8304\n",
      "Epoch 4259/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 959098462.5774 - val_loss: 3773984350.4068\n",
      "Epoch 4260/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 751251176.5537 - val_loss: 3281992348.9961\n",
      "Epoch 4261/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 745242954.9308 - val_loss: 3241390591.7480\n",
      "Epoch 4262/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 773186492.7226 - val_loss: 4689936372.8383\n",
      "Epoch 4263/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1560556782.5504 - val_loss: 3372154760.0293\n",
      "Epoch 4264/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1002531821.4519 - val_loss: 3639191084.2869\n",
      "Epoch 4265/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 681822269.7310 - val_loss: 3458030017.4402\n",
      "Epoch 4266/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 964014603.0568 - val_loss: 3251675605.8329\n",
      "Epoch 4267/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 711846087.5273 - val_loss: 3776568599.9280\n",
      "Epoch 4268/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 765207656.1936 - val_loss: 3165652767.2574\n",
      "Epoch 4269/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 786489534.8340 - val_loss: 3615503150.7353\n",
      "Epoch 4270/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 850483501.7963 - val_loss: 3577368129.8183\n",
      "Epoch 4271/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 753439237.6995 - val_loss: 3240607829.4954\n",
      "Epoch 4272/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 691501770.8407 - val_loss: 3759220684.2869\n",
      "Epoch 4273/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 775366706.4401 - val_loss: 3294546581.6574\n",
      "Epoch 4274/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 907644248.1666 - val_loss: 4455814930.7443\n",
      "Epoch 4275/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 1383244694.7890 - val_loss: 3968719765.9994\n",
      "Epoch 4276/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 711820914.6472 - val_loss: 3162615898.5902\n",
      "Epoch 4277/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1086942980.8981 - val_loss: 3481418172.6785\n",
      "Epoch 4278/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 759404799.0636 - val_loss: 3513543233.7283\n",
      "Epoch 4279/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 785025270.2037 - val_loss: 3801314194.8850\n",
      "Epoch 4280/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 688968583.4733 - val_loss: 3185498067.6276\n",
      "Epoch 4281/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 735779490.2870 - val_loss: 3153279114.1896\n",
      "Epoch 4282/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 850626062.7124 - val_loss: 3230369498.2661\n",
      "Epoch 4283/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 725496209.7558 - val_loss: 3225486768.8731\n",
      "Epoch 4284/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 74us/step - loss: 732140058.7237 - val_loss: 3392568564.7842\n",
      "Epoch 4285/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 987976171.7231 - val_loss: 3402380129.5932\n",
      "Epoch 4286/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 774921878.2082 - val_loss: 4705466620.2914\n",
      "Epoch 4287/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 956980184.2746 - val_loss: 5550135168.1080\n",
      "Epoch 4288/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 756778863.6669 - val_loss: 3381479720.3758\n",
      "Epoch 4289/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 723822795.1649 - val_loss: 3973393816.4838\n",
      "Epoch 4290/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 755955736.2026 - val_loss: 3401152758.2875\n",
      "Epoch 4291/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 759085037.0557 - val_loss: 4131902812.2824\n",
      "Epoch 4292/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1035272481.2786 - val_loss: 6371212493.1241\n",
      "Epoch 4293/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 902044021.0512 - val_loss: 3208493953.5212\n",
      "Epoch 4294/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 773031105.9809 - val_loss: 3829004948.7752\n",
      "Epoch 4295/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 861662317.9921 - val_loss: 3436796532.7122\n",
      "Epoch 4296/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 928431358.6235 - val_loss: 3338694638.1412\n",
      "Epoch 4297/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 738307210.2285 - val_loss: 3209964510.1817\n",
      "Epoch 4298/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 623534179.8357 - val_loss: 4161550309.7271\n",
      "Epoch 4299/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1080591778.6472 - val_loss: 4367288670.4968\n",
      "Epoch 4300/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 957687725.8751 - val_loss: 4446886201.0509\n",
      "Epoch 4301/7000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 981548774.2487 - val_loss: 3200109794.1063\n",
      "Epoch 4302/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 698954652.8216 - val_loss: 3337779163.5533\n",
      "Epoch 4303/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 690407755.5791 - val_loss: 3320270327.7367\n",
      "Epoch 4304/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 744927147.5431 - val_loss: 4677041995.4318\n",
      "Epoch 4305/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 959535044.5200 - val_loss: 3248522518.5755\n",
      "Epoch 4306/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 774211785.2651 - val_loss: 3202406494.0557\n",
      "Epoch 4307/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 726296349.1007 - val_loss: 3386166583.1426\n",
      "Epoch 4308/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 757483412.1958 - val_loss: 3543073340.8135\n",
      "Epoch 4309/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 763853598.2532 - val_loss: 4422435475.1190\n",
      "Epoch 4310/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 782874127.9370 - val_loss: 3275144286.4788\n",
      "Epoch 4311/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 693327820.5695 - val_loss: 3448642797.4616\n",
      "Epoch 4312/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 866603075.9437 - val_loss: 3456657046.4225\n",
      "Epoch 4313/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 812072410.4356 - val_loss: 3295200314.9232\n",
      "Epoch 4314/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1178458288.0214 - val_loss: 3195526023.8942\n",
      "Epoch 4315/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1005272568.4727 - val_loss: 3426236019.6861\n",
      "Epoch 4316/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 835647630.1002 - val_loss: 3182654986.8917\n",
      "Epoch 4317/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 733260157.1908 - val_loss: 4009259874.0613\n",
      "Epoch 4318/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 837289223.0321 - val_loss: 3108580352.8281\n",
      "Epoch 4319/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 721190159.8109 - val_loss: 4918879565.2681\n",
      "Epoch 4320/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1011606477.7580 - val_loss: 3483256650.2616\n",
      "Epoch 4321/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 873490832.2701 - val_loss: 3372092955.2563\n",
      "Epoch 4322/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 685544134.8520 - val_loss: 3440821715.1190\n",
      "Epoch 4323/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 653274947.7456 - val_loss: 4379514173.3896\n",
      "Epoch 4324/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 773093073.0715 - val_loss: 3313104264.2172\n",
      "Epoch 4325/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 711731617.8953 - val_loss: 3303955672.5288\n",
      "Epoch 4326/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 746522274.2870 - val_loss: 3812613341.1826\n",
      "Epoch 4327/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 831519181.7580 - val_loss: 3308417062.8681\n",
      "Epoch 4328/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1036051137.4766 - val_loss: 4082788990.5238\n",
      "Epoch 4329/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 816402732.3061 - val_loss: 3246177869.2321\n",
      "Epoch 4330/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 692105435.2639 - val_loss: 3466387640.6549\n",
      "Epoch 4331/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 805201396.5020 - val_loss: 3928357918.3167\n",
      "Epoch 4332/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 732799665.6297 - val_loss: 3506567036.9305\n",
      "Epoch 4333/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 810703669.6635 - val_loss: 3228389634.5294\n",
      "Epoch 4334/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 985503021.5239 - val_loss: 4248685211.9404\n",
      "Epoch 4335/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 832427271.8210 - val_loss: 3533877596.3634\n",
      "Epoch 4336/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 872349345.9989 - val_loss: 3893197741.1331\n",
      "Epoch 4337/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 840012658.9983 - val_loss: 3458240733.3086\n",
      "Epoch 4338/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 761120314.2735 - val_loss: 3457350329.7890\n",
      "Epoch 4339/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 698424780.3084 - val_loss: 3358448131.4068\n",
      "Epoch 4340/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 800882056.7968 - val_loss: 3766471874.6644\n",
      "Epoch 4341/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 811698127.9100 - val_loss: 3583326233.9871\n",
      "Epoch 4342/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 888023110.8790 - val_loss: 3644502215.8672\n",
      "Epoch 4343/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 908269154.3950 - val_loss: 3513226838.2515\n",
      "Epoch 4344/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 679885978.2195 - val_loss: 3763560137.9556\n",
      "Epoch 4345/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 835469510.7980 - val_loss: 3197597392.7516\n",
      "Epoch 4346/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 708395924.4750 - val_loss: 3457529195.9449\n",
      "Epoch 4347/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 763582901.7313 - val_loss: 3481932770.9075\n",
      "Epoch 4348/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 750388426.4086 - val_loss: 3234143889.9218\n",
      "Epoch 4349/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 73us/step - loss: 909707419.1559 - val_loss: 3549805478.4360\n",
      "Epoch 4350/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1007247444.3489 - val_loss: 3203930286.1952\n",
      "Epoch 4351/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 667512130.4491 - val_loss: 3318438122.1806\n",
      "Epoch 4352/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 677685915.1559 - val_loss: 3965414917.7609\n",
      "Epoch 4353/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 802145615.1446 - val_loss: 3107274900.0979\n",
      "Epoch 4354/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 665593653.5914 - val_loss: 3965828026.1851\n",
      "Epoch 4355/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 780974702.2983 - val_loss: 3364636175.8605\n",
      "Epoch 4356/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 803118538.2285 - val_loss: 3595686358.7196\n",
      "Epoch 4357/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 900487941.9786 - val_loss: 3248283734.2965\n",
      "Epoch 4358/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 828289569.8852 - val_loss: 4333614416.8506\n",
      "Epoch 4359/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 797153173.3213 - val_loss: 3157612135.8132\n",
      "Epoch 4360/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 698458429.0467 - val_loss: 3483327484.9755\n",
      "Epoch 4361/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 964111419.5701 - val_loss: 5562493489.6158\n",
      "Epoch 4362/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1053048052.6911 - val_loss: 3361104878.0872\n",
      "Epoch 4363/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 732915785.8503 - val_loss: 3253258438.4720\n",
      "Epoch 4364/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 736060586.7147 - val_loss: 3275994364.8225\n",
      "Epoch 4365/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 698278468.1733 - val_loss: 3376332076.3049\n",
      "Epoch 4366/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 843160787.6286 - val_loss: 3747528454.5890\n",
      "Epoch 4367/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 956311882.5526 - val_loss: 3986818135.4937\n",
      "Epoch 4368/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 855418611.2684 - val_loss: 4039256617.0284\n",
      "Epoch 4369/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 794621731.4536 - val_loss: 3161682498.3944\n",
      "Epoch 4370/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 653414103.1491 - val_loss: 3613365285.9679\n",
      "Epoch 4371/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 787678046.9015 - val_loss: 3693234640.0405\n",
      "Epoch 4372/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 802347504.5492 - val_loss: 3558951331.4565\n",
      "Epoch 4373/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 716847215.2167 - val_loss: 4882017066.5226\n",
      "Epoch 4374/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 830397605.2223 - val_loss: 3751511832.6639\n",
      "Epoch 4375/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 728077610.2825 - val_loss: 5705636799.8020\n",
      "Epoch 4376/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 919431034.2555 - val_loss: 3966589702.9491\n",
      "Epoch 4377/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 875173459.9167 - val_loss: 4269626732.0889\n",
      "Epoch 4378/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 775580825.7693 - val_loss: 3108216608.4816\n",
      "Epoch 4379/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 761142298.2645 - val_loss: 3774706359.4847\n",
      "Epoch 4380/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 907998985.7243 - val_loss: 3585040632.3218\n",
      "Epoch 4381/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 822678485.2673 - val_loss: 3193744315.2444\n",
      "Epoch 4382/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 841288566.5008 - val_loss: 3230578824.6098\n",
      "Epoch 4383/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 770748888.6888 - val_loss: 3209391033.5865\n",
      "Epoch 4384/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 907053150.2893 - val_loss: 5914436775.6422\n",
      "Epoch 4385/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 701215988.6775 - val_loss: 3155594847.9752\n",
      "Epoch 4386/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 683172464.5492 - val_loss: 4005566743.5297\n",
      "Epoch 4387/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 687918153.6522 - val_loss: 3898719079.0931\n",
      "Epoch 4388/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 874517811.0703 - val_loss: 5533438952.6684\n",
      "Epoch 4389/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1359889507.4035 - val_loss: 4161934282.6037\n",
      "Epoch 4390/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 796054833.0940 - val_loss: 3397867822.7623\n",
      "Epoch 4391/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 621747416.1666 - val_loss: 3393025712.6481\n",
      "Epoch 4392/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1179039997.4069 - val_loss: 3742593160.8754\n",
      "Epoch 4393/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 778903268.9252 - val_loss: 3418015808.5581\n",
      "Epoch 4394/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 654563891.6106 - val_loss: 3285422679.5837\n",
      "Epoch 4395/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 893584502.7800 - val_loss: 3217976237.0610\n",
      "Epoch 4396/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 751058166.4918 - val_loss: 3596817692.2644\n",
      "Epoch 4397/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 727507929.6072 - val_loss: 3419731465.7935\n",
      "Epoch 4398/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 624452672.0360 - val_loss: 3834386142.8028\n",
      "Epoch 4399/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 793820260.4840 - val_loss: 3263062743.0616\n",
      "Epoch 4400/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 854963293.6230 - val_loss: 4348983684.8608\n",
      "Epoch 4401/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 858250333.9291 - val_loss: 3236424039.7502\n",
      "Epoch 4402/7000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 771562901.3213 - val_loss: 5191690832.3646\n",
      "Epoch 4403/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1061219051.9752 - val_loss: 3614300407.5927\n",
      "Epoch 4404/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1118478749.5329 - val_loss: 3193227146.8377\n",
      "Epoch 4405/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 751632868.2679 - val_loss: 3239523921.4807\n",
      "Epoch 4406/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 656624399.8469 - val_loss: 3473548782.4473\n",
      "Epoch 4407/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 799337157.9426 - val_loss: 3283582841.3750\n",
      "Epoch 4408/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 840233881.3416 - val_loss: 3611715512.6549\n",
      "Epoch 4409/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 713791253.5509 - val_loss: 3415294006.8726\n",
      "Epoch 4410/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 918929570.9353 - val_loss: 3511373473.1612\n",
      "Epoch 4411/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 802727074.7552 - val_loss: 3101360373.0633\n",
      "Epoch 4412/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 644904303.4328 - val_loss: 3309338285.5381\n",
      "Epoch 4413/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 649938635.6331 - val_loss: 3491255531.2068\n",
      "Epoch 4414/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 83us/step - loss: 794521994.0844 - val_loss: 3255012891.7063\n",
      "Epoch 4415/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 826772068.0158 - val_loss: 3140187452.7764\n",
      "Epoch 4416/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 751148987.6781 - val_loss: 5263757858.7814\n",
      "Epoch 4417/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 844430534.7710 - val_loss: 3777743098.0411\n",
      "Epoch 4418/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1148884819.1964 - val_loss: 3164169254.3640\n",
      "Epoch 4419/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 737841604.1778 - val_loss: 5027814211.6186\n",
      "Epoch 4420/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 882613631.7839 - val_loss: 3450998455.2776\n",
      "Epoch 4421/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 781412216.7608 - val_loss: 3322232807.2281\n",
      "Epoch 4422/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 768990650.9038 - val_loss: 3214764880.6346\n",
      "Epoch 4423/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 807119894.4738 - val_loss: 4034593730.2864\n",
      "Epoch 4424/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1033681954.3590 - val_loss: 3370509398.0624\n",
      "Epoch 4425/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 756388154.6337 - val_loss: 4998179194.9952\n",
      "Epoch 4426/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1280357177.9854 - val_loss: 3848924354.7724\n",
      "Epoch 4427/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 785635190.2757 - val_loss: 3166196832.5131\n",
      "Epoch 4428/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 679430130.4221 - val_loss: 3258902426.1221\n",
      "Epoch 4429/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 740046753.8548 - val_loss: 3390103652.9013\n",
      "Epoch 4430/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 829644907.1109 - val_loss: 3894576152.5018\n",
      "Epoch 4431/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 720558021.9426 - val_loss: 4308168131.3665\n",
      "Epoch 4432/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1057888108.2386 - val_loss: 3152467832.0698\n",
      "Epoch 4433/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 587371100.6595 - val_loss: 3077795663.7120\n",
      "Epoch 4434/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 662425559.8784 - val_loss: 3272583169.0577\n",
      "Epoch 4435/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 684691464.9319 - val_loss: 3082861166.5913\n",
      "Epoch 4436/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 668691044.3759 - val_loss: 3217769632.2700\n",
      "Epoch 4437/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 655831192.0698 - val_loss: 4249314234.5091\n",
      "Epoch 4438/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 745179159.3742 - val_loss: 3497029789.0925\n",
      "Epoch 4439/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 706388361.7153 - val_loss: 3217078116.7482\n",
      "Epoch 4440/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 658904407.5363 - val_loss: 3923519574.9536\n",
      "Epoch 4441/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 882247004.7766 - val_loss: 5551377278.0917\n",
      "Epoch 4442/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 855021397.4294 - val_loss: 3168502096.0518\n",
      "Epoch 4443/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 713203733.6545 - val_loss: 3611911123.2270\n",
      "Epoch 4444/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1003905168.0810 - val_loss: 3480858367.8560\n",
      "Epoch 4445/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 810011983.2921 - val_loss: 3238113374.4068\n",
      "Epoch 4446/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 674199280.3331 - val_loss: 3054199057.4087\n",
      "Epoch 4447/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 609340956.4164 - val_loss: 3343556330.0096\n",
      "Epoch 4448/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 666804288.1080 - val_loss: 4004884466.7499\n",
      "Epoch 4449/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1002581797.7085 - val_loss: 3134914174.3257\n",
      "Epoch 4450/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 722930972.1373 - val_loss: 3379448280.0788\n",
      "Epoch 4451/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 923073736.2656 - val_loss: 4020468863.7300\n",
      "Epoch 4452/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 841688309.5554 - val_loss: 5249362556.3994\n",
      "Epoch 4453/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 996521077.4114 - val_loss: 5099245518.0962\n",
      "Epoch 4454/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 969426544.2251 - val_loss: 3787177356.4759\n",
      "Epoch 4455/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 665805296.3331 - val_loss: 3103322420.7122\n",
      "Epoch 4456/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 563457440.7473 - val_loss: 3758383616.0090\n",
      "Epoch 4457/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 767730429.1548 - val_loss: 4609046997.5044\n",
      "Epoch 4458/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 741497585.1795 - val_loss: 3203424722.7949\n",
      "Epoch 4459/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 691617768.5582 - val_loss: 3302378968.3038\n",
      "Epoch 4460/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 733250787.9077 - val_loss: 3106211056.7696\n",
      "Epoch 4461/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 641042046.3883 - val_loss: 3232315433.8385\n",
      "Epoch 4462/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 804878600.0675 - val_loss: 3710266609.9578\n",
      "Epoch 4463/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 810363347.1964 - val_loss: 3298824217.3210\n",
      "Epoch 4464/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 764100875.8852 - val_loss: 3648114824.7584\n",
      "Epoch 4465/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 788398166.2217 - val_loss: 3062620512.4771\n",
      "Epoch 4466/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 681231669.4339 - val_loss: 3076770733.6821\n",
      "Epoch 4467/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 745490624.0360 - val_loss: 3123761931.8819\n",
      "Epoch 4468/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 790628657.9178 - val_loss: 3759327744.0675\n",
      "Epoch 4469/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 619820054.1857 - val_loss: 4839103057.7688\n",
      "Epoch 4470/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 974476677.5701 - val_loss: 3256818392.8799\n",
      "Epoch 4471/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 669653300.0428 - val_loss: 3171447208.4636\n",
      "Epoch 4472/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 748486499.9781 - val_loss: 4009349936.9316\n",
      "Epoch 4473/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 805980680.4997 - val_loss: 3810744323.3125\n",
      "Epoch 4474/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 867011892.7271 - val_loss: 3936483250.0658\n",
      "Epoch 4475/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 802104611.0613 - val_loss: 3194324998.0489\n",
      "Epoch 4476/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 731839417.0850 - val_loss: 3266338430.8478\n",
      "Epoch 4477/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 940102633.8773 - val_loss: 3321421073.7868\n",
      "Epoch 4478/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 690179006.3793 - val_loss: 3381245716.8113\n",
      "Epoch 4479/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 102us/step - loss: 1000322009.9313 - val_loss: 4941583922.9480\n",
      "Epoch 4480/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 963427302.0191 - val_loss: 3212962030.9243\n",
      "Epoch 4481/7000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 760975704.4997 - val_loss: 3340628209.1297\n",
      "Epoch 4482/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 586443933.3438 - val_loss: 3084927775.2979\n",
      "Epoch 4483/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 647564358.2667 - val_loss: 3202394484.6672\n",
      "Epoch 4484/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 661966504.1756 - val_loss: 4007663737.5190\n",
      "Epoch 4485/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 679096330.8407 - val_loss: 3085621341.1826\n",
      "Epoch 4486/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 753282068.9972 - val_loss: 3151413935.4824\n",
      "Epoch 4487/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 944459097.1007 - val_loss: 3362005592.8439\n",
      "Epoch 4488/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 814844002.6472 - val_loss: 3608328457.8295\n",
      "Epoch 4489/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 712218389.6095 - val_loss: 6335357917.0025\n",
      "Epoch 4490/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1090210699.0568 - val_loss: 3596599091.4520\n",
      "Epoch 4491/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 822668205.4519 - val_loss: 3224777626.1221\n",
      "Epoch 4492/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 728039826.9443 - val_loss: 3851819545.9961\n",
      "Epoch 4493/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1373006968.3647 - val_loss: 3240935188.6312\n",
      "Epoch 4494/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 813646699.5791 - val_loss: 3869407946.6397\n",
      "Epoch 4495/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 615857972.8981 - val_loss: 3195726901.9004\n",
      "Epoch 4496/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 671346207.8379 - val_loss: 4174876563.8031\n",
      "Epoch 4497/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 721835039.5498 - val_loss: 3013929060.0506\n",
      "Epoch 4498/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 587816624.3331 - val_loss: 3267039655.3902\n",
      "Epoch 4499/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 842610970.8678 - val_loss: 3205914803.4880\n",
      "Epoch 4500/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 804048774.5189 - val_loss: 3907146932.0281\n",
      "Epoch 4501/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 624066203.3652 - val_loss: 3115507566.8613\n",
      "Epoch 4502/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 760274751.5228 - val_loss: 3222036414.6408\n",
      "Epoch 4503/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 772998448.2881 - val_loss: 3692416607.3789\n",
      "Epoch 4504/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 761224164.2611 - val_loss: 3711312284.9845\n",
      "Epoch 4505/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 694334359.6984 - val_loss: 3253119758.8388\n",
      "Epoch 4506/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 926575356.5988 - val_loss: 3755249751.7097\n",
      "Epoch 4507/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 689428191.6669 - val_loss: 3567720373.3963\n",
      "Epoch 4508/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 820609400.0765 - val_loss: 3474940666.9952\n",
      "Epoch 4509/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 821757648.6393 - val_loss: 3057480820.9733\n",
      "Epoch 4510/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 618070298.2330 - val_loss: 3244690347.5398\n",
      "Epoch 4511/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 626434714.0034 - val_loss: 3687325923.7176\n",
      "Epoch 4512/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 897049399.1761 - val_loss: 4057540000.2430\n",
      "Epoch 4513/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 800214840.4727 - val_loss: 3181796854.7105\n",
      "Epoch 4514/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 696847753.4361 - val_loss: 3265382300.7325\n",
      "Epoch 4515/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 828298429.0827 - val_loss: 3421727078.8501\n",
      "Epoch 4516/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 720609864.0315 - val_loss: 3369412231.6602\n",
      "Epoch 4517/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 838698844.9297 - val_loss: 3105868514.0613\n",
      "Epoch 4518/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 762640530.2240 - val_loss: 3304822483.2000\n",
      "Epoch 4519/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 683400731.2999 - val_loss: 3830157616.1845\n",
      "Epoch 4520/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 687529640.1216 - val_loss: 3341799046.9491\n",
      "Epoch 4521/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 789271117.6140 - val_loss: 3193641869.9702\n",
      "Epoch 4522/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 615719789.4879 - val_loss: 3509943529.0689\n",
      "Epoch 4523/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 649924078.2802 - val_loss: 3360373974.1795\n",
      "Epoch 4524/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 786291141.5824 - val_loss: 5764536451.2765\n",
      "Epoch 4525/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 870917077.7175 - val_loss: 3940738525.5246\n",
      "Epoch 4526/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 690413926.2847 - val_loss: 3343315893.4684\n",
      "Epoch 4527/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 765325591.4282 - val_loss: 3612674178.8985\n",
      "Epoch 4528/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 740052052.3309 - val_loss: 3607349740.8450\n",
      "Epoch 4529/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 766325464.2386 - val_loss: 3875139899.7041\n",
      "Epoch 4530/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 761664281.4271 - val_loss: 3274988780.1789\n",
      "Epoch 4531/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 775326972.9747 - val_loss: 5010797424.7696\n",
      "Epoch 4532/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1145744561.0174 - val_loss: 3570801230.1862\n",
      "Epoch 4533/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 615627258.9578 - val_loss: 3522744820.0641\n",
      "Epoch 4534/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 778406585.7693 - val_loss: 4238056890.4371\n",
      "Epoch 4535/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 767239566.9645 - val_loss: 3262478989.4481\n",
      "Epoch 4536/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 616645435.9302 - val_loss: 6125756879.7165\n",
      "Epoch 4537/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1396977410.6652 - val_loss: 3789454259.1820\n",
      "Epoch 4538/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 818502587.7501 - val_loss: 3893511668.3342\n",
      "Epoch 4539/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 767705055.1536 - val_loss: 2986695306.7927\n",
      "Epoch 4540/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 549709920.0540 - val_loss: 3405349459.5871\n",
      "Epoch 4541/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 629817234.6562 - val_loss: 3246012138.5316\n",
      "Epoch 4542/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 862362572.2814 - val_loss: 4022489994.0636\n",
      "Epoch 4543/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 989123577.7333 - val_loss: 5746362110.6318\n",
      "Epoch 4544/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 81us/step - loss: 795702681.4992 - val_loss: 3079021478.4360\n",
      "Epoch 4545/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 625957773.0816 - val_loss: 3045388377.9421\n",
      "Epoch 4546/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 637763460.3039 - val_loss: 4457948348.9755\n",
      "Epoch 4547/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 692171802.7777 - val_loss: 4588424285.9387\n",
      "Epoch 4548/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 764481161.5892 - val_loss: 3413519922.1198\n",
      "Epoch 4549/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 687031050.4176 - val_loss: 3158868331.6568\n",
      "Epoch 4550/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 596450388.7181 - val_loss: 3294409002.7747\n",
      "Epoch 4551/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 814479644.3084 - val_loss: 3619745625.2219\n",
      "Epoch 4552/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 758747380.1148 - val_loss: 3259745061.9499\n",
      "Epoch 4553/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 660760054.8880 - val_loss: 3740379720.0113\n",
      "Epoch 4554/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 656199270.2487 - val_loss: 3130773424.5491\n",
      "Epoch 4555/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 650021528.9229 - val_loss: 4108821605.3918\n",
      "Epoch 4556/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 810836738.2690 - val_loss: 3648044984.3848\n",
      "Epoch 4557/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 671472170.9308 - val_loss: 3904764461.3671\n",
      "Epoch 4558/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 658246550.3478 - val_loss: 3011766329.0689\n",
      "Epoch 4559/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 658687633.6297 - val_loss: 3192670572.7010\n",
      "Epoch 4560/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 738389993.4271 - val_loss: 3156443649.5302\n",
      "Epoch 4561/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 669045516.2454 - val_loss: 3058505993.5955\n",
      "Epoch 4562/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 631222862.3703 - val_loss: 5663012266.2346\n",
      "Epoch 4563/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 847764533.5284 - val_loss: 3517261400.7539\n",
      "Epoch 4564/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1069425399.7884 - val_loss: 3836673293.8442\n",
      "Epoch 4565/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 802912259.7997 - val_loss: 3108758173.1646\n",
      "Epoch 4566/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 648304632.9409 - val_loss: 3097787914.1266\n",
      "Epoch 4567/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 750769931.1649 - val_loss: 3893576831.2979\n",
      "Epoch 4568/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 816210433.4902 - val_loss: 3063779687.0121\n",
      "Epoch 4569/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 586306194.6562 - val_loss: 3806819355.1122\n",
      "Epoch 4570/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 636285075.4125 - val_loss: 3614029634.7904\n",
      "Epoch 4571/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 865380769.3506 - val_loss: 3341622671.7345\n",
      "Epoch 4572/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 699806431.5678 - val_loss: 3294166722.1423\n",
      "Epoch 4573/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 811230300.6685 - val_loss: 3197230731.8706\n",
      "Epoch 4574/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 701231023.9370 - val_loss: 3796417283.4745\n",
      "Epoch 4575/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 951689932.1373 - val_loss: 4472208878.0692\n",
      "Epoch 4576/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1063274536.5537 - val_loss: 3194467131.3373\n",
      "Epoch 4577/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1187354785.0625 - val_loss: 3371498536.7066\n",
      "Epoch 4578/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 778912267.6320 - val_loss: 3256261514.4731\n",
      "Epoch 4579/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 631078315.9752 - val_loss: 3033948921.9443\n",
      "Epoch 4580/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 644935978.1204 - val_loss: 3059418919.8582\n",
      "Epoch 4581/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 720557288.5177 - val_loss: 3833413994.1086\n",
      "Epoch 4582/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 933612842.2105 - val_loss: 3268336590.6003\n",
      "Epoch 4583/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 738361488.2386 - val_loss: 3491920388.1767\n",
      "Epoch 4584/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 636886738.9083 - val_loss: 3429253263.5904\n",
      "Epoch 4585/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1005350631.4463 - val_loss: 4003579161.8520\n",
      "Epoch 4586/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 696214188.4074 - val_loss: 5306096650.0996\n",
      "Epoch 4587/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 742204076.9567 - val_loss: 3017057793.9803\n",
      "Epoch 4588/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 601127608.6168 - val_loss: 3240037077.3783\n",
      "Epoch 4589/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 992727394.3590 - val_loss: 3243594626.4124\n",
      "Epoch 4590/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 636808626.4232 - val_loss: 3198374168.9159\n",
      "Epoch 4591/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 879714313.7423 - val_loss: 3407289086.8118\n",
      "Epoch 4592/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 626236314.2195 - val_loss: 3169442153.5055\n",
      "Epoch 4593/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 679866093.8706 - val_loss: 3500085574.0759\n",
      "Epoch 4594/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 700728796.6956 - val_loss: 2998240778.5316\n",
      "Epoch 4595/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 788944163.7997 - val_loss: 3850122071.0076\n",
      "Epoch 4596/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 616366087.5093 - val_loss: 3792307481.2759\n",
      "Epoch 4597/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 757548030.1632 - val_loss: 3276127240.8844\n",
      "Epoch 4598/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 843658841.8863 - val_loss: 3662328205.2861\n",
      "Epoch 4599/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 916124203.9392 - val_loss: 3976211213.8262\n",
      "Epoch 4600/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1054702208.6483 - val_loss: 3155734384.6976\n",
      "Epoch 4601/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 539850499.6376 - val_loss: 3044451148.5840\n",
      "Epoch 4602/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 704610191.2707 - val_loss: 3284832880.8776\n",
      "Epoch 4603/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 684321988.4187 - val_loss: 3868852518.7961\n",
      "Epoch 4604/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 701402186.4626 - val_loss: 4931048765.6416\n",
      "Epoch 4605/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 745717026.4311 - val_loss: 3937825352.1553\n",
      "Epoch 4606/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 727418153.3461 - val_loss: 5563362776.1418\n",
      "Epoch 4607/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 680257064.7338 - val_loss: 3274640009.3975\n",
      "Epoch 4608/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 673725501.2808 - val_loss: 3447799734.8726\n",
      "Epoch 4609/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 84us/step - loss: 666506535.2212 - val_loss: 3305882864.5536\n",
      "Epoch 4610/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 940708308.3129 - val_loss: 4330948397.0430\n",
      "Epoch 4611/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 633719383.2482 - val_loss: 3120294895.3834\n",
      "Epoch 4612/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 625264689.2988 - val_loss: 3496072531.6051\n",
      "Epoch 4613/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 932862845.6950 - val_loss: 3444644275.6051\n",
      "Epoch 4614/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 869168642.5391 - val_loss: 4210204643.0515\n",
      "Epoch 4615/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 669095867.2279 - val_loss: 3353114474.5046\n",
      "Epoch 4616/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 565235752.7518 - val_loss: 3207604691.9291\n",
      "Epoch 4617/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 632327385.8593 - val_loss: 3180990788.9148\n",
      "Epoch 4618/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 653259452.0023 - val_loss: 3370981321.8475\n",
      "Epoch 4619/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 995485793.3146 - val_loss: 3160711249.1927\n",
      "Epoch 4620/7000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 621915243.0028 - val_loss: 3044573635.6726\n",
      "Epoch 4621/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 658235603.3044 - val_loss: 3654915698.9480\n",
      "Epoch 4622/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 798759622.3748 - val_loss: 3106288026.8062\n",
      "Epoch 4623/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 762194861.0737 - val_loss: 3148168317.1105\n",
      "Epoch 4624/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 554605482.5346 - val_loss: 3552867746.6914\n",
      "Epoch 4625/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 1001013983.6218 - val_loss: 4800508936.2093\n",
      "Epoch 4626/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 887141937.6297 - val_loss: 3373402999.7187\n",
      "Epoch 4627/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 806432725.6635 - val_loss: 3297709290.6127\n",
      "Epoch 4628/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 606489956.6100 - val_loss: 3061497377.3412\n",
      "Epoch 4629/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 814302107.0838 - val_loss: 3581848227.1775\n",
      "Epoch 4630/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 713651669.3033 - val_loss: 4732648355.1055\n",
      "Epoch 4631/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 664429650.9443 - val_loss: 3669576350.5193\n",
      "Epoch 4632/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 721700477.1908 - val_loss: 4321182274.9705\n",
      "Epoch 4633/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 951171815.5093 - val_loss: 3997812308.8293\n",
      "Epoch 4634/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1070030288.6933 - val_loss: 3507639568.4096\n",
      "Epoch 4635/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 684717961.7243 - val_loss: 3371266849.7373\n",
      "Epoch 4636/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 689334960.1666 - val_loss: 3502075051.3868\n",
      "Epoch 4637/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 732471384.0225 - val_loss: 3580060116.8653\n",
      "Epoch 4638/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 733443547.2729 - val_loss: 3031777992.4973\n",
      "Epoch 4639/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 724223629.1097 - val_loss: 3581386639.5544\n",
      "Epoch 4640/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 633738115.7817 - val_loss: 4024073472.7201\n",
      "Epoch 4641/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 843650321.7963 - val_loss: 2967643938.1063\n",
      "Epoch 4642/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 608989998.1902 - val_loss: 3827715340.6020\n",
      "Epoch 4643/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 696097205.8075 - val_loss: 4407668703.4509\n",
      "Epoch 4644/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 768376796.8846 - val_loss: 3454596940.1519\n",
      "Epoch 4645/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 795800918.9781 - val_loss: 3467933310.4338\n",
      "Epoch 4646/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 695418105.9494 - val_loss: 3693123937.3142\n",
      "Epoch 4647/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 666064872.8059 - val_loss: 3097617462.4405\n",
      "Epoch 4648/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 567732380.5965 - val_loss: 3695223936.1800\n",
      "Epoch 4649/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 824614340.5020 - val_loss: 3133089671.0121\n",
      "Epoch 4650/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 964288997.7805 - val_loss: 3738549006.1862\n",
      "Epoch 4651/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 785819642.0934 - val_loss: 3241275384.5997\n",
      "Epoch 4652/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 783243794.4581 - val_loss: 3135800988.6875\n",
      "Epoch 4653/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 665165045.6725 - val_loss: 3099629737.6765\n",
      "Epoch 4654/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 570627574.8880 - val_loss: 3876379620.7257\n",
      "Epoch 4655/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 664577835.5070 - val_loss: 3128275469.7361\n",
      "Epoch 4656/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 594317093.4204 - val_loss: 3077538956.6380\n",
      "Epoch 4657/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 625528001.1615 - val_loss: 3318654374.2470\n",
      "Epoch 4658/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 637036288.7203 - val_loss: 5397763422.6228\n",
      "Epoch 4659/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1007102981.7625 - val_loss: 3147306930.2594\n",
      "Epoch 4660/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 800237691.8942 - val_loss: 3253891691.2068\n",
      "Epoch 4661/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 686917625.5892 - val_loss: 3874578415.1494\n",
      "Epoch 4662/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 871544751.5048 - val_loss: 3301027043.3755\n",
      "Epoch 4663/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 781616161.7828 - val_loss: 3266004636.6245\n",
      "Epoch 4664/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 658502396.8306 - val_loss: 5530923562.4866\n",
      "Epoch 4665/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1048078934.3118 - val_loss: 3184595651.5105\n",
      "Epoch 4666/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 610093474.8182 - val_loss: 2970741228.4084\n",
      "Epoch 4667/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 673827567.5048 - val_loss: 3260601908.8743\n",
      "Epoch 4668/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 703687941.3303 - val_loss: 3447220344.5468\n",
      "Epoch 4669/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 685340122.8841 - val_loss: 3003162140.6065\n",
      "Epoch 4670/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 588750252.5875 - val_loss: 4166541202.0658\n",
      "Epoch 4671/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 839034078.0957 - val_loss: 3085228015.9775\n",
      "Epoch 4672/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 599029726.7575 - val_loss: 3364383503.3384\n",
      "Epoch 4673/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 805880434.0259 - val_loss: 3031050407.7682\n",
      "Epoch 4674/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 74us/step - loss: 566356696.4187 - val_loss: 3167694223.8785\n",
      "Epoch 4675/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 574825292.0653 - val_loss: 3939007660.0169\n",
      "Epoch 4676/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 912062931.2324 - val_loss: 3478137891.4295\n",
      "Epoch 4677/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 905957203.2684 - val_loss: 3441875019.7558\n",
      "Epoch 4678/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 760676899.7636 - val_loss: 4363731740.5525\n",
      "Epoch 4679/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 973876688.5672 - val_loss: 3074270888.3488\n",
      "Epoch 4680/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 579137741.5374 - val_loss: 3661823340.5210\n",
      "Epoch 4681/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 770335195.1919 - val_loss: 3034080001.9443\n",
      "Epoch 4682/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 585353405.9471 - val_loss: 4286795652.3567\n",
      "Epoch 4683/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 682622699.8312 - val_loss: 3839087715.4475\n",
      "Epoch 4684/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 883752645.8165 - val_loss: 3191596866.8624\n",
      "Epoch 4685/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 608007732.9432 - val_loss: 3016753308.0934\n",
      "Epoch 4686/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 737543226.8137 - val_loss: 3118479186.4889\n",
      "Epoch 4687/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 619003542.4918 - val_loss: 4653105854.2897\n",
      "Epoch 4688/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 668582829.0197 - val_loss: 3784638208.4861\n",
      "Epoch 4689/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 887475378.0979 - val_loss: 4146164027.5353\n",
      "Epoch 4690/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 840051925.9696 - val_loss: 3270470486.4135\n",
      "Epoch 4691/7000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 640941818.9578 - val_loss: 4742403627.8909\n",
      "Epoch 4692/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 974868926.8115 - val_loss: 3095869782.9536\n",
      "Epoch 4693/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 589294267.4980 - val_loss: 3601460099.7547\n",
      "Epoch 4694/7000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 773749652.4119 - val_loss: 3680871793.8498\n",
      "Epoch 4695/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 753699665.8875 - val_loss: 3305378590.1660\n",
      "Epoch 4696/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 623061344.3421 - val_loss: 3445584594.1288\n",
      "Epoch 4697/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 689286485.8706 - val_loss: 2957775477.9454\n",
      "Epoch 4698/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 594656092.0923 - val_loss: 3238434349.7632\n",
      "Epoch 4699/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 585352322.9353 - val_loss: 3328330343.4667\n",
      "Epoch 4700/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 655016077.9381 - val_loss: 3223283911.0391\n",
      "Epoch 4701/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 693315268.3399 - val_loss: 3204380441.5460\n",
      "Epoch 4702/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 735577794.8813 - val_loss: 3098993232.1395\n",
      "Epoch 4703/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 705730663.4553 - val_loss: 2939964549.2928\n",
      "Epoch 4704/7000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 595145143.8244 - val_loss: 5814760262.7871\n",
      "Epoch 4705/7000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1261626373.3123 - val_loss: 3247539108.3297\n",
      "Epoch 4706/7000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 607850592.8284 - val_loss: 2991290116.1632\n",
      "Epoch 4707/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 542957365.5554 - val_loss: 3115104451.2338\n",
      "Epoch 4708/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 771576947.6826 - val_loss: 3259268253.7947\n",
      "Epoch 4709/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 579634098.4941 - val_loss: 3356345611.3508\n",
      "Epoch 4710/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 688065474.9893 - val_loss: 3214671585.3592\n",
      "Epoch 4711/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 601114525.1277 - val_loss: 3038154840.8979\n",
      "Epoch 4712/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 567906068.7991 - val_loss: 3091615313.7688\n",
      "Epoch 4713/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 710388708.2499 - val_loss: 3175085696.1530\n",
      "Epoch 4714/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 819287982.4153 - val_loss: 3174125225.3210\n",
      "Epoch 4715/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 591883393.2606 - val_loss: 4113485022.9468\n",
      "Epoch 4716/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1181716928.9004 - val_loss: 3596058959.1224\n",
      "Epoch 4717/7000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 1131240267.3450 - val_loss: 2959933000.6233\n",
      "Epoch 4718/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 485492159.8199 - val_loss: 2926785020.9395\n",
      "Epoch 4719/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 681133555.5385 - val_loss: 2976496834.4664\n",
      "Epoch 4720/7000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 802457478.4108 - val_loss: 3840367182.1142\n",
      "Epoch 4721/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 779143277.1998 - val_loss: 3155291166.1322\n",
      "Epoch 4722/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 895459996.2544 - val_loss: 3690255389.9927\n",
      "Epoch 4723/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 680309775.2707 - val_loss: 3073328482.2954\n",
      "Epoch 4724/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 861914579.6286 - val_loss: 3023802016.2250\n",
      "Epoch 4725/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 563287622.4603 - val_loss: 3016216690.2053\n",
      "Epoch 4726/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 563771216.6753 - val_loss: 3662651302.8771\n",
      "Epoch 4727/7000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 701693249.1525 - val_loss: 3340287129.3840\n",
      "Epoch 4728/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 760127601.0174 - val_loss: 3164657815.8717\n",
      "Epoch 4729/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 569768215.6804 - val_loss: 3054397978.0321\n",
      "Epoch 4730/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 538161582.4783 - val_loss: 5932516355.1685\n",
      "Epoch 4731/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 793346651.2819 - val_loss: 3034560313.2669\n",
      "Epoch 4732/7000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 650471621.0422 - val_loss: 3175132812.6380\n",
      "Epoch 4733/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 691682699.4530 - val_loss: 3387548172.2959\n",
      "Epoch 4734/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 594152375.5363 - val_loss: 3646761384.3263\n",
      "Epoch 4735/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 990691059.7997 - val_loss: 3042970956.8360\n",
      "Epoch 4736/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 675371642.3005 - val_loss: 3101622805.2613\n",
      "Epoch 4737/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 496138975.5138 - val_loss: 3334987010.6644\n",
      "Epoch 4738/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 622231673.3731 - val_loss: 3194294893.9972\n",
      "Epoch 4739/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 94us/step - loss: 612566165.6815 - val_loss: 4318409021.4886\n",
      "Epoch 4740/7000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 645800019.8447 - val_loss: 3127260607.6399\n",
      "Epoch 4741/7000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 627016303.6488 - val_loss: 3297412260.4917\n",
      "Epoch 4742/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 589193228.3894 - val_loss: 3652779573.3873\n",
      "Epoch 4743/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 836568508.8711 - val_loss: 3555867474.7769\n",
      "Epoch 4744/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 626557547.1829 - val_loss: 3947947879.2281\n",
      "Epoch 4745/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 576701502.8115 - val_loss: 3599650405.5179\n",
      "Epoch 4746/7000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 720073737.9043 - val_loss: 4004964458.7207\n",
      "Epoch 4747/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 588914012.6415 - val_loss: 3086276673.4492\n",
      "Epoch 4748/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 660763484.6685 - val_loss: 3433387621.1038\n",
      "Epoch 4749/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 674832606.3253 - val_loss: 3810954406.1480\n",
      "Epoch 4750/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 641667114.2060 - val_loss: 3201087260.0484\n",
      "Epoch 4751/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 768206001.4913 - val_loss: 2921998404.2442\n",
      "Epoch 4752/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 731528437.3393 - val_loss: 3802921253.1533\n",
      "Epoch 4753/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 770511712.5222 - val_loss: 3973468994.5384\n",
      "Epoch 4754/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 856765441.0084 - val_loss: 3218667213.6011\n",
      "Epoch 4755/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 706364381.8571 - val_loss: 2990003530.5316\n",
      "Epoch 4756/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 798982840.6168 - val_loss: 3489369456.4816\n",
      "Epoch 4757/7000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 847580098.6472 - val_loss: 3163695170.3134\n",
      "Epoch 4758/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 660795468.3534 - val_loss: 3415828230.2290\n",
      "Epoch 4759/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 799893766.6809 - val_loss: 3246644735.1539\n",
      "Epoch 4760/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 724269378.8092 - val_loss: 3209369398.6025\n",
      "Epoch 4761/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 683043074.1609 - val_loss: 3245558798.1682\n",
      "Epoch 4762/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 743657965.7310 - val_loss: 3141833024.9902\n",
      "Epoch 4763/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 617353677.6207 - val_loss: 2902600482.8084\n",
      "Epoch 4764/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 529855735.6443 - val_loss: 3362265118.6858\n",
      "Epoch 4765/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 645697151.9977 - val_loss: 2908149784.9519\n",
      "Epoch 4766/7000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 566263611.2819 - val_loss: 2982067221.9139\n",
      "Epoch 4767/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 780739294.8565 - val_loss: 2942713762.2143\n",
      "Epoch 4768/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 723547634.4221 - val_loss: 3606547470.1862\n",
      "Epoch 4769/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 707873197.3438 - val_loss: 3120726511.1494\n",
      "Epoch 4770/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 785029710.8385 - val_loss: 3535608862.7308\n",
      "Epoch 4771/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 685508233.9494 - val_loss: 3049231122.3269\n",
      "Epoch 4772/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 644893352.1216 - val_loss: 4897415922.9660\n",
      "Epoch 4773/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1466249417.8323 - val_loss: 3023719999.5229\n",
      "Epoch 4774/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 747818807.4282 - val_loss: 3092108166.4450\n",
      "Epoch 4775/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 581919115.3540 - val_loss: 3049668235.1257\n",
      "Epoch 4776/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 752634584.0225 - val_loss: 3793454276.5187\n",
      "Epoch 4777/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 612157872.0225 - val_loss: 3097234499.3845\n",
      "Epoch 4778/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 607301002.7327 - val_loss: 3293710801.3277\n",
      "Epoch 4779/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 581977084.6505 - val_loss: 3439239920.4996\n",
      "Epoch 4780/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 565486095.3877 - val_loss: 3159736348.5705\n",
      "Epoch 4781/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 652999848.4097 - val_loss: 4642732295.9572\n",
      "Epoch 4782/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 714376155.0478 - val_loss: 3058931903.5949\n",
      "Epoch 4783/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 712308587.9212 - val_loss: 2982037340.4714\n",
      "Epoch 4784/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 581534859.3405 - val_loss: 2885579769.4830\n",
      "Epoch 4785/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 681378930.1699 - val_loss: 3033294975.0098\n",
      "Epoch 4786/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 550851450.8858 - val_loss: 2973415712.8911\n",
      "Epoch 4787/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 642592806.7237 - val_loss: 3104232063.5004\n",
      "Epoch 4788/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 800582532.7901 - val_loss: 3432426316.1879\n",
      "Epoch 4789/7000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1087646282.7957 - val_loss: 2996184120.0968\n",
      "Epoch 4790/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 492839042.6292 - val_loss: 5103872944.5356\n",
      "Epoch 4791/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 762264157.1367 - val_loss: 5226417153.1522\n",
      "Epoch 4792/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 863700320.7743 - val_loss: 3001255510.4135\n",
      "Epoch 4793/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 569532411.5926 - val_loss: 3461600206.7443\n",
      "Epoch 4794/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 605006398.7755 - val_loss: 4245517606.1300\n",
      "Epoch 4795/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 960244744.5267 - val_loss: 3021323819.9269\n",
      "Epoch 4796/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 655255491.3495 - val_loss: 3123699201.5662\n",
      "Epoch 4797/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 602921929.3641 - val_loss: 2949984740.9598\n",
      "Epoch 4798/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 539020094.9195 - val_loss: 3066212211.1460\n",
      "Epoch 4799/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 539714339.7997 - val_loss: 2973099421.6146\n",
      "Epoch 4800/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 815451335.5993 - val_loss: 2957384059.9044\n",
      "Epoch 4801/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 547301771.1649 - val_loss: 3434745311.3789\n",
      "Epoch 4802/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 762040157.6770 - val_loss: 2909064882.4439\n",
      "Epoch 4803/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 655169572.5920 - val_loss: 6853420735.9100\n",
      "Epoch 4804/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 89us/step - loss: 919934531.9977 - val_loss: 3208450274.9390\n",
      "Epoch 4805/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 599588272.7653 - val_loss: 4978512939.4588\n",
      "Epoch 4806/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 697980967.9617 - val_loss: 3048400627.9111\n",
      "Epoch 4807/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 555176899.8177 - val_loss: 3374840599.7817\n",
      "Epoch 4808/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 661848266.6246 - val_loss: 3226296443.4273\n",
      "Epoch 4809/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 590801233.0062 - val_loss: 3158949306.6172\n",
      "Epoch 4810/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 541189764.4660 - val_loss: 3566146041.1589\n",
      "Epoch 4811/7000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 725085946.3455 - val_loss: 3921262578.1018\n",
      "Epoch 4812/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 709954757.4384 - val_loss: 3727332333.3401\n",
      "Epoch 4813/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 768485761.2606 - val_loss: 5310970036.3522\n",
      "Epoch 4814/7000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 658853109.5374 - val_loss: 2986913482.6037\n",
      "Epoch 4815/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 526976966.0506 - val_loss: 3664496997.2118\n",
      "Epoch 4816/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 673296047.9910 - val_loss: 3057127009.7193\n",
      "Epoch 4817/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 684185837.5599 - val_loss: 7727505716.7842\n",
      "Epoch 4818/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 973706795.3630 - val_loss: 2967130989.1691\n",
      "Epoch 4819/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 966857229.6140 - val_loss: 5486231770.5181\n",
      "Epoch 4820/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 964268348.7541 - val_loss: 2928019359.9111\n",
      "Epoch 4821/7000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 535383697.6837 - val_loss: 3653818283.4228\n",
      "Epoch 4822/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 566887865.6702 - val_loss: 2980425358.1772\n",
      "Epoch 4823/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 536281771.7231 - val_loss: 6658711679.5319\n",
      "Epoch 4824/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 903032250.2893 - val_loss: 3187808411.1842\n",
      "Epoch 4825/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 508167560.7518 - val_loss: 3475878460.6425\n",
      "Epoch 4826/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 621483186.1970 - val_loss: 3064679478.3505\n",
      "Epoch 4827/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 583780849.0174 - val_loss: 4081582945.3232\n",
      "Epoch 4828/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 872378174.7935 - val_loss: 2889742473.7890\n",
      "Epoch 4829/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 502271036.6685 - val_loss: 3999868682.7657\n",
      "Epoch 4830/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 716343366.0146 - val_loss: 2980566794.4506\n",
      "Epoch 4831/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 566548935.9595 - val_loss: 3679712994.4394\n",
      "Epoch 4832/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 633673985.3686 - val_loss: 3219551221.7744\n",
      "Epoch 4833/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 774084150.3478 - val_loss: 3311593211.9314\n",
      "Epoch 4834/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 598342245.6545 - val_loss: 3733723633.7418\n",
      "Epoch 4835/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 660269364.1508 - val_loss: 4014388961.7733\n",
      "Epoch 4836/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 600642729.4181 - val_loss: 3273029896.7854\n",
      "Epoch 4837/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1106808203.9572 - val_loss: 3253255266.2233\n",
      "Epoch 4838/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 684775450.2735 - val_loss: 2915087982.9873\n",
      "Epoch 4839/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 660531048.0855 - val_loss: 4562617585.1297\n",
      "Epoch 4840/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 732485965.0647 - val_loss: 3359978543.8335\n",
      "Epoch 4841/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 686572737.9088 - val_loss: 4321544602.5361\n",
      "Epoch 4842/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1472865396.8351 - val_loss: 4596053888.1800\n",
      "Epoch 4843/7000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 776966377.3461 - val_loss: 3853501522.7049\n",
      "Epoch 4844/7000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 696234162.0619 - val_loss: 3015143328.2250\n",
      "Epoch 4845/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 640803933.4069 - val_loss: 2932435002.4191\n",
      "Epoch 4846/7000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 658826082.1429 - val_loss: 3294435693.0520\n",
      "Epoch 4847/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 511513841.1615 - val_loss: 3167820017.6473\n",
      "Epoch 4848/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 538184253.8030 - val_loss: 3086736263.0661\n",
      "Epoch 4849/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 525049367.7884 - val_loss: 2945818382.6183\n",
      "Epoch 4850/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 464030646.2037 - val_loss: 3230024761.7260\n",
      "Epoch 4851/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 691502961.8458 - val_loss: 3772069980.9125\n",
      "Epoch 4852/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 608346233.6972 - val_loss: 3824997723.3103\n",
      "Epoch 4853/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 605137093.4609 - val_loss: 2920589995.5038\n",
      "Epoch 4854/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 676676769.9809 - val_loss: 3522443043.5556\n",
      "Epoch 4855/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 805257386.3545 - val_loss: 2981491093.9814\n",
      "Epoch 4856/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 625453528.4547 - val_loss: 3401873338.0006\n",
      "Epoch 4857/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1582873392.5312 - val_loss: 4371871736.0068\n",
      "Epoch 4858/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 697922739.3410 - val_loss: 3501567960.8259\n",
      "Epoch 4859/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 573602724.1598 - val_loss: 2831506716.9755\n",
      "Epoch 4860/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 590686299.5521 - val_loss: 4482658297.6990\n",
      "Epoch 4861/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 807455285.0152 - val_loss: 4259601530.9232\n",
      "Epoch 4862/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 930911576.6168 - val_loss: 3070757788.4174\n",
      "Epoch 4863/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 483013493.1953 - val_loss: 3044912912.5806\n",
      "Epoch 4864/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 541039058.9758 - val_loss: 3115647198.6408\n",
      "Epoch 4865/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 706619500.7589 - val_loss: 2896710627.1775\n",
      "Epoch 4866/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 557321195.0658 - val_loss: 2940787219.7671\n",
      "Epoch 4867/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 560309617.4856 - val_loss: 3863866591.2529\n",
      "Epoch 4868/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 725745905.4496 - val_loss: 3066201811.2360\n",
      "Epoch 4869/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 94us/step - loss: 679679073.7468 - val_loss: 5760816803.5015\n",
      "Epoch 4870/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 960318282.1925 - val_loss: 3658201856.4861\n",
      "Epoch 4871/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1035296279.9595 - val_loss: 2942288655.7795\n",
      "Epoch 4872/7000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 519031373.4271 - val_loss: 2989260314.5969\n",
      "Epoch 4873/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 689505442.9949 - val_loss: 3116129552.7786\n",
      "Epoch 4874/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 496957358.2915 - val_loss: 3089466988.9530\n",
      "Epoch 4875/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 533461796.1868 - val_loss: 3275982833.6158\n",
      "Epoch 4876/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 591000288.2341 - val_loss: 2876518878.0827\n",
      "Epoch 4877/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 498102037.1109 - val_loss: 2868473011.5308\n",
      "Epoch 4878/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 569132936.4457 - val_loss: 4527069838.0782\n",
      "Epoch 4879/7000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 866422168.1306 - val_loss: 3527511968.9271\n",
      "Epoch 4880/7000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 585736377.9313 - val_loss: 3071192166.1840\n",
      "Epoch 4881/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 538295293.9651 - val_loss: 3029765883.7153\n",
      "Epoch 4882/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 629354648.4322 - val_loss: 3805683617.2332\n",
      "Epoch 4883/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 761407642.5796 - val_loss: 2937377909.3783\n",
      "Epoch 4884/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 634164762.3275 - val_loss: 3158872753.6158\n",
      "Epoch 4885/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 845031888.1981 - val_loss: 4188287171.3125\n",
      "Epoch 4886/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 708818541.9921 - val_loss: 3392593560.5018\n",
      "Epoch 4887/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 803291561.4361 - val_loss: 2900017586.3719\n",
      "Epoch 4888/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 540945924.7271 - val_loss: 3154781940.1812\n",
      "Epoch 4889/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 527818815.4598 - val_loss: 3219200428.7550\n",
      "Epoch 4890/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 578375243.2369 - val_loss: 3167911097.2759\n",
      "Epoch 4891/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 571464585.9043 - val_loss: 2949898544.4006\n",
      "Epoch 4892/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 480870809.7940 - val_loss: 2817611341.0273\n",
      "Epoch 4893/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 502533834.8137 - val_loss: 4443627736.9339\n",
      "Epoch 4894/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 627906697.4463 - val_loss: 3428416043.4408\n",
      "Epoch 4895/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 743633365.6455 - val_loss: 3186507779.5646\n",
      "Epoch 4896/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 692225965.9786 - val_loss: 3309062924.0979\n",
      "Epoch 4897/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 584770828.4434 - val_loss: 3005568794.5722\n",
      "Epoch 4898/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 967955382.5419 - val_loss: 2913576962.0658\n",
      "Epoch 4899/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 491733834.3365 - val_loss: 3519759471.3474\n",
      "Epoch 4900/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 679162941.0107 - val_loss: 3241571478.5395\n",
      "Epoch 4901/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 650001729.7546 - val_loss: 2872474846.5148\n",
      "Epoch 4902/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 509131132.6775 - val_loss: 2881775871.0999\n",
      "Epoch 4903/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 605058047.7119 - val_loss: 2993923192.8709\n",
      "Epoch 4904/7000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 674500161.9088 - val_loss: 3054596892.4444\n",
      "Epoch 4905/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 609751031.9325 - val_loss: 3818509683.4880\n",
      "Epoch 4906/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 703411473.9358 - val_loss: 2835881634.1873\n",
      "Epoch 4907/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 534188700.7856 - val_loss: 3179472324.0866\n",
      "Epoch 4908/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 643275470.1452 - val_loss: 2810856040.4253\n",
      "Epoch 4909/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 586477179.4980 - val_loss: 3126994289.7238\n",
      "Epoch 4910/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 747675119.0726 - val_loss: 3026218454.6385\n",
      "Epoch 4911/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 985617659.0208 - val_loss: 2806084962.1333\n",
      "Epoch 4912/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 675776092.9207 - val_loss: 3655464905.1094\n",
      "Epoch 4913/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 680176841.0270 - val_loss: 2984361567.7570\n",
      "Epoch 4914/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 520927706.0934 - val_loss: 3036426154.4146\n",
      "Epoch 4915/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 580202342.1047 - val_loss: 3443494657.9443\n",
      "Epoch 4916/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 696713938.1069 - val_loss: 2912577490.6149\n",
      "Epoch 4917/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 496873025.0805 - val_loss: 4095166408.1193\n",
      "Epoch 4918/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 600881566.9736 - val_loss: 3015766062.9693\n",
      "Epoch 4919/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 673977884.5402 - val_loss: 2882944255.5049\n",
      "Epoch 4920/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 605798296.0585 - val_loss: 3423232200.5153\n",
      "Epoch 4921/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1125797047.5723 - val_loss: 3807251661.7992\n",
      "Epoch 4922/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 607414683.3630 - val_loss: 3058843123.9741\n",
      "Epoch 4923/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 518547630.1002 - val_loss: 3122113524.4827\n",
      "Epoch 4924/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 519123121.1975 - val_loss: 6731512255.7660\n",
      "Epoch 4925/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1132953753.3191 - val_loss: 2876139771.0492\n",
      "Epoch 4926/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 460138423.5723 - val_loss: 2968136602.4641\n",
      "Epoch 4927/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 832885792.4142 - val_loss: 6888473131.8008\n",
      "Epoch 4928/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1005289092.8981 - val_loss: 2972281685.8824\n",
      "Epoch 4929/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 703731391.0276 - val_loss: 2921681963.6073\n",
      "Epoch 4930/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 504422303.1896 - val_loss: 3941778778.0141\n",
      "Epoch 4931/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 712347753.9223 - val_loss: 3075859576.4208\n",
      "Epoch 4932/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 526436315.6961 - val_loss: 2898204286.4518\n",
      "Epoch 4933/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 537361834.5076 - val_loss: 2960506889.3435\n",
      "Epoch 4934/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 82us/step - loss: 454423322.2195 - val_loss: 2974099406.4203\n",
      "Epoch 4935/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 655155645.5329 - val_loss: 2836819447.8627\n",
      "Epoch 4936/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 684198996.0608 - val_loss: 4243776433.6518\n",
      "Epoch 4937/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 725875171.1514 - val_loss: 2812885686.8906\n",
      "Epoch 4938/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 509812167.5273 - val_loss: 4394948106.6577\n",
      "Epoch 4939/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 795450271.1176 - val_loss: 5538958941.7226\n",
      "Epoch 4940/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 888508891.6061 - val_loss: 3350702261.0453\n",
      "Epoch 4941/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 599377927.0771 - val_loss: 2933418678.3010\n",
      "Epoch 4942/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 473722548.5470 - val_loss: 3842034855.5162\n",
      "Epoch 4943/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 692507336.6888 - val_loss: 2972978469.5179\n",
      "Epoch 4944/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 622328413.3528 - val_loss: 3594017875.1730\n",
      "Epoch 4945/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 485707269.1885 - val_loss: 2884110735.8785\n",
      "Epoch 4946/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 530620502.7620 - val_loss: 2986256805.9859\n",
      "Epoch 4947/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 560178899.6106 - val_loss: 2867623069.4346\n",
      "Epoch 4948/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 623475320.2566 - val_loss: 3160656898.6284\n",
      "Epoch 4949/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 547811049.2380 - val_loss: 4908421538.9705\n",
      "Epoch 4950/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 914780033.8908 - val_loss: 3017042014.1547\n",
      "Epoch 4951/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 687640553.4541 - val_loss: 6116463981.3851\n",
      "Epoch 4952/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 993170523.9420 - val_loss: 2997046005.5584\n",
      "Epoch 4953/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 524135862.9600 - val_loss: 4138203812.1857\n",
      "Epoch 4954/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 750633227.7321 - val_loss: 2903828525.6191\n",
      "Epoch 4955/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 664328711.4192 - val_loss: 3244456009.0914\n",
      "Epoch 4956/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 826787902.3793 - val_loss: 3124749557.7024\n",
      "Epoch 4957/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 679946557.0467 - val_loss: 2928238301.0745\n",
      "Epoch 4958/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 624813700.2589 - val_loss: 3021993259.1977\n",
      "Epoch 4959/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 538499196.6145 - val_loss: 3042633872.7426\n",
      "Epoch 4960/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 555792813.3799 - val_loss: 5561185300.6672\n",
      "Epoch 4961/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 682740119.2662 - val_loss: 3246062222.1502\n",
      "Epoch 4962/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 564357625.1030 - val_loss: 2872271728.8866\n",
      "Epoch 4963/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 634120498.2780 - val_loss: 4952198210.4124\n",
      "Epoch 4964/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1407780001.6027 - val_loss: 2905981947.8414\n",
      "Epoch 4965/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 501327559.3315 - val_loss: 3247903945.7035\n",
      "Epoch 4966/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 508390360.7248 - val_loss: 3373091696.5716\n",
      "Epoch 4967/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 539312190.4873 - val_loss: 2986911131.1662\n",
      "Epoch 4968/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 537560622.2577 - val_loss: 2804035060.6402\n",
      "Epoch 4969/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 694089832.7518 - val_loss: 3266459894.0624\n",
      "Epoch 4970/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 600352989.5329 - val_loss: 3405093792.7111\n",
      "Epoch 4971/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 758228806.5729 - val_loss: 3508379247.0504\n",
      "Epoch 4972/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 571877362.4581 - val_loss: 2937897788.0045\n",
      "Epoch 4973/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 663339331.7817 - val_loss: 3051714617.6990\n",
      "Epoch 4974/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 748466107.1199 - val_loss: 3021039428.4377\n",
      "Epoch 4975/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 548394258.1519 - val_loss: 2984197273.3210\n",
      "Epoch 4976/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 609985459.4305 - val_loss: 3654596800.0180\n",
      "Epoch 4977/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 793009619.9887 - val_loss: 3172396303.2124\n",
      "Epoch 4978/7000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 458757961.5442 - val_loss: 2972660257.2512\n",
      "Epoch 4979/7000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 542396819.7366 - val_loss: 2867734288.4366\n",
      "Epoch 4980/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 556262704.4772 - val_loss: 3276944483.0875\n",
      "Epoch 4981/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 532533488.3782 - val_loss: 2851525414.0219\n",
      "Epoch 4982/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 919244303.0726 - val_loss: 2997199415.3586\n",
      "Epoch 4983/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 591859236.7721 - val_loss: 3030537622.2897\n",
      "Epoch 4984/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 635543070.5414 - val_loss: 3892525575.5972\n",
      "Epoch 4985/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 627579505.2696 - val_loss: 2999638553.9601\n",
      "Epoch 4986/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 496438028.9477 - val_loss: 2853506117.1218\n",
      "Epoch 4987/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 520912138.0124 - val_loss: 3498450454.3955\n",
      "Epoch 4988/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 627966109.6950 - val_loss: 2842326017.2422\n",
      "Epoch 4989/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 719538650.3343 - val_loss: 3009707114.7207\n",
      "Epoch 4990/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 529578756.9882 - val_loss: 3896455007.5589\n",
      "Epoch 4991/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 722836850.8542 - val_loss: 3011584820.1541\n",
      "Epoch 4992/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 775825354.5706 - val_loss: 2896880121.5505\n",
      "Epoch 4993/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 646174960.2971 - val_loss: 5613809393.3097\n",
      "Epoch 4994/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1504639992.9094 - val_loss: 3542222524.6515\n",
      "Epoch 4995/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 749803462.6449 - val_loss: 4299022581.9454\n",
      "Epoch 4996/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 724637328.4232 - val_loss: 3102766714.8152\n",
      "Epoch 4997/7000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 565761340.9387 - val_loss: 2944934292.2577\n",
      "Epoch 4998/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 458870022.0056 - val_loss: 2915299343.7705\n",
      "Epoch 4999/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 87us/step - loss: 499900239.5228 - val_loss: 2929416300.7550\n",
      "Epoch 5000/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 573458315.0748 - val_loss: 3368773963.4678\n",
      "Epoch 5001/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 701106416.8869 - val_loss: 3469184750.6453\n",
      "Epoch 5002/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 600322834.4581 - val_loss: 2938816002.0028\n",
      "Epoch 5003/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 570782849.7648 - val_loss: 2779599554.6599\n",
      "Epoch 5004/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 562571807.3360 - val_loss: 3060608412.9845\n",
      "Epoch 5005/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 567528770.2330 - val_loss: 3423901596.9845\n",
      "Epoch 5006/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 635328434.2780 - val_loss: 2852534437.3333\n",
      "Epoch 5007/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 581496171.6331 - val_loss: 3274035654.1390\n",
      "Epoch 5008/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 545689758.0191 - val_loss: 2774286803.8571\n",
      "Epoch 5009/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 825950339.9257 - val_loss: 3098332705.9713\n",
      "Epoch 5010/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 878721737.4631 - val_loss: 3140403271.8852\n",
      "Epoch 5011/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 464639125.0062 - val_loss: 2870183528.0923\n",
      "Epoch 5012/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 456824891.8222 - val_loss: 3194439181.4301\n",
      "Epoch 5013/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 657022836.8171 - val_loss: 2936488487.0031\n",
      "Epoch 5014/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 632597825.8008 - val_loss: 3800575114.8017\n",
      "Epoch 5015/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 549146068.8891 - val_loss: 3259116824.3398\n",
      "Epoch 5016/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1060811433.2741 - val_loss: 4811260785.7058\n",
      "Epoch 5017/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 644053380.0698 - val_loss: 3468241919.9010\n",
      "Epoch 5018/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 517321278.4513 - val_loss: 2942903497.6675\n",
      "Epoch 5019/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 662536506.6066 - val_loss: 2836407965.5246\n",
      "Epoch 5020/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 427761522.9983 - val_loss: 2937039810.7904\n",
      "Epoch 5021/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 706333656.1936 - val_loss: 3504065198.9423\n",
      "Epoch 5022/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 555353314.3230 - val_loss: 3092627512.8349\n",
      "Epoch 5023/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 548590062.2082 - val_loss: 6403174928.0225\n",
      "Epoch 5024/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1301247350.2757 - val_loss: 2951972455.0481\n",
      "Epoch 5025/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 471231993.6117 - val_loss: 3424387965.1195\n",
      "Epoch 5026/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 529660813.2448 - val_loss: 2922407997.9432\n",
      "Epoch 5027/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 469943532.4389 - val_loss: 2923499928.4748\n",
      "Epoch 5028/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 604562052.3534 - val_loss: 3271757493.1803\n",
      "Epoch 5029/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 625832346.1294 - val_loss: 2929252323.4295\n",
      "Epoch 5030/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 547149038.7124 - val_loss: 2796255016.5063\n",
      "Epoch 5031/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 531116569.3371 - val_loss: 6949261385.0914\n",
      "Epoch 5032/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 737842820.8523 - val_loss: 2997954395.4543\n",
      "Epoch 5033/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 738387842.9893 - val_loss: 2938612104.1913\n",
      "Epoch 5034/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 582830399.2257 - val_loss: 3400763897.3570\n",
      "Epoch 5035/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 914564906.5166 - val_loss: 5484845815.2506\n",
      "Epoch 5036/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 764012239.2347 - val_loss: 3475009928.0473\n",
      "Epoch 5037/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 874491784.8779 - val_loss: 3117563097.3480\n",
      "Epoch 5038/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 800767576.7968 - val_loss: 3334181577.0554\n",
      "Epoch 5039/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 588629840.6753 - val_loss: 3019066695.0751\n",
      "Epoch 5040/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 517615765.1683 - val_loss: 2977838531.6726\n",
      "Epoch 5041/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 689516059.9932 - val_loss: 2996895392.1350\n",
      "Epoch 5042/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 559411180.5875 - val_loss: 3248354625.4222\n",
      "Epoch 5043/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 530395474.6697 - val_loss: 3237098303.6309\n",
      "Epoch 5044/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1019416098.3140 - val_loss: 3068744885.0543\n",
      "Epoch 5045/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 591461122.9353 - val_loss: 3552806364.1384\n",
      "Epoch 5046/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 570562527.1806 - val_loss: 2922009611.1842\n",
      "Epoch 5047/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 511811376.6213 - val_loss: 2916520706.3809\n",
      "Epoch 5048/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 576455904.8132 - val_loss: 3477577571.7896\n",
      "Epoch 5049/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 704729239.2842 - val_loss: 5771164600.6008\n",
      "Epoch 5050/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 794651325.1548 - val_loss: 4143710577.7058\n",
      "Epoch 5051/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 540260580.3039 - val_loss: 3387957005.3941\n",
      "Epoch 5052/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 702226933.5779 - val_loss: 2743382399.3879\n",
      "Epoch 5053/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 642436763.9842 - val_loss: 3760453597.1916\n",
      "Epoch 5054/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 839043226.2195 - val_loss: 7475399713.8453\n",
      "Epoch 5055/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 817962118.8430 - val_loss: 3370254331.3193\n",
      "Epoch 5056/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 719467537.6657 - val_loss: 3836734220.6380\n",
      "Epoch 5057/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 487485560.6168 - val_loss: 4464286861.6461\n",
      "Epoch 5058/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 579613355.0748 - val_loss: 2805502275.0740\n",
      "Epoch 5059/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 722412795.9662 - val_loss: 3327789977.6000\n",
      "Epoch 5060/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 701004744.5537 - val_loss: 2745694115.8526\n",
      "Epoch 5061/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 637841554.8362 - val_loss: 3056623289.5730\n",
      "Epoch 5062/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 573330948.7901 - val_loss: 2977524346.1311\n",
      "Epoch 5063/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 643898501.6545 - val_loss: 3149168323.1235\n",
      "Epoch 5064/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 88us/step - loss: 710592376.3467 - val_loss: 2832695861.4594\n",
      "Epoch 5065/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 614188159.8559 - val_loss: 3319117476.3837\n",
      "Epoch 5066/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 651623839.5138 - val_loss: 4732005206.9176\n",
      "Epoch 5067/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 636031865.1570 - val_loss: 2967364895.5769\n",
      "Epoch 5068/7000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 529359614.4153 - val_loss: 5104227114.4506\n",
      "Epoch 5069/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 727541702.7169 - val_loss: 3347007061.5134\n",
      "Epoch 5070/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 584920373.8436 - val_loss: 2782871529.3435\n",
      "Epoch 5071/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 634459166.6134 - val_loss: 3330658148.5997\n",
      "Epoch 5072/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 737270283.8852 - val_loss: 2803343714.3134\n",
      "Epoch 5073/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 481443704.5087 - val_loss: 3385810975.6850\n",
      "Epoch 5074/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 681810206.6134 - val_loss: 2914268502.1277\n",
      "Epoch 5075/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 770953033.6162 - val_loss: 3297798079.5139\n",
      "Epoch 5076/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 503748284.3624 - val_loss: 3642415208.3083\n",
      "Epoch 5077/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 622320116.8261 - val_loss: 2767848472.1958\n",
      "Epoch 5078/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 457819512.3647 - val_loss: 3351383086.5373\n",
      "Epoch 5079/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 727098860.4795 - val_loss: 2877446861.4931\n",
      "Epoch 5080/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 711222867.4125 - val_loss: 3185217184.4771\n",
      "Epoch 5081/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 660136722.4356 - val_loss: 3238091125.5314\n",
      "Epoch 5082/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 541480539.3450 - val_loss: 3039678640.0765\n",
      "Epoch 5083/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 486208955.5931 - val_loss: 2794313161.8115\n",
      "Epoch 5084/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 652184929.6443 - val_loss: 2901158245.5359\n",
      "Epoch 5085/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 472267754.0245 - val_loss: 2838901310.7938\n",
      "Epoch 5086/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 541229255.3832 - val_loss: 3478137910.0174\n",
      "Epoch 5087/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 680190919.5993 - val_loss: 3453474334.2087\n",
      "Epoch 5088/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 630157998.1362 - val_loss: 3505400479.8020\n",
      "Epoch 5089/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 546765208.4907 - val_loss: 3610116682.4596\n",
      "Epoch 5090/7000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 540193322.5166 - val_loss: 2848143965.9207\n",
      "Epoch 5091/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 487493705.3866 - val_loss: 4105439847.8582\n",
      "Epoch 5092/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1258207083.8852 - val_loss: 3261383081.9826\n",
      "Epoch 5093/7000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 553603960.2926 - val_loss: 3774105648.1485\n",
      "Epoch 5094/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 568834500.4479 - val_loss: 2998762453.9499\n",
      "Epoch 5095/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 514206561.6567 - val_loss: 4234532482.1783\n",
      "Epoch 5096/7000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 722620711.0051 - val_loss: 3724030524.8135\n",
      "Epoch 5097/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 887981571.9797 - val_loss: 3013066452.0911\n",
      "Epoch 5098/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 584752029.2358 - val_loss: 2944764191.4689\n",
      "Epoch 5099/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 491076619.8492 - val_loss: 4326611743.0368\n",
      "Epoch 5100/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 759721843.9707 - val_loss: 3889207749.5809\n",
      "Epoch 5101/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 617614500.3759 - val_loss: 3988314057.2534\n",
      "Epoch 5102/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 539854995.8312 - val_loss: 3043179015.2191\n",
      "Epoch 5103/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 556156873.0355 - val_loss: 3332527065.6000\n",
      "Epoch 5104/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 634215775.4057 - val_loss: 3210990784.5671\n",
      "Epoch 5105/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 662437010.2780 - val_loss: 2752063750.7241\n",
      "Epoch 5106/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 503552720.6303 - val_loss: 2963142039.7997\n",
      "Epoch 5107/7000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 606598841.1930 - val_loss: 3879805638.8951\n",
      "Epoch 5108/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 644322849.8368 - val_loss: 2977702090.0276\n",
      "Epoch 5109/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 416118295.6263 - val_loss: 3013869182.5418\n",
      "Epoch 5110/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 725291632.9454 - val_loss: 2935515673.1859\n",
      "Epoch 5111/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 665979115.2549 - val_loss: 2875101368.0788\n",
      "Epoch 5112/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 700501923.1154 - val_loss: 2969674179.5286\n",
      "Epoch 5113/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 539701023.9460 - val_loss: 2919719913.8115\n",
      "Epoch 5114/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 795921330.6382 - val_loss: 5267523772.9035\n",
      "Epoch 5115/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1066798077.8751 - val_loss: 2755304138.7117\n",
      "Epoch 5116/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 577511001.1750 - val_loss: 2997112551.0481\n",
      "Epoch 5117/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 678932949.2223 - val_loss: 2873647562.5947\n",
      "Epoch 5118/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 556561371.8244 - val_loss: 3538718306.5654\n",
      "Epoch 5119/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 598442779.3945 - val_loss: 2754070309.8959\n",
      "Epoch 5120/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 616856223.5633 - val_loss: 2815459742.4248\n",
      "Epoch 5121/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 596504397.4159 - val_loss: 2861252963.1775\n",
      "Epoch 5122/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 411473565.6050 - val_loss: 3539686333.4616\n",
      "Epoch 5123/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 604731533.9502 - val_loss: 2777482231.3677\n",
      "Epoch 5124/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 459612403.8267 - val_loss: 3105847644.6785\n",
      "Epoch 5125/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 584554313.9043 - val_loss: 3059778419.9741\n",
      "Epoch 5126/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 722438612.7811 - val_loss: 4417219286.1975\n",
      "Epoch 5127/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 674793554.5144 - val_loss: 2721359554.7184\n",
      "Epoch 5128/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 431114828.7766 - val_loss: 3598498539.8459\n",
      "Epoch 5129/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 71us/step - loss: 531083734.0326 - val_loss: 3368382817.1072\n",
      "Epoch 5130/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 481422785.0445 - val_loss: 2793803990.2515\n",
      "Epoch 5131/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 596723965.8841 - val_loss: 4665405399.5117\n",
      "Epoch 5132/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 877871530.8588 - val_loss: 4257392804.1496\n",
      "Epoch 5133/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 653559401.4564 - val_loss: 4241329204.2622\n",
      "Epoch 5134/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 594310931.2504 - val_loss: 2869736372.3972\n",
      "Epoch 5135/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 562814866.4761 - val_loss: 3215889260.3589\n",
      "Epoch 5136/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 627345256.7518 - val_loss: 3986412522.2526\n",
      "Epoch 5137/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 851187315.8987 - val_loss: 3534719245.1421\n",
      "Epoch 5138/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 522910040.5616 - val_loss: 2832680748.4850\n",
      "Epoch 5139/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 767898417.7738 - val_loss: 3235077144.8101\n",
      "Epoch 5140/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 706672126.9555 - val_loss: 3424086679.9617\n",
      "Epoch 5141/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 682951668.4750 - val_loss: 3764167425.2242\n",
      "Epoch 5142/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 655658231.1401 - val_loss: 2779824755.5060\n",
      "Epoch 5143/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 524247960.8329 - val_loss: 3685023363.8886\n",
      "Epoch 5144/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 584648019.6837 - val_loss: 3983305877.5314\n",
      "Epoch 5145/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 543230573.9021 - val_loss: 3606215444.5232\n",
      "Epoch 5146/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 695037761.1885 - val_loss: 3126736369.7598\n",
      "Epoch 5147/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 807016956.5425 - val_loss: 2741171891.2383\n",
      "Epoch 5148/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 481075079.4958 - val_loss: 2864514115.7626\n",
      "Epoch 5149/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 439034322.3680 - val_loss: 3031657662.4338\n",
      "Epoch 5150/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 636997667.7907 - val_loss: 3748210154.6127\n",
      "Epoch 5151/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 661147729.1615 - val_loss: 2833566272.0000\n",
      "Epoch 5152/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 494835580.0788 - val_loss: 3336031332.1857\n",
      "Epoch 5153/7000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 550777865.4856 - val_loss: 3411159455.1449\n",
      "Epoch 5154/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 855106343.3742 - val_loss: 2901471401.4335\n",
      "Epoch 5155/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 531490637.1480 - val_loss: 2687337275.6703\n",
      "Epoch 5156/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 622828420.5920 - val_loss: 4424225924.3207\n",
      "Epoch 5157/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 657426201.3911 - val_loss: 2748466601.7710\n",
      "Epoch 5158/7000\n",
      "3554/3554 [==============================] - 1s 146us/step - loss: 450619552.7743 - val_loss: 2731221404.7280\n",
      "Epoch 5159/7000\n",
      "3554/3554 [==============================] - 1s 141us/step - loss: 503869656.9229 - val_loss: 2771168488.7944\n",
      "Epoch 5160/7000\n",
      "3554/3554 [==============================] - 1s 153us/step - loss: 602887448.6348 - val_loss: 3073239038.5598\n",
      "Epoch 5161/7000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 670396353.0805 - val_loss: 3409659014.2650\n",
      "Epoch 5162/7000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 490213505.3326 - val_loss: 3047389284.2802\n",
      "Epoch 5163/7000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 514504658.4041 - val_loss: 3344995910.1120\n",
      "Epoch 5164/7000\n",
      "3554/3554 [==============================] - 1s 146us/step - loss: 501546184.0990 - val_loss: 2727878453.7924\n",
      "Epoch 5165/7000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 502098275.5656 - val_loss: 5238123021.0340\n",
      "Epoch 5166/7000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 813300163.9257 - val_loss: 3457994827.9719\n",
      "Epoch 5167/7000\n",
      "3554/3554 [==============================] - 1s 153us/step - loss: 663249691.0118 - val_loss: 4033241845.8104\n",
      "Epoch 5168/7000\n",
      "3554/3554 [==============================] - 0s 140us/step - loss: 658865792.1441 - val_loss: 3333696203.5038\n",
      "Epoch 5169/7000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 655727272.9792 - val_loss: 3018451683.6681\n",
      "Epoch 5170/7000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 514964098.0889 - val_loss: 3228272163.5015\n",
      "Epoch 5171/7000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 540212486.9105 - val_loss: 2968618539.4588\n",
      "Epoch 5172/7000\n",
      "3554/3554 [==============================] - 0s 131us/step - loss: 566751693.5059 - val_loss: 2807317007.8200\n",
      "Epoch 5173/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 636472208.0450 - val_loss: 3039466748.8945\n",
      "Epoch 5174/7000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 530005513.1480 - val_loss: 3574911364.1226\n",
      "Epoch 5175/7000\n",
      "3554/3554 [==============================] - 0s 132us/step - loss: 563358606.5504 - val_loss: 3640970494.1637\n",
      "Epoch 5176/7000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 668521966.2983 - val_loss: 3654740336.6976\n",
      "Epoch 5177/7000\n",
      "3554/3554 [==============================] - 0s 131us/step - loss: 679242878.9555 - val_loss: 2744787561.2444\n",
      "Epoch 5178/7000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 492439375.5588 - val_loss: 2905289598.5328\n",
      "Epoch 5179/7000\n",
      "3554/3554 [==============================] - 1s 162us/step - loss: 753021989.4204 - val_loss: 3259103468.6290\n",
      "Epoch 5180/7000\n",
      "3554/3554 [==============================] - 1s 150us/step - loss: 556947603.8087 - val_loss: 2722986701.2771\n",
      "Epoch 5181/7000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 585127051.8627 - val_loss: 3111945749.4954\n",
      "Epoch 5182/7000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 452606764.9387 - val_loss: 3033997619.4160\n",
      "Epoch 5183/7000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 843738065.9989 - val_loss: 3256205912.0068\n",
      "Epoch 5184/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 518261222.9690 - val_loss: 4431929451.5128\n",
      "Epoch 5185/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 818072676.4119 - val_loss: 3062607887.1584\n",
      "Epoch 5186/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 581154530.0349 - val_loss: 5143676283.3913\n",
      "Epoch 5187/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 646318942.3793 - val_loss: 2836803206.3100\n",
      "Epoch 5188/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 527285509.0535 - val_loss: 2816292570.0906\n",
      "Epoch 5189/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 441986916.2915 - val_loss: 3419595829.5584\n",
      "Epoch 5190/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 450701451.9932 - val_loss: 2884246233.5460\n",
      "Epoch 5191/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 622887278.7845 - val_loss: 2935242900.3117\n",
      "Epoch 5192/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 561137614.7755 - val_loss: 3819626244.6807\n",
      "Epoch 5193/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 736040603.9122 - val_loss: 5301891483.9044\n",
      "Epoch 5194/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 75us/step - loss: 656003454.4963 - val_loss: 2752909583.6624\n",
      "Epoch 5195/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 488291130.4176 - val_loss: 2797128695.9347\n",
      "Epoch 5196/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 497892387.3315 - val_loss: 3530341144.0158\n",
      "Epoch 5197/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 621263410.2870 - val_loss: 2726713858.9525\n",
      "Epoch 5198/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 481272706.4491 - val_loss: 3004566327.6647\n",
      "Epoch 5199/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 547334034.1519 - val_loss: 3075878806.2650\n",
      "Epoch 5200/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 579620471.1896 - val_loss: 3669630274.3764\n",
      "Epoch 5201/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 798745881.7873 - val_loss: 2891699831.3249\n",
      "Epoch 5202/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 453772624.0990 - val_loss: 2969575162.3651\n",
      "Epoch 5203/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 488965600.6978 - val_loss: 3297413645.1781\n",
      "Epoch 5204/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 547966610.4401 - val_loss: 3611844510.6408\n",
      "Epoch 5205/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1115686091.4530 - val_loss: 2965436577.0712\n",
      "Epoch 5206/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 461821205.0512 - val_loss: 3434538035.6321\n",
      "Epoch 5207/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 656769639.4913 - val_loss: 3263197069.1150\n",
      "Epoch 5208/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 466946863.9730 - val_loss: 3470045697.2242\n",
      "Epoch 5209/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 657193671.9955 - val_loss: 5351983369.6135\n",
      "Epoch 5210/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 578970449.8776 - val_loss: 3021954188.8540\n",
      "Epoch 5211/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 513239095.8616 - val_loss: 2910195648.6121\n",
      "Epoch 5212/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 504997020.2183 - val_loss: 3305171037.6686\n",
      "Epoch 5213/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 771978918.7530 - val_loss: 3101445421.0520\n",
      "Epoch 5214/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 581932008.7878 - val_loss: 2959175660.4489\n",
      "Epoch 5215/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 608257189.1683 - val_loss: 3011807529.7215\n",
      "Epoch 5216/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 625198592.5763 - val_loss: 3006251179.8008\n",
      "Epoch 5217/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 582782953.1660 - val_loss: 2912801189.8419\n",
      "Epoch 5218/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 620222218.2105 - val_loss: 3424206021.2478\n",
      "Epoch 5219/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 535462871.8784 - val_loss: 3101187835.1392\n",
      "Epoch 5220/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 621172467.7907 - val_loss: 2853941779.8931\n",
      "Epoch 5221/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 620395275.3450 - val_loss: 3674003703.7187\n",
      "Epoch 5222/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 681548946.2240 - val_loss: 3052093452.1541\n",
      "Epoch 5223/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 767230867.8267 - val_loss: 3297258162.1648\n",
      "Epoch 5224/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 564198928.2071 - val_loss: 2767863286.1885\n",
      "Epoch 5225/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 505355355.7862 - val_loss: 3261260275.4520\n",
      "Epoch 5226/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 509163869.4969 - val_loss: 2976901380.7977\n",
      "Epoch 5227/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 526562107.0118 - val_loss: 3784851451.2293\n",
      "Epoch 5228/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 751142457.1210 - val_loss: 2951052511.5949\n",
      "Epoch 5229/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 504184212.7023 - val_loss: 2733297742.0602\n",
      "Epoch 5230/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 645904723.4125 - val_loss: 5697902529.0622\n",
      "Epoch 5231/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 920848944.1351 - val_loss: 2917731743.5994\n",
      "Epoch 5232/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 557867302.4705 - val_loss: 2880685036.7010\n",
      "Epoch 5233/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 514293754.9578 - val_loss: 3099198412.1249\n",
      "Epoch 5234/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 784936506.8948 - val_loss: 2817772818.0748\n",
      "Epoch 5235/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 474666738.6201 - val_loss: 2726347311.9145\n",
      "Epoch 5236/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 503148039.4913 - val_loss: 3296827160.4478\n",
      "Epoch 5237/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 993687895.3022 - val_loss: 2749471087.7255\n",
      "Epoch 5238/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 572067597.2538 - val_loss: 3165580540.8990\n",
      "Epoch 5239/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 478575741.5509 - val_loss: 2903244716.3319\n",
      "Epoch 5240/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 663150135.7164 - val_loss: 3521666800.6616\n",
      "Epoch 5241/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 675361458.5841 - val_loss: 3600368728.6278\n",
      "Epoch 5242/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 560315046.6809 - val_loss: 3739294722.5924\n",
      "Epoch 5243/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 593281085.5689 - val_loss: 3567755374.3032\n",
      "Epoch 5244/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 638897518.7124 - val_loss: 2819243321.7350\n",
      "Epoch 5245/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 588003288.4907 - val_loss: 2931956862.1367\n",
      "Epoch 5246/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 542582585.3011 - val_loss: 2747819352.8259\n",
      "Epoch 5247/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 526230466.1249 - val_loss: 2829773678.8973\n",
      "Epoch 5248/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 644642104.7271 - val_loss: 2829045290.5992\n",
      "Epoch 5249/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 649856381.4789 - val_loss: 4330158024.3893\n",
      "Epoch 5250/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 592812354.4541 - val_loss: 2994861290.9097\n",
      "Epoch 5251/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 522361776.7037 - val_loss: 3121701548.7370\n",
      "Epoch 5252/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 522144921.3799 - val_loss: 3732681759.2349\n",
      "Epoch 5253/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 501707146.3725 - val_loss: 2752581031.0301\n",
      "Epoch 5254/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 515749544.4204 - val_loss: 2983188961.7013\n",
      "Epoch 5255/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 771749302.6899 - val_loss: 2938156727.3108\n",
      "Epoch 5256/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 559664629.1232 - val_loss: 2719507591.8312\n",
      "Epoch 5257/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 502035596.1733 - val_loss: 3321919178.5541\n",
      "Epoch 5258/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 531039847.0231 - val_loss: 2991134722.3134\n",
      "Epoch 5259/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 76us/step - loss: 520128403.6736 - val_loss: 2768712616.6504\n",
      "Epoch 5260/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 571704934.9330 - val_loss: 3254803333.3108\n",
      "Epoch 5261/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 646206277.8706 - val_loss: 3452795360.5221\n",
      "Epoch 5262/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1004659797.3213 - val_loss: 2757017064.0698\n",
      "Epoch 5263/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 751313411.2414 - val_loss: 2933102430.1907\n",
      "Epoch 5264/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 876542612.3500 - val_loss: 3056440671.2349\n",
      "Epoch 5265/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 658037133.9921 - val_loss: 2753311299.6726\n",
      "Epoch 5266/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 431335612.4705 - val_loss: 3300859676.7325\n",
      "Epoch 5267/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 461516123.7681 - val_loss: 4213846087.1111\n",
      "Epoch 5268/7000\n",
      "3554/3554 [==============================] - 0s 68us/step - loss: 850676790.4558 - val_loss: 4414255729.3817\n",
      "Epoch 5269/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 828884614.7349 - val_loss: 3226539968.5581\n",
      "Epoch 5270/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 665943823.3967 - val_loss: 2766134758.4180\n",
      "Epoch 5271/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 438951953.1075 - val_loss: 2860281829.1173\n",
      "Epoch 5272/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 451858142.6134 - val_loss: 2952387615.2709\n",
      "Epoch 5273/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 517318881.2493 - val_loss: 2847569099.8098\n",
      "Epoch 5274/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 613208707.2414 - val_loss: 3220922365.8037\n",
      "Epoch 5275/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 904194197.2493 - val_loss: 3326162353.8138\n",
      "Epoch 5276/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 652920559.5768 - val_loss: 2759490818.4934\n",
      "Epoch 5277/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 486329303.8424 - val_loss: 3626164324.2397\n",
      "Epoch 5278/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 759779689.9223 - val_loss: 2902806109.0880\n",
      "Epoch 5279/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 463985463.7524 - val_loss: 5614659963.3553\n",
      "Epoch 5280/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 648303017.4721 - val_loss: 2799612042.6217\n",
      "Epoch 5281/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 502875844.0878 - val_loss: 2885254230.5395\n",
      "Epoch 5282/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 481150497.8368 - val_loss: 2838944035.0335\n",
      "Epoch 5283/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 473499930.7237 - val_loss: 2864541084.3657\n",
      "Epoch 5284/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 539224072.0630 - val_loss: 3040096098.8174\n",
      "Epoch 5285/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 735585338.3275 - val_loss: 3461101228.5390\n",
      "Epoch 5286/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 563862182.5909 - val_loss: 3002396680.7134\n",
      "Epoch 5287/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 509589111.7524 - val_loss: 2990095139.8526\n",
      "Epoch 5288/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 403749228.3534 - val_loss: 2756377307.3868\n",
      "Epoch 5289/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 632628241.0715 - val_loss: 4329252758.5755\n",
      "Epoch 5290/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 625601854.4333 - val_loss: 3257556828.1744\n",
      "Epoch 5291/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 548139168.9184 - val_loss: 3786797273.2579\n",
      "Epoch 5292/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 547943629.5059 - val_loss: 3328753545.6315\n",
      "Epoch 5293/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 637951601.8638 - val_loss: 4069452192.8011\n",
      "Epoch 5294/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 623389142.7079 - val_loss: 3157245065.9736\n",
      "Epoch 5295/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 601661186.6111 - val_loss: 2855004705.1792\n",
      "Epoch 5296/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 456392257.9629 - val_loss: 3028218644.7077\n",
      "Epoch 5297/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 652597136.4952 - val_loss: 2882281647.3474\n",
      "Epoch 5298/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 562744006.3658 - val_loss: 2863541076.7752\n",
      "Epoch 5299/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 462186104.2926 - val_loss: 2806496287.7930\n",
      "Epoch 5300/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 902092544.4911 - val_loss: 2955124852.0641\n",
      "Epoch 5301/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 486745776.8464 - val_loss: 2706921761.1162\n",
      "Epoch 5302/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 470543716.9162 - val_loss: 2922428258.2954\n",
      "Epoch 5303/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 667304828.0743 - val_loss: 3194345980.6155\n",
      "Epoch 5304/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 725118521.1210 - val_loss: 2816644892.7685\n",
      "Epoch 5305/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 541292930.5031 - val_loss: 3888083388.6155\n",
      "Epoch 5306/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 552813004.1283 - val_loss: 3129772245.9994\n",
      "Epoch 5307/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 493539029.0017 - val_loss: 2933665431.7277\n",
      "Epoch 5308/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 531354262.3658 - val_loss: 2752202940.3814\n",
      "Epoch 5309/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 472782417.0515 - val_loss: 3167307871.0368\n",
      "Epoch 5310/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1032178631.3112 - val_loss: 3090844122.6419\n",
      "Epoch 5311/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 782969063.9775 - val_loss: 2781427737.9601\n",
      "Epoch 5312/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 781980963.0996 - val_loss: 2695996867.4925\n",
      "Epoch 5313/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 569366026.2690 - val_loss: 2852088621.4391\n",
      "Epoch 5314/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 494695708.9026 - val_loss: 2774167963.5184\n",
      "Epoch 5315/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 556231871.9235 - val_loss: 2710456641.9623\n",
      "Epoch 5316/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 400639305.5262 - val_loss: 2958747791.4554\n",
      "Epoch 5317/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 593981791.2077 - val_loss: 2744554124.2419\n",
      "Epoch 5318/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 457381414.0326 - val_loss: 2863811593.0014\n",
      "Epoch 5319/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 504074583.8424 - val_loss: 2755872076.1339\n",
      "Epoch 5320/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 477684684.1013 - val_loss: 2915834360.5828\n",
      "Epoch 5321/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 451279705.5464 - val_loss: 2778637511.8717\n",
      "Epoch 5322/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 626114412.6595 - val_loss: 2993483533.9432\n",
      "Epoch 5323/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 612024645.2943 - val_loss: 4328048161.2692\n",
      "Epoch 5324/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 80us/step - loss: 742584923.6106 - val_loss: 3158327307.3058\n",
      "Epoch 5325/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 554082315.7952 - val_loss: 2809617952.8371\n",
      "Epoch 5326/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 639390162.4401 - val_loss: 2901070610.9030\n",
      "Epoch 5327/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 450230710.3838 - val_loss: 2994088075.8368\n",
      "Epoch 5328/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 665278733.1255 - val_loss: 3208901941.3243\n",
      "Epoch 5329/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 603425551.3787 - val_loss: 2783096762.5451\n",
      "Epoch 5330/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 452415545.3371 - val_loss: 2737565549.3221\n",
      "Epoch 5331/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 787664776.7878 - val_loss: 2732695074.1513\n",
      "Epoch 5332/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 614186637.0737 - val_loss: 2671274268.2464\n",
      "Epoch 5333/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 448784734.7214 - val_loss: 2827235280.2925\n",
      "Epoch 5334/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 596310055.5453 - val_loss: 4165094642.8940\n",
      "Epoch 5335/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 548919651.5115 - val_loss: 2785706711.7637\n",
      "Epoch 5336/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 758329795.4755 - val_loss: 2757746841.2399\n",
      "Epoch 5337/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 493792005.0782 - val_loss: 2771713318.8501\n",
      "Epoch 5338/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 479179759.7209 - val_loss: 2814934450.7229\n",
      "Epoch 5339/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 478936157.0647 - val_loss: 2960828001.6473\n",
      "Epoch 5340/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 620026656.4772 - val_loss: 3385215665.9308\n",
      "Epoch 5341/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 520534444.8396 - val_loss: 2855188384.3691\n",
      "Epoch 5342/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 604650593.5802 - val_loss: 2776018312.3533\n",
      "Epoch 5343/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 466495416.9049 - val_loss: 3635970052.9148\n",
      "Epoch 5344/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 705592576.9364 - val_loss: 2848697288.2993\n",
      "Epoch 5345/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 522755432.4097 - val_loss: 2785525740.7910\n",
      "Epoch 5346/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 516074240.7383 - val_loss: 3525673035.4678\n",
      "Epoch 5347/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 642655874.9893 - val_loss: 3729412860.5435\n",
      "Epoch 5348/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 650090613.6095 - val_loss: 3103321943.3722\n",
      "Epoch 5349/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 487988068.4389 - val_loss: 2813797387.0627\n",
      "Epoch 5350/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 697841470.5053 - val_loss: 2769167997.6686\n",
      "Epoch 5351/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 708274746.7552 - val_loss: 4503680555.5668\n",
      "Epoch 5352/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 559030342.0844 - val_loss: 2710065456.7786\n",
      "Epoch 5353/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 583094398.9916 - val_loss: 3288647834.6802\n",
      "Epoch 5354/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 763495113.0940 - val_loss: 2643460273.9218\n",
      "Epoch 5355/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 454923197.9471 - val_loss: 3364430882.6194\n",
      "Epoch 5356/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 515394304.3782 - val_loss: 2923902463.6534\n",
      "Epoch 5357/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 639763791.1041 - val_loss: 2880688474.0861\n",
      "Epoch 5358/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 536678983.0951 - val_loss: 2952115137.0982\n",
      "Epoch 5359/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 719285672.4097 - val_loss: 2986366880.9451\n",
      "Epoch 5360/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 515673662.5053 - val_loss: 2823828917.5584\n",
      "Epoch 5361/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 556101677.5059 - val_loss: 4070419416.4478\n",
      "Epoch 5362/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 651298618.0574 - val_loss: 3641977806.0062\n",
      "Epoch 5363/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 743168816.9454 - val_loss: 4852093561.4110\n",
      "Epoch 5364/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 902642211.1334 - val_loss: 2863830624.4951\n",
      "Epoch 5365/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 517547202.0529 - val_loss: 2879196261.1758\n",
      "Epoch 5366/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 532031936.1891 - val_loss: 2801496486.9671\n",
      "Epoch 5367/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 396138764.6956 - val_loss: 2674661686.3910\n",
      "Epoch 5368/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 462064041.1300 - val_loss: 5945477411.3395\n",
      "Epoch 5369/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1296366827.3630 - val_loss: 3481988951.7457\n",
      "Epoch 5370/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 480465807.8863 - val_loss: 2716537792.1260\n",
      "Epoch 5371/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 507691657.9764 - val_loss: 4574908673.2962\n",
      "Epoch 5372/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 796596066.5031 - val_loss: 2811401032.8079\n",
      "Epoch 5373/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 483748169.9561 - val_loss: 2598303445.9814\n",
      "Epoch 5374/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 438057050.7237 - val_loss: 2866989254.1660\n",
      "Epoch 5375/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 495760854.8700 - val_loss: 2991112292.7437\n",
      "Epoch 5376/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 989659358.3838 - val_loss: 4110190375.3902\n",
      "Epoch 5377/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 515932364.0653 - val_loss: 3195282314.7117\n",
      "Epoch 5378/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 672756281.6972 - val_loss: 2816899531.6118\n",
      "Epoch 5379/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 510104805.2403 - val_loss: 2733127228.3094\n",
      "Epoch 5380/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 435477300.4389 - val_loss: 3029788342.1525\n",
      "Epoch 5381/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 577881487.0546 - val_loss: 2705892657.8228\n",
      "Epoch 5382/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 807522376.9319 - val_loss: 2718748147.7356\n",
      "Epoch 5383/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 495202368.8284 - val_loss: 3970582318.3032\n",
      "Epoch 5384/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 634636020.2949 - val_loss: 4532899254.2605\n",
      "Epoch 5385/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 585412415.4778 - val_loss: 2833088966.1615\n",
      "Epoch 5386/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 570821678.1092 - val_loss: 2714943476.0461\n",
      "Epoch 5387/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 383953966.6021 - val_loss: 2651868373.2658\n",
      "Epoch 5388/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 390173537.1705 - val_loss: 4408340675.8706\n",
      "Epoch 5389/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 73us/step - loss: 701129501.7490 - val_loss: 2770380931.4835\n",
      "Epoch 5390/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 618828096.9949 - val_loss: 2734141557.4053\n",
      "Epoch 5391/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 451759721.8143 - val_loss: 3028497447.7547\n",
      "Epoch 5392/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 786283414.0777 - val_loss: 3166137672.3713\n",
      "Epoch 5393/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 670629957.2583 - val_loss: 2645149948.1564\n",
      "Epoch 5394/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 506141293.7400 - val_loss: 2741708945.3547\n",
      "Epoch 5395/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 517546290.7867 - val_loss: 3118608744.6323\n",
      "Epoch 5396/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 441337814.0777 - val_loss: 2982418820.2307\n",
      "Epoch 5397/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 534111776.9634 - val_loss: 3076522435.6456\n",
      "Epoch 5398/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 550710665.0039 - val_loss: 2905856602.1941\n",
      "Epoch 5399/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 615692640.7833 - val_loss: 2634625260.0529\n",
      "Epoch 5400/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 455533141.2493 - val_loss: 4477531932.0124\n",
      "Epoch 5401/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 784588214.8880 - val_loss: 3558984779.1797\n",
      "Epoch 5402/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 560821654.3433 - val_loss: 2807133193.1814\n",
      "Epoch 5403/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 497630556.7766 - val_loss: 3122912620.5570\n",
      "Epoch 5404/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 526793151.4868 - val_loss: 2608249215.6039\n",
      "Epoch 5405/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 627682140.7766 - val_loss: 3202089999.8425\n",
      "Epoch 5406/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1031652006.6269 - val_loss: 2983040941.9792\n",
      "Epoch 5407/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 487905947.8762 - val_loss: 2949117745.5527\n",
      "Epoch 5408/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 540071635.2617 - val_loss: 2670531516.5615\n",
      "Epoch 5409/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 405158502.2172 - val_loss: 2798511621.2568\n",
      "Epoch 5410/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 446101612.1193 - val_loss: 2914193181.3266\n",
      "Epoch 5411/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 423753263.7569 - val_loss: 2661549756.7325\n",
      "Epoch 5412/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 455984237.1638 - val_loss: 2642821199.4779\n",
      "Epoch 5413/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 521246847.4598 - val_loss: 2805906152.4523\n",
      "Epoch 5414/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 514180778.7867 - val_loss: 2692215073.5752\n",
      "Epoch 5415/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 611914097.1480 - val_loss: 2685301075.7671\n",
      "Epoch 5416/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 506181409.1345 - val_loss: 2809259354.3741\n",
      "Epoch 5417/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1103453492.7631 - val_loss: 2673898461.7226\n",
      "Epoch 5418/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 573498162.5481 - val_loss: 3543090149.6979\n",
      "Epoch 5419/7000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 567468858.128 - 0s 86us/step - loss: 565541753.6612 - val_loss: 3041260110.6993\n",
      "Epoch 5420/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 510815576.6708 - val_loss: 4426554617.0149\n",
      "Epoch 5421/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 476994210.4806 - val_loss: 2726073495.0346\n",
      "Epoch 5422/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 424140859.4980 - val_loss: 2609987989.5674\n",
      "Epoch 5423/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 412956365.4766 - val_loss: 2752338924.8450\n",
      "Epoch 5424/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 472954054.2307 - val_loss: 8345288653.6281\n",
      "Epoch 5425/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1105823154.3320 - val_loss: 2690568763.8864\n",
      "Epoch 5426/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 426793846.4198 - val_loss: 2600627594.2256\n",
      "Epoch 5427/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 464131069.7490 - val_loss: 3672547260.8675\n",
      "Epoch 5428/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 570635218.9736 - val_loss: 2997185833.5100\n",
      "Epoch 5429/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 479784938.7147 - val_loss: 2987988696.0473\n",
      "Epoch 5430/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 482308275.7727 - val_loss: 3160449967.2034\n",
      "Epoch 5431/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 443489200.6213 - val_loss: 2713675703.1246\n",
      "Epoch 5432/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 942830419.9887 - val_loss: 2780864776.8844\n",
      "Epoch 5433/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 534523420.7766 - val_loss: 2680579780.2667\n",
      "Epoch 5434/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 739418186.4356 - val_loss: 5622352756.5862\n",
      "Epoch 5435/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 896831294.0912 - val_loss: 2642627568.5716\n",
      "Epoch 5436/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 460912112.0090 - val_loss: 2947183319.3632\n",
      "Epoch 5437/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 450081163.9392 - val_loss: 2729086198.8456\n",
      "Epoch 5438/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 438270469.6005 - val_loss: 2908292665.9421\n",
      "Epoch 5439/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 474904159.6308 - val_loss: 2635113358.0242\n",
      "Epoch 5440/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 559757210.5616 - val_loss: 3445414864.2385\n",
      "Epoch 5441/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 687247182.8745 - val_loss: 2899293896.8169\n",
      "Epoch 5442/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 820987771.2099 - val_loss: 2761016781.7541\n",
      "Epoch 5443/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 411533791.0411 - val_loss: 2738268768.9992\n",
      "Epoch 5444/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 585755246.6134 - val_loss: 3135249131.6118\n",
      "Epoch 5445/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 631582360.6708 - val_loss: 2892097560.9339\n",
      "Epoch 5446/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 451642202.5436 - val_loss: 2740175324.0484\n",
      "Epoch 5447/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 606700010.0664 - val_loss: 3045380657.8228\n",
      "Epoch 5448/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 563919910.1767 - val_loss: 2690831497.8700\n",
      "Epoch 5449/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 641737027.1244 - val_loss: 3477776106.5226\n",
      "Epoch 5450/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 494660372.4232 - val_loss: 2659781725.2388\n",
      "Epoch 5451/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 405446620.5965 - val_loss: 2908786901.0453\n",
      "Epoch 5452/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 490060065.9719 - val_loss: 4074519788.2689\n",
      "Epoch 5453/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 519093021.0343 - val_loss: 2819362764.0079\n",
      "Epoch 5454/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 72us/step - loss: 540801678.8205 - val_loss: 2960854826.1086\n",
      "Epoch 5455/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 459272857.3911 - val_loss: 2640405106.4349\n",
      "Epoch 5456/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 523315711.7299 - val_loss: 2852563188.3702\n",
      "Epoch 5457/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 512202219.4350 - val_loss: 3117847459.6096\n",
      "Epoch 5458/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 590750880.2611 - val_loss: 2969560469.5314\n",
      "Epoch 5459/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 568904280.9589 - val_loss: 2915416733.6866\n",
      "Epoch 5460/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 664961490.2600 - val_loss: 2867906606.9761\n",
      "Epoch 5461/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 540447159.0591 - val_loss: 3514914705.7148\n",
      "Epoch 5462/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 505048017.3776 - val_loss: 3256297863.7232\n",
      "Epoch 5463/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 644090491.9139 - val_loss: 2633912192.2295\n",
      "Epoch 5464/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 592362994.1339 - val_loss: 3378256370.7859\n",
      "Epoch 5465/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 528976845.6860 - val_loss: 2728287810.3944\n",
      "Epoch 5466/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 685583149.3799 - val_loss: 4172584914.2008\n",
      "Epoch 5467/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 807047290.7147 - val_loss: 3087686999.3046\n",
      "Epoch 5468/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 499360434.9983 - val_loss: 4621416211.7851\n",
      "Epoch 5469/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 792730991.9370 - val_loss: 4413924921.3570\n",
      "Epoch 5470/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 804101970.3500 - val_loss: 2849922554.2771\n",
      "Epoch 5471/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 460630235.1559 - val_loss: 3481662251.1527\n",
      "Epoch 5472/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 836420127.4418 - val_loss: 2742316602.0118\n",
      "Epoch 5473/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 482585846.5639 - val_loss: 3874908587.2608\n",
      "Epoch 5474/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 525747299.4755 - val_loss: 2682440389.1668\n",
      "Epoch 5475/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 489764306.3320 - val_loss: 3352926588.1384\n",
      "Epoch 5476/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 744339163.6961 - val_loss: 3372908966.2740\n",
      "Epoch 5477/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1005378584.3016 - val_loss: 3568686211.7086\n",
      "Epoch 5478/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 434911046.8430 - val_loss: 2721947325.3176\n",
      "Epoch 5479/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 454521219.4373 - val_loss: 2813538235.3958\n",
      "Epoch 5480/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 448492112.9634 - val_loss: 2933340041.9015\n",
      "Epoch 5481/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 601539636.0788 - val_loss: 2612547474.1738\n",
      "Epoch 5482/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 504915820.9547 - val_loss: 2572202083.7356\n",
      "Epoch 5483/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 467471484.4581 - val_loss: 3538370042.4551\n",
      "Epoch 5484/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 600586087.5093 - val_loss: 2949080628.3522\n",
      "Epoch 5485/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 516936497.4496 - val_loss: 3203503632.2205\n",
      "Epoch 5486/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 503856406.1328 - val_loss: 2865456538.2481\n",
      "Epoch 5487/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 444540003.4935 - val_loss: 2898082214.1727\n",
      "Epoch 5488/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 531532643.7276 - val_loss: 3018755611.5263\n",
      "Epoch 5489/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 469662044.5605 - val_loss: 3407247535.0233\n",
      "Epoch 5490/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 463591305.3281 - val_loss: 2922851357.4526\n",
      "Epoch 5491/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 454298289.0861 - val_loss: 2862780828.2644\n",
      "Epoch 5492/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 719722934.3658 - val_loss: 2573770486.9851\n",
      "Epoch 5493/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 391465461.9786 - val_loss: 2531142716.8135\n",
      "Epoch 5494/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 468011647.0298 - val_loss: 2623615325.3536\n",
      "Epoch 5495/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 421587451.8942 - val_loss: 5399147662.7623\n",
      "Epoch 5496/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 795235155.2504 - val_loss: 2641531379.6141\n",
      "Epoch 5497/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 556616575.5138 - val_loss: 2710141367.4802\n",
      "Epoch 5498/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 679731774.8835 - val_loss: 3328453929.8025\n",
      "Epoch 5499/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 586274353.3416 - val_loss: 3030221375.4149\n",
      "Epoch 5500/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 724238165.6005 - val_loss: 2722960992.5131\n",
      "Epoch 5501/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 593249871.8109 - val_loss: 3881863782.3100\n",
      "Epoch 5502/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 632538945.1885 - val_loss: 4584753655.0706\n",
      "Epoch 5503/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 878395500.1553 - val_loss: 3036439889.7958\n",
      "Epoch 5504/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 462359535.1806 - val_loss: 3684331632.6976\n",
      "Epoch 5505/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 915373137.3236 - val_loss: 2976160754.4574\n",
      "Epoch 5506/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 624183467.9392 - val_loss: 2639693522.9930\n",
      "Epoch 5507/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 452779336.2476 - val_loss: 3818316631.7637\n",
      "Epoch 5508/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 458089004.4434 - val_loss: 2890171256.0608\n",
      "Epoch 5509/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 575687442.0124 - val_loss: 2613913710.1457\n",
      "Epoch 5510/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 571315081.7760 - val_loss: 2723641562.9142\n",
      "Epoch 5511/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 451091094.9781 - val_loss: 2803969889.3097\n",
      "Epoch 5512/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 687876532.6685 - val_loss: 4092762201.5100\n",
      "Epoch 5513/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 679749739.5250 - val_loss: 2744487469.2366\n",
      "Epoch 5514/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 694478069.0884 - val_loss: 2970711115.5218\n",
      "Epoch 5515/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 624418747.4980 - val_loss: 3485964634.5001\n",
      "Epoch 5516/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 602131078.2127 - val_loss: 2809199132.1564\n",
      "Epoch 5517/7000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 377784548.5200 - val_loss: 2810305428.2262\n",
      "Epoch 5518/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 422608611.9797 - val_loss: 4400126653.2276\n",
      "Epoch 5519/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 79us/step - loss: 591916216.2746 - val_loss: 2648069254.6340\n",
      "Epoch 5520/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 393390550.7259 - val_loss: 2634163859.5150\n",
      "Epoch 5521/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 517057393.8098 - val_loss: 3626903962.5001\n",
      "Epoch 5522/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 730442031.3618 - val_loss: 3617963433.1724\n",
      "Epoch 5523/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 456306324.1508 - val_loss: 3426037685.8644\n",
      "Epoch 5524/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 663084217.0940 - val_loss: 3560369499.9764\n",
      "Epoch 5525/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 517731124.2589 - val_loss: 3290456159.1269\n",
      "Epoch 5526/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 531024196.7541 - val_loss: 2733265040.3983\n",
      "Epoch 5527/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 580870907.2459 - val_loss: 4131798281.3435\n",
      "Epoch 5528/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 821854700.7856 - val_loss: 2838632919.8672\n",
      "Epoch 5529/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 434086041.9944 - val_loss: 3252568513.4762\n",
      "Epoch 5530/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 617697417.7107 - val_loss: 3098420908.7550\n",
      "Epoch 5531/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 459632513.4406 - val_loss: 2706051805.4886\n",
      "Epoch 5532/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 434276147.4305 - val_loss: 2919857763.5195\n",
      "Epoch 5533/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 429303695.2347 - val_loss: 3574937030.9671\n",
      "Epoch 5534/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 455059620.6911 - val_loss: 3067284504.7719\n",
      "Epoch 5535/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 534761373.1187 - val_loss: 2736748467.4160\n",
      "Epoch 5536/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 468915924.0518 - val_loss: 3255004279.6917\n",
      "Epoch 5537/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 606590285.2538 - val_loss: 2723969288.4253\n",
      "Epoch 5538/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 637825994.8407 - val_loss: 2955897106.0388\n",
      "Epoch 5539/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 726305249.4586 - val_loss: 2810726757.7879\n",
      "Epoch 5540/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 719389662.8295 - val_loss: 2960312836.8788\n",
      "Epoch 5541/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 492533925.3123 - val_loss: 2883031029.7114\n",
      "Epoch 5542/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 536704420.0158 - val_loss: 4576349088.0810\n",
      "Epoch 5543/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 629566186.9488 - val_loss: 2684757044.0731\n",
      "Epoch 5544/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 576853617.2335 - val_loss: 3215858596.9058\n",
      "Epoch 5545/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 465457954.8272 - val_loss: 2581085983.8290\n",
      "Epoch 5546/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 460119185.4496 - val_loss: 2752015316.6852\n",
      "Epoch 5547/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 528576857.7153 - val_loss: 2840976229.4639\n",
      "Epoch 5548/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 520166872.2926 - val_loss: 2664555936.4591\n",
      "Epoch 5549/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 457078920.6078 - val_loss: 2872721102.3122\n",
      "Epoch 5550/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 487348222.3163 - val_loss: 2910885798.9221\n",
      "Epoch 5551/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 447995162.6877 - val_loss: 3663021658.2301\n",
      "Epoch 5552/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 531612062.5144 - val_loss: 2885460260.5997\n",
      "Epoch 5553/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 781538813.7310 - val_loss: 3182747317.3963\n",
      "Epoch 5554/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 527340908.8396 - val_loss: 5166732580.7257\n",
      "Epoch 5555/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 931809556.9477 - val_loss: 2944054337.7283\n",
      "Epoch 5556/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 455851258.9398 - val_loss: 2858725599.1494\n",
      "Epoch 5557/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 429752573.3348 - val_loss: 2931193305.0059\n",
      "Epoch 5558/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 567499593.4361 - val_loss: 2751835537.5167\n",
      "Epoch 5559/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 406050849.1705 - val_loss: 3398469288.1913\n",
      "Epoch 5560/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 484511834.1654 - val_loss: 2640331807.6084\n",
      "Epoch 5561/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 457955636.5110 - val_loss: 3428869907.5871\n",
      "Epoch 5562/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 719176896.6055 - val_loss: 2634280927.8110\n",
      "Epoch 5563/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 408031454.5864 - val_loss: 2615234810.0366\n",
      "Epoch 5564/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 458359297.6927 - val_loss: 3170735653.3108\n",
      "Epoch 5565/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 633190462.1092 - val_loss: 2668277146.1581\n",
      "Epoch 5566/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 650345453.7220 - val_loss: 3624113497.9409\n",
      "Epoch 5567/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 524275688.1576 - val_loss: 3028540855.0031\n",
      "Epoch 5568/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 486222248.3286 - val_loss: 3156754582.4135\n",
      "Epoch 5569/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 640611748.3039 - val_loss: 5954146895.0684\n",
      "Epoch 5570/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 784569790.2172 - val_loss: 2999638232.1328\n",
      "Epoch 5571/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 610113892.6820 - val_loss: 2846058726.4540\n",
      "Epoch 5572/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 834378886.4288 - val_loss: 3087858305.8993\n",
      "Epoch 5573/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 482212726.1317 - val_loss: 2709931714.9345\n",
      "Epoch 5574/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 480226735.3877 - val_loss: 2583743510.3955\n",
      "Epoch 5575/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 420950127.7209 - val_loss: 2623046030.5688\n",
      "Epoch 5576/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 470855408.6393 - val_loss: 2556358596.8608\n",
      "Epoch 5577/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 478802649.8953 - val_loss: 4222619739.7063\n",
      "Epoch 5578/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 743155519.3655 - val_loss: 2926868770.3494\n",
      "Epoch 5579/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 456988083.5385 - val_loss: 2794570310.6790\n",
      "Epoch 5580/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 576725612.0113 - val_loss: 2861935101.8397\n",
      "Epoch 5581/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 549249334.5008 - val_loss: 2759412316.3004\n",
      "Epoch 5582/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 510034265.2110 - val_loss: 3222693802.4506\n",
      "Epoch 5583/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 457069984.0180 - val_loss: 2663288403.0110\n",
      "Epoch 5584/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 76us/step - loss: 532763319.1266 - val_loss: 2950644786.3809\n",
      "Epoch 5585/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 434332437.3213 - val_loss: 2749852843.7558\n",
      "Epoch 5586/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 439537463.9955 - val_loss: 3148068749.6911\n",
      "Epoch 5587/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 548024643.0703 - val_loss: 2729482297.7170\n",
      "Epoch 5588/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 410341395.0523 - val_loss: 2832679832.8079\n",
      "Epoch 5589/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 592168053.4834 - val_loss: 2846079154.4619\n",
      "Epoch 5590/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 552135220.0608 - val_loss: 2957604087.9707\n",
      "Epoch 5591/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 510846013.1007 - val_loss: 2764145068.6267\n",
      "Epoch 5592/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 478293408.9904 - val_loss: 3302729959.3722\n",
      "Epoch 5593/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 791278681.1750 - val_loss: 9967602173.8397\n",
      "Epoch 5594/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1146352992.1981 - val_loss: 2666245441.0172\n",
      "Epoch 5595/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 487715773.8751 - val_loss: 2776309740.3139\n",
      "Epoch 5596/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 621142589.3889 - val_loss: 3122243223.4419\n",
      "Epoch 5597/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 383212700.2724 - val_loss: 2800467735.6467\n",
      "Epoch 5598/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 621754660.0698 - val_loss: 3215561905.0037\n",
      "Epoch 5599/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 423384522.6967 - val_loss: 3292097359.7525\n",
      "Epoch 5600/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 562982421.8165 - val_loss: 2654271495.2056\n",
      "Epoch 5601/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 488667946.4986 - val_loss: 2866285462.6295\n",
      "Epoch 5602/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 602326489.1030 - val_loss: 5631249459.5601\n",
      "Epoch 5603/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 743613267.3990 - val_loss: 3401321989.7609\n",
      "Epoch 5604/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 482802291.7186 - val_loss: 2612189740.5930\n",
      "Epoch 5605/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 449000779.0388 - val_loss: 2935876313.3300\n",
      "Epoch 5606/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 449535366.9871 - val_loss: 2743113119.2518\n",
      "Epoch 5607/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 724763682.8903 - val_loss: 2831636013.7992\n",
      "Epoch 5608/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 690471442.2600 - val_loss: 3675144904.4793\n",
      "Epoch 5609/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 724001763.6016 - val_loss: 2647119309.5921\n",
      "Epoch 5610/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 417457036.6415 - val_loss: 2790350763.0447\n",
      "Epoch 5611/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 513517697.3416 - val_loss: 2582768646.9944\n",
      "Epoch 5612/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 486213579.9212 - val_loss: 2742633178.7342\n",
      "Epoch 5613/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 523246115.1154 - val_loss: 2773776189.6056\n",
      "Epoch 5614/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 524663756.5695 - val_loss: 2623708861.3207\n",
      "Epoch 5615/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 477364593.5397 - val_loss: 3322859180.8360\n",
      "Epoch 5616/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 585900840.7068 - val_loss: 2636669367.9302\n",
      "Epoch 5617/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 521722114.5931 - val_loss: 5062396743.6692\n",
      "Epoch 5618/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 849440750.7394 - val_loss: 2898484269.7992\n",
      "Epoch 5619/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 411620251.3720 - val_loss: 3110123929.2759\n",
      "Epoch 5620/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 660950565.3844 - val_loss: 3444213543.9662\n",
      "Epoch 5621/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 656214485.7895 - val_loss: 3512019289.1139\n",
      "Epoch 5622/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 568904904.1216 - val_loss: 2751641077.4864\n",
      "Epoch 5623/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 474184494.7158 - val_loss: 3707446122.5046\n",
      "Epoch 5624/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 443776168.2521 - val_loss: 2678162080.6211\n",
      "Epoch 5625/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 406376216.3467 - val_loss: 3157384959.8380\n",
      "Epoch 5626/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 571472091.9752 - val_loss: 2588742558.9018\n",
      "Epoch 5627/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 656834610.2780 - val_loss: 3444025114.9502\n",
      "Epoch 5628/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 789472805.7445 - val_loss: 2619447738.2751\n",
      "Epoch 5629/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 599353922.5571 - val_loss: 2953350725.6169\n",
      "Epoch 5630/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 609269427.2144 - val_loss: 3287143303.1291\n",
      "Epoch 5631/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 481279355.3180 - val_loss: 2712843735.3136\n",
      "Epoch 5632/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 649133655.5363 - val_loss: 2675538821.8329\n",
      "Epoch 5633/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 435383137.9156 - val_loss: 2516246061.1961\n",
      "Epoch 5634/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 413092976.3692 - val_loss: 2943361421.9679\n",
      "Epoch 5635/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 599675651.2414 - val_loss: 3384134347.4318\n",
      "Epoch 5636/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 474855461.6635 - val_loss: 3519639937.6563\n",
      "Epoch 5637/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 556320124.8306 - val_loss: 2664835678.8388\n",
      "Epoch 5638/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 554012462.9600 - val_loss: 3940442781.6686\n",
      "Epoch 5639/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 532812493.0737 - val_loss: 2621773524.2847\n",
      "Epoch 5640/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 397787755.0163 - val_loss: 2807732268.5030\n",
      "Epoch 5641/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 431271520.7338 - val_loss: 3277297375.5049\n",
      "Epoch 5642/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 504091096.6348 - val_loss: 2656802328.8619\n",
      "Epoch 5643/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 600911777.4947 - val_loss: 2780032499.9741\n",
      "Epoch 5644/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 679782665.7603 - val_loss: 2713116160.1080\n",
      "Epoch 5645/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 772152331.5971 - val_loss: 3165055471.4194\n",
      "Epoch 5646/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 559292266.2735 - val_loss: 3104918012.4174\n",
      "Epoch 5647/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 457986417.1615 - val_loss: 3424948744.1193\n",
      "Epoch 5648/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 720262167.7400 - val_loss: 2637397266.1108\n",
      "Epoch 5649/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 76us/step - loss: 443512392.4547 - val_loss: 2677926751.4509\n",
      "Epoch 5650/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 388220111.3134 - val_loss: 2987305520.3826\n",
      "Epoch 5651/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 453970058.0844 - val_loss: 4215599049.6765\n",
      "Epoch 5652/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 555122841.3416 - val_loss: 2956792023.1336\n",
      "Epoch 5653/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 537345229.0737 - val_loss: 4240702862.9423\n",
      "Epoch 5654/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 650370136.8914 - val_loss: 3156429739.6208\n",
      "Epoch 5655/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 429181146.2285 - val_loss: 3117314062.4113\n",
      "Epoch 5656/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 416889486.6044 - val_loss: 3593545180.2824\n",
      "Epoch 5657/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 607110944.2701 - val_loss: 4562622743.9797\n",
      "Epoch 5658/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 685712023.6443 - val_loss: 2563937046.0084\n",
      "Epoch 5659/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 466489935.2167 - val_loss: 2857785584.1935\n",
      "Epoch 5660/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 382594795.0028 - val_loss: 2642546508.2239\n",
      "Epoch 5661/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 513781198.8295 - val_loss: 3810860703.2889\n",
      "Epoch 5662/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 692202532.2319 - val_loss: 2672199031.3046\n",
      "Epoch 5663/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 386385819.4941 - val_loss: 2835033435.4003\n",
      "Epoch 5664/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 522401003.3990 - val_loss: 3647871466.5406\n",
      "Epoch 5665/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 488632762.1092 - val_loss: 2557178211.4993\n",
      "Epoch 5666/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 361574998.4558 - val_loss: 2514642767.4644\n",
      "Epoch 5667/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 450761762.9893 - val_loss: 5296316106.2076\n",
      "Epoch 5668/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 679630559.5858 - val_loss: 3168804409.4110\n",
      "Epoch 5669/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 598742938.1114 - val_loss: 3345126702.5913\n",
      "Epoch 5670/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 777522669.3765 - val_loss: 2859305942.4495\n",
      "Epoch 5671/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 552806990.6584 - val_loss: 2898549549.1691\n",
      "Epoch 5672/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 409541841.7918 - val_loss: 2749967916.5390\n",
      "Epoch 5673/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 691209697.8908 - val_loss: 2832509320.7494\n",
      "Epoch 5674/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 761292745.4947 - val_loss: 2522675814.9041\n",
      "Epoch 5675/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 412549468.6145 - val_loss: 2665309415.6152\n",
      "Epoch 5676/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 499805391.1176 - val_loss: 2558347147.0807\n",
      "Epoch 5677/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 453804604.2904 - val_loss: 3869195675.9044\n",
      "Epoch 5678/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 481454865.1795 - val_loss: 2721381338.8200\n",
      "Epoch 5679/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 480508048.8914 - val_loss: 3001095470.2627\n",
      "Epoch 5680/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 527616397.2358 - val_loss: 2716214025.3615\n",
      "Epoch 5681/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 469782139.4080 - val_loss: 3906453299.0560\n",
      "Epoch 5682/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 713984926.1272 - val_loss: 2728367562.1581\n",
      "Epoch 5683/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 411227628.7676 - val_loss: 2704951144.1103\n",
      "Epoch 5684/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 631993903.7929 - val_loss: 3323507659.7198\n",
      "Epoch 5685/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 540536091.6781 - val_loss: 2776251108.1046\n",
      "Epoch 5686/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 486648464.2611 - val_loss: 2719028808.8304\n",
      "Epoch 5687/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 434069788.3624 - val_loss: 3819003687.8222\n",
      "Epoch 5688/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 436453632.2082 - val_loss: 2649152956.0101\n",
      "Epoch 5689/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 517821188.9522 - val_loss: 3531471532.1924\n",
      "Epoch 5690/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 460709484.3804 - val_loss: 2926141384.9834\n",
      "Epoch 5691/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 522292680.4997 - val_loss: 2647932239.4982\n",
      "Epoch 5692/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 503970461.1854 - val_loss: 3363029052.8495\n",
      "Epoch 5693/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 700253922.2870 - val_loss: 3629149128.6594\n",
      "Epoch 5694/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 593128419.9617 - val_loss: 2757063412.9778\n",
      "Epoch 5695/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 544451877.5464 - val_loss: 3586934600.9204\n",
      "Epoch 5696/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 552981590.5369 - val_loss: 2792546977.0622\n",
      "Epoch 5697/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 422299728.3872 - val_loss: 2741859433.5685\n",
      "Epoch 5698/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 433827268.2138 - val_loss: 5072567232.8101\n",
      "Epoch 5699/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 649445410.9353 - val_loss: 2569508063.3114\n",
      "Epoch 5700/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 573676653.9921 - val_loss: 3099303747.9606\n",
      "Epoch 5701/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 613208324.5087 - val_loss: 3731393199.4374\n",
      "Epoch 5702/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 437537942.6854 - val_loss: 2598392198.4630\n",
      "Epoch 5703/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 389904080.4592 - val_loss: 2503671057.9218\n",
      "Epoch 5704/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 469257947.4440 - val_loss: 2855927192.0878\n",
      "Epoch 5705/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 488038283.4530 - val_loss: 3691553047.0076\n",
      "Epoch 5706/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 926636656.4052 - val_loss: 2588331727.0684\n",
      "Epoch 5707/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 362398566.6269 - val_loss: 2660556939.7198\n",
      "Epoch 5708/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 380106217.9584 - val_loss: 2935326183.4397\n",
      "Epoch 5709/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1145969918.0732 - val_loss: 3495045954.8264\n",
      "Epoch 5710/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 441969279.1716 - val_loss: 2676734412.9440\n",
      "Epoch 5711/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 414238429.1187 - val_loss: 2781162994.0028\n",
      "Epoch 5712/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 429845636.3939 - val_loss: 2699074150.8411\n",
      "Epoch 5713/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 465416348.1643 - val_loss: 3946590660.2847\n",
      "Epoch 5714/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 71us/step - loss: 742189159.0051 - val_loss: 2554442453.4413\n",
      "Epoch 5715/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 539682117.4474 - val_loss: 2620754640.8911\n",
      "Epoch 5716/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 368778092.5830 - val_loss: 2653567370.6217\n",
      "Epoch 5717/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 509194395.3180 - val_loss: 2619823276.9530\n",
      "Epoch 5718/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 414674477.6320 - val_loss: 2605026909.6326\n",
      "Epoch 5719/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 447571653.5917 - val_loss: 2638208067.1955\n",
      "Epoch 5720/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 439451280.2971 - val_loss: 2550043118.7983\n",
      "Epoch 5721/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 494088867.7997 - val_loss: 3136885427.4925\n",
      "Epoch 5722/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 423227719.3472 - val_loss: 2710444299.6298\n",
      "Epoch 5723/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 504656387.1086 - val_loss: 2787168742.7961\n",
      "Epoch 5724/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 560661561.9133 - val_loss: 3578250734.9063\n",
      "Epoch 5725/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 689352413.2988 - val_loss: 3810501304.1688\n",
      "Epoch 5726/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 509904420.0788 - val_loss: 3479238311.5882\n",
      "Epoch 5727/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 600317977.5712 - val_loss: 2702257557.7294\n",
      "Epoch 5728/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 495432282.8137 - val_loss: 2541730491.6096\n",
      "Epoch 5729/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 500736099.1165 - val_loss: 2669887361.1972\n",
      "Epoch 5730/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 510320350.1362 - val_loss: 2632325187.4700\n",
      "Epoch 5731/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 487575784.6618 - val_loss: 3003225981.9117\n",
      "Epoch 5732/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 450235677.3168 - val_loss: 2879860847.2574\n",
      "Epoch 5733/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 757783706.6877 - val_loss: 3043486003.5195\n",
      "Epoch 5734/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 448405154.4356 - val_loss: 2661484481.4582\n",
      "Epoch 5735/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 391112388.6100 - val_loss: 2675719370.0726\n",
      "Epoch 5736/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 552742558.5053 - val_loss: 2731193049.4920\n",
      "Epoch 5737/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 507807023.1086 - val_loss: 3943333530.6802\n",
      "Epoch 5738/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 621905024.1080 - val_loss: 2689330874.3111\n",
      "Epoch 5739/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 558244305.6837 - val_loss: 2617843490.6644\n",
      "Epoch 5740/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 501777269.4057 - val_loss: 2998535200.2070\n",
      "Epoch 5741/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 497573478.4288 - val_loss: 2613005453.3041\n",
      "Epoch 5742/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 571811689.1660 - val_loss: 3476768884.4422\n",
      "Epoch 5743/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 851488940.1733 - val_loss: 3613983627.7378\n",
      "Epoch 5744/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 508690004.4569 - val_loss: 2758238198.3775\n",
      "Epoch 5745/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 437647875.3134 - val_loss: 4483359318.3235\n",
      "Epoch 5746/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 807478519.2752 - val_loss: 2555596863.9460\n",
      "Epoch 5747/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 500531408.1080 - val_loss: 2578344205.3581\n",
      "Epoch 5748/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 421082082.8813 - val_loss: 2652083974.6790\n",
      "Epoch 5749/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 608717884.4705 - val_loss: 2665389090.8895\n",
      "Epoch 5750/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 451458372.7181 - val_loss: 3389484644.6717\n",
      "Epoch 5751/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 599029566.5954 - val_loss: 3543421110.5305\n",
      "Epoch 5752/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 542684066.1609 - val_loss: 3189938540.0709\n",
      "Epoch 5753/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 559949874.8903 - val_loss: 2558448364.8810\n",
      "Epoch 5754/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 432255880.3106 - val_loss: 2638258795.1887\n",
      "Epoch 5755/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 487788996.2859 - val_loss: 4253066503.7772\n",
      "Epoch 5756/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 476960245.4834 - val_loss: 3896468892.6605\n",
      "Epoch 5757/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 785221940.6730 - val_loss: 2768614472.0023\n",
      "Epoch 5758/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 478513188.1958 - val_loss: 2730682995.2135\n",
      "Epoch 5759/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 439212919.5543 - val_loss: 2996079780.0956\n",
      "Epoch 5760/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 440401617.9358 - val_loss: 2825709936.7966\n",
      "Epoch 5761/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 518340179.7591 - val_loss: 2572198585.6540\n",
      "Epoch 5762/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 407553312.4862 - val_loss: 2514159245.8352\n",
      "Epoch 5763/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 517290569.3506 - val_loss: 3048757012.6852\n",
      "Epoch 5764/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 398862161.9539 - val_loss: 3671602672.1215\n",
      "Epoch 5765/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 547573365.6995 - val_loss: 2671761413.2208\n",
      "Epoch 5766/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 536682927.1041 - val_loss: 2698919902.0467\n",
      "Epoch 5767/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 519320508.7946 - val_loss: 3445854890.8107\n",
      "Epoch 5768/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 537280583.2752 - val_loss: 2621696595.0650\n",
      "Epoch 5769/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 396103831.9325 - val_loss: 2489682413.5651\n",
      "Epoch 5770/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 349600040.3962 - val_loss: 2579873051.2878\n",
      "Epoch 5771/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 448649828.7721 - val_loss: 2567475515.7783\n",
      "Epoch 5772/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 580349757.0827 - val_loss: 3012082903.7997\n",
      "Epoch 5773/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 470578925.3438 - val_loss: 3094689806.0242\n",
      "Epoch 5774/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 763484015.7074 - val_loss: 2753247069.3446\n",
      "Epoch 5775/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 539674747.8402 - val_loss: 5246993808.3105\n",
      "Epoch 5776/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 795028072.9139 - val_loss: 2619124756.1992\n",
      "Epoch 5777/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 425273155.1334 - val_loss: 2637983653.8622\n",
      "Epoch 5778/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 565413223.9775 - val_loss: 2608850806.0084\n",
      "Epoch 5779/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 75us/step - loss: 388338166.3028 - val_loss: 2807513451.2923\n",
      "Epoch 5780/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 957235665.1210 - val_loss: 3295911893.1263\n",
      "Epoch 5781/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 472700173.5476 - val_loss: 2698645347.4115\n",
      "Epoch 5782/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 401613344.0000 - val_loss: 2828286615.9347\n",
      "Epoch 5783/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 421024486.8520 - val_loss: 2524154759.7232\n",
      "Epoch 5784/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 438873019.5521 - val_loss: 2532076818.0028\n",
      "Epoch 5785/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 676035266.7012 - val_loss: 3015810726.0579\n",
      "Epoch 5786/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 824237955.4935 - val_loss: 2711297347.5466\n",
      "Epoch 5787/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 465349914.4806 - val_loss: 2601154696.6143\n",
      "Epoch 5788/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 545198493.4609 - val_loss: 3244919068.1699\n",
      "Epoch 5789/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 759460807.1311 - val_loss: 2835394537.8340\n",
      "Epoch 5790/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 454573467.0838 - val_loss: 3969304112.5716\n",
      "Epoch 5791/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1117140673.3326 - val_loss: 3296436681.1814\n",
      "Epoch 5792/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 465621610.7147 - val_loss: 3302435852.0979\n",
      "Epoch 5793/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 538298736.6213 - val_loss: 2620917933.7215\n",
      "Epoch 5794/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 428115439.7389 - val_loss: 3941757243.9134\n",
      "Epoch 5795/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 563660403.9707 - val_loss: 2655754566.0669\n",
      "Epoch 5796/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 374101173.0737 - val_loss: 2583543676.4714\n",
      "Epoch 5797/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 441786750.7349 - val_loss: 2631818301.6056\n",
      "Epoch 5798/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 416015411.5656 - val_loss: 3047602632.6864\n",
      "Epoch 5799/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 513840306.4941 - val_loss: 3390585767.4442\n",
      "Epoch 5800/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 634856707.1874 - val_loss: 2806703037.6619\n",
      "Epoch 5801/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 542960956.2183 - val_loss: 3025551599.5994\n",
      "Epoch 5802/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 553585305.6972 - val_loss: 2952457032.9834\n",
      "Epoch 5803/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 449853789.9651 - val_loss: 3054484123.5623\n",
      "Epoch 5804/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 479792829.6590 - val_loss: 2753283723.4678\n",
      "Epoch 5805/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 478237896.5177 - val_loss: 2901497800.4748\n",
      "Epoch 5806/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 438603324.6010 - val_loss: 2494618434.0343\n",
      "Epoch 5807/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 412809035.9617 - val_loss: 3482353093.7249\n",
      "Epoch 5808/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 557855247.5048 - val_loss: 2721784407.9077\n",
      "Epoch 5809/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 458849399.8244 - val_loss: 2976078269.5246\n",
      "Epoch 5810/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 523501244.9026 - val_loss: 2623900468.3522\n",
      "Epoch 5811/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 544108547.0974 - val_loss: 2569067812.2037\n",
      "Epoch 5812/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 530153131.0028 - val_loss: 3396005649.5347\n",
      "Epoch 5813/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 479591028.0608 - val_loss: 2473363859.3350\n",
      "Epoch 5814/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 381281173.8886 - val_loss: 4332463419.2293\n",
      "Epoch 5815/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 608524464.7653 - val_loss: 2671201932.0529\n",
      "Epoch 5816/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 764072528.6933 - val_loss: 2680569685.7564\n",
      "Epoch 5817/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 454260924.1058 - val_loss: 2649047036.4714\n",
      "Epoch 5818/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 642842223.4328 - val_loss: 6183308364.0439\n",
      "Epoch 5819/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 837672906.4986 - val_loss: 2858398893.5831\n",
      "Epoch 5820/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 654361741.4879 - val_loss: 3267707614.5508\n",
      "Epoch 5821/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 598119096.1125 - val_loss: 3242458595.2467\n",
      "Epoch 5822/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 683773804.0833 - val_loss: 2578780494.7398\n",
      "Epoch 5823/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 435357553.1975 - val_loss: 2478318832.2565\n",
      "Epoch 5824/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 429664803.4755 - val_loss: 2498421715.8751\n",
      "Epoch 5825/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 424832604.9994 - val_loss: 3076306746.1311\n",
      "Epoch 5826/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 489587385.8053 - val_loss: 2499691465.8025\n",
      "Epoch 5827/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 393149150.2983 - val_loss: 2877300091.9224\n",
      "Epoch 5828/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 524344574.3433 - val_loss: 3661908408.7449\n",
      "Epoch 5829/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 779563551.5138 - val_loss: 2486700373.4008\n",
      "Epoch 5830/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 361760794.9848 - val_loss: 3886747868.9305\n",
      "Epoch 5831/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 521439820.6145 - val_loss: 3454666348.6380\n",
      "Epoch 5832/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 424850631.7704 - val_loss: 3399866569.7575\n",
      "Epoch 5833/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 561557485.6860 - val_loss: 2905003335.2191\n",
      "Epoch 5834/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 491518336.8644 - val_loss: 4259863265.7013\n",
      "Epoch 5835/7000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 555093471.9280 - val_loss: 3150837250.0478\n",
      "Epoch 5836/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 472991479.3292 - val_loss: 2485307986.0928\n",
      "Epoch 5837/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 330435868.1103 - val_loss: 3412276270.2672\n",
      "Epoch 5838/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 498367753.9764 - val_loss: 3173613596.3094\n",
      "Epoch 5839/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 464328497.7558 - val_loss: 2731362820.3522\n",
      "Epoch 5840/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 486020788.7991 - val_loss: 2858544725.4053\n",
      "Epoch 5841/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 585122597.4564 - val_loss: 3091663262.2267\n",
      "Epoch 5842/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 556409507.7591 - val_loss: 2617162198.7916\n",
      "Epoch 5843/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 410209242.5076 - val_loss: 2926523000.0428\n",
      "Epoch 5844/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 84us/step - loss: 546366230.4018 - val_loss: 5616340847.1854\n",
      "Epoch 5845/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 722511059.5926 - val_loss: 2719093156.7122\n",
      "Epoch 5846/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 454287330.1790 - val_loss: 3412269498.0861\n",
      "Epoch 5847/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 634664176.3827 - val_loss: 2926980550.8231\n",
      "Epoch 5848/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 412735825.3056 - val_loss: 2699230249.5775\n",
      "Epoch 5849/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 362931177.1840 - val_loss: 2930336869.6799\n",
      "Epoch 5850/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 620230736.8914 - val_loss: 3422873364.0371\n",
      "Epoch 5851/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 538376162.1069 - val_loss: 4526631712.7651\n",
      "Epoch 5852/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 815747712.3962 - val_loss: 2691046557.6326\n",
      "Epoch 5853/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 415209517.9921 - val_loss: 2584319908.6942\n",
      "Epoch 5854/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 434128273.7558 - val_loss: 3203903146.8827\n",
      "Epoch 5855/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 524150226.9443 - val_loss: 2677685142.0534\n",
      "Epoch 5856/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 466796296.4885 - val_loss: 2660195499.7423\n",
      "Epoch 5857/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 507245802.1384 - val_loss: 2637098359.4532\n",
      "Epoch 5858/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 539429117.6140 - val_loss: 3166380483.4790\n",
      "Epoch 5859/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 495103840.2341 - val_loss: 3115301298.0838\n",
      "Epoch 5860/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 415492290.9173 - val_loss: 2500432733.5156\n",
      "Epoch 5861/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 414654389.5914 - val_loss: 3081857375.3429\n",
      "Epoch 5862/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 508758706.6021 - val_loss: 2770003257.3412\n",
      "Epoch 5863/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 724654928.4232 - val_loss: 3158850213.2838\n",
      "Epoch 5864/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 438908877.4159 - val_loss: 2577280014.9603\n",
      "Epoch 5865/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 406225927.3472 - val_loss: 2787859667.3035\n",
      "Epoch 5866/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 533862588.1733 - val_loss: 2629550437.5719\n",
      "Epoch 5867/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 393963828.3309 - val_loss: 3183838232.2228\n",
      "Epoch 5868/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 523255420.6866 - val_loss: 2952339386.4461\n",
      "Epoch 5869/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 656953387.9797 - val_loss: 2475117061.3558\n",
      "Epoch 5870/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 352125655.2302 - val_loss: 2875928831.7660\n",
      "Epoch 5871/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 568419202.9173 - val_loss: 2974191435.7198\n",
      "Epoch 5872/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 556532922.7597 - val_loss: 2659812998.5238\n",
      "Epoch 5873/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 724472278.6899 - val_loss: 2779046154.8917\n",
      "Epoch 5874/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 526249746.9263 - val_loss: 2516858079.9010\n",
      "Epoch 5875/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 411326878.9736 - val_loss: 2641995255.8267\n",
      "Epoch 5876/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 471996976.8014 - val_loss: 2674326437.6619\n",
      "Epoch 5877/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 600690767.5228 - val_loss: 2581540343.2056\n",
      "Epoch 5878/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 420049748.4569 - val_loss: 4462794193.2647\n",
      "Epoch 5879/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 606130758.4018 - val_loss: 2541298928.6391\n",
      "Epoch 5880/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 506168396.7136 - val_loss: 3635620857.8070\n",
      "Epoch 5881/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 722209656.3782 - val_loss: 2756458622.0557\n",
      "Epoch 5882/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 397769738.6427 - val_loss: 2541167536.5446\n",
      "Epoch 5883/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 452507788.0743 - val_loss: 3288637955.8256\n",
      "Epoch 5884/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 488133469.9122 - val_loss: 4405438093.5314\n",
      "Epoch 5885/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 741686895.4598 - val_loss: 2773462436.2937\n",
      "Epoch 5886/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 436193272.5627 - val_loss: 2590996345.9691\n",
      "Epoch 5887/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 492056267.5611 - val_loss: 2675627975.9572\n",
      "Epoch 5888/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 486516912.8734 - val_loss: 2517818112.6391\n",
      "Epoch 5889/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 417044356.2949 - val_loss: 2994132184.7719\n",
      "Epoch 5890/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 532042331.3765 - val_loss: 2974409838.8163\n",
      "Epoch 5891/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 504094267.2819 - val_loss: 2726668710.7691\n",
      "Epoch 5892/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 514413437.5836 - val_loss: 2507478337.9533\n",
      "Epoch 5893/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 384157413.7805 - val_loss: 2845136525.5741\n",
      "Epoch 5894/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 613082387.1604 - val_loss: 2745141250.3404\n",
      "Epoch 5895/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 467938247.3112 - val_loss: 3104471266.8624\n",
      "Epoch 5896/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 487176935.6443 - val_loss: 2724518523.3643\n",
      "Epoch 5897/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 559069239.3756 - val_loss: 2596221094.2051\n",
      "Epoch 5898/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 405612510.0011 - val_loss: 2533826287.8267\n",
      "Epoch 5899/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 414668229.4539 - val_loss: 2490525744.1215\n",
      "Epoch 5900/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 479825738.2690 - val_loss: 3736076414.3527\n",
      "Epoch 5901/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 811185343.4057 - val_loss: 3143442835.9111\n",
      "Epoch 5902/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 747239444.9252 - val_loss: 3862412756.7212\n",
      "Epoch 5903/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 688426765.2358 - val_loss: 2855725488.4996\n",
      "Epoch 5904/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 397131340.1373 - val_loss: 2565920953.9511\n",
      "Epoch 5905/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 559429779.3236 - val_loss: 3144115994.5902\n",
      "Epoch 5906/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 418782395.1514 - val_loss: 2495476488.4973\n",
      "Epoch 5907/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 322709131.3720 - val_loss: 2493374415.2709\n",
      "Epoch 5908/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 336825221.8346 - val_loss: 4698425169.3007\n",
      "Epoch 5909/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 74us/step - loss: 853253903.6488 - val_loss: 2534147256.7134\n",
      "Epoch 5910/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 445229304.5729 - val_loss: 2767039844.0596\n",
      "Epoch 5911/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 482715040.3782 - val_loss: 2635892881.1927\n",
      "Epoch 5912/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 498171666.5841 - val_loss: 7143321177.8520\n",
      "Epoch 5913/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1536720752.8734 - val_loss: 2950631756.2149\n",
      "Epoch 5914/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 435004882.4041 - val_loss: 3457705888.9451\n",
      "Epoch 5915/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 459594453.1052 - val_loss: 2500048472.1643\n",
      "Epoch 5916/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 509420599.3922 - val_loss: 2611847544.9024\n",
      "Epoch 5917/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 417819131.1199 - val_loss: 2593466567.0661\n",
      "Epoch 5918/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 420979622.8610 - val_loss: 2634585716.9193\n",
      "Epoch 5919/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 467361956.0653 - val_loss: 2530847463.0121\n",
      "Epoch 5920/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 420776528.1981 - val_loss: 2625183857.0284\n",
      "Epoch 5921/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 329902751.0726 - val_loss: 2503821901.2321\n",
      "Epoch 5922/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 405059895.5453 - val_loss: 2715389227.8368\n",
      "Epoch 5923/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 622734503.0816 - val_loss: 2873282359.6467\n",
      "Epoch 5924/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 541634706.8002 - val_loss: 2626470209.1409\n",
      "Epoch 5925/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 432987934.3658 - val_loss: 2512002515.6591\n",
      "Epoch 5926/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 330012447.4418 - val_loss: 2633912347.0222\n",
      "Epoch 5927/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 645938810.5976 - val_loss: 6229793857.5752\n",
      "Epoch 5928/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1279408422.6595 - val_loss: 2766927171.5376\n",
      "Epoch 5929/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 433006595.9797 - val_loss: 3120633196.1609\n",
      "Epoch 5930/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 488745291.7772 - val_loss: 2800261754.2031\n",
      "Epoch 5931/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 435395430.9510 - val_loss: 2668319540.6492\n",
      "Epoch 5932/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 540076053.2133 - val_loss: 2544876011.4948\n",
      "Epoch 5933/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 458408333.2898 - val_loss: 3351453562.1671\n",
      "Epoch 5934/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 507478956.8576 - val_loss: 2676383398.7932\n",
      "Epoch 5935/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 348412613.1232 - val_loss: 2600728385.0622\n",
      "Epoch 5936/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 372563508.6911 - val_loss: 2739889989.6349\n",
      "Epoch 5937/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 418563755.3990 - val_loss: 2582446494.4968\n",
      "Epoch 5938/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 568455739.3540 - val_loss: 3678835634.1558\n",
      "Epoch 5939/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 823442866.9083 - val_loss: 2770538045.0655\n",
      "Epoch 5940/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 478931322.9308 - val_loss: 2543497146.9052\n",
      "Epoch 5941/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 390260725.9156 - val_loss: 2578624448.0900\n",
      "Epoch 5942/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 460593824.8160 - val_loss: 3002184118.9806\n",
      "Epoch 5943/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 464316172.5515 - val_loss: 2967726760.9384\n",
      "Epoch 5944/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 482962674.9443 - val_loss: 2599849653.2883\n",
      "Epoch 5945/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 369983339.6061 - val_loss: 2771257869.4661\n",
      "Epoch 5946/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 505536614.8430 - val_loss: 2597867880.7741\n",
      "Epoch 5947/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 389476847.1131 - val_loss: 2672837027.9696\n",
      "Epoch 5948/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 496229756.7946 - val_loss: 2776528031.2889\n",
      "Epoch 5949/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 469910479.1626 - val_loss: 3521633350.9806\n",
      "Epoch 5950/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 467125490.3241 - val_loss: 3520176546.6014\n",
      "Epoch 5951/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 516634339.8357 - val_loss: 2580528351.6309\n",
      "Epoch 5952/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 585890011.6714 - val_loss: 3110658847.3969\n",
      "Epoch 5953/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 494559348.0113 - val_loss: 3192398635.8549\n",
      "Epoch 5954/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 473865028.2859 - val_loss: 2636511850.1221\n",
      "Epoch 5955/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 365617697.5037 - val_loss: 3028583887.7345\n",
      "Epoch 5956/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 456836125.0467 - val_loss: 4020506782.3347\n",
      "Epoch 5957/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 751364137.7603 - val_loss: 2862142331.2113\n",
      "Epoch 5958/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 441424308.2589 - val_loss: 4141298912.4231\n",
      "Epoch 5959/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 606627441.4789 - val_loss: 3397299915.6118\n",
      "Epoch 5960/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 396529647.2167 - val_loss: 2795076588.6695\n",
      "Epoch 5961/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 407627320.4057 - val_loss: 2535804205.1173\n",
      "Epoch 5962/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 297820484.1418 - val_loss: 2439055087.1044\n",
      "Epoch 5963/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 613667589.9426 - val_loss: 2856677081.6146\n",
      "Epoch 5964/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 436102895.7569 - val_loss: 2898851332.6267\n",
      "Epoch 5965/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 632079623.1491 - val_loss: 2631399303.9077\n",
      "Epoch 5966/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 466457538.5504 - val_loss: 3044967598.1187\n",
      "Epoch 5967/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 600598611.9707 - val_loss: 3212871869.6551\n",
      "Epoch 5968/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 730762524.3444 - val_loss: 2933874208.8011\n",
      "Epoch 5969/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 636716621.2684 - val_loss: 2539250130.7207\n",
      "Epoch 5970/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 323682999.9325 - val_loss: 3397114663.2821\n",
      "Epoch 5971/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 534622891.8852 - val_loss: 2874961365.5764\n",
      "Epoch 5972/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 431403470.6584 - val_loss: 2924691275.8278\n",
      "Epoch 5973/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 471715491.7276 - val_loss: 3734896060.3994\n",
      "Epoch 5974/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 74us/step - loss: 568977720.0315 - val_loss: 2619236810.1356\n",
      "Epoch 5975/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 500089634.6922 - val_loss: 2730625962.2278\n",
      "Epoch 5976/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 391044072.5357 - val_loss: 3409526539.4498\n",
      "Epoch 5977/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 555814656.1261 - val_loss: 3361130056.2993\n",
      "Epoch 5978/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 450950466.0889 - val_loss: 2781285486.1052\n",
      "Epoch 5979/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 573184560.4052 - val_loss: 3398339993.4380\n",
      "Epoch 5980/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 480426965.9741 - val_loss: 2675374200.1665\n",
      "Epoch 5981/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 392286437.8391 - val_loss: 2521688074.2796\n",
      "Epoch 5982/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 454281786.4806 - val_loss: 2481427319.5027\n",
      "Epoch 5983/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 587464763.0658 - val_loss: 2557761397.0993\n",
      "Epoch 5984/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 350223944.0018 - val_loss: 3124208633.4830\n",
      "Epoch 5985/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 674518599.3967 - val_loss: 2801874657.6563\n",
      "Epoch 5986/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 629143625.1750 - val_loss: 2691128176.4141\n",
      "Epoch 5987/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 593733059.4665 - val_loss: 2612194241.5302\n",
      "Epoch 5988/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 525075382.7440 - val_loss: 3659475732.2037\n",
      "Epoch 5989/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 525277151.5498 - val_loss: 3113657214.2897\n",
      "Epoch 5990/7000\n",
      "3554/3554 [==============================] - 0s 68us/step - loss: 438161790.1542 - val_loss: 3015769414.3280\n",
      "Epoch 5991/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 440285657.4541 - val_loss: 2645614673.4110\n",
      "Epoch 5992/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 572704124.6866 - val_loss: 2560081445.8869\n",
      "Epoch 5993/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 589547321.6252 - val_loss: 2490419791.8245\n",
      "Epoch 5994/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 527822948.7001 - val_loss: 2518460485.6160\n",
      "Epoch 5995/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 910613152.3421 - val_loss: 2728337055.2259\n",
      "Epoch 5996/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 598112369.3416 - val_loss: 2560152886.1885\n",
      "Epoch 5997/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 352491204.3219 - val_loss: 3211937639.6782\n",
      "Epoch 5998/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 439626821.7130 - val_loss: 2440266986.4281\n",
      "Epoch 5999/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 357367064.1846 - val_loss: 2525119538.6239\n",
      "Epoch 6000/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 410305578.2465 - val_loss: 2466770483.1100\n",
      "Epoch 6001/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 374548418.5661 - val_loss: 2786807711.9471\n",
      "Epoch 6002/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 504513469.6590 - val_loss: 4075563437.3671\n",
      "Epoch 6003/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 849359357.0107 - val_loss: 2836923216.1812\n",
      "Epoch 6004/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 425166102.2037 - val_loss: 2673125782.9176\n",
      "Epoch 6005/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 430477660.1643 - val_loss: 3405729907.6231\n",
      "Epoch 6006/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 550871093.8796 - val_loss: 3113474897.5842\n",
      "Epoch 6007/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 967121822.0732 - val_loss: 2737793336.2318\n",
      "Epoch 6008/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 493005994.5346 - val_loss: 2511967441.2467\n",
      "Epoch 6009/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 441564545.5127 - val_loss: 3231339825.8768\n",
      "Epoch 6010/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 481577641.8503 - val_loss: 2564897889.6743\n",
      "Epoch 6011/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 460833834.1384 - val_loss: 2881294862.0219\n",
      "Epoch 6012/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 438292163.2774 - val_loss: 3478907740.4264\n",
      "Epoch 6013/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 471483018.0664 - val_loss: 4740914965.4594\n",
      "Epoch 6014/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 450008872.6618 - val_loss: 2493938026.3392\n",
      "Epoch 6015/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 446118772.0428 - val_loss: 3293525772.2419\n",
      "Epoch 6016/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 565421894.9510 - val_loss: 2937726383.5634\n",
      "Epoch 6017/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 531348853.1052 - val_loss: 2621650683.0447\n",
      "Epoch 6018/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 594168713.6342 - val_loss: 3460563163.8909\n",
      "Epoch 6019/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 839645804.1981 - val_loss: 4642445584.5626\n",
      "Epoch 6020/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 857928453.9426 - val_loss: 2439954947.1055\n",
      "Epoch 6021/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 388041608.9004 - val_loss: 2630930510.5283\n",
      "Epoch 6022/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 343630871.1221 - val_loss: 2482844294.4439\n",
      "Epoch 6023/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 439266751.0096 - val_loss: 2501812901.7159\n",
      "Epoch 6024/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 362233809.8008 - val_loss: 2584303667.1865\n",
      "Epoch 6025/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 421981516.0653 - val_loss: 2517358971.2023\n",
      "Epoch 6026/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 345570702.1002 - val_loss: 2443038238.6048\n",
      "Epoch 6027/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 473102070.9240 - val_loss: 2429649218.1423\n",
      "Epoch 6028/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 458246867.7006 - val_loss: 2651597479.6872\n",
      "Epoch 6029/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 593523616.9094 - val_loss: 2627507038.7668\n",
      "Epoch 6030/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 373634870.7440 - val_loss: 4818646038.4675\n",
      "Epoch 6031/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 628811266.3590 - val_loss: 4002914490.4371\n",
      "Epoch 6032/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 516593777.1075 - val_loss: 2566536568.9879\n",
      "Epoch 6033/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 427398736.1162 - val_loss: 3029953167.6084\n",
      "Epoch 6034/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 540242437.7445 - val_loss: 2664329818.4821\n",
      "Epoch 6035/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 442130436.2859 - val_loss: 3204899598.6903\n",
      "Epoch 6036/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 473677536.8464 - val_loss: 2574906910.9378\n",
      "Epoch 6037/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 444768345.8233 - val_loss: 2920347744.4141\n",
      "Epoch 6038/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 555422180.0473 - val_loss: 2625548533.8779\n",
      "Epoch 6039/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 85us/step - loss: 419817520.9814 - val_loss: 2538377197.1331\n",
      "Epoch 6040/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 418448838.6989 - val_loss: 3121358315.4408\n",
      "Epoch 6041/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 770059215.2347 - val_loss: 4682728508.0934\n",
      "Epoch 6042/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 817376065.8368 - val_loss: 3132674128.0765\n",
      "Epoch 6043/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 561389275.8942 - val_loss: 2865693056.6661\n",
      "Epoch 6044/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 351641583.0816 - val_loss: 2601594401.1072\n",
      "Epoch 6045/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 454478172.5785 - val_loss: 2557256487.8042\n",
      "Epoch 6046/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 390284333.8481 - val_loss: 2661946727.7502\n",
      "Epoch 6047/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 422919149.8661 - val_loss: 2715055254.3055\n",
      "Epoch 6048/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 720394217.5262 - val_loss: 3236799529.8025\n",
      "Epoch 6049/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 781148739.4215 - val_loss: 6045589318.9311\n",
      "Epoch 6050/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1278792221.6770 - val_loss: 3843722648.7359\n",
      "Epoch 6051/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 467221853.4249 - val_loss: 2464811303.5083\n",
      "Epoch 6052/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 458811287.4057 - val_loss: 2643082424.7629\n",
      "Epoch 6053/7000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 361457908.5875 - val_loss: 2433657679.7840\n",
      "Epoch 6054/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 398348722.6021 - val_loss: 2533497541.0228\n",
      "Epoch 6055/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 389594779.3180 - val_loss: 2518295515.0402\n",
      "Epoch 6056/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 391373408.6775 - val_loss: 2700146712.6571\n",
      "Epoch 6057/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 380885384.9679 - val_loss: 3695994615.8627\n",
      "Epoch 6058/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 580051403.1649 - val_loss: 2942456118.7286\n",
      "Epoch 6059/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 472390013.1187 - val_loss: 2615724811.0177\n",
      "Epoch 6060/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 531915779.4215 - val_loss: 3738712147.7311\n",
      "Epoch 6061/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 555400911.8199 - val_loss: 3016225517.3131\n",
      "Epoch 6062/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 671610650.3995 - val_loss: 3789018907.9044\n",
      "Epoch 6063/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 591718844.1261 - val_loss: 2436422697.3075\n",
      "Epoch 6064/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 336574811.1041 - val_loss: 2839784707.1595\n",
      "Epoch 6065/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 406713927.7614 - val_loss: 2588118456.7224\n",
      "Epoch 6066/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 463188737.0084 - val_loss: 2742977887.0098\n",
      "Epoch 6067/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 610482886.9398 - val_loss: 2409575644.1744\n",
      "Epoch 6068/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 501898094.9285 - val_loss: 2862101942.9356\n",
      "Epoch 6069/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 480470784.4052 - val_loss: 2882844007.8942\n",
      "Epoch 6070/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 407049875.2864 - val_loss: 2526668758.0444\n",
      "Epoch 6071/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 493152367.6488 - val_loss: 5603393511.8042\n",
      "Epoch 6072/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 721737646.7496 - val_loss: 2776042966.0759\n",
      "Epoch 6073/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 392891391.0636 - val_loss: 2444629705.2872\n",
      "Epoch 6074/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 394523010.7732 - val_loss: 3501560249.3637\n",
      "Epoch 6075/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 411542509.8165 - val_loss: 2385335231.0368\n",
      "Epoch 6076/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 480609915.9572 - val_loss: 2655769035.0177\n",
      "Epoch 6077/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 358979992.3467 - val_loss: 2529341897.5235\n",
      "Epoch 6078/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 580145202.8903 - val_loss: 3392742555.5443\n",
      "Epoch 6079/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 464287739.4080 - val_loss: 2496712055.5207\n",
      "Epoch 6080/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 413341952.4772 - val_loss: 2636466637.0430\n",
      "Epoch 6081/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 444950082.8813 - val_loss: 3367713978.8737\n",
      "Epoch 6082/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 654220846.3883 - val_loss: 2760175081.4740\n",
      "Epoch 6083/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 594743953.6477 - val_loss: 4194068135.5702\n",
      "Epoch 6084/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1421869997.7130 - val_loss: 2641232512.3241\n",
      "Epoch 6085/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 344348069.7175 - val_loss: 2730284968.1508\n",
      "Epoch 6086/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 448048610.5706 - val_loss: 2454950259.8301\n",
      "Epoch 6087/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 378107340.3174 - val_loss: 2563591725.0172\n",
      "Epoch 6088/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 470946320.9994 - val_loss: 3538592443.4813\n",
      "Epoch 6089/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 652124205.1322 - val_loss: 2414438822.6520\n",
      "Epoch 6090/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 501502381.9561 - val_loss: 2795921168.9947\n",
      "Epoch 6091/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 379435681.2966 - val_loss: 2492136403.2090\n",
      "Epoch 6092/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 448509576.6438 - val_loss: 4631824977.7958\n",
      "Epoch 6093/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1303081134.9465 - val_loss: 2980717329.5257\n",
      "Epoch 6094/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 383902055.1851 - val_loss: 2635785228.8180\n",
      "Epoch 6095/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 408110808.6775 - val_loss: 2405813877.5314\n",
      "Epoch 6096/7000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 493776328.1916 - val_loss: 2883322484.9508\n",
      "Epoch 6097/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 341695953.3956 - val_loss: 2484334398.2177\n",
      "Epoch 6098/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 427097619.3770 - val_loss: 2374797775.7975\n",
      "Epoch 6099/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 352844050.6021 - val_loss: 2450433674.8377\n",
      "Epoch 6100/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 429452176.4592 - val_loss: 4424483282.3989\n",
      "Epoch 6101/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 440343345.5217 - val_loss: 2687356774.8940\n",
      "Epoch 6102/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1110047831.5903 - val_loss: 5389124970.7927\n",
      "Epoch 6103/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 631659098.8497 - val_loss: 3820464519.4892\n",
      "Epoch 6104/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 73us/step - loss: 428018863.4328 - val_loss: 2543067834.6532\n",
      "Epoch 6105/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 483927385.0490 - val_loss: 2543520061.2714\n",
      "Epoch 6106/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 479245703.4553 - val_loss: 2540362695.6512\n",
      "Epoch 6107/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 808460895.0816 - val_loss: 2732150204.3004\n",
      "Epoch 6108/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 471661272.5695 - val_loss: 3764740829.9027\n",
      "Epoch 6109/7000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 496082030.7845 - val_loss: 2532789205.2433\n",
      "Epoch 6110/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 575916851.9617 - val_loss: 2532554696.6233\n",
      "Epoch 6111/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 361286288.5672 - val_loss: 3303746309.0408\n",
      "Epoch 6112/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 552429619.3675 - val_loss: 2406728062.4518\n",
      "Epoch 6113/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 316126599.2752 - val_loss: 2550009565.9747\n",
      "Epoch 6114/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 376958499.7687 - val_loss: 2458468720.7966\n",
      "Epoch 6115/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 360055285.1953 - val_loss: 2488044849.9803\n",
      "Epoch 6116/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 440050340.6556 - val_loss: 2718727993.3930\n",
      "Epoch 6117/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 404085446.8790 - val_loss: 3184603703.7367\n",
      "Epoch 6118/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 530108946.1925 - val_loss: 2676689096.9924\n",
      "Epoch 6119/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 424174802.6742 - val_loss: 2468217136.5896\n",
      "Epoch 6120/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 519252714.2555 - val_loss: 2447464721.0397\n",
      "Epoch 6121/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 676858553.9133 - val_loss: 2451664588.5750\n",
      "Epoch 6122/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 528769393.7243 - val_loss: 2576767218.5429\n",
      "Epoch 6123/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 467542212.0698 - val_loss: 3561822625.7283\n",
      "Epoch 6124/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 595406336.7788 - val_loss: 3247308261.4999\n",
      "Epoch 6125/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 534795137.9449 - val_loss: 3174015246.9828\n",
      "Epoch 6126/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 612579059.6826 - val_loss: 2673013032.4816\n",
      "Epoch 6127/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 501455679.6218 - val_loss: 3039560590.8523\n",
      "Epoch 6128/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 388150995.4125 - val_loss: 3961372755.2450\n",
      "Epoch 6129/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 586945208.2296 - val_loss: 2544227752.2183\n",
      "Epoch 6130/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 386121332.5470 - val_loss: 2444860239.6782\n",
      "Epoch 6131/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 444152432.5042 - val_loss: 2441312267.9696\n",
      "Epoch 6132/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 524372433.6477 - val_loss: 5256905389.2591\n",
      "Epoch 6133/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 540229640.8835 - val_loss: 2615755053.6911\n",
      "Epoch 6134/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 473756921.3101 - val_loss: 2936732063.2124\n",
      "Epoch 6135/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 421578948.5920 - val_loss: 2503059557.1471\n",
      "Epoch 6136/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 336596098.4401 - val_loss: 2819225010.8872\n",
      "Epoch 6137/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 383516007.7614 - val_loss: 2510402751.6489\n",
      "Epoch 6138/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 491770915.3675 - val_loss: 4330354861.8121\n",
      "Epoch 6139/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 854017427.0884 - val_loss: 3579530903.1876\n",
      "Epoch 6140/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 583701719.1131 - val_loss: 4246458685.4256\n",
      "Epoch 6141/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 540680763.2819 - val_loss: 2496131421.5246\n",
      "Epoch 6142/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 507529715.0343 - val_loss: 4514074928.7246\n",
      "Epoch 6143/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1018959594.6787 - val_loss: 2810284988.1654\n",
      "Epoch 6144/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 451445349.9786 - val_loss: 2774154693.9342\n",
      "Epoch 6145/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 430322136.9049 - val_loss: 3230325116.1474\n",
      "Epoch 6146/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 527883806.1092 - val_loss: 2698654831.7795\n",
      "Epoch 6147/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 942810889.5082 - val_loss: 2758576895.4779\n",
      "Epoch 6148/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 545317187.9302 - val_loss: 3149045220.4107\n",
      "Epoch 6149/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 405563732.0698 - val_loss: 2430176099.0425\n",
      "Epoch 6150/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 342127663.6849 - val_loss: 2604587839.9100\n",
      "Epoch 6151/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 380258565.7625 - val_loss: 2512200355.5015\n",
      "Epoch 6152/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 449029170.3590 - val_loss: 2592148311.9977\n",
      "Epoch 6153/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 549498667.7411 - val_loss: 2463785208.4883\n",
      "Epoch 6154/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 413219928.4547 - val_loss: 2720147274.3786\n",
      "Epoch 6155/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 419588255.8739 - val_loss: 2410070488.8889\n",
      "Epoch 6156/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 512125438.5234 - val_loss: 2500076535.3857\n",
      "Epoch 6157/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 424623715.0253 - val_loss: 2841775900.9350\n",
      "Epoch 6158/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 528021074.9173 - val_loss: 2711132740.0821\n",
      "Epoch 6159/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 403672084.8171 - val_loss: 3918224013.7181\n",
      "Epoch 6160/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 597070377.8863 - val_loss: 3231540322.6554\n",
      "Epoch 6161/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 447190092.6235 - val_loss: 2985057524.1902\n",
      "Epoch 6162/7000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 552117230.5684 - val_loss: 4591105578.2346\n",
      "Epoch 6163/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 745130750.5594 - val_loss: 3030984266.7027\n",
      "Epoch 6164/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 522114237.8571 - val_loss: 2425401543.4543\n",
      "Epoch 6165/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 494949915.3720 - val_loss: 2663899639.8267\n",
      "Epoch 6166/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 438423776.7473 - val_loss: 2435758271.8830\n",
      "Epoch 6167/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 344311566.2532 - val_loss: 3034461913.2579\n",
      "Epoch 6168/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 431641650.7642 - val_loss: 2549944459.9539\n",
      "Epoch 6169/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 72us/step - loss: 452210679.6443 - val_loss: 3475138699.8954\n",
      "Epoch 6170/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 712936936.3827 - val_loss: 3225317653.3513\n",
      "Epoch 6171/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 459071613.5149 - val_loss: 2598725246.2852\n",
      "Epoch 6172/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 365615807.9648 - val_loss: 2604994480.7876\n",
      "Epoch 6173/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 614646326.5999 - val_loss: 2473263024.3443\n",
      "Epoch 6174/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 502300704.7127 - val_loss: 3397215876.5682\n",
      "Epoch 6175/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 417417215.6218 - val_loss: 2455671436.7550\n",
      "Epoch 6176/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 470324879.1761 - val_loss: 2577668002.9435\n",
      "Epoch 6177/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 546966320.9814 - val_loss: 2653109245.8037\n",
      "Epoch 6178/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 569572294.8790 - val_loss: 2713384121.9331\n",
      "Epoch 6179/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 525203420.3084 - val_loss: 4507076249.8520\n",
      "Epoch 6180/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 620331912.0675 - val_loss: 3716135004.7505\n",
      "Epoch 6181/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 496934902.9420 - val_loss: 3033973646.0782\n",
      "Epoch 6182/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 367119770.9758 - val_loss: 2589243583.4217\n",
      "Epoch 6183/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 488003891.8604 - val_loss: 2412279660.9350\n",
      "Epoch 6184/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 350246202.6292 - val_loss: 3089348016.4906\n",
      "Epoch 6185/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 479644959.9820 - val_loss: 2706515537.9668\n",
      "Epoch 6186/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 522280231.7546 - val_loss: 2584681598.7398\n",
      "Epoch 6187/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 379083909.1503 - val_loss: 2494588599.9167\n",
      "Epoch 6188/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 366770952.3557 - val_loss: 2389973615.6068\n",
      "Epoch 6189/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 482473382.1047 - val_loss: 3063812399.1854\n",
      "Epoch 6190/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 470202487.5363 - val_loss: 3066242293.9904\n",
      "Epoch 6191/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 794103425.9111 - val_loss: 2651337259.2698\n",
      "Epoch 6192/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 372888829.5779 - val_loss: 2420495979.7828\n",
      "Epoch 6193/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 630085812.1508 - val_loss: 3403438012.5795\n",
      "Epoch 6194/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 487048504.0405 - val_loss: 2469766067.8639\n",
      "Epoch 6195/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 473407760.1171 - val_loss: 3232095537.7418\n",
      "Epoch 6196/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 457050159.9730 - val_loss: 2465861501.6315\n",
      "Epoch 6197/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 349185034.5166 - val_loss: 2395622734.3139\n",
      "Epoch 6198/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 436045487.1086 - val_loss: 3852798156.7460\n",
      "Epoch 6199/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 769191706.5751 - val_loss: 2392092992.8416\n",
      "Epoch 6200/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 390938468.3489 - val_loss: 2807043665.5887\n",
      "Epoch 6201/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 444872403.3405 - val_loss: 3671909672.2633\n",
      "Epoch 6202/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1002265795.6736 - val_loss: 4107338642.1108\n",
      "Epoch 6203/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 811130369.1885 - val_loss: 2541805300.0956\n",
      "Epoch 6204/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 394791916.0113 - val_loss: 4020489546.9097\n",
      "Epoch 6205/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 488934377.1480 - val_loss: 2470376888.7719\n",
      "Epoch 6206/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 403033863.0591 - val_loss: 2793446774.8726\n",
      "Epoch 6207/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 650984330.0349 - val_loss: 2803801914.0703\n",
      "Epoch 6208/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 507873330.3860 - val_loss: 2371366607.6579\n",
      "Epoch 6209/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 324377696.9139 - val_loss: 2447378069.1443\n",
      "Epoch 6210/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 351179607.5408 - val_loss: 2500030902.0985\n",
      "Epoch 6211/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 340913162.2825 - val_loss: 2511304723.3980\n",
      "Epoch 6212/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 374015807.4237 - val_loss: 3003288771.2225\n",
      "Epoch 6213/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 683935039.9460 - val_loss: 3328089143.2686\n",
      "Epoch 6214/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 556104422.0506 - val_loss: 2637314692.4107\n",
      "Epoch 6215/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 430684513.0264 - val_loss: 2553528475.8639\n",
      "Epoch 6216/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 408461378.0889 - val_loss: 2526702119.5342\n",
      "Epoch 6217/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 467329853.3438 - val_loss: 2863735434.5496\n",
      "Epoch 6218/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 607254334.1306 - val_loss: 2722097035.7738\n",
      "Epoch 6219/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 449054482.4941 - val_loss: 2521994880.4737\n",
      "Epoch 6220/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 600356884.3129 - val_loss: 7322046008.9609\n",
      "Epoch 6221/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 867977043.3495 - val_loss: 2912583651.9876\n",
      "Epoch 6222/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 566724675.3360 - val_loss: 3776623170.3854\n",
      "Epoch 6223/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 550987102.6764 - val_loss: 2572306852.6807\n",
      "Epoch 6224/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 376420134.4648 - val_loss: 2999161179.5533\n",
      "Epoch 6225/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 730247624.6798 - val_loss: 2422277577.0914\n",
      "Epoch 6226/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 421338058.9578 - val_loss: 2441968282.5361\n",
      "Epoch 6227/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 498713350.6269 - val_loss: 2701010810.5992\n",
      "Epoch 6228/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 475258322.1790 - val_loss: 5227339703.1246\n",
      "Epoch 6229/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 761475828.8846 - val_loss: 2591425964.5817\n",
      "Epoch 6230/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 395414674.2870 - val_loss: 2617549764.1603\n",
      "Epoch 6231/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 353171407.6488 - val_loss: 3156275734.4945\n",
      "Epoch 6232/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 625313718.5909 - val_loss: 2609104054.1165\n",
      "Epoch 6233/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 406463491.7817 - val_loss: 2500641187.4700\n",
      "Epoch 6234/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 81us/step - loss: 440829800.2386 - val_loss: 2452311877.9927\n",
      "Epoch 6235/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 354313563.6083 - val_loss: 3093439502.8703\n",
      "Epoch 6236/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 509239308.7856 - val_loss: 2447747210.0388\n",
      "Epoch 6237/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 381711074.3230 - val_loss: 2634515501.3311\n",
      "Epoch 6238/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 402178446.4783 - val_loss: 3109737358.5463\n",
      "Epoch 6239/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 465327873.8225 - val_loss: 2601805061.9139\n",
      "Epoch 6240/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 456367154.9983 - val_loss: 2537971242.8827\n",
      "Epoch 6241/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 366717686.8700 - val_loss: 2468420539.4273\n",
      "Epoch 6242/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 407588563.6286 - val_loss: 2506696039.2158\n",
      "Epoch 6243/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 434435650.5571 - val_loss: 2679450665.1904\n",
      "Epoch 6244/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 574217906.3950 - val_loss: 2634342283.0537\n",
      "Epoch 6245/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 564306441.3236 - val_loss: 2544745904.4579\n",
      "Epoch 6246/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 371320480.8464 - val_loss: 2529283654.5710\n",
      "Epoch 6247/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 405999642.5796 - val_loss: 2398974402.7454\n",
      "Epoch 6248/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 652364756.6370 - val_loss: 2865332932.1406\n",
      "Epoch 6249/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 721555828.6550 - val_loss: 2456119081.8295\n",
      "Epoch 6250/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 464084429.6342 - val_loss: 2647948779.4588\n",
      "Epoch 6251/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 405251367.0051 - val_loss: 2687911946.9007\n",
      "Epoch 6252/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 381121433.7513 - val_loss: 2644940654.9693\n",
      "Epoch 6253/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 493315964.8846 - val_loss: 2827189118.9018\n",
      "Epoch 6254/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 474491724.5695 - val_loss: 2549959830.0354\n",
      "Epoch 6255/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 423855856.0270 - val_loss: 2696889191.4352\n",
      "Epoch 6256/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 404641622.9600 - val_loss: 2768098334.0287\n",
      "Epoch 6257/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 451986384.8194 - val_loss: 5777102741.4594\n",
      "Epoch 6258/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 605819214.3613 - val_loss: 2458585226.7733\n",
      "Epoch 6259/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 464319308.3714 - val_loss: 4002094447.0594\n",
      "Epoch 6260/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 644070103.8064 - val_loss: 2824888361.0914\n",
      "Epoch 6261/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 451098468.5155 - val_loss: 3040959171.5916\n",
      "Epoch 6262/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 588290502.6989 - val_loss: 2676656333.3041\n",
      "Epoch 6263/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 451399167.9820 - val_loss: 2608945349.5989\n",
      "Epoch 6264/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 414640320.3061 - val_loss: 2558542566.1525\n",
      "Epoch 6265/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 370579905.0535 - val_loss: 2772494065.3997\n",
      "Epoch 6266/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 427545929.4361 - val_loss: 2413925156.8954\n",
      "Epoch 6267/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 476722055.1266 - val_loss: 3154607369.4965\n",
      "Epoch 6268/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 450057111.0501 - val_loss: 2574782003.8121\n",
      "Epoch 6269/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 381274979.9482 - val_loss: 2519880165.5179\n",
      "Epoch 6270/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 411754714.6697 - val_loss: 2727828117.9657\n",
      "Epoch 6271/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 598422155.1649 - val_loss: 3298670579.9741\n",
      "Epoch 6272/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 592573652.1688 - val_loss: 2405742075.4543\n",
      "Epoch 6273/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 419682500.8621 - val_loss: 3013183455.0909\n",
      "Epoch 6274/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 403350887.0771 - val_loss: 2385989800.2903\n",
      "Epoch 6275/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 349956190.8475 - val_loss: 2559831363.0695\n",
      "Epoch 6276/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 492826682.5796 - val_loss: 2483647017.6945\n",
      "Epoch 6277/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 453418444.6370 - val_loss: 2456679048.2183\n",
      "Epoch 6278/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 333515068.0383 - val_loss: 2847546790.7691\n",
      "Epoch 6279/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 431065321.0490 - val_loss: 3269053570.7409\n",
      "Epoch 6280/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 530343321.2549 - val_loss: 2439679814.6520\n",
      "Epoch 6281/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 375031181.8301 - val_loss: 2463616434.4619\n",
      "Epoch 6282/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 442960060.1013 - val_loss: 4214894602.8782\n",
      "Epoch 6283/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 503902757.2043 - val_loss: 3001347296.3691\n",
      "Epoch 6284/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 587563380.9071 - val_loss: 3414936096.0450\n",
      "Epoch 6285/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 593497087.7366 - val_loss: 2375817856.1530\n",
      "Epoch 6286/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 330471321.1030 - val_loss: 2394834455.1876\n",
      "Epoch 6287/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 412452205.7963 - val_loss: 2473607504.4186\n",
      "Epoch 6288/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 437147085.0107 - val_loss: 2441921631.6129\n",
      "Epoch 6289/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 362063622.5189 - val_loss: 2543830940.1114\n",
      "Epoch 6290/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 398763533.3979 - val_loss: 2482463404.9260\n",
      "Epoch 6291/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 438754219.8672 - val_loss: 2601913413.5347\n",
      "Epoch 6292/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 434272022.6179 - val_loss: 3518692845.4391\n",
      "Epoch 6293/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 733955112.6438 - val_loss: 2563619547.5511\n",
      "Epoch 6294/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 587575502.8430 - val_loss: 2763953961.8745\n",
      "Epoch 6295/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 356945021.6320 - val_loss: 2479969454.5980\n",
      "Epoch 6296/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 316702413.7400 - val_loss: 2499763122.9772\n",
      "Epoch 6297/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 428228646.9758 - val_loss: 2645636727.8312\n",
      "Epoch 6298/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 434313756.9207 - val_loss: 3885824374.6205\n",
      "Epoch 6299/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 91us/step - loss: 896448592.9319 - val_loss: 2410647051.5623\n",
      "Epoch 6300/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 410570625.8008 - val_loss: 5046778991.5454\n",
      "Epoch 6301/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 710483298.0822 - val_loss: 2540627815.4847\n",
      "Epoch 6302/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 354379644.6685 - val_loss: 2619721694.1468\n",
      "Epoch 6303/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 516490996.8171 - val_loss: 2636548767.5848\n",
      "Epoch 6304/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 383320619.8312 - val_loss: 2611616441.5730\n",
      "Epoch 6305/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 322493042.4041 - val_loss: 2364822397.4903\n",
      "Epoch 6306/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 442007409.8458 - val_loss: 2605603269.8329\n",
      "Epoch 6307/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 424398528.8374 - val_loss: 2833300676.4287\n",
      "Epoch 6308/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 463611458.8633 - val_loss: 3450383715.6456\n",
      "Epoch 6309/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 483636751.4868 - val_loss: 4640259011.2450\n",
      "Epoch 6310/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 761649481.0850 - val_loss: 2625366789.9769\n",
      "Epoch 6311/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 515684999.2954 - val_loss: 2371279740.9710\n",
      "Epoch 6312/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 509927999.8920 - val_loss: 5038472186.1221\n",
      "Epoch 6313/7000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 854260967.4373 - val_loss: 2581427702.3145\n",
      "Epoch 6314/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 379555171.6916 - val_loss: 3216604157.4909\n",
      "Epoch 6315/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 383731776.2566 - val_loss: 2946537084.6875\n",
      "Epoch 6316/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 344348781.5239 - val_loss: 2491982494.1862\n",
      "Epoch 6317/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 413916813.1097 - val_loss: 2567609468.0394\n",
      "Epoch 6318/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 494810479.9730 - val_loss: 2658937887.3935\n",
      "Epoch 6319/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 421060156.1688 - val_loss: 4104878583.7907\n",
      "Epoch 6320/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 512125307.0748 - val_loss: 2800656216.1215\n",
      "Epoch 6321/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 522155981.9291 - val_loss: 2661481025.9916\n",
      "Epoch 6322/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 386288086.4828 - val_loss: 2470899360.3241\n",
      "Epoch 6323/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 385184692.7271 - val_loss: 2414084259.3530\n",
      "Epoch 6324/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 335994048.8936 - val_loss: 2511964143.8965\n",
      "Epoch 6325/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 438188943.1266 - val_loss: 4613377697.6653\n",
      "Epoch 6326/7000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 742906499.5476 - val_loss: 2694434865.0217\n",
      "Epoch 6327/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 501206421.4654 - val_loss: 2527874187.2203\n",
      "Epoch 6328/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 330993530.3995 - val_loss: 2604903946.9997\n",
      "Epoch 6329/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 409376403.2324 - val_loss: 2754764909.6731\n",
      "Epoch 6330/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 748042421.3033 - val_loss: 8816381941.4143\n",
      "Epoch 6331/7000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 738737641.3821 - val_loss: 2715723001.6945\n",
      "Epoch 6332/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 640080373.1232 - val_loss: 2478445334.9671\n",
      "Epoch 6333/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 430074304.4322 - val_loss: 2844986826.9457\n",
      "Epoch 6334/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 352692367.6669 - val_loss: 2386849488.6954\n",
      "Epoch 6335/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 466534671.5183 - val_loss: 2381097450.4225\n",
      "Epoch 6336/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 287889927.3292 - val_loss: 2450683084.5255\n",
      "Epoch 6337/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 554325754.1204 - val_loss: 2646562246.7781\n",
      "Epoch 6338/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 412700631.5476 - val_loss: 2400160724.3769\n",
      "Epoch 6339/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 315559234.1249 - val_loss: 3718516382.2447\n",
      "Epoch 6340/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 635606666.0664 - val_loss: 2689335196.4084\n",
      "Epoch 6341/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 415625332.2409 - val_loss: 2442374333.9994\n",
      "Epoch 6342/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 370411269.3303 - val_loss: 3875335033.5190\n",
      "Epoch 6343/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 734773983.2212 - val_loss: 2498438781.3626\n",
      "Epoch 6344/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 368017363.3585 - val_loss: 2502736308.1632\n",
      "Epoch 6345/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 384833580.8981 - val_loss: 2600330838.0759\n",
      "Epoch 6346/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 384360625.0084 - val_loss: 2394415538.3809\n",
      "Epoch 6347/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 379558522.6472 - val_loss: 2978753255.5702\n",
      "Epoch 6348/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 455095311.4192 - val_loss: 2493183975.5162\n",
      "Epoch 6349/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 364148391.6173 - val_loss: 3500997538.7274\n",
      "Epoch 6350/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 659377303.1401 - val_loss: 2459343649.4852\n",
      "Epoch 6351/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 461119011.2414 - val_loss: 5672717359.0233\n",
      "Epoch 6352/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 955122142.5549 - val_loss: 2562927622.3550\n",
      "Epoch 6353/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 472700839.6533 - val_loss: 2591533467.1449\n",
      "Epoch 6354/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 496065653.2133 - val_loss: 2761145582.2492\n",
      "Epoch 6355/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 616633281.7648 - val_loss: 2601319683.5916\n",
      "Epoch 6356/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 509122537.3731 - val_loss: 2558726130.7128\n",
      "Epoch 6357/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 478810198.4738 - val_loss: 2377155781.0813\n",
      "Epoch 6358/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 366811654.7169 - val_loss: 2646144180.0101\n",
      "Epoch 6359/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 385110065.7175 - val_loss: 2424142735.1944\n",
      "Epoch 6360/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 423421497.6432 - val_loss: 2439899082.8714\n",
      "Epoch 6361/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 391448712.3917 - val_loss: 2891541205.4504\n",
      "Epoch 6362/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 537158066.2015 - val_loss: 2356143292.0664\n",
      "Epoch 6363/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 359589650.2960 - val_loss: 3840708200.6864\n",
      "Epoch 6364/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 84us/step - loss: 672787019.7817 - val_loss: 2542539349.4278\n",
      "Epoch 6365/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 421679503.2707 - val_loss: 2406849925.4368\n",
      "Epoch 6366/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 373051850.3095 - val_loss: 2671334568.4343\n",
      "Epoch 6367/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 475292582.9690 - val_loss: 3748311502.2762\n",
      "Epoch 6368/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 718593312.5222 - val_loss: 2450225179.3125\n",
      "Epoch 6369/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 405012570.1835 - val_loss: 2438395792.5761\n",
      "Epoch 6370/7000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 353866462.8160 - val_loss: 2538341701.7609\n",
      "Epoch 6371/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 768920067.3134 - val_loss: 2954039300.7302\n",
      "Epoch 6372/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 377207939.3495 - val_loss: 2801561264.2205\n",
      "Epoch 6373/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 391941159.2572 - val_loss: 3423803921.4447\n",
      "Epoch 6374/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 553653301.3236 - val_loss: 2362597822.8838\n",
      "Epoch 6375/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 350869568.1080 - val_loss: 2448370655.6084\n",
      "Epoch 6376/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 494149748.8846 - val_loss: 2707806582.4405\n",
      "Epoch 6377/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 376406281.5802 - val_loss: 3982621353.1004\n",
      "Epoch 6378/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 513466560.5672 - val_loss: 2427349071.5004\n",
      "Epoch 6379/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 349541370.8858 - val_loss: 2590619890.2549\n",
      "Epoch 6380/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 445937452.4434 - val_loss: 2574002931.7041\n",
      "Epoch 6381/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 435443577.4136 - val_loss: 2668722888.7584\n",
      "Epoch 6382/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 487374044.7406 - val_loss: 2712834099.4520\n",
      "Epoch 6383/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 585555579.8132 - val_loss: 2746485040.1935\n",
      "Epoch 6384/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 473377049.2470 - val_loss: 2375514331.5533\n",
      "Epoch 6385/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 380436793.2831 - val_loss: 2696664103.4622\n",
      "Epoch 6386/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 508806601.5082 - val_loss: 4408520925.8307\n",
      "Epoch 6387/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 669681440.7023 - val_loss: 2909412927.6129\n",
      "Epoch 6388/7000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 680191489.6837 - val_loss: 2350018774.5215\n",
      "Epoch 6389/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 358618016.9184 - val_loss: 2924490142.9288\n",
      "Epoch 6390/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 386858292.3669 - val_loss: 2797459316.2937\n",
      "Epoch 6391/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 571802027.1469 - val_loss: 3535018027.8639\n",
      "Epoch 6392/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 377661326.3883 - val_loss: 2441000155.7783\n",
      "Epoch 6393/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 382952477.5329 - val_loss: 5127967600.8416\n",
      "Epoch 6394/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 797026425.1930 - val_loss: 2665993200.4928\n",
      "Epoch 6395/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 424173948.5785 - val_loss: 2353858457.5910\n",
      "Epoch 6396/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 313226148.3039 - val_loss: 3757871709.5966\n",
      "Epoch 6397/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 631349818.3635 - val_loss: 2415146657.3907\n",
      "Epoch 6398/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 403519385.5712 - val_loss: 2561429932.3646\n",
      "Epoch 6399/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 449304505.0129 - val_loss: 2410064443.0132\n",
      "Epoch 6400/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 390746135.8784 - val_loss: 2540018598.7060\n",
      "Epoch 6401/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 370791987.6826 - val_loss: 2699195353.3660\n",
      "Epoch 6402/7000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 401827130.5976 - val_loss: 2342286096.2385\n",
      "Epoch 6403/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 467348276.1317 - val_loss: 2525858636.5750\n",
      "Epoch 6404/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 400105063.9775 - val_loss: 3285450781.3806\n",
      "Epoch 6405/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 457953358.0191 - val_loss: 2557907307.8475\n",
      "Epoch 6406/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 398522900.4299 - val_loss: 2496357166.7173\n",
      "Epoch 6407/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 568926543.9010 - val_loss: 2839389140.7212\n",
      "Epoch 6408/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 493272808.8959 - val_loss: 2682114626.4259\n",
      "Epoch 6409/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 394152321.8098 - val_loss: 2525112563.7761\n",
      "Epoch 6410/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 341201797.1503 - val_loss: 3160414604.9080\n",
      "Epoch 6411/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 546935724.9026 - val_loss: 2342384916.9013\n",
      "Epoch 6412/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 390295243.1919 - val_loss: 2580633033.2534\n",
      "Epoch 6413/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 438243633.2606 - val_loss: 2537038711.7187\n",
      "Epoch 6414/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 394050863.6488 - val_loss: 3196875141.6394\n",
      "Epoch 6415/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 579401200.9094 - val_loss: 2437708192.6391\n",
      "Epoch 6416/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 399254531.9347 - val_loss: 2689031912.3150\n",
      "Epoch 6417/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 327260272.5492 - val_loss: 2723530535.7007\n",
      "Epoch 6418/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 415800915.3765 - val_loss: 2588266815.2664\n",
      "Epoch 6419/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 589130322.1699 - val_loss: 2624478757.3918\n",
      "Epoch 6420/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 635274527.9820 - val_loss: 3073579589.1488\n",
      "Epoch 6421/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 462108901.4654 - val_loss: 2485478159.9842\n",
      "Epoch 6422/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 365185962.7147 - val_loss: 4297041294.8703\n",
      "Epoch 6423/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 461034078.4153 - val_loss: 2426756334.5316\n",
      "Epoch 6424/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 316236147.4260 - val_loss: 2454391901.2006\n",
      "Epoch 6425/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 443925981.1728 - val_loss: 2569337917.0835\n",
      "Epoch 6426/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 433157013.2853 - val_loss: 2423204103.4397\n",
      "Epoch 6427/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 466108998.6809 - val_loss: 2435544898.8973\n",
      "Epoch 6428/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 324450856.4007 - val_loss: 2887384124.8675\n",
      "Epoch 6429/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 95us/step - loss: 724534150.3748 - val_loss: 3010353193.9589\n",
      "Epoch 6430/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 782677801.5982 - val_loss: 2533239509.8734\n",
      "Epoch 6431/7000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 379401208.0765 - val_loss: 2569071102.5440\n",
      "Epoch 6432/7000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 409281012.6190 - val_loss: 2909621737.1117\n",
      "Epoch 6433/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 522793883.8942 - val_loss: 3951803099.4318\n",
      "Epoch 6434/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 459754028.1553 - val_loss: 2498557588.7752\n",
      "Epoch 6435/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 349455476.6550 - val_loss: 2655818818.6284\n",
      "Epoch 6436/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 468772284.2724 - val_loss: 2466211161.1792\n",
      "Epoch 6437/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 383178814.0340 - val_loss: 3112550362.5902\n",
      "Epoch 6438/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 423037320.5718 - val_loss: 2690052488.2003\n",
      "Epoch 6439/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 359373557.6995 - val_loss: 3025642338.8354\n",
      "Epoch 6440/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 405755396.5380 - val_loss: 2657832511.7840\n",
      "Epoch 6441/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 412676798.0461 - val_loss: 2672349616.1575\n",
      "Epoch 6442/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 436199245.0017 - val_loss: 2589735296.1890\n",
      "Epoch 6443/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 627287961.5982 - val_loss: 2487016784.6188\n",
      "Epoch 6444/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 352542196.1148 - val_loss: 3274455949.5201\n",
      "Epoch 6445/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 721064121.0760 - val_loss: 2787450840.7899\n",
      "Epoch 6446/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 483793719.4733 - val_loss: 2560432133.8262\n",
      "Epoch 6447/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 429896008.2476 - val_loss: 3310122443.0357\n",
      "Epoch 6448/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 463044455.8154 - val_loss: 2346152037.0138\n",
      "Epoch 6449/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 320886876.3331 - val_loss: 2437914844.4962\n",
      "Epoch 6450/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 341885309.1187 - val_loss: 2911509743.7795\n",
      "Epoch 6451/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 476566626.2915 - val_loss: 2724646984.9474\n",
      "Epoch 6452/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 482562251.8492 - val_loss: 3797888323.9246\n",
      "Epoch 6453/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 681348045.6860 - val_loss: 2670402811.0852\n",
      "Epoch 6454/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 389133392.8914 - val_loss: 2420474282.5677\n",
      "Epoch 6455/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 382917713.3956 - val_loss: 2809475145.8565\n",
      "Epoch 6456/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 510733833.6522 - val_loss: 4748919930.8512\n",
      "Epoch 6457/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 724415194.9038 - val_loss: 2658942697.9286\n",
      "Epoch 6458/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 485081458.7462 - val_loss: 4068113408.0000\n",
      "Epoch 6459/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 588384412.7856 - val_loss: 2441872494.6228\n",
      "Epoch 6460/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 311253687.1491 - val_loss: 2418174808.5558\n",
      "Epoch 6461/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 393606590.3073 - val_loss: 3695554693.9634\n",
      "Epoch 6462/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1155726268.2183 - val_loss: 2393878887.8627\n",
      "Epoch 6463/7000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 336537793.3686 - val_loss: 2376673851.6928\n",
      "Epoch 6464/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 380913089.9358 - val_loss: 2532403668.9463\n",
      "Epoch 6465/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 367899138.1609 - val_loss: 2392906789.8959\n",
      "Epoch 6466/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 455608321.8008 - val_loss: 2529850093.1083\n",
      "Epoch 6467/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 350989979.1199 - val_loss: 2385364798.5778\n",
      "Epoch 6468/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 383158162.9443 - val_loss: 6908184997.7699\n",
      "Epoch 6469/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 836090282.8588 - val_loss: 2738281648.2475\n",
      "Epoch 6470/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 571883465.1345 - val_loss: 2632434285.1646\n",
      "Epoch 6471/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 375715290.1204 - val_loss: 2451724780.8360\n",
      "Epoch 6472/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 682715692.6235 - val_loss: 3810265692.4805\n",
      "Epoch 6473/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 415306509.8053 - val_loss: 2511409078.6790\n",
      "Epoch 6474/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 347012053.1232 - val_loss: 2681749649.1657\n",
      "Epoch 6475/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 719576050.7822 - val_loss: 2701236702.5508\n",
      "Epoch 6476/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 380712827.2819 - val_loss: 2432238252.7010\n",
      "Epoch 6477/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 405147253.3123 - val_loss: 2442130837.7446\n",
      "Epoch 6478/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 309290356.7901 - val_loss: 2363829122.9885\n",
      "Epoch 6479/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 338628599.3382 - val_loss: 2347384981.3828\n",
      "Epoch 6480/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 373373172.3849 - val_loss: 3080257401.4830\n",
      "Epoch 6481/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 431677648.3151 - val_loss: 2659456595.1010\n",
      "Epoch 6482/7000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 583168560.1531 - val_loss: 3244657236.6132\n",
      "Epoch 6483/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 620183521.4586 - val_loss: 2679891264.5845\n",
      "Epoch 6484/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 617304783.3067 - val_loss: 2359543698.7511\n",
      "Epoch 6485/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 331816856.8149 - val_loss: 2870555473.2647\n",
      "Epoch 6486/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 551560795.7772 - val_loss: 2472123951.5364\n",
      "Epoch 6487/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 298577828.2409 - val_loss: 2751624589.4751\n",
      "Epoch 6488/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 542191043.1514 - val_loss: 2645088824.0968\n",
      "Epoch 6489/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 420105427.8652 - val_loss: 2764466710.6700\n",
      "Epoch 6490/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 762613282.1384 - val_loss: 2460689505.9364\n",
      "Epoch 6491/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 491567799.3742 - val_loss: 2338910493.9027\n",
      "Epoch 6492/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 362525679.3517 - val_loss: 2736158481.9308\n",
      "Epoch 6493/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 555021994.2195 - val_loss: 2492821001.8745\n",
      "Epoch 6494/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 85us/step - loss: 386783825.1367 - val_loss: 2507526840.1688\n",
      "Epoch 6495/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 426527158.7440 - val_loss: 3725908716.8630\n",
      "Epoch 6496/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 673092924.5695 - val_loss: 2487407557.5719\n",
      "Epoch 6497/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 378081557.3371 - val_loss: 2381676023.8031\n",
      "Epoch 6498/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 329107109.6545 - val_loss: 2364870422.3775\n",
      "Epoch 6499/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 309348325.8075 - val_loss: 2391915799.0402\n",
      "Epoch 6500/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 578781541.8526 - val_loss: 2844527621.4008\n",
      "Epoch 6501/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 529424533.3821 - val_loss: 2649252103.9010\n",
      "Epoch 6502/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 440938723.0163 - val_loss: 2600870080.3601\n",
      "Epoch 6503/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 329919662.5144 - val_loss: 2478604758.5125\n",
      "Epoch 6504/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 410633994.7507 - val_loss: 2564405994.6307\n",
      "Epoch 6505/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 425456973.0377 - val_loss: 2908460908.0439\n",
      "Epoch 6506/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 683085364.0788 - val_loss: 2518499280.4861\n",
      "Epoch 6507/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 348415633.9809 - val_loss: 2610387088.3736\n",
      "Epoch 6508/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 454107590.4648 - val_loss: 2967720834.4079\n",
      "Epoch 6509/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 470507410.7912 - val_loss: 2435156015.7840\n",
      "Epoch 6510/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 339460759.1671 - val_loss: 2706871759.5162\n",
      "Epoch 6511/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 423451857.5217 - val_loss: 2939444077.4278\n",
      "Epoch 6512/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 549034404.6280 - val_loss: 3036350771.4925\n",
      "Epoch 6513/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 444145203.8807 - val_loss: 2722829695.1044\n",
      "Epoch 6514/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 487930109.0107 - val_loss: 2389548741.6669\n",
      "Epoch 6515/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 400829068.9657 - val_loss: 3521475220.8833\n",
      "Epoch 6516/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 340796849.1975 - val_loss: 2473377672.4163\n",
      "Epoch 6517/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 567426665.6972 - val_loss: 2587324431.5184\n",
      "Epoch 6518/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 410129206.5189 - val_loss: 2439053452.7460\n",
      "Epoch 6519/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 416743097.6882 - val_loss: 2430792027.5983\n",
      "Epoch 6520/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 476175515.9842 - val_loss: 2770350900.1947\n",
      "Epoch 6521/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 484475741.5411 - val_loss: 2438119573.8374\n",
      "Epoch 6522/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 687735161.0850 - val_loss: 2495957060.4906\n",
      "Epoch 6523/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 472061541.7805 - val_loss: 2862981301.7564\n",
      "Epoch 6524/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 439114786.2150 - val_loss: 2416383777.3952\n",
      "Epoch 6525/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 506054551.3022 - val_loss: 2500262906.3201\n",
      "Epoch 6526/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 467326962.6472 - val_loss: 2506762653.9927\n",
      "Epoch 6527/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 306978328.5988 - val_loss: 2312558677.3018\n",
      "Epoch 6528/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 345738058.6877 - val_loss: 2631058998.6520\n",
      "Epoch 6529/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 508965310.4513 - val_loss: 2544202190.7173\n",
      "Epoch 6530/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 597644089.3461 - val_loss: 2486120887.9167\n",
      "Epoch 6531/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 322582370.6652 - val_loss: 2350000693.0678\n",
      "Epoch 6532/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 540024479.0096 - val_loss: 2474133573.0408\n",
      "Epoch 6533/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 346966634.2465 - val_loss: 2575863767.7547\n",
      "Epoch 6534/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 358000341.8616 - val_loss: 3444884163.6231\n",
      "Epoch 6535/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 433300283.1019 - val_loss: 2535176345.1679\n",
      "Epoch 6536/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 359765333.7895 - val_loss: 2538549853.2006\n",
      "Epoch 6537/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 763053305.2290 - val_loss: 2878570377.3255\n",
      "Epoch 6538/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 650971948.4615 - val_loss: 2605296564.5345\n",
      "Epoch 6539/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 442869136.4052 - val_loss: 2779747331.7356\n",
      "Epoch 6540/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 442339061.8526 - val_loss: 2335176793.0149\n",
      "Epoch 6541/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 467208821.8075 - val_loss: 2602115680.8934\n",
      "Epoch 6542/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 329692640.7158 - val_loss: 2530012591.3091\n",
      "Epoch 6543/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 407241300.2949 - val_loss: 2606807595.2608\n",
      "Epoch 6544/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 371068412.2814 - val_loss: 2445570286.6453\n",
      "Epoch 6545/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 362110526.6854 - val_loss: 2481569097.0194\n",
      "Epoch 6546/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 536473382.0957 - val_loss: 2812893631.5297\n",
      "Epoch 6547/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 445447996.1463 - val_loss: 2516498945.6979\n",
      "Epoch 6548/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 366469052.1553 - val_loss: 2360271300.9688\n",
      "Epoch 6549/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 378232476.4524 - val_loss: 2680724017.8948\n",
      "Epoch 6550/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 395854206.5594 - val_loss: 3636101854.5508\n",
      "Epoch 6551/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 485117858.6382 - val_loss: 3611534283.3958\n",
      "Epoch 6552/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 646644716.4434 - val_loss: 2905750084.1947\n",
      "Epoch 6553/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 548286847.3697 - val_loss: 2580453338.0141\n",
      "Epoch 6554/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 568949374.2195 - val_loss: 2499160490.9367\n",
      "Epoch 6555/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 507287975.9055 - val_loss: 2332005647.6940\n",
      "Epoch 6556/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 429897438.6314 - val_loss: 2568745461.1060\n",
      "Epoch 6557/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 406709433.1930 - val_loss: 2528075964.3904\n",
      "Epoch 6558/7000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 310201652.9612 - val_loss: 2562608977.5404\n",
      "Epoch 6559/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 96us/step - loss: 557389006.0461 - val_loss: 2724058810.8152\n",
      "Epoch 6560/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 392089174.9781 - val_loss: 2581915968.4141\n",
      "Epoch 6561/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 363323257.5172 - val_loss: 2696684937.5055\n",
      "Epoch 6562/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 549129797.2223 - val_loss: 5280356468.5142\n",
      "Epoch 6563/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1087817977.8773 - val_loss: 2670708107.8729\n",
      "Epoch 6564/7000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 425387167.2527 - val_loss: 2641400948.8023\n",
      "Epoch 6565/7000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 367603827.4035 - val_loss: 2455768464.4906\n",
      "Epoch 6566/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 342981305.9494 - val_loss: 2900120935.3722\n",
      "Epoch 6567/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 781964423.7794 - val_loss: 2450269103.9775\n",
      "Epoch 6568/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 318402565.9426 - val_loss: 2384918226.9570\n",
      "Epoch 6569/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 417197574.6269 - val_loss: 2544594812.7505\n",
      "Epoch 6570/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 668845438.6314 - val_loss: 3390897576.2903\n",
      "Epoch 6571/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 414743789.9786 - val_loss: 2670573358.9153\n",
      "Epoch 6572/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 347948972.4615 - val_loss: 2358632874.8107\n",
      "Epoch 6573/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 408215907.8357 - val_loss: 4243127275.8008\n",
      "Epoch 6574/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 420486185.8841 - val_loss: 2598964504.8866\n",
      "Epoch 6575/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 502090673.1525 - val_loss: 2567500572.0191\n",
      "Epoch 6576/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 377167869.3528 - val_loss: 2400976316.9823\n",
      "Epoch 6577/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 339446056.0495 - val_loss: 2460712457.1004\n",
      "Epoch 6578/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 326371727.6849 - val_loss: 2422369264.3736\n",
      "Epoch 6579/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 381920593.3146 - val_loss: 3507646983.0571\n",
      "Epoch 6580/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 657372594.0889 - val_loss: 2613990010.8692\n",
      "Epoch 6581/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 349436375.5183 - val_loss: 2891023218.8107\n",
      "Epoch 6582/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 732416337.4586 - val_loss: 2382441013.0397\n",
      "Epoch 6583/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 300103201.2876 - val_loss: 2384768185.7080\n",
      "Epoch 6584/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 411879668.3354 - val_loss: 3153390417.7328\n",
      "Epoch 6585/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 362361377.8053 - val_loss: 2507604762.3606\n",
      "Epoch 6586/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 403306477.0557 - val_loss: 2655549619.4610\n",
      "Epoch 6587/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 400102860.9747 - val_loss: 2339650641.4402\n",
      "Epoch 6588/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 336233335.0321 - val_loss: 2595509848.0608\n",
      "Epoch 6589/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 549549420.5515 - val_loss: 2655979510.1322\n",
      "Epoch 6590/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 375084055.2302 - val_loss: 2335451105.2827\n",
      "Epoch 6591/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 321243969.6027 - val_loss: 2715629020.7280\n",
      "Epoch 6592/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 461637617.9629 - val_loss: 3242014022.6340\n",
      "Epoch 6593/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 552551619.5566 - val_loss: 2710299816.1328\n",
      "Epoch 6594/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 521969997.3044 - val_loss: 3548743396.6357\n",
      "Epoch 6595/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 397116061.1097 - val_loss: 2530364248.3218\n",
      "Epoch 6596/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 517334817.1885 - val_loss: 3289804105.8745\n",
      "Epoch 6597/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 525855235.8897 - val_loss: 2864299813.1398\n",
      "Epoch 6598/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 423358836.1148 - val_loss: 2430172387.4835\n",
      "Epoch 6599/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 594000171.4350 - val_loss: 2551047052.1744\n",
      "Epoch 6600/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 512196552.3376 - val_loss: 2818319680.7156\n",
      "Epoch 6601/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 346960158.1632 - val_loss: 3130054378.2886\n",
      "Epoch 6602/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 497428985.1570 - val_loss: 3883807156.5502\n",
      "Epoch 6603/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 442206555.5442 - val_loss: 2437365282.3899\n",
      "Epoch 6604/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 351495735.3562 - val_loss: 3522773227.8368\n",
      "Epoch 6605/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 558802663.8900 - val_loss: 2559488816.3196\n",
      "Epoch 6606/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 456393018.3905 - val_loss: 2610792296.6684\n",
      "Epoch 6607/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 279401530.0304 - val_loss: 3022035889.6518\n",
      "Epoch 6608/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 373260942.7124 - val_loss: 3819277278.0647\n",
      "Epoch 6609/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 490049939.6646 - val_loss: 2851176303.5094\n",
      "Epoch 6610/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 437096364.7136 - val_loss: 2553268167.5072\n",
      "Epoch 6611/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 420491090.2780 - val_loss: 2454713515.9764\n",
      "Epoch 6612/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 391439257.8413 - val_loss: 2420634009.6540\n",
      "Epoch 6613/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 482856475.4980 - val_loss: 4502027707.1572\n",
      "Epoch 6614/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 477053434.4176 - val_loss: 2704382215.4172\n",
      "Epoch 6615/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 885035979.0028 - val_loss: 2741506414.0557\n",
      "Epoch 6616/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 824761431.0141 - val_loss: 4536419579.6186\n",
      "Epoch 6617/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2768166827.2909 - val_loss: 3404819035.9314\n",
      "Epoch 6618/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 316012125.9381 - val_loss: 2351964363.1977\n",
      "Epoch 6619/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 313779626.5369 - val_loss: 2498345768.2700\n",
      "Epoch 6620/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 278373052.5605 - val_loss: 2697644486.2740\n",
      "Epoch 6621/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 438187259.0658 - val_loss: 3958330985.6765\n",
      "Epoch 6622/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 388928987.4350 - val_loss: 2342024540.7212\n",
      "Epoch 6623/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 321437533.3528 - val_loss: 2485428786.8726\n",
      "Epoch 6624/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 76us/step - loss: 310489762.0889 - val_loss: 2967023399.4892\n",
      "Epoch 6625/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 351158628.5200 - val_loss: 2795487912.4591\n",
      "Epoch 6626/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 632613776.2071 - val_loss: 4590027741.1105\n",
      "Epoch 6627/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1338296186.4986 - val_loss: 2511107985.5055\n",
      "Epoch 6628/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 291430999.6995 - val_loss: 2381845483.7603\n",
      "Epoch 6629/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 281973607.1491 - val_loss: 3108930843.6523\n",
      "Epoch 6630/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 416410085.1683 - val_loss: 2417086777.4605\n",
      "Epoch 6631/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 525297470.1002 - val_loss: 2606818005.6574\n",
      "Epoch 6632/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 417258798.0461 - val_loss: 2382562856.4433\n",
      "Epoch 6633/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 379766336.0360 - val_loss: 3005236398.9491\n",
      "Epoch 6634/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 525078484.7721 - val_loss: 2502273048.1440\n",
      "Epoch 6635/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 373484964.6730 - val_loss: 2406239126.3595\n",
      "Epoch 6636/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 465460327.5813 - val_loss: 2463586897.3097 ETA: 0s - loss: 528624855.88\n",
      "Epoch 6637/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 323844474.0934 - val_loss: 2445485951.2529\n",
      "Epoch 6638/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 284049848.1846 - val_loss: 3307865347.8166\n",
      "Epoch 6639/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 416178620.2544 - val_loss: 2673027255.4127\n",
      "Epoch 6640/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 797152300.6235 - val_loss: 2406697315.5916\n",
      "Epoch 6641/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 424950482.5121 - val_loss: 2563717445.6259\n",
      "Epoch 6642/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 324223124.8891 - val_loss: 3806238059.2968\n",
      "Epoch 6643/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1178768794.1474 - val_loss: 2753458607.8155\n",
      "Epoch 6644/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 381252306.1880 - val_loss: 4111336849.5347\n",
      "Epoch 6645/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 639833424.0180 - val_loss: 2641054781.0937\n",
      "Epoch 6646/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 320575581.2808 - val_loss: 2594237243.2259\n",
      "Epoch 6647/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 376742322.0214 - val_loss: 2639146618.4776\n",
      "Epoch 6648/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 358598607.5318 - val_loss: 2446645498.4191\n",
      "Epoch 6649/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 317745031.7254 - val_loss: 2372468670.4698\n",
      "Epoch 6650/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 346530923.0929 - val_loss: 2649897269.3603\n",
      "Epoch 6651/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 391087871.6398 - val_loss: 2931985775.8695\n",
      "Epoch 6652/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 608798532.6100 - val_loss: 2728779195.1482\n",
      "Epoch 6653/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 453197077.6455 - val_loss: 2891646582.7353\n",
      "Epoch 6654/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 314691809.9989 - val_loss: 2716746080.3150\n",
      "Epoch 6655/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 665724025.1120 - val_loss: 2429353862.3004\n",
      "Epoch 6656/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 342634921.7873 - val_loss: 2510756270.2492\n",
      "Epoch 6657/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 486045314.8588 - val_loss: 2562038058.8827\n",
      "Epoch 6658/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 445403443.1784 - val_loss: 2661144958.3437\n",
      "Epoch 6659/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 373716985.4271 - val_loss: 2790090392.3353\n",
      "Epoch 6660/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 445876150.9871 - val_loss: 2396035668.2532\n",
      "Epoch 6661/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 410696814.2442 - val_loss: 2967842784.5806\n",
      "Epoch 6662/7000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 404490725.8165 - val_loss: 2476312546.5564\n",
      "Epoch 6663/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 406405293.3573 - val_loss: 2410403196.2532\n",
      "Epoch 6664/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 368306887.8875 - val_loss: 2566101014.0534\n",
      "Epoch 6665/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 433295997.2988 - val_loss: 2842369405.8532\n",
      "Epoch 6666/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 590690973.1728 - val_loss: 2672252824.0428\n",
      "Epoch 6667/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 509675324.2904 - val_loss: 3670633990.0309\n",
      "Epoch 6668/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 661634171.2459 - val_loss: 3577111372.7820\n",
      "Epoch 6669/7000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 627187989.137 - 0s 86us/step - loss: 625328914.7541 - val_loss: 2461728695.3046\n",
      "Epoch 6670/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 381152205.9741 - val_loss: 2368389476.3297\n",
      "Epoch 6671/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 328923687.4823 - val_loss: 2558223516.4309\n",
      "Epoch 6672/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 457718736.8554 - val_loss: 3324083570.1558\n",
      "Epoch 6673/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 533069047.9865 - val_loss: 2349717574.2875\n",
      "Epoch 6674/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 295572776.2802 - val_loss: 2705298379.8819\n",
      "Epoch 6675/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 347250809.9133 - val_loss: 2635488774.8861\n",
      "Epoch 6676/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 337079329.2065 - val_loss: 2978215702.6475\n",
      "Epoch 6677/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 676848195.5025 - val_loss: 2717504350.1322\n",
      "Epoch 6678/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 365492844.0293 - val_loss: 2556702259.7131\n",
      "Epoch 6679/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 345650271.0816 - val_loss: 5351752279.7817\n",
      "Epoch 6680/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 636893338.9848 - val_loss: 2587152047.4149\n",
      "Epoch 6681/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 270415260.8531 - val_loss: 2487064678.7331\n",
      "Epoch 6682/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 477283516.6483 - val_loss: 3093044476.6155\n",
      "Epoch 6683/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 496469334.5098 - val_loss: 2841583821.1916\n",
      "Epoch 6684/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 825155096.9364 - val_loss: 2391579334.3550\n",
      "Epoch 6685/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 347499191.0445 - val_loss: 2406859699.5241\n",
      "Epoch 6686/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 314083864.8239 - val_loss: 2429059610.7342\n",
      "Epoch 6687/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 326827499.2549 - val_loss: 2587075690.0996\n",
      "Epoch 6688/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 427101559.2842 - val_loss: 2973181556.8923\n",
      "Epoch 6689/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 80us/step - loss: 602859287.8424 - val_loss: 2469924319.9865\n",
      "Epoch 6690/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 601727662.5324 - val_loss: 2387287183.9865\n",
      "Epoch 6691/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 708479212.2183 - val_loss: 2685180088.8214\n",
      "Epoch 6692/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 363952491.8672 - val_loss: 2462338566.0264\n",
      "Epoch 6693/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 393598118.7530 - val_loss: 2394123026.8489\n",
      "Epoch 6694/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 353608957.3438 - val_loss: 2494903732.2779\n",
      "Epoch 6695/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 395995811.3382 - val_loss: 2465586340.6740\n",
      "Epoch 6696/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 367481846.7620 - val_loss: 2365464240.8596\n",
      "Epoch 6697/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 323283937.9989 - val_loss: 2747522435.1685\n",
      "Epoch 6698/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 464019380.3669 - val_loss: 2818877736.2003\n",
      "Epoch 6699/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 423269899.7591 - val_loss: 3548224889.3210\n",
      "Epoch 6700/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 600221814.3838 - val_loss: 3067605160.2138\n",
      "Epoch 6701/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 780204636.7046 - val_loss: 2354423824.8866\n",
      "Epoch 6702/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 363913016.4367 - val_loss: 2452015195.0633\n",
      "Epoch 6703/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 364789980.8036 - val_loss: 2321463135.7896\n",
      "Epoch 6704/7000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 404896885.3754 - val_loss: 2355541219.9381\n",
      "Epoch 6705/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 390316040.6978 - val_loss: 2463448100.3522\n",
      "Epoch 6706/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 355163511.0501 - val_loss: 2296024625.0127\n",
      "Epoch 6707/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 338007511.1941 - val_loss: 2361677334.3685\n",
      "Epoch 6708/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 339956127.6849 - val_loss: 2421383374.9446\n",
      "Epoch 6709/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 401530553.4091 - val_loss: 4629430153.0374\n",
      "Epoch 6710/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 500119544.4547 - val_loss: 3112349678.7353\n",
      "Epoch 6711/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 644873265.4001 - val_loss: 2415822296.1598\n",
      "Epoch 6712/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 394060825.2110 - val_loss: 2375366778.5451\n",
      "Epoch 6713/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 760010151.0771 - val_loss: 2732843864.3128\n",
      "Epoch 6714/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 393455712.6708 - val_loss: 2546935632.8686\n",
      "Epoch 6715/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 342268417.4406 - val_loss: 2498767059.6861\n",
      "Epoch 6716/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 388946063.4147 - val_loss: 3704079329.1792\n",
      "Epoch 6717/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 685701982.9555 - val_loss: 2408009481.8813\n",
      "Epoch 6718/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 482047605.3438 - val_loss: 3313856580.8428\n",
      "Epoch 6719/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 451132606.3613 - val_loss: 2884459416.9722\n",
      "Epoch 6720/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 502955062.0439 - val_loss: 3158578701.2501\n",
      "Epoch 6721/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 559337672.5177 - val_loss: 2779046856.7122\n",
      "Epoch 6722/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 415221541.9606 - val_loss: 2610379736.8146\n",
      "Epoch 6723/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 450874053.4834 - val_loss: 2541693413.9617\n",
      "Epoch 6724/7000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 465188854.6629 - val_loss: 2423639332.3297\n",
      "Epoch 6725/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 312528033.4811 - val_loss: 2694706344.5018\n",
      "Epoch 6726/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 541988979.1604 - val_loss: 2939885467.0560\n",
      "Epoch 6727/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 648709866.9938 - val_loss: 2347774178.2391\n",
      "Epoch 6728/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 334549099.4350 - val_loss: 2576204706.6014\n",
      "Epoch 6729/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 393430754.8948 - val_loss: 2516963055.1097\n",
      "Epoch 6730/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 421684580.1598 - val_loss: 4152124678.0669\n",
      "Epoch 6731/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 800258660.6640 - val_loss: 2283990314.8107\n",
      "Epoch 6732/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 329365601.1795 - val_loss: 2325508864.3421\n",
      "Epoch 6733/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 348100409.5892 - val_loss: 2514915445.9949\n",
      "Epoch 6734/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 394416952.5447 - val_loss: 3194726872.7989\n",
      "Epoch 6735/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 505994519.4823 - val_loss: 3081918611.7761\n",
      "Epoch 6736/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 382728115.8177 - val_loss: 2330545280.7308\n",
      "Epoch 6737/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 329854778.4176 - val_loss: 3764232605.3626\n",
      "Epoch 6738/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1034624346.6156 - val_loss: 3168279274.5406\n",
      "Epoch 6739/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 482304141.2538 - val_loss: 2824452781.8695\n",
      "Epoch 6740/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 395923629.4519 - val_loss: 2563574489.8700\n",
      "Epoch 6741/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 351583794.3860 - val_loss: 2337343356.9755\n",
      "Epoch 6742/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 409088710.7169 - val_loss: 2733822480.5671\n",
      "Epoch 6743/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 376865397.4564 - val_loss: 3144141229.8802\n",
      "Epoch 6744/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 452826180.3759 - val_loss: 3408542718.1997\n",
      "Epoch 6745/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 443312300.2634 - val_loss: 2273654752.2115\n",
      "Epoch 6746/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 361672805.2763 - val_loss: 2835309381.1781\n",
      "Epoch 6747/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 443655168.0000 - val_loss: 2307310239.2259\n",
      "Epoch 6748/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 338810790.2127 - val_loss: 2441658089.1477\n",
      "Epoch 6749/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 354328363.3360 - val_loss: 2444347674.5767\n",
      "Epoch 6750/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 470335050.5706 - val_loss: 4079142730.1716\n",
      "Epoch 6751/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 744978507.1199 - val_loss: 2857553323.6838\n",
      "Epoch 6752/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 695785987.4350 - val_loss: 2439472219.5353\n",
      "Epoch 6753/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 362697942.2938 - val_loss: 2711488451.5286\n",
      "Epoch 6754/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 72us/step - loss: 412532480.1441 - val_loss: 2339014664.2453\n",
      "Epoch 6755/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 372034052.4980 - val_loss: 2451426756.8698\n",
      "Epoch 6756/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 305826499.6376 - val_loss: 2596369746.7544\n",
      "Epoch 6757/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 388947488.1261 - val_loss: 2724071317.5134\n",
      "Epoch 6758/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 472366862.5144 - val_loss: 2917305334.7826\n",
      "Epoch 6759/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 408495860.4373 - val_loss: 2660650786.3179\n",
      "Epoch 6760/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 318881156.5740 - val_loss: 4311404436.2712\n",
      "Epoch 6761/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 808710732.8711 - val_loss: 2651279102.5598\n",
      "Epoch 6762/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 318731292.8126 - val_loss: 3639407157.4504\n",
      "Epoch 6763/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 627604830.4333 - val_loss: 2382477700.3117\n",
      "Epoch 6764/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 330412959.3697 - val_loss: 2737155944.0203\n",
      "Epoch 6765/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 337065827.6016 - val_loss: 2375491886.1592\n",
      "Epoch 6766/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 353151104.1396 - val_loss: 2570227753.1432\n",
      "Epoch 6767/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 323849033.9764 - val_loss: 2548012754.2008\n",
      "Epoch 6768/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 532265513.4902 - val_loss: 2885729089.5122\n",
      "Epoch 6769/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 633614502.9600 - val_loss: 2410572473.3207\n",
      "Epoch 6770/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 442341058.1429 - val_loss: 4477292128.4591\n",
      "Epoch 6771/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 616557550.5189 - val_loss: 2545648844.8113\n",
      "Epoch 6772/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 325958175.8739 - val_loss: 2504590107.3013\n",
      "Epoch 6773/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 397946084.1193 - val_loss: 2430442498.6655\n",
      "Epoch 6774/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 343735712.5312 - val_loss: 2749553307.3643\n",
      "Epoch 6775/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 330196817.6747 - val_loss: 2715959879.7277\n",
      "Epoch 6776/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 488798024.4277 - val_loss: 2796991194.3741\n",
      "Epoch 6777/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 461089276.3264 - val_loss: 2431342222.7803\n",
      "Epoch 6778/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 441221254.9690 - val_loss: 4935444907.6748\n",
      "Epoch 6779/7000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 488887441.9809 - val_loss: 2652624127.8256\n",
      "Epoch 6780/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 436838639.4958 - val_loss: 2908640034.2323\n",
      "Epoch 6781/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 383139005.6950 - val_loss: 2363138616.8124\n",
      "Epoch 6782/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 318207116.6415 - val_loss: 2534187367.5567\n",
      "Epoch 6783/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 348881524.9972 - val_loss: 2356183707.7513\n",
      "Epoch 6784/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 373488515.5476 - val_loss: 2665418492.3274\n",
      "Epoch 6785/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 348266831.8829 - val_loss: 2984880323.6006\n",
      "Epoch 6786/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 508242926.6044 - val_loss: 2383761061.1572\n",
      "Epoch 6787/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 522657232.6033 - val_loss: 3523871260.2104\n",
      "Epoch 6788/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 430246191.5408 - val_loss: 3368388657.5437\n",
      "Epoch 6789/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 636187794.1159 - val_loss: 3307004336.6436\n",
      "Epoch 6790/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 432424085.7895 - val_loss: 2934715157.6934\n",
      "Epoch 6791/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 474759585.0084 - val_loss: 2534554768.7404\n",
      "Epoch 6792/7000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 461713304.2414 - val_loss: 2569729647.7840\n",
      "Epoch 6793/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 360748853.6671 - val_loss: 2348435434.6127\n",
      "Epoch 6794/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 380990868.5470 - val_loss: 2475419899.9989\n",
      "Epoch 6795/7000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 340472217.142 - 0s 85us/step - loss: 440388643.7276 - val_loss: 3110863118.1142\n",
      "Epoch 6796/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 550165320.4277 - val_loss: 2674089746.3224\n",
      "Epoch 6797/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 410657612.7496 - val_loss: 3887571695.0774\n",
      "Epoch 6798/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 546434636.6235 - val_loss: 2990486936.5828\n",
      "Epoch 6799/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 417260698.8137 - val_loss: 2523912929.0262\n",
      "Epoch 6800/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 504992282.5481 - val_loss: 2913028761.1499\n",
      "Epoch 6801/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 526557328.4952 - val_loss: 2693850371.9651\n",
      "Epoch 6802/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 386413092.3039 - val_loss: 2752219134.8478\n",
      "Epoch 6803/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 426407951.1986 - val_loss: 11366374385.5257\n",
      "Epoch 6804/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 986746415.0366 - val_loss: 4516434108.1474\n",
      "Epoch 6805/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 614459316.1564 - val_loss: 2312142035.1989\n",
      "Epoch 6806/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 314804621.3258 - val_loss: 2644255241.2354\n",
      "Epoch 6807/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 286771802.8407 - val_loss: 2356641414.5170\n",
      "Epoch 6808/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 352330233.3011 - val_loss: 2328224955.7761\n",
      "Epoch 6809/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 547193177.2245 - val_loss: 2979229892.0146\n",
      "Epoch 6810/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 380812941.9201 - val_loss: 2877541888.0720\n",
      "Epoch 6811/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 367875812.3444 - val_loss: 2285266453.7384\n",
      "Epoch 6812/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 352920638.2172 - val_loss: 2375629483.7896\n",
      "Epoch 6813/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 304712569.5937 - val_loss: 2305647041.2647\n",
      "Epoch 6814/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 278072113.7017 - val_loss: 2405796701.1049\n",
      "Epoch 6815/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 388736629.6590 - val_loss: 2861971239.2191\n",
      "Epoch 6816/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 413759741.5692 - val_loss: 2490610514.5800\n",
      "Epoch 6817/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 333943914.6292 - val_loss: 2374231154.1198\n",
      "Epoch 6818/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 412148799.5138 - val_loss: 2624422864.7606\n",
      "Epoch 6819/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 74us/step - loss: 342055131.3360 - val_loss: 3290562811.3913\n",
      "Epoch 6820/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 540793182.8655 - val_loss: 2783693428.1902\n",
      "Epoch 6821/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 707685333.2043 - val_loss: 2352650253.9882\n",
      "Epoch 6822/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 423217599.9280 - val_loss: 2785260799.7300\n",
      "Epoch 6823/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 434018415.8649 - val_loss: 2649040836.1226\n",
      "Epoch 6824/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 433490611.1424 - val_loss: 2476334215.7997\n",
      "Epoch 6825/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 293844538.2465 - val_loss: 2333962134.9086\n",
      "Epoch 6826/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 331294649.7062 - val_loss: 2873743516.3364\n",
      "Epoch 6827/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 374760611.7209 - val_loss: 2402622375.1139\n",
      "Epoch 6828/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 408596069.7085 - val_loss: 3290654824.8124\n",
      "Epoch 6829/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1016470190.6044 - val_loss: 4357771169.5212\n",
      "Epoch 6830/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 568034449.7198 - val_loss: 2310081170.8782\n",
      "Epoch 6831/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 279471508.2228 - val_loss: 2495013257.0554\n",
      "Epoch 6832/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 422104787.0073 - val_loss: 2361943480.1283\n",
      "Epoch 6833/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 394338390.1767 - val_loss: 2570379590.2785\n",
      "Epoch 6834/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 432924649.9223 - val_loss: 2968672899.4205\n",
      "Epoch 6835/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 407935884.3174 - val_loss: 2637248732.6650\n",
      "Epoch 6836/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 580515202.8497 - val_loss: 2459222809.7688\n",
      "Epoch 6837/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 401672700.9747 - val_loss: 2732586817.5122\n",
      "Epoch 6838/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 508153447.3292 - val_loss: 5221809323.9269\n",
      "Epoch 6839/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 494142586.3950 - val_loss: 2327455347.4700\n",
      "Epoch 6840/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 301374819.3315 - val_loss: 2494180828.2239\n",
      "Epoch 6841/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 283913963.7051 - val_loss: 3692357509.6889\n",
      "Epoch 6842/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 443725294.7124 - val_loss: 2607521405.8937\n",
      "Epoch 6843/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 360253898.9128 - val_loss: 2452229466.9682\n",
      "Epoch 6844/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 413171501.0917 - val_loss: 7289958560.5851\n",
      "Epoch 6845/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 1776177448.6258 - val_loss: 5267541439.6579\n",
      "Epoch 6846/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 495260728.7608 - val_loss: 2700166654.2807\n",
      "Epoch 6847/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 304380180.4209 - val_loss: 2681953006.7893\n",
      "Epoch 6848/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 415988493.0827 - val_loss: 2610733162.5587\n",
      "Epoch 6849/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 384155925.4654 - val_loss: 2513576950.8613\n",
      "Epoch 6850/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 350214797.4339 - val_loss: 2413707513.6000\n",
      "Epoch 6851/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 353095108.3579 - val_loss: 2434438811.5533\n",
      "Epoch 6852/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 431243883.3990 - val_loss: 2420750770.7139\n",
      "Epoch 6853/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 470817761.1885 - val_loss: 5671979565.0790\n",
      "Epoch 6854/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 608186474.9308 - val_loss: 2523100392.7314\n",
      "Epoch 6855/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 294225703.0951 - val_loss: 2843058301.9387\n",
      "Epoch 6856/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 429582722.3050 - val_loss: 2470149283.6096\n",
      "Epoch 6857/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 334012814.7980 - val_loss: 2314754383.1533\n",
      "Epoch 6858/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 329494651.8942 - val_loss: 5614243542.3415\n",
      "Epoch 6859/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1216552549.5104 - val_loss: 2995438641.1522\n",
      "Epoch 6860/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 473960232.6258 - val_loss: 3162067143.4532\n",
      "Epoch 6861/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 356799001.9043 - val_loss: 2837400660.2532\n",
      "Epoch 6862/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 336964617.2921 - val_loss: 2664268685.9972\n",
      "Epoch 6863/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 535363919.0906 - val_loss: 2788026954.4821\n",
      "Epoch 6864/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 348810428.8666 - val_loss: 3229306712.2228\n",
      "Epoch 6865/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 347869721.0039 - val_loss: 2353165150.1333\n",
      "Epoch 6866/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 317252621.2898 - val_loss: 2626017135.5094\n",
      "Epoch 6867/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 652906483.1739 - val_loss: 2978157426.9660\n",
      "Epoch 6868/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 341896284.8070 - val_loss: 3349218751.3159\n",
      "Epoch 6869/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 328415865.4091 - val_loss: 2306063032.4883\n",
      "Epoch 6870/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 434567866.2735 - val_loss: 2709619605.1443\n",
      "Epoch 6871/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 459052600.4367 - val_loss: 2618023113.5820\n",
      "Epoch 6872/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 371041305.8593 - val_loss: 2924343534.8208\n",
      "Epoch 6873/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 358670540.2814 - val_loss: 2575688955.7513\n",
      "Epoch 6874/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 521193295.8109 - val_loss: 2802001068.3094\n",
      "Epoch 6875/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 858523279.7029 - val_loss: 3340921781.0363\n",
      "Epoch 6876/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 749788710.6449 - val_loss: 2332946201.7260\n",
      "Epoch 6877/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 356596937.4001 - val_loss: 2602634109.3350\n",
      "Epoch 6878/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 592038887.3551 - val_loss: 2400221414.8096\n",
      "Epoch 6879/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 292590083.4665 - val_loss: 2270636305.2017\n",
      "Epoch 6880/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 459306954.8407 - val_loss: 2962243116.3409\n",
      "Epoch 6881/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 344475938.9038 - val_loss: 2265027076.8489\n",
      "Epoch 6882/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 335385740.6505 - val_loss: 2858234790.1210\n",
      "Epoch 6883/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 338386340.2206 - val_loss: 2368254383.4982\n",
      "Epoch 6884/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 76us/step - loss: 345360657.7783 - val_loss: 3314796743.7052\n",
      "Epoch 6885/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 399998941.5959 - val_loss: 3290146275.3305\n",
      "Epoch 6886/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 382455339.1289 - val_loss: 2406921101.4560\n",
      "Epoch 6887/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 398395400.0675 - val_loss: 2308494148.4602\n",
      "Epoch 6888/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 316506378.7507 - val_loss: 3762486042.3021\n",
      "Epoch 6889/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 551893723.6601 - val_loss: 2919288230.1120\n",
      "Epoch 6890/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 746162672.1216 - val_loss: 2696095191.2416\n",
      "Epoch 6891/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 398682354.7462 - val_loss: 2627324102.1885\n",
      "Epoch 6892/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 374727495.7074 - val_loss: 2266570373.9207\n",
      "Epoch 6893/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 357528998.0867 - val_loss: 2435752887.2596\n",
      "Epoch 6894/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 309531846.9088 - val_loss: 2302400044.1789\n",
      "Epoch 6895/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 325279855.1806 - val_loss: 2656859423.0211\n",
      "Epoch 6896/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 486237753.3281 - val_loss: 2544824012.6875\n",
      "Epoch 6897/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 424079747.6556 - val_loss: 2295750710.9626\n",
      "Epoch 6898/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 360878401.6207 - val_loss: 2606073161.2714\n",
      "Epoch 6899/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 525111917.5779 - val_loss: 2583934617.6990\n",
      "Epoch 6900/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 402430995.5926 - val_loss: 2931200962.6689\n",
      "Epoch 6901/7000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 510763382.7710 - val_loss: 2618173231.8605\n",
      "Epoch 6902/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 344742815.0456 - val_loss: 2284798556.2025\n",
      "Epoch 6903/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 537676208.5425 - val_loss: 2897209219.0245\n",
      "Epoch 6904/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 506263717.8886 - val_loss: 2384149756.0304\n",
      "Epoch 6905/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 305997371.4620 - val_loss: 2642051361.2512\n",
      "Epoch 6906/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 443774979.8177 - val_loss: 2471708753.2489\n",
      "Epoch 6907/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 367284211.0163 - val_loss: 2638760023.3181\n",
      "Epoch 6908/7000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 314268666.4536 - val_loss: 2404782513.7328\n",
      "Epoch 6909/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 867157066.7237 - val_loss: 2540013009.5077\n",
      "Epoch 6910/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 376078628.8801 - val_loss: 2709106435.7806\n",
      "Epoch 6911/7000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 270659606.7394 - val_loss: 2348390055.9449\n",
      "Epoch 6912/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 339957543.4373 - val_loss: 2312575951.8065\n",
      "Epoch 6913/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 712605954.8272 - val_loss: 2604447569.6968\n",
      "Epoch 6914/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 371850673.8458 - val_loss: 2402021844.9103\n",
      "Epoch 6915/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 363307337.0940 - val_loss: 2710052788.3567\n",
      "Epoch 6916/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 507326110.6764 - val_loss: 4130668966.7060\n",
      "Epoch 6917/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 684746888.1080 - val_loss: 2548207032.3235\n",
      "Epoch 6918/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 404454619.0219 - val_loss: 2678186357.8464\n",
      "Epoch 6919/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 373802204.3084 - val_loss: 2781469759.8020\n",
      "Epoch 6920/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 391701418.7530 - val_loss: 2367495865.4717\n",
      "Epoch 6921/7000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 324877557.0242 - val_loss: 3077511127.1876\n",
      "Epoch 6922/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 337648940.4434 - val_loss: 2485450384.8113\n",
      "Epoch 6923/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 364440478.4243 - val_loss: 2760975895.8537\n",
      "Epoch 6924/7000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 340797448.2656 - val_loss: 2400980414.4878\n",
      "Epoch 6925/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 488976191.7659 - val_loss: 2708461763.5826\n",
      "Epoch 6926/7000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 594888193.9989 - val_loss: 2369891445.9004\n",
      "Epoch 6927/7000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 378806978.7012 - val_loss: 4655395623.6017\n",
      "Epoch 6928/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 793958856.2183 - val_loss: 2397663095.3857\n",
      "Epoch 6929/7000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 449763871.8739 - val_loss: 2288854235.9606\n",
      "Epoch 6930/7000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 291238331.7141 - val_loss: 3727818247.1291\n",
      "Epoch 6931/7000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 542169598.4153 - val_loss: 4331331940.5277\n",
      "Epoch 6932/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 520548506.9387 - val_loss: 2408898320.7606\n",
      "Epoch 6933/7000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 288737351.6624 - val_loss: 2388466194.5969\n",
      "Epoch 6934/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 297093797.3866 - val_loss: 2447320136.3353\n",
      "Epoch 6935/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 410161870.4063 - val_loss: 2484673971.1550\n",
      "Epoch 6936/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 633198052.5200 - val_loss: 2448926151.6872\n",
      "Epoch 6937/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 388437256.4997 - val_loss: 2687261116.6335\n",
      "Epoch 6938/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 369963770.4176 - val_loss: 2786750434.7994\n",
      "Epoch 6939/7000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 400515059.0253 - val_loss: 3355609559.2056\n",
      "Epoch 6940/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 435110898.5301 - val_loss: 2979133924.7212\n",
      "Epoch 6941/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 416433952.3244 - val_loss: 2396539579.7603\n",
      "Epoch 6942/7000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 348131445.0422 - val_loss: 3101794575.3384\n",
      "Epoch 6943/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 544931577.0129 - val_loss: 3620000692.5232\n",
      "Epoch 6944/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 624521314.1857 - val_loss: 2383939245.2675\n",
      "Epoch 6945/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 559997710.2082 - val_loss: 2607550001.6518\n",
      "Epoch 6946/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 378092433.4316 - val_loss: 2585019035.1662\n",
      "Epoch 6947/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 381692628.3489 - val_loss: 2307386674.9930\n",
      "Epoch 6948/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 337044555.9932 - val_loss: 3613901517.5201\n",
      "Epoch 6949/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 88us/step - loss: 828455016.8869 - val_loss: 2521843864.8034\n",
      "Epoch 6950/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 360221775.3517 - val_loss: 2522268438.2065\n",
      "Epoch 6951/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 387630863.4747 - val_loss: 2438605329.9022\n",
      "Epoch 6952/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 327134715.8402 - val_loss: 3232091906.3944\n",
      "Epoch 6953/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 749067738.9758 - val_loss: 2807438672.0326\n",
      "Epoch 6954/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 425544993.8548 - val_loss: 2953441092.1941\n",
      "Epoch 6955/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 460152725.9066 - val_loss: 2348631454.5778\n",
      "Epoch 6956/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 389002633.2200 - val_loss: 2371419638.3781\n",
      "Epoch 6957/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 408414341.4710 - val_loss: 2283763088.3747\n",
      "Epoch 6958/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 394223956.7136 - val_loss: 2418354367.2079\n",
      "Epoch 6959/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 305220822.5459 - val_loss: 2304816338.0906\n",
      "Epoch 6960/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 353332984.1306 - val_loss: 2592342249.8909\n",
      "Epoch 6961/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 422690736.9094 - val_loss: 2889054970.9952\n",
      "Epoch 6962/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 455555570.6201 - val_loss: 2453466770.9750\n",
      "Epoch 6963/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 462861426.9443 - val_loss: 2392964606.1997\n",
      "Epoch 6964/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 407245421.0917 - val_loss: 2757426264.2318\n",
      "Epoch 6965/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 455791164.1553 - val_loss: 2555713563.1887\n",
      "Epoch 6966/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 349369412.0158 - val_loss: 2480532836.6357\n",
      "Epoch 6967/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 344998334.4153 - val_loss: 2517495374.0422\n",
      "Epoch 6968/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 508755523.5115 - val_loss: 2317820837.5044\n",
      "Epoch 6969/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 343402719.9460 - val_loss: 2574939785.0869\n",
      "Epoch 6970/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 417198115.7817 - val_loss: 2676096703.4419\n",
      "Epoch 6971/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 547270275.8177 - val_loss: 2379974855.3181\n",
      "Epoch 6972/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 393619820.2724 - val_loss: 2506968668.7775\n",
      "Epoch 6973/7000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 998947150.5234 - val_loss: 2673273001.4290\n",
      "Epoch 6974/7000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 404384475.3089 - val_loss: 3320649250.3111\n",
      "Epoch 6975/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 327804215.2482 - val_loss: 2517878170.3966\n",
      "Epoch 6976/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 374942535.8875 - val_loss: 5327588872.6774\n",
      "Epoch 6977/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 748171076.0113 - val_loss: 2401021168.2610\n",
      "Epoch 6978/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 279775599.9190 - val_loss: 2286645644.7190\n",
      "Epoch 6979/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 545667876.4254 - val_loss: 2829347969.5842\n",
      "Epoch 6980/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 341004897.0467 - val_loss: 2342502819.2810\n",
      "Epoch 6981/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 350331709.5431 - val_loss: 2326510253.3761\n",
      "Epoch 6982/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 323092998.9150 - val_loss: 2746743772.1564\n",
      "Epoch 6983/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 386802145.5307 - val_loss: 5122405362.4619\n",
      "Epoch 6984/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 408111057.5127 - val_loss: 2605140317.3198\n",
      "Epoch 6985/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 364624806.0957 - val_loss: 2370179690.7589\n",
      "Epoch 6986/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 332836671.6759 - val_loss: 2806322297.5730\n",
      "Epoch 6987/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 414302706.7552 - val_loss: 2522591718.0399\n",
      "Epoch 6988/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 326892359.8875 - val_loss: 2493102448.5176\n",
      "Epoch 6989/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 430935055.8244 - val_loss: 2363305410.7904\n",
      "Epoch 6990/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 446484349.8391 - val_loss: 2538510200.2447\n",
      "Epoch 6991/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 473302317.4564 - val_loss: 2506764466.1378\n",
      "Epoch 6992/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 330516942.7304 - val_loss: 3199108019.9921\n",
      "Epoch 6993/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 581554547.1064 - val_loss: 3801011495.0211\n",
      "Epoch 6994/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 565247252.4569 - val_loss: 2583817773.0700\n",
      "Epoch 6995/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 387686192.3331 - val_loss: 2309604423.9302\n",
      "Epoch 6996/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 370105251.4176 - val_loss: 2837752947.1977\n",
      "Epoch 6997/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 466762391.6669 - val_loss: 2387239707.2281\n",
      "Epoch 6998/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 318069421.0917 - val_loss: 4748772159.0098\n",
      "Epoch 6999/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 490059366.7530 - val_loss: 3043324180.2712\n",
      "Epoch 7000/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 436708137.8863 - val_loss: 2491479299.9966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe839dd518>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile model\n",
    "model22.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(\"model22 loss:\",model22.loss)\n",
    "\n",
    "model_train22 = model22.fit(predictors,target, epochs=7000, validation_split=0.5, callbacks=[early_stopping_monitor], verbose=True)\n",
    "model_train22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbe83071160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the plot\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(model_train22.history['val_loss'], 'r',\n",
    "         )\n",
    "plt.title(\"Adam only\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.savefig(\"Adam graph for 7000 epochs with 150 callbacks\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model22.save(\"adam_7000_epochs_only_with _150_callbacks.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
