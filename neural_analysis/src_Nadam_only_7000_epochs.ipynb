{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the less hidden layes didn't work out as per the graph above so using more hidden layers\n",
    "#as per above diagram using only adam and nadam\n",
    "#importing pandas to visualise the dataset in tabular format\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#introducing stable analysis through random seed\n",
    "np.random.seed(42)\n",
    "#importing time function to create animated behaviour\n",
    "import time\n",
    "#importing regExp for data cleaning\n",
    "import re\n",
    "from numpy import NaN\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/scaled_train.csv\")\n",
    "test = pd.read_csv(\"../data/scaled_test.csv\")\n",
    "\n",
    "X_train = df.drop(['PRT_ID','SALES_PRICE'],axis=1)\n",
    "y_train = df['SALES_PRICE']\n",
    "\n",
    "X_test = test.drop(['PRT_ID'],axis=1)\n",
    "\n",
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Specify the model\n",
    "predictors = X_train.values\n",
    "target = y_train.values.reshape((-1,1)).astype('int32')\n",
    "\n",
    "n_cols = predictors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model 2\n",
    "model22 = Sequential()\n",
    "model22.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "model22.add(Dense(70, kernel_initializer='normal', activation='relu'))\n",
    "model22.add(Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "model22.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model22.add(Dense(1, kernel_initializer='normal'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model22 loss: mean_squared_error\n",
      "Train on 3554 samples, validate on 3555 samples\n",
      "Epoch 1/7000\n",
      "3554/3554 [==============================] - 1s 240us/step - loss: 129560768089593.3750 - val_loss: 104503276478457.0938\n",
      "Epoch 2/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 34642810017014.0625 - val_loss: 7263557694508.0713\n",
      "Epoch 3/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 6683045662164.4932 - val_loss: 5938049882208.2070\n",
      "Epoch 4/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 5562734086382.5684 - val_loss: 5208254253496.7090\n",
      "Epoch 5/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 4897672463133.5332 - val_loss: 4755172055279.0771\n",
      "Epoch 6/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 4479655167307.3447 - val_loss: 4465717300345.8428\n",
      "Epoch 7/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 4178046849224.5361 - val_loss: 4228401996322.1333\n",
      "Epoch 8/7000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 3949436754183.9233 - val_loss: 4111502587808.9453\n",
      "Epoch 9/7000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 3786013217060.7363 - val_loss: 3971191618224.4277\n",
      "Epoch 10/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 3634974740929.4766 - val_loss: 3776450195146.0635\n",
      "Epoch 11/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 3509249847916.0474 - val_loss: 3700035999383.9438\n",
      "Epoch 12/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 3394904986409.0581 - val_loss: 3653787693552.5894\n",
      "Epoch 13/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 3289718234227.8267 - val_loss: 3465556979438.9331\n",
      "Epoch 14/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 3183651142711.8965 - val_loss: 3377695647500.3140\n",
      "Epoch 15/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 3078938431522.5752 - val_loss: 3316276376527.8965\n",
      "Epoch 16/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2986538920787.7007 - val_loss: 3204654455262.7310\n",
      "Epoch 17/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 2884151748436.2769 - val_loss: 3051919374798.6001\n",
      "Epoch 18/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2798112646945.5669 - val_loss: 2971001749448.6953\n",
      "Epoch 19/7000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 2709683298603.6514 - val_loss: 2926833674793.6226\n",
      "Epoch 20/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2620120238908.6509 - val_loss: 2763022872399.7163\n",
      "Epoch 21/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2528875251065.4453 - val_loss: 2678155025623.1694\n",
      "Epoch 22/7000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 2453724125202.789 - 0s 85us/step - loss: 2447784989490.2783 - val_loss: 2583607691165.4888\n",
      "Epoch 23/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 2370108741195.2007 - val_loss: 2581725407910.0581\n",
      "Epoch 24/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 2298928679381.0693 - val_loss: 2515349199114.7295\n",
      "Epoch 25/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 2222907152316.0024 - val_loss: 2577557441528.7988\n",
      "Epoch 26/7000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 2164227527900.7043 - val_loss: 2295014345803.7559\n",
      "Epoch 27/7000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 2090704486916.3220 - val_loss: 2242337882254.8701\n",
      "Epoch 28/7000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 2021541240928.8105 - val_loss: 2344091556231.1650\n",
      "Epoch 29/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1973809427070.4873 - val_loss: 2077998074301.3176\n",
      "Epoch 30/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1914535239260.4885 - val_loss: 2207574197274.7881\n",
      "Epoch 31/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1865328343326.9736 - val_loss: 1953081401834.8286\n",
      "Epoch 32/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1816169428227.8896 - val_loss: 1902156056113.3997\n",
      "Epoch 33/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1762008748813.3979 - val_loss: 1867410240173.5471\n",
      "Epoch 34/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1720699278019.6375 - val_loss: 1801569534053.3918\n",
      "Epoch 35/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1673027543265.8909 - val_loss: 1752444443227.1663\n",
      "Epoch 36/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1626741694450.1699 - val_loss: 1701321435509.8823\n",
      "Epoch 37/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1589071616033.4226 - val_loss: 1659208109717.0632\n",
      "Epoch 38/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1545003512335.8469 - val_loss: 1617883399204.0056\n",
      "Epoch 39/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1505303066385.4316 - val_loss: 1731745360932.5818\n",
      "Epoch 40/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1475401192177.7375 - val_loss: 1532505062050.6013\n",
      "Epoch 41/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1431120955086.5864 - val_loss: 1805020006813.0566\n",
      "Epoch 42/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1407633899197.2988 - val_loss: 1561332735103.6040\n",
      "Epoch 43/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1370532685809.0173 - val_loss: 1458759361615.7886\n",
      "Epoch 44/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1330894716568.4187 - val_loss: 1513166795068.8496\n",
      "Epoch 45/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1306878243242.4265 - val_loss: 1375032868541.3896\n",
      "Epoch 46/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1270462819201.8008 - val_loss: 1346006267827.3801\n",
      "Epoch 47/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1248664718102.1135 - val_loss: 1309679794504.9475\n",
      "Epoch 48/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1221671671795.3225 - val_loss: 1312845903039.5500\n",
      "Epoch 49/7000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1200246672160.9905 - val_loss: 1261211564941.6462\n",
      "Epoch 50/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1177384255612.4705 - val_loss: 1237766230653.1555\n",
      "Epoch 51/7000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1157159826341.5283 - val_loss: 1356201640373.8284\n",
      "Epoch 52/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1142446852758.6899 - val_loss: 1221808312063.0640\n",
      "Epoch 53/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1119943746576.2791 - val_loss: 1184693416805.8960\n",
      "Epoch 54/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1102326074467.6917 - val_loss: 1353346816667.6882\n",
      "Epoch 55/7000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1089098547163.1198 - val_loss: 1176172064467.2810\n",
      "Epoch 56/7000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1075821293634.8452 - val_loss: 1142599583613.2275\n",
      "Epoch 57/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1061172581502.1992 - val_loss: 1176154451266.3223\n",
      "Epoch 58/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1056051230887.1130 - val_loss: 1117961596217.1050\n",
      "Epoch 59/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1042721981162.8228 - val_loss: 1106941493354.0005\n",
      "Epoch 60/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1031545550093.1096 - val_loss: 1156713119771.6523\n",
      "Epoch 61/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1023189389162.1744 - val_loss: 1100065151468.5569\n",
      "Epoch 62/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1016647467588.8621 - val_loss: 1121123887588.4917\n",
      "Epoch 63/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 87us/step - loss: 1007718974574.0641 - val_loss: 1082739375035.7333\n",
      "Epoch 64/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1001503952063.8920 - val_loss: 1063941865038.7803\n",
      "Epoch 65/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 992522197606.2848 - val_loss: 1107899832826.3831\n",
      "Epoch 66/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 987481204038.7350 - val_loss: 1061617268756.1632\n",
      "Epoch 67/7000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 983097679696.8193 - val_loss: 1066691608488.4343\n",
      "Epoch 68/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 976902472906.2645 - val_loss: 1049611699715.3125\n",
      "Epoch 69/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 971682612085.1232 - val_loss: 1113218216123.8054\n",
      "Epoch 70/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 970149589326.2262 - val_loss: 1031505288499.3440\n",
      "Epoch 71/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 964694091115.6150 - val_loss: 1028930277409.4132\n",
      "Epoch 72/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 960964741607.5093 - val_loss: 1072228243957.7744\n",
      "Epoch 73/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 957071740529.2335 - val_loss: 1115108209030.5891\n",
      "Epoch 74/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 958588680598.8340 - val_loss: 1021878619442.1919\n",
      "Epoch 75/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 951025402446.0822 - val_loss: 1031635991617.3862\n",
      "Epoch 76/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 950796434478.6765 - val_loss: 1009528391728.9677\n",
      "Epoch 77/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 946476650180.2139 - val_loss: 1009908814917.4188\n",
      "Epoch 78/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 941778615905.0984 - val_loss: 1074673593057.9713\n",
      "Epoch 79/7000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 942145900744.5358 - val_loss: 1021677869566.9918\n",
      "Epoch 80/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 937502005659.4441 - val_loss: 1002795155064.2588\n",
      "Epoch 81/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 934525244920.2206 - val_loss: 1044544945088.3420\n",
      "Epoch 82/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 936745375205.7805 - val_loss: 1002202292111.0863\n",
      "Epoch 83/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 933075132909.2719 - val_loss: 994759217461.9364\n",
      "Epoch 84/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 925072146727.0410 - val_loss: 994828183418.9232\n",
      "Epoch 85/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 926135560315.3179 - val_loss: 1036416503099.4093\n",
      "Epoch 86/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 927611492846.4243 - val_loss: 993533009332.3882\n",
      "Epoch 87/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 923414266206.3612 - val_loss: 985887765727.8109\n",
      "Epoch 88/7000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 918209089837.9562 - val_loss: 983034992385.9443\n",
      "Epoch 89/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 921880881690.2195 - val_loss: 1030660042704.7606\n",
      "Epoch 90/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 916943924107.0208 - val_loss: 1132407932184.2678\n",
      "Epoch 91/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 923144827186.5660 - val_loss: 993989241468.5795\n",
      "Epoch 92/7000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 911921894747.4800 - val_loss: 1072216793389.8712\n",
      "Epoch 93/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 915516693555.2864 - val_loss: 996516469680.2115\n",
      "Epoch 94/7000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 909966119038.7754 - val_loss: 971377424040.0742\n",
      "Epoch 95/7000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 908572188621.2898 - val_loss: 968415379234.7815\n",
      "Epoch 96/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 908532202293.7355 - val_loss: 976888295362.9344\n",
      "Epoch 97/7000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 906425079085.3799 - val_loss: 1007943809818.4281\n",
      "Epoch 98/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 905147788134.1407 - val_loss: 1011460300871.4352\n",
      "Epoch 99/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 904434484527.6849 - val_loss: 969054179624.1102\n",
      "Epoch 100/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 897785902137.0490 - val_loss: 964791000440.4749\n",
      "Epoch 101/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 899425658072.0945 - val_loss: 960011686930.7229\n",
      "Epoch 102/7000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 896915324679.0591 - val_loss: 960325566394.8691\n",
      "Epoch 103/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 894537164840.3376 - val_loss: 958885195908.5007\n",
      "Epoch 104/7000\n",
      "3554/3554 [==============================] - 0s 132us/step - loss: 895765716286.6675 - val_loss: 1001306130356.5322\n",
      "Epoch 105/7000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 895947305109.8256 - val_loss: 978716196458.4326\n",
      "Epoch 106/7000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 896613408514.4491 - val_loss: 1007710663664.1575\n",
      "Epoch 107/7000\n",
      "3554/3554 [==============================] - 1s 165us/step - loss: 892351404425.0039 - val_loss: 955240705986.9344\n",
      "Epoch 108/7000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 888590478117.6003 - val_loss: 971604412538.7072\n",
      "Epoch 109/7000\n",
      "3554/3554 [==============================] - 1s 207us/step - loss: 888796096709.0781 - val_loss: 954881404267.8009\n",
      "Epoch 110/7000\n",
      "3554/3554 [==============================] - 1s 177us/step - loss: 890264507612.7046 - val_loss: 948800090603.9808\n",
      "Epoch 111/7000\n",
      "3554/3554 [==============================] - 1s 153us/step - loss: 892544414601.8683 - val_loss: 950074634363.2832\n",
      "Epoch 112/7000\n",
      "3554/3554 [==============================] - 0s 136us/step - loss: 885581882998.9961 - val_loss: 949324696273.8408\n",
      "Epoch 113/7000\n",
      "3554/3554 [==============================] - 0s 135us/step - loss: 885305861520.4952 - val_loss: 968725567667.1639\n",
      "Epoch 114/7000\n",
      "3554/3554 [==============================] - 0s 139us/step - loss: 886851230835.8267 - val_loss: 948174802834.5428\n",
      "Epoch 115/7000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 884606707503.3969 - val_loss: 941969835919.6625\n",
      "Epoch 116/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 882720115249.2695 - val_loss: 950804282064.6886\n",
      "Epoch 117/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 884555067532.6055 - val_loss: 1057958442912.9452\n",
      "Epoch 118/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 889906854866.4761 - val_loss: 951965055991.6467\n",
      "Epoch 119/7000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 883837495290.2374 - val_loss: 941817930329.4380\n",
      "Epoch 120/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 879338821554.7822 - val_loss: 944835564263.1561\n",
      "Epoch 121/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 879224095826.4041 - val_loss: 1006960382538.4596\n",
      "Epoch 122/7000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 880009000066.8092 - val_loss: 967137584594.9209\n",
      "Epoch 123/7000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 880160468182.9420 - val_loss: 950744618532.7257\n",
      "Epoch 124/7000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 877847727065.3911 - val_loss: 1006037011951.1494\n",
      "Epoch 125/7000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 878615815642.2555 - val_loss: 1043503073706.8827\n",
      "Epoch 126/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 135us/step - loss: 885947850823.4553 - val_loss: 942099562357.7384\n",
      "Epoch 127/7000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 873166702120.6259 - val_loss: 932938425502.1367\n",
      "Epoch 128/7000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 873359086045.1368 - val_loss: 973984354646.1975\n",
      "Epoch 129/7000\n",
      "3554/3554 [==============================] - 0s 139us/step - loss: 877839656935.7974 - val_loss: 935061275541.1353\n",
      "Epoch 130/7000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 871277177416.3196 - val_loss: 926579772482.5385\n",
      "Epoch 131/7000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 866572325258.1565 - val_loss: 929620574120.4343\n",
      "Epoch 132/7000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 869107820160.2161 - val_loss: 932243365950.2178\n",
      "Epoch 133/7000\n",
      "3554/3554 [==============================] - 1s 152us/step - loss: 867411344052.6550 - val_loss: 927442238630.7781\n",
      "Epoch 134/7000\n",
      "3554/3554 [==============================] - 0s 135us/step - loss: 867628142857.0759 - val_loss: 942379213226.3066\n",
      "Epoch 135/7000\n",
      "3554/3554 [==============================] - 1s 152us/step - loss: 868633254778.8859 - val_loss: 941269098867.0020\n",
      "Epoch 136/7000\n",
      "3554/3554 [==============================] - 0s 130us/step - loss: 867532091988.9972 - val_loss: 964852757972.0731\n",
      "Epoch 137/7000\n",
      "3554/3554 [==============================] - 1s 150us/step - loss: 868159483592.8239 - val_loss: 920909185263.6534\n",
      "Epoch 138/7000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 865003489043.7367 - val_loss: 921587471765.8555\n",
      "Epoch 139/7000\n",
      "3554/3554 [==============================] - 1s 143us/step - loss: 864303955460.8982 - val_loss: 936930881092.4106\n",
      "Epoch 140/7000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 866971613498.6337 - val_loss: 919731122515.8931\n",
      "Epoch 141/7000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 861578969871.7029 - val_loss: 929989636187.0222\n",
      "Epoch 142/7000\n",
      "3554/3554 [==============================] - 1s 141us/step - loss: 862840853759.2797 - val_loss: 917206678229.2974\n",
      "Epoch 143/7000\n",
      "3554/3554 [==============================] - 0s 131us/step - loss: 861070459910.3387 - val_loss: 923512888622.7354\n",
      "Epoch 144/7000\n",
      "3554/3554 [==============================] - 1s 165us/step - loss: 860620075498.9668 - val_loss: 922417419061.5044\n",
      "Epoch 145/7000\n",
      "3554/3554 [==============================] - 1s 170us/step - loss: 860104412195.1515 - val_loss: 926545539462.5890\n",
      "Epoch 146/7000\n",
      "3554/3554 [==============================] - 1s 161us/step - loss: 856975277950.9196 - val_loss: 936044234261.7474\n",
      "Epoch 147/7000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 861442513630.1453 - val_loss: 917868731270.7330\n",
      "Epoch 148/7000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 862544308328.8779 - val_loss: 981574974593.9083\n",
      "Epoch 149/7000\n",
      "3554/3554 [==============================] - 1s 144us/step - loss: 861439639782.5009 - val_loss: 951638131379.3080\n",
      "Epoch 150/7000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 860024180457.0939 - val_loss: 912516057620.8833\n",
      "Epoch 151/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 855893979737.6072 - val_loss: 927810804393.5145\n",
      "Epoch 152/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 856853143086.3883 - val_loss: 927725691214.1322\n",
      "Epoch 153/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 857024412664.5087 - val_loss: 912127506972.9485\n",
      "Epoch 154/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 852996168303.5048 - val_loss: 943955466442.2076\n",
      "Epoch 155/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 854697923359.8379 - val_loss: 963294538585.7980\n",
      "Epoch 156/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 858727815332.8081 - val_loss: 908846042247.6692\n",
      "Epoch 157/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 849463164946.4401 - val_loss: 912737566277.5629\n",
      "Epoch 158/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 854340445824.2161 - val_loss: 908612639830.1255\n",
      "Epoch 159/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 853354371543.3741 - val_loss: 937555758870.1074\n",
      "Epoch 160/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 851096631868.7946 - val_loss: 904578647117.4841\n",
      "Epoch 161/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 849094515772.5065 - val_loss: 925635770922.7747\n",
      "Epoch 162/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 848821986584.6349 - val_loss: 906699604152.3488\n",
      "Epoch 163/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 852389100221.8751 - val_loss: 916601399642.2301\n",
      "Epoch 164/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 848798625287.2031 - val_loss: 909123166708.0461\n",
      "Epoch 165/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 847940309635.0973 - val_loss: 969049700538.0770\n",
      "Epoch 166/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 850917943483.8582 - val_loss: 904044107738.5542\n",
      "Epoch 167/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 846764232342.1136 - val_loss: 915905656893.6416\n",
      "Epoch 168/7000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 856652853222.6450 - val_loss: 921675361090.7544\n",
      "Epoch 169/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 845558016667.2999 - val_loss: 918404391545.6990\n",
      "Epoch 170/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 845505199408.8373 - val_loss: 906117158049.5933\n",
      "Epoch 171/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 847429480607.0455 - val_loss: 931909192300.4490\n",
      "Epoch 172/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 852474108822.5459 - val_loss: 941826017176.8799\n",
      "Epoch 173/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 846675700194.8993 - val_loss: 894369707494.5081\n",
      "Epoch 174/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 844722956268.4075 - val_loss: 897124343893.2614\n",
      "Epoch 175/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 841224558606.9825 - val_loss: 902099670841.2489\n",
      "Epoch 176/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 846589954738.3500 - val_loss: 895971843282.5609\n",
      "Epoch 177/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 843771471967.6580 - val_loss: 899165152188.3094\n",
      "Epoch 178/7000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 842045432513.3325 - val_loss: 905447623211.9269\n",
      "Epoch 179/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 841462782492.5244 - val_loss: 913294789795.3215\n",
      "Epoch 180/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 841052734500.3038 - val_loss: 907131227087.3204\n",
      "Epoch 181/7000\n",
      "3554/3554 [==============================] - 0s 138us/step - loss: 841126726838.6720 - val_loss: 929301880829.6957\n",
      "Epoch 182/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 841947555324.8306 - val_loss: 906528438057.1184\n",
      "Epoch 183/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 837797332981.6276 - val_loss: 895910715283.6951\n",
      "Epoch 184/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 840068605097.9944 - val_loss: 948029475233.6653\n",
      "Epoch 185/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 837256318697.0939 - val_loss: 894608642569.9375\n",
      "Epoch 186/7000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 839981812512.9905 - val_loss: 906592455207.3181\n",
      "Epoch 187/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 839221830411.0928 - val_loss: 888199784992.4050\n",
      "Epoch 188/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 842401865545.9044 - val_loss: 892835268016.3556\n",
      "Epoch 189/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 91us/step - loss: 837088472329.6522 - val_loss: 893615679258.1401\n",
      "Epoch 190/7000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 835538185394.0619 - val_loss: 896729216527.9865\n",
      "Epoch 191/7000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 835673444395.7952 - val_loss: 905347421156.6357\n",
      "Epoch 192/7000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 842979471436.0652 - val_loss: 888488957734.8141\n",
      "Epoch 193/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 835083594690.3409 - val_loss: 908410280589.8622\n",
      "Epoch 194/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 835265471953.0354 - val_loss: 886984447506.2909\n",
      "Epoch 195/7000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 833120902868.3489 - val_loss: 894084269068.9620\n",
      "Epoch 196/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 836143620026.8497 - val_loss: 892872452903.1021\n",
      "Epoch 197/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 833442235280.7833 - val_loss: 943404128942.1232\n",
      "Epoch 198/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 834122619872.3062 - val_loss: 888561277881.4290\n",
      "Epoch 199/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 834618760602.8677 - val_loss: 888739651572.4781\n",
      "Epoch 200/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 835551668374.9780 - val_loss: 890099467419.8324\n",
      "Epoch 201/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 832134645482.2465 - val_loss: 887410450383.6084\n",
      "Epoch 202/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 835301981350.5369 - val_loss: 888427143221.0002\n",
      "Epoch 203/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 831600968555.9033 - val_loss: 884189046720.0540\n",
      "Epoch 204/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 830619509063.3112 - val_loss: 879897954399.0548\n",
      "Epoch 205/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 827255514843.2639 - val_loss: 879586674658.6194\n",
      "Epoch 206/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 831957462212.5020 - val_loss: 878624569935.6444\n",
      "Epoch 207/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 827838512147.0164 - val_loss: 884876402224.8236\n",
      "Epoch 208/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 831692740696.7428 - val_loss: 889062620354.4304\n",
      "Epoch 209/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 829330773357.9202 - val_loss: 890989244806.5890\n",
      "Epoch 210/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 834586561921.5127 - val_loss: 902156198489.4380\n",
      "Epoch 211/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 828229039548.2904 - val_loss: 875607883112.3444\n",
      "Epoch 212/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 831616780065.5667 - val_loss: 891382974881.6653\n",
      "Epoch 213/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 826072817926.7710 - val_loss: 877572536547.5555\n",
      "Epoch 214/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 826161539435.0388 - val_loss: 893786121083.7874\n",
      "Epoch 215/7000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 827190144841.9044 - val_loss: 874684729227.0537\n",
      "Epoch 216/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 826193574534.5548 - val_loss: 926576025187.5195\n",
      "Epoch 217/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 829252675025.0354 - val_loss: 886234868620.4939\n",
      "Epoch 218/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 826976845704.1396 - val_loss: 882753388078.5193\n",
      "Epoch 219/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 832253626625.0084 - val_loss: 871326054392.5109\n",
      "Epoch 220/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 825068740990.6315 - val_loss: 892711746574.6903\n",
      "Epoch 221/7000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 822342271390.9016 - val_loss: 872006022487.6377\n",
      "Epoch 222/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 823735685938.2780 - val_loss: 871464662866.5969\n",
      "Epoch 223/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 824206156001.8909 - val_loss: 881729373902.0962\n",
      "Epoch 224/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 824947363349.0332 - val_loss: 892779874869.1443\n",
      "Epoch 225/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 825070792944.5852 - val_loss: 866913905742.0602\n",
      "Epoch 226/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 820694086422.6178 - val_loss: 905213681887.5229\n",
      "Epoch 227/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 825953569218.6293 - val_loss: 897169798685.8126\n",
      "Epoch 228/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 822207526747.1919 - val_loss: 872179758663.2911\n",
      "Epoch 229/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 818086340823.5183 - val_loss: 871729714305.3322\n",
      "Epoch 230/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 820385040318.3073 - val_loss: 868159544456.8214\n",
      "Epoch 231/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 817094654119.1130 - val_loss: 884960940383.4149\n",
      "Epoch 232/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 829372957298.9623 - val_loss: 865418912446.8298\n",
      "Epoch 233/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 823237158703.3969 - val_loss: 912815397605.4279\n",
      "Epoch 234/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 825965820467.5745 - val_loss: 885245625928.4434\n",
      "Epoch 235/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 820429208705.6567 - val_loss: 872284066977.5933\n",
      "Epoch 236/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 818056355319.0680 - val_loss: 883925708361.0194\n",
      "Epoch 237/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 819694196575.8019 - val_loss: 881443905833.2625\n",
      "Epoch 238/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 820277403154.7281 - val_loss: 885175826456.7719\n",
      "Epoch 239/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 816608080150.9061 - val_loss: 863612277092.0237\n",
      "Epoch 240/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 818901686766.4243 - val_loss: 865429861770.3336\n",
      "Epoch 241/7000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 818086137235.9528 - val_loss: 879292407510.7375\n",
      "Epoch 242/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 822041329276.7585 - val_loss: 860666675352.0878\n",
      "Epoch 243/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 812892292325.9247 - val_loss: 858265769467.2473\n",
      "Epoch 244/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 811832415699.3405 - val_loss: 871914397629.1736\n",
      "Epoch 245/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 816207328691.0703 - val_loss: 889951710451.9741\n",
      "Epoch 246/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 815769574884.6281 - val_loss: 861330398446.2133\n",
      "Epoch 247/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 814532753777.9539 - val_loss: 914790137777.6517\n",
      "Epoch 248/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 816358394223.6489 - val_loss: 860860739817.8926\n",
      "Epoch 249/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 811455840458.8407 - val_loss: 860726221675.0807\n",
      "Epoch 250/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 814790329774.4603 - val_loss: 856937052617.9916\n",
      "Epoch 251/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 810126202092.8396 - val_loss: 855686902980.1587\n",
      "Epoch 252/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 84us/step - loss: 809596911159.6083 - val_loss: 877035967635.7671\n",
      "Epoch 253/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 811792704907.8853 - val_loss: 854805895397.8599\n",
      "Epoch 254/7000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 811798389754.8137 - val_loss: 867240665657.1769\n",
      "Epoch 255/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 810063550221.9741 - val_loss: 863192535345.3278\n",
      "Epoch 256/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 808430786215.4012 - val_loss: 857156756536.7449\n",
      "Epoch 257/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 815418028495.3066 - val_loss: 880799589174.6565\n",
      "Epoch 258/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 812001167285.0872 - val_loss: 865232416089.3660\n",
      "Epoch 259/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 816524460382.3612 - val_loss: 872155521256.7404\n",
      "Epoch 260/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 813709141410.9353 - val_loss: 856780187510.3145\n",
      "Epoch 261/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 805943913603.9618 - val_loss: 857140353014.2064\n",
      "Epoch 262/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 808861803911.2751 - val_loss: 856307509469.7947\n",
      "Epoch 263/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 807769374922.8407 - val_loss: 891896725688.3488\n",
      "Epoch 264/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 812311328630.8519 - val_loss: 888070733529.0419\n",
      "Epoch 265/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 817347595050.2104 - val_loss: 855596765853.4166\n",
      "Epoch 266/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 804754068569.3191 - val_loss: 856679341948.6515\n",
      "Epoch 267/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 807137344853.7175 - val_loss: 863315667497.6226\n",
      "Epoch 268/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 811535130425.7693 - val_loss: 869422744275.5691\n",
      "Epoch 269/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 807989408631.4283 - val_loss: 848523760405.2433\n",
      "Epoch 270/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 805976044352.1080 - val_loss: 847832076943.5905\n",
      "Epoch 271/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 806240238223.7749 - val_loss: 866333984369.9218\n",
      "Epoch 272/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 810791880306.3861 - val_loss: 848061199095.2866\n",
      "Epoch 273/7000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 804082229649.0714 - val_loss: 849800095924.3162\n",
      "Epoch 274/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 806756177520.0809 - val_loss: 848709038880.7651\n",
      "Epoch 275/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 802880518108.2723 - val_loss: 844613007836.4264\n",
      "Epoch 276/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 807741624753.6298 - val_loss: 847167375215.4014\n",
      "Epoch 277/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 800878891522.0168 - val_loss: 844519926585.5370\n",
      "Epoch 278/7000\n",
      "3554/3554 [==============================] - 1s 143us/step - loss: 805512651982.8744 - val_loss: 845958692020.6042\n",
      "Epoch 279/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 804700564194.7552 - val_loss: 861242358840.1688\n",
      "Epoch 280/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 802944093486.5323 - val_loss: 844866716809.3975\n",
      "Epoch 281/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 806043297260.6956 - val_loss: 847252669904.6166\n",
      "Epoch 282/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 802959261179.6781 - val_loss: 843101452570.8602\n",
      "Epoch 283/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 806117940487.3472 - val_loss: 844771014118.5081\n",
      "Epoch 284/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 802646169633.4226 - val_loss: 867789195783.0571\n",
      "Epoch 285/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 807732479039.9640 - val_loss: 849969111553.8723\n",
      "Epoch 286/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 801664923556.9521 - val_loss: 848114834826.9097\n",
      "Epoch 287/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 803308565773.1096 - val_loss: 842443764134.8501\n",
      "Epoch 288/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 798751659678.1813 - val_loss: 843773033901.4751\n",
      "Epoch 289/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 801537026955.0208 - val_loss: 855872180570.8062\n",
      "Epoch 290/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 804757338113.1526 - val_loss: 837101379397.3468\n",
      "Epoch 291/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 799219541023.6938 - val_loss: 848653155605.3873\n",
      "Epoch 292/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 802377274355.8988 - val_loss: 838637384660.5052\n",
      "Epoch 293/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 796731584703.3157 - val_loss: 847151500054.9716\n",
      "Epoch 294/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 801482162056.1396 - val_loss: 837977104980.8292\n",
      "Epoch 295/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 798840141613.0917 - val_loss: 851710464683.2428\n",
      "Epoch 296/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 796719289110.6178 - val_loss: 836987262436.2036\n",
      "Epoch 297/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 801054588167.6354 - val_loss: 838544423494.4270\n",
      "Epoch 298/7000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 797662517889.9448 - val_loss: 844691612396.9170\n",
      "Epoch 299/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 798999392396.6055 - val_loss: 845891360795.0762\n",
      "Epoch 300/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 798404957457.7197 - val_loss: 848260912008.4613\n",
      "Epoch 301/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 797893566920.3917 - val_loss: 844907552834.8264\n",
      "Epoch 302/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 799068914991.6849 - val_loss: 893371109045.3243\n",
      "Epoch 303/7000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 796841130916.3760 - val_loss: 833543459176.6323\n",
      "Epoch 304/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 793894350822.6450 - val_loss: 836357689626.2841\n",
      "Epoch 305/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 796906035353.2831 - val_loss: 835701745166.8344\n",
      "Epoch 306/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 795217804177.9359 - val_loss: 833223888625.2377\n",
      "Epoch 307/7000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 793798079480.5087 - val_loss: 831685446602.7117\n",
      "Epoch 308/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 795821633741.1458 - val_loss: 834204975597.1331\n",
      "Epoch 309/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 794924306457.3550 - val_loss: 837079354360.7988\n",
      "Epoch 310/7000\n",
      "3554/3554 [==============================] - 0s 135us/step - loss: 794107034624.5762 - val_loss: 891591366862.8163\n",
      "Epoch 311/7000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 801221357763.9258 - val_loss: 842405190401.0802\n",
      "Epoch 312/7000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 792951409754.4716 - val_loss: 840251491801.8340\n",
      "Epoch 313/7000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 796054502409.7963 - val_loss: 841529639100.9575\n",
      "Epoch 314/7000\n",
      "3554/3554 [==============================] - 1s 141us/step - loss: 796994659507.2145 - val_loss: 835499051812.7977\n",
      "Epoch 315/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 130us/step - loss: 787836134689.8547 - val_loss: 869887339192.4928\n",
      "Epoch 316/7000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 793146837295.1085 - val_loss: 829918668196.8337\n",
      "Epoch 317/7000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 791914149243.7501 - val_loss: 848659907177.5685\n",
      "Epoch 318/7000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 796386277533.8932 - val_loss: 828970725001.5415\n",
      "Epoch 319/7000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 789390390338.2690 - val_loss: 832611072752.9497\n",
      "Epoch 320/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 792116063852.6234 - val_loss: 834869728316.2014\n",
      "Epoch 321/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 792263719300.3940 - val_loss: 836011554319.9865\n",
      "Epoch 322/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 791649135406.8204 - val_loss: 832139272802.6554\n",
      "Epoch 323/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 788941434882.3049 - val_loss: 832757108603.4993\n",
      "Epoch 324/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 795254869967.5947 - val_loss: 828562572139.6569\n",
      "Epoch 325/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 790416445935.5768 - val_loss: 828832778229.0543\n",
      "Epoch 326/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 790569854527.6759 - val_loss: 826953851227.9584\n",
      "Epoch 327/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 789998134690.9353 - val_loss: 830365971214.3302\n",
      "Epoch 328/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 789540217583.4327 - val_loss: 827852108659.7220\n",
      "Epoch 329/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 792368259288.6709 - val_loss: 837442377344.9001\n",
      "Epoch 330/7000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 791385551283.6466 - val_loss: 867848300332.5750\n",
      "Epoch 331/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 792820703752.9320 - val_loss: 842569329414.8411\n",
      "Epoch 332/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 784864605102.7484 - val_loss: 915656875822.3032\n",
      "Epoch 333/7000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 789172638329.8774 - val_loss: 824846447074.7634\n",
      "Epoch 334/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 786125101218.5031 - val_loss: 823238608124.6155\n",
      "Epoch 335/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 781406245746.8182 - val_loss: 829740478559.6310\n",
      "Epoch 336/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 787655287599.9730 - val_loss: 841112760383.3699\n",
      "Epoch 337/7000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 790046263562.2285 - val_loss: 826227703056.7786\n",
      "Epoch 338/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 786121420525.7040 - val_loss: 843898984286.1187\n",
      "Epoch 339/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 789198223517.8932 - val_loss: 871707781811.8842\n",
      "Epoch 340/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 791102432960.7563 - val_loss: 833831499593.3795\n",
      "Epoch 341/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 785174815204.0518 - val_loss: 822201798740.1091\n",
      "Epoch 342/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 789713322924.4435 - val_loss: 822710223451.7423\n",
      "Epoch 343/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 782755517916.5604 - val_loss: 872742852860.9036\n",
      "Epoch 344/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 783434364624.8915 - val_loss: 836381956712.9924\n",
      "Epoch 345/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 783346727097.5531 - val_loss: 823348012651.0087\n",
      "Epoch 346/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 784172896355.1154 - val_loss: 821576394757.1848\n",
      "Epoch 347/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 781991233332.0067 - val_loss: 832717331440.7336\n",
      "Epoch 348/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 784166698125.1818 - val_loss: 839432393875.7671\n",
      "Epoch 349/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 779965731274.6967 - val_loss: 826853174437.6259\n",
      "Epoch 350/7000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 784070436756.8170 - val_loss: 832297792754.2458\n",
      "Epoch 351/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 785923224411.7682 - val_loss: 827031891644.2374\n",
      "Epoch 352/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 783976226673.0895 - val_loss: 826649049541.3828\n",
      "Epoch 353/7000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 777591113016.9049 - val_loss: 827570944545.5573\n",
      "Epoch 354/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 780144509444.3219 - val_loss: 821836230673.2827\n",
      "Epoch 355/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 783059384376.4728 - val_loss: 839694299789.2861\n",
      "Epoch 356/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 781005649515.4711 - val_loss: 822052059764.5142\n",
      "Epoch 357/7000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 782209610117.5464 - val_loss: 816240544041.8385\n",
      "Epoch 358/7000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 779483842969.1390 - val_loss: 833291007075.3755\n",
      "Epoch 359/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 778721382637.4159 - val_loss: 827900492717.9072\n",
      "Epoch 360/7000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 778960239238.5548 - val_loss: 814779778789.1398\n",
      "Epoch 361/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 778080613050.4176 - val_loss: 822195282968.4838\n",
      "Epoch 362/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 775996945990.5908 - val_loss: 815904279176.1013\n",
      "Epoch 363/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 778923674354.8904 - val_loss: 818642296382.6498\n",
      "Epoch 364/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 784074017278.5593 - val_loss: 813648128802.4934\n",
      "Epoch 365/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 777431072002.7372 - val_loss: 814788701013.1893\n",
      "Epoch 366/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 777116824559.2887 - val_loss: 884531955922.2728\n",
      "Epoch 367/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 782924037175.8965 - val_loss: 815021043996.5885\n",
      "Epoch 368/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 776886969516.2993 - val_loss: 815320607227.5353\n",
      "Epoch 369/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 778827495425.1526 - val_loss: 811401511953.5708\n",
      "Epoch 370/7000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 772264352284.5244 - val_loss: 826939300687.4285\n",
      "Epoch 371/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 776873297356.4255 - val_loss: 809210790915.7446\n",
      "Epoch 372/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 773149452420.5380 - val_loss: 829024749635.4026\n",
      "Epoch 373/7000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 779465542984.45 - 0s 85us/step - loss: 776615205561.2650 - val_loss: 815649196325.2299\n",
      "Epoch 374/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 773101558162.2240 - val_loss: 806372690153.3164\n",
      "Epoch 375/7000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 771808692646.9691 - val_loss: 813285069759.7660\n",
      "Epoch 376/7000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 776287103910.6809 - val_loss: 812056487623.1831\n",
      "Epoch 377/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 770862549710.0101 - val_loss: 833223992727.0076\n",
      "Epoch 378/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 88us/step - loss: 782682073414.1587 - val_loss: 817638030276.9508\n",
      "Epoch 379/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 770112866939.0298 - val_loss: 807362235085.2321\n",
      "Epoch 380/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 773162426206.6494 - val_loss: 806341772204.1790\n",
      "Epoch 381/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 769919464597.2493 - val_loss: 803530005299.7761\n",
      "Epoch 382/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 770398135945.4362 - val_loss: 844149522478.0872\n",
      "Epoch 383/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 776264213996.6956 - val_loss: 817203381772.5299\n",
      "Epoch 384/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 774593014501.0602 - val_loss: 808236677490.4259\n",
      "Epoch 385/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 768862031777.4946 - val_loss: 848111202381.1960\n",
      "Epoch 386/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 770745114951.3112 - val_loss: 860150177158.3010\n",
      "Epoch 387/7000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 767398657669.9786 - val_loss: 807450731286.3955\n",
      "Epoch 388/7000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 768830332582.2488 - val_loss: 802375328082.7410\n",
      "Epoch 389/7000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 764825738540.2274 - val_loss: 808902363161.9241\n",
      "Epoch 390/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 765745925699.1334 - val_loss: 810256054204.5974\n",
      "Epoch 391/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 761361282787.3314 - val_loss: 793954520817.2377\n",
      "Epoch 392/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 756370251771.3900 - val_loss: 812789853050.0591\n",
      "Epoch 393/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 758619512477.0287 - val_loss: 793418786544.6616\n",
      "Epoch 394/7000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 755335306208.3062 - val_loss: 793284067277.3041\n",
      "Epoch 395/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 750387330481.9178 - val_loss: 800656321180.8405\n",
      "Epoch 396/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 753732505588.4750 - val_loss: 843663351100.5615\n",
      "Epoch 397/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 755662422513.8818 - val_loss: 821948149975.4576\n",
      "Epoch 398/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 749829375325.7850 - val_loss: 777277427731.5870\n",
      "Epoch 399/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 745221744459.0568 - val_loss: 833043497863.3091\n",
      "Epoch 400/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 746641678206.9196 - val_loss: 781369043861.7114\n",
      "Epoch 401/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 741062101368.8688 - val_loss: 801766021308.3815\n",
      "Epoch 402/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 745504796914.0259 - val_loss: 772417318214.9310\n",
      "Epoch 403/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 743179828132.3760 - val_loss: 821007126496.8911\n",
      "Epoch 404/7000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 741105481897.4182 - val_loss: 840369035844.1227\n",
      "Epoch 405/7000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 739836045840.9994 - val_loss: 786477483882.7927\n",
      "Epoch 406/7000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 743341892464.5132 - val_loss: 780387239865.1409\n",
      "Epoch 407/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 735606281067.9033 - val_loss: 771821652883.4070\n",
      "Epoch 408/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 736354713406.3794 - val_loss: 774652954290.4438\n",
      "Epoch 409/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 734740650128.0630 - val_loss: 765031763895.4126\n",
      "Epoch 410/7000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 735325062539.8853 - val_loss: 802441329010.4259\n",
      "Epoch 411/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 736637312752.0090 - val_loss: 798964848008.0293\n",
      "Epoch 412/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 736710115360.2701 - val_loss: 781125804426.0455\n",
      "Epoch 413/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 731550511576.5267 - val_loss: 770643517741.8712\n",
      "Epoch 414/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 730802185727.1357 - val_loss: 762103824577.5663\n",
      "Epoch 415/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 731543357798.4288 - val_loss: 768938393337.3030\n",
      "Epoch 416/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 728234395688.3376 - val_loss: 765114622470.4810\n",
      "Epoch 417/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 730519300302.2982 - val_loss: 762583293917.4346\n",
      "Epoch 418/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 735612031609.8774 - val_loss: 763040434727.3181\n",
      "Epoch 419/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 732158228287.5317 - val_loss: 768241404722.6239\n",
      "Epoch 420/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 729008016870.9331 - val_loss: 781356589367.0886\n",
      "Epoch 421/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 733901387311.5408 - val_loss: 757030660142.6633\n",
      "Epoch 422/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 728060054839.7524 - val_loss: 775095459648.7382\n",
      "Epoch 423/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 728966203464.6077 - val_loss: 800344013732.6897\n",
      "Epoch 424/7000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 729624523279.8469 - val_loss: 789871403388.2194\n",
      "Epoch 425/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 730054969246.0371 - val_loss: 768390157856.1171\n",
      "Epoch 426/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 722829651297.2426 - val_loss: 763983057413.3289\n",
      "Epoch 427/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 723122880488.3735 - val_loss: 761514517749.7024\n",
      "Epoch 428/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 723277773262.1543 - val_loss: 777854998951.4261\n",
      "Epoch 429/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 721823675707.2100 - val_loss: 833471861769.5055\n",
      "Epoch 430/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 723963798393.7333 - val_loss: 751951566994.9030\n",
      "Epoch 431/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 724858354836.0967 - val_loss: 787013474510.8163\n",
      "Epoch 432/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 721422410216.6619 - val_loss: 748200547097.8521\n",
      "Epoch 433/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 717097861728.5222 - val_loss: 764263776103.9122\n",
      "Epoch 434/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 722189845973.6455 - val_loss: 756443387603.8571\n",
      "Epoch 435/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 720997664776.0675 - val_loss: 834687381871.5454\n",
      "Epoch 436/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 725908790516.9072 - val_loss: 745448200643.0785\n",
      "Epoch 437/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 720505536862.3612 - val_loss: 751083964077.8352\n",
      "Epoch 438/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 717073594101.7715 - val_loss: 761354500517.1218\n",
      "Epoch 439/7000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 721513392712.3196 - val_loss: 753694384941.4391\n",
      "Epoch 440/7000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 715780001079.7524 - val_loss: 747643073492.5052\n",
      "Epoch 441/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 85us/step - loss: 720220926535.1672 - val_loss: 795538765516.9440\n",
      "Epoch 442/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 727673993751.9146 - val_loss: 742803569545.0374\n",
      "Epoch 443/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 715513579030.1858 - val_loss: 751401644500.9373\n",
      "Epoch 444/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 715057743382.1858 - val_loss: 743392170575.0684\n",
      "Epoch 445/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 716402630596.0697 - val_loss: 744006161394.4619\n",
      "Epoch 446/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 712455469313.0084 - val_loss: 740484335969.1432\n",
      "Epoch 447/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 709106068510.5414 - val_loss: 740886753684.4152\n",
      "Epoch 448/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 712596235175.8334 - val_loss: 786490090373.0048\n",
      "Epoch 449/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 715083736003.4935 - val_loss: 743109654870.7736\n",
      "Epoch 450/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 710281964989.4429 - val_loss: 749239186936.9429\n",
      "Epoch 451/7000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 712687081865.0039 - val_loss: 751704030075.2113\n",
      "Epoch 452/7000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 715138960006.5548 - val_loss: 736929506153.3524\n",
      "Epoch 453/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 711578347836.9387 - val_loss: 757755389510.1389\n",
      "Epoch 454/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 710272214840.6167 - val_loss: 774775003467.2517\n",
      "Epoch 455/7000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 709735136026.0753 - val_loss: 739995574103.7817\n",
      "Epoch 456/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 710325566206.4154 - val_loss: 735287653244.9396\n",
      "Epoch 457/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 704972531909.0781 - val_loss: 748347908176.6526\n",
      "Epoch 458/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 710154044249.4631 - val_loss: 753181670857.1274\n",
      "Epoch 459/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 708013130954.2645 - val_loss: 737173595750.4000\n",
      "Epoch 460/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 708573658564.3578 - val_loss: 750252006237.2545\n",
      "Epoch 461/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 707986334724.0337 - val_loss: 753795432512.5221\n",
      "Epoch 462/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 710457894389.9156 - val_loss: 731490610429.1915\n",
      "Epoch 463/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 707826210821.7626 - val_loss: 732418144331.4678\n",
      "Epoch 464/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 707390175528.1936 - val_loss: 738670964472.1508\n",
      "Epoch 465/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 709513202630.9510 - val_loss: 738335835084.4399\n",
      "Epoch 466/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 707595665387.8312 - val_loss: 741046381922.5834\n",
      "Epoch 467/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 706750596427.3450 - val_loss: 732463783823.0863\n",
      "Epoch 468/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 711042265717.2673 - val_loss: 739709071745.9803\n",
      "Epoch 469/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 705850814106.7238 - val_loss: 736909612852.6403\n",
      "Epoch 470/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 704977961439.4418 - val_loss: 731547188404.6042\n",
      "Epoch 471/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 704560333390.0822 - val_loss: 731159105744.5446\n",
      "Epoch 472/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 707261003814.0326 - val_loss: 776526935932.0754\n",
      "Epoch 473/7000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 705846086368.4502 - val_loss: 736452234841.1499\n",
      "Epoch 474/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 706451492538.9938 - val_loss: 779476180367.5184\n",
      "Epoch 475/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 707224940444.8846 - val_loss: 731382441408.4861\n",
      "Epoch 476/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 704901936765.9111 - val_loss: 732918667152.8146\n",
      "Epoch 477/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 700961957568.7563 - val_loss: 730505206966.9086\n",
      "Epoch 478/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 705752848704.9724 - val_loss: 731115892541.2816\n",
      "Epoch 479/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 705944537059.1874 - val_loss: 734150751326.7668\n",
      "Epoch 480/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 700763032076.3895 - val_loss: 756487024219.4543\n",
      "Epoch 481/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 709049259475.3405 - val_loss: 739589173919.7209\n",
      "Epoch 482/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 702815052969.9944 - val_loss: 768936893032.9924\n",
      "Epoch 483/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 700971238841.9854 - val_loss: 738120018197.0992\n",
      "Epoch 484/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 703247512877.3799 - val_loss: 724560326092.5840\n",
      "Epoch 485/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 699698996108.1733 - val_loss: 728384804453.2478\n",
      "Epoch 486/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 699810561872.8193 - val_loss: 728687662900.6403\n",
      "Epoch 487/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 700143476971.1108 - val_loss: 839198866838.4315\n",
      "Epoch 488/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 708448227968.6031 - val_loss: 729997019844.0146\n",
      "Epoch 489/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 697924656004.1057 - val_loss: 739386708568.2858\n",
      "Epoch 490/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 699790022108.5604 - val_loss: 741813522336.3690\n",
      "Epoch 491/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 700023782787.8176 - val_loss: 725982659431.0481\n",
      "Epoch 492/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 699930631027.9707 - val_loss: 739947894258.0298\n",
      "Epoch 493/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 698587967803.7861 - val_loss: 782480406354.5969\n",
      "Epoch 494/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 707332469107.1063 - val_loss: 744022371866.9323\n",
      "Epoch 495/7000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 704937785511.1130 - val_loss: 745985014535.9933\n",
      "Epoch 496/7000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 699325660750.6584 - val_loss: 749621812503.6917\n",
      "Epoch 497/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 697572634156.0833 - val_loss: 736292300049.3547\n",
      "Epoch 498/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 697532599626.1925 - val_loss: 756140334189.1691\n",
      "Epoch 499/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 697448522986.5345 - val_loss: 720703912804.1676\n",
      "Epoch 500/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 699002590583.1401 - val_loss: 740775101116.5255\n",
      "Epoch 501/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 698536956897.4586 - val_loss: 723299337371.8324\n",
      "Epoch 502/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 694700637820.7585 - val_loss: 777673720439.3947\n",
      "Epoch 503/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 701945485903.2346 - val_loss: 738899870954.1805\n",
      "Epoch 504/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 86us/step - loss: 695505856487.7974 - val_loss: 732582510444.5210\n",
      "Epoch 505/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 701930000519.9955 - val_loss: 720531867586.3584\n",
      "Epoch 506/7000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 695760537202.3861 - val_loss: 723106734294.3055\n",
      "Epoch 507/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 699272231503.2346 - val_loss: 721836465288.8214\n",
      "Epoch 508/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 699779456952.5447 - val_loss: 738734712620.5750\n",
      "Epoch 509/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 697046885403.0839 - val_loss: 744624172842.8467\n",
      "Epoch 510/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 696406110984.7878 - val_loss: 725421328290.0973\n",
      "Epoch 511/7000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 695348992475.9843 - val_loss: 733377019318.6925\n",
      "Epoch 512/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 694730802830.0461 - val_loss: 738749441795.0964\n",
      "Epoch 513/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 697514022419.8807 - val_loss: 724334991460.8158\n",
      "Epoch 514/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 697645634695.4193 - val_loss: 722442732501.6573\n",
      "Epoch 515/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 693100590653.3707 - val_loss: 720327996851.8121\n",
      "Epoch 516/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 694033219789.1458 - val_loss: 730823138436.2126\n",
      "Epoch 517/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 694304423283.6826 - val_loss: 729670914293.4143\n",
      "Epoch 518/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 695126683336.8239 - val_loss: 771807244107.1078\n",
      "Epoch 519/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 702591748814.0101 - val_loss: 726091140904.5424\n",
      "Epoch 520/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 694617156952.0225 - val_loss: 728034423096.2408\n",
      "Epoch 521/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 697417399287.3562 - val_loss: 739426341699.3306\n",
      "Epoch 522/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 698148154195.7007 - val_loss: 762189280332.3319\n",
      "Epoch 523/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 693778916798.5953 - val_loss: 769920052251.3643\n",
      "Epoch 524/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 699713880527.3066 - val_loss: 731119346555.7874\n",
      "Epoch 525/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 692319377893.2043 - val_loss: 718188502456.9969\n",
      "Epoch 526/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 692828370262.8700 - val_loss: 762114494796.9800\n",
      "Epoch 527/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 700148566835.4305 - val_loss: 747760906464.6750\n",
      "Epoch 528/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 691818920693.1953 - val_loss: 803387617380.2396\n",
      "Epoch 529/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 701421548418.9534 - val_loss: 719011731068.2914\n",
      "Epoch 530/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 693468005403.0839 - val_loss: 732831164352.0540\n",
      "Epoch 531/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 694180871620.3578 - val_loss: 728686816020.6672\n",
      "Epoch 532/7000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 696842452475.6781 - val_loss: 795400862011.1212\n",
      "Epoch 533/7000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 697489901244.1464 - val_loss: 769638241865.5955\n",
      "Epoch 534/7000\n",
      "3554/3554 [==============================] - 1s 150us/step - loss: 694210662655.8558 - val_loss: 734222288064.7021\n",
      "Epoch 535/7000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 692447589101.1278 - val_loss: 718747169942.0714\n",
      "Epoch 536/7000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 692173264668.9567 - val_loss: 719738740885.7834\n",
      "Epoch 537/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 692755509794.2870 - val_loss: 744466124068.3657\n",
      "Epoch 538/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 695028690973.9651 - val_loss: 766706207792.1035\n",
      "Epoch 539/7000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 693008545193.8502 - val_loss: 721542825369.3120\n",
      "Epoch 540/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 691556846544.1711 - val_loss: 722320370835.1910\n",
      "Epoch 541/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 691874366362.0034 - val_loss: 851699080370.2998\n",
      "Epoch 542/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 702275088201.9044 - val_loss: 724948310642.2098\n",
      "Epoch 543/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 691512758518.6360 - val_loss: 720286916711.6962\n",
      "Epoch 544/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 691131647150.6044 - val_loss: 738899543458.5294\n",
      "Epoch 545/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 691070419174.5009 - val_loss: 749766173250.3944\n",
      "Epoch 546/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 692787724297.2201 - val_loss: 726350433544.7134\n",
      "Epoch 547/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 691152094991.1267 - val_loss: 764475892391.7863\n",
      "Epoch 548/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 690322743844.5919 - val_loss: 732502480111.9415\n",
      "Epoch 549/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 691436435807.5138 - val_loss: 727502203083.3597\n",
      "Epoch 550/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 688835349488.4413 - val_loss: 718691527776.4951\n",
      "Epoch 551/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 688482567674.5256 - val_loss: 730151028374.7915\n",
      "Epoch 552/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 696398825922.6293 - val_loss: 717254156682.0455\n",
      "Epoch 553/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 691684415041.9808 - val_loss: 719746399601.5618\n",
      "Epoch 554/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 692187230302.5054 - val_loss: 778367802371.1685\n",
      "Epoch 555/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 696891125845.2853 - val_loss: 729462912136.2452\n",
      "Epoch 556/7000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 690222386432.4323 - val_loss: 814384777481.5775\n",
      "Epoch 557/7000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 694654784029.6770 - val_loss: 717280526598.6970\n",
      "Epoch 558/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 687308835817.5261 - val_loss: 715185686590.7938\n",
      "Epoch 559/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 688892092226.9893 - val_loss: 737589358770.5879\n",
      "Epoch 560/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 692667000494.3163 - val_loss: 741346673902.7893\n",
      "Epoch 561/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 690668633374.3973 - val_loss: 719498332918.7106\n",
      "Epoch 562/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 689114421866.8948 - val_loss: 716130984233.2625\n",
      "Epoch 563/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 689857748517.1683 - val_loss: 714726881240.2498\n",
      "Epoch 564/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 688689129466.2374 - val_loss: 714289974886.9761\n",
      "Epoch 565/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 690394171999.3696 - val_loss: 726433492820.3252\n",
      "Epoch 566/7000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 685435790413.7941 - val_loss: 744049961785.5370\n",
      "Epoch 567/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 101us/step - loss: 695725800577.6567 - val_loss: 725219060449.9713\n",
      "Epoch 568/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 690351915847.0231 - val_loss: 749224134211.8346\n",
      "Epoch 569/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 693052989813.4114 - val_loss: 719251289371.7244\n",
      "Epoch 570/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 687688080946.9983 - val_loss: 715660564834.2954\n",
      "Epoch 571/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 688374493177.0850 - val_loss: 765115767000.0338\n",
      "Epoch 572/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 693241556339.6826 - val_loss: 722274035611.1842\n",
      "Epoch 573/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 688363734577.8457 - val_loss: 726590817306.7882\n",
      "Epoch 574/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 691427028226.7372 - val_loss: 717996980917.0363\n",
      "Epoch 575/7000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 688964742405.0422 - val_loss: 714559127681.0442\n",
      "Epoch 576/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 689790606562.4670 - val_loss: 717417772163.6366\n",
      "Epoch 577/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 684871168970.4086 - val_loss: 747224237174.9626\n",
      "Epoch 578/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 692724164546.9174 - val_loss: 721672031796.2802\n",
      "Epoch 579/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 687238727429.9066 - val_loss: 717510838279.4891\n",
      "Epoch 580/7000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 687906793613.7581 - val_loss: 761505245355.0988\n",
      "Epoch 581/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 694271641967.6489 - val_loss: 722019170476.2509\n",
      "Epoch 582/7000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 689479315587.3855 - val_loss: 751227986138.9142\n",
      "Epoch 583/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 690445655672.1487 - val_loss: 768898444177.1027\n",
      "Epoch 584/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 691306139701.0151 - val_loss: 715848414459.4633\n",
      "Epoch 585/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 689576752092.8485 - val_loss: 756009463737.7170\n",
      "Epoch 586/7000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 692330919162.6697 - val_loss: 712591521641.6405\n",
      "Epoch 587/7000\n",
      "3554/3554 [==============================] - 0s 130us/step - loss: 686674759926.6360 - val_loss: 761659693410.2954\n",
      "Epoch 588/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 690510617761.9269 - val_loss: 726146344928.3151\n",
      "Epoch 589/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 689068588760.9590 - val_loss: 730480834746.0770\n",
      "Epoch 590/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 686621359962.0394 - val_loss: 724397216998.7240\n",
      "Epoch 591/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 686702731234.0349 - val_loss: 714029905622.1615\n",
      "Epoch 592/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 687236764613.7985 - val_loss: 728424804899.2855\n",
      "Epoch 593/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 688500979962.0934 - val_loss: 722976517267.1910\n",
      "Epoch 594/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 688085022214.0507 - val_loss: 750859926745.4740\n",
      "Epoch 595/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 689337977632.9905 - val_loss: 736581147397.6888\n",
      "Epoch 596/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 690656998632.2296 - val_loss: 715789134446.7533\n",
      "Epoch 597/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 688200654161.1074 - val_loss: 727431500505.3300\n",
      "Epoch 598/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 688516932602.8137 - val_loss: 725906739394.7184\n",
      "Epoch 599/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 689716276577.2426 - val_loss: 738479664961.8903\n",
      "Epoch 600/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 691562128590.8744 - val_loss: 750301768782.0602\n",
      "Epoch 601/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 685996878850.8813 - val_loss: 784968909076.5232\n",
      "Epoch 602/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 685764301470.7574 - val_loss: 728945183506.3629\n",
      "Epoch 603/7000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 685649229696.0720 - val_loss: 732708833029.4009\n",
      "Epoch 604/7000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 688370077223.4733 - val_loss: 721492375350.9446\n",
      "Epoch 605/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 689199014722.4131 - val_loss: 712236814503.0662\n",
      "Epoch 606/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 686631221857.6748 - val_loss: 777943045857.6832\n",
      "Epoch 607/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 690308668541.0466 - val_loss: 796951783820.9260\n",
      "Epoch 608/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 692409744587.4170 - val_loss: 742211224814.7893\n",
      "Epoch 609/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 687488326209.4047 - val_loss: 734492764980.9282\n",
      "Epoch 610/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 686529887398.5369 - val_loss: 722622305639.7682\n",
      "Epoch 611/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 688886637802.5345 - val_loss: 726747403734.3774\n",
      "Epoch 612/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 688059236891.3719 - val_loss: 726442585530.1490\n",
      "Epoch 613/7000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 687607241014.0237 - val_loss: 726567981246.1097\n",
      "Epoch 614/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 687823155100.8846 - val_loss: 739832779803.9403\n",
      "Epoch 615/7000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 689301175093.7355 - val_loss: 725877946489.5551\n",
      "Epoch 616/7000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 687887046726.3027 - val_loss: 736626544986.8062\n",
      "Epoch 617/7000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 688275756351.8198 - val_loss: 716347596438.2155\n",
      "Epoch 618/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 686092781364.0067 - val_loss: 736325909583.2124\n",
      "Epoch 619/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 687730098747.6422 - val_loss: 729886276263.2101\n",
      "Epoch 620/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 688819838750.1091 - val_loss: 720268716912.8417\n",
      "Epoch 621/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 687729209715.1063 - val_loss: 723590337342.7218\n",
      "Epoch 622/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 689894781538.8271 - val_loss: 713066729722.0231\n",
      "Epoch 623/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 688885812646.3928 - val_loss: 743409848445.5876\n",
      "Epoch 624/7000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 691423758712.8688 - val_loss: 717640561436.1564\n",
      "Epoch 625/7000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 682058359314.1520 - val_loss: 710336610331.6523\n",
      "Epoch 626/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 687308190850.8092 - val_loss: 713307135329.4313\n",
      "Epoch 627/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 686412318672.7473 - val_loss: 719478853646.9784\n",
      "Epoch 628/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 689269913315.3314 - val_loss: 723093514936.4928\n",
      "Epoch 629/7000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 684613663403.4351 - val_loss: 747543212648.4163\n",
      "Epoch 630/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 87us/step - loss: 686065661077.2493 - val_loss: 716280404285.4255\n",
      "Epoch 631/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 686239945015.1761 - val_loss: 744157714970.6442\n",
      "Epoch 632/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 684939552338.1158 - val_loss: 720911417588.2622\n",
      "Epoch 633/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 685934657877.1414 - val_loss: 728225858360.9609\n",
      "Epoch 634/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 690574509000.1035 - val_loss: 718221066530.3494\n",
      "Epoch 635/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 684353171665.7557 - val_loss: 716197399945.7576\n",
      "Epoch 636/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 684527031615.8198 - val_loss: 743240103900.8585\n",
      "Epoch 637/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 689305863480.9049 - val_loss: 720863506956.2419\n",
      "Epoch 638/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 685479964259.4036 - val_loss: 833531422195.1820\n",
      "Epoch 639/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 692772701874.9263 - val_loss: 723063352928.0630\n",
      "Epoch 640/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 686428078255.1807 - val_loss: 805398927691.2517\n",
      "Epoch 641/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 691627132336.7654 - val_loss: 711825764931.5465\n",
      "Epoch 642/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 688420556207.6128 - val_loss: 714085128412.6425\n",
      "Epoch 643/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 682554877494.4558 - val_loss: 718991411239.7502\n",
      "Epoch 644/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 683404975127.6265 - val_loss: 722594793848.1868\n",
      "Epoch 645/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 684492021653.9696 - val_loss: 715387109394.4349\n",
      "Epoch 646/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 688987287664.9454 - val_loss: 722830147026.3448\n",
      "Epoch 647/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 685203996565.9696 - val_loss: 717783734718.4697\n",
      "Epoch 648/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 685479933833.2920 - val_loss: 746353626035.6681\n",
      "Epoch 649/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 688518672856.5267 - val_loss: 734432418473.5145\n",
      "Epoch 650/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 686373722025.5621 - val_loss: 747884291396.0507\n",
      "Epoch 651/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 688445709012.9252 - val_loss: 752085915794.9030\n",
      "Epoch 652/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 686653175569.4316 - val_loss: 750599401069.8892\n",
      "Epoch 653/7000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 695640654045.2808 - val_loss: 718206864759.3226\n",
      "Epoch 654/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 687555520658.3679 - val_loss: 715442331650.3043\n",
      "Epoch 655/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 680883965129.1119 - val_loss: 731842154547.8481\n",
      "Epoch 656/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 685433668349.2628 - val_loss: 714919014744.5018\n",
      "Epoch 657/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 683267276532.6189 - val_loss: 767130299046.0580\n",
      "Epoch 658/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 685363802971.7682 - val_loss: 768382994743.6647\n",
      "Epoch 659/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 688319563166.3252 - val_loss: 741443229280.6392\n",
      "Epoch 660/7000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 689835996244.7091 - val_loss: 717336323783.1831\n",
      "Epoch 661/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 686122209462.0956 - val_loss: 725833226290.1199\n",
      "Epoch 662/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 686373727262.5414 - val_loss: 730606145809.0667\n",
      "Epoch 663/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 682633818888.7878 - val_loss: 722238998277.4009\n",
      "Epoch 664/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 686169233804.3174 - val_loss: 723165818123.0177\n",
      "Epoch 665/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 685389823290.0574 - val_loss: 711201721829.9319\n",
      "Epoch 666/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 683343861931.7231 - val_loss: 712831764063.4869\n",
      "Epoch 667/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 681770264348.9567 - val_loss: 716667452638.0826\n",
      "Epoch 668/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 685027577964.3353 - val_loss: 720414781632.4141\n",
      "Epoch 669/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 684296995074.1610 - val_loss: 714159020851.7761\n",
      "Epoch 670/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 682047349081.7512 - val_loss: 719962878208.9362\n",
      "Epoch 671/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 682841964562.4401 - val_loss: 712840246431.2889\n",
      "Epoch 672/7000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 684032825195.3269 - val_loss: 738756360461.0341\n",
      "Epoch 673/7000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 685401848892.5065 - val_loss: 715704783752.4613\n",
      "Epoch 674/7000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 684000984802.1790 - val_loss: 730090460206.3752\n",
      "Epoch 675/7000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 685620830980.83 - 0s 86us/step - loss: 685568687934.3794 - val_loss: 740128918553.0599\n",
      "Epoch 676/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 689978016836.5740 - val_loss: 716988061239.1606\n",
      "Epoch 677/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 685717649635.0433 - val_loss: 722300477608.2183\n",
      "Epoch 678/7000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 682147329283.8898 - val_loss: 731913036478.8298\n",
      "Epoch 679/7000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 688670059947.0028 - val_loss: 713320275951.8695\n",
      "Epoch 680/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 682749691755.3269 - val_loss: 740144730315.9359\n",
      "Epoch 681/7000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 686864557677.7760 - val_loss: 726885548866.1783\n",
      "Epoch 682/7000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 685795513977.3010 - val_loss: 749678135635.3170\n",
      "Epoch 683/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 687269951277.0917 - val_loss: 720098904527.7524\n",
      "Epoch 684/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 686243928881.1256 - val_loss: 715322817656.6909\n",
      "Epoch 685/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 685176281278.1632 - val_loss: 755846064349.7947\n",
      "Epoch 686/7000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 687030747606.2217 - val_loss: 736154046870.7196\n",
      "Epoch 687/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 687172788145.6298 - val_loss: 719034151109.0228\n",
      "Epoch 688/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 684230905586.3140 - val_loss: 717698527134.0647\n",
      "Epoch 689/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 684377684513.1345 - val_loss: 715669073674.5857\n",
      "Epoch 690/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 685000533217.3146 - val_loss: 719306529693.7766\n",
      "Epoch 691/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 684696523934.4694 - val_loss: 731849156668.4895\n",
      "Epoch 692/7000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 685442594503.6714 - val_loss: 754347474519.9978\n",
      "Epoch 693/7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 89us/step - loss: 685312800381.9111 - val_loss: 727974671537.7238\n",
      "Epoch 694/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 681756444255.9460 - val_loss: 723600612299.8639\n",
      "Epoch 695/7000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 683127660419.5295 - val_loss: 710929406495.2529\n",
      "Epoch 696/7000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 684404559233.5127 - val_loss: 713839869140.8652\n",
      "Epoch 697/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 685574040044.1193 - val_loss: 751416287787.3508\n",
      "Epoch 698/7000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 686883841885.4969 - val_loss: 722438365739.3508\n",
      "Epoch 699/7000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 683238550586.2015 - val_loss: 718948360392.4794\n",
      "Epoch 700/7000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 681277510109.1368 - val_loss: 710388674028.8450\n",
      "Epoch 701/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 683051039320.4547 - val_loss: 735813324653.6731\n",
      "Epoch 702/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 684224548990.7754 - val_loss: 752909016320.6481\n",
      "Epoch 703/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 686249637335.9506 - val_loss: 715884114840.5918\n",
      "Epoch 704/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 682905204091.7501 - val_loss: 737779671369.5234\n",
      "Epoch 705/7000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 686324394803.4305 - val_loss: 731113522571.4858\n",
      "Epoch 706/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 682885062577.6298 - val_loss: 723612243842.9885\n",
      "Epoch 707/7000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 682438235584.9004 - val_loss: 730919429273.5280\n",
      "Epoch 708/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 685458744536.0945 - val_loss: 731071839758.2582\n",
      "Epoch 709/7000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 684332222296.8870 - val_loss: 722066755548.2825\n",
      "Epoch 710/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 687213691543.8424 - val_loss: 715929864572.7955\n",
      "Epoch 711/7000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 683594944472.8148 - val_loss: 770336447514.2120\n",
      "Epoch 712/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 687237988951.3021 - val_loss: 717006817974.1885\n",
      "Epoch 713/7000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 688520317452.3895 - val_loss: 798691299988.1991\n",
      "Epoch 714/7000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 693438192737.3867 - val_loss: 729081561488.9586\n",
      "Epoch 715/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 688789394475.2189 - val_loss: 714444258705.8228\n",
      "Epoch 716/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 681732119833.7872 - val_loss: 723850522673.5437\n",
      "Epoch 717/7000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 684732715558.8971 - val_loss: 746985049154.5385\n",
      "Epoch 718/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 683155725630.6675 - val_loss: 721367600853.5853\n",
      "Epoch 719/7000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 682982784977.8999 - val_loss: 729701471527.2461\n",
      "Epoch 720/7000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 683286832344.0945 - val_loss: 712070110165.0813\n",
      "Epoch 721/7000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 680275327751.6354 - val_loss: 711020350018.9705\n",
      "Epoch 722/7000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 681397555677.1368 - val_loss: 716385744105.0284\n",
      "Epoch 723/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 687138571327.9640 - val_loss: 744868437147.2562\n",
      "Epoch 724/7000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 684091070838.5638 - val_loss: 718526276199.2642\n",
      "Epoch 725/7000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 683523714272.1621 - val_loss: 721908313815.8898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff03e519518>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile model\n",
    "model22.compile(loss='mean_squared_error', optimizer='nadam')\n",
    "print(\"model22 loss:\",model22.loss)\n",
    "\n",
    "model_train22 = model22.fit(predictors,target, epochs=7000, validation_split=0.5, callbacks=[early_stopping_monitor], verbose=True)\n",
    "model_train22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff03d85f400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the plot\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(model_train22.history['val_loss'], 'r',\n",
    "         )\n",
    "plt.title(\"Nadam only\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.savefig(\"Nadam graph for 7000 epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model22.save(\"nadam_7000_epochs_only.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
