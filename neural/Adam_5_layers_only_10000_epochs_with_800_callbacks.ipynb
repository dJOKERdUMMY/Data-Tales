{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#the less hidden layes didn't work out as per the graph above so using more hidden layers\n",
    "#as per above diagram using only adam and nadam\n",
    "#importing pandas to visualise the dataset in tabular format\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 150)\n",
    "\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#introducing stable analysis through random seed\n",
    "np.random.seed(42)\n",
    "#importing time function to create animated behaviour\n",
    "import time\n",
    "#importing regExp for data cleaning\n",
    "import re\n",
    "from numpy import NaN\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(patience=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/scaled_train.csv\")\n",
    "test = pd.read_csv(\"../data/scaled_test.csv\")\n",
    "\n",
    "X_train = df.drop(['PRT_ID','SALES_PRICE'],axis=1)\n",
    "y_train = df['SALES_PRICE']\n",
    "\n",
    "X_test = test.drop(['PRT_ID'],axis=1)\n",
    "\n",
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Specify the model\n",
    "predictors = X_train.values\n",
    "target = y_train.values.reshape((-1,1)).astype('int32')\n",
    "\n",
    "n_cols = predictors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model 2\n",
    "model22 = Sequential()\n",
    "model22.add(Dense(150, activation='relu', input_shape=(n_cols,)))\n",
    "model22.add(Dense(100, kernel_initializer='normal', activation='relu'))\n",
    "model22.add(Dense(70, kernel_initializer='normal', activation='relu'))\n",
    "model22.add(Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "model22.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model22.add(Dense(1, kernel_initializer='normal'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model22 loss: mean_squared_error\n",
      "Train on 3554 samples, validate on 3555 samples\n",
      "Epoch 1/10000\n",
      "3554/3554 [==============================] - 1s 151us/step - loss: 133260583222198.8281 - val_loss: 130149386830400.0938\n",
      "Epoch 2/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 73735279023792.6250 - val_loss: 8646029534462.9199\n",
      "Epoch 3/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 7211598344083.6650 - val_loss: 6163082042237.5156\n",
      "Epoch 4/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 5727568582643.3232 - val_loss: 5316004596830.1904\n",
      "Epoch 5/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 4897981991445.6094 - val_loss: 4708520000457.5596\n",
      "Epoch 6/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 4408694326548.0244 - val_loss: 4357196756555.8999\n",
      "Epoch 7/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 4072280766769.4136 - val_loss: 4114923436600.6011\n",
      "Epoch 8/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 3843858507567.3965 - val_loss: 3929763523980.0620\n",
      "Epoch 9/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 3661915519677.8750 - val_loss: 3788562633806.6362\n",
      "Epoch 10/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 3503841854666.2642 - val_loss: 3742638765648.5088\n",
      "Epoch 11/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 3383784336064.1802 - val_loss: 3552279873815.4038\n",
      "Epoch 12/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 3253080210395.6963 - val_loss: 3414518773277.8125\n",
      "Epoch 13/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 3135191697545.1479 - val_loss: 3384281814670.7261\n",
      "Epoch 14/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 3034319933336.2744 - val_loss: 3231234717734.5981\n",
      "Epoch 15/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 2925433967889.7197 - val_loss: 3082096640562.2637\n",
      "Epoch 16/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 2830749539240.9858 - val_loss: 3061773353711.2212\n",
      "Epoch 17/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2723582917577.2559 - val_loss: 2937050934631.1919\n",
      "Epoch 18/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 2628986215595.1470 - val_loss: 2780684940170.7656\n",
      "Epoch 19/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 2543446794087.8696 - val_loss: 2679374398983.9214\n",
      "Epoch 20/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2447524321580.8037 - val_loss: 2612130548779.4946\n",
      "Epoch 21/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2369127737126.1768 - val_loss: 2497933262880.2612\n",
      "Epoch 22/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 2274458619265.5127 - val_loss: 2470992909860.7256\n",
      "Epoch 23/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 2205414272538.7959 - val_loss: 2319382370782.7310\n",
      "Epoch 24/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 2133282073658.2014 - val_loss: 2227993949025.2871\n",
      "Epoch 25/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 2065148148506.0754 - val_loss: 2155050328006.3911\n",
      "Epoch 26/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1978760612493.4700 - val_loss: 2084780754900.7932\n",
      "Epoch 27/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1905238317347.5835 - val_loss: 2009790477637.2029\n",
      "Epoch 28/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1856207790038.5098 - val_loss: 1973579671612.4895\n",
      "Epoch 29/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1789449726711.5002 - val_loss: 1873693015114.6038\n",
      "Epoch 30/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1740379834099.4666 - val_loss: 1803581137847.7007\n",
      "Epoch 31/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 1667215697213.5149 - val_loss: 1753757555005.4255\n",
      "Epoch 32/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 1624681379066.6697 - val_loss: 1691098375948.3140\n",
      "Epoch 33/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1552091215688.7520 - val_loss: 1627740300377.0059\n",
      "Epoch 34/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 1516897419310.1001 - val_loss: 1606786979880.9023\n",
      "Epoch 35/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1470321373822.4873 - val_loss: 1526547015169.0081\n",
      "Epoch 36/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1424308472507.5701 - val_loss: 1475268854889.1365\n",
      "Epoch 37/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1367606622006.3118 - val_loss: 1450411204057.2581\n",
      "Epoch 38/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1320363975195.3721 - val_loss: 1374701085637.5269\n",
      "Epoch 39/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1284579009650.6741 - val_loss: 1344024584323.3486\n",
      "Epoch 40/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1240029391570.6201 - val_loss: 1297981211684.0056\n",
      "Epoch 41/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 1221880924499.9888 - val_loss: 1320272538089.1003\n",
      "Epoch 42/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 1182593138494.3794 - val_loss: 1239069022106.0320\n",
      "Epoch 43/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1144135099469.7939 - val_loss: 1201827367947.2336\n",
      "Epoch 44/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1124103561690.8318 - val_loss: 1180845441162.2617\n",
      "Epoch 45/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1094997024744.9500 - val_loss: 1169614101041.6877\n",
      "Epoch 46/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1074996205020.5604 - val_loss: 1129592498950.8411\n",
      "Epoch 47/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 1049248620050.7281 - val_loss: 1259726742759.8762\n",
      "Epoch 48/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1053179435306.4985 - val_loss: 1082278398424.9698\n",
      "Epoch 49/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1014161980121.5352 - val_loss: 1108932973669.6799\n",
      "Epoch 50/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1006065188550.5188 - val_loss: 1054271714661.4639\n",
      "Epoch 51/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 988952810124.3174 - val_loss: 1046427468402.7859\n",
      "Epoch 52/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 989894509226.2825 - val_loss: 1046608248546.2594\n",
      "Epoch 53/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 965233505383.1492 - val_loss: 1021802152406.0895\n",
      "Epoch 54/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 952792653367.6083 - val_loss: 1042862534982.0669\n",
      "Epoch 55/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 939437860858.2374 - val_loss: 1014018297119.7570\n",
      "Epoch 56/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 948757787732.7091 - val_loss: 1068278593348.7708\n",
      "Epoch 57/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 919843479381.4294 - val_loss: 989155502845.6237\n",
      "Epoch 58/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 922816035563.9752 - val_loss: 1023128682731.0447\n",
      "Epoch 59/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 928203503912.1936 - val_loss: 959744506982.2560\n",
      "Epoch 60/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 905667250967.7704 - val_loss: 954963462363.4902\n",
      "Epoch 61/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 891723571130.8497 - val_loss: 963866690964.7032\n",
      "Epoch 62/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 917765801171.4845 - val_loss: 946458558196.6942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 896031231278.5323 - val_loss: 937583851655.3811\n",
      "Epoch 64/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 880734712418.8271 - val_loss: 937410658940.0034\n",
      "Epoch 65/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 875248243598.4784 - val_loss: 953096013435.1393\n",
      "Epoch 66/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 881875345043.8086 - val_loss: 931403584235.7649\n",
      "Epoch 67/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 880731265795.0253 - val_loss: 921422049942.5035\n",
      "Epoch 68/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 867500570007.4103 - val_loss: 919914308687.7885\n",
      "Epoch 69/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 877434773185.9089 - val_loss: 915020090420.7123\n",
      "Epoch 70/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 864533153182.3252 - val_loss: 923702548682.2076\n",
      "Epoch 71/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 866896974891.2189 - val_loss: 913932118011.9674\n",
      "Epoch 72/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 858372069566.1632 - val_loss: 924256808129.2782\n",
      "Epoch 73/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 855313195980.7136 - val_loss: 921346384842.1356\n",
      "Epoch 74/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 844487997948.2544 - val_loss: 895560210412.9890\n",
      "Epoch 75/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 841776458616.5807 - val_loss: 896796581802.7386\n",
      "Epoch 76/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 842545387507.3224 - val_loss: 910091560121.7891\n",
      "Epoch 77/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 846116215232.3241 - val_loss: 915468043839.2258\n",
      "Epoch 78/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 843513693653.6455 - val_loss: 936079731969.8003\n",
      "Epoch 79/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 833789892512.3420 - val_loss: 889582200104.3983\n",
      "Epoch 80/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 841328047990.8519 - val_loss: 899459755957.1083\n",
      "Epoch 81/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 831343651003.8582 - val_loss: 878190550816.4771\n",
      "Epoch 82/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 831687201180.5964 - val_loss: 880306530986.6666\n",
      "Epoch 83/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 828624960288.4142 - val_loss: 873742019491.5376\n",
      "Epoch 84/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 831045711808.6122 - val_loss: 888392680373.3964\n",
      "Epoch 85/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 825296559754.5886 - val_loss: 909786240156.9845\n",
      "Epoch 86/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 831362311430.1947 - val_loss: 869743431086.6273\n",
      "Epoch 87/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 812874774556.8126 - val_loss: 875337673778.4078\n",
      "Epoch 88/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 816508204725.2313 - val_loss: 867024077002.7837\n",
      "Epoch 89/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 822163208506.6337 - val_loss: 861439478583.2327\n",
      "Epoch 90/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 815804465142.7799 - val_loss: 886946384870.3640\n",
      "Epoch 91/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 816657179596.7136 - val_loss: 859104365809.6698\n",
      "Epoch 92/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 811025879849.0580 - val_loss: 856251022829.9972\n",
      "Epoch 93/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 808338912239.2887 - val_loss: 863361974009.3030\n",
      "Epoch 94/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 811856873258.7867 - val_loss: 864666222610.4349\n",
      "Epoch 95/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 805817448633.5531 - val_loss: 854680012337.3997\n",
      "Epoch 96/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 818304372337.2335 - val_loss: 852560381572.3567\n",
      "Epoch 97/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 806235422784.5402 - val_loss: 851893493836.0438\n",
      "Epoch 98/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 801014767878.7710 - val_loss: 846886564571.6343\n",
      "Epoch 99/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 795894604001.8909 - val_loss: 926921446400.2881\n",
      "Epoch 100/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 816310363370.5345 - val_loss: 856381406158.1682\n",
      "Epoch 101/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 799978753787.5341 - val_loss: 844955869319.9573\n",
      "Epoch 102/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 799691946252.5334 - val_loss: 858494645550.1592\n",
      "Epoch 103/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 796577981988.0157 - val_loss: 892812608589.4841\n",
      "Epoch 104/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 806710345986.1610 - val_loss: 857471741605.1938\n",
      "Epoch 105/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 794118780947.5925 - val_loss: 857257026755.0065\n",
      "Epoch 106/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 789550733953.9448 - val_loss: 842227185048.1598\n",
      "Epoch 107/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 796017613524.9252 - val_loss: 838587047703.2596\n",
      "Epoch 108/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 786739242910.0371 - val_loss: 855276263225.2489\n",
      "Epoch 109/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 791018337549.1096 - val_loss: 832852166036.7032\n",
      "Epoch 110/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 798212744574.0552 - val_loss: 841496444195.2135\n",
      "Epoch 111/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 787316637234.9983 - val_loss: 832819680348.4624\n",
      "Epoch 112/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 779868743047.2751 - val_loss: 867134619624.9564\n",
      "Epoch 113/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 795717414794.4446 - val_loss: 828105141017.2760\n",
      "Epoch 114/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 790568694499.9077 - val_loss: 826714088288.1350\n",
      "Epoch 115/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 780034051134.8114 - val_loss: 830744177709.7992\n",
      "Epoch 116/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 788241827350.1858 - val_loss: 838168287125.4233\n",
      "Epoch 117/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 786997950824.7339 - val_loss: 831531588196.3837\n",
      "Epoch 118/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 778035241121.3506 - val_loss: 840074742214.5350\n",
      "Epoch 119/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 793808301400.0225 - val_loss: 823657917840.6707\n",
      "Epoch 120/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 774045284565.2133 - val_loss: 825196808457.5775\n",
      "Epoch 121/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 777003201676.0293 - val_loss: 818244690014.4788\n",
      "Epoch 122/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 777928144177.9899 - val_loss: 816464429986.9614\n",
      "Epoch 123/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 768366557120.6122 - val_loss: 829031779214.7983\n",
      "Epoch 124/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 776932707713.5127 - val_loss: 820211801104.9946\n",
      "Epoch 125/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 768846287352.7969 - val_loss: 817934366915.2946\n",
      "Epoch 126/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 780085973386.1565 - val_loss: 837641701438.7938\n",
      "Epoch 127/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 769680668258.2510 - val_loss: 815032745223.5612\n",
      "Epoch 128/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 763348624332.7136 - val_loss: 822982512940.7190\n",
      "Epoch 129/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 774876007394.6111 - val_loss: 810668397462.2875\n",
      "Epoch 130/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 770849199912.4817 - val_loss: 813796592462.2762\n",
      "Epoch 131/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 760521212908.9836 - val_loss: 806724587530.3696\n",
      "Epoch 132/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 756277708116.5649 - val_loss: 893585354727.8042\n",
      "Epoch 133/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 778157249809.7197 - val_loss: 848085218122.2437\n",
      "Epoch 134/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 758359140622.8385 - val_loss: 829823446813.0205\n",
      "Epoch 135/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 764036482923.3269 - val_loss: 801594588331.3867\n",
      "Epoch 136/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 755859238680.9230 - val_loss: 810054589221.9500\n",
      "Epoch 137/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 759924203681.3506 - val_loss: 886456672769.8723\n",
      "Epoch 138/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 776943776105.8864 - val_loss: 846637676624.0765\n",
      "Epoch 139/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 789662809572.6281 - val_loss: 809501872949.5044\n",
      "Epoch 140/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 752844920819.3224 - val_loss: 812668833470.5417\n",
      "Epoch 141/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 755250921158.5188 - val_loss: 840318456449.7643\n",
      "Epoch 142/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 748954955727.5947 - val_loss: 803816924405.7024\n",
      "Epoch 143/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 760122682555.2819 - val_loss: 858050769761.2872\n",
      "Epoch 144/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 761737830810.2915 - val_loss: 794179036958.7488\n",
      "Epoch 145/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 751459567716.2678 - val_loss: 801505818745.5551\n",
      "Epoch 146/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 744016174205.0466 - val_loss: 805187011232.8732\n",
      "Epoch 147/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 753086021088.0179 - val_loss: 789617022514.5519\n",
      "Epoch 148/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 745384679273.0220 - val_loss: 814918195503.5995\n",
      "Epoch 149/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 741576708739.0973 - val_loss: 794619834841.5460\n",
      "Epoch 150/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 745639996764.6326 - val_loss: 793493909913.0239\n",
      "Epoch 151/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 737254324345.0129 - val_loss: 792869558912.0360\n",
      "Epoch 152/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 739235435507.8988 - val_loss: 785342562004.4332\n",
      "Epoch 153/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 743300747031.1942 - val_loss: 829237650272.1350\n",
      "Epoch 154/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 737167650680.0045 - val_loss: 783817537989.3828\n",
      "Epoch 155/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 739568799345.2335 - val_loss: 783718745607.9213\n",
      "Epoch 156/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 744930680200.4277 - val_loss: 807126466831.9144\n",
      "Epoch 157/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 738189114064.3151 - val_loss: 780018192942.8074\n",
      "Epoch 158/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 741520430095.5587 - val_loss: 787759395713.5482\n",
      "Epoch 159/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 735601193165.1458 - val_loss: 778483909543.5702\n",
      "Epoch 160/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 731697240899.5656 - val_loss: 777180448019.6591\n",
      "Epoch 161/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 735275190768.7294 - val_loss: 808684410294.1165\n",
      "Epoch 162/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 738400043413.6815 - val_loss: 798236097767.3002\n",
      "Epoch 163/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 733033948998.4469 - val_loss: 780264798122.1626\n",
      "Epoch 164/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 726081503010.7192 - val_loss: 778795045256.8934\n",
      "Epoch 165/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 728639121107.1964 - val_loss: 810487127407.2573\n",
      "Epoch 166/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 748009739132.0382 - val_loss: 771237481520.1035\n",
      "Epoch 167/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 739887115331.4215 - val_loss: 781528920897.0261\n",
      "Epoch 168/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 728773211229.9291 - val_loss: 774108851757.3671\n",
      "Epoch 169/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 727548890691.1334 - val_loss: 782220228171.8999\n",
      "Epoch 170/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 724774936686.6405 - val_loss: 783920066867.6321\n",
      "Epoch 171/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 728030271825.6837 - val_loss: 764779096470.1434\n",
      "Epoch 172/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 720129009630.5774 - val_loss: 852907086267.5894\n",
      "Epoch 173/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 734611753097.1481 - val_loss: 868527761818.7522\n",
      "Epoch 174/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 723966138253.9021 - val_loss: 765402049093.2748\n",
      "Epoch 175/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 718473612267.8312 - val_loss: 762749617261.7451\n",
      "Epoch 176/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 712699175709.5330 - val_loss: 769663949098.9907\n",
      "Epoch 177/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 727250732870.4469 - val_loss: 774738819686.6880\n",
      "Epoch 178/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 720548598864.0990 - val_loss: 768779752535.8538\n",
      "Epoch 179/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 713893713178.9398 - val_loss: 764165645981.7046\n",
      "Epoch 180/10000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 714396290507.2729 - val_loss: 773998329680.8687\n",
      "Epoch 181/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 722946973350.2488 - val_loss: 760485631238.9851\n",
      "Epoch 182/10000\n",
      "3554/3554 [==============================] - 0s 134us/step - loss: 717780613330.9083 - val_loss: 807397771815.3181\n",
      "Epoch 183/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 722311775572.5649 - val_loss: 766826941488.1035\n",
      "Epoch 184/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 719624377368.7788 - val_loss: 765157769787.4813\n",
      "Epoch 185/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 722500929569.4226 - val_loss: 760510458506.4056\n",
      "Epoch 186/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 706243575116.4974 - val_loss: 763066504155.4183\n",
      "Epoch 187/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 722919370044.3623 - val_loss: 759710538054.6431\n",
      "Epoch 188/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 715661685374.4873 - val_loss: 822206455165.0835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 712927741305.4452 - val_loss: 763694790597.8149\n",
      "Epoch 190/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 707488990133.6636 - val_loss: 753202807493.7429\n",
      "Epoch 191/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 713440708528.4772 - val_loss: 755323963487.0548\n",
      "Epoch 192/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 708707118940.3444 - val_loss: 757997523567.3293\n",
      "Epoch 193/10000\n",
      "3554/3554 [==============================] - 1s 146us/step - loss: 709643300257.7827 - val_loss: 768022753808.8506\n",
      "Epoch 194/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 708179630666.6246 - val_loss: 750540736708.4467\n",
      "Epoch 195/10000\n",
      "3554/3554 [==============================] - 1s 179us/step - loss: 707303825043.8086 - val_loss: 820925107192.7988\n",
      "Epoch 196/10000\n",
      "3554/3554 [==============================] - 1s 195us/step - loss: 725518371349.6094 - val_loss: 789572554601.0645\n",
      "Epoch 197/10000\n",
      "3554/3554 [==============================] - 1s 166us/step - loss: 706471625386.2825 - val_loss: 779904067773.5336\n",
      "Epoch 198/10000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 715716393993.7963 - val_loss: 750089355817.0464\n",
      "Epoch 199/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 701370661132.5334 - val_loss: 748430817581.2950\n",
      "Epoch 200/10000\n",
      "3554/3554 [==============================] - 1s 169us/step - loss: 694653707406.3342 - val_loss: 795936486499.3755\n",
      "Epoch 201/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 711065539239.4012 - val_loss: 758375052889.7261\n",
      "Epoch 202/10000\n",
      "3554/3554 [==============================] - 1s 144us/step - loss: 703042632575.4957 - val_loss: 764546737213.3536\n",
      "Epoch 203/10000\n",
      "3554/3554 [==============================] - 1s 151us/step - loss: 696266911377.5037 - val_loss: 786981136730.2301\n",
      "Epoch 204/10000\n",
      "3554/3554 [==============================] - 1s 172us/step - loss: 701442291584.0720 - val_loss: 745511068871.6152\n",
      "Epoch 205/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 701704541577.5802 - val_loss: 747474764771.4835\n",
      "Epoch 206/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 700874734002.4941 - val_loss: 743420927624.3893\n",
      "Epoch 207/10000\n",
      "3554/3554 [==============================] - 0s 137us/step - loss: 695339474911.7299 - val_loss: 747206217079.3226\n",
      "Epoch 208/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 695954192375.9325 - val_loss: 758284793083.4633\n",
      "Epoch 209/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 707233496212.0967 - val_loss: 740684866022.2200\n",
      "Epoch 210/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 703329934042.6877 - val_loss: 806471470976.1080\n",
      "Epoch 211/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 692131089673.6522 - val_loss: 744012584858.0321\n",
      "Epoch 212/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 693243609936.2432 - val_loss: 787006810250.8376\n",
      "Epoch 213/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 703940134671.1267 - val_loss: 740681463832.7719\n",
      "Epoch 214/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 694458151541.2673 - val_loss: 770064567763.4971\n",
      "Epoch 215/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 700905146237.7670 - val_loss: 783021606509.3131\n",
      "Epoch 216/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 700938764629.1414 - val_loss: 737630525854.2087\n",
      "Epoch 217/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 687611400051.3945 - val_loss: 742682215874.7904\n",
      "Epoch 218/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 687441792053.5914 - val_loss: 739828298482.6780\n",
      "Epoch 219/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 683350656543.4058 - val_loss: 759853501713.9308\n",
      "Epoch 220/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 686855698405.4924 - val_loss: 752349484078.3752\n",
      "Epoch 221/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 700230931222.6178 - val_loss: 748024005663.3969\n",
      "Epoch 222/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 689510575263.6218 - val_loss: 731398909360.9316\n",
      "Epoch 223/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 699401153575.7614 - val_loss: 746233087025.8318\n",
      "Epoch 224/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 681342549084.7766 - val_loss: 746831156463.9415\n",
      "Epoch 225/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 694220432019.2324 - val_loss: 740035314028.0889\n",
      "Epoch 226/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 694791131677.6770 - val_loss: 742382618124.5299\n",
      "Epoch 227/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 705541089274.2374 - val_loss: 769742469375.2079\n",
      "Epoch 228/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 680417391285.8075 - val_loss: 733270248763.4093\n",
      "Epoch 229/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 682481610422.3839 - val_loss: 739823091085.2141\n",
      "Epoch 230/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 677767423090.6742 - val_loss: 739978344776.9474\n",
      "Epoch 231/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 685532926275.8536 - val_loss: 726366809894.2379\n",
      "Epoch 232/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 683621043917.4340 - val_loss: 725152689501.9747\n",
      "Epoch 233/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 677164335334.5009 - val_loss: 727579629502.9019\n",
      "Epoch 234/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 681679072904.2836 - val_loss: 725622297872.2025\n",
      "Epoch 235/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 684567087167.3878 - val_loss: 728296963840.2161\n",
      "Epoch 236/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 677014496951.5363 - val_loss: 825368955376.0135\n",
      "Epoch 237/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 684277316184.4547 - val_loss: 722856748402.1378\n",
      "Epoch 238/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 691443072544.5582 - val_loss: 724423001704.7043\n",
      "Epoch 239/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 676263932468.7271 - val_loss: 722570407349.5404\n",
      "Epoch 240/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 679393346651.6240 - val_loss: 721473080077.7542\n",
      "Epoch 241/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 674155490044.1102 - val_loss: 726259881508.7257\n",
      "Epoch 242/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 671708044449.9269 - val_loss: 722785932020.9823\n",
      "Epoch 243/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 679596855846.8971 - val_loss: 820408455030.8906\n",
      "Epoch 244/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 684810950790.8429 - val_loss: 747498786936.9789\n",
      "Epoch 245/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 678811749798.3928 - val_loss: 720800976662.1074\n",
      "Epoch 246/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 669685179626.5345 - val_loss: 719098659322.9592\n",
      "Epoch 247/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 669814684276.1147 - val_loss: 719296637000.0112\n",
      "Epoch 248/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 673576737622.0056 - val_loss: 805779200206.8163\n",
      "Epoch 249/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 678371507938.1790 - val_loss: 761656646050.8174\n",
      "Epoch 250/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 680555055490.0889 - val_loss: 716602005535.6849\n",
      "Epoch 251/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 668484016290.5031 - val_loss: 764022655366.0129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 252/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 683660439429.8345 - val_loss: 732103153465.2489\n",
      "Epoch 253/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 670775161876.1688 - val_loss: 737597107545.3660\n",
      "Epoch 254/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 676434633243.3719 - val_loss: 717854001661.8397\n",
      "Epoch 255/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 667828349484.6595 - val_loss: 721463203567.5094\n",
      "Epoch 256/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 662230625292.1012 - val_loss: 714858244313.1859\n",
      "Epoch 257/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 662704169471.7119 - val_loss: 716018015861.9545\n",
      "Epoch 258/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 668787771925.6094 - val_loss: 713920020042.1716\n",
      "Epoch 259/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 666236842705.4677 - val_loss: 719443088720.7246\n",
      "Epoch 260/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 672101672050.6742 - val_loss: 716104642015.0188\n",
      "Epoch 261/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 667105637225.5981 - val_loss: 762875021570.6644\n",
      "Epoch 262/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 666018045255.8876 - val_loss: 714452989732.5098\n",
      "Epoch 263/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 662457725234.5660 - val_loss: 713931176380.1654\n",
      "Epoch 264/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 662628784152.2026 - val_loss: 737556238129.7598\n",
      "Epoch 265/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 673923297798.6270 - val_loss: 748194081897.7125\n",
      "Epoch 266/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 671771071494.3387 - val_loss: 747463212014.4292\n",
      "Epoch 267/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 664236622100.6010 - val_loss: 714815457333.5764\n",
      "Epoch 268/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 658526151596.4435 - val_loss: 711844822844.1294\n",
      "Epoch 269/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 655697021784.3105 - val_loss: 752248405739.4768\n",
      "Epoch 270/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 670838338469.5284 - val_loss: 728889743327.1628\n",
      "Epoch 271/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 652744263752.6077 - val_loss: 702050827569.0397\n",
      "Epoch 272/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 651317236327.4373 - val_loss: 704164774828.1790\n",
      "Epoch 273/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 656817532679.0591 - val_loss: 740316859168.1891\n",
      "Epoch 274/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 647865249305.6433 - val_loss: 697321083095.4576\n",
      "Epoch 275/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 653713464758.5278 - val_loss: 696882233122.7815\n",
      "Epoch 276/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 647439559166.5593 - val_loss: 704163127607.0886\n",
      "Epoch 277/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 639066554672.2611 - val_loss: 717644961035.5939\n",
      "Epoch 278/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 637669137636.7721 - val_loss: 686079529465.8070\n",
      "Epoch 279/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 644463495830.6899 - val_loss: 715624858609.3097\n",
      "Epoch 280/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 643082113325.9562 - val_loss: 684328291906.1063\n",
      "Epoch 281/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 638463338130.6562 - val_loss: 685286637512.6953\n",
      "Epoch 282/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 624432453785.2831 - val_loss: 688792615199.4689\n",
      "Epoch 283/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 625706860636.2003 - val_loss: 669702640826.9412\n",
      "Epoch 284/10000\n",
      "3554/3554 [==============================] - 0s 135us/step - loss: 619592056324.8981 - val_loss: 702473646862.3302\n",
      "Epoch 285/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 616506775133.6410 - val_loss: 693381957284.6177\n",
      "Epoch 286/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 613338366164.0608 - val_loss: 661683345066.3787\n",
      "Epoch 287/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 615162510696.1576 - val_loss: 693896569622.3955\n",
      "Epoch 288/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 612648922225.5216 - val_loss: 671453259023.0503\n",
      "Epoch 289/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 600193032122.8497 - val_loss: 653790280241.6877\n",
      "Epoch 290/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 591928179989.1772 - val_loss: 684591913752.1238\n",
      "Epoch 291/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 601600375052.5334 - val_loss: 638421444375.8357\n",
      "Epoch 292/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 592976569560.0946 - val_loss: 635585176628.1361\n",
      "Epoch 293/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 587657242060.4254 - val_loss: 631551336328.1732\n",
      "Epoch 294/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 575525433461.5554 - val_loss: 621468751339.1167\n",
      "Epoch 295/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 579563711366.4108 - val_loss: 613964503313.6427\n",
      "Epoch 296/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 566949138196.8892 - val_loss: 611945144697.9150\n",
      "Epoch 297/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 565199891634.0619 - val_loss: 631963059434.1805\n",
      "Epoch 298/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 556173265088.4683 - val_loss: 622548150496.0990\n",
      "Epoch 299/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 557319400856.5627 - val_loss: 598085985797.6168\n",
      "Epoch 300/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 547052522853.8526 - val_loss: 589154261846.3414\n",
      "Epoch 301/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 541185474596.8801 - val_loss: 592206851590.1930\n",
      "Epoch 302/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 536634123092.8531 - val_loss: 574264155703.7367\n",
      "Epoch 303/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 527678997715.4846 - val_loss: 570787524620.6740\n",
      "Epoch 304/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 534282372694.7260 - val_loss: 584288448870.3280\n",
      "Epoch 305/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 521181888770.1609 - val_loss: 577830543913.0464\n",
      "Epoch 306/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 520690764955.0118 - val_loss: 548210534988.1879\n",
      "Epoch 307/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 502443804209.8458 - val_loss: 549179258752.6841\n",
      "Epoch 308/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 501621652563.5565 - val_loss: 562957520263.4531\n",
      "Epoch 309/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 499229330822.1227 - val_loss: 530673885061.8689\n",
      "Epoch 310/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 491589405758.8115 - val_loss: 558839517330.3269\n",
      "Epoch 311/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 493015752837.6906 - val_loss: 528737599656.2183\n",
      "Epoch 312/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 481832122691.8537 - val_loss: 515927165933.2771\n",
      "Epoch 313/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 473689430897.6657 - val_loss: 522837166140.4894\n",
      "Epoch 314/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 477245888923.4440 - val_loss: 564074498435.7086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 315/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 473826765494.9601 - val_loss: 527266022742.4855\n",
      "Epoch 316/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 464940161509.2043 - val_loss: 582932802974.4967\n",
      "Epoch 317/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 461184473822.1452 - val_loss: 521450858254.6183\n",
      "Epoch 318/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 461444621795.4755 - val_loss: 536844408485.7699\n",
      "Epoch 319/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 447632134685.6769 - val_loss: 490706830482.6149\n",
      "Epoch 320/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 443229011027.5565 - val_loss: 502062769215.6580\n",
      "Epoch 321/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 443374985460.3309 - val_loss: 477700722596.9778\n",
      "Epoch 322/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 437156687911.1851 - val_loss: 486850356250.7882\n",
      "Epoch 323/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 433156161665.0805 - val_loss: 485851953363.4250\n",
      "Epoch 324/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 428617973062.7350 - val_loss: 470601659945.3345\n",
      "Epoch 325/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 431649972744.9319 - val_loss: 479948795262.2357\n",
      "Epoch 326/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 440342686241.1345 - val_loss: 461590633355.3418\n",
      "Epoch 327/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 418647132896.4502 - val_loss: 459435735113.1635\n",
      "Epoch 328/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 413738159139.1514 - val_loss: 453651963821.0430\n",
      "Epoch 329/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 412975712125.7670 - val_loss: 454185660624.5446\n",
      "Epoch 330/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 409076322237.1547 - val_loss: 456619774384.0675\n",
      "Epoch 331/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 410415880990.6854 - val_loss: 450447388719.2394\n",
      "Epoch 332/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 404354781504.3962 - val_loss: 439222112088.9339\n",
      "Epoch 333/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 406575348524.5154 - val_loss: 478316473839.1494\n",
      "Epoch 334/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 423565815054.2622 - val_loss: 440749056488.5244\n",
      "Epoch 335/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 399211464149.6454 - val_loss: 446021133970.1829\n",
      "Epoch 336/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 398880307496.1936 - val_loss: 441164228108.5300\n",
      "Epoch 337/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 397803591418.3815 - val_loss: 442185216971.2878\n",
      "Epoch 338/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 397122233283.4935 - val_loss: 493611227347.4250\n",
      "Epoch 339/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 392712721949.1008 - val_loss: 421219957576.5153\n",
      "Epoch 340/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 392613122027.2549 - val_loss: 447601367020.9890\n",
      "Epoch 341/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 393915123959.7884 - val_loss: 465374291201.2242\n",
      "Epoch 342/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 390750555908.7541 - val_loss: 417392303994.3471\n",
      "Epoch 343/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 381364964986.4536 - val_loss: 417600581430.3685\n",
      "Epoch 344/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 385372532125.1727 - val_loss: 423829447054.6543\n",
      "Epoch 345/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 383750193271.8605 - val_loss: 434348213042.0478\n",
      "Epoch 346/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 386067449725.7670 - val_loss: 412394142331.4273\n",
      "Epoch 347/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 378601595290.2915 - val_loss: 416339563052.5029\n",
      "Epoch 348/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 375050208154.0034 - val_loss: 414925539932.3184\n",
      "Epoch 349/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 370892495101.5509 - val_loss: 412442147919.2124\n",
      "Epoch 350/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 374382714552.6888 - val_loss: 415608526734.5103\n",
      "Epoch 351/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 370824361957.4924 - val_loss: 404926019293.0745\n",
      "Epoch 352/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 376676946461.6769 - val_loss: 409003578856.8124\n",
      "Epoch 353/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 367304603968.3962 - val_loss: 405585130579.2450\n",
      "Epoch 354/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 370592525665.2426 - val_loss: 402030325634.4124\n",
      "Epoch 355/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 369184168458.0844 - val_loss: 432647980515.0515\n",
      "Epoch 356/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 368426358047.5498 - val_loss: 416417682386.2009\n",
      "Epoch 357/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 367534969272.2566 - val_loss: 395371825864.6234\n",
      "Epoch 358/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 363430080210.0439 - val_loss: 396211600914.8669\n",
      "Epoch 359/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 363496484783.3247 - val_loss: 446888674591.1808\n",
      "Epoch 360/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 358712141550.8565 - val_loss: 393353343398.8501\n",
      "Epoch 361/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 358834925989.8166 - val_loss: 409497273631.1808\n",
      "Epoch 362/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 361617107089.2156 - val_loss: 411356768268.0979\n",
      "Epoch 363/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 358426439119.8829 - val_loss: 401757580502.0175\n",
      "Epoch 364/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 367148758497.1705 - val_loss: 397425491518.6498\n",
      "Epoch 365/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 353655015929.9494 - val_loss: 391149365333.8374\n",
      "Epoch 366/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 355300530753.4046 - val_loss: 463703187285.4774\n",
      "Epoch 367/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 364902486935.6984 - val_loss: 395391310526.2537\n",
      "Epoch 368/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 357437215363.0974 - val_loss: 398246625770.8287\n",
      "Epoch 369/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 364584515269.3663 - val_loss: 438450133343.9910\n",
      "Epoch 370/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 355276256359.1491 - val_loss: 384889049255.0661\n",
      "Epoch 371/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 353737193537.6927 - val_loss: 384610895041.8543\n",
      "Epoch 372/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 348716308365.9020 - val_loss: 388777398570.4146\n",
      "Epoch 373/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 348291599109.3304 - val_loss: 380369301253.9769\n",
      "Epoch 374/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 350329091682.2510 - val_loss: 383242728319.2439\n",
      "Epoch 375/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 348821714963.5926 - val_loss: 388283900662.1345\n",
      "Epoch 376/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 363697474991.6129 - val_loss: 386988969410.2144\n",
      "Epoch 377/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 347313458838.1137 - val_loss: 410158055585.3052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 348400627022.8024 - val_loss: 388318881617.4447\n",
      "Epoch 379/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 344684159017.4902 - val_loss: 379072318945.3232\n",
      "Epoch 380/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 348356055756.8576 - val_loss: 377087150834.1018\n",
      "Epoch 381/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 350806590156.8576 - val_loss: 393382025798.4270\n",
      "Epoch 382/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 340949782018.5931 - val_loss: 381348752221.2546\n",
      "Epoch 383/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 342485354496.0000 - val_loss: 381296635161.9960\n",
      "Epoch 384/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 334732857475.3855 - val_loss: 388429794213.8419\n",
      "Epoch 385/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 343509469182.8475 - val_loss: 369481493622.3865\n",
      "Epoch 386/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 341245313660.1823 - val_loss: 386605774514.4439\n",
      "Epoch 387/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 347053866722.1789 - val_loss: 396980301432.2588\n",
      "Epoch 388/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 342848708013.3078 - val_loss: 370416780008.3083\n",
      "Epoch 389/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 337091266761.6883 - val_loss: 380899361845.2883\n",
      "Epoch 390/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 335156258883.9977 - val_loss: 368630290771.3170\n",
      "Epoch 391/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 336502504116.6550 - val_loss: 368771680640.2520\n",
      "Epoch 392/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 329021980130.3231 - val_loss: 375959618180.0687\n",
      "Epoch 393/10000\n",
      "3554/3554 [==============================] - 0s 139us/step - loss: 329862798627.0073 - val_loss: 389257562820.0146\n",
      "Epoch 394/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 343443435245.7040 - val_loss: 371069366131.4340\n",
      "Epoch 395/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 332061229544.6617 - val_loss: 385799009458.8760\n",
      "Epoch 396/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 332304529352.1036 - val_loss: 364805138211.3575\n",
      "Epoch 397/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 327892629357.6320 - val_loss: 362277972567.7097\n",
      "Epoch 398/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 337405639173.4744 - val_loss: 370429535591.7682\n",
      "Epoch 399/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 353568783074.7552 - val_loss: 363752446155.3598\n",
      "Epoch 400/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 323609014841.3371 - val_loss: 361274821904.7786\n",
      "Epoch 401/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 326161067919.0546 - val_loss: 362806013904.7606\n",
      "Epoch 402/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 329831554587.9482 - val_loss: 376914223761.8948\n",
      "Epoch 403/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 322652240500.1148 - val_loss: 361418870754.0433\n",
      "Epoch 404/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 326677207986.2060 - val_loss: 363957953819.7243\n",
      "Epoch 405/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 323457851940.5920 - val_loss: 356627169104.8687\n",
      "Epoch 406/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 328285205238.3478 - val_loss: 374035831475.8841\n",
      "Epoch 407/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 329500342927.7749 - val_loss: 355739162646.4675\n",
      "Epoch 408/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 332728945994.1925 - val_loss: 377225360091.6343\n",
      "Epoch 409/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 324752907398.2667 - val_loss: 363209339264.8281\n",
      "Epoch 410/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 335499958139.4620 - val_loss: 358134359935.5319\n",
      "Epoch 411/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 318345353756.5245 - val_loss: 355204034004.6492\n",
      "Epoch 412/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 321987092088.1486 - val_loss: 371224382524.7775\n",
      "Epoch 413/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 318040647028.8351 - val_loss: 357264673673.0374\n",
      "Epoch 414/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 314183089217.1165 - val_loss: 368918305539.3845\n",
      "Epoch 415/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 312036275303.1491 - val_loss: 390148782844.4714\n",
      "Epoch 416/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 304699991809.2966 - val_loss: 338033699257.2850\n",
      "Epoch 417/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 297158799482.1655 - val_loss: 343536291551.9550\n",
      "Epoch 418/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 297541949740.8036 - val_loss: 337438090451.1370\n",
      "Epoch 419/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 288687481998.3342 - val_loss: 311964867846.4090\n",
      "Epoch 420/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 283227541220.4839 - val_loss: 306159142814.6408\n",
      "Epoch 421/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 267833558580.1508 - val_loss: 338140471648.5671\n",
      "Epoch 422/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 261340354215.4012 - val_loss: 297058168719.0864\n",
      "Epoch 423/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 268984715769.9493 - val_loss: 290199493647.8425\n",
      "Epoch 424/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 255677175196.0202 - val_loss: 299387418056.5513\n",
      "Epoch 425/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 245546841891.8717 - val_loss: 273579255252.0732\n",
      "Epoch 426/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 242135007480.9409 - val_loss: 270790530819.0965\n",
      "Epoch 427/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 236784349048.0045 - val_loss: 276052970479.5814\n",
      "Epoch 428/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 235864912220.0563 - val_loss: 260368493439.8200\n",
      "Epoch 429/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 224851707168.7023 - val_loss: 272546558377.1544\n",
      "Epoch 430/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 225964553134.7484 - val_loss: 253155196010.2886\n",
      "Epoch 431/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 227952463593.0940 - val_loss: 247736868119.6917\n",
      "Epoch 432/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 216421326354.7282 - val_loss: 255978194131.1370\n",
      "Epoch 433/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 219705397397.8255 - val_loss: 246923841434.6082\n",
      "Epoch 434/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 220232279735.5363 - val_loss: 240569529188.7437\n",
      "Epoch 435/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 212492067812.9162 - val_loss: 236927578306.7184\n",
      "Epoch 436/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 212546943345.9539 - val_loss: 253118820804.8068\n",
      "Epoch 437/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 212369882057.2560 - val_loss: 232878792164.7798\n",
      "Epoch 438/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 212458536259.2774 - val_loss: 245413628282.4911\n",
      "Epoch 439/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 208476916734.2712 - val_loss: 233387720194.7364\n",
      "Epoch 440/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 206378086259.3945 - val_loss: 229513401931.8999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 204695384730.1474 - val_loss: 248998384919.1156\n",
      "Epoch 442/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 207701923458.5211 - val_loss: 230802607513.8880\n",
      "Epoch 443/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 201123084353.6927 - val_loss: 222404267738.1941\n",
      "Epoch 444/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 199073884569.1390 - val_loss: 293264703308.2599\n",
      "Epoch 445/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 209474050671.5048 - val_loss: 222088770970.4641\n",
      "Epoch 446/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 201374598337.0445 - val_loss: 227491245740.1069\n",
      "Epoch 447/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 197117784951.4283 - val_loss: 219068630148.7888\n",
      "Epoch 448/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 198507806176.0180 - val_loss: 235154595736.3038\n",
      "Epoch 449/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 206308342637.0557 - val_loss: 220175161685.6214\n",
      "Epoch 450/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 196466416917.1773 - val_loss: 212442777837.9252\n",
      "Epoch 451/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 193215874486.5278 - val_loss: 211069123285.2973\n",
      "Epoch 452/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 190290759495.5993 - val_loss: 208531621506.0523\n",
      "Epoch 453/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 189072014783.7479 - val_loss: 216643685636.1046\n",
      "Epoch 454/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 189387054306.4671 - val_loss: 203014522742.3145\n",
      "Epoch 455/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 181614140363.5611 - val_loss: 202090736326.3190\n",
      "Epoch 456/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 178740617360.6393 - val_loss: 197485511639.9617\n",
      "Epoch 457/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 177590249341.1908 - val_loss: 203907240358.8501\n",
      "Epoch 458/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 175670544797.7490 - val_loss: 191281858754.1423\n",
      "Epoch 459/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 177935855277.1638 - val_loss: 206846226922.8287\n",
      "Epoch 460/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 175767319673.5892 - val_loss: 211638857914.6532\n",
      "Epoch 461/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 174715313920.1440 - val_loss: 204760943721.7125\n",
      "Epoch 462/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 160580016290.5031 - val_loss: 179709130610.8579\n",
      "Epoch 463/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 162161639082.8588 - val_loss: 175677337451.3688\n",
      "Epoch 464/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 159405240064.1440 - val_loss: 178683808653.6461\n",
      "Epoch 465/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 157799191051.2369 - val_loss: 165671422391.5567\n",
      "Epoch 466/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 149144432697.6252 - val_loss: 161890711991.5567\n",
      "Epoch 467/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 147195721632.3422 - val_loss: 177860445282.2234\n",
      "Epoch 468/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 146911343352.6528 - val_loss: 163070389642.9097\n",
      "Epoch 469/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 144572750366.8295 - val_loss: 154601572642.9254\n",
      "Epoch 470/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 136468340503.1941 - val_loss: 151901092321.0352\n",
      "Epoch 471/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 133218881598.2352 - val_loss: 176575923791.3564\n",
      "Epoch 472/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 147095834732.3354 - val_loss: 145319845328.0405\n",
      "Epoch 473/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 129640510576.3692 - val_loss: 159792935162.0231\n",
      "Epoch 474/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 131714429019.0478 - val_loss: 141436648564.0821\n",
      "Epoch 475/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 123854108461.0917 - val_loss: 141564202822.4990\n",
      "Epoch 476/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 122425108307.4125 - val_loss: 135731610033.2197\n",
      "Epoch 477/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 121933107637.9516 - val_loss: 132389845398.1435\n",
      "Epoch 478/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 118938247774.2172 - val_loss: 189464039012.6717\n",
      "Epoch 479/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 120342050965.2493 - val_loss: 127994834147.8436\n",
      "Epoch 480/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 115281506911.9460 - val_loss: 135585727893.8554\n",
      "Epoch 481/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 110042929249.9629 - val_loss: 124651922507.1797\n",
      "Epoch 482/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 116149828977.3776 - val_loss: 122430588509.1826\n",
      "Epoch 483/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 108889755055.6128 - val_loss: 116990816029.0205\n",
      "Epoch 484/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 104473626410.7867 - val_loss: 121867667465.2174\n",
      "Epoch 485/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 104747081575.8694 - val_loss: 116262853863.3001\n",
      "Epoch 486/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 105342961432.3466 - val_loss: 145799270911.5679\n",
      "Epoch 487/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 102262891293.5329 - val_loss: 110333088722.2009\n",
      "Epoch 488/10000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 97707297053.767 - 0s 86us/step - loss: 98815358285.6500 - val_loss: 127794741559.0886\n",
      "Epoch 489/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 111568069221.1322 - val_loss: 115749754491.1392\n",
      "Epoch 490/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 101708876980.3669 - val_loss: 105836895583.1269\n",
      "Epoch 491/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 96637440487.5093 - val_loss: 106852632855.4037\n",
      "Epoch 492/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 91830118539.4530 - val_loss: 104071791693.4841\n",
      "Epoch 493/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 89514319120.5672 - val_loss: 103794434027.2608\n",
      "Epoch 494/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 88076031222.0596 - val_loss: 101146161479.2191\n",
      "Epoch 495/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 86484037117.9831 - val_loss: 119254558183.6602\n",
      "Epoch 496/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 90601739205.7985 - val_loss: 94977792101.3918\n",
      "Epoch 497/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 87769767129.2470 - val_loss: 97624130297.5910\n",
      "Epoch 498/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 82212894877.8931 - val_loss: 93575821634.0343\n",
      "Epoch 499/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 84130229988.4839 - val_loss: 89953151235.5285\n",
      "Epoch 500/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 83119775481.2290 - val_loss: 98009650318.8703\n",
      "Epoch 501/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 86102863256.5627 - val_loss: 89888898293.4144\n",
      "Epoch 502/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 84006604438.1137 - val_loss: 107580117377.9803\n",
      "Epoch 503/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 83124384143.3427 - val_loss: 91561947801.9601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 504/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 78443199654.5368 - val_loss: 89647536776.1013\n",
      "Epoch 505/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 81631098800.4772 - val_loss: 88585659020.1339\n",
      "Epoch 506/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 75898834275.5475 - val_loss: 84272766319.2574\n",
      "Epoch 507/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 75919335035.0298 - val_loss: 90691088960.6661\n",
      "Epoch 508/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 74303504559.1806 - val_loss: 82163950845.7677\n",
      "Epoch 509/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 74237087446.6539 - val_loss: 99209850517.0633\n",
      "Epoch 510/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 75569733101.8481 - val_loss: 86892084683.4318\n",
      "Epoch 511/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 72741779782.1587 - val_loss: 84528429078.4675\n",
      "Epoch 512/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 74712094356.9612 - val_loss: 78621559623.3631\n",
      "Epoch 513/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 70231957191.6714 - val_loss: 80578165763.1685\n",
      "Epoch 514/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 70187336300.0473 - val_loss: 78590117775.6624\n",
      "Epoch 515/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 71004988770.3951 - val_loss: 111879666316.7100\n",
      "Epoch 516/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 78038680584.6438 - val_loss: 86132971399.5972\n",
      "Epoch 517/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 74544961209.8413 - val_loss: 113916941651.0290\n",
      "Epoch 518/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 70618043980.3534 - val_loss: 75374496536.1238\n",
      "Epoch 519/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 69241125720.3106 - val_loss: 76016904364.2509\n",
      "Epoch 520/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 68682810289.0535 - val_loss: 75899093931.6028\n",
      "Epoch 521/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 68064029532.9207 - val_loss: 73661134008.6369\n",
      "Epoch 522/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 68753281881.4632 - val_loss: 79152398781.1736\n",
      "Epoch 523/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 66097101999.7569 - val_loss: 92680034781.0025\n",
      "Epoch 524/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 75527799553.8728 - val_loss: 79264108300.8900\n",
      "Epoch 525/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 68409693243.3540 - val_loss: 73448984682.0006\n",
      "Epoch 526/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 66874014200.7969 - val_loss: 73470611578.1311\n",
      "Epoch 527/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 67124910445.3438 - val_loss: 100847794339.0335\n",
      "Epoch 528/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 64574152799.9460 - val_loss: 73233718965.3243\n",
      "Epoch 529/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 63198230847.2437 - val_loss: 94762839978.7387\n",
      "Epoch 530/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 66007736575.8559 - val_loss: 99142013304.4748\n",
      "Epoch 531/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 70428719620.3219 - val_loss: 78448769996.0079\n",
      "Epoch 532/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 65283218520.1666 - val_loss: 71357192499.6321\n",
      "Epoch 533/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 62384825449.4541 - val_loss: 71501642585.2219\n",
      "Epoch 534/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 62034051277.1458 - val_loss: 80633166829.9972\n",
      "Epoch 535/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 64509035067.6421 - val_loss: 85761764979.9381\n",
      "Epoch 536/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 66387372766.1452 - val_loss: 71758982069.9724\n",
      "Epoch 537/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 65749502984.9319 - val_loss: 67585487563.5038\n",
      "Epoch 538/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 62940244653.7400 - val_loss: 71895413786.7882\n",
      "Epoch 539/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 62079679271.9055 - val_loss: 92293118674.9930\n",
      "Epoch 540/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 64073980781.0557 - val_loss: 67920442047.4059\n",
      "Epoch 541/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 62569740402.0979 - val_loss: 93841118527.4419\n",
      "Epoch 542/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 66986917307.1379 - val_loss: 69271928335.4104\n",
      "Epoch 543/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 64053124043.8492 - val_loss: 97081752920.2138\n",
      "Epoch 544/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 61613042165.3393 - val_loss: 66886358069.2883\n",
      "Epoch 545/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 64299005093.3844 - val_loss: 69344961657.5550\n",
      "Epoch 546/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 66533895879.6714 - val_loss: 72725621247.2799\n",
      "Epoch 547/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 60982234253.1818 - val_loss: 71592196316.6425\n",
      "Epoch 548/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 61730672372.6190 - val_loss: 64819513187.8796\n",
      "Epoch 549/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 60405010672.2971 - val_loss: 84093553758.4788\n",
      "Epoch 550/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 58847171037.1367 - val_loss: 67107313972.2082\n",
      "Epoch 551/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 58393427540.1328 - val_loss: 66157788867.1505\n",
      "Epoch 552/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 62292858516.9612 - val_loss: 89504162263.9617\n",
      "Epoch 553/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 61939017738.3725 - val_loss: 65330846192.0135\n",
      "Epoch 554/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 61154695017.0219 - val_loss: 65239665063.7142\n",
      "Epoch 555/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 58250409146.1294 - val_loss: 67363626396.1924\n",
      "Epoch 556/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 58692673043.8807 - val_loss: 84956611242.5226\n",
      "Epoch 557/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 58719583158.2397 - val_loss: 67266848247.7907\n",
      "Epoch 558/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 57122709663.0456 - val_loss: 64177620565.1173\n",
      "Epoch 559/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 60847313652.0428 - val_loss: 69148755544.5738\n",
      "Epoch 560/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 58112595120.9094 - val_loss: 72264270362.0681\n",
      "Epoch 561/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 57927824621.7040 - val_loss: 69590169326.7893\n",
      "Epoch 562/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 58265764146.5661 - val_loss: 65036374238.6588\n",
      "Epoch 563/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 58085180813.0377 - val_loss: 65302062004.8203\n",
      "Epoch 564/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 57511335661.7040 - val_loss: 63756188127.8830\n",
      "Epoch 565/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 56358281225.2200 - val_loss: 65479436424.3893\n",
      "Epoch 566/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 58221556746.9488 - val_loss: 75772333240.9249\n",
      "Epoch 567/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 56726291395.4935 - val_loss: 64282776735.2889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 568/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 58113420026.9578 - val_loss: 68109961449.3165\n",
      "Epoch 569/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 55455513047.3742 - val_loss: 75357478624.5311\n",
      "Epoch 570/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 58983285542.1767 - val_loss: 64124807073.5212\n",
      "Epoch 571/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 54848981991.2212 - val_loss: 68477546170.9412\n",
      "Epoch 572/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 55531326895.6128 - val_loss: 64553822407.9032\n",
      "Epoch 573/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 60409756638.0011 - val_loss: 64549402001.8228\n",
      "Epoch 574/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 55966438544.6393 - val_loss: 71827321200.9857\n",
      "Epoch 575/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 55347650633.7603 - val_loss: 62705475994.7522\n",
      "Epoch 576/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 54764875561.6342 - val_loss: 60828034325.3873\n",
      "Epoch 577/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 56347819165.3168 - val_loss: 68915437172.2262\n",
      "Epoch 578/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 55673106116.2138 - val_loss: 72395685029.6259\n",
      "Epoch 579/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 57649231336.0855 - val_loss: 61217360723.4610\n",
      "Epoch 580/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 54966085822.4513 - val_loss: 73909585328.3556\n",
      "Epoch 581/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 55371665796.2138 - val_loss: 64220698504.7494\n",
      "Epoch 582/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 54740717359.3967 - val_loss: 68836825263.4194\n",
      "Epoch 583/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 53154162504.4637 - val_loss: 69926338831.9145\n",
      "Epoch 584/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 57372682773.6095 - val_loss: 62139162688.5221\n",
      "Epoch 585/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 54822687168.0360 - val_loss: 61983417930.7477\n",
      "Epoch 586/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 55282020723.1064 - val_loss: 62684297383.9302\n",
      "Epoch 587/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 56163067886.7124 - val_loss: 60735323038.9288\n",
      "Epoch 588/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 54955897724.0383 - val_loss: 75170868396.5390\n",
      "Epoch 589/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 53830844090.2735 - val_loss: 118602225944.2678\n",
      "Epoch 590/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 55160178338.7912 - val_loss: 64598244330.2526\n",
      "Epoch 591/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 53431149733.3844 - val_loss: 69139965845.4233\n",
      "Epoch 592/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 53531804363.7051 - val_loss: 62431441581.5471\n",
      "Epoch 593/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 55695289047.2302 - val_loss: 61003225216.4681\n",
      "Epoch 594/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 57679455007.8379 - val_loss: 70781545957.9319\n",
      "Epoch 595/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 52905876842.4626 - val_loss: 72499717033.8745\n",
      "Epoch 596/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 52977481415.6714 - val_loss: 60585899177.6585\n",
      "Epoch 597/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 53547867708.2183 - val_loss: 60340895368.9654\n",
      "Epoch 598/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 51642804895.9100 - val_loss: 63682344238.3032\n",
      "Epoch 599/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 53481255032.4367 - val_loss: 64786806574.3032\n",
      "Epoch 600/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 53932237980.1643 - val_loss: 81831514456.7899\n",
      "Epoch 601/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 53817628267.4710 - val_loss: 61803611933.0205\n",
      "Epoch 602/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 53906523907.6016 - val_loss: 65487130033.3637\n",
      "Epoch 603/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 51138759618.3410 - val_loss: 80664423130.0501\n",
      "Epoch 604/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 52543744826.3455 - val_loss: 62084588048.2745\n",
      "Epoch 605/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 53875515793.0715 - val_loss: 68872834725.1938\n",
      "Epoch 606/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 53381061452.7856 - val_loss: 64718141790.8388\n",
      "Epoch 607/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 54828835500.7856 - val_loss: 67426450118.3190\n",
      "Epoch 608/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 51033794330.6517 - val_loss: 60929593339.6793\n",
      "Epoch 609/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 51568542582.2757 - val_loss: 69100029355.7468\n",
      "Epoch 610/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 52651311924.5830 - val_loss: 65820376085.0273\n",
      "Epoch 611/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 52387697798.2667 - val_loss: 63741677459.6951\n",
      "Epoch 612/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 54103369722.2375 - val_loss: 64236373525.7474\n",
      "Epoch 613/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 53910589977.0670 - val_loss: 93143099450.1851\n",
      "Epoch 614/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 52215011223.3022 - val_loss: 59440586787.7176\n",
      "Epoch 615/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 49604082255.2347 - val_loss: 67410402608.8956\n",
      "Epoch 616/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 50078881163.3090 - val_loss: 59815569070.4113\n",
      "Epoch 617/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 51143134256.9814 - val_loss: 63466969511.1381\n",
      "Epoch 618/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 50965242386.1519 - val_loss: 73955043496.7944\n",
      "Epoch 619/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 61658478680.7428 - val_loss: 71097137855.4059\n",
      "Epoch 620/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 54851007203.9077 - val_loss: 60444393668.4467\n",
      "Epoch 621/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 49866388057.6072 - val_loss: 75404647883.9359\n",
      "Epoch 622/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 52577388378.0394 - val_loss: 57623662049.3232\n",
      "Epoch 623/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 52481960216.0585 - val_loss: 57404799275.5668\n",
      "Epoch 624/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 51407908477.9111 - val_loss: 63127260093.7496\n",
      "Epoch 625/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 50242554059.9932 - val_loss: 66752229417.1904\n",
      "Epoch 626/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 49722476754.9083 - val_loss: 57148921319.9482\n",
      "Epoch 627/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 52117730628.4299 - val_loss: 57426263141.1038\n",
      "Epoch 628/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 49613086231.3382 - val_loss: 57845153379.5195\n",
      "Epoch 629/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 50391635568.0810 - val_loss: 60973855804.3454\n",
      "Epoch 630/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 50708060030.9195 - val_loss: 57208348476.1294\n",
      "Epoch 631/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 51014875936.9904 - val_loss: 63587215933.2096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 632/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 49350318337.0084 - val_loss: 59707551232.4321\n",
      "Epoch 633/10000\n",
      "3554/3554 [==============================] - 0s 130us/step - loss: 49330036975.7209 - val_loss: 57943241504.1890\n",
      "Epoch 634/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 51749033094.2667 - val_loss: 61567840777.7935\n",
      "Epoch 635/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 50322970528.3421 - val_loss: 61781668556.5120\n",
      "Epoch 636/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 49701767785.7423 - val_loss: 60574104315.3193\n",
      "Epoch 637/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 50704840921.8233 - val_loss: 62689334494.6588\n",
      "Epoch 638/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 53811620235.3090 - val_loss: 80811640231.2101\n",
      "Epoch 639/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 50164826190.3703 - val_loss: 58824102669.1781\n",
      "Epoch 640/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 47988216552.5177 - val_loss: 63796573176.7989\n",
      "Epoch 641/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 49005396770.1429 - val_loss: 61968809309.1105\n",
      "Epoch 642/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 51786091317.7355 - val_loss: 58975785317.3198\n",
      "Epoch 643/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 47908163514.8497 - val_loss: 59816793197.7451\n",
      "Epoch 644/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 48895239596.1553 - val_loss: 57499650136.1418\n",
      "Epoch 645/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 48364865477.2223 - val_loss: 66003284554.1716\n",
      "Epoch 646/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 47509046690.9353 - val_loss: 58869843144.7674\n",
      "Epoch 647/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 49041284645.1683 - val_loss: 59631932107.2158\n",
      "Epoch 648/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 48160974256.4772 - val_loss: 71490236580.4737\n",
      "Epoch 649/10000\n",
      "3554/3554 [==============================] - 1s 142us/step - loss: 49584067982.1902 - val_loss: 64034428419.4565\n",
      "Epoch 650/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 51397032811.9032 - val_loss: 61918879832.1418\n",
      "Epoch 651/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 47651371638.4198 - val_loss: 61643107933.1826\n",
      "Epoch 652/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 46823200402.6562 - val_loss: 60868555972.4467\n",
      "Epoch 653/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 48467629624.7608 - val_loss: 56213001164.4399\n",
      "Epoch 654/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 47622174622.3253 - val_loss: 57436260183.7817\n",
      "Epoch 655/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 49413700986.5976 - val_loss: 64346479655.4622\n",
      "Epoch 656/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 54137699992.4187 - val_loss: 89236083209.9375\n",
      "Epoch 657/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 51570039862.7440 - val_loss: 57332011244.7730\n",
      "Epoch 658/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 49517498029.1638 - val_loss: 77078740543.3699\n",
      "Epoch 659/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 49536728625.8458 - val_loss: 58974707408.9767\n",
      "Epoch 660/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 49585415750.5909 - val_loss: 60758819422.6228\n",
      "Epoch 661/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 50503504853.6455 - val_loss: 56752291364.7257\n",
      "Epoch 662/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 46656716061.9651 - val_loss: 56425364583.5522\n",
      "Epoch 663/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 47206136028.1283 - val_loss: 59621764867.0245\n",
      "Epoch 664/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 47687311376.7113 - val_loss: 84079402662.3460\n",
      "Epoch 665/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 50909648523.7411 - val_loss: 60321017829.4999\n",
      "Epoch 666/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 49474151513.8953 - val_loss: 59714112304.8956\n",
      "Epoch 667/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 46786403613.8211 - val_loss: 65615225258.8827\n",
      "Epoch 668/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 47955577939.7006 - val_loss: 56487067704.4568\n",
      "Epoch 669/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 47002193576.5537 - val_loss: 61106253556.1181\n",
      "Epoch 670/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 48335773661.4249 - val_loss: 62511381449.5595\n",
      "Epoch 671/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 48400781238.2397 - val_loss: 57197849850.3111\n",
      "Epoch 672/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 46050212071.6534 - val_loss: 55138849596.9935\n",
      "Epoch 673/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 46588694395.4620 - val_loss: 58927773744.1035\n",
      "Epoch 674/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 45920704148.9612 - val_loss: 55250024189.3356\n",
      "Epoch 675/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 49859552793.2110 - val_loss: 59984591581.7947\n",
      "Epoch 676/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 46806997776.8554 - val_loss: 68264225433.0959\n",
      "Epoch 677/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 46336456437.7715 - val_loss: 64034442156.3229\n",
      "Epoch 678/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 50952147485.6770 - val_loss: 75803812038.1750\n",
      "Epoch 679/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 50543617828.4480 - val_loss: 58985247047.6512\n",
      "Epoch 680/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 45266699054.2442 - val_loss: 58009834216.8844\n",
      "Epoch 681/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 47206201573.3483 - val_loss: 55487654373.6439\n",
      "Epoch 682/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 47468455068.1643 - val_loss: 68191082276.5097\n",
      "Epoch 683/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 46374719557.1503 - val_loss: 72615224038.8681\n",
      "Epoch 684/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 45417365901.9021 - val_loss: 52984987847.9032\n",
      "Epoch 685/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 43485479225.4811 - val_loss: 92082106843.8504\n",
      "Epoch 686/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 51745212557.7580 - val_loss: 54269847494.9671\n",
      "Epoch 687/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 44015577552.4592 - val_loss: 52507716222.8838\n",
      "Epoch 688/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 44980476729.1930 - val_loss: 51591181019.0582\n",
      "Epoch 689/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 43701913296.8914 - val_loss: 87166321671.7772\n",
      "Epoch 690/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 44404201440.8824 - val_loss: 60302345159.2551\n",
      "Epoch 691/10000\n",
      "3554/3554 [==============================] - 0s 134us/step - loss: 42960717496.9769 - val_loss: 54145684649.9466\n",
      "Epoch 692/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 42485565782.2938 - val_loss: 67656806414.4023\n",
      "Epoch 693/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 45770444940.6055 - val_loss: 56803133372.3094\n",
      "Epoch 694/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 44357458444.3894 - val_loss: 52670855731.4160\n",
      "Epoch 695/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 43024255032.4727 - val_loss: 52863148326.3820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 696/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 42490924420.3939 - val_loss: 53756539271.1651\n",
      "Epoch 697/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 41739466973.7850 - val_loss: 72899494774.0264\n",
      "Epoch 698/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 42042681791.7479 - val_loss: 48686702660.2667\n",
      "Epoch 699/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 41260017418.5166 - val_loss: 50125828439.3496\n",
      "Epoch 700/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 40844795731.1244 - val_loss: 48736127287.9527\n",
      "Epoch 701/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 44661716734.9916 - val_loss: 119950435614.0287\n",
      "Epoch 702/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 43878185975.3562 - val_loss: 49058125275.5623\n",
      "Epoch 703/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 45216905927.0951 - val_loss: 49369616223.8470\n",
      "Epoch 704/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 42531006934.2217 - val_loss: 48437407959.7457\n",
      "Epoch 705/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 40264919315.4485 - val_loss: 51930344580.2127\n",
      "Epoch 706/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 42453201124.1958 - val_loss: 57859571648.9181\n",
      "Epoch 707/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 41493930428.8666 - val_loss: 46648170013.8127\n",
      "Epoch 708/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 39769602782.7214 - val_loss: 89860786999.2326\n",
      "Epoch 709/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 45715866489.7333 - val_loss: 48978354799.0414\n",
      "Epoch 710/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 39351552065.6927 - val_loss: 49677916333.4031\n",
      "Epoch 711/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 42220197960.6078 - val_loss: 49988172878.0602\n",
      "Epoch 712/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 38075963120.0090 - val_loss: 50249088853.6214\n",
      "Epoch 713/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 37075552291.1514 - val_loss: 58184151717.4819\n",
      "Epoch 714/10000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 39772433286.4108 - val_loss: 61664036055.7457\n",
      "Epoch 715/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 40331162636.1013 - val_loss: 53058892497.2647\n",
      "Epoch 716/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 39642690513.3236 - val_loss: 47402252818.5789\n",
      "Epoch 717/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 38119220432.0270 - val_loss: 63605291272.4253\n",
      "Epoch 718/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 38886564927.9640 - val_loss: 65660597933.8352\n",
      "Epoch 719/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 37095467914.4446 - val_loss: 43869631913.5865\n",
      "Epoch 720/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 34824682744.4367 - val_loss: 41848179617.2332\n",
      "Epoch 721/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 34463731540.2769 - val_loss: 47306641291.3418\n",
      "Epoch 722/10000\n",
      "3554/3554 [==============================] - 0s 130us/step - loss: 33382116663.7524 - val_loss: 42158899865.9601\n",
      "Epoch 723/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 34267599859.8987 - val_loss: 43972501993.6765\n",
      "Epoch 724/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 32822792351.0456 - val_loss: 43909941641.7575\n",
      "Epoch 725/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 31827707100.7046 - val_loss: 50822533883.8954\n",
      "Epoch 726/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 36265926552.2746 - val_loss: 40628854934.3595\n",
      "Epoch 727/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 31364908447.4778 - val_loss: 45001411283.5691\n",
      "Epoch 728/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 31488595853.9021 - val_loss: 74230790190.6633\n",
      "Epoch 729/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 34139419284.3849 - val_loss: 41473420688.6706\n",
      "Epoch 730/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 30003491293.1367 - val_loss: 48003369466.3831\n",
      "Epoch 731/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 29736661979.6961 - val_loss: 40012462303.8110\n",
      "Epoch 732/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 30650938837.6455 - val_loss: 36591449023.9100\n",
      "Epoch 733/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 31021853529.4631 - val_loss: 36867724040.7134\n",
      "Epoch 734/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 27992804997.4024 - val_loss: 44853103628.3859\n",
      "Epoch 735/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 27403013258.5886 - val_loss: 43158758944.6931\n",
      "Epoch 736/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 26512430017.4766 - val_loss: 42376220614.6790\n",
      "Epoch 737/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 27977972444.1283 - val_loss: 33755437931.0807\n",
      "Epoch 738/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 26182378917.2403 - val_loss: 32641272392.7314\n",
      "Epoch 739/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 25885574492.9207 - val_loss: 38492993593.3210\n",
      "Epoch 740/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 25717414263.7164 - val_loss: 34274778472.3443\n",
      "Epoch 741/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 26229032979.5926 - val_loss: 34914334327.2506\n",
      "Epoch 742/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 25663760507.3180 - val_loss: 54256028338.7319\n",
      "Epoch 743/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 30359941654.7620 - val_loss: 30225039836.4264\n",
      "Epoch 744/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 23615362523.4080 - val_loss: 36082098575.9505\n",
      "Epoch 745/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 25410915265.1885 - val_loss: 29174715631.9415\n",
      "Epoch 746/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 24941946371.7456 - val_loss: 38553695532.4309\n",
      "Epoch 747/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 23521598861.0377 - val_loss: 29355498384.6706\n",
      "Epoch 748/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 21920415303.7434 - val_loss: 31269919689.3435\n",
      "Epoch 749/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 22125391687.5993 - val_loss: 37039695564.9440\n",
      "Epoch 750/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 22345505114.9038 - val_loss: 40402233557.7294\n",
      "Epoch 751/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 21698835493.7445 - val_loss: 27209299787.8999\n",
      "Epoch 752/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 22025202546.9623 - val_loss: 29064812349.8577\n",
      "Epoch 753/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 20583427335.3472 - val_loss: 32741275817.3705\n",
      "Epoch 754/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 21488484973.1998 - val_loss: 34023275779.0965\n",
      "Epoch 755/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 21510251700.0788 - val_loss: 48178030767.1314\n",
      "Epoch 756/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 25487190088.6078 - val_loss: 49575235290.1941\n",
      "Epoch 757/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 21449159196.5245 - val_loss: 29594756646.3100\n",
      "Epoch 758/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 19383532712.8419 - val_loss: 26807583543.0886\n",
      "Epoch 759/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 20766844387.4755 - val_loss: 27582967179.0537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 760/10000\n",
      "3554/3554 [==============================] - 0s 136us/step - loss: 19323665729.2786 - val_loss: 25495704380.2734\n",
      "Epoch 761/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 20835731961.6612 - val_loss: 26535608972.1339\n",
      "Epoch 762/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 18517773874.9983 - val_loss: 26976291766.8366\n",
      "Epoch 763/10000\n",
      "3554/3554 [==============================] - 1s 158us/step - loss: 18926585469.3348 - val_loss: 27263859032.4298\n",
      "Epoch 764/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 19493322834.9803 - val_loss: 26844260307.6411\n",
      "Epoch 765/10000\n",
      "3554/3554 [==============================] - 0s 137us/step - loss: 18259666442.6607 - val_loss: 31595801294.2402\n",
      "Epoch 766/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 20548752217.4631 - val_loss: 32478387321.8430\n",
      "Epoch 767/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 18203399916.5515 - val_loss: 24664135122.1288\n",
      "Epoch 768/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 18541456269.3258 - val_loss: 24087236898.7094\n",
      "Epoch 769/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 16739137414.5549 - val_loss: 36540775796.1542\n",
      "Epoch 770/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 18200599957.1052 - val_loss: 23313505273.9511\n",
      "Epoch 771/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 17102970608.0090 - val_loss: 35448979428.3477\n",
      "Epoch 772/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 18183760449.4046 - val_loss: 21602174875.6163\n",
      "Epoch 773/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 16308614940.9567 - val_loss: 21204590626.7094\n",
      "Epoch 774/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 15979520462.0822 - val_loss: 21764041523.7761\n",
      "Epoch 775/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 15945356974.3163 - val_loss: 23105277493.5764\n",
      "Epoch 776/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 15873000025.6072 - val_loss: 20476911123.7311\n",
      "Epoch 777/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 16444712503.6083 - val_loss: 21104881417.4335\n",
      "Epoch 778/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 16697930725.4924 - val_loss: 19608512939.3148\n",
      "Epoch 779/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 14873496913.1075 - val_loss: 21864613595.9224\n",
      "Epoch 780/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 13560251923.3044 - val_loss: 19244059969.0262\n",
      "Epoch 781/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 14610277142.6179 - val_loss: 17487883091.8931\n",
      "Epoch 782/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 16395762113.4766 - val_loss: 18146641946.5001\n",
      "Epoch 783/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 12953264856.3827 - val_loss: 18143426261.5134\n",
      "Epoch 784/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 12563037739.5070 - val_loss: 18982683938.3494\n",
      "Epoch 785/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 13038834046.6314 - val_loss: 33899994456.7899\n",
      "Epoch 786/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 19273446136.5425 - val_loss: 15567555430.7601\n",
      "Epoch 787/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 11481235264.6843 - val_loss: 17441771770.5271\n",
      "Epoch 788/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 11531414319.9730 - val_loss: 14947231444.7212\n",
      "Epoch 789/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 10593024432.4772 - val_loss: 17588720735.1989\n",
      "Epoch 790/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 11135831052.3894 - val_loss: 16701367470.8433\n",
      "Epoch 791/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 12166719228.6866 - val_loss: 15809789485.5111\n",
      "Epoch 792/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 10008932866.5931 - val_loss: 14225342081.4762\n",
      "Epoch 793/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 10290595652.2138 - val_loss: 17215088010.9097\n",
      "Epoch 794/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 9994637710.7665 - val_loss: 25813218193.2467\n",
      "Epoch 795/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 13724633352.2116 - val_loss: 15546890004.3792\n",
      "Epoch 796/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 9714752701.5869 - val_loss: 12938697678.6723\n",
      "Epoch 797/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 9479901765.1503 - val_loss: 14466999127.7817\n",
      "Epoch 798/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 9153314092.2273 - val_loss: 17462544258.4124\n",
      "Epoch 799/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 9627847636.7811 - val_loss: 15672307292.8945\n",
      "Epoch 800/10000\n",
      "3554/3554 [==============================] - 0s 139us/step - loss: 9143551147.1469 - val_loss: 14817742784.4861\n",
      "Epoch 801/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 9675658504.4997 - val_loss: 15251754633.1094\n",
      "Epoch 802/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 8817168992.0900 - val_loss: 13814226460.1564\n",
      "Epoch 803/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 8374481611.7051 - val_loss: 27759361506.4754\n",
      "Epoch 804/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 10140814669.6500 - val_loss: 27404998007.7547\n",
      "Epoch 805/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 11619493344.3061 - val_loss: 13633874670.7173\n",
      "Epoch 806/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 7857491527.0231 - val_loss: 13818926060.4129\n",
      "Epoch 807/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 8147590850.6292 - val_loss: 12170323737.0239\n",
      "Epoch 808/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 7875415997.4429 - val_loss: 12485065446.6160\n",
      "Epoch 809/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 8528225093.0062 - val_loss: 10771685837.5921\n",
      "Epoch 810/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 7901176967.4192 - val_loss: 32933875073.1162\n",
      "Epoch 811/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 12577038043.5521 - val_loss: 13955365412.2937\n",
      "Epoch 812/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 8143963799.2662 - val_loss: 22355040183.1246\n",
      "Epoch 813/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 9599333954.5571 - val_loss: 18741926640.6616\n",
      "Epoch 814/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 9805406154.9848 - val_loss: 13530042806.3325\n",
      "Epoch 815/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 7060531084.7496 - val_loss: 10454424904.8754\n",
      "Epoch 816/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 6755853441.3686 - val_loss: 11854712509.1015\n",
      "Epoch 817/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 6884622364.5965 - val_loss: 12981166431.1269\n",
      "Epoch 818/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 6574782014.5234 - val_loss: 10769073660.5435\n",
      "Epoch 819/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 8202521537.4766 - val_loss: 9700566339.7626\n",
      "Epoch 820/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 7086456996.9882 - val_loss: 9496308788.7842\n",
      "Epoch 821/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 6141581413.9966 - val_loss: 10841887351.3587\n",
      "Epoch 822/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 7152728530.7642 - val_loss: 12506923016.7854\n",
      "Epoch 823/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 7396814177.8188 - val_loss: 17714645626.4191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 824/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 7159074178.5211 - val_loss: 12852579795.4970\n",
      "Epoch 825/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 7627879180.2454 - val_loss: 23000077977.6720\n",
      "Epoch 826/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 7171970438.2667 - val_loss: 11998062552.9699\n",
      "Epoch 827/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 6559507320.7248 - val_loss: 12687298456.0158\n",
      "Epoch 828/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 6325312331.6331 - val_loss: 12872942700.6650\n",
      "Epoch 829/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 6090662493.7130 - val_loss: 8547137937.1027\n",
      "Epoch 830/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 6169873616.8914 - val_loss: 9544722949.7249\n",
      "Epoch 831/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 6120049384.5177 - val_loss: 26926885321.4155\n",
      "Epoch 832/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 10649302345.3281 - val_loss: 15569471686.4630\n",
      "Epoch 833/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 5957170265.3911 - val_loss: 8054071435.3418\n",
      "Epoch 834/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 6233319114.6967 - val_loss: 8729055397.4098\n",
      "Epoch 835/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 6352214601.1840 - val_loss: 8135210866.4259\n",
      "Epoch 836/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 7214195399.2752 - val_loss: 12361177581.2771\n",
      "Epoch 837/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 5545228696.2746 - val_loss: 8797682240.9181\n",
      "Epoch 838/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 5144734631.5453 - val_loss: 9400215130.6622\n",
      "Epoch 839/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 6564363818.3545 - val_loss: 9730511006.8388\n",
      "Epoch 840/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 5495488666.4356 - val_loss: 11101326123.5668\n",
      "Epoch 841/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 5158864500.3894 - val_loss: 9441118708.4782\n",
      "Epoch 842/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 6063367903.8739 - val_loss: 10339883409.5347\n",
      "Epoch 843/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 6320619465.9764 - val_loss: 8689186558.2717\n",
      "Epoch 844/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 5316075847.3112 - val_loss: 8430083856.7651\n",
      "Epoch 845/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 5639974903.3562 - val_loss: 7777680287.8290\n",
      "Epoch 846/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 5926129544.8599 - val_loss: 14263001655.3046\n",
      "Epoch 847/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 6011426291.6106 - val_loss: 9576001328.6076\n",
      "Epoch 848/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 6284821263.4508 - val_loss: 7411487009.3592\n",
      "Epoch 849/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 4943817687.6624 - val_loss: 18415151079.6602\n",
      "Epoch 850/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 6425087504.1351 - val_loss: 9077704977.2827\n",
      "Epoch 851/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 5017932557.3979 - val_loss: 10032291436.1609\n",
      "Epoch 852/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 5354584122.7777 - val_loss: 19974545716.7842\n",
      "Epoch 853/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 6688484885.8255 - val_loss: 7435476865.4042\n",
      "Epoch 854/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 4475281104.7113 - val_loss: 8816341103.4734\n",
      "Epoch 855/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 5418454953.5622 - val_loss: 8185339710.7938\n",
      "Epoch 856/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 6161197520.9544 - val_loss: 7461230082.8174\n",
      "Epoch 857/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 6015188508.2724 - val_loss: 7367673751.9437\n",
      "Epoch 858/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 5161009281.0805 - val_loss: 7159943356.3814\n",
      "Epoch 859/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 4931528333.3258 - val_loss: 9969781985.6833\n",
      "Epoch 860/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 6022852099.4575 - val_loss: 7739850010.9322\n",
      "Epoch 861/10000\n",
      "3554/3554 [==============================] - 0s 137us/step - loss: 4859489170.2240 - val_loss: 9024287898.1401\n",
      "Epoch 862/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 4538134172.7406 - val_loss: 8045422740.6492\n",
      "Epoch 863/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 4427453712.1351 - val_loss: 8067278881.4492\n",
      "Epoch 864/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 5852138948.0698 - val_loss: 20442442231.7907\n",
      "Epoch 865/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 6471037305.4451 - val_loss: 10599167031.3046\n",
      "Epoch 866/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 5386683391.7119 - val_loss: 6807189921.8813\n",
      "Epoch 867/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 4596303054.7304 - val_loss: 13416041766.8141\n",
      "Epoch 868/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 4669781100.5515 - val_loss: 6693060637.8127\n",
      "Epoch 869/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 4273287051.1649 - val_loss: 6915557052.9215\n",
      "Epoch 870/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 4025342167.9505 - val_loss: 6531507509.9679\n",
      "Epoch 871/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 4181234212.3399 - val_loss: 6248848924.9485\n",
      "Epoch 872/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 4824862885.3844 - val_loss: 7922548969.3165\n",
      "Epoch 873/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 5177414228.4209 - val_loss: 6852872459.5218\n",
      "Epoch 874/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 5002923622.8610 - val_loss: 11560078123.8549\n",
      "Epoch 875/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 5975636753.4316 - val_loss: 6582465948.8383\n",
      "Epoch 876/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 5195651306.2465 - val_loss: 8746471180.2059\n",
      "Epoch 877/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 5387089347.7817 - val_loss: 21857790782.7218\n",
      "Epoch 878/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 5341695673.2651 - val_loss: 7914524218.8332\n",
      "Epoch 879/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 4979808030.1092 - val_loss: 6247991674.5632\n",
      "Epoch 880/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 4249690770.2240 - val_loss: 6754696707.7086\n",
      "Epoch 881/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 3953474710.9961 - val_loss: 6367834046.4068\n",
      "Epoch 882/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 4545449296.4592 - val_loss: 6102924428.5300\n",
      "Epoch 883/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 4214174519.4643 - val_loss: 6642948069.7879\n",
      "Epoch 884/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 4207200125.6230 - val_loss: 7041858212.2217\n",
      "Epoch 885/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 5393608511.4237 - val_loss: 6272677116.5165\n",
      "Epoch 886/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 4183658456.8149 - val_loss: 10756820124.6965\n",
      "Epoch 887/10000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 4227399655.5093 - val_loss: 7224561692.2284\n",
      "Epoch 888/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 4829690093.9921 - val_loss: 6473569716.8923\n",
      "Epoch 889/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 3936807803.3180 - val_loss: 8955123338.0816\n",
      "Epoch 890/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 4481088270.5504 - val_loss: 6523419679.6985\n",
      "Epoch 891/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 4123777737.7243 - val_loss: 6952682078.8208\n",
      "Epoch 892/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 3861571161.3191 - val_loss: 7733236761.6360\n",
      "Epoch 893/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 4402449856.5402 - val_loss: 8547755083.6478\n",
      "Epoch 894/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 5920701791.8019 - val_loss: 6401540857.3030\n",
      "Epoch 895/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 4139694838.4198 - val_loss: 6097673764.2397\n",
      "Epoch 896/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 3540172681.7243 - val_loss: 7258149494.0264\n",
      "Epoch 897/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 3856119655.2932 - val_loss: 5779968235.7648\n",
      "Epoch 898/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 3689100740.0698 - val_loss: 9821968537.6720\n",
      "Epoch 899/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 4373317831.3832 - val_loss: 10833513426.6329\n",
      "Epoch 900/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 4176170021.6005 - val_loss: 6532625425.6428\n",
      "Epoch 901/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 3831656052.9792 - val_loss: 5735799745.4222\n",
      "Epoch 902/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 4036380129.7468 - val_loss: 10191580155.1032\n",
      "Epoch 903/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 4462771128.5447 - val_loss: 5594442531.9336\n",
      "Epoch 904/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 4006791616.6123 - val_loss: 11393720899.2585\n",
      "Epoch 905/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 3578244457.4541 - val_loss: 5837936069.6709\n",
      "Epoch 906/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 4357003762.0799 - val_loss: 9237614465.8363\n",
      "Epoch 907/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 3522488953.9494 - val_loss: 8155315189.9904\n",
      "Epoch 908/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 3712248102.7530 - val_loss: 5611963684.5592\n",
      "Epoch 909/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 3723009613.6140 - val_loss: 8598406221.0520\n",
      "Epoch 910/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 4316319708.8486 - val_loss: 17936947072.1080\n",
      "Epoch 911/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 4950347727.5948 - val_loss: 15474955669.8554\n",
      "Epoch 912/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 5078084651.5070 - val_loss: 5606018645.9454\n",
      "Epoch 913/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 3627751333.3844 - val_loss: 9725011039.3429\n",
      "Epoch 914/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 4387366164.0158 - val_loss: 5549085025.9173\n",
      "Epoch 915/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 4957398565.1683 - val_loss: 10461759675.0852\n",
      "Epoch 916/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 3973537301.8976 - val_loss: 5289924411.7693\n",
      "Epoch 917/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 4382500392.6258 - val_loss: 16269760110.6093\n",
      "Epoch 918/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 3963476221.6950 - val_loss: 6343461453.3761\n",
      "Epoch 919/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 3870743904.9004 - val_loss: 6059872919.4037\n",
      "Epoch 920/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 3457863765.6455 - val_loss: 5501080977.3907\n",
      "Epoch 921/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 4036495448.1666 - val_loss: 7411670889.9488\n",
      "Epoch 922/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 4150044499.4125 - val_loss: 7141290023.1741\n",
      "Epoch 923/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 3404325786.2915 - val_loss: 6220645979.6793\n",
      "Epoch 924/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 3466783442.7642 - val_loss: 8724978859.6388\n",
      "Epoch 925/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 3437843522.3410 - val_loss: 6594688952.5648\n",
      "Epoch 926/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 3270541887.9640 - val_loss: 5878898333.9567\n",
      "Epoch 927/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 3374240386.5211 - val_loss: 6930025829.9679\n",
      "Epoch 928/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 3340128606.2172 - val_loss: 5369350497.0352\n",
      "Epoch 929/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 3618938242.0889 - val_loss: 5647217920.8821\n",
      "Epoch 930/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 3457406347.0208 - val_loss: 11243942588.0934\n",
      "Epoch 931/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 3340102270.7755 - val_loss: 11134382224.0225\n",
      "Epoch 932/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 3202847779.1514 - val_loss: 5232072579.1325\n",
      "Epoch 933/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 3297048558.4243 - val_loss: 10589465446.4720\n",
      "Epoch 934/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 3543373060.8981 - val_loss: 7007023317.7069\n",
      "Epoch 935/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 3384772055.8064 - val_loss: 6409454821.6799\n",
      "Epoch 936/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 3201647466.1745 - val_loss: 7587669345.1792\n",
      "Epoch 937/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 6664486154.8047 - val_loss: 7333130617.7710\n",
      "Epoch 938/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 4405358780.8666 - val_loss: 5679945539.4385\n",
      "Epoch 939/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 3569507728.6393 - val_loss: 5832573694.3077\n",
      "Epoch 940/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 3851410385.3956 - val_loss: 6532612376.5918\n",
      "Epoch 941/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 2887908406.4558 - val_loss: 4835575756.9800\n",
      "Epoch 942/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 4249926552.8509 - val_loss: 18545756355.2945\n",
      "Epoch 943/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 4969696484.7721 - val_loss: 7427195667.8391\n",
      "Epoch 944/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 3112875365.2763 - val_loss: 5699383825.5707\n",
      "Epoch 945/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 3201651583.9280 - val_loss: 10510264402.7409\n",
      "Epoch 946/10000\n",
      "3554/3554 [==============================] - 1s 144us/step - loss: 3577079934.5954 - val_loss: 5039743878.2290\n",
      "Epoch 947/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 2504145094.3748 - val_loss: 5157568122.5992\n",
      "Epoch 948/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 2776213694.3793 - val_loss: 5584927745.1882\n",
      "Epoch 949/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 3399344543.0456 - val_loss: 7977156349.9837\n",
      "Epoch 950/10000\n",
      "3554/3554 [==============================] - 0s 141us/step - loss: 3394135078.3208 - val_loss: 5848619924.6672\n",
      "Epoch 951/10000\n",
      "3554/3554 [==============================] - 0s 134us/step - loss: 3183409166.4063 - val_loss: 8521381589.0453\n",
      "Epoch 952/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 3810163485.0467 - val_loss: 5059955575.8627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 953/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 3474500523.0028 - val_loss: 5436540743.3271\n",
      "Epoch 954/10000\n",
      "3554/3554 [==============================] - 1s 170us/step - loss: 2874473114.5976 - val_loss: 6198620796.0034\n",
      "Epoch 955/10000\n",
      "3554/3554 [==============================] - 1s 168us/step - loss: 2881903670.0236 - val_loss: 5827414160.6526\n",
      "Epoch 956/10000\n",
      "3554/3554 [==============================] - 1s 180us/step - loss: 3209328523.3630 - val_loss: 6245126782.3797\n",
      "Epoch 957/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 3363326356.0968 - val_loss: 4878899279.6917\n",
      "Epoch 958/10000\n",
      "3554/3554 [==============================] - 1s 145us/step - loss: 2768756221.3348 - val_loss: 7605336102.9581\n",
      "Epoch 959/10000\n",
      "3554/3554 [==============================] - 0s 136us/step - loss: 3005552803.6556 - val_loss: 9262418881.4942\n",
      "Epoch 960/10000\n",
      "3554/3554 [==============================] - 1s 150us/step - loss: 4212559418.4896 - val_loss: 5149850232.9789\n",
      "Epoch 961/10000\n",
      "3554/3554 [==============================] - 1s 150us/step - loss: 3183228226.4131 - val_loss: 8545015400.0203\n",
      "Epoch 962/10000\n",
      "3554/3554 [==============================] - 1s 164us/step - loss: 3296581713.0355 - val_loss: 4891101895.5432\n",
      "Epoch 963/10000\n",
      "3554/3554 [==============================] - 0s 140us/step - loss: 2676287061.5734 - val_loss: 5294116298.2526\n",
      "Epoch 964/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 3517785902.6314 - val_loss: 4779293263.0053\n",
      "Epoch 965/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 3136577174.2577 - val_loss: 4827933157.4008\n",
      "Epoch 966/10000\n",
      "3554/3554 [==============================] - 1s 152us/step - loss: 2890736316.7586 - val_loss: 4252157358.9153\n",
      "Epoch 967/10000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 2643376740.5560 - val_loss: 4783943347.7693\n",
      "Epoch 968/10000\n",
      "3554/3554 [==============================] - 1s 150us/step - loss: 2974375157.6995 - val_loss: 4378133982.1722\n",
      "Epoch 969/10000\n",
      "3554/3554 [==============================] - 1s 171us/step - loss: 2980835394.3410 - val_loss: 15046080466.9210\n",
      "Epoch 970/10000\n",
      "3554/3554 [==============================] - 1s 165us/step - loss: 6183955454.7034 - val_loss: 4551533041.2242\n",
      "Epoch 971/10000\n",
      "3554/3554 [==============================] - 1s 147us/step - loss: 3215711370.5886 - val_loss: 5324891948.5750\n",
      "Epoch 972/10000\n",
      "3554/3554 [==============================] - 1s 156us/step - loss: 2481334130.5301 - val_loss: 7180821199.7255\n",
      "Epoch 973/10000\n",
      "3554/3554 [==============================] - 1s 141us/step - loss: 3184961550.9826 - val_loss: 15150500779.0267\n",
      "Epoch 974/10000\n",
      "3554/3554 [==============================] - 1s 155us/step - loss: 3512917475.4395 - val_loss: 6210791135.9550\n",
      "Epoch 975/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 2563041052.2364 - val_loss: 5273105837.7632\n",
      "Epoch 976/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 2720566412.3174 - val_loss: 6145764582.4360\n",
      "Epoch 977/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 2972801541.1863 - val_loss: 8207632485.3918\n",
      "Epoch 978/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 3236996355.8897 - val_loss: 6180490132.2352\n",
      "Epoch 979/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 4730477516.2093 - val_loss: 8103202143.7030\n",
      "Epoch 980/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 3038527571.9887 - val_loss: 6321562925.5741\n",
      "Epoch 981/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 2694078721.6387 - val_loss: 9310397300.7302\n",
      "Epoch 982/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 3482484836.6100 - val_loss: 4326887110.6610\n",
      "Epoch 983/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 2376304538.2735 - val_loss: 17086399460.3477\n",
      "Epoch 984/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 3596415860.8711 - val_loss: 8742262332.9215\n",
      "Epoch 985/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 2753558992.3872 - val_loss: 8762217139.5240\n",
      "Epoch 986/10000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 3612877824.5763 - val_loss: 5781514439.7772\n",
      "Epoch 987/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 3006554654.8295 - val_loss: 8264456796.4624\n",
      "Epoch 988/10000\n",
      "3554/3554 [==============================] - 0s 138us/step - loss: 3932886313.2741 - val_loss: 5052201906.5879\n",
      "Epoch 989/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 2978727591.2572 - val_loss: 5054310790.3910\n",
      "Epoch 990/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 2345641081.4451 - val_loss: 4826003676.3544\n",
      "Epoch 991/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 2366072297.2380 - val_loss: 4655074651.4003\n",
      "Epoch 992/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 2625510553.6792 - val_loss: 4462888571.7513\n",
      "Epoch 993/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 2491415193.2831 - val_loss: 5810702497.3052\n",
      "Epoch 994/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 2603518459.0118 - val_loss: 4498520076.6740\n",
      "Epoch 995/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 2739552365.7580 - val_loss: 6469761913.1229\n",
      "Epoch 996/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 2953840465.3956 - val_loss: 6478274842.2841\n",
      "Epoch 997/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 2932144711.0231 - val_loss: 4355913563.9572\n",
      "Epoch 998/10000\n",
      "3554/3554 [==============================] - 1s 147us/step - loss: 3161046613.7175 - val_loss: 5567373821.8397\n",
      "Epoch 999/10000\n",
      "3554/3554 [==============================] - 0s 137us/step - loss: 2536953508.6640 - val_loss: 4410323290.5181\n",
      "Epoch 1000/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 4485212846.0281 - val_loss: 5515965911.9617\n",
      "Epoch 1001/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 3761773300.8351 - val_loss: 4958304834.4506\n",
      "Epoch 1002/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 2601967961.3191 - val_loss: 4052720035.5668\n",
      "Epoch 1003/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 2237307145.9403 - val_loss: 3964719445.9094\n",
      "Epoch 1004/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 2478351442.9803 - val_loss: 4227517735.1741\n",
      "Epoch 1005/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 2814879811.5656 - val_loss: 5260118459.3373\n",
      "Epoch 1006/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 2789513880.7068 - val_loss: 5293424525.9342\n",
      "Epoch 1007/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 2666169933.5059 - val_loss: 5560967115.7918\n",
      "Epoch 1008/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 2759152647.7794 - val_loss: 11436247581.5246\n",
      "Epoch 1009/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 4436139182.8925 - val_loss: 4701772614.7871\n",
      "Epoch 1010/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 2408714132.2409 - val_loss: 4648298100.8022\n",
      "Epoch 1011/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 2457397860.9882 - val_loss: 6771551894.0714\n",
      "Epoch 1012/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2664282268.5785 - val_loss: 4952140213.7564\n",
      "Epoch 1013/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 2340299592.6078 - val_loss: 4920006847.1179\n",
      "Epoch 1014/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 2778457107.5926 - val_loss: 5816710619.6703\n",
      "Epoch 1015/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 3912050996.8711 - val_loss: 3851832934.2650\n",
      "Epoch 1016/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 2509682481.9899 - val_loss: 12375306496.3601\n",
      "Epoch 1017/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 2951845838.4423 - val_loss: 6818836221.5876\n",
      "Epoch 1018/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 2611937984.7563 - val_loss: 4389198647.3767\n",
      "Epoch 1019/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 2806836347.0298 - val_loss: 4388488283.2023\n",
      "Epoch 1020/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 2669703551.6398 - val_loss: 6559023601.7418\n",
      "Epoch 1021/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 2306997113.5892 - val_loss: 10692407177.0374\n",
      "Epoch 1022/10000\n",
      "3554/3554 [==============================] - 0s 137us/step - loss: 3546443355.3360 - val_loss: 11833694544.9947\n",
      "Epoch 1023/10000\n",
      "3554/3554 [==============================] - 1s 179us/step - loss: 3835310163.2324 - val_loss: 4124293298.9255\n",
      "Epoch 1024/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 2411610476.7676 - val_loss: 7173937599.1899\n",
      "Epoch 1025/10000\n",
      "3554/3554 [==============================] - 0s 130us/step - loss: 2510794628.2138 - val_loss: 12107558283.4858\n",
      "Epoch 1026/10000\n",
      "3554/3554 [==============================] - 0s 134us/step - loss: 2533572251.0118 - val_loss: 4462481482.2706\n",
      "Epoch 1027/10000\n",
      "3554/3554 [==============================] - 1s 161us/step - loss: 2782425002.1384 - val_loss: 4946832533.9994\n",
      "Epoch 1028/10000\n",
      "3554/3554 [==============================] - 1s 157us/step - loss: 2167276307.3765 - val_loss: 6009635718.9131\n",
      "Epoch 1029/10000\n",
      "3554/3554 [==============================] - 1s 151us/step - loss: 3268829343.6218 - val_loss: 4897023159.0526\n",
      "Epoch 1030/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 3118177143.1401 - val_loss: 4958966975.5859\n",
      "Epoch 1031/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 2614251666.3500 - val_loss: 4387393294.1648\n",
      "Epoch 1032/10000\n",
      "3554/3554 [==============================] - 1s 151us/step - loss: 2553342644.9432 - val_loss: 9402007959.8717\n",
      "Epoch 1033/10000\n",
      "3554/3554 [==============================] - 1s 149us/step - loss: 2275156396.0113 - val_loss: 4225834891.4858\n",
      "Epoch 1034/10000\n",
      "3554/3554 [==============================] - 1s 145us/step - loss: 2291472247.1761 - val_loss: 4781704340.1992\n",
      "Epoch 1035/10000\n",
      "3554/3554 [==============================] - 1s 166us/step - loss: 2690929782.5098 - val_loss: 5998138267.9764\n",
      "Epoch 1036/10000\n",
      "3554/3554 [==============================] - 1s 159us/step - loss: 2065540822.4378 - val_loss: 4310880287.6129\n",
      "Epoch 1037/10000\n",
      "3554/3554 [==============================] - 1s 161us/step - loss: 2113328007.1761 - val_loss: 3754368006.3730\n",
      "Epoch 1038/10000\n",
      "3554/3554 [==============================] - 1s 185us/step - loss: 2611570139.4080 - val_loss: 5418328782.4023\n",
      "Epoch 1039/10000\n",
      "3554/3554 [==============================] - 1s 167us/step - loss: 2415716820.2048 - val_loss: 5820513708.6830\n",
      "Epoch 1040/10000\n",
      "3554/3554 [==============================] - 1s 154us/step - loss: 2592131585.7288 - val_loss: 12618819002.1491\n",
      "Epoch 1041/10000\n",
      "3554/3554 [==============================] - 1s 158us/step - loss: 3241927568.4232 - val_loss: 3882572705.0982\n",
      "Epoch 1042/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 2328624616.3016 - val_loss: 3732808283.9404\n",
      "Epoch 1043/10000\n",
      "3554/3554 [==============================] - 0s 137us/step - loss: 2224732264.0135 - val_loss: 6890106450.7769\n",
      "Epoch 1044/10000\n",
      "3554/3554 [==============================] - 1s 197us/step - loss: 4952588919.8604 - val_loss: 24263685674.4866\n",
      "Epoch 1045/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 5161548389.4204 - val_loss: 4045081389.9319\n",
      "Epoch 1046/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 2284184287.2977 - val_loss: 4488993971.5961\n",
      "Epoch 1047/10000\n",
      "3554/3554 [==============================] - 1s 171us/step - loss: 2480410037.4834 - val_loss: 4325173404.5165\n",
      "Epoch 1048/10000\n",
      "3554/3554 [==============================] - 1s 150us/step - loss: 1859212035.0253 - val_loss: 4323162948.0146\n",
      "Epoch 1049/10000\n",
      "3554/3554 [==============================] - 0s 141us/step - loss: 2668273088.1801 - val_loss: 6061477664.8371\n",
      "Epoch 1050/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 2091258792.5763 - val_loss: 3608119110.1030\n",
      "Epoch 1051/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 1931209340.0383 - val_loss: 5696270095.4824\n",
      "Epoch 1052/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 2278677597.4789 - val_loss: 5246789661.5606\n",
      "Epoch 1053/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 3232510597.1863 - val_loss: 6633631303.7232\n",
      "Epoch 1054/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 2784430220.3894 - val_loss: 3822879209.2084\n",
      "Epoch 1055/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1906012777.4541 - val_loss: 8226162255.1404\n",
      "Epoch 1056/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 2769748262.8970 - val_loss: 4032162965.2433\n",
      "Epoch 1057/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 2210013818.1654 - val_loss: 5855356249.9781\n",
      "Epoch 1058/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1994057221.1863 - val_loss: 4075218653.3626\n",
      "Epoch 1059/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 2931458959.4328 - val_loss: 7298121672.0473\n",
      "Epoch 1060/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 2096582607.5948 - val_loss: 8179078039.4397\n",
      "Epoch 1061/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 2320535436.4615 - val_loss: 8229530651.0762\n",
      "Epoch 1062/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 3163502194.3860 - val_loss: 6748241055.7210\n",
      "Epoch 1063/10000\n",
      "3554/3554 [==============================] - 0s 136us/step - loss: 4149850833.1435 - val_loss: 3545804286.4698\n",
      "Epoch 1064/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 1982403582.9916 - val_loss: 3495947791.2754\n",
      "Epoch 1065/10000\n",
      "3554/3554 [==============================] - 1s 146us/step - loss: 2036500797.5149 - val_loss: 10357384115.6681\n",
      "Epoch 1066/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 2860344325.0422 - val_loss: 5859466093.7091\n",
      "Epoch 1067/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 2598604834.2870 - val_loss: 5779213276.4264\n",
      "Epoch 1068/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 2007262290.5301 - val_loss: 8921588101.9409\n",
      "Epoch 1069/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 2636670610.9443 - val_loss: 4828298486.5665\n",
      "Epoch 1070/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 2366763659.3089 - val_loss: 5998112242.5879\n",
      "Epoch 1071/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 2325193673.8323 - val_loss: 4007309893.3648\n",
      "Epoch 1072/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 2615108356.2499 - val_loss: 3877722054.7781\n",
      "Epoch 1073/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 1949382858.1204 - val_loss: 3738131465.2895\n",
      "Epoch 1074/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1824874064.2431 - val_loss: 6354270249.4785\n",
      "Epoch 1075/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 2463534562.3950 - val_loss: 4700351022.2312\n",
      "Epoch 1076/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 2218036481.0084 - val_loss: 12820566026.0816\n",
      "Epoch 1077/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 3727958929.8638 - val_loss: 4491082587.0942\n",
      "Epoch 1078/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1712020137.4902 - val_loss: 3790085325.7361\n",
      "Epoch 1079/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1821488102.3568 - val_loss: 4473598180.3117\n",
      "Epoch 1080/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1779987019.9212 - val_loss: 5411433755.9404\n",
      "Epoch 1081/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 120us/step - loss: 2950528413.4609 - val_loss: 6509061837.1601\n",
      "Epoch 1082/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 2669884614.8790 - val_loss: 6573294349.0340\n",
      "Epoch 1083/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 2190725782.6899 - val_loss: 8186260894.3527\n",
      "Epoch 1084/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 2728951755.5611 - val_loss: 4291374494.3527\n",
      "Epoch 1085/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1843742535.9595 - val_loss: 13787400140.4399\n",
      "Epoch 1086/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 3132962023.6533 - val_loss: 3862864312.2768\n",
      "Epoch 1087/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 2826210523.9977 - val_loss: 4519728234.3426\n",
      "Epoch 1088/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 2301425489.1075 - val_loss: 3549926005.4031\n",
      "Epoch 1089/10000\n",
      "3554/3554 [==============================] - 0s 135us/step - loss: 2017555179.0568 - val_loss: 5207339901.7316\n",
      "Epoch 1090/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1933257848.7428 - val_loss: 3476169159.3992\n",
      "Epoch 1091/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 2318601497.7693 - val_loss: 4165685594.2301\n",
      "Epoch 1092/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 1993181096.5177 - val_loss: 3256335695.4284\n",
      "Epoch 1093/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1744619776.1801 - val_loss: 4239782193.1927\n",
      "Epoch 1094/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 2313525668.4299 - val_loss: 3724459015.1156\n",
      "Epoch 1095/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1987297380.1238 - val_loss: 4091801821.3896\n",
      "Epoch 1096/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1882900840.5898 - val_loss: 3580122875.1685\n",
      "Epoch 1097/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1944920622.8205 - val_loss: 6018729796.2667\n",
      "Epoch 1098/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 2046992660.0248 - val_loss: 3603664729.5505\n",
      "Epoch 1099/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 2761251562.9668 - val_loss: 4097136069.0239\n",
      "Epoch 1100/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 2355533862.7890 - val_loss: 5812206368.4771\n",
      "Epoch 1101/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 2146923443.6466 - val_loss: 4336805164.2062\n",
      "Epoch 1102/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 3209481235.3585 - val_loss: 3306254656.3961\n",
      "Epoch 1103/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 1784070257.6297 - val_loss: 3684401937.1387\n",
      "Epoch 1104/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 2240505869.8301 - val_loss: 13916928376.0428\n",
      "Epoch 1105/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 3730814566.1767 - val_loss: 3898912071.8245\n",
      "Epoch 1106/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 2213067816.1936 - val_loss: 4146424686.7713\n",
      "Epoch 1107/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1916355345.7198 - val_loss: 6423356978.8399\n",
      "Epoch 1108/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 2733234944.7923 - val_loss: 3726966956.5390\n",
      "Epoch 1109/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 2236214188.5875 - val_loss: 4882769926.8906\n",
      "Epoch 1110/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 4700514180.1058 - val_loss: 6873157862.7601\n",
      "Epoch 1111/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 2609812463.2887 - val_loss: 9833657490.7949\n",
      "Epoch 1112/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 2522170792.0495 - val_loss: 5033660204.5390\n",
      "Epoch 1113/10000\n",
      "3554/3554 [==============================] - 0s 137us/step - loss: 1754477824.6843 - val_loss: 3971979834.0411\n",
      "Epoch 1114/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 2144482188.5695 - val_loss: 3216352006.7331\n",
      "Epoch 1115/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1717788083.0703 - val_loss: 6195186655.9550\n",
      "Epoch 1116/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 2198095650.2510 - val_loss: 3351995886.1840\n",
      "Epoch 1117/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1464038960.7653 - val_loss: 3293409142.5665\n",
      "Epoch 1118/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1850391859.8897 - val_loss: 10731561081.1229\n",
      "Epoch 1119/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2532537676.8576 - val_loss: 3453994888.7494\n",
      "Epoch 1120/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1853053291.1109 - val_loss: 3555137946.1401\n",
      "Epoch 1121/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 1967775227.9662 - val_loss: 3312184351.6489\n",
      "Epoch 1122/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 2323280332.1193 - val_loss: 3760873302.8546\n",
      "Epoch 1123/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 2750601328.2161 - val_loss: 4145058459.5083\n",
      "Epoch 1124/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 2202916989.6230 - val_loss: 4285515694.1232\n",
      "Epoch 1125/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 2136485522.2600 - val_loss: 3442141195.8819\n",
      "Epoch 1126/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 1821865855.9280 - val_loss: 9299158199.9887\n",
      "Epoch 1127/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 2658061980.4524 - val_loss: 9977428232.1373\n",
      "Epoch 1128/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 3086376822.0777 - val_loss: 3871027156.4692\n",
      "Epoch 1129/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1761337892.8441 - val_loss: 4058674628.2082\n",
      "Epoch 1130/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 2152304787.5926 - val_loss: 3239080267.9179\n",
      "Epoch 1131/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 1729394890.1564 - val_loss: 3941997328.7066\n",
      "Epoch 1132/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 1623443508.8711 - val_loss: 3887799144.5783\n",
      "Epoch 1133/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1949547109.4204 - val_loss: 3396813740.0799\n",
      "Epoch 1134/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1933036943.3427 - val_loss: 3672319453.7947\n",
      "Epoch 1135/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1962657204.7991 - val_loss: 3361916693.8734\n",
      "Epoch 1136/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 2120228036.3579 - val_loss: 3883193318.3235\n",
      "Epoch 1137/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1763257067.2549 - val_loss: 4579205681.1072\n",
      "Epoch 1138/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 2442689545.1120 - val_loss: 3250929097.2174\n",
      "Epoch 1139/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1739252647.9055 - val_loss: 4157587975.2911\n",
      "Epoch 1140/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1550391945.2921 - val_loss: 3640324093.8577\n",
      "Epoch 1141/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 2064954625.5847 - val_loss: 4548474531.0335\n",
      "Epoch 1142/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 2505222856.2476 - val_loss: 9165285491.7941\n",
      "Epoch 1143/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2789048952.6168 - val_loss: 4115460906.3466\n",
      "Epoch 1144/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1758257229.6500 - val_loss: 6433735672.4388\n",
      "Epoch 1145/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 1898713201.7378 - val_loss: 3339435074.7634\n",
      "Epoch 1146/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 2569337872.7473 - val_loss: 3794115458.9345\n",
      "Epoch 1147/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1840967554.9533 - val_loss: 4420580533.3243\n",
      "Epoch 1148/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1888697128.9139 - val_loss: 4939958217.7395\n",
      "Epoch 1149/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2181577296.6213 - val_loss: 3488247744.7516\n",
      "Epoch 1150/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 2075270062.4603 - val_loss: 4322449771.1527\n",
      "Epoch 1151/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2932167940.7901 - val_loss: 6322442576.0765\n",
      "Epoch 1152/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2172274372.9342 - val_loss: 3209898851.5195\n",
      "Epoch 1153/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1686831958.1497 - val_loss: 4405890733.7632\n",
      "Epoch 1154/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 2235424776.5718 - val_loss: 6369150051.3755\n",
      "Epoch 1155/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1770367213.2718 - val_loss: 3287559343.6895\n",
      "Epoch 1156/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1739339691.2909 - val_loss: 4270612487.2731\n",
      "Epoch 1157/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1883830720.9769 - val_loss: 4332143920.9316\n",
      "Epoch 1158/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1816471994.8497 - val_loss: 7531369901.6191\n",
      "Epoch 1159/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2787479209.5622 - val_loss: 8515032289.4672\n",
      "Epoch 1160/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1880431676.3624 - val_loss: 6204144715.6118\n",
      "Epoch 1161/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 3355756564.4570 - val_loss: 3587880267.2698\n",
      "Epoch 1162/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1688549705.5982 - val_loss: 2991996273.0757\n",
      "Epoch 1163/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1709775525.7445 - val_loss: 4029368764.8135\n",
      "Epoch 1164/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1529864164.4840 - val_loss: 2858647302.1930\n",
      "Epoch 1165/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1391633604.1058 - val_loss: 3073807401.3255\n",
      "Epoch 1166/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1451512026.0394 - val_loss: 3041023652.6357\n",
      "Epoch 1167/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2006889484.2454 - val_loss: 5206745520.4996\n",
      "Epoch 1168/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1963717718.2938 - val_loss: 3286055022.1052\n",
      "Epoch 1169/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1864275008.7563 - val_loss: 3530760016.8686\n",
      "Epoch 1170/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1821319778.0709 - val_loss: 3696109800.5963\n",
      "Epoch 1171/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 1580908871.8875 - val_loss: 5544803986.6869\n",
      "Epoch 1172/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 1765532494.3703 - val_loss: 3076104622.8118\n",
      "Epoch 1173/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1954385415.4373 - val_loss: 3600934800.0945\n",
      "Epoch 1174/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1750563701.2673 - val_loss: 3439055781.2118\n",
      "Epoch 1175/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1748741480.3737 - val_loss: 7195331697.3457\n",
      "Epoch 1176/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1695177550.6764 - val_loss: 3020346720.3421\n",
      "Epoch 1177/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1424309878.0597 - val_loss: 3064689978.3471\n",
      "Epoch 1178/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1879494595.1334 - val_loss: 6014247680.4141\n",
      "Epoch 1179/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1895202435.5295 - val_loss: 3362210397.2186\n",
      "Epoch 1180/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1700059497.0219 - val_loss: 11129980041.3975\n",
      "Epoch 1181/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 2587007270.0326 - val_loss: 3469783410.0298\n",
      "Epoch 1182/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 2475093520.7113 - val_loss: 5590472590.9176\n",
      "Epoch 1183/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 2908384309.0152 - val_loss: 8093300823.9257\n",
      "Epoch 1184/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1678056987.0838 - val_loss: 4797678537.4515\n",
      "Epoch 1185/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1971183122.1519 - val_loss: 5196439010.7634\n",
      "Epoch 1186/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 2310863672.1125 - val_loss: 10127003320.1328\n",
      "Epoch 1187/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 2300935058.6922 - val_loss: 3145610781.2186\n",
      "Epoch 1188/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 1438500480.4854 - val_loss: 7094762071.2416\n",
      "Epoch 1189/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 2163175721.2020 - val_loss: 5054239350.6025\n",
      "Epoch 1190/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1637253682.9623 - val_loss: 3838582170.8242\n",
      "Epoch 1191/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 1740359500.1013 - val_loss: 4768283607.4037\n",
      "Epoch 1192/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1551573763.7456 - val_loss: 7437766363.8323\n",
      "Epoch 1193/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 3213276908.9116 - val_loss: 3447772208.0675\n",
      "Epoch 1194/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1877110008.2746 - val_loss: 3724780347.0492\n",
      "Epoch 1195/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 2131782893.7040 - val_loss: 6684750795.4318\n",
      "Epoch 1196/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1459089120.5943 - val_loss: 3556354201.2579\n",
      "Epoch 1197/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1826691206.0574 - val_loss: 3587128778.8917\n",
      "Epoch 1198/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 1926082878.3793 - val_loss: 3606036920.7809\n",
      "Epoch 1199/10000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 1720746999.3562 - val_loss: 6062589926.3640\n",
      "Epoch 1200/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 2128061366.3118 - val_loss: 4618501844.7662\n",
      "Epoch 1201/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 1871402355.1244 - val_loss: 4440035856.2025\n",
      "Epoch 1202/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 1599410421.9516 - val_loss: 3273534393.6810\n",
      "Epoch 1203/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1753483846.9150 - val_loss: 4532725203.9651\n",
      "Epoch 1204/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1992736811.2189 - val_loss: 7606324818.5249\n",
      "Epoch 1205/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 2307431699.4485 - val_loss: 3999887262.7218\n",
      "Epoch 1206/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1509476544.6123 - val_loss: 7204546255.7345\n",
      "Epoch 1207/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 2472319035.3540 - val_loss: 4301859218.7229\n",
      "Epoch 1208/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 2918515755.6511 - val_loss: 3668256896.9902\n",
      "Epoch 1209/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 91us/step - loss: 1769545907.0703 - val_loss: 4306166124.9530\n",
      "Epoch 1210/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 2623963433.5802 - val_loss: 2803901563.7243\n",
      "Epoch 1211/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1634383502.0371 - val_loss: 4853489258.3246\n",
      "Epoch 1212/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1234298284.2994 - val_loss: 3225479281.1927\n",
      "Epoch 1213/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 2110499670.2577 - val_loss: 3616162395.5803\n",
      "Epoch 1214/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1616183274.2465 - val_loss: 3222410697.1634\n",
      "Epoch 1215/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 1879075791.6669 - val_loss: 4263441233.3367\n",
      "Epoch 1216/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1474010529.2065 - val_loss: 2927468101.8239\n",
      "Epoch 1217/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1268469146.7597 - val_loss: 2814253170.1963\n",
      "Epoch 1218/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 2429034056.2476 - val_loss: 8320542110.4968\n",
      "Epoch 1219/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1470721707.3630 - val_loss: 3460786713.7800\n",
      "Epoch 1220/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1778330220.6235 - val_loss: 4836531758.0152\n",
      "Epoch 1221/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2174569663.0276 - val_loss: 3161657626.6217\n",
      "Epoch 1222/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 1549732929.5490 - val_loss: 4471981761.7103\n",
      "Epoch 1223/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1365455168.2611 - val_loss: 8027179329.2782\n",
      "Epoch 1224/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 2067002736.2251 - val_loss: 3380995630.9513\n",
      "Epoch 1225/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 2131459856.2791 - val_loss: 4420260785.3637\n",
      "Epoch 1226/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1576110749.0647 - val_loss: 12857805992.4343\n",
      "Epoch 1227/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2920498731.0748 - val_loss: 3290475562.9907\n",
      "Epoch 1228/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1450901657.5712 - val_loss: 6988121928.3533\n",
      "Epoch 1229/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2992220001.0985 - val_loss: 3967628158.9198\n",
      "Epoch 1230/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1508798974.8475 - val_loss: 4220105070.6813\n",
      "Epoch 1231/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 1442527424.7563 - val_loss: 3277070022.8231\n",
      "Epoch 1232/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 1202886370.4491 - val_loss: 2642942833.1387\n",
      "Epoch 1233/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 1159000832.2161 - val_loss: 5021920170.5496\n",
      "Epoch 1234/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 2315856685.2358 - val_loss: 3706135977.4065\n",
      "Epoch 1235/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1386657544.2116 - val_loss: 3266428648.1823\n",
      "Epoch 1236/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1523448016.8914 - val_loss: 11793461443.0425\n",
      "Epoch 1237/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 4231605430.0011 - val_loss: 2699881189.7204\n",
      "Epoch 1238/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1247130172.1463 - val_loss: 2838496796.3184\n",
      "Epoch 1239/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2102870332.7406 - val_loss: 3537393512.9294\n",
      "Epoch 1240/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1107009361.9358 - val_loss: 4877285420.7550\n",
      "Epoch 1241/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2107415593.9223 - val_loss: 3009540518.7871\n",
      "Epoch 1242/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 1491385774.1002 - val_loss: 3535150954.6667\n",
      "Epoch 1243/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1392056517.0782 - val_loss: 3550631912.1103\n",
      "Epoch 1244/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1339483247.8469 - val_loss: 2723043159.3406\n",
      "Epoch 1245/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1724078779.2819 - val_loss: 5453550632.0383\n",
      "Epoch 1246/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1599966598.9150 - val_loss: 2654891121.7778\n",
      "Epoch 1247/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 2263484174.1902 - val_loss: 6836995176.8484\n",
      "Epoch 1248/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1452575942.3748 - val_loss: 3663880817.8498\n",
      "Epoch 1249/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2118961336.8329 - val_loss: 4794941595.2923\n",
      "Epoch 1250/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1947539816.8779 - val_loss: 5640385613.4481\n",
      "Epoch 1251/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2459621284.3759 - val_loss: 4524364962.1333\n",
      "Epoch 1252/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 6178892484.4660 - val_loss: 2852629824.8101\n",
      "Epoch 1253/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1094486688.5222 - val_loss: 2891282275.6816\n",
      "Epoch 1254/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1145751242.4086 - val_loss: 7653071240.0293\n",
      "Epoch 1255/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1713727389.6590 - val_loss: 2873461081.4200\n",
      "Epoch 1256/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1091992572.9387 - val_loss: 3150932297.8115\n",
      "Epoch 1257/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1208860577.2065 - val_loss: 3823159278.1412\n",
      "Epoch 1258/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1220704633.9944 - val_loss: 2778165667.9696\n",
      "Epoch 1259/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1171197860.3759 - val_loss: 6211330687.8020\n",
      "Epoch 1260/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1616059436.8396 - val_loss: 4388356604.3994\n",
      "Epoch 1261/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1451940037.7265 - val_loss: 3298936462.8523\n",
      "Epoch 1262/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1613787479.4463 - val_loss: 6272780211.3800\n",
      "Epoch 1263/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 2234556023.0861 - val_loss: 2969277750.9446\n",
      "Epoch 1264/10000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 1255286269.6230 - val_loss: 8109376820.5682\n",
      "Epoch 1265/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 2223913130.7867 - val_loss: 3026251782.2470\n",
      "Epoch 1266/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1300339506.9983 - val_loss: 3744913114.7342\n",
      "Epoch 1267/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1597823683.7456 - val_loss: 3609750340.4827\n",
      "Epoch 1268/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1525194006.5098 - val_loss: 5637112576.5041\n",
      "Epoch 1269/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1516256117.8796 - val_loss: 3018284495.0323\n",
      "Epoch 1270/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1435530281.7783 - val_loss: 3774023024.1575\n",
      "Epoch 1271/10000\n",
      "3554/3554 [==============================] - 0s 141us/step - loss: 2240395011.4575 - val_loss: 3587351558.0489\n",
      "Epoch 1272/10000\n",
      "3554/3554 [==============================] - 0s 130us/step - loss: 1557478277.6905 - val_loss: 3833801169.4987\n",
      "Epoch 1273/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 1479189085.1367 - val_loss: 2762909550.3775\n",
      "Epoch 1274/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1381366792.3196 - val_loss: 4046200297.1724\n",
      "Epoch 1275/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 1910691288.5267 - val_loss: 3032161220.5907\n",
      "Epoch 1276/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 3150468652.1283 - val_loss: 5527618017.4672\n",
      "Epoch 1277/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 1356944983.5903 - val_loss: 3259776222.3347\n",
      "Epoch 1278/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 2474265094.4108 - val_loss: 3361755523.9606\n",
      "Epoch 1279/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 1364095771.6601 - val_loss: 3418678202.4371\n",
      "Epoch 1280/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 1421700648.1936 - val_loss: 3979148899.4250\n",
      "Epoch 1281/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1444649955.5476 - val_loss: 2743047748.7707\n",
      "Epoch 1282/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1837822688.9544 - val_loss: 3350780781.2591\n",
      "Epoch 1283/10000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 1461458024.5898 - val_loss: 9900809789.2096\n",
      "Epoch 1284/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 3070006283.0929 - val_loss: 4507763848.3893\n",
      "Epoch 1285/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 1859241918.5954 - val_loss: 3222491257.4110\n",
      "Epoch 1286/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 1418445132.3894 - val_loss: 3494649545.4852\n",
      "Epoch 1287/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 1507137824.3061 - val_loss: 2547531193.6698\n",
      "Epoch 1288/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 1665222036.0968 - val_loss: 4984913398.5035\n",
      "Epoch 1289/10000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 2085594278.4648 - val_loss: 4804387661.9522\n",
      "Epoch 1290/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 1315909788.3804 - val_loss: 2790436434.7499\n",
      "Epoch 1291/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 2072605871.0366 - val_loss: 9657326709.2343\n",
      "Epoch 1292/10000\n",
      "3554/3554 [==============================] - 0s 130us/step - loss: 1911539418.3995 - val_loss: 3656350241.6107\n",
      "Epoch 1293/10000\n",
      "3554/3554 [==============================] - 1s 159us/step - loss: 1175034456.5988 - val_loss: 2931227834.4191\n",
      "Epoch 1294/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 1334869067.2549 - val_loss: 6534434242.1423\n",
      "Epoch 1295/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 2483978578.5481 - val_loss: 5082162840.1058\n",
      "Epoch 1296/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 2158763835.2459 - val_loss: 3128095674.2526\n",
      "Epoch 1297/10000\n",
      "3554/3554 [==============================] - 1s 152us/step - loss: 1520012763.7681 - val_loss: 3462150741.3333\n",
      "Epoch 1298/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 1444929042.0720 - val_loss: 2453728444.3027\n",
      "Epoch 1299/10000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 1210292027.2099 - val_loss: 3299615543.7637\n",
      "Epoch 1300/10000\n",
      "3554/3554 [==============================] - 1s 174us/step - loss: 1291486534.5549 - val_loss: 3268398332.0304\n",
      "Epoch 1301/10000\n",
      "3554/3554 [==============================] - 1s 163us/step - loss: 1399217091.7817 - val_loss: 4126800504.3398\n",
      "Epoch 1302/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 2215374914.5931 - val_loss: 2804708743.3677\n",
      "Epoch 1303/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1191063528.4097 - val_loss: 2552017503.7930\n",
      "Epoch 1304/10000\n",
      "3554/3554 [==============================] - 1s 147us/step - loss: 1681834645.2133 - val_loss: 2713439890.7038\n",
      "Epoch 1305/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 1348865940.9972 - val_loss: 3286600531.6771\n",
      "Epoch 1306/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 1238174950.6449 - val_loss: 3249518730.0546\n",
      "Epoch 1307/10000\n",
      "3554/3554 [==============================] - 0s 141us/step - loss: 1416480133.4024 - val_loss: 4433880773.9589\n",
      "Epoch 1308/10000\n",
      "3554/3554 [==============================] - 0s 135us/step - loss: 1808116404.3309 - val_loss: 3849698933.8824\n",
      "Epoch 1309/10000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 1446643388.8666 - val_loss: 2867159101.9927\n",
      "Epoch 1310/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 2005703815.3652 - val_loss: 4410485658.8242\n",
      "Epoch 1311/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 1441971807.6061 - val_loss: 3255778595.0695\n",
      "Epoch 1312/10000\n",
      "3554/3554 [==============================] - 1s 154us/step - loss: 2027418053.5104 - val_loss: 5481455908.4827\n",
      "Epoch 1313/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 1947239446.2577 - val_loss: 2433698148.2217\n",
      "Epoch 1314/10000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 1401381188.4299 - val_loss: 5864144794.8962\n",
      "Epoch 1315/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 1890101356.1418 - val_loss: 4763024825.1139\n",
      "Epoch 1316/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 1207575982.3163 - val_loss: 3467696729.3885\n",
      "Epoch 1317/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 1671253582.5864 - val_loss: 2510706865.9263\n",
      "Epoch 1318/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 2798300102.9510 - val_loss: 4023114072.2858\n",
      "Epoch 1319/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1731769108.8891 - val_loss: 2639730857.6585\n",
      "Epoch 1320/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1264805098.2645 - val_loss: 3057425007.9055\n",
      "Epoch 1321/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1517012432.7293 - val_loss: 3077203995.0402\n",
      "Epoch 1322/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1172852264.6258 - val_loss: 12126371260.5255\n",
      "Epoch 1323/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 2519864610.2870 - val_loss: 3053442555.9314\n",
      "Epoch 1324/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1368536586.2285 - val_loss: 4020722273.7193\n",
      "Epoch 1325/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 2237938387.1964 - val_loss: 3196269926.5440\n",
      "Epoch 1326/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1314006345.8233 - val_loss: 2496574676.6312\n",
      "Epoch 1327/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1145057571.3562 - val_loss: 2822109589.8734\n",
      "Epoch 1328/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 1411886577.5937 - val_loss: 3632125905.2647\n",
      "Epoch 1329/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 1471947492.1958 - val_loss: 9026004168.1193\n",
      "Epoch 1330/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 2358664725.0332 - val_loss: 6691258348.2689\n",
      "Epoch 1331/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 2808859121.7107 - val_loss: 2780837586.5789\n",
      "Epoch 1332/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 1526852680.9859 - val_loss: 3348786832.5986\n",
      "Epoch 1333/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1976767165.0827 - val_loss: 9992373068.6920\n",
      "Epoch 1334/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1648625746.1519 - val_loss: 3216782477.3131\n",
      "Epoch 1335/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1449863211.1289 - val_loss: 2895015880.0113\n",
      "Epoch 1336/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1049496731.9842 - val_loss: 3558009779.9201\n",
      "Epoch 1337/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 85us/step - loss: 1232791035.4620 - val_loss: 2713385894.9401\n",
      "Epoch 1338/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1488519346.6382 - val_loss: 14481545476.1046\n",
      "Epoch 1339/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 3289745734.4468 - val_loss: 2638775465.1679\n",
      "Epoch 1340/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1080097125.2043 - val_loss: 3955281127.3361\n",
      "Epoch 1341/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1266174718.5774 - val_loss: 3600553405.2366\n",
      "Epoch 1342/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 1047223741.5869 - val_loss: 5081915638.2785\n",
      "Epoch 1343/10000\n",
      "3554/3554 [==============================] - 0s 134us/step - loss: 1264255715.9437 - val_loss: 3023440571.2653\n",
      "Epoch 1344/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 1272729160.7158 - val_loss: 5811870909.1736\n",
      "Epoch 1345/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 1889538810.3815 - val_loss: 7036469860.8158\n",
      "Epoch 1346/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1302495451.8402 - val_loss: 16074810549.4684\n",
      "Epoch 1347/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 4212573049.9494 - val_loss: 2767201788.0866\n",
      "Epoch 1348/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 1315162203.9122 - val_loss: 2893482760.2228\n",
      "Epoch 1349/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 1287483289.9313 - val_loss: 2518836491.1797\n",
      "Epoch 1350/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1161425990.0326 - val_loss: 2711952061.7204\n",
      "Epoch 1351/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1029289853.8931 - val_loss: 3561382604.1384\n",
      "Epoch 1352/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1407921869.4699 - val_loss: 3593329396.6942\n",
      "Epoch 1353/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2187028605.9111 - val_loss: 4648108900.8878\n",
      "Epoch 1354/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 3015699797.7175 - val_loss: 3284083572.0731\n",
      "Epoch 1355/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1105123925.3573 - val_loss: 2647033426.9210\n",
      "Epoch 1356/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1218072637.8210 - val_loss: 2843019537.6428\n",
      "Epoch 1357/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1444828343.6083 - val_loss: 4226562842.2841\n",
      "Epoch 1358/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1253491927.5543 - val_loss: 2743548095.4779\n",
      "Epoch 1359/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 1162505249.6027 - val_loss: 3661502046.8388\n",
      "Epoch 1360/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 1281732358.9150 - val_loss: 3208257492.5052\n",
      "Epoch 1361/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1198913192.1486 - val_loss: 2477848682.0006\n",
      "Epoch 1362/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1467384578.6292 - val_loss: 6478821231.4014\n",
      "Epoch 1363/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1358305204.8790 - val_loss: 2395700954.0951\n",
      "Epoch 1364/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 958578352.9612 - val_loss: 2720531595.1617\n",
      "Epoch 1365/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1048255532.2994 - val_loss: 4651067852.0079\n",
      "Epoch 1366/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1945729685.8255 - val_loss: 5613673781.5044\n",
      "Epoch 1367/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1621197874.9263 - val_loss: 3955846484.0371\n",
      "Epoch 1368/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1599167099.0298 - val_loss: 3406123870.8073\n",
      "Epoch 1369/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1443695555.3495 - val_loss: 5584867233.3772\n",
      "Epoch 1370/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1131575897.8953 - val_loss: 3344394938.6352\n",
      "Epoch 1371/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1498075111.7974 - val_loss: 4128065550.5463\n",
      "Epoch 1372/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 2225286390.2893 - val_loss: 6312683086.1322\n",
      "Epoch 1373/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1186710940.7406 - val_loss: 2500081709.4661\n",
      "Epoch 1374/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1104509613.7400 - val_loss: 10636890333.0745\n",
      "Epoch 1375/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1738891499.9032 - val_loss: 2416556565.6844\n",
      "Epoch 1376/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1317567079.0051 - val_loss: 5197337129.6225\n",
      "Epoch 1377/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 2088771234.5751 - val_loss: 4844750192.9136\n",
      "Epoch 1378/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1584289378.3950 - val_loss: 5696050813.5156\n",
      "Epoch 1379/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 2063644674.9893 - val_loss: 3652108565.4774\n",
      "Epoch 1380/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 1485222841.5892 - val_loss: 2738093880.9699\n",
      "Epoch 1381/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 1232363776.8284 - val_loss: 3145912727.1696\n",
      "Epoch 1382/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 1027815501.6950 - val_loss: 2706649804.1879\n",
      "Epoch 1383/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1253504191.2662 - val_loss: 3378105760.5311\n",
      "Epoch 1384/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 1086017647.3517 - val_loss: 4107793992.7494\n",
      "Epoch 1385/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1478610180.6100 - val_loss: 2679212515.0065\n",
      "Epoch 1386/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1228637619.8267 - val_loss: 9111554063.6985\n",
      "Epoch 1387/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 2641393581.0197 - val_loss: 2848562530.2594\n",
      "Epoch 1388/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1253085229.0377 - val_loss: 3427333224.6684\n",
      "Epoch 1389/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1432315943.3472 - val_loss: 2974725472.3150\n",
      "Epoch 1390/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1470196552.7158 - val_loss: 3055291172.6537\n",
      "Epoch 1391/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1120273884.5605 - val_loss: 3098259498.2391\n",
      "Epoch 1392/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 2062409585.3776 - val_loss: 2719725441.8363\n",
      "Epoch 1393/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1306964981.5554 - val_loss: 2487480555.9629\n",
      "Epoch 1394/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 1764274710.6179 - val_loss: 7368405463.3857\n",
      "Epoch 1395/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1574873230.7665 - val_loss: 3130446742.9626\n",
      "Epoch 1396/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1110461138.0259 - val_loss: 2847306462.7668\n",
      "Epoch 1397/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 1601799717.3123 - val_loss: 4062754356.2802\n",
      "Epoch 1398/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 1593123756.0833 - val_loss: 3182400571.8684\n",
      "Epoch 1399/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1529722552.2926 - val_loss: 3898418449.0667\n",
      "Epoch 1400/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 1145618021.1322 - val_loss: 4170291493.3738\n",
      "Epoch 1401/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1669811764.9792 - val_loss: 3781313973.2118\n",
      "Epoch 1402/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1290265817.8233 - val_loss: 2843875866.0681\n",
      "Epoch 1403/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 2177820344.8509 - val_loss: 2510969460.4422\n",
      "Epoch 1404/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1055404878.7575 - val_loss: 3738872541.0385\n",
      "Epoch 1405/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1190942077.9111 - val_loss: 3040968177.5977\n",
      "Epoch 1406/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1528848392.6438 - val_loss: 10874713442.5834\n",
      "Epoch 1407/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2182291297.3641 - val_loss: 2617461538.9885\n",
      "Epoch 1408/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1277770831.6128 - val_loss: 3093879763.6411\n",
      "Epoch 1409/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1105162675.7186 - val_loss: 2532799489.6383\n",
      "Epoch 1410/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1992095463.4733 - val_loss: 2325260622.0242\n",
      "Epoch 1411/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1038992529.2155 - val_loss: 2940993379.2315\n",
      "Epoch 1412/10000\n",
      "3554/3554 [==============================] - 0s 131us/step - loss: 1806748422.8790 - val_loss: 4000922871.3586\n",
      "Epoch 1413/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1326810568.2116 - val_loss: 4193310082.5564\n",
      "Epoch 1414/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1393104349.4249 - val_loss: 4525160461.2501\n",
      "Epoch 1415/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2092640445.7310 - val_loss: 6848626368.0900\n",
      "Epoch 1416/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1462273517.7040 - val_loss: 2701746781.1646\n",
      "Epoch 1417/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1371089941.0332 - val_loss: 7985553833.2264\n",
      "Epoch 1418/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 2152065551.2887 - val_loss: 2835411833.9871\n",
      "Epoch 1419/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1090595120.3331 - val_loss: 4764980008.6143\n",
      "Epoch 1420/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 1678999876.0698 - val_loss: 3342434079.1089\n",
      "Epoch 1421/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 1250341212.0923 - val_loss: 3699018794.9817\n",
      "Epoch 1422/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 1201025317.9966 - val_loss: 13942745533.6056\n",
      "Epoch 1423/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 3442786041.3371 - val_loss: 2442640964.3252\n",
      "Epoch 1424/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1310525754.0574 - val_loss: 4925717983.7390\n",
      "Epoch 1425/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 2218028380.7766 - val_loss: 2642188719.7525\n",
      "Epoch 1426/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 954521424.3872 - val_loss: 5024018377.2714\n",
      "Epoch 1427/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1134704721.3956 - val_loss: 3982855121.9803\n",
      "Epoch 1428/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1577893552.4007 - val_loss: 3032410324.9913\n",
      "Epoch 1429/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1110612565.8616 - val_loss: 3037215529.1454\n",
      "Epoch 1430/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1135301692.1193 - val_loss: 3027882821.8869\n",
      "Epoch 1431/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1089640681.5262 - val_loss: 2611870885.5269\n",
      "Epoch 1432/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1001599030.6719 - val_loss: 11579968355.8076\n",
      "Epoch 1433/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2241665071.0231 - val_loss: 2206714570.1131\n",
      "Epoch 1434/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1553712905.0760 - val_loss: 2739511579.6433\n",
      "Epoch 1435/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1359492163.9797 - val_loss: 3529581365.9364\n",
      "Epoch 1436/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1159470360.5627 - val_loss: 4619750144.7921\n",
      "Epoch 1437/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1203690352.5853 - val_loss: 2287766822.4135\n",
      "Epoch 1438/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1309039293.1548 - val_loss: 2634935385.7980\n",
      "Epoch 1439/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1541314431.2617 - val_loss: 4230735767.9797\n",
      "Epoch 1440/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 1421141930.7147 - val_loss: 2644192577.3142\n",
      "Epoch 1441/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 999023910.4648 - val_loss: 12434134608.8686\n",
      "Epoch 1442/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2672580291.2459 - val_loss: 2843423840.9271\n",
      "Epoch 1443/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1153835591.1671 - val_loss: 2720755193.1949\n",
      "Epoch 1444/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 1253482440.9679 - val_loss: 4275244800.7741\n",
      "Epoch 1445/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1473370056.9319 - val_loss: 2232704373.5921\n",
      "Epoch 1446/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 3109687504.6033 - val_loss: 11522000564.5322\n",
      "Epoch 1447/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 2318338302.7755 - val_loss: 3306357336.5738\n",
      "Epoch 1448/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1152011549.7040 - val_loss: 2402481038.5643\n",
      "Epoch 1449/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1130098099.9707 - val_loss: 4002755890.0478\n",
      "Epoch 1450/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1493148716.8576 - val_loss: 3478215436.0259\n",
      "Epoch 1451/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1268823725.5959 - val_loss: 4141571815.2641\n",
      "Epoch 1452/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1154307448.4367 - val_loss: 2383530572.7910\n",
      "Epoch 1453/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 923041269.5014 - val_loss: 2322588332.1069\n",
      "Epoch 1454/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 1161179979.0568 - val_loss: 4607794016.1350\n",
      "Epoch 1455/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 1235672097.1345 - val_loss: 7538030122.3426\n",
      "Epoch 1456/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2476101019.0838 - val_loss: 2994381784.8259\n",
      "Epoch 1457/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1732291219.0884 - val_loss: 4478748972.8990\n",
      "Epoch 1458/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1560515091.3044 - val_loss: 13589613268.7212\n",
      "Epoch 1459/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 3242115717.2583 - val_loss: 2516380281.7530\n",
      "Epoch 1460/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1144720018.9443 - val_loss: 2640022608.2745\n",
      "Epoch 1461/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1364293359.2167 - val_loss: 3174457349.0363\n",
      "Epoch 1462/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1041664947.4125 - val_loss: 2198352483.8616\n",
      "Epoch 1463/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1110210460.2003 - val_loss: 2416511729.9938\n",
      "Epoch 1464/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1261493111.1401 - val_loss: 3886112922.6082\n",
      "Epoch 1465/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 95us/step - loss: 1906581204.3489 - val_loss: 3047829958.9671\n",
      "Epoch 1466/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1620148915.2527 - val_loss: 2421525563.7963\n",
      "Epoch 1467/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 926348426.4716 - val_loss: 2265258020.9075\n",
      "Epoch 1468/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1262769217.5847 - val_loss: 2556520499.8661\n",
      "Epoch 1469/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1283278146.4491 - val_loss: 8054246209.0262\n",
      "Epoch 1470/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1538704260.1058 - val_loss: 3521672987.8684\n",
      "Epoch 1471/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1076370221.4519 - val_loss: 2676725193.0104\n",
      "Epoch 1472/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1447242487.7164 - val_loss: 2527494230.6835\n",
      "Epoch 1473/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 934263891.2324 - val_loss: 2362692642.6599\n",
      "Epoch 1474/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1359925004.9173 - val_loss: 3251831214.3392\n",
      "Epoch 1475/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1529556294.8790 - val_loss: 5250234749.3716\n",
      "Epoch 1476/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1511300086.2037 - val_loss: 2633603668.4692\n",
      "Epoch 1477/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1435157123.0974 - val_loss: 3496119592.3398\n",
      "Epoch 1478/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1354059631.0726 - val_loss: 2655435907.1325\n",
      "Epoch 1479/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1151744604.7046 - val_loss: 2406527060.7122\n",
      "Epoch 1480/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1279416844.2814 - val_loss: 4042898929.9578\n",
      "Epoch 1481/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1487250224.1171 - val_loss: 4412824143.5544\n",
      "Epoch 1482/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1610062265.9854 - val_loss: 6675930876.3274\n",
      "Epoch 1483/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1353664262.3028 - val_loss: 2423470476.6020\n",
      "Epoch 1484/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 964141006.8025 - val_loss: 2478371694.2492\n",
      "Epoch 1485/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1820956168.9499 - val_loss: 2975456582.1986\n",
      "Epoch 1486/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1309163599.9100 - val_loss: 2637268915.7221\n",
      "Epoch 1487/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1093792461.4519 - val_loss: 2807256334.6543\n",
      "Epoch 1488/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1167833285.8886 - val_loss: 2586168595.3710\n",
      "Epoch 1489/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1227098609.2335 - val_loss: 6052305766.1120\n",
      "Epoch 1490/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1691696050.2060 - val_loss: 9066673400.5108\n",
      "Epoch 1491/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 2296599601.1975 - val_loss: 2220645492.1091\n",
      "Epoch 1492/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 924506906.2555 - val_loss: 2787840565.5584\n",
      "Epoch 1493/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1061947668.3129 - val_loss: 3287082637.6101\n",
      "Epoch 1494/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1432303275.4350 - val_loss: 5717174600.0833\n",
      "Epoch 1495/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 1323447482.0664 - val_loss: 2717803418.5902\n",
      "Epoch 1496/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1300138775.1941 - val_loss: 2348536354.0793\n",
      "Epoch 1497/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1218061566.9916 - val_loss: 5597334974.3257\n",
      "Epoch 1498/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1128630511.6849 - val_loss: 4408978079.9370\n",
      "Epoch 1499/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1357323824.3512 - val_loss: 3604268162.1963\n",
      "Epoch 1500/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1070114578.2960 - val_loss: 2712643140.2667\n",
      "Epoch 1501/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1367804709.1322 - val_loss: 2306434519.4037\n",
      "Epoch 1502/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1104059029.9696 - val_loss: 3265683146.2796\n",
      "Epoch 1503/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 1785523341.2898 - val_loss: 2826425833.5325\n",
      "Epoch 1504/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1190731883.4170 - val_loss: 2611422614.1075\n",
      "Epoch 1505/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 993476940.8666 - val_loss: 6028087235.4385\n",
      "Epoch 1506/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2342452142.4603 - val_loss: 5825604458.5046\n",
      "Epoch 1507/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1400578228.7091 - val_loss: 4532981789.0205\n",
      "Epoch 1508/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1587673332.9071 - val_loss: 11663590205.7136\n",
      "Epoch 1509/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1791588272.9094 - val_loss: 2465090097.5437\n",
      "Epoch 1510/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1288816680.6258 - val_loss: 3835002298.5091\n",
      "Epoch 1511/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1920495624.0675 - val_loss: 4109992007.3091\n",
      "Epoch 1512/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1274565776.5492 - val_loss: 2364208430.9153\n",
      "Epoch 1513/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 808002636.2093 - val_loss: 5875669963.8639\n",
      "Epoch 1514/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1755945289.2200 - val_loss: 2432197044.9013\n",
      "Epoch 1515/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1301780597.1232 - val_loss: 2795683973.6529\n",
      "Epoch 1516/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1661233705.3461 - val_loss: 2478230135.8177\n",
      "Epoch 1517/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1447289631.1896 - val_loss: 2723649213.4976\n",
      "Epoch 1518/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1079922310.8430 - val_loss: 3324318465.8003\n",
      "Epoch 1519/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 2836691496.0495 - val_loss: 3077145084.4174\n",
      "Epoch 1520/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1315111177.5082 - val_loss: 2222273992.1271\n",
      "Epoch 1521/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1037018602.9308 - val_loss: 2454863782.2920\n",
      "Epoch 1522/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1378431168.1249 - val_loss: 2326343232.4141\n",
      "Epoch 1523/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 894074420.8711 - val_loss: 2342193338.3831\n",
      "Epoch 1524/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1686776923.3360 - val_loss: 2436388922.8692\n",
      "Epoch 1525/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 966867089.7918 - val_loss: 3664898321.2647\n",
      "Epoch 1526/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1307251198.7034 - val_loss: 2185559864.6188\n",
      "Epoch 1527/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 1487355595.8672 - val_loss: 5807973289.9466\n",
      "Epoch 1528/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1610270883.8717 - val_loss: 2486865983.2799\n",
      "Epoch 1529/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1441355032.5627 - val_loss: 5479933168.9496\n",
      "Epoch 1530/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1148153002.8948 - val_loss: 2685936844.2059\n",
      "Epoch 1531/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1190550612.1328 - val_loss: 4143223037.7857\n",
      "Epoch 1532/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 1385854548.5290 - val_loss: 2265718282.1626\n",
      "Epoch 1533/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 1252378821.1503 - val_loss: 3721489747.8571\n",
      "Epoch 1534/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1331115928.5627 - val_loss: 5797985352.8034\n",
      "Epoch 1535/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1354439242.4536 - val_loss: 2630580734.8118\n",
      "Epoch 1536/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 834342234.3095 - val_loss: 2642109866.0006\n",
      "Epoch 1537/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1082052095.1716 - val_loss: 9561900447.6489\n",
      "Epoch 1538/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 1304622613.2493 - val_loss: 3980243835.6073\n",
      "Epoch 1539/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 1088585700.9162 - val_loss: 2249385376.2970\n",
      "Epoch 1540/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1078799073.6117 - val_loss: 2435512446.4158\n",
      "Epoch 1541/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1598544147.7366 - val_loss: 2419766523.6793\n",
      "Epoch 1542/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 841740912.0810 - val_loss: 20529895330.0973\n",
      "Epoch 1543/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 4528070089.8323 - val_loss: 3840699808.2970\n",
      "Epoch 1544/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1573104544.9904 - val_loss: 3750189361.0757\n",
      "Epoch 1545/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1314170734.8745 - val_loss: 2039133409.3052\n",
      "Epoch 1546/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1441071768.7788 - val_loss: 2247638879.1809\n",
      "Epoch 1547/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1503677054.7755 - val_loss: 2328297245.7451\n",
      "Epoch 1548/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 828574571.5070 - val_loss: 3766490573.4121\n",
      "Epoch 1549/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 762320783.0546 - val_loss: 7397588178.8489\n",
      "Epoch 1550/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1407494929.0715 - val_loss: 3327085065.9556\n",
      "Epoch 1551/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1309989867.8312 - val_loss: 2180289876.7032\n",
      "Epoch 1552/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 944718985.3731 - val_loss: 4326462879.0729\n",
      "Epoch 1553/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1160445068.0293 - val_loss: 12393694131.0920\n",
      "Epoch 1554/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2068900421.0996 - val_loss: 2844341188.1947\n",
      "Epoch 1555/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1711102974.2712 - val_loss: 6485192269.9162\n",
      "Epoch 1556/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1572640362.5706 - val_loss: 2968111997.6776\n",
      "Epoch 1557/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 917436144.2251 - val_loss: 3819073662.7758\n",
      "Epoch 1558/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1974311759.3787 - val_loss: 3737942402.0523\n",
      "Epoch 1559/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 2253928635.5701 - val_loss: 4052555106.5114\n",
      "Epoch 1560/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1169991566.0461 - val_loss: 2337856275.9291\n",
      "Epoch 1561/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1136293576.1396 - val_loss: 2370381670.0174\n",
      "Epoch 1562/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 933030328.8329 - val_loss: 3660458807.8807\n",
      "Epoch 1563/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2723621915.7321 - val_loss: 7257070370.8174\n",
      "Epoch 1564/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2091041361.9719 - val_loss: 2172113618.7139\n",
      "Epoch 1565/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 961697415.1671 - val_loss: 2949409529.2850\n",
      "Epoch 1566/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 891574524.9747 - val_loss: 2288662266.2211\n",
      "Epoch 1567/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1146521994.7327 - val_loss: 3023792961.9983\n",
      "Epoch 1568/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1277654112.7023 - val_loss: 2206311210.5046\n",
      "Epoch 1569/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1181503893.3213 - val_loss: 2556735980.1249\n",
      "Epoch 1570/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1225651351.1311 - val_loss: 3004609591.7367\n",
      "Epoch 1571/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1449856087.0141 - val_loss: 2358613720.9159\n",
      "Epoch 1572/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1101083496.7338 - val_loss: 2324514987.2068\n",
      "Epoch 1573/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 969981433.1930 - val_loss: 2196671261.1466\n",
      "Epoch 1574/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1080130263.5115 - val_loss: 3531925466.5361\n",
      "Epoch 1575/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1339780681.0039 - val_loss: 2439760484.2622\n",
      "Epoch 1576/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1078313022.5053 - val_loss: 2580020978.2864\n",
      "Epoch 1577/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 989656257.1885 - val_loss: 2216030478.5328\n",
      "Epoch 1578/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1053262351.2707 - val_loss: 8098810829.1601\n",
      "Epoch 1579/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 2033621894.7541 - val_loss: 2407685019.9134\n",
      "Epoch 1580/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1557299174.6089 - val_loss: 4898730546.5519\n",
      "Epoch 1581/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1649659026.1880 - val_loss: 3796270917.0948\n",
      "Epoch 1582/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 1175780484.1058 - val_loss: 2809939885.0430\n",
      "Epoch 1583/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1056746812.8666 - val_loss: 3748173340.2284\n",
      "Epoch 1584/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 939327676.6325 - val_loss: 2216826421.1803\n",
      "Epoch 1585/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1081440594.9353 - val_loss: 2858112608.4951\n",
      "Epoch 1586/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1267007430.8790 - val_loss: 2885809780.8653\n",
      "Epoch 1587/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1064729321.9403 - val_loss: 2229389764.3612\n",
      "Epoch 1588/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1481682157.1277 - val_loss: 6146977818.3561\n",
      "Epoch 1589/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1585235273.2560 - val_loss: 2247639657.5145\n",
      "Epoch 1590/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 884309682.3210 - val_loss: 2504879516.2644\n",
      "Epoch 1591/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1186569789.3348 - val_loss: 2714095822.5643\n",
      "Epoch 1592/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1228052641.3506 - val_loss: 2942835132.1564\n",
      "Epoch 1593/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 86us/step - loss: 1442336839.6871 - val_loss: 2353029920.8371\n",
      "Epoch 1594/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1115650215.2212 - val_loss: 2324038613.8734\n",
      "Epoch 1595/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1923501371.1559 - val_loss: 2557843558.2020\n",
      "Epoch 1596/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1039494647.4282 - val_loss: 2604384417.3412\n",
      "Epoch 1597/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 950976325.4384 - val_loss: 2139379447.9707\n",
      "Epoch 1598/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1424422180.5920 - val_loss: 2365147331.7581\n",
      "Epoch 1599/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 787216989.2088 - val_loss: 2663757155.0965\n",
      "Epoch 1600/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1151779743.8739 - val_loss: 8511509247.4239\n",
      "Epoch 1601/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1409413138.8723 - val_loss: 2133842870.6925\n",
      "Epoch 1602/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 858309516.7496 - val_loss: 5104734420.5772\n",
      "Epoch 1603/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1033811496.0495 - val_loss: 3723022956.6560\n",
      "Epoch 1604/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1416403136.2341 - val_loss: 2016082061.3941\n",
      "Epoch 1605/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 1042885844.2679 - val_loss: 3800258462.4248\n",
      "Epoch 1606/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1354057176.8329 - val_loss: 2577000371.3800\n",
      "Epoch 1607/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1139785134.2802 - val_loss: 2829226388.3792\n",
      "Epoch 1608/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1089384258.6494 - val_loss: 2306832602.5361\n",
      "Epoch 1609/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1197544341.1052 - val_loss: 6861840844.2959\n",
      "Epoch 1610/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2222948696.5988 - val_loss: 10593224663.3857\n",
      "Epoch 1611/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2994065423.1806 - val_loss: 5511364708.4197\n",
      "Epoch 1612/10000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 1070689094.62 - 0s 85us/step - loss: 1262287928.2566 - val_loss: 2963667429.5719\n",
      "Epoch 1613/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 800586124.6775 - val_loss: 2090028990.4743\n",
      "Epoch 1614/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1025223366.4648 - val_loss: 2699499552.7651\n",
      "Epoch 1615/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 1014111352.1125 - val_loss: 3761007509.1353\n",
      "Epoch 1616/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 943449197.0737 - val_loss: 2711971560.7381\n",
      "Epoch 1617/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1044036299.2459 - val_loss: 2360774253.8802\n",
      "Epoch 1618/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1440096228.6775 - val_loss: 2148870697.2624\n",
      "Epoch 1619/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 2143762975.3337 - val_loss: 3639245383.2191\n",
      "Epoch 1620/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1011218958.7665 - val_loss: 2206792508.1114\n",
      "Epoch 1621/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1185886023.5633 - val_loss: 4453737068.3769\n",
      "Epoch 1622/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1538925779.8087 - val_loss: 2831072044.5210\n",
      "Epoch 1623/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1200461500.2904 - val_loss: 2231868528.6616\n",
      "Epoch 1624/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 857222154.2645 - val_loss: 2014189177.7890\n",
      "Epoch 1625/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 1394148179.6286 - val_loss: 2540217982.4878\n",
      "Epoch 1626/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1360354922.0214 - val_loss: 7210315043.1415\n",
      "Epoch 1627/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1622532507.2999 - val_loss: 2501575233.4042\n",
      "Epoch 1628/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1309880793.5712 - val_loss: 2504859102.9108\n",
      "Epoch 1629/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2601323635.1064 - val_loss: 3739738830.1682\n",
      "Epoch 1630/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 974433720.9049 - val_loss: 2040317911.3879\n",
      "Epoch 1631/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 815769215.5048 - val_loss: 2083401913.9601\n",
      "Epoch 1632/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1454819597.4789 - val_loss: 2555533024.4951\n",
      "Epoch 1633/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1266239837.3483 - val_loss: 2154671105.4852\n",
      "Epoch 1634/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 884753030.9871 - val_loss: 3691378503.4712\n",
      "Epoch 1635/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 870735668.0068 - val_loss: 3774400601.3660\n",
      "Epoch 1636/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1724799238.9150 - val_loss: 2526821161.4425\n",
      "Epoch 1637/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1568528994.1790 - val_loss: 3267522914.2954\n",
      "Epoch 1638/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 945285320.6438 - val_loss: 2110433675.7738\n",
      "Epoch 1639/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1207827460.0338 - val_loss: 2947054266.6352\n",
      "Epoch 1640/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2204173756.0563 - val_loss: 5275467549.2366\n",
      "Epoch 1641/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1108829101.7760 - val_loss: 1959301794.2864\n",
      "Epoch 1642/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 822342360.3827 - val_loss: 3016440065.1522\n",
      "Epoch 1643/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1812446075.9662 - val_loss: 2718907616.8191\n",
      "Epoch 1644/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 921925969.3956 - val_loss: 2064935942.2200\n",
      "Epoch 1645/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1044305968.6933 - val_loss: 5221699801.0419\n",
      "Epoch 1646/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1554489902.8205 - val_loss: 4997906525.2546\n",
      "Epoch 1647/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1841215092.9792 - val_loss: 2211368944.0968\n",
      "Epoch 1648/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1197457242.2645 - val_loss: 2270129574.3640\n",
      "Epoch 1649/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 851673450.2915 - val_loss: 2191591364.4647\n",
      "Epoch 1650/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1464304230.4828 - val_loss: 2237338946.4484\n",
      "Epoch 1651/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1548450302.7394 - val_loss: 2287746358.1165\n",
      "Epoch 1652/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1174939118.8565 - val_loss: 5044480888.9069\n",
      "Epoch 1653/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1547327339.8492 - val_loss: 5786563304.0923\n",
      "Epoch 1654/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1080088045.7760 - val_loss: 2321234862.5553\n",
      "Epoch 1655/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1063059722.1925 - val_loss: 2034462705.8250\n",
      "Epoch 1656/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 749947572.0968 - val_loss: 2065676675.4565\n",
      "Epoch 1657/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1004334012.6325 - val_loss: 2327688971.6478\n",
      "Epoch 1658/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1065067986.0439 - val_loss: 5634168968.6413\n",
      "Epoch 1659/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 1573602629.4744 - val_loss: 3996949306.3831\n",
      "Epoch 1660/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 2708777274.7777 - val_loss: 4372980308.8293\n",
      "Epoch 1661/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 1582308356.4660 - val_loss: 3238825174.8096\n",
      "Epoch 1662/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 920195031.1581 - val_loss: 2623300521.3705\n",
      "Epoch 1663/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 838978240.4682 - val_loss: 2680631735.7367\n",
      "Epoch 1664/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1393965680.8014 - val_loss: 2212297539.0470\n",
      "Epoch 1665/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 887304659.8447 - val_loss: 2810309412.3657\n",
      "Epoch 1666/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 934018170.7417 - val_loss: 6449284309.0093\n",
      "Epoch 1667/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1306762041.3551 - val_loss: 2673877700.5817\n",
      "Epoch 1668/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1413967766.8880 - val_loss: 3134918319.8515\n",
      "Epoch 1669/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1323283749.1503 - val_loss: 1979495160.4726\n",
      "Epoch 1670/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1077944509.8391 - val_loss: 2899188690.2008\n",
      "Epoch 1671/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 862065750.2217 - val_loss: 3660888861.3806\n",
      "Epoch 1672/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1845769435.7681 - val_loss: 2799295913.3165\n",
      "Epoch 1673/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1002255280.8824 - val_loss: 3000502989.0430\n",
      "Epoch 1674/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1296922522.8678 - val_loss: 7142717863.4262\n",
      "Epoch 1675/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 3018778531.3540 - val_loss: 2197533804.0889\n",
      "Epoch 1676/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 994804843.2077 - val_loss: 2627841580.3229\n",
      "Epoch 1677/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 740429734.3208 - val_loss: 2746352819.5691\n",
      "Epoch 1678/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1191984386.1609 - val_loss: 9905556645.6259\n",
      "Epoch 1679/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2040552989.1007 - val_loss: 5728831163.0852\n",
      "Epoch 1680/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1316115349.3934 - val_loss: 2579273368.9519\n",
      "Epoch 1681/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 970208515.6016 - val_loss: 2146366966.9266\n",
      "Epoch 1682/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 960264226.2510 - val_loss: 3078874980.7977\n",
      "Epoch 1683/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 986819611.7681 - val_loss: 2364505472.5108\n",
      "Epoch 1684/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1553061504.9364 - val_loss: 4283129419.6973\n",
      "Epoch 1685/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1180386154.9668 - val_loss: 3704386996.0821\n",
      "Epoch 1686/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 867427771.0298 - val_loss: 2494379419.2383\n",
      "Epoch 1687/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1296895544.4907 - val_loss: 2025644807.0031\n",
      "Epoch 1688/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 1091719972.4479 - val_loss: 2545044586.1626\n",
      "Epoch 1689/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1278192796.3084 - val_loss: 3512124568.3038\n",
      "Epoch 1690/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1278951867.3540 - val_loss: 2020206817.1522\n",
      "Epoch 1691/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1049474648.9589 - val_loss: 2372219169.8093\n",
      "Epoch 1692/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1291557772.6055 - val_loss: 2823719004.8945\n",
      "Epoch 1693/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1086437442.0529 - val_loss: 2026326134.3707\n",
      "Epoch 1694/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1188788920.4727 - val_loss: 3182436089.0149\n",
      "Epoch 1695/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 3045292263.5633 - val_loss: 2088782873.8087\n",
      "Epoch 1696/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 930908865.5127 - val_loss: 2174769715.2990\n",
      "Epoch 1697/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 833200766.5234 - val_loss: 2625329582.8793\n",
      "Epoch 1698/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 944188951.3922 - val_loss: 2226379470.3842\n",
      "Epoch 1699/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 789183955.0793 - val_loss: 2214989493.5044\n",
      "Epoch 1700/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 977361006.9690 - val_loss: 2194868476.9305\n",
      "Epoch 1701/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1438276627.3765 - val_loss: 2247387219.1752\n",
      "Epoch 1702/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1118742091.6781 - val_loss: 2252940258.4551\n",
      "Epoch 1703/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 963822311.1131 - val_loss: 4749743953.7328\n",
      "Epoch 1704/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1381951113.6162 - val_loss: 2151494445.3851\n",
      "Epoch 1705/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1384079857.8818 - val_loss: 3650890835.6771\n",
      "Epoch 1706/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1654702965.3393 - val_loss: 2801627857.9308\n",
      "Epoch 1707/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 831655701.5734 - val_loss: 2144751679.2371\n",
      "Epoch 1708/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1002609312.7383 - val_loss: 9333755942.7421\n",
      "Epoch 1709/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1838420685.2538 - val_loss: 2427429776.6706\n",
      "Epoch 1710/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 957502749.2178 - val_loss: 1956256934.1210\n",
      "Epoch 1711/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1051397085.8481 - val_loss: 3537743061.1533\n",
      "Epoch 1712/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1537579670.1137 - val_loss: 2939169703.5702\n",
      "Epoch 1713/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 850665389.1277 - val_loss: 2240999961.1139\n",
      "Epoch 1714/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 826581855.2077 - val_loss: 2525879575.0436\n",
      "Epoch 1715/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1304205130.3995 - val_loss: 2151463895.4577\n",
      "Epoch 1716/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 851869800.3737 - val_loss: 6850042181.7789\n",
      "Epoch 1717/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1343561602.7732 - val_loss: 2000730616.5558\n",
      "Epoch 1718/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1324509046.1317 - val_loss: 2913675762.1108\n",
      "Epoch 1719/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1623064339.0343 - val_loss: 2803838771.0740\n",
      "Epoch 1720/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1439939561.4541 - val_loss: 2463379671.1516\n",
      "Epoch 1721/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 99us/step - loss: 1198357136.6753 - val_loss: 2265369885.8667\n",
      "Epoch 1722/10000\n",
      "3554/3554 [==============================] - 0s 137us/step - loss: 793457501.1007 - val_loss: 2446160077.2321\n",
      "Epoch 1723/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 910780864.7338 - val_loss: 3446903288.4388\n",
      "Epoch 1724/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1368604192.2701 - val_loss: 3714629291.8909\n",
      "Epoch 1725/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1137820500.1013 - val_loss: 1860967349.3018\n",
      "Epoch 1726/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 995324890.0034 - val_loss: 2014346303.8245\n",
      "Epoch 1727/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1095696573.3889 - val_loss: 1941523097.7080\n",
      "Epoch 1728/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1196214008.4367 - val_loss: 6897757774.9243\n",
      "Epoch 1729/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 2336568837.4564 - val_loss: 2484237014.1255\n",
      "Epoch 1730/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1260413001.4001 - val_loss: 2180766335.6940\n",
      "Epoch 1731/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1009128997.7085 - val_loss: 2478592624.5716\n",
      "Epoch 1732/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 852334362.9038 - val_loss: 4110847639.7277\n",
      "Epoch 1733/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1302202294.8610 - val_loss: 2909331816.3263\n",
      "Epoch 1734/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 925903007.0276 - val_loss: 1915905013.9994\n",
      "Epoch 1735/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1007283856.2904 - val_loss: 2407553997.7699\n",
      "Epoch 1736/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 827800537.5712 - val_loss: 2564685707.6658\n",
      "Epoch 1737/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1584123533.2898 - val_loss: 2547241160.0383\n",
      "Epoch 1738/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1179967673.7333 - val_loss: 2133909819.5713\n",
      "Epoch 1739/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 873085638.2577 - val_loss: 2161653165.7091\n",
      "Epoch 1740/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 748801153.5127 - val_loss: 2977120668.2914\n",
      "Epoch 1741/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1804133873.3056 - val_loss: 2579451342.5823\n",
      "Epoch 1742/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 941434112.0000 - val_loss: 7929154430.6678\n",
      "Epoch 1743/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2180053200.4592 - val_loss: 4635380911.7795\n",
      "Epoch 1744/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1159948470.9510 - val_loss: 2246921430.3415\n",
      "Epoch 1745/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 822448218.0394 - val_loss: 2486051153.5887\n",
      "Epoch 1746/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 966966863.8829 - val_loss: 6544310765.8532\n",
      "Epoch 1747/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1301703028.1868 - val_loss: 2577763296.6031\n",
      "Epoch 1748/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1365236057.1750 - val_loss: 1986492096.4051\n",
      "Epoch 1749/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 886359562.0124 - val_loss: 2151177788.2464\n",
      "Epoch 1750/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1493740870.5189 - val_loss: 2650852362.2931\n",
      "Epoch 1751/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1173390171.9122 - val_loss: 2395688524.3049\n",
      "Epoch 1752/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1053350880.4052 - val_loss: 1854882237.9657\n",
      "Epoch 1753/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 928293510.5909 - val_loss: 2828672266.7297\n",
      "Epoch 1754/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 872572579.3315 - val_loss: 3226055804.5795\n",
      "Epoch 1755/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1338892275.6331 - val_loss: 2353285930.3044\n",
      "Epoch 1756/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1080420635.0838 - val_loss: 3039824151.8515\n",
      "Epoch 1757/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 938863048.3196 - val_loss: 9851016318.8838\n",
      "Epoch 1758/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2984172780.2634 - val_loss: 3267513572.4557\n",
      "Epoch 1759/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1013761311.0006 - val_loss: 2178812654.0062\n",
      "Epoch 1760/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 730330193.9358 - val_loss: 1946320653.1781\n",
      "Epoch 1761/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 807472285.7850 - val_loss: 2292185129.4430\n",
      "Epoch 1762/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1109705335.5723 - val_loss: 14975812717.7451\n",
      "Epoch 1763/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 3095161263.0006 - val_loss: 1893838502.2560\n",
      "Epoch 1764/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 765859011.6376 - val_loss: 12829314990.8433\n",
      "Epoch 1765/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 3835057859.3495 - val_loss: 2765592867.7896\n",
      "Epoch 1766/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 824263069.1728 - val_loss: 1915668057.5370\n",
      "Epoch 1767/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 728954348.9477 - val_loss: 1998579752.5963\n",
      "Epoch 1768/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 722850767.5228 - val_loss: 2044220152.7449\n",
      "Epoch 1769/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 801843949.0197 - val_loss: 6597611209.7755\n",
      "Epoch 1770/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1187592506.0214 - val_loss: 2531228524.6830\n",
      "Epoch 1771/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1177802550.5999 - val_loss: 5459916148.1541\n",
      "Epoch 1772/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2028710841.7693 - val_loss: 2176052512.9451\n",
      "Epoch 1773/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1396348983.6083 - val_loss: 2504837710.6003\n",
      "Epoch 1774/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 786196505.9313 - val_loss: 5807641371.1482\n",
      "Epoch 1775/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1465671930.0934 - val_loss: 2402469984.9857\n",
      "Epoch 1776/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1151814591.1716 - val_loss: 3180129872.6549\n",
      "Epoch 1777/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 754409973.8436 - val_loss: 2168857678.0512\n",
      "Epoch 1778/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1201945728.1125 - val_loss: 1808302007.3677\n",
      "Epoch 1779/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 695187542.5504 - val_loss: 2762887671.7367\n",
      "Epoch 1780/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 994914337.7828 - val_loss: 2006966181.0723\n",
      "Epoch 1781/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1010700478.5594 - val_loss: 5254153695.9730\n",
      "Epoch 1782/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1596040870.7530 - val_loss: 2841790329.0509\n",
      "Epoch 1783/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 920155963.5521 - val_loss: 1912339722.8377\n",
      "Epoch 1784/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 834751910.7530 - val_loss: 3509929519.8335\n",
      "Epoch 1785/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1145489719.3202 - val_loss: 1888473823.1134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1786/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1044183039.7389 - val_loss: 4292341569.0082\n",
      "Epoch 1787/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1884154266.0034 - val_loss: 7899226901.2433\n",
      "Epoch 1788/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 986826350.9826 - val_loss: 2685034859.1887\n",
      "Epoch 1789/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 873640528.8194 - val_loss: 3514088168.0563\n",
      "Epoch 1790/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1593212768.5943 - val_loss: 8538574439.0481\n",
      "Epoch 1791/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1447870331.6061 - val_loss: 2163567617.9083\n",
      "Epoch 1792/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1739105829.7445 - val_loss: 4202653038.4113\n",
      "Epoch 1793/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1284057709.9201 - val_loss: 2569072158.8028\n",
      "Epoch 1794/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 868889045.1412 - val_loss: 1930711951.3564\n",
      "Epoch 1795/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 716980928.3602 - val_loss: 2130300559.3024\n",
      "Epoch 1796/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 806626758.8790 - val_loss: 2603704032.5311\n",
      "Epoch 1797/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1089620621.7580 - val_loss: 2883926617.5100\n",
      "Epoch 1798/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1330918620.9747 - val_loss: 1926775232.0855\n",
      "Epoch 1799/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 884098522.8317 - val_loss: 4752660847.6895\n",
      "Epoch 1800/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1007915417.7153 - val_loss: 2921844962.4754\n",
      "Epoch 1801/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1507577248.3421 - val_loss: 1960627788.7550\n",
      "Epoch 1802/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 973322749.8391 - val_loss: 3517707160.4568\n",
      "Epoch 1803/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1587859665.4496 - val_loss: 3227919270.4180\n",
      "Epoch 1804/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1350604051.3044 - val_loss: 4729427416.7269\n",
      "Epoch 1805/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1378105952.8824 - val_loss: 3648641782.4225\n",
      "Epoch 1806/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1148971684.1598 - val_loss: 2160587173.4278\n",
      "Epoch 1807/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 919586327.9280 - val_loss: 2929307758.7488\n",
      "Epoch 1808/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 701759617.2245 - val_loss: 5790994516.0686\n",
      "Epoch 1809/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2581567476.1868 - val_loss: 2563725610.0546\n",
      "Epoch 1810/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 1129907909.6185 - val_loss: 3592321478.0669\n",
      "Epoch 1811/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 920458495.5678 - val_loss: 3233160683.4768\n",
      "Epoch 1812/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 805486175.2257 - val_loss: 1873421208.2858\n",
      "Epoch 1813/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 878132348.7766 - val_loss: 1955372975.7328\n",
      "Epoch 1814/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 661925288.4682 - val_loss: 2565774176.4591\n",
      "Epoch 1815/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 912036124.5245 - val_loss: 2859005518.4923\n",
      "Epoch 1816/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1184570851.9077 - val_loss: 6660082123.5758\n",
      "Epoch 1817/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 3288548784.7653 - val_loss: 4153814182.0940\n",
      "Epoch 1818/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1524402109.8751 - val_loss: 5658248256.5221\n",
      "Epoch 1819/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1409223275.7591 - val_loss: 3506305744.9046\n",
      "Epoch 1820/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1176364539.2819 - val_loss: 3091944351.9730\n",
      "Epoch 1821/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1347648862.2172 - val_loss: 2376767009.6653\n",
      "Epoch 1822/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 966347357.8728 - val_loss: 2270563371.0245\n",
      "Epoch 1823/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 700492951.5543 - val_loss: 2694464018.5069\n",
      "Epoch 1824/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 943294652.3005 - val_loss: 5115468325.6619\n",
      "Epoch 1825/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 890160695.8965 - val_loss: 5216673062.0219\n",
      "Epoch 1826/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1447607500.4795 - val_loss: 2953258860.6290\n",
      "Epoch 1827/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1120108876.4795 - val_loss: 2226052828.2104\n",
      "Epoch 1828/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1861772873.4992 - val_loss: 3222604175.3204\n",
      "Epoch 1829/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 803939973.1142 - val_loss: 1854394553.4875\n",
      "Epoch 1830/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 976216152.0225 - val_loss: 3499855251.1010\n",
      "Epoch 1831/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1176367295.4778 - val_loss: 2461859685.5584\n",
      "Epoch 1832/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 967030269.4789 - val_loss: 3529526822.0579\n",
      "Epoch 1833/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1051991861.1953 - val_loss: 2409127022.4203\n",
      "Epoch 1834/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1138224981.6635 - val_loss: 1971543869.7992\n",
      "Epoch 1835/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 861023838.7034 - val_loss: 2906126873.6360\n",
      "Epoch 1836/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1414486580.2769 - val_loss: 1909402444.1249\n",
      "Epoch 1837/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 1348544605.0647 - val_loss: 2363244287.1359\n",
      "Epoch 1838/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 912624159.8739 - val_loss: 2154819342.5463\n",
      "Epoch 1839/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 725927435.0208 - val_loss: 4115303266.3674\n",
      "Epoch 1840/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 961604916.5560 - val_loss: 1893563280.0495\n",
      "Epoch 1841/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 901077413.1322 - val_loss: 2900283708.2734\n",
      "Epoch 1842/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 900642619.1199 - val_loss: 2584106153.9105\n",
      "Epoch 1843/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1162699614.7935 - val_loss: 2198379601.4357\n",
      "Epoch 1844/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 881457644.9837 - val_loss: 2934215910.2470\n",
      "Epoch 1845/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1602521547.5791 - val_loss: 3119670953.2264\n",
      "Epoch 1846/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1079830293.6455 - val_loss: 3137267913.0194\n",
      "Epoch 1847/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 941445713.7017 - val_loss: 3509100978.5699\n",
      "Epoch 1848/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1439062739.0523 - val_loss: 4777957136.3466\n",
      "Epoch 1849/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1027368266.3725 - val_loss: 2139925084.2104\n",
      "Epoch 1850/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 927542799.9910 - val_loss: 2230843082.7027\n",
      "Epoch 1851/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 838456849.4676 - val_loss: 5192022956.9710\n",
      "Epoch 1852/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1099868896.8464 - val_loss: 2121642396.1857\n",
      "Epoch 1853/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 763539304.6618 - val_loss: 1767042858.3809\n",
      "Epoch 1854/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 721864989.8886 - val_loss: 3083894667.9944\n",
      "Epoch 1855/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 770884595.6106 - val_loss: 2636861070.8523\n",
      "Epoch 1856/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1531615608.0045 - val_loss: 3158671079.1561\n",
      "Epoch 1857/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 2256788237.8301 - val_loss: 1812630914.3111\n",
      "Epoch 1858/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 767644600.5447 - val_loss: 2149865001.1904\n",
      "Epoch 1859/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1477776128.8644 - val_loss: 2725691771.9314\n",
      "Epoch 1860/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 2760155611.6961 - val_loss: 2143239896.1958\n",
      "Epoch 1861/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 901382671.2662 - val_loss: 2338212766.4495\n",
      "Epoch 1862/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 754854626.7777 - val_loss: 1832247155.2630\n",
      "Epoch 1863/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 798009543.5183 - val_loss: 4243861045.3963\n",
      "Epoch 1864/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 890930136.2071 - val_loss: 3163502047.9910\n",
      "Epoch 1865/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 824981878.1677 - val_loss: 2986591611.1392\n",
      "Epoch 1866/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1275530692.2138 - val_loss: 5262306898.5519\n",
      "Epoch 1867/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2654036654.3163 - val_loss: 3125423817.8115\n",
      "Epoch 1868/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1552272450.5751 - val_loss: 1895200785.1072\n",
      "Epoch 1869/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 856381265.2515 - val_loss: 3452902332.3094\n",
      "Epoch 1870/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1024720410.6674 - val_loss: 1978022832.7156\n",
      "Epoch 1871/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 843901304.0405 - val_loss: 1763165196.3409\n",
      "Epoch 1872/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 885629447.2482 - val_loss: 2698599458.6014\n",
      "Epoch 1873/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1146603288.3827 - val_loss: 4639067337.9195\n",
      "Epoch 1874/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 918651654.8070 - val_loss: 1907699763.7221\n",
      "Epoch 1875/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 641934192.2251 - val_loss: 2248278892.2869\n",
      "Epoch 1876/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1062520246.5999 - val_loss: 2195455808.9271\n",
      "Epoch 1877/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 991584366.5864 - val_loss: 2099901891.8661\n",
      "Epoch 1878/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 993360266.0799 - val_loss: 2028680245.2703\n",
      "Epoch 1879/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 877867403.9572 - val_loss: 1793927965.5246\n",
      "Epoch 1880/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 908512956.0743 - val_loss: 1931096762.3201\n",
      "Epoch 1881/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 968413354.2701 - val_loss: 2044004835.2675\n",
      "Epoch 1882/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 814412285.1367 - val_loss: 2296606592.1440\n",
      "Epoch 1883/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 3843033331.1784 - val_loss: 7524303652.6177\n",
      "Epoch 1884/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2400827971.8537 - val_loss: 1871808942.5373\n",
      "Epoch 1885/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 684189773.1097 - val_loss: 2564838575.1314\n",
      "Epoch 1886/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 803619053.8481 - val_loss: 2045569901.1150\n",
      "Epoch 1887/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 920022776.0765 - val_loss: 1800031097.4245\n",
      "Epoch 1888/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1466119682.4851 - val_loss: 2342581939.8661\n",
      "Epoch 1889/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 923555248.1261 - val_loss: 2254361635.6276\n",
      "Epoch 1890/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 743788414.5324 - val_loss: 1677813428.0641\n",
      "Epoch 1891/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 748706413.3078 - val_loss: 4045172607.9460\n",
      "Epoch 1892/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1299485801.3101 - val_loss: 1847660288.6571\n",
      "Epoch 1893/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1039685910.2938 - val_loss: 2591811036.2464\n",
      "Epoch 1894/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 887617385.2966 - val_loss: 1682425969.2107\n",
      "Epoch 1895/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 820700835.4215 - val_loss: 3280871448.7719\n",
      "Epoch 1896/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1223847458.1429 - val_loss: 4312276036.3387\n",
      "Epoch 1897/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1042616994.4941 - val_loss: 7359122824.7494\n",
      "Epoch 1898/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1106889187.1874 - val_loss: 2758185003.4948\n",
      "Epoch 1899/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 2000517909.6815 - val_loss: 2436380319.3249\n",
      "Epoch 1900/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 733225262.4243 - val_loss: 1843546154.8557\n",
      "Epoch 1901/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 2050207061.4654 - val_loss: 2253194459.2135\n",
      "Epoch 1902/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 911674610.4446 - val_loss: 1800362073.3120\n",
      "Epoch 1903/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 748867047.8694 - val_loss: 2450649556.8563\n",
      "Epoch 1904/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 754013735.4733 - val_loss: 2650782926.9243\n",
      "Epoch 1905/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1057446216.3917 - val_loss: 1817274409.2985\n",
      "Epoch 1906/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 884517018.5076 - val_loss: 2208254750.3887\n",
      "Epoch 1907/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1340844555.2729 - val_loss: 2341288509.5696\n",
      "Epoch 1908/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1724221286.2847 - val_loss: 2984579318.5665\n",
      "Epoch 1909/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 874104953.8233 - val_loss: 1925112844.1879\n",
      "Epoch 1910/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 868683326.8115 - val_loss: 3418670507.4948\n",
      "Epoch 1911/10000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 1022738914.5751 - val_loss: 1876180503.1741\n",
      "Epoch 1912/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 1114912758.7800 - val_loss: 4356893777.2287\n",
      "Epoch 1913/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 2478767203.1154 - val_loss: 7909085321.9736\n",
      "Epoch 1914/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2930038689.1345 - val_loss: 2707241324.7370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1915/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 786065278.1722 - val_loss: 1851774329.7620\n",
      "Epoch 1916/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 655594520.4907 - val_loss: 3674951969.7733\n",
      "Epoch 1917/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1135666249.4721 - val_loss: 2084971358.1660\n",
      "Epoch 1918/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 844098890.7147 - val_loss: 1754220345.6000\n",
      "Epoch 1919/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 781933095.1491 - val_loss: 2554194087.7502\n",
      "Epoch 1920/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 639432717.3979 - val_loss: 4959039077.8239\n",
      "Epoch 1921/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1066802683.7501 - val_loss: 3407937181.6017\n",
      "Epoch 1922/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1790265469.2268 - val_loss: 2073066669.1533\n",
      "Epoch 1923/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 709923704.6528 - val_loss: 1711684169.1589\n",
      "Epoch 1924/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 986514444.8216 - val_loss: 2501112098.9885\n",
      "Epoch 1925/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 742773621.6995 - val_loss: 9183706438.4990\n",
      "Epoch 1926/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 3846730473.4001 - val_loss: 2373798195.1775\n",
      "Epoch 1927/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 761319624.1756 - val_loss: 1699148308.6132\n",
      "Epoch 1928/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 705854728.2161 - val_loss: 1879202975.4329\n",
      "Epoch 1929/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 730357444.6820 - val_loss: 1938340305.6248\n",
      "Epoch 1930/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 693863470.3163 - val_loss: 2171310669.0700\n",
      "Epoch 1931/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1312842480.1531 - val_loss: 1967999816.9294\n",
      "Epoch 1932/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1272755054.4963 - val_loss: 2793098818.4664\n",
      "Epoch 1933/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1568144670.8666 - val_loss: 1930173119.8380\n",
      "Epoch 1934/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 783403636.3714 - val_loss: 1963832339.3350\n",
      "Epoch 1935/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 996386405.4564 - val_loss: 3034689218.6914\n",
      "Epoch 1936/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 857665698.8272 - val_loss: 1991464635.1482\n",
      "Epoch 1937/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 841958349.1818 - val_loss: 2071009277.6236\n",
      "Epoch 1938/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1172317618.5661 - val_loss: 1905321564.9665\n",
      "Epoch 1939/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 780778106.0124 - val_loss: 1977806399.1449\n",
      "Epoch 1940/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1016586583.4012 - val_loss: 2729424371.7401\n",
      "Epoch 1941/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1276283982.2983 - val_loss: 2044880104.6504\n",
      "Epoch 1942/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 821588166.8790 - val_loss: 4150709672.0023\n",
      "Epoch 1943/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 934521166.8295 - val_loss: 1847701224.1710\n",
      "Epoch 1944/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 761255247.5948 - val_loss: 3733502868.0551\n",
      "Epoch 1945/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1293235666.6922 - val_loss: 2861484642.6554\n",
      "Epoch 1946/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1300584569.5712 - val_loss: 2637666961.3187\n",
      "Epoch 1947/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 873049213.4429 - val_loss: 2153460333.6371\n",
      "Epoch 1948/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1099436140.5155 - val_loss: 3727557285.0138\n",
      "Epoch 1949/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 879090465.1120 - val_loss: 2586382095.7525\n",
      "Epoch 1950/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 936213443.7186 - val_loss: 2114299595.0852\n",
      "Epoch 1951/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1005356341.8706 - val_loss: 5712880846.6183\n",
      "Epoch 1952/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1062089855.4598 - val_loss: 1899095546.2931\n",
      "Epoch 1953/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 845400797.4249 - val_loss: 8453274463.4869\n",
      "Epoch 1954/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 2904100888.4907 - val_loss: 2102729259.9089\n",
      "Epoch 1955/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 767698511.2347 - val_loss: 2612403179.0627\n",
      "Epoch 1956/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 918341460.1283 - val_loss: 4108584843.1167\n",
      "Epoch 1957/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 855735408.6213 - val_loss: 2061148176.8146\n",
      "Epoch 1958/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 656539034.9398 - val_loss: 2519565847.5814\n",
      "Epoch 1959/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 773266965.0512 - val_loss: 1972974095.8425\n",
      "Epoch 1960/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 720581186.3950 - val_loss: 1828664044.2779\n",
      "Epoch 1961/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1262269707.5611 - val_loss: 2162388666.2886\n",
      "Epoch 1962/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 672414910.1632 - val_loss: 3080475826.5699\n",
      "Epoch 1963/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1123583628.6775 - val_loss: 2032777144.1193\n",
      "Epoch 1964/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1288810144.9904 - val_loss: 2184304672.6751\n",
      "Epoch 1965/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 957099308.6595 - val_loss: 5055767219.7401\n",
      "Epoch 1966/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 884717308.5335 - val_loss: 2129348748.3139\n",
      "Epoch 1967/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1293888710.1227 - val_loss: 2219267697.3097\n",
      "Epoch 1968/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 709329577.6342 - val_loss: 1854727271.2551\n",
      "Epoch 1969/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 805552399.0726 - val_loss: 2259096646.5710\n",
      "Epoch 1970/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 946816993.7107 - val_loss: 1926931848.0473\n",
      "Epoch 1971/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1314054676.7451 - val_loss: 4923429523.1910\n",
      "Epoch 1972/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2445221758.0551 - val_loss: 3576745164.2239\n",
      "Epoch 1973/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1494575863.2482 - val_loss: 1929210706.5609\n",
      "Epoch 1974/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 816427827.7186 - val_loss: 1859123608.5558\n",
      "Epoch 1975/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1004432486.2307 - val_loss: 2537561121.9893\n",
      "Epoch 1976/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 921981217.9268 - val_loss: 1844879803.0582\n",
      "Epoch 1977/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 805735216.4412 - val_loss: 1996471137.1972\n",
      "Epoch 1978/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 707589920.8464 - val_loss: 1915335451.2383\n",
      "Epoch 1979/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 789386518.6899 - val_loss: 2284820958.8748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1980/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1506711428.1058 - val_loss: 3797319768.3848\n",
      "Epoch 1981/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 875039124.7811 - val_loss: 1845251007.0098\n",
      "Epoch 1982/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 862818696.7968 - val_loss: 3657358011.5893\n",
      "Epoch 1983/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1390322191.1266 - val_loss: 7205434407.1741\n",
      "Epoch 1984/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2042864710.3028 - val_loss: 44170891600.4366\n",
      "Epoch 1985/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 8300972275.3225 - val_loss: 1883785066.4956\n",
      "Epoch 1986/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 722070967.6804 - val_loss: 3131737632.0450\n",
      "Epoch 1987/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 723918519.8244 - val_loss: 1661090732.8450\n",
      "Epoch 1988/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 583127467.4350 - val_loss: 3590235168.6211\n",
      "Epoch 1989/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1289974940.2003 - val_loss: 2774915680.6166\n",
      "Epoch 1990/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 778587899.0208 - val_loss: 1863031403.3778\n",
      "Epoch 1991/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 644386711.7344 - val_loss: 1660664322.0973\n",
      "Epoch 1992/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 551156969.8863 - val_loss: 2814631143.6062\n",
      "Epoch 1993/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1199377173.2493 - val_loss: 2507029247.0098\n",
      "Epoch 1994/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 959671417.5892 - val_loss: 8643065487.6444\n",
      "Epoch 1995/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2262367287.1401 - val_loss: 2042836063.8830\n",
      "Epoch 1996/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 603452479.9280 - val_loss: 2772742758.1615\n",
      "Epoch 1997/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 769202696.5718 - val_loss: 3056591968.9992\n",
      "Epoch 1998/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 813780664.8329 - val_loss: 1918428317.4346\n",
      "Epoch 1999/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1087417858.6652 - val_loss: 2255723452.6695\n",
      "Epoch 2000/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 683049095.7074 - val_loss: 4162131836.8675\n",
      "Epoch 2001/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 848604340.0068 - val_loss: 2172891425.4492\n",
      "Epoch 2002/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 849233801.7378 - val_loss: 1998612855.2326\n",
      "Epoch 2003/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 689945802.9128 - val_loss: 2400249868.5300\n",
      "Epoch 2004/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 875409907.2594 - val_loss: 1706334008.3398\n",
      "Epoch 2005/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 632124548.4660 - val_loss: 1903612859.8774\n",
      "Epoch 2006/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1208607913.8863 - val_loss: 5605871216.7696\n",
      "Epoch 2007/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1010874908.7766 - val_loss: 3855195911.7052\n",
      "Epoch 2008/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1369062534.8430 - val_loss: 2190877179.2113\n",
      "Epoch 2009/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 934611340.3894 - val_loss: 1635802420.6357\n",
      "Epoch 2010/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 819922706.8723 - val_loss: 7033637373.2276\n",
      "Epoch 2011/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 2165033012.0068 - val_loss: 2040119791.5814\n",
      "Epoch 2012/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 918358322.2780 - val_loss: 4361229324.4579\n",
      "Epoch 2013/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1316881805.1277 - val_loss: 1691285401.9871\n",
      "Epoch 2014/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 561699172.2138 - val_loss: 2203210548.3702\n",
      "Epoch 2015/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 812414188.6415 - val_loss: 1804106096.4546\n",
      "Epoch 2016/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 792046473.8233 - val_loss: 2120273160.8574\n",
      "Epoch 2017/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 691885052.9758 - val_loss: 2016547552.2430\n",
      "Epoch 2018/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 870971070.2712 - val_loss: 2648685871.5094\n",
      "Epoch 2019/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 967380265.8863 - val_loss: 1914758330.1851\n",
      "Epoch 2020/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1668985269.6635 - val_loss: 2645290243.4565\n",
      "Epoch 2021/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 864503048.9679 - val_loss: 2173543778.4664\n",
      "Epoch 2022/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 784448874.4986 - val_loss: 2885009400.7899\n",
      "Epoch 2023/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 808923345.4676 - val_loss: 2050640460.1519\n",
      "Epoch 2024/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1513217064.8419 - val_loss: 3803436775.4442\n",
      "Epoch 2025/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 894221456.9994 - val_loss: 1857536732.2712\n",
      "Epoch 2026/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1000570615.1401 - val_loss: 2166931909.8149\n",
      "Epoch 2027/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1023011385.8773 - val_loss: 1775411394.8444\n",
      "Epoch 2028/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1586591208.7923 - val_loss: 2189972509.3806\n",
      "Epoch 2029/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1035357531.9122 - val_loss: 2995251176.8934\n",
      "Epoch 2030/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1452280018.3320 - val_loss: 2462844506.1941\n",
      "Epoch 2031/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 890733431.2189 - val_loss: 2024345600.7381\n",
      "Epoch 2032/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 728906291.6466 - val_loss: 3751129975.8987\n",
      "Epoch 2033/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 823181711.6669 - val_loss: 1647878041.8160\n",
      "Epoch 2034/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 616690298.3815 - val_loss: 4857835082.5316\n",
      "Epoch 2035/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 926595134.5470 - val_loss: 3024670095.4509\n",
      "Epoch 2036/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1054264650.0844 - val_loss: 2064072785.8048\n",
      "Epoch 2037/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1093139585.9449 - val_loss: 2503283844.9958\n",
      "Epoch 2038/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1297845961.9764 - val_loss: 9398069778.5429\n",
      "Epoch 2039/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1795362189.9021 - val_loss: 7054506033.7058\n",
      "Epoch 2040/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 2636721304.7068 - val_loss: 2438700789.0183\n",
      "Epoch 2041/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 870066567.2988 - val_loss: 2247180236.3679\n",
      "Epoch 2042/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1021300920.3286 - val_loss: 2437963694.9513\n",
      "Epoch 2043/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 656084903.1851 - val_loss: 1606512486.6880\n",
      "Epoch 2044/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 623728537.4271 - val_loss: 12814814456.0068\n",
      "Epoch 2045/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1832565527.4823 - val_loss: 2776032420.0056\n",
      "Epoch 2046/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 628316976.6933 - val_loss: 5208366271.8380\n",
      "Epoch 2047/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 2358878753.3866 - val_loss: 2937132882.2909\n",
      "Epoch 2048/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 730726326.0236 - val_loss: 1737704333.9522\n",
      "Epoch 2049/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 524416177.9178 - val_loss: 2735735245.0160\n",
      "Epoch 2050/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 844761767.5408 - val_loss: 1791436537.8430\n",
      "Epoch 2051/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 631156065.2425 - val_loss: 2088100566.1165\n",
      "Epoch 2052/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 739225843.9167 - val_loss: 1982025117.2906\n",
      "Epoch 2053/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 811423993.9494 - val_loss: 1934728547.3755\n",
      "Epoch 2054/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1065778566.9060 - val_loss: 2210902688.3511\n",
      "Epoch 2055/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 792608940.2273 - val_loss: 1882289024.1440\n",
      "Epoch 2056/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 843739785.7963 - val_loss: 2456655851.2788\n",
      "Epoch 2057/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 806238737.3596 - val_loss: 8670687001.3480\n",
      "Epoch 2058/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1574121189.9606 - val_loss: 2514399629.9837\n",
      "Epoch 2059/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 933564147.8987 - val_loss: 2548607525.8419\n",
      "Epoch 2060/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1213584440.0405 - val_loss: 1978920798.7848\n",
      "Epoch 2061/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 976886747.5881 - val_loss: 1644179913.7980\n",
      "Epoch 2062/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 748327131.9122 - val_loss: 2951446033.2512\n",
      "Epoch 2063/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 3128866933.8255 - val_loss: 1590287077.0138\n",
      "Epoch 2064/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 553886285.5779 - val_loss: 1933543793.0397\n",
      "Epoch 2065/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 616277122.9533 - val_loss: 2266327701.9274\n",
      "Epoch 2066/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 770128362.9308 - val_loss: 3381399784.4613\n",
      "Epoch 2067/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 979443105.6781 - val_loss: 1595953870.6003\n",
      "Epoch 2068/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 614147456.0833 - val_loss: 3585323859.3890\n",
      "Epoch 2069/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1048739500.6055 - val_loss: 3856959963.6658\n",
      "Epoch 2070/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1269827840.9364 - val_loss: 3790427652.1767\n",
      "Epoch 2071/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1367297258.6787 - val_loss: 8089227445.0363\n",
      "Epoch 2072/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1870742999.3742 - val_loss: 5197828772.3297\n",
      "Epoch 2073/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1106409650.3500 - val_loss: 5215995675.5443\n",
      "Epoch 2074/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 855332806.5909 - val_loss: 2176696260.8068\n",
      "Epoch 2075/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 800683428.0878 - val_loss: 1840394652.1204\n",
      "Epoch 2076/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 905392938.0664 - val_loss: 2102880294.7421\n",
      "Epoch 2077/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 745153641.2560 - val_loss: 2239437135.2664\n",
      "Epoch 2078/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 640556319.4958 - val_loss: 2017025374.9738\n",
      "Epoch 2079/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1125164093.6590 - val_loss: 2762135806.3437\n",
      "Epoch 2080/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1835067146.9848 - val_loss: 3060394182.2290\n",
      "Epoch 2081/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1528222191.7929 - val_loss: 2709903627.6298\n",
      "Epoch 2082/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 900068172.4164 - val_loss: 2388488366.2492\n",
      "Epoch 2083/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 561662704.1351 - val_loss: 1663011153.1364\n",
      "Epoch 2084/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 642864828.8576 - val_loss: 2428247467.3328\n",
      "Epoch 2085/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 869846861.5059 - val_loss: 4254062639.8155\n",
      "Epoch 2086/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 808634310.7349 - val_loss: 13481705701.2838\n",
      "Epoch 2087/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 3036236177.2696 - val_loss: 8068673994.2796\n",
      "Epoch 2088/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 2267578128.6393 - val_loss: 2886903318.3955\n",
      "Epoch 2089/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 840600176.8734 - val_loss: 3428798839.0346\n",
      "Epoch 2090/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 722698740.4930 - val_loss: 1957855273.0543\n",
      "Epoch 2091/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 564045071.4147 - val_loss: 1803004307.5691\n",
      "Epoch 2092/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 589373870.0642 - val_loss: 1804225511.4172\n",
      "Epoch 2093/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 676116821.2673 - val_loss: 1756335196.3364\n",
      "Epoch 2094/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 742955930.5841 - val_loss: 2431500650.0186\n",
      "Epoch 2095/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1044882132.2949 - val_loss: 2803910033.8228\n",
      "Epoch 2096/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1027639718.2487 - val_loss: 1850733916.6965\n",
      "Epoch 2097/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 761299043.5836 - val_loss: 1615390376.3803\n",
      "Epoch 2098/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 681436577.3506 - val_loss: 2560458688.0540\n",
      "Epoch 2099/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 853083340.8576 - val_loss: 5237600127.5319\n",
      "Epoch 2100/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1215099248.7293 - val_loss: 2068845530.3471\n",
      "Epoch 2101/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 836400159.3697 - val_loss: 5304161697.5212\n",
      "Epoch 2102/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1364171778.7732 - val_loss: 4592297868.8540\n",
      "Epoch 2103/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 842365779.2504 - val_loss: 3015071325.9072\n",
      "Epoch 2104/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 1256759942.8070 - val_loss: 1636798061.6371\n",
      "Epoch 2105/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 889809960.8959 - val_loss: 1744277170.9120\n",
      "Epoch 2106/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 730237721.6252 - val_loss: 1953057354.0996\n",
      "Epoch 2107/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 671381584.1711 - val_loss: 5382065982.7218\n",
      "Epoch 2108/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 3550465309.4879 - val_loss: 2399472013.4301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2109/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 775036955.9482 - val_loss: 2287628307.8211\n",
      "Epoch 2110/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 884847179.9932 - val_loss: 3086492922.4551\n",
      "Epoch 2111/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 904662577.6297 - val_loss: 2353340874.8377\n",
      "Epoch 2112/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 784920123.8132 - val_loss: 1627342187.0177\n",
      "Epoch 2113/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 824186258.3320 - val_loss: 2693697215.9415\n",
      "Epoch 2114/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 601155651.6916 - val_loss: 1689163715.3395\n",
      "Epoch 2115/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 693278762.1474 - val_loss: 2260224121.3210\n",
      "Epoch 2116/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 654458892.8216 - val_loss: 2120404588.0799\n",
      "Epoch 2117/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 663264371.0343 - val_loss: 1662328787.4250\n",
      "Epoch 2118/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 707298667.9752 - val_loss: 3050317051.1752\n",
      "Epoch 2119/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1213584395.5070 - val_loss: 1846881953.0622\n",
      "Epoch 2120/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 754706734.9105 - val_loss: 2306101561.8970\n",
      "Epoch 2121/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 939911105.7614 - val_loss: 1939779912.5018\n",
      "Epoch 2122/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1042153451.3990 - val_loss: 4669214696.7404\n",
      "Epoch 2123/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1296075853.3258 - val_loss: 2365865730.5564\n",
      "Epoch 2124/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1621756385.8188 - val_loss: 2764540085.1083\n",
      "Epoch 2125/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 934510726.9510 - val_loss: 3258319260.9125\n",
      "Epoch 2126/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1060991370.6246 - val_loss: 4247447130.3021\n",
      "Epoch 2127/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1243012513.4947 - val_loss: 3337695555.7716\n",
      "Epoch 2128/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 994773690.7057 - val_loss: 5282109333.2073\n",
      "Epoch 2129/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 928774174.6854 - val_loss: 2432512371.5421\n",
      "Epoch 2130/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 588999881.9944 - val_loss: 1674169211.4948\n",
      "Epoch 2131/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 682211450.1272 - val_loss: 2174913773.8442\n",
      "Epoch 2132/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 658651892.8531 - val_loss: 2121640103.8942\n",
      "Epoch 2133/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1411835978.3905 - val_loss: 1706008421.6799\n",
      "Epoch 2134/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 688153164.4975 - val_loss: 4497214202.8152\n",
      "Epoch 2135/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1068852005.9246 - val_loss: 1675747578.8242\n",
      "Epoch 2136/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 814342127.8829 - val_loss: 3008814274.8354\n",
      "Epoch 2137/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1334716286.0011 - val_loss: 3328338367.7660\n",
      "Epoch 2138/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 702376728.6348 - val_loss: 1590992431.9595\n",
      "Epoch 2139/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 624031775.8019 - val_loss: 1620429029.6754\n",
      "Epoch 2140/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 827027535.8649 - val_loss: 1596310503.2641\n",
      "Epoch 2141/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 894207523.0523 - val_loss: 1539703229.7947\n",
      "Epoch 2142/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 736245866.0664 - val_loss: 3110398293.6934\n",
      "Epoch 2143/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 1593781215.0388 - val_loss: 3167551195.5263\n",
      "Epoch 2144/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1684873415.1311 - val_loss: 1502292745.4380\n",
      "Epoch 2145/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 582546385.8638 - val_loss: 1492320150.2965\n",
      "Epoch 2146/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1698706661.6365 - val_loss: 1763883158.4495\n",
      "Epoch 2147/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 725880714.0124 - val_loss: 2019830498.3944\n",
      "Epoch 2148/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 651624575.4958 - val_loss: 3467514321.2737\n",
      "Epoch 2149/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 924913889.1165 - val_loss: 1938241090.5519\n",
      "Epoch 2150/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1383987081.8683 - val_loss: 2591910719.3429\n",
      "Epoch 2151/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1530729281.9494 - val_loss: 2790858262.8861\n",
      "Epoch 2152/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 696054726.7890 - val_loss: 2629918132.2622\n",
      "Epoch 2153/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 577863427.1874 - val_loss: 1675728938.4484\n",
      "Epoch 2154/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 563897934.9105 - val_loss: 2650513738.3876\n",
      "Epoch 2155/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 776673745.5037 - val_loss: 2298483000.0518\n",
      "Epoch 2156/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 905801580.0113 - val_loss: 1928100960.2768\n",
      "Epoch 2157/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1006227521.0445 - val_loss: 3905393545.9376\n",
      "Epoch 2158/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 2275755525.6185 - val_loss: 1833244719.4194\n",
      "Epoch 2159/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 879083298.7192 - val_loss: 1782228455.4532\n",
      "Epoch 2160/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 719829554.1339 - val_loss: 2392235930.6352\n",
      "Epoch 2161/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 792093614.7845 - val_loss: 4283770742.8906\n",
      "Epoch 2162/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1175920454.9510 - val_loss: 2547672691.6861\n",
      "Epoch 2163/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 769104341.7535 - val_loss: 2063998427.7423\n",
      "Epoch 2164/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 862100238.5864 - val_loss: 3482674237.7677\n",
      "Epoch 2165/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1395262223.5453 - val_loss: 1980945136.6976\n",
      "Epoch 2166/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 656235303.5858 - val_loss: 1665360422.6790\n",
      "Epoch 2167/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 591488750.0461 - val_loss: 2280541040.1935\n",
      "Epoch 2168/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1054214736.9634 - val_loss: 1767633473.7733\n",
      "Epoch 2169/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1125623468.0180 - val_loss: 1926849735.3271\n",
      "Epoch 2170/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 783758643.8087 - val_loss: 1924194477.0397\n",
      "Epoch 2171/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 973492105.4733 - val_loss: 2422780875.5758\n",
      "Epoch 2172/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 756844665.2290 - val_loss: 1907038430.0107\n",
      "Epoch 2173/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 862567980.1553 - val_loss: 2418321977.2219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2174/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 963563614.1092 - val_loss: 3385758962.3539\n",
      "Epoch 2175/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 727958013.8391 - val_loss: 1802799349.1983\n",
      "Epoch 2176/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 823709987.6556 - val_loss: 1669314615.7075\n",
      "Epoch 2177/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 735389128.5177 - val_loss: 2501960307.3260\n",
      "Epoch 2178/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 753109280.0900 - val_loss: 2135358069.4864\n",
      "Epoch 2179/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1089528803.3315 - val_loss: 2367820104.7944\n",
      "Epoch 2180/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1122862410.2645 - val_loss: 12085762112.3781\n",
      "Epoch 2181/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2732305613.2898 - val_loss: 2811849783.3046\n",
      "Epoch 2182/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1099771207.2392 - val_loss: 2076693601.5032\n",
      "Epoch 2183/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1014874356.1058 - val_loss: 2249662196.7167\n",
      "Epoch 2184/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 655100292.2544 - val_loss: 1857744412.4354\n",
      "Epoch 2185/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 873771379.6826 - val_loss: 2204542290.6869\n",
      "Epoch 2186/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 899024876.3714 - val_loss: 2068031988.5862\n",
      "Epoch 2187/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 523213208.8689 - val_loss: 2141201784.6549\n",
      "Epoch 2188/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 551373069.0141 - val_loss: 1679878866.9930\n",
      "Epoch 2189/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 766212053.8796 - val_loss: 3672160838.7871\n",
      "Epoch 2190/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 972002901.8075 - val_loss: 1973605357.7271\n",
      "Epoch 2191/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 601988995.8177 - val_loss: 1582257452.6470\n",
      "Epoch 2192/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 698693520.6640 - val_loss: 4746837699.0785\n",
      "Epoch 2193/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1081380548.6055 - val_loss: 2460917655.2956\n",
      "Epoch 2194/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 823489106.7462 - val_loss: 2118972598.8366\n",
      "Epoch 2195/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 903190563.8897 - val_loss: 1703149449.1409\n",
      "Epoch 2196/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 902378706.0439 - val_loss: 2107410352.4276\n",
      "Epoch 2197/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 993949431.3562 - val_loss: 4443794167.7187\n",
      "Epoch 2198/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1385891482.2015 - val_loss: 2434168766.8478\n",
      "Epoch 2199/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1549406324.7271 - val_loss: 1547868897.8892\n",
      "Epoch 2200/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 728156938.8768 - val_loss: 2460437116.5795\n",
      "Epoch 2201/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 888178434.0529 - val_loss: 2760056520.9834\n",
      "Epoch 2202/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 631140261.0962 - val_loss: 2189554309.8329\n",
      "Epoch 2203/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 909769417.7243 - val_loss: 1557423988.4782\n",
      "Epoch 2204/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 719797898.4446 - val_loss: 2913480892.2194\n",
      "Epoch 2205/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1530991315.1964 - val_loss: 2034053815.1246\n",
      "Epoch 2206/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 622707345.6477 - val_loss: 2540773254.4810\n",
      "Epoch 2207/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 880224626.9128 - val_loss: 2655966776.7089\n",
      "Epoch 2208/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1157486314.2645 - val_loss: 2517391416.3848\n",
      "Epoch 2209/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 889399713.8728 - val_loss: 1952000493.3131\n",
      "Epoch 2210/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 559345071.5048 - val_loss: 10180141031.3722\n",
      "Epoch 2211/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 2608452988.8306 - val_loss: 1690812678.4810\n",
      "Epoch 2212/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 760343409.9539 - val_loss: 6224379659.1617\n",
      "Epoch 2213/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 2175611883.8312 - val_loss: 2901450798.7713\n",
      "Epoch 2214/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 779834211.6196 - val_loss: 2202875985.3187\n",
      "Epoch 2215/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1039061088.8104 - val_loss: 2702137113.4920\n",
      "Epoch 2216/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 620948482.4671 - val_loss: 1489819262.1761\n",
      "Epoch 2217/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 645750961.6297 - val_loss: 1591620868.3927\n",
      "Epoch 2218/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 687243933.4609 - val_loss: 10497607346.7319\n",
      "Epoch 2219/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1623899625.7918 - val_loss: 1795167579.4003\n",
      "Epoch 2220/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 476238692.4299 - val_loss: 1592274055.6872\n",
      "Epoch 2221/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 441611527.6173 - val_loss: 1497922894.8523\n",
      "Epoch 2222/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 704693091.3495 - val_loss: 2455353632.3691\n",
      "Epoch 2223/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 975404829.9201 - val_loss: 1787269761.7823\n",
      "Epoch 2224/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 490097384.5898 - val_loss: 1483298069.3918\n",
      "Epoch 2225/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 617592052.7721 - val_loss: 2613422537.5235\n",
      "Epoch 2226/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 646605856.5492 - val_loss: 1774705787.9111\n",
      "Epoch 2227/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 834616636.3624 - val_loss: 5723372543.1359\n",
      "Epoch 2228/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1176460552.7158 - val_loss: 1529145993.4605\n",
      "Epoch 2229/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 593473399.0591 - val_loss: 2194304415.3249\n",
      "Epoch 2230/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 734224437.0152 - val_loss: 2028278753.0757\n",
      "Epoch 2231/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 800094064.6033 - val_loss: 2178316172.9980\n",
      "Epoch 2232/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1041157216.3421 - val_loss: 1772794838.4585\n",
      "Epoch 2233/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 941441481.9764 - val_loss: 2242601905.4897\n",
      "Epoch 2234/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 741759504.5672 - val_loss: 2152909856.0090\n",
      "Epoch 2235/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 758297650.1339 - val_loss: 1861785340.4534\n",
      "Epoch 2236/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 638344843.8852 - val_loss: 3800916170.8557\n",
      "Epoch 2237/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1647973563.2819 - val_loss: 2627027040.2385\n",
      "Epoch 2238/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1119420945.1300 - val_loss: 1551957760.4501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2239/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 512413976.3489 - val_loss: 1696738954.8197\n",
      "Epoch 2240/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 578050439.0591 - val_loss: 2097630764.3409\n",
      "Epoch 2241/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 731056540.9387 - val_loss: 3861849389.5651\n",
      "Epoch 2242/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 3053589652.3129 - val_loss: 2317247480.3668\n",
      "Epoch 2243/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1766762310.1047 - val_loss: 2117185945.8700\n",
      "Epoch 2244/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 513929442.5751 - val_loss: 1986111897.6810\n",
      "Epoch 2245/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 704670691.9077 - val_loss: 1968758956.7370\n",
      "Epoch 2246/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1135109235.6826 - val_loss: 2185313461.7564\n",
      "Epoch 2247/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 730987300.6280 - val_loss: 2966311946.0096\n",
      "Epoch 2248/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 832184488.8419 - val_loss: 2191679774.7488\n",
      "Epoch 2249/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 866860921.1570 - val_loss: 3200292304.9046\n",
      "Epoch 2250/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 985051124.0608 - val_loss: 1924562199.2776\n",
      "Epoch 2251/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 564933778.6201 - val_loss: 1791594336.9992\n",
      "Epoch 2252/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 514181717.1412 - val_loss: 2623222736.6166\n",
      "Epoch 2253/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 738698037.6095 - val_loss: 1846924377.6900\n",
      "Epoch 2254/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 628734340.9702 - val_loss: 3903018751.2079\n",
      "Epoch 2255/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1009117425.2065 - val_loss: 2689356429.0475\n",
      "Epoch 2256/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1003012967.6173 - val_loss: 3090348096.9181\n",
      "Epoch 2257/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 685918490.8047 - val_loss: 2178533613.9769\n",
      "Epoch 2258/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 832775703.0861 - val_loss: 1558416913.1702\n",
      "Epoch 2259/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 758455367.9595 - val_loss: 2374910245.0138\n",
      "Epoch 2260/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1264760472.6438 - val_loss: 3783155110.5620\n",
      "Epoch 2261/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 714755519.8920 - val_loss: 1526016124.1204\n",
      "Epoch 2262/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 495317887.3157 - val_loss: 3814771649.5134\n",
      "Epoch 2263/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1046515394.1429 - val_loss: 2751659365.3333\n",
      "Epoch 2264/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 815418360.3647 - val_loss: 8617978888.1373\n",
      "Epoch 2265/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1821430289.1795 - val_loss: 2337554769.5887\n",
      "Epoch 2266/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 659212259.6196 - val_loss: 3468273110.2335\n",
      "Epoch 2267/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 728568424.1396 - val_loss: 1628352232.6143\n",
      "Epoch 2268/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1332440389.5824 - val_loss: 5128882506.6037\n",
      "Epoch 2269/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1188677127.9449 - val_loss: 3049545184.0090\n",
      "Epoch 2270/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 965407363.2594 - val_loss: 2402526431.7030\n",
      "Epoch 2271/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 738676473.8053 - val_loss: 1917305302.6155\n",
      "Epoch 2272/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 541725657.4631 - val_loss: 5572766201.8790\n",
      "Epoch 2273/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 979383315.4485 - val_loss: 2184663195.7603\n",
      "Epoch 2274/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 600119737.9313 - val_loss: 2340352775.7772\n",
      "Epoch 2275/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 930950713.2659 - val_loss: 2566941578.9097\n",
      "Epoch 2276/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 777095538.0619 - val_loss: 1587792926.8028\n",
      "Epoch 2277/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 748108072.7091 - val_loss: 4720810257.8948\n",
      "Epoch 2278/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 785946843.2864 - val_loss: 1686056953.5055\n",
      "Epoch 2279/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 882782479.9415 - val_loss: 2401027786.4956\n",
      "Epoch 2280/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 941665113.9313 - val_loss: 2471298685.6416\n",
      "Epoch 2281/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 830370508.1373 - val_loss: 6105580689.4627\n",
      "Epoch 2282/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 1853853632.0360 - val_loss: 2285604440.7719\n",
      "Epoch 2283/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 854676183.4463 - val_loss: 3050466462.8602\n",
      "Epoch 2284/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 787577986.5931 - val_loss: 2471802709.9454\n",
      "Epoch 2285/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 794670132.9071 - val_loss: 8671442118.6070\n",
      "Epoch 2286/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1141015261.7310 - val_loss: 1818248499.3890\n",
      "Epoch 2287/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 665473488.4952 - val_loss: 3213549508.4107\n",
      "Epoch 2288/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 953508809.4001 - val_loss: 1614683345.2113\n",
      "Epoch 2289/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 554487710.4918 - val_loss: 1810171028.0720\n",
      "Epoch 2290/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 734895565.3438 - val_loss: 1726095460.0416\n",
      "Epoch 2291/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 598571737.3551 - val_loss: 2899515169.0172\n",
      "Epoch 2292/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 754650591.1536 - val_loss: 2058654354.8309\n",
      "Epoch 2293/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 771151253.1773 - val_loss: 10606006978.2864\n",
      "Epoch 2294/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2064601469.6387 - val_loss: 2825617321.5865\n",
      "Epoch 2295/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 629927909.6365 - val_loss: 1589960551.0301\n",
      "Epoch 2296/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 445470464.9904 - val_loss: 1580112602.1221\n",
      "Epoch 2297/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 802870151.5453 - val_loss: 1843096231.0031\n",
      "Epoch 2298/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 492268516.1958 - val_loss: 3068205086.6048\n",
      "Epoch 2299/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1563698750.9195 - val_loss: 2139413748.1181\n",
      "Epoch 2300/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 922091031.1941 - val_loss: 3001406886.5980\n",
      "Epoch 2301/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1142412866.7732 - val_loss: 2186324065.6383\n",
      "Epoch 2302/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 592609406.0551 - val_loss: 2853511992.3668\n",
      "Epoch 2303/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1024815264.0720 - val_loss: 2696565298.0748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2304/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 691071121.3596 - val_loss: 3604070509.8172\n",
      "Epoch 2305/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1231349049.7693 - val_loss: 1691350787.2405\n",
      "Epoch 2306/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 615314400.8104 - val_loss: 1497851254.0985\n",
      "Epoch 2307/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 558890231.9685 - val_loss: 2103495613.3176\n",
      "Epoch 2308/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 674949841.2876 - val_loss: 5918523585.4222\n",
      "Epoch 2309/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1848082275.5295 - val_loss: 1958266803.2180\n",
      "Epoch 2310/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1891142808.5087 - val_loss: 1573137257.6360\n",
      "Epoch 2311/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 612341296.3512 - val_loss: 2475948050.6149\n",
      "Epoch 2312/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 559578742.4378 - val_loss: 1606102162.6329\n",
      "Epoch 2313/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 552291249.0535 - val_loss: 2283816971.9381\n",
      "Epoch 2314/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 945658953.4721 - val_loss: 2933652560.2205\n",
      "Epoch 2315/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1001822929.0535 - val_loss: 1976388871.7502\n",
      "Epoch 2316/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1296188066.5031 - val_loss: 5985341936.8776\n",
      "Epoch 2317/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1001130818.3230 - val_loss: 3553825202.5159\n",
      "Epoch 2318/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1534121323.1469 - val_loss: 1765562825.3907\n",
      "Epoch 2319/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 677200594.4401 - val_loss: 4209617199.9595\n",
      "Epoch 2320/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 878843714.6258 - val_loss: 2921671582.2807\n",
      "Epoch 2321/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 688528691.5926 - val_loss: 1625841809.1027\n",
      "Epoch 2322/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 584024802.5121 - val_loss: 1690391233.9623\n",
      "Epoch 2323/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 635575733.3078 - val_loss: 1824562945.1612\n",
      "Epoch 2324/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 569609667.9257 - val_loss: 1597128245.5854\n",
      "Epoch 2325/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 485960167.5273 - val_loss: 1702155876.1316\n",
      "Epoch 2326/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 698678495.6218 - val_loss: 1471390996.3432\n",
      "Epoch 2327/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 598224725.9516 - val_loss: 1781228481.6563\n",
      "Epoch 2328/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1202116071.2212 - val_loss: 3365469807.6895\n",
      "Epoch 2329/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1431000582.6269 - val_loss: 4196888712.7494\n",
      "Epoch 2330/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1143713237.2853 - val_loss: 1378967629.2501\n",
      "Epoch 2331/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 532316163.9977 - val_loss: 1871727295.2090\n",
      "Epoch 2332/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 809216597.6455 - val_loss: 2348931537.5077\n",
      "Epoch 2333/10000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 875058755.2774 - val_loss: 1766274535.9842\n",
      "Epoch 2334/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 923374532.1080 - val_loss: 4065863251.8211\n",
      "Epoch 2335/10000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 740952330.4806 - val_loss: 2091814959.6523\n",
      "Epoch 2336/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 980613538.0709 - val_loss: 1620413584.3826\n",
      "Epoch 2337/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 549395772.7226 - val_loss: 2498707856.3826\n",
      "Epoch 2338/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 1861799927.3562 - val_loss: 3592256436.6762\n",
      "Epoch 2339/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 939157007.2527 - val_loss: 1537763281.4605\n",
      "Epoch 2340/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 449459850.4446 - val_loss: 1699042644.1992\n",
      "Epoch 2341/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 804296243.2504 - val_loss: 1776266806.8096\n",
      "Epoch 2342/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 986982629.3303 - val_loss: 12967475787.6118\n",
      "Epoch 2343/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 3351756979.2324 - val_loss: 1614566992.9046\n",
      "Epoch 2344/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 478791329.1480 - val_loss: 3426836526.7353\n",
      "Epoch 2345/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 651235161.8289 - val_loss: 2039980070.4540\n",
      "Epoch 2346/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 541476047.7029 - val_loss: 1406021218.2504\n",
      "Epoch 2347/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 496722668.8396 - val_loss: 1610511210.7297\n",
      "Epoch 2348/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 495312928.5402 - val_loss: 1636965610.9480\n",
      "Epoch 2349/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 547080877.5599 - val_loss: 1672215045.7429\n",
      "Epoch 2350/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 617100786.9353 - val_loss: 1458593770.4326\n",
      "Epoch 2351/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 720815011.8717 - val_loss: 1779209707.7918\n",
      "Epoch 2352/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 615248957.8751 - val_loss: 1505149271.7277\n",
      "Epoch 2353/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 657195730.9972 - val_loss: 1746138960.7606\n",
      "Epoch 2354/10000\n",
      "3554/3554 [==============================] - 0s 134us/step - loss: 651852671.6398 - val_loss: 2068066482.0208\n",
      "Epoch 2355/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 560857065.6162 - val_loss: 1928853141.6034\n",
      "Epoch 2356/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 956498220.2634 - val_loss: 1532974860.0034\n",
      "Epoch 2357/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1109684832.6843 - val_loss: 1918874360.3758\n",
      "Epoch 2358/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 793410390.9420 - val_loss: 1978997966.1902\n",
      "Epoch 2359/10000\n",
      "3554/3554 [==============================] - 0s 132us/step - loss: 930849405.3123 - val_loss: 2765463272.3083\n",
      "Epoch 2360/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 811050094.3523 - val_loss: 2241929200.9226\n",
      "Epoch 2361/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 2113909620.4547 - val_loss: 1664122150.8861\n",
      "Epoch 2362/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 663236971.0929 - val_loss: 1748708146.0118\n",
      "Epoch 2363/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 674592720.1711 - val_loss: 4572893131.5758\n",
      "Epoch 2364/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 970768907.3810 - val_loss: 11763701586.3089\n",
      "Epoch 2365/10000\n",
      "3554/3554 [==============================] - 0s 130us/step - loss: 2081642910.8655 - val_loss: 2303641316.3859\n",
      "Epoch 2366/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 655094166.7620 - val_loss: 1434266214.6610\n",
      "Epoch 2367/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 547300577.0084 - val_loss: 1623381699.8706\n",
      "Epoch 2368/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 940404833.2425 - val_loss: 1838620192.2970\n",
      "Epoch 2369/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 837875215.1277 - val_loss: 1621257119.4689\n",
      "Epoch 2370/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 462216939.9032 - val_loss: 3425854842.2391\n",
      "Epoch 2371/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 988731011.0974 - val_loss: 2660807825.3817\n",
      "Epoch 2372/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 654251628.7946 - val_loss: 3387488771.8076\n",
      "Epoch 2373/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 1086583972.4479 - val_loss: 1583397200.3511\n",
      "Epoch 2374/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 879614395.3900 - val_loss: 2930162360.2048\n",
      "Epoch 2375/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 903891502.5414 - val_loss: 1671001721.7260\n",
      "Epoch 2376/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 481638650.7417 - val_loss: 1779523655.1471\n",
      "Epoch 2377/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 534102905.0850 - val_loss: 2400389782.6475\n",
      "Epoch 2378/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 648102453.9516 - val_loss: 2592187530.3696\n",
      "Epoch 2379/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 975956467.0343 - val_loss: 6406644544.5221\n",
      "Epoch 2380/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1372581607.0771 - val_loss: 1660222043.6883\n",
      "Epoch 2381/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 1074857791.9640 - val_loss: 2859268294.4270\n",
      "Epoch 2382/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 650750812.2003 - val_loss: 3114739367.1021\n",
      "Epoch 2383/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 1086346571.0208 - val_loss: 2578680779.8008\n",
      "Epoch 2384/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 608320324.2589 - val_loss: 2717471073.9353\n",
      "Epoch 2385/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 656183917.0692 - val_loss: 1775863592.8304\n",
      "Epoch 2386/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 935207416.4007 - val_loss: 2210177582.1592\n",
      "Epoch 2387/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1533362474.5886 - val_loss: 2093457439.3069\n",
      "Epoch 2388/10000\n",
      "3554/3554 [==============================] - 0s 130us/step - loss: 505352629.6635 - val_loss: 1437700588.8113\n",
      "Epoch 2389/10000\n",
      "3554/3554 [==============================] - 0s 137us/step - loss: 592019453.2628 - val_loss: 1952647372.9125\n",
      "Epoch 2390/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 765640441.7333 - val_loss: 1699529290.1986\n",
      "Epoch 2391/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 762612142.2082 - val_loss: 5190279093.9004\n",
      "Epoch 2392/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 1771254805.1773 - val_loss: 2645332704.5671\n",
      "Epoch 2393/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1037622826.7867 - val_loss: 1638363237.0869\n",
      "Epoch 2394/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 673881274.9938 - val_loss: 1412107904.3150\n",
      "Epoch 2395/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 612397706.2285 - val_loss: 5635266212.1947\n",
      "Epoch 2396/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 1148591357.6590 - val_loss: 1653033606.7646\n",
      "Epoch 2397/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 666507499.1469 - val_loss: 1486983322.3741\n",
      "Epoch 2398/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 900088862.4783 - val_loss: 1457914279.3271\n",
      "Epoch 2399/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1199188792.5808 - val_loss: 1778904741.7114\n",
      "Epoch 2400/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 712734705.8278 - val_loss: 3093055203.7536\n",
      "Epoch 2401/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 529668596.9071 - val_loss: 2137556223.2079\n",
      "Epoch 2402/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 690305980.4705 - val_loss: 2198762502.4630\n",
      "Epoch 2403/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 660226811.6781 - val_loss: 4314180025.7890\n",
      "Epoch 2404/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1727420142.4423 - val_loss: 2484712493.7812\n",
      "Epoch 2405/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 713264904.2476 - val_loss: 1491605581.0880\n",
      "Epoch 2406/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 612202287.7029 - val_loss: 1409521361.1094\n",
      "Epoch 2407/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1060411143.7794 - val_loss: 2059383298.3404\n",
      "Epoch 2408/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 988808011.7051 - val_loss: 1972117300.8563\n",
      "Epoch 2409/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1041620953.0670 - val_loss: 5081263835.9224\n",
      "Epoch 2410/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 1106026374.3388 - val_loss: 1893709459.7671\n",
      "Epoch 2411/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1125958430.1092 - val_loss: 2854695759.8155\n",
      "Epoch 2412/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1687167406.0236 - val_loss: 1644748009.2264\n",
      "Epoch 2413/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 476549368.9409 - val_loss: 1993262002.5339\n",
      "Epoch 2414/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 750031830.2938 - val_loss: 1898694536.8844\n",
      "Epoch 2415/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 570576814.6044 - val_loss: 2004531609.2759\n",
      "Epoch 2416/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 606645831.2032 - val_loss: 2053488371.0560\n",
      "Epoch 2417/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 729036376.0945 - val_loss: 3633835750.6520\n",
      "Epoch 2418/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1143530837.6995 - val_loss: 1832357458.1907\n",
      "Epoch 2419/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 671669369.5892 - val_loss: 2037927169.0778\n",
      "Epoch 2420/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 861555679.8019 - val_loss: 1591880255.6669\n",
      "Epoch 2421/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 514578850.1609 - val_loss: 1956759784.6751\n",
      "Epoch 2422/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 485930430.9736 - val_loss: 2547234329.7080\n",
      "Epoch 2423/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1281820622.2983 - val_loss: 7200652942.5823\n",
      "Epoch 2424/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 996619011.8897 - val_loss: 2015279368.5513\n",
      "Epoch 2425/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 719576781.9741 - val_loss: 1546297461.1263\n",
      "Epoch 2426/10000\n",
      "3554/3554 [==============================] - 0s 131us/step - loss: 540847097.3731 - val_loss: 1665187680.7471\n",
      "Epoch 2427/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 465173849.0310 - val_loss: 3996716530.3809\n",
      "Epoch 2428/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 1001897287.2335 - val_loss: 1735172860.1024\n",
      "Epoch 2429/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1118948048.8194 - val_loss: 3510395371.5488\n",
      "Epoch 2430/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 925606249.4541 - val_loss: 1560841081.1634\n",
      "Epoch 2431/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 438210508.1913 - val_loss: 2381571400.6594\n",
      "Epoch 2432/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 578062048.4502 - val_loss: 5501981258.0006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2433/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1313519870.7124 - val_loss: 1950666364.8675\n",
      "Epoch 2434/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 546049815.7974 - val_loss: 1653081550.7083\n",
      "Epoch 2435/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 995114428.5155 - val_loss: 1722709810.0478\n",
      "Epoch 2436/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 831241885.0827 - val_loss: 1669812786.7949\n",
      "Epoch 2437/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 646705448.9139 - val_loss: 1374296991.6489\n",
      "Epoch 2438/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 649156119.9280 - val_loss: 2052316455.8942\n",
      "Epoch 2439/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 787749736.6697 - val_loss: 2344757278.9108\n",
      "Epoch 2440/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 3133014731.4890 - val_loss: 1877798900.2622\n",
      "Epoch 2441/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 957938962.0214 - val_loss: 2437086774.2605\n",
      "Epoch 2442/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 705091088.8194 - val_loss: 1602216343.5477\n",
      "Epoch 2443/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 711045466.5796 - val_loss: 2167082539.7828\n",
      "Epoch 2444/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 529664571.2999 - val_loss: 4050345709.5651\n",
      "Epoch 2445/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 507665793.8998 - val_loss: 1617228202.6644\n",
      "Epoch 2446/10000\n",
      "3554/3554 [==============================] - 0s 135us/step - loss: 580053581.1446 - val_loss: 2150189689.6630\n",
      "Epoch 2447/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 578649029.6995 - val_loss: 2335603135.3789\n",
      "Epoch 2448/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1110342184.1936 - val_loss: 3424078164.9013\n",
      "Epoch 2449/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1708220280.4907 - val_loss: 1838047956.4895\n",
      "Epoch 2450/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 760982300.0023 - val_loss: 1783974198.3055\n",
      "Epoch 2451/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 434788561.5037 - val_loss: 1885328195.2090\n",
      "Epoch 2452/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 631746104.4637 - val_loss: 1721005690.8242\n",
      "Epoch 2453/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 946811585.1885 - val_loss: 1653361541.9949\n",
      "Epoch 2454/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 572998795.5250 - val_loss: 1557923485.8487\n",
      "Epoch 2455/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 771017490.2060 - val_loss: 1709626388.2262\n",
      "Epoch 2456/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 718791532.1013 - val_loss: 2326618194.4799\n",
      "Epoch 2457/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 2874975615.0636 - val_loss: 1667070792.6143\n",
      "Epoch 2458/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1083531772.0563 - val_loss: 3014076677.4729\n",
      "Epoch 2459/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 806480364.4569 - val_loss: 1454803624.0653\n",
      "Epoch 2460/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 465390729.7873 - val_loss: 1427390772.3072\n",
      "Epoch 2461/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 654278953.7783 - val_loss: 3286114449.1139\n",
      "Epoch 2462/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 1167224510.0551 - val_loss: 1461637088.5131\n",
      "Epoch 2463/10000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 526351618.8475 - val_loss: 1466774788.8428\n",
      "Epoch 2464/10000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 557074072.4187 - val_loss: 1382781456.5086\n",
      "Epoch 2465/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 368187976.9679 - val_loss: 2174670676.9013\n",
      "Epoch 2466/10000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 655731126.3230 - val_loss: 2247635688.8304\n",
      "Epoch 2467/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 646793096.7158 - val_loss: 1712081848.8889\n",
      "Epoch 2468/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 705655593.4992 - val_loss: 1410601231.1854\n",
      "Epoch 2469/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 533461596.8936 - val_loss: 2094378700.8000\n",
      "Epoch 2470/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1007906383.2347 - val_loss: 4281062308.1136\n",
      "Epoch 2471/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 1311603092.7451 - val_loss: 1543367457.3052\n",
      "Epoch 2472/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 576836283.5701 - val_loss: 1989077063.9617\n",
      "Epoch 2473/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 620915127.7524 - val_loss: 1572623957.8374\n",
      "Epoch 2474/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1651270531.2774 - val_loss: 2101789028.2352\n",
      "Epoch 2475/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1100685162.9668 - val_loss: 1826527324.0563\n",
      "Epoch 2476/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 559772561.5037 - val_loss: 1403155917.9702\n",
      "Epoch 2477/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 367277076.4209 - val_loss: 4338877652.7212\n",
      "Epoch 2478/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1001743807.3157 - val_loss: 2680521097.9105\n",
      "Epoch 2479/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1118326901.9156 - val_loss: 2349270860.8270\n",
      "Epoch 2480/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 759698239.3382 - val_loss: 1567927277.0160\n",
      "Epoch 2481/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 511418437.0073 - val_loss: 1370236717.4031\n",
      "Epoch 2482/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 552404576.9544 - val_loss: 2610248938.6667\n",
      "Epoch 2483/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1026432359.1491 - val_loss: 3013077624.4568\n",
      "Epoch 2484/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1006809975.3202 - val_loss: 1926695556.7347\n",
      "Epoch 2485/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 552146586.2195 - val_loss: 3351057237.7654\n",
      "Epoch 2486/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1820139614.0912 - val_loss: 6847346805.9544\n",
      "Epoch 2487/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1009172457.0940 - val_loss: 2143371061.0183\n",
      "Epoch 2488/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 656492846.0822 - val_loss: 1774066747.6973\n",
      "Epoch 2489/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 508846305.0445 - val_loss: 1452588572.1744\n",
      "Epoch 2490/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 809061588.5650 - val_loss: 1363878097.6428\n",
      "Epoch 2491/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 493968440.8059 - val_loss: 1496474126.7443\n",
      "Epoch 2492/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1496954936.5447 - val_loss: 4872871500.5840\n",
      "Epoch 2493/10000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 875941636.2679 - val_loss: 1583182067.4160\n",
      "Epoch 2494/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 513106996.7991 - val_loss: 2155329748.5412\n",
      "Epoch 2495/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 673421522.4581 - val_loss: 2138001750.4056\n",
      "Epoch 2496/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 529554872.3388 - val_loss: 1488342135.8976\n",
      "Epoch 2497/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 579011589.5464 - val_loss: 1395461775.4824\n",
      "Epoch 2498/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 504426365.8751 - val_loss: 1615986181.4729\n",
      "Epoch 2499/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 476200955.8042 - val_loss: 2428729012.6942\n",
      "Epoch 2500/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1056097856.6483 - val_loss: 2196441968.1215\n",
      "Epoch 2501/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1235553023.3877 - val_loss: 2565061780.3252\n",
      "Epoch 2502/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 849417314.7192 - val_loss: 2453533436.0394\n",
      "Epoch 2503/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 929684731.9842 - val_loss: 1848077433.9781\n",
      "Epoch 2504/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 822234827.5070 - val_loss: 2094812004.3837\n",
      "Epoch 2505/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 764637028.9882 - val_loss: 5019587739.8143\n",
      "Epoch 2506/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 3262815737.3731 - val_loss: 1814769389.4571\n",
      "Epoch 2507/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 756834454.4378 - val_loss: 1497957903.7165\n",
      "Epoch 2508/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 552343553.0377 - val_loss: 1677220768.8011\n",
      "Epoch 2509/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 638911084.3354 - val_loss: 4592294921.6495\n",
      "Epoch 2510/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 1358394093.1255 - val_loss: 2005232105.7620\n",
      "Epoch 2511/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 621828720.9454 - val_loss: 1913597103.9955\n",
      "Epoch 2512/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 617034844.2364 - val_loss: 1569905052.3724\n",
      "Epoch 2513/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 614665019.3900 - val_loss: 2176023365.4729\n",
      "Epoch 2514/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 556464868.5560 - val_loss: 1344935623.8492\n",
      "Epoch 2515/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 566139817.9764 - val_loss: 1442356745.2985\n",
      "Epoch 2516/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 575428708.0158 - val_loss: 1392866594.3021\n",
      "Epoch 2517/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 680819971.4575 - val_loss: 1584810832.3466\n",
      "Epoch 2518/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1067912585.9223 - val_loss: 1818008409.6000\n",
      "Epoch 2519/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 733509976.4187 - val_loss: 1656056573.0475\n",
      "Epoch 2520/10000\n",
      "3554/3554 [==============================] - 0s 134us/step - loss: 502475361.0985 - val_loss: 1588099860.9193\n",
      "Epoch 2521/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 590885549.7400 - val_loss: 2817144144.9767\n",
      "Epoch 2522/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 2140036014.0281 - val_loss: 1435979148.6695\n",
      "Epoch 2523/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 653870248.5898 - val_loss: 1377650653.3401\n",
      "Epoch 2524/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 443569300.6415 - val_loss: 1626682761.6675\n",
      "Epoch 2525/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 1642135708.1463 - val_loss: 2304870777.9871\n",
      "Epoch 2526/10000\n",
      "3554/3554 [==============================] - 1s 141us/step - loss: 1529038106.9758 - val_loss: 1454492121.3750\n",
      "Epoch 2527/10000\n",
      "3554/3554 [==============================] - 0s 134us/step - loss: 796252113.5397 - val_loss: 1613133488.6076\n",
      "Epoch 2528/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 476644761.0850 - val_loss: 1790422825.3840\n",
      "Epoch 2529/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 523054784.5402 - val_loss: 1654403913.1994\n",
      "Epoch 2530/10000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 529839440.7653 - val_loss: 1373206020.0686\n",
      "Epoch 2531/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 419979646.1857 - val_loss: 1397162563.3935\n",
      "Epoch 2532/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 678698720.5943 - val_loss: 2157586736.1035\n",
      "Epoch 2533/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 1224651284.5965 - val_loss: 2533030956.8810\n",
      "Epoch 2534/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1151088866.0754 - val_loss: 1578079766.9131\n",
      "Epoch 2535/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 399383299.7456 - val_loss: 1914757533.4627\n",
      "Epoch 2536/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1080003157.8976 - val_loss: 1849216995.3305\n",
      "Epoch 2537/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 817118764.6956 - val_loss: 1521593741.3356\n",
      "Epoch 2538/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 466150281.5082 - val_loss: 1512164392.2723\n",
      "Epoch 2539/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 634204654.4963 - val_loss: 2250443592.4793\n",
      "Epoch 2540/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 612727666.2600 - val_loss: 1302353445.1038\n",
      "Epoch 2541/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 751835110.0687 - val_loss: 1659264931.9876\n",
      "Epoch 2542/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 791381511.1536 - val_loss: 1790236061.0025\n",
      "Epoch 2543/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 535426770.2510 - val_loss: 4140837468.8225\n",
      "Epoch 2544/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 931418471.6714 - val_loss: 1635071988.8833\n",
      "Epoch 2545/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 766252536.6528 - val_loss: 3339729545.1094\n",
      "Epoch 2546/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1072224461.7580 - val_loss: 1465251900.8720\n",
      "Epoch 2547/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 553078950.6089 - val_loss: 1757632298.1536\n",
      "Epoch 2548/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 1170698028.5718 - val_loss: 1535833573.2838\n",
      "Epoch 2549/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 863732011.5070 - val_loss: 2296165990.4000\n",
      "Epoch 2550/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 1470926932.8531 - val_loss: 7714008386.1783\n",
      "Epoch 2551/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1602761465.3011 - val_loss: 1817197078.5395\n",
      "Epoch 2552/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1158378179.2774 - val_loss: 6405906611.5961\n",
      "Epoch 2553/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1202170557.0107 - val_loss: 1385696324.3004\n",
      "Epoch 2554/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 572183035.9572 - val_loss: 1521438397.0655\n",
      "Epoch 2555/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 412944274.8002 - val_loss: 1964949847.0076\n",
      "Epoch 2556/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 644467482.8880 - val_loss: 2219021333.2883\n",
      "Epoch 2557/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 883748219.7681 - val_loss: 1686337350.5710\n",
      "Epoch 2558/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 566640696.5447 - val_loss: 1517920185.5910\n",
      "Epoch 2559/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 593228676.8981 - val_loss: 1551683769.1319\n",
      "Epoch 2560/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 625835876.5560 - val_loss: 1539118140.9215\n",
      "Epoch 2561/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 856774272.5042 - val_loss: 1443959302.6880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2562/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 817536067.0613 - val_loss: 1912754547.8661\n",
      "Epoch 2563/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1074464741.0602 - val_loss: 2291115450.2571\n",
      "Epoch 2564/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1045371032.0585 - val_loss: 1360973087.4869\n",
      "Epoch 2565/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 443539221.7535 - val_loss: 6914627394.2504\n",
      "Epoch 2566/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 933467329.9449 - val_loss: 2238419466.0006\n",
      "Epoch 2567/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 527748763.9167 - val_loss: 2806112860.2464\n",
      "Epoch 2568/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 854837465.6792 - val_loss: 4253863613.8937\n",
      "Epoch 2569/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 1061445083.8042 - val_loss: 1638727656.2003\n",
      "Epoch 2570/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 882298593.4992 - val_loss: 1316038556.7415\n",
      "Epoch 2571/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 597665515.0748 - val_loss: 1833667345.7508\n",
      "Epoch 2572/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 547642097.5937 - val_loss: 5776792162.6554\n",
      "Epoch 2573/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 3111420544.9004 - val_loss: 1844129287.2551\n",
      "Epoch 2574/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 515512150.1137 - val_loss: 1415459364.2397\n",
      "Epoch 2575/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 466834610.0979 - val_loss: 1443178655.3879\n",
      "Epoch 2576/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 430072244.6820 - val_loss: 2216008588.2419\n",
      "Epoch 2577/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 528943296.2881 - val_loss: 2273372474.6172\n",
      "Epoch 2578/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 441723649.2966 - val_loss: 1432565220.6672\n",
      "Epoch 2579/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 668677002.8768 - val_loss: 1591458540.2689\n",
      "Epoch 2580/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 782060759.0321 - val_loss: 1815666142.2627\n",
      "Epoch 2581/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 591524984.9049 - val_loss: 1502341907.5961\n",
      "Epoch 2582/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1439579457.6567 - val_loss: 1504695521.3727\n",
      "Epoch 2583/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 609723770.2015 - val_loss: 3080306441.2895\n",
      "Epoch 2584/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 870131866.6517 - val_loss: 3438590148.9508\n",
      "Epoch 2585/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1847658975.6939 - val_loss: 2498089284.1046\n",
      "Epoch 2586/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 903488759.6263 - val_loss: 1658360749.1150\n",
      "Epoch 2587/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 582705901.0197 - val_loss: 2737595802.1041\n",
      "Epoch 2588/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 744694130.1925 - val_loss: 1340915766.2965\n",
      "Epoch 2589/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 317822369.7107 - val_loss: 5939258080.3871\n",
      "Epoch 2590/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1091274867.3675 - val_loss: 1660853421.3851\n",
      "Epoch 2591/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 990616176.1441 - val_loss: 2044823391.2709\n",
      "Epoch 2592/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 759207270.6449 - val_loss: 2027292410.1322\n",
      "Epoch 2593/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 485877688.8869 - val_loss: 1384215133.4346\n",
      "Epoch 2594/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 561583678.9555 - val_loss: 2818409932.2959\n",
      "Epoch 2595/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 2152192060.7586 - val_loss: 1503232340.0821\n",
      "Epoch 2596/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 681757621.6815 - val_loss: 2904261915.1122\n",
      "Epoch 2597/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 1086546215.8694 - val_loss: 2018469651.3508\n",
      "Epoch 2598/10000\n",
      "3554/3554 [==============================] - 0s 137us/step - loss: 749645492.5650 - val_loss: 1628991309.3401\n",
      "Epoch 2599/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 1179392168.6258 - val_loss: 2766266737.2827\n",
      "Epoch 2600/10000\n",
      "3554/3554 [==============================] - 1s 141us/step - loss: 814013722.6438 - val_loss: 1619002618.2031\n",
      "Epoch 2601/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 907524675.1334 - val_loss: 2673534818.7004\n",
      "Epoch 2602/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1375179052.8756 - val_loss: 1718409886.4428\n",
      "Epoch 2603/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 571885840.2431 - val_loss: 2778553505.8813\n",
      "Epoch 2604/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 525214369.4226 - val_loss: 1534753140.7707\n",
      "Epoch 2605/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1038792255.8199 - val_loss: 2242224974.6723\n",
      "Epoch 2606/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 544770880.6123 - val_loss: 1396649957.5089\n",
      "Epoch 2607/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 653610784.9184 - val_loss: 1429277716.8293\n",
      "Epoch 2608/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 539937533.5509 - val_loss: 1735698317.6821\n",
      "Epoch 2609/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 623292204.2153 - val_loss: 1368691622.7060\n",
      "Epoch 2610/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 479267929.3551 - val_loss: 1812275472.5986\n",
      "Epoch 2611/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 882275849.8323 - val_loss: 2977287725.2411\n",
      "Epoch 2612/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 683021550.0642 - val_loss: 1506683455.1539\n",
      "Epoch 2613/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 729010277.8526 - val_loss: 1625472195.3733\n",
      "Epoch 2614/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 619586470.7440 - val_loss: 1543548363.5038\n",
      "Epoch 2615/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 573561901.8120 - val_loss: 8545471879.4532\n",
      "Epoch 2616/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 2093424457.0287 - val_loss: 2568900704.0540\n",
      "Epoch 2617/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 755705429.2853 - val_loss: 1770898352.8596\n",
      "Epoch 2618/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 478075799.9325 - val_loss: 2003332441.6900\n",
      "Epoch 2619/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 910253611.3630 - val_loss: 6035831315.6591\n",
      "Epoch 2620/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 2996593024.8351 - val_loss: 1714528801.4492\n",
      "Epoch 2621/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 618428751.4868 - val_loss: 1495853691.6343\n",
      "Epoch 2622/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 342020942.0732 - val_loss: 1386739128.9474\n",
      "Epoch 2623/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 572693999.2887 - val_loss: 1876211719.4487\n",
      "Epoch 2624/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 786636037.7625 - val_loss: 4218418769.1117\n",
      "Epoch 2625/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 984084988.2364 - val_loss: 1339636362.7837\n",
      "Epoch 2626/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 560065719.8244 - val_loss: 5860991714.6914\n",
      "Epoch 2627/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 974017809.5037 - val_loss: 1408247235.7828\n",
      "Epoch 2628/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 538577153.6027 - val_loss: 1560785787.2923\n",
      "Epoch 2629/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 489197476.2319 - val_loss: 25548088421.6799\n",
      "Epoch 2630/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 5198708023.4102 - val_loss: 3316447483.0312\n",
      "Epoch 2631/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 475639401.1840 - val_loss: 1491048923.1842\n",
      "Epoch 2632/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 415731021.7940 - val_loss: 1635506027.1842\n",
      "Epoch 2633/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 510979779.2414 - val_loss: 1482928552.0293\n",
      "Epoch 2634/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 548662788.7901 - val_loss: 1309261096.6053\n",
      "Epoch 2635/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 397445145.3281 - val_loss: 3116901662.3617\n",
      "Epoch 2636/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 792009214.7079 - val_loss: 1836925419.2968\n",
      "Epoch 2637/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 499774509.6320 - val_loss: 1543681850.2211\n",
      "Epoch 2638/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 805940023.7884 - val_loss: 4060741176.0968\n",
      "Epoch 2639/10000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 810537553.8998 - val_loss: 2274343594.9907\n",
      "Epoch 2640/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 721921494.4198 - val_loss: 2844634666.9637\n",
      "Epoch 2641/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 666584806.6089 - val_loss: 1622003016.7404\n",
      "Epoch 2642/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 846083276.3849 - val_loss: 1564684614.5733\n",
      "Epoch 2643/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 578126249.9944 - val_loss: 1662927546.9997\n",
      "Epoch 2644/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 428457161.1300 - val_loss: 2018540218.3021\n",
      "Epoch 2645/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 552562217.3101 - val_loss: 1507313181.6686\n",
      "Epoch 2646/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 745506579.8087 - val_loss: 2809266437.2568\n",
      "Epoch 2647/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1506231612.9387 - val_loss: 3020481235.2990\n",
      "Epoch 2648/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 1911458888.9679 - val_loss: 1642361076.5142\n",
      "Epoch 2649/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 527870937.1660 - val_loss: 2291289225.3435\n",
      "Epoch 2650/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 332688580.8621 - val_loss: 1577607016.3443\n",
      "Epoch 2651/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 605118064.4232 - val_loss: 1643424322.8264\n",
      "Epoch 2652/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 529804294.6764 - val_loss: 1434923127.4847\n",
      "Epoch 2653/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 560917285.5284 - val_loss: 1582244884.7392\n",
      "Epoch 2654/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1912982288.7113 - val_loss: 6788458019.5736\n",
      "Epoch 2655/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1984020815.2707 - val_loss: 1801141638.8231\n",
      "Epoch 2656/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 596752312.6258 - val_loss: 1420311160.1508\n",
      "Epoch 2657/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 518146543.6488 - val_loss: 1373559405.3941\n",
      "Epoch 2658/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 518540838.1767 - val_loss: 2146051323.8954\n",
      "Epoch 2659/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 670036341.3573 - val_loss: 2039100544.8281\n",
      "Epoch 2660/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 374907840.3602 - val_loss: 1325302245.5719\n",
      "Epoch 2661/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1302583971.3675 - val_loss: 1637822740.1395\n",
      "Epoch 2662/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 664191271.6714 - val_loss: 3274598736.9767\n",
      "Epoch 2663/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 845780117.2853 - val_loss: 1487019083.8098\n",
      "Epoch 2664/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 469367242.5166 - val_loss: 1535921131.5736\n",
      "Epoch 2665/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 774950653.9831 - val_loss: 2987481893.0858\n",
      "Epoch 2666/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 806511174.8430 - val_loss: 1407385647.8155\n",
      "Epoch 2667/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1009008578.3410 - val_loss: 1854600071.2371\n",
      "Epoch 2668/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 896419104.6933 - val_loss: 1439636755.8121\n",
      "Epoch 2669/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 446184620.1913 - val_loss: 2981990969.7890\n",
      "Epoch 2670/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 764070557.5329 - val_loss: 6866436641.6293\n",
      "Epoch 2671/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1648457317.0962 - val_loss: 1426888018.0478\n",
      "Epoch 2672/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 418786332.5785 - val_loss: 1375378674.1378\n",
      "Epoch 2673/10000\n",
      "3554/3554 [==============================] - 0s 136us/step - loss: 368565947.0028 - val_loss: 1460188624.0585\n",
      "Epoch 2674/10000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 442256992.5025 - val_loss: 1381689966.8433\n",
      "Epoch 2675/10000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 399746102.6629 - val_loss: 1313801164.7280\n",
      "Epoch 2676/10000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 682761359.2167 - val_loss: 1939215672.0788\n",
      "Epoch 2677/10000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 565325361.1975 - val_loss: 1542784952.7899\n",
      "Epoch 2678/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 770677648.2071 - val_loss: 3959230685.9747\n",
      "Epoch 2679/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 1545468991.0276 - val_loss: 3047024246.8906\n",
      "Epoch 2680/10000\n",
      "3554/3554 [==============================] - 0s 140us/step - loss: 1076429329.4316 - val_loss: 1698513457.3592\n",
      "Epoch 2681/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 630564376.0225 - val_loss: 1528717391.7525\n",
      "Epoch 2682/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 784490040.0900 - val_loss: 1417073372.7685\n",
      "Epoch 2683/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 721672816.5132 - val_loss: 1712740488.2993\n",
      "Epoch 2684/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1426596017.6117 - val_loss: 1453401828.3657\n",
      "Epoch 2685/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 500504778.8588 - val_loss: 1758793380.8788\n",
      "Epoch 2686/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 655624040.0585 - val_loss: 1662829994.8467\n",
      "Epoch 2687/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 767483569.4856 - val_loss: 5821401443.9516\n",
      "Epoch 2688/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 1816546450.5841 - val_loss: 1901409517.6011\n",
      "Epoch 2689/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 452782308.9387 - val_loss: 1231842959.2259\n",
      "Epoch 2690/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 335761310.9736 - val_loss: 1305990990.2132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2691/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 452943418.8407 - val_loss: 1462086107.4993\n",
      "Epoch 2692/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 605751156.5110 - val_loss: 1930525114.1491\n",
      "Epoch 2693/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 954961226.5346 - val_loss: 1602456354.5564\n",
      "Epoch 2694/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 704776237.1638 - val_loss: 1827299233.1972\n",
      "Epoch 2695/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1038829788.2364 - val_loss: 8799171972.2847\n",
      "Epoch 2696/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1249074036.3309 - val_loss: 1709702077.9477\n",
      "Epoch 2697/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 591011144.4367 - val_loss: 1407911664.9136\n",
      "Epoch 2698/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 692754324.2409 - val_loss: 4809329114.4101\n",
      "Epoch 2699/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 675752833.0805 - val_loss: 1626146480.3916\n",
      "Epoch 2700/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 436444498.9235 - val_loss: 1213415017.6540\n",
      "Epoch 2701/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 513520384.0180 - val_loss: 1822581337.1139\n",
      "Epoch 2702/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 427525674.2825 - val_loss: 1466055332.6447\n",
      "Epoch 2703/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 559482919.6894 - val_loss: 1425581468.5840\n",
      "Epoch 2704/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 512318095.5228 - val_loss: 1397570386.0028\n",
      "Epoch 2705/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 863355800.8059 - val_loss: 1326205052.3454\n",
      "Epoch 2706/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1467394583.1221 - val_loss: 2361530150.3100\n",
      "Epoch 2707/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 610243696.5492 - val_loss: 1549982739.4610\n",
      "Epoch 2708/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 604134736.7383 - val_loss: 1403636251.5173\n",
      "Epoch 2709/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 522537180.0023 - val_loss: 1418423136.3691\n",
      "Epoch 2710/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 530788300.1373 - val_loss: 1600844809.4695\n",
      "Epoch 2711/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1433708341.5194 - val_loss: 1643192412.4985\n",
      "Epoch 2712/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 591430292.1688 - val_loss: 1416308418.7454\n",
      "Epoch 2713/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1372621280.5042 - val_loss: 2091143424.8101\n",
      "Epoch 2714/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 539384882.9983 - val_loss: 3921825028.3117\n",
      "Epoch 2715/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 634530828.8486 - val_loss: 1547396784.1395\n",
      "Epoch 2716/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 573909977.0940 - val_loss: 1417789229.6686\n",
      "Epoch 2717/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 580051217.6477 - val_loss: 2510573450.7477\n",
      "Epoch 2718/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1371753008.0090 - val_loss: 7344724417.3502\n",
      "Epoch 2719/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 814725101.0107 - val_loss: 1356718098.6869\n",
      "Epoch 2720/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 544241357.9021 - val_loss: 1329617549.3401\n",
      "Epoch 2721/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 446500371.7907 - val_loss: 1302103825.4402\n",
      "Epoch 2722/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 866554682.2015 - val_loss: 3276033212.4354\n",
      "Epoch 2723/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1018863433.9043 - val_loss: 7358138005.6394\n",
      "Epoch 2724/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2306644646.3028 - val_loss: 1316306070.5080\n",
      "Epoch 2725/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 768110995.9955 - val_loss: 2248810615.7367\n",
      "Epoch 2726/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 590074982.7169 - val_loss: 1578986952.6594\n",
      "Epoch 2727/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 420975371.2189 - val_loss: 1588150775.6557\n",
      "Epoch 2728/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 988814021.2549 - val_loss: 2447714382.1322\n",
      "Epoch 2729/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 634183592.5537 - val_loss: 1298745211.2383\n",
      "Epoch 2730/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 501207566.9645 - val_loss: 1661692372.2892\n",
      "Epoch 2731/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 595779570.8903 - val_loss: 1555188326.9626\n",
      "Epoch 2732/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 650248278.9781 - val_loss: 1796215816.2813\n",
      "Epoch 2733/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 941423357.5509 - val_loss: 2530100435.4610\n",
      "Epoch 2734/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 1044651186.5661 - val_loss: 1558077945.0779\n",
      "Epoch 2735/10000\n",
      "3554/3554 [==============================] - 0s 131us/step - loss: 857965263.7389 - val_loss: 2201396575.7660\n",
      "Epoch 2736/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 2835326711.0051 - val_loss: 1641983517.8127\n",
      "Epoch 2737/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 437827449.4879 - val_loss: 1522068843.5038\n",
      "Epoch 2738/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1014219725.9561 - val_loss: 1418528786.9030\n",
      "Epoch 2739/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 363177633.3506 - val_loss: 1995445349.5854\n",
      "Epoch 2740/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 554636047.4147 - val_loss: 1723336828.8675\n",
      "Epoch 2741/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 476864311.4125 - val_loss: 1734088442.6532\n",
      "Epoch 2742/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 723542829.6680 - val_loss: 1753958115.0357\n",
      "Epoch 2743/10000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 473094836.2949 - val_loss: 1979793441.5572\n",
      "Epoch 2744/10000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 746462304.3106 - val_loss: 1554324852.2082\n",
      "Epoch 2745/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 711374771.6466 - val_loss: 1667742682.4821\n",
      "Epoch 2746/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 1134606469.1503 - val_loss: 1417014752.2430\n",
      "Epoch 2747/10000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 558659789.5239 - val_loss: 2504801312.9091\n",
      "Epoch 2748/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 508489048.6348 - val_loss: 1290517049.1949\n",
      "Epoch 2749/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 460914894.6584 - val_loss: 2168540092.0574\n",
      "Epoch 2750/10000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 544461510.5729 - val_loss: 1406903123.2540\n",
      "Epoch 2751/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 509806474.3725 - val_loss: 1266939234.5024\n",
      "Epoch 2752/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 593916468.1508 - val_loss: 5944328559.2574\n",
      "Epoch 2753/10000\n",
      "3554/3554 [==============================] - 1s 148us/step - loss: 837595183.5588 - val_loss: 1611823675.5533\n",
      "Epoch 2754/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 2176999319.7704 - val_loss: 3428206504.0923\n",
      "Epoch 2755/10000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 1040296983.8784 - val_loss: 2134314420.4602\n",
      "Epoch 2756/10000\n",
      "3554/3554 [==============================] - 1s 143us/step - loss: 508515668.0608 - val_loss: 1660174335.4239\n",
      "Epoch 2757/10000\n",
      "3554/3554 [==============================] - 1s 147us/step - loss: 1075512043.4620 - val_loss: 1675578972.1474\n",
      "Epoch 2758/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 510092709.9426 - val_loss: 2305709460.5952\n",
      "Epoch 2759/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 512376955.2099 - val_loss: 1766747856.7876\n",
      "Epoch 2760/10000\n",
      "3554/3554 [==============================] - 0s 134us/step - loss: 627418022.3208 - val_loss: 1324781034.7567\n",
      "Epoch 2761/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 610174745.8526 - val_loss: 1826745106.2368\n",
      "Epoch 2762/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 371727751.2752 - val_loss: 1509700859.5353\n",
      "Epoch 2763/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 419199038.6674 - val_loss: 1425388598.0805\n",
      "Epoch 2764/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1092856286.2893 - val_loss: 3337607322.7702\n",
      "Epoch 2765/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 1976578658.1429 - val_loss: 1921476806.3190\n",
      "Epoch 2766/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 875447747.8897 - val_loss: 1516081254.0489\n",
      "Epoch 2767/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 460952889.9854 - val_loss: 1200685438.2897\n",
      "Epoch 2768/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 551240899.0343 - val_loss: 2157461876.7482\n",
      "Epoch 2769/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 659197315.5656 - val_loss: 1635931655.2169\n",
      "Epoch 2770/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 796774490.3568 - val_loss: 1660253585.9128\n",
      "Epoch 2771/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 621422896.3196 - val_loss: 1292903615.5139\n",
      "Epoch 2772/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 618649394.5661 - val_loss: 2277493207.6287\n",
      "Epoch 2773/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 820360077.9741 - val_loss: 1776816435.4385\n",
      "Epoch 2774/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 645749404.9116 - val_loss: 1351645193.3975\n",
      "Epoch 2775/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 517675103.5138 - val_loss: 1404255910.0399\n",
      "Epoch 2776/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 804741042.9409 - val_loss: 1316735817.4065\n",
      "Epoch 2777/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 787588003.5836 - val_loss: 1854802041.9150\n",
      "Epoch 2778/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 574744789.5374 - val_loss: 1926385547.6118\n",
      "Epoch 2779/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1115924909.1458 - val_loss: 4736822245.4999\n",
      "Epoch 2780/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1699626623.0996 - val_loss: 1274519791.6039\n",
      "Epoch 2781/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 404213555.5385 - val_loss: 1274616828.8872\n",
      "Epoch 2782/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 604685724.0923 - val_loss: 2989081778.9120\n",
      "Epoch 2783/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 482811033.3731 - val_loss: 2306432235.8549\n",
      "Epoch 2784/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 1257465911.5003 - val_loss: 1686723178.1176\n",
      "Epoch 2785/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 357456536.2206 - val_loss: 1907206676.6312\n",
      "Epoch 2786/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 572624867.0703 - val_loss: 2063326959.8695\n",
      "Epoch 2787/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1177315142.7935 - val_loss: 1242732589.0430\n",
      "Epoch 2788/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 518601699.7344 - val_loss: 1344922394.3921\n",
      "Epoch 2789/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 431491329.6424 - val_loss: 1289913811.4700\n",
      "Epoch 2790/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 672701756.1688 - val_loss: 2958291812.8788\n",
      "Epoch 2791/10000\n",
      "3554/3554 [==============================] - 0s 136us/step - loss: 1179267855.6669 - val_loss: 2028244478.8118\n",
      "Epoch 2792/10000\n",
      "3554/3554 [==============================] - 0s 140us/step - loss: 559282679.1086 - val_loss: 2175737481.9376\n",
      "Epoch 2793/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 463257406.5144 - val_loss: 2343543869.3221\n",
      "Epoch 2794/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 794246225.9358 - val_loss: 2265368303.9415\n",
      "Epoch 2795/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 619699190.1317 - val_loss: 2880831131.9764\n",
      "Epoch 2796/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 756756512.1531 - val_loss: 2619795507.7266\n",
      "Epoch 2797/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 783154776.8149 - val_loss: 1676131255.4352\n",
      "Epoch 2798/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 696866927.4170 - val_loss: 1642982171.8684\n",
      "Epoch 2799/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 613562666.8407 - val_loss: 1802459306.5226\n",
      "Epoch 2800/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 617890730.5706 - val_loss: 4119879584.3150\n",
      "Epoch 2801/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1353477130.0124 - val_loss: 1534115769.9691\n",
      "Epoch 2802/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 562661092.6280 - val_loss: 2369032370.0478\n",
      "Epoch 2803/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1135036514.6832 - val_loss: 6066948004.6537\n",
      "Epoch 2804/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2063551070.0011 - val_loss: 2941466799.6714\n",
      "Epoch 2805/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 698512426.1745 - val_loss: 1734777572.5637\n",
      "Epoch 2806/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 586068680.1396 - val_loss: 3358772945.4177\n",
      "Epoch 2807/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 825017242.5796 - val_loss: 1475093204.9350\n",
      "Epoch 2808/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 730307327.7119 - val_loss: 3093145908.3522\n",
      "Epoch 2809/10000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 1990841205.6275 - val_loss: 1687947598.5643\n",
      "Epoch 2810/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 438663739.0152 - val_loss: 1471862141.0475\n",
      "Epoch 2811/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 372968312.6078 - val_loss: 1294348568.0113\n",
      "Epoch 2812/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 388716084.8261 - val_loss: 1384977530.5992\n",
      "Epoch 2813/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 309920235.4080 - val_loss: 1496512719.7525\n",
      "Epoch 2814/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 556647604.2319 - val_loss: 1642997235.8211\n",
      "Epoch 2815/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 765396455.1851 - val_loss: 5392369591.8447\n",
      "Epoch 2816/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 2103481374.0912 - val_loss: 2585368839.7592\n",
      "Epoch 2817/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 562902815.4598 - val_loss: 1375652555.9179\n",
      "Epoch 2818/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 545368009.6027 - val_loss: 1279273913.4290\n",
      "Epoch 2819/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 308917137.6567 - val_loss: 1480179890.9840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2820/10000\n",
      "3554/3554 [==============================] - 0s 132us/step - loss: 421672862.3343 - val_loss: 1278671756.1159\n",
      "Epoch 2821/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 543027579.5971 - val_loss: 2007480957.7755\n",
      "Epoch 2822/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 512797697.5003 - val_loss: 1662237235.2000\n",
      "Epoch 2823/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 634762488.5808 - val_loss: 1448911663.0504\n",
      "Epoch 2824/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1591779774.8160 - val_loss: 1506928549.6979\n",
      "Epoch 2825/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 409640734.4783 - val_loss: 1449470797.2231\n",
      "Epoch 2826/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 529974541.2628 - val_loss: 1328263931.7783\n",
      "Epoch 2827/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 499451851.4350 - val_loss: 1331481782.8186\n",
      "Epoch 2828/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 501562143.9820 - val_loss: 2833654578.5519\n",
      "Epoch 2829/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 826964277.0152 - val_loss: 8272553631.7210\n",
      "Epoch 2830/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 2134394807.8965 - val_loss: 1892747316.7842\n",
      "Epoch 2831/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 376248069.9966 - val_loss: 1374462547.1010\n",
      "Epoch 2832/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1519860622.2262 - val_loss: 1592063122.7949\n",
      "Epoch 2833/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 324200296.5627 - val_loss: 1661337489.3592\n",
      "Epoch 2834/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 509394137.7012 - val_loss: 1180043227.3553\n",
      "Epoch 2835/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 326860601.9854 - val_loss: 1301336687.0233\n",
      "Epoch 2836/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 508026965.1052 - val_loss: 1856124636.8990\n",
      "Epoch 2837/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 793195558.4828 - val_loss: 1342152047.4824\n",
      "Epoch 2838/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 434861378.7012 - val_loss: 6575773669.0678\n",
      "Epoch 2839/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2969269328.5312 - val_loss: 1927573046.2245\n",
      "Epoch 2840/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 465813511.7434 - val_loss: 1218574289.4155\n",
      "Epoch 2841/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 352554973.5059 - val_loss: 1582010247.9730\n",
      "Epoch 2842/10000\n",
      "3554/3554 [==============================] - 0s 135us/step - loss: 464736857.8593 - val_loss: 1170126428.3544\n",
      "Epoch 2843/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 1820894266.4536 - val_loss: 5670407593.8745\n",
      "Epoch 2844/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 851439630.5864 - val_loss: 1625660701.9027\n",
      "Epoch 2845/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 408865565.6860 - val_loss: 1538112163.5331\n",
      "Epoch 2846/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 442753857.9088 - val_loss: 3925168099.2675\n",
      "Epoch 2847/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 725920042.1609 - val_loss: 1930189370.1851\n",
      "Epoch 2848/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 730899265.5487 - val_loss: 5763146387.3350\n",
      "Epoch 2849/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 938340217.6792 - val_loss: 1787660272.4096\n",
      "Epoch 2850/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 612482628.5740 - val_loss: 4572639199.5229\n",
      "Epoch 2851/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 764558991.6308 - val_loss: 3950486490.0861\n",
      "Epoch 2852/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 1001369938.4761 - val_loss: 1731725306.8872\n",
      "Epoch 2853/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 1587073958.7389 - val_loss: 1859255017.1364\n",
      "Epoch 2854/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 474408802.9713 - val_loss: 1215185964.1429\n",
      "Epoch 2855/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 555117777.7017 - val_loss: 1500485693.0655\n",
      "Epoch 2856/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 325533069.7085 - val_loss: 1223756793.1229\n",
      "Epoch 2857/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 606245663.1536 - val_loss: 2269508672.7381\n",
      "Epoch 2858/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 488769582.6764 - val_loss: 1880899800.4748\n",
      "Epoch 2859/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 773628225.5127 - val_loss: 1843220506.8579\n",
      "Epoch 2860/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 667709569.2583 - val_loss: 1316037510.8771\n",
      "Epoch 2861/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 494799581.2088 - val_loss: 3324016881.9578\n",
      "Epoch 2862/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 1107207604.6235 - val_loss: 1610071324.5345\n",
      "Epoch 2863/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 693676312.1666 - val_loss: 1790276379.5803\n",
      "Epoch 2864/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 487188001.3866 - val_loss: 1743595475.7671\n",
      "Epoch 2865/10000\n",
      "3554/3554 [==============================] - 0s 132us/step - loss: 801463721.7603 - val_loss: 5308734834.8084\n",
      "Epoch 2866/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 1045143581.1367 - val_loss: 2566418582.6475\n",
      "Epoch 2867/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 498936462.3683 - val_loss: 1526503271.6084\n",
      "Epoch 2868/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 419155327.8559 - val_loss: 1880154903.0796\n",
      "Epoch 2869/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 966463178.6337 - val_loss: 1418873692.5165\n",
      "Epoch 2870/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 768691685.2763 - val_loss: 1903661371.6973\n",
      "Epoch 2871/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 626557481.8233 - val_loss: 3078682524.1564\n",
      "Epoch 2872/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 710521157.7985 - val_loss: 4264771871.3969\n",
      "Epoch 2873/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 842821599.2617 - val_loss: 3838696416.3871\n",
      "Epoch 2874/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 671301412.4890 - val_loss: 3858303817.9286\n",
      "Epoch 2875/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 533375139.7997 - val_loss: 1320250572.7820\n",
      "Epoch 2876/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 673056173.8841 - val_loss: 4227021863.7502\n",
      "Epoch 2877/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1825652152.8329 - val_loss: 2211570907.1482\n",
      "Epoch 2878/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 558409058.9353 - val_loss: 4117598632.4163\n",
      "Epoch 2879/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 1773494694.0743 - val_loss: 1491365798.5980\n",
      "Epoch 2880/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 427437643.3450 - val_loss: 1668280128.7741\n",
      "Epoch 2881/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 371292137.2786 - val_loss: 1285957848.8979\n",
      "Epoch 2882/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 368438111.2257 - val_loss: 1739407349.4143\n",
      "Epoch 2883/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 734669210.5796 - val_loss: 2269404767.5949\n",
      "Epoch 2884/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 726689895.8694 - val_loss: 1906167667.5195\n",
      "Epoch 2885/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 369100785.1435 - val_loss: 2829974206.6138\n",
      "Epoch 2886/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 463692129.4136 - val_loss: 1940679515.9404\n",
      "Epoch 2887/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 618433372.8126 - val_loss: 1307877685.9364\n",
      "Epoch 2888/10000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 565022271.3877 - val_loss: 3968046032.6166\n",
      "Epoch 2889/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 1109151331.6376 - val_loss: 2094589427.2900\n",
      "Epoch 2890/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 572474325.2133 - val_loss: 2136210486.8726\n",
      "Epoch 2891/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 1154481657.1764 - val_loss: 1710045060.1406\n",
      "Epoch 2892/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 393344508.5065 - val_loss: 1626004617.7035\n",
      "Epoch 2893/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 490006371.6781 - val_loss: 1449158385.9578\n",
      "Epoch 2894/10000\n",
      "3554/3554 [==============================] - 1s 143us/step - loss: 655740240.4502 - val_loss: 3042979852.7685\n",
      "Epoch 2895/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 942215161.2290 - val_loss: 2188307194.7792\n",
      "Epoch 2896/10000\n",
      "3554/3554 [==============================] - 0s 130us/step - loss: 722834807.2842 - val_loss: 1306445860.9778\n",
      "Epoch 2897/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 550407093.2673 - val_loss: 1625738602.6487\n",
      "Epoch 2898/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 479027900.8801 - val_loss: 1537830330.6532\n",
      "Epoch 2899/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 516037300.8711 - val_loss: 2327814111.7255\n",
      "Epoch 2900/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 638760057.3731 - val_loss: 1548914552.4928\n",
      "Epoch 2901/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 666700637.1030 - val_loss: 1344022482.1468\n",
      "Epoch 2902/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 618421715.6286 - val_loss: 1927041849.2084\n",
      "Epoch 2903/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 643553914.1654 - val_loss: 5150047270.0940\n",
      "Epoch 2904/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1447609765.2043 - val_loss: 1785995474.5609\n",
      "Epoch 2905/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 425084841.3877 - val_loss: 1499762324.5592\n",
      "Epoch 2906/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 578378853.9246 - val_loss: 1561606116.5547\n",
      "Epoch 2907/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 580090805.2133 - val_loss: 2338647843.3935\n",
      "Epoch 2908/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1030301336.2960 - val_loss: 1551539175.2281\n",
      "Epoch 2909/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 740542408.9319 - val_loss: 1584632623.1674\n",
      "Epoch 2910/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 390387226.7237 - val_loss: 2342239735.1516\n",
      "Epoch 2911/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 727807627.0298 - val_loss: 4923952276.8473\n",
      "Epoch 2912/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 755561062.8610 - val_loss: 7822153242.6442\n",
      "Epoch 2913/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 3604749396.7181 - val_loss: 1669527560.6954\n",
      "Epoch 2914/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 544000490.0304 - val_loss: 1344444678.8501\n",
      "Epoch 2915/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 375903777.9268 - val_loss: 1436909896.4613\n",
      "Epoch 2916/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 603942828.0023 - val_loss: 1181575393.3952\n",
      "Epoch 2917/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 425241306.2555 - val_loss: 6831968978.4169\n",
      "Epoch 2918/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 1559692123.3720 - val_loss: 1297413379.2956\n",
      "Epoch 2919/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 511160266.5886 - val_loss: 1688104151.0661\n",
      "Epoch 2920/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 722455475.8312 - val_loss: 1204101710.0332\n",
      "Epoch 2921/10000\n",
      "3554/3554 [==============================] - 0s 140us/step - loss: 545083780.6100 - val_loss: 2376598104.4388\n",
      "Epoch 2922/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 561717159.8424 - val_loss: 1839517038.3932\n",
      "Epoch 2923/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 364760817.1255 - val_loss: 1301343434.7927\n",
      "Epoch 2924/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 405989179.4980 - val_loss: 1982127377.2107\n",
      "Epoch 2925/10000\n",
      "3554/3554 [==============================] - 1s 164us/step - loss: 483256603.5521 - val_loss: 1645365838.9603\n",
      "Epoch 2926/10000\n",
      "3554/3554 [==============================] - 0s 135us/step - loss: 991240039.1851 - val_loss: 1635985992.9474\n",
      "Epoch 2927/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 449324221.3708 - val_loss: 1986443035.3643\n",
      "Epoch 2928/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 2149210801.4857 - val_loss: 2671023326.3707\n",
      "Epoch 2929/10000\n",
      "3554/3554 [==============================] - 1s 141us/step - loss: 659969366.6359 - val_loss: 1124733732.3837\n",
      "Epoch 2930/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 323895312.8599 - val_loss: 1243107175.5882\n",
      "Epoch 2931/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 373877990.2172 - val_loss: 1366731075.1055\n",
      "Epoch 2932/10000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 719276847.8379 - val_loss: 1335833397.1803\n",
      "Epoch 2933/10000\n",
      "3554/3554 [==============================] - 1s 148us/step - loss: 437743912.2949 - val_loss: 2884495622.6250\n",
      "Epoch 2934/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 408326937.8773 - val_loss: 1386516751.9865\n",
      "Epoch 2935/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 746056142.3253 - val_loss: 2539556731.3373\n",
      "Epoch 2936/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 1183537219.4575 - val_loss: 4006672186.9052\n",
      "Epoch 2937/10000\n",
      "3554/3554 [==============================] - 0s 130us/step - loss: 755497708.8751 - val_loss: 1190420184.0968\n",
      "Epoch 2938/10000\n",
      "3554/3554 [==============================] - 1s 176us/step - loss: 367456198.7552 - val_loss: 1511883321.4650\n",
      "Epoch 2939/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 453009278.5954 - val_loss: 1684143111.3902\n",
      "Epoch 2940/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 570786763.2549 - val_loss: 1396418757.3828\n",
      "Epoch 2941/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 740077620.5470 - val_loss: 1682600233.8385\n",
      "Epoch 2942/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 519494615.7344 - val_loss: 1848250686.1457\n",
      "Epoch 2943/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 495922867.6286 - val_loss: 1341164435.5331\n",
      "Epoch 2944/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 1863345391.8469 - val_loss: 6592934881.0352\n",
      "Epoch 2945/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1024781567.6038 - val_loss: 2827914959.5004\n",
      "Epoch 2946/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 802846386.4221 - val_loss: 1372756294.1030\n",
      "Epoch 2947/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 547112915.2864 - val_loss: 1553710235.4183\n",
      "Epoch 2948/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 107us/step - loss: 462487116.2183 - val_loss: 1551271357.4616\n",
      "Epoch 2949/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 341743977.5892 - val_loss: 1225382212.2667\n",
      "Epoch 2950/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 609016883.2684 - val_loss: 1919698940.6560\n",
      "Epoch 2951/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 837492767.4778 - val_loss: 5958552420.9598\n",
      "Epoch 2952/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 3307358328.9769 - val_loss: 3784801122.1513\n",
      "Epoch 2953/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 680264855.8424 - val_loss: 2701507017.5325\n",
      "Epoch 2954/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 386551577.5712 - val_loss: 1273862432.3376\n",
      "Epoch 2955/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 527426566.1587 - val_loss: 1385309554.4259\n",
      "Epoch 2956/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 476208706.1249 - val_loss: 1756975093.4143\n",
      "Epoch 2957/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 470645641.1030 - val_loss: 1263498300.4422\n",
      "Epoch 2958/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 402550153.6162 - val_loss: 1997089349.8509\n",
      "Epoch 2959/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1542054076.4246 - val_loss: 1306837809.5797\n",
      "Epoch 2960/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 441261183.7479 - val_loss: 1522551015.0841\n",
      "Epoch 2961/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 405296892.3624 - val_loss: 2974027758.5733\n",
      "Epoch 2962/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 382317593.9956 - val_loss: 1424257912.1508\n",
      "Epoch 2963/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 314725474.4941 - val_loss: 1451389748.5862\n",
      "Epoch 2964/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 934059791.5228 - val_loss: 1277097638.2515\n",
      "Epoch 2965/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 514854920.5627 - val_loss: 1311812508.8045\n",
      "Epoch 2966/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 514836207.0726 - val_loss: 3248533714.9570\n",
      "Epoch 2967/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1673356764.2183 - val_loss: 2046358467.2585\n",
      "Epoch 2968/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1991449729.4766 - val_loss: 1558668295.1291\n",
      "Epoch 2969/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 356763549.6770 - val_loss: 1135893811.9921\n",
      "Epoch 2970/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 305093952.1306 - val_loss: 2062170833.8813\n",
      "Epoch 2971/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 547744017.2876 - val_loss: 1988284082.4439\n",
      "Epoch 2972/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 440485301.8436 - val_loss: 2592477697.4762\n",
      "Epoch 2973/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 582122306.2870 - val_loss: 3384256300.9350\n",
      "Epoch 2974/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 685967172.2859 - val_loss: 2785654875.6703\n",
      "Epoch 2975/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 407228865.5003 - val_loss: 1764007809.6203\n",
      "Epoch 2976/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 430425350.6989 - val_loss: 9338364412.4354\n",
      "Epoch 2977/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 2814992131.0974 - val_loss: 3961170505.8115\n",
      "Epoch 2978/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1754233430.5549 - val_loss: 1525977839.6759\n",
      "Epoch 2979/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 334816085.3033 - val_loss: 1487583866.3291\n",
      "Epoch 2980/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 340504261.8571 - val_loss: 1153243362.1873\n",
      "Epoch 2981/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 396245246.1092 - val_loss: 1488085447.0751\n",
      "Epoch 2982/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 874125042.7372 - val_loss: 2352671788.4309\n",
      "Epoch 2983/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 395463613.0197 - val_loss: 1563684583.1921\n",
      "Epoch 2984/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 487884357.9066 - val_loss: 2668664459.4768\n",
      "Epoch 2985/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 454919402.8858 - val_loss: 1960346758.2290\n",
      "Epoch 2986/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 377557542.5369 - val_loss: 1302071803.1617\n",
      "Epoch 2987/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 598867860.3939 - val_loss: 1669481363.1190\n",
      "Epoch 2988/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 459895408.3976 - val_loss: 1554002592.2250\n",
      "Epoch 2989/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 375666858.7147 - val_loss: 3862215639.2326\n",
      "Epoch 2990/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2087354508.3174 - val_loss: 2331989265.5302\n",
      "Epoch 2991/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 907277078.4558 - val_loss: 1254623051.1617\n",
      "Epoch 2992/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 422658262.4378 - val_loss: 1567196301.5561\n",
      "Epoch 2993/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 722437256.2071 - val_loss: 1444323099.6163\n",
      "Epoch 2994/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 347140337.5937 - val_loss: 2222671796.3702\n",
      "Epoch 2995/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 536172051.7006 - val_loss: 2998512725.2613\n",
      "Epoch 2996/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 732058058.7147 - val_loss: 1410216671.9010\n",
      "Epoch 2997/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 393518491.1201 - val_loss: 1116896620.5570\n",
      "Epoch 2998/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 408792514.1249 - val_loss: 1363238650.6892\n",
      "Epoch 2999/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 1314228907.2684 - val_loss: 1170897450.7387\n",
      "Epoch 3000/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 366857565.4879 - val_loss: 1159968097.0667\n",
      "Epoch 3001/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 405840437.0602 - val_loss: 1294915883.7108\n",
      "Epoch 3002/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 562739881.0580 - val_loss: 1453553074.2278\n",
      "Epoch 3003/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 653130489.6792 - val_loss: 4434203430.5980\n",
      "Epoch 3004/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 768576687.0186 - val_loss: 1390066984.6864\n",
      "Epoch 3005/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 509957937.6657 - val_loss: 2256321568.6211\n",
      "Epoch 3006/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 615488080.5492 - val_loss: 1873764584.3803\n",
      "Epoch 3007/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1190862170.9758 - val_loss: 2531010185.6135\n",
      "Epoch 3008/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1285278555.9527 - val_loss: 1601049929.0554\n",
      "Epoch 3009/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 640895350.5639 - val_loss: 1772512084.9913\n",
      "Epoch 3010/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 591729532.3264 - val_loss: 3026374229.9814\n",
      "Epoch 3011/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 674182945.8548 - val_loss: 5085760616.0563\n",
      "Epoch 3012/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 983307858.9758 - val_loss: 2477209415.5342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3013/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 597143671.1761 - val_loss: 1949739761.4627\n",
      "Epoch 3014/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 336523507.0163 - val_loss: 1243915175.0121\n",
      "Epoch 3015/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 357730155.8312 - val_loss: 1275572162.7904\n",
      "Epoch 3016/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 617756028.9026 - val_loss: 3985242222.4473\n",
      "Epoch 3017/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1738545994.3725 - val_loss: 1777254134.0895\n",
      "Epoch 3018/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 416150709.1683 - val_loss: 1367351216.3916\n",
      "Epoch 3019/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 338721592.5087 - val_loss: 1343765639.0031\n",
      "Epoch 3020/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 480915016.4007 - val_loss: 1226249109.5764\n",
      "Epoch 3021/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 425703283.6106 - val_loss: 1168758164.4692\n",
      "Epoch 3022/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 450116027.9842 - val_loss: 1430415540.1271\n",
      "Epoch 3023/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 486632101.9426 - val_loss: 1217129815.0706\n",
      "Epoch 3024/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 593880077.6140 - val_loss: 1284387459.2135\n",
      "Epoch 3025/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 561037354.9308 - val_loss: 5223538788.2037\n",
      "Epoch 3026/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 4980450216.6618 - val_loss: 1301873984.8191\n",
      "Epoch 3027/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 394506941.1007 - val_loss: 1221329114.9682\n",
      "Epoch 3028/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 354239421.6230 - val_loss: 1840747487.0459\n",
      "Epoch 3029/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 367841802.7147 - val_loss: 1136516973.5291\n",
      "Epoch 3030/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 267648561.8818 - val_loss: 1255940505.0779\n",
      "Epoch 3031/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 366920451.3855 - val_loss: 2062588106.3066\n",
      "Epoch 3032/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 389980083.1424 - val_loss: 1467229160.3803\n",
      "Epoch 3033/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 544117128.1249 - val_loss: 1803379765.7744\n",
      "Epoch 3034/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 662516747.0940 - val_loss: 1455649045.4053\n",
      "Epoch 3035/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 387937908.5830 - val_loss: 1780659024.5806\n",
      "Epoch 3036/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 548572640.1981 - val_loss: 1301034547.9921\n",
      "Epoch 3037/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 375130757.1075 - val_loss: 1229707399.7052\n",
      "Epoch 3038/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 690206599.4913 - val_loss: 1261177949.6056\n",
      "Epoch 3039/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 587898195.8807 - val_loss: 9242432270.3302\n",
      "Epoch 3040/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 2107919088.9274 - val_loss: 1151481122.4124\n",
      "Epoch 3041/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 608905339.1739 - val_loss: 5744688808.8664\n",
      "Epoch 3042/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 701145770.0577 - val_loss: 1518085481.1364\n",
      "Epoch 3043/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 349221479.4733 - val_loss: 1366362727.0481\n",
      "Epoch 3044/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 468515439.6398 - val_loss: 1855560214.2875\n",
      "Epoch 3045/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 572732401.8638 - val_loss: 1354517463.9617\n",
      "Epoch 3046/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 384430943.8379 - val_loss: 1795021755.9854\n",
      "Epoch 3047/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1048831013.7445 - val_loss: 1402500514.1333\n",
      "Epoch 3048/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 575033900.8036 - val_loss: 1333195003.0132\n",
      "Epoch 3049/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 639925887.9820 - val_loss: 1623067564.4669\n",
      "Epoch 3050/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 722426508.8936 - val_loss: 2560568970.4776\n",
      "Epoch 3051/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2170392886.1857 - val_loss: 3070594842.6442\n",
      "Epoch 3052/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 940362527.4057 - val_loss: 3464238252.7550\n",
      "Epoch 3053/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 3985963846.9510 - val_loss: 1347720497.0397\n",
      "Epoch 3054/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 353250206.5864 - val_loss: 1339888282.0321\n",
      "Epoch 3055/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 320633657.1030 - val_loss: 1661311158.1885\n",
      "Epoch 3056/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 366836104.4097 - val_loss: 1178875628.4850\n",
      "Epoch 3057/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 311505217.5127 - val_loss: 1341224323.3485\n",
      "Epoch 3058/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 331999121.9657 - val_loss: 1158899888.2790\n",
      "Epoch 3059/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 639245823.5498 - val_loss: 1382788272.0675\n",
      "Epoch 3060/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 388024236.0833 - val_loss: 3444328721.9668\n",
      "Epoch 3061/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 821262006.2847 - val_loss: 2222232251.7333\n",
      "Epoch 3062/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 478759377.2245 - val_loss: 1213263046.2380\n",
      "Epoch 3063/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 586209486.0822 - val_loss: 2703794340.3657\n",
      "Epoch 3064/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1723444877.4879 - val_loss: 1706874348.9170\n",
      "Epoch 3065/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 427306708.9026 - val_loss: 1181306929.7418\n",
      "Epoch 3066/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 284130358.5008 - val_loss: 1429899962.9052\n",
      "Epoch 3067/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 482211800.7023 - val_loss: 4629033394.6599\n",
      "Epoch 3068/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 719300187.3360 - val_loss: 5148582482.5429\n",
      "Epoch 3069/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 864781831.0951 - val_loss: 3416187508.2802\n",
      "Epoch 3070/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 855731539.4485 - val_loss: 1843900328.2903\n",
      "Epoch 3071/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 528231526.5369 - val_loss: 1450484679.6512\n",
      "Epoch 3072/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 685776914.7282 - val_loss: 3324934222.6723\n",
      "Epoch 3073/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 482898820.6640 - val_loss: 3160850581.9274\n",
      "Epoch 3074/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 875817954.8002 - val_loss: 1390337680.8326\n",
      "Epoch 3075/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 376307597.1548 - val_loss: 1233642694.8591\n",
      "Epoch 3076/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 464708812.9477 - val_loss: 1733121259.1617\n",
      "Epoch 3077/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 795515729.6117 - val_loss: 1438100536.7899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3078/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 650666290.4221 - val_loss: 1682607605.8824\n",
      "Epoch 3079/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 960509391.5768 - val_loss: 1187478291.7131\n",
      "Epoch 3080/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 647817264.3331 - val_loss: 1488842601.9826\n",
      "Epoch 3081/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 721487654.1767 - val_loss: 2008659136.6301\n",
      "Epoch 3082/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 417209122.8272 - val_loss: 2176644908.5750\n",
      "Epoch 3083/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 452709908.6010 - val_loss: 1465239036.7235\n",
      "Epoch 3084/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 585126872.2026 - val_loss: 5261712842.4956\n",
      "Epoch 3085/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 733392181.3754 - val_loss: 2102069248.0720\n",
      "Epoch 3086/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 638197644.8576 - val_loss: 2880136352.5086\n",
      "Epoch 3087/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 857257017.3236 - val_loss: 1932458287.4194\n",
      "Epoch 3088/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 741373618.4761 - val_loss: 1303732035.3350\n",
      "Epoch 3089/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 479172244.8452 - val_loss: 1625918363.7153\n",
      "Epoch 3090/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 367871949.6500 - val_loss: 3386878079.0008\n",
      "Epoch 3091/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 593768816.3512 - val_loss: 1313386954.6037\n",
      "Epoch 3092/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 571075225.7738 - val_loss: 1353872358.6790\n",
      "Epoch 3093/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1091738844.5965 - val_loss: 2891223979.9269\n",
      "Epoch 3094/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 533254926.4423 - val_loss: 2023148001.5212\n",
      "Epoch 3095/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 492705724.2364 - val_loss: 1570753797.9049\n",
      "Epoch 3096/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 995297001.6702 - val_loss: 3112050550.4900\n",
      "Epoch 3097/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 962175130.8678 - val_loss: 13263432373.6124\n",
      "Epoch 3098/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 3352126509.8120 - val_loss: 1440985546.4956\n",
      "Epoch 3099/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 702659820.9319 - val_loss: 1264299566.4653\n",
      "Epoch 3100/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 237014303.0186 - val_loss: 1123083598.6003\n",
      "Epoch 3101/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 214866018.9330 - val_loss: 1437748289.5302\n",
      "Epoch 3102/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 412274416.4007 - val_loss: 1352261342.8928\n",
      "Epoch 3103/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 446614320.1891 - val_loss: 1679771792.2025\n",
      "Epoch 3104/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 385150967.8965 - val_loss: 1579258954.2436\n",
      "Epoch 3105/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 940905440.9184 - val_loss: 4250759370.3516\n",
      "Epoch 3106/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 620263258.4896 - val_loss: 1130243647.8380\n",
      "Epoch 3107/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 529193134.1452 - val_loss: 1314077698.7364\n",
      "Epoch 3108/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 479829634.7822 - val_loss: 1291534966.7286\n",
      "Epoch 3109/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 468099424.5582 - val_loss: 1838438757.8059\n",
      "Epoch 3110/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 665800448.1801 - val_loss: 2026183378.5429\n",
      "Epoch 3111/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 764878362.9038 - val_loss: 2911774112.6571\n",
      "Epoch 3112/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 460717381.0242 - val_loss: 1462883400.8574\n",
      "Epoch 3113/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1572022392.5087 - val_loss: 1330002263.5297\n",
      "Epoch 3114/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 412951279.3967 - val_loss: 1268341025.9893\n",
      "Epoch 3115/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 336656843.1829 - val_loss: 1126400063.6759\n",
      "Epoch 3116/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 336946215.7254 - val_loss: 1677964724.5322\n",
      "Epoch 3117/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 490419014.0326 - val_loss: 1443598539.4318\n",
      "Epoch 3118/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 533532913.6657 - val_loss: 2974405783.6557\n",
      "Epoch 3119/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1659199770.2735 - val_loss: 2220531166.1817\n",
      "Epoch 3120/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 508162779.6961 - val_loss: 1777830585.6810\n",
      "Epoch 3121/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 564927610.7057 - val_loss: 1962391013.8599\n",
      "Epoch 3122/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 599571787.8492 - val_loss: 1427212000.9992\n",
      "Epoch 3123/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 954100358.6809 - val_loss: 1285491289.5100\n",
      "Epoch 3124/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 388504435.1199 - val_loss: 1228221755.4093\n",
      "Epoch 3125/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 394300254.8655 - val_loss: 1524004476.0034\n",
      "Epoch 3126/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 312117887.6308 - val_loss: 2296075008.4321\n",
      "Epoch 3127/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 377455208.9412 - val_loss: 1549366562.2143\n",
      "Epoch 3128/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 632800628.2679 - val_loss: 2355496113.3277\n",
      "Epoch 3129/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 756422814.6066 - val_loss: 1174578448.0765\n",
      "Epoch 3130/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 478753713.5397 - val_loss: 3113283241.9466\n",
      "Epoch 3131/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 944688919.6804 - val_loss: 1356484637.0925\n",
      "Epoch 3132/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 374407574.4378 - val_loss: 2272468274.3179\n",
      "Epoch 3133/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 693975225.6432 - val_loss: 1084938807.0706\n",
      "Epoch 3134/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 436283592.3557 - val_loss: 1355276183.0976\n",
      "Epoch 3135/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1083689890.1069 - val_loss: 2229674754.7724\n",
      "Epoch 3136/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 523514782.6854 - val_loss: 1458226182.8771\n",
      "Epoch 3137/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 545051409.1435 - val_loss: 6879171931.8143\n",
      "Epoch 3138/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 2339872334.8745 - val_loss: 2097524591.8335\n",
      "Epoch 3139/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 792380497.7558 - val_loss: 1198586556.1294\n",
      "Epoch 3140/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 299349901.8481 - val_loss: 1102570497.7913\n",
      "Epoch 3141/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 494868123.6151 - val_loss: 2054688291.2855\n",
      "Epoch 3142/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 412224691.5025 - val_loss: 2076878423.0256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3143/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 525146475.0884 - val_loss: 1263620817.0037\n",
      "Epoch 3144/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 303858946.4491 - val_loss: 1075267468.1699\n",
      "Epoch 3145/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 492384903.0636 - val_loss: 1586290073.6180\n",
      "Epoch 3146/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 953722431.1716 - val_loss: 1693157317.4549\n",
      "Epoch 3147/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 510293370.9308 - val_loss: 1834718808.9339\n",
      "Epoch 3148/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 331028415.7839 - val_loss: 3316873186.6194\n",
      "Epoch 3149/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 858219909.3844 - val_loss: 1429192856.3938\n",
      "Epoch 3150/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 683354186.3365 - val_loss: 3472207885.5381\n",
      "Epoch 3151/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1054651188.4569 - val_loss: 1835438870.5485\n",
      "Epoch 3152/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 562704533.2845 - val_loss: 1259870403.0785\n",
      "Epoch 3153/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 563165241.5622 - val_loss: 1224200155.9944\n",
      "Epoch 3154/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 414986546.4941 - val_loss: 1493259205.4188\n",
      "Epoch 3155/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 349135160.1553 - val_loss: 1295474611.6321\n",
      "Epoch 3156/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 386170334.6314 - val_loss: 1103906626.5204\n",
      "Epoch 3157/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 561572517.9606 - val_loss: 5154385000.9204\n",
      "Epoch 3158/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1875136890.2015 - val_loss: 2597020609.0622\n",
      "Epoch 3159/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 563276746.5886 - val_loss: 1180242219.5668\n",
      "Epoch 3160/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 567163126.5639 - val_loss: 1259728927.1359\n",
      "Epoch 3161/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 401466636.2904 - val_loss: 3043482347.4138\n",
      "Epoch 3162/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 569130817.8008 - val_loss: 1373434193.1567\n",
      "Epoch 3163/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 309472795.0838 - val_loss: 1230600584.3173\n",
      "Epoch 3164/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 358582149.5464 - val_loss: 1246461664.3241\n",
      "Epoch 3165/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 847493468.3804 - val_loss: 2822172574.4968\n",
      "Epoch 3166/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1101139185.7378 - val_loss: 1447318494.0467\n",
      "Epoch 3167/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 348723475.4305 - val_loss: 1061785384.9744\n",
      "Epoch 3168/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 456913289.1120 - val_loss: 1521962497.6023\n",
      "Epoch 3169/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 579042425.9133 - val_loss: 1782287909.0408\n",
      "Epoch 3170/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 874925706.1204 - val_loss: 1879123041.6833\n",
      "Epoch 3171/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 483631628.1733 - val_loss: 1242689029.9769\n",
      "Epoch 3172/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 595620448.2116 - val_loss: 1696375439.6534\n",
      "Epoch 3173/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1241990664.6438 - val_loss: 1712810936.2768\n",
      "Epoch 3174/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 870972262.9690 - val_loss: 1152304265.7935\n",
      "Epoch 3175/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 409194961.1165 - val_loss: 2158637943.7907\n",
      "Epoch 3176/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 4774005949.7310 - val_loss: 10470598784.0360\n",
      "Epoch 3177/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 3486278512.1947 - val_loss: 2020369384.5243\n",
      "Epoch 3178/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 398423174.2127 - val_loss: 1456810574.6723\n",
      "Epoch 3179/10000\n",
      "3554/3554 [==============================] - 0s 130us/step - loss: 323066322.6201 - val_loss: 1114040234.5226\n",
      "Epoch 3180/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 221675748.5898 - val_loss: 1389974090.1041\n",
      "Epoch 3181/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 311830961.1975 - val_loss: 1395779835.1032\n",
      "Epoch 3182/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 319595162.7957 - val_loss: 1475691313.1117\n",
      "Epoch 3183/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 264104981.5554 - val_loss: 1138755632.0135\n",
      "Epoch 3184/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 306976646.5976 - val_loss: 3494960760.6549\n",
      "Epoch 3185/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 619774955.7681 - val_loss: 1150537412.3027\n",
      "Epoch 3186/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 330102139.9122 - val_loss: 1233432248.7809\n",
      "Epoch 3187/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 299810144.7923 - val_loss: 1376716048.8146\n",
      "Epoch 3188/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 407855858.3500 - val_loss: 1135286658.1603\n",
      "Epoch 3189/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 377388119.3067 - val_loss: 1984922872.2588\n",
      "Epoch 3190/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 422021853.4609 - val_loss: 2390565090.7634\n",
      "Epoch 3191/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 721310818.9713 - val_loss: 1273434301.7496\n",
      "Epoch 3192/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 770286769.6657 - val_loss: 1434296993.1342\n",
      "Epoch 3193/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 779899946.9308 - val_loss: 2173775293.1015\n",
      "Epoch 3194/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 491080163.4395 - val_loss: 1240832369.2647\n",
      "Epoch 3195/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 815499917.9741 - val_loss: 1679396476.7955\n",
      "Epoch 3196/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 743710177.1795 - val_loss: 1128823064.1778\n",
      "Epoch 3197/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 431865924.9814 - val_loss: 1188920785.5887\n",
      "Epoch 3198/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 404786621.2628 - val_loss: 2654132609.1432\n",
      "Epoch 3199/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 918802603.2189 - val_loss: 1684310345.2354\n",
      "Epoch 3200/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 354996444.2780 - val_loss: 1947497080.5648\n",
      "Epoch 3201/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 545606185.2380 - val_loss: 2326458635.0177\n",
      "Epoch 3202/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 604649241.7918 - val_loss: 1428180359.3451\n",
      "Epoch 3203/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 496787901.6860 - val_loss: 1696884036.4827\n",
      "Epoch 3204/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 400239447.6263 - val_loss: 2196679114.3516\n",
      "Epoch 3205/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 462852222.2352 - val_loss: 1519961079.7367\n",
      "Epoch 3206/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1347239368.2476 - val_loss: 1708650734.9333\n",
      "Epoch 3207/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 725017812.4615 - val_loss: 2370679174.4450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3208/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1664735210.4986 - val_loss: 1777281946.8962\n",
      "Epoch 3209/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 520200027.0838 - val_loss: 1526518678.9536\n",
      "Epoch 3210/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 603258531.6556 - val_loss: 2815929503.8650\n",
      "Epoch 3211/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1574120078.1992 - val_loss: 1937558502.1480\n",
      "Epoch 3212/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 375762113.1615 - val_loss: 1111005565.4436\n",
      "Epoch 3213/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 366387725.2448 - val_loss: 1498978671.8335\n",
      "Epoch 3214/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 335448697.2290 - val_loss: 1180414741.0633\n",
      "Epoch 3215/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 318921938.9803 - val_loss: 1202769518.0692\n",
      "Epoch 3216/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 727636476.3624 - val_loss: 1247440057.2309\n",
      "Epoch 3217/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 431631467.5160 - val_loss: 1270428088.7809\n",
      "Epoch 3218/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 339824103.4553 - val_loss: 1323430990.6723\n",
      "Epoch 3219/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 303625355.5971 - val_loss: 1518501656.6459\n",
      "Epoch 3220/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 965172521.5262 - val_loss: 2125970238.1457\n",
      "Epoch 3221/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 932574274.3050 - val_loss: 1218931302.0219\n",
      "Epoch 3222/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 537682398.4333 - val_loss: 1887843595.9179\n",
      "Epoch 3223/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 640799676.2183 - val_loss: 2090408668.1024\n",
      "Epoch 3224/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 912831898.1745 - val_loss: 1682088773.0588\n",
      "Epoch 3225/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 476518858.3725 - val_loss: 2332295033.3210\n",
      "Epoch 3226/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 410399144.7878 - val_loss: 1674728633.5910\n",
      "Epoch 3227/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 574952522.9668 - val_loss: 1204476661.2793\n",
      "Epoch 3228/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 548283121.1975 - val_loss: 1826381654.5215\n",
      "Epoch 3229/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1303384439.2257 - val_loss: 2322870755.2585\n",
      "Epoch 3230/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1194066281.9088 - val_loss: 1764986303.4239\n",
      "Epoch 3231/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 338367688.0405 - val_loss: 2536851278.2402\n",
      "Epoch 3232/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 671835155.3270 - val_loss: 1108832942.8613\n",
      "Epoch 3233/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 415714477.0653 - val_loss: 2159925699.3305\n",
      "Epoch 3234/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 622342148.3939 - val_loss: 2237443308.5030\n",
      "Epoch 3235/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 492724790.9285 - val_loss: 1981709173.3243\n",
      "Epoch 3236/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1064616361.2741 - val_loss: 1350510349.7722\n",
      "Epoch 3237/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 799151040.7563 - val_loss: 1281019613.2906\n",
      "Epoch 3238/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 776421532.3804 - val_loss: 3716951195.9764\n",
      "Epoch 3239/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 961225384.7878 - val_loss: 1147397954.4844\n",
      "Epoch 3240/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 292990644.3264 - val_loss: 1460323802.7882\n",
      "Epoch 3241/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 414553808.6393 - val_loss: 1468115654.5710\n",
      "Epoch 3242/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 396606343.0951 - val_loss: 1151446823.8762\n",
      "Epoch 3243/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 484743706.0034 - val_loss: 1456018002.2008\n",
      "Epoch 3244/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 1286168289.0264 - val_loss: 2725134425.9421\n",
      "Epoch 3245/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1476192685.0917 - val_loss: 1550316222.2537\n",
      "Epoch 3246/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 486163516.1598 - val_loss: 1110714435.7266\n",
      "Epoch 3247/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 293622680.3692 - val_loss: 1071597607.9482\n",
      "Epoch 3248/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 407489883.1019 - val_loss: 1223613691.2653\n",
      "Epoch 3249/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 566482415.2347 - val_loss: 1082101382.8771\n",
      "Epoch 3250/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 355031799.6083 - val_loss: 1433124557.4121\n",
      "Epoch 3251/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 680373106.3838 - val_loss: 1423610841.1139\n",
      "Epoch 3252/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 814371334.8610 - val_loss: 1245943655.1741\n",
      "Epoch 3253/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 436351089.7378 - val_loss: 1349629803.9179\n",
      "Epoch 3254/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 933860681.8784 - val_loss: 4919801130.3426\n",
      "Epoch 3255/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 1007617204.1261 - val_loss: 1122064575.1899\n",
      "Epoch 3256/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 434660095.7749 - val_loss: 3070802613.0363\n",
      "Epoch 3257/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1410588924.8801 - val_loss: 1283095258.3021\n",
      "Epoch 3258/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 304287394.2757 - val_loss: 1487052218.7252\n",
      "Epoch 3259/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 492738342.2037 - val_loss: 1630314865.3502\n",
      "Epoch 3260/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 546498529.9088 - val_loss: 2371511924.1722\n",
      "Epoch 3261/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 1367941054.7394 - val_loss: 2593194394.7162\n",
      "Epoch 3262/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 2818492516.5200 - val_loss: 5138794508.6020\n",
      "Epoch 3263/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 802355242.2825 - val_loss: 1455687062.9356\n",
      "Epoch 3264/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 402178907.3360 - val_loss: 1400469747.9561\n",
      "Epoch 3265/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 297755556.5560 - val_loss: 1777255309.3131\n",
      "Epoch 3266/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 352209357.0760 - val_loss: 1097120825.6990\n",
      "Epoch 3267/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 395957710.9105 - val_loss: 1868042280.3263\n",
      "Epoch 3268/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 425457110.3298 - val_loss: 1112418547.2540\n",
      "Epoch 3269/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 268578294.7980 - val_loss: 1273170483.0560\n",
      "Epoch 3270/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 408101549.1660 - val_loss: 1393613537.7913\n",
      "Epoch 3271/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 531531347.8807 - val_loss: 1363421282.0703\n",
      "Epoch 3272/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 413563122.7102 - val_loss: 1685341237.4774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3273/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 519112330.4986 - val_loss: 1297243632.1215\n",
      "Epoch 3274/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 353908554.7687 - val_loss: 1302280012.0529\n",
      "Epoch 3275/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 571128976.9094 - val_loss: 1182749780.2532\n",
      "Epoch 3276/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 339874246.8160 - val_loss: 2188928982.3055\n",
      "Epoch 3277/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 864788264.5898 - val_loss: 1351419273.0734\n",
      "Epoch 3278/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 506616867.2898 - val_loss: 1085457160.4253\n",
      "Epoch 3279/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1316589269.5734 - val_loss: 8291951511.4397\n",
      "Epoch 3280/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1130728449.5127 - val_loss: 1159831267.5736\n",
      "Epoch 3281/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 422252058.0754 - val_loss: 3085884070.1030\n",
      "Epoch 3282/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 790342958.8700 - val_loss: 3562384092.2104\n",
      "Epoch 3283/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 521672277.5194 - val_loss: 2291879526.1120\n",
      "Epoch 3284/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 536781569.9088 - val_loss: 1111816209.3907\n",
      "Epoch 3285/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 367313655.3202 - val_loss: 1259995894.9266\n",
      "Epoch 3286/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 312759134.0642 - val_loss: 1082657543.6512\n",
      "Epoch 3287/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 351871305.2921 - val_loss: 1832556539.3868\n",
      "Epoch 3288/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1108776520.9686 - val_loss: 1699757182.3257\n",
      "Epoch 3289/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 851232127.2752 - val_loss: 1049554968.3308\n",
      "Epoch 3290/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1066851083.5070 - val_loss: 1913528100.9778\n",
      "Epoch 3291/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1494328230.1294 - val_loss: 1121867938.0973\n",
      "Epoch 3292/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 428676511.4147 - val_loss: 1017147683.2585\n",
      "Epoch 3293/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 253292657.3596 - val_loss: 1823897446.3460\n",
      "Epoch 3294/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 333714241.7738 - val_loss: 1841483553.4852\n",
      "Epoch 3295/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 433236898.3590 - val_loss: 1128608068.3387\n",
      "Epoch 3296/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 429347282.6652 - val_loss: 1122529467.7783\n",
      "Epoch 3297/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 411926086.5549 - val_loss: 1119183603.9021\n",
      "Epoch 3298/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 505077550.7485 - val_loss: 1392077522.5429\n",
      "Epoch 3299/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 484775893.8616 - val_loss: 1284362898.9930\n",
      "Epoch 3300/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 554856689.5217 - val_loss: 1866388629.5404\n",
      "Epoch 3301/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 596337636.4119 - val_loss: 1249538345.9646\n",
      "Epoch 3302/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 431992814.1092 - val_loss: 1242766118.3955\n",
      "Epoch 3303/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 496758417.8998 - val_loss: 1722710890.8805\n",
      "Epoch 3304/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 654440256.5222 - val_loss: 1412382909.0925\n",
      "Epoch 3305/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1191674765.9921 - val_loss: 1360359803.1032\n",
      "Epoch 3306/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1916696976.0990 - val_loss: 1498889382.9671\n",
      "Epoch 3307/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 380802251.8312 - val_loss: 1394282913.2332\n",
      "Epoch 3308/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 310715335.5408 - val_loss: 1541341749.6844\n",
      "Epoch 3309/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 792405367.2122 - val_loss: 1210450180.7527\n",
      "Epoch 3310/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 476519865.3371 - val_loss: 5089989670.3820\n",
      "Epoch 3311/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1362538081.6207 - val_loss: 3924570506.3336\n",
      "Epoch 3312/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1048466766.5684 - val_loss: 1459970717.2006\n",
      "Epoch 3313/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 546824652.3444 - val_loss: 1535039785.7575\n",
      "Epoch 3314/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 417812918.2217 - val_loss: 1673266360.4928\n",
      "Epoch 3315/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 329802987.5431 - val_loss: 1093391321.9871\n",
      "Epoch 3316/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 598898051.6196 - val_loss: 2773950991.4104\n",
      "Epoch 3317/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 824065321.6342 - val_loss: 1483293151.6850\n",
      "Epoch 3318/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 510076268.4074 - val_loss: 1377353051.6883\n",
      "Epoch 3319/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 455662499.4395 - val_loss: 3833658667.9989\n",
      "Epoch 3320/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 810563476.9207 - val_loss: 1320370558.8208\n",
      "Epoch 3321/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 986351185.3956 - val_loss: 1915122705.3367\n",
      "Epoch 3322/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1198175040.7023 - val_loss: 1250121090.6824\n",
      "Epoch 3323/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 296539325.6950 - val_loss: 1297849347.0335\n",
      "Epoch 3324/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1068386651.2999 - val_loss: 8705273842.3719\n",
      "Epoch 3325/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 2454871151.3967 - val_loss: 1553681771.7648\n",
      "Epoch 3326/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 480983854.6944 - val_loss: 1528591240.2453\n",
      "Epoch 3327/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 260893488.6798 - val_loss: 1357556712.2903\n",
      "Epoch 3328/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 287260375.2662 - val_loss: 1076979580.3634\n",
      "Epoch 3329/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 333293693.4699 - val_loss: 1112062092.8900\n",
      "Epoch 3330/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 313621244.9927 - val_loss: 1118148911.4104\n",
      "Epoch 3331/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 334212041.6882 - val_loss: 1188031201.6023\n",
      "Epoch 3332/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1444997944.7608 - val_loss: 1851680483.7356\n",
      "Epoch 3333/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 707667797.4789 - val_loss: 1368966796.7100\n",
      "Epoch 3334/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 481704605.1007 - val_loss: 1176229585.9578\n",
      "Epoch 3335/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 288970151.5183 - val_loss: 1290171185.2917\n",
      "Epoch 3336/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 350068974.5971 - val_loss: 1180969689.3660\n",
      "Epoch 3337/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 541993289.4541 - val_loss: 1899239452.9035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3338/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 297497211.7862 - val_loss: 1304334516.1722\n",
      "Epoch 3339/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1000170195.9887 - val_loss: 2914847251.6591\n",
      "Epoch 3340/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 740276633.2831 - val_loss: 1062479153.1297\n",
      "Epoch 3341/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 243969447.7029 - val_loss: 1202063390.5688\n",
      "Epoch 3342/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 674347414.6584 - val_loss: 1122036544.4636\n",
      "Epoch 3343/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 274573637.6545 - val_loss: 1088836852.9823\n",
      "Epoch 3344/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 309394350.5076 - val_loss: 2031653173.2883\n",
      "Epoch 3345/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 649973480.0315 - val_loss: 3121160992.8371\n",
      "Epoch 3346/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1082866901.9786 - val_loss: 1459241867.9539\n",
      "Epoch 3347/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 796512898.6652 - val_loss: 1877881806.2672\n",
      "Epoch 3348/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 498274454.2577 - val_loss: 1913112848.8866\n",
      "Epoch 3349/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 717100075.7952 - val_loss: 3522989914.7342\n",
      "Epoch 3350/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 2267346121.6882 - val_loss: 5112843912.2453\n",
      "Epoch 3351/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2066922465.8008 - val_loss: 1395153285.2208\n",
      "Epoch 3352/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 327054408.1576 - val_loss: 1106150710.5845\n",
      "Epoch 3353/10000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 289496460.7676 - val_loss: 1271339685.4098\n",
      "Epoch 3354/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 421304554.3331 - val_loss: 1120733301.6754\n",
      "Epoch 3355/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 279124402.2893 - val_loss: 2487723377.9128\n",
      "Epoch 3356/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 457238682.5661 - val_loss: 1012203037.5966\n",
      "Epoch 3357/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 371757736.7338 - val_loss: 1311522399.7750\n",
      "Epoch 3358/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 622543397.0062 - val_loss: 1082703314.0433\n",
      "Epoch 3359/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 280270086.2217 - val_loss: 1009955139.6186\n",
      "Epoch 3360/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 522600870.5189 - val_loss: 2911997622.7196\n",
      "Epoch 3361/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 524580079.6218 - val_loss: 1087485017.9421\n",
      "Epoch 3362/10000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 347581424.8284 - val_loss: 1995949513.1454\n",
      "Epoch 3363/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 535096922.4896 - val_loss: 3208844497.4492\n",
      "Epoch 3364/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 850779600.5312 - val_loss: 1458783698.3449\n",
      "Epoch 3365/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 580083540.4209 - val_loss: 2187911724.7190\n",
      "Epoch 3366/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 884975013.0152 - val_loss: 1214987280.9226\n",
      "Epoch 3367/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 563103779.9077 - val_loss: 1156654144.7561\n",
      "Epoch 3368/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 801059835.9662 - val_loss: 1422726867.4970\n",
      "Epoch 3369/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 812651315.2504 - val_loss: 2713625973.7564\n",
      "Epoch 3370/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 425004889.5172 - val_loss: 1172270864.5266\n",
      "Epoch 3371/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 436154076.5605 - val_loss: 3965674538.8827\n",
      "Epoch 3372/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 1273039025.0535 - val_loss: 2335998179.8076\n",
      "Epoch 3373/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 2159047008.4795 - val_loss: 1489649287.1561\n",
      "Epoch 3374/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 404117026.7912 - val_loss: 1373685541.4819\n",
      "Epoch 3375/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 303905163.7681 - val_loss: 1053366376.3983\n",
      "Epoch 3376/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 310492240.7833 - val_loss: 1288142472.7854\n",
      "Epoch 3377/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 301977184.3962 - val_loss: 1253258410.0366\n",
      "Epoch 3378/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 430252484.0698 - val_loss: 1470594842.1221\n",
      "Epoch 3379/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 413115621.2043 - val_loss: 2715323101.8352\n",
      "Epoch 3380/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 620386317.0872 - val_loss: 1108753912.7809\n",
      "Epoch 3381/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 506925716.4029 - val_loss: 1106337627.2203\n",
      "Epoch 3382/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 478332541.3033 - val_loss: 1138652554.3516\n",
      "Epoch 3383/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 381727276.2273 - val_loss: 1702737979.8414\n",
      "Epoch 3384/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1422079709.3708 - val_loss: 2583633666.8805\n",
      "Epoch 3385/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 386597618.1339 - val_loss: 2574747245.7271\n",
      "Epoch 3386/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1005846236.7046 - val_loss: 1291912177.1477\n",
      "Epoch 3387/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 301665292.6775 - val_loss: 1431032831.4149\n",
      "Epoch 3388/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2262163706.0214 - val_loss: 3864660190.3347\n",
      "Epoch 3389/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1189848362.7147 - val_loss: 1187168772.7887\n",
      "Epoch 3390/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 295299268.8711 - val_loss: 1298928576.5941\n",
      "Epoch 3391/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 360679331.7006 - val_loss: 1124884069.3018\n",
      "Epoch 3392/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 367991715.4215 - val_loss: 1122417223.9032\n",
      "Epoch 3393/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 237697072.4412 - val_loss: 1219627942.8861\n",
      "Epoch 3394/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 383133857.5419 - val_loss: 1320809318.7015\n",
      "Epoch 3395/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 252987016.7968 - val_loss: 1549261754.5812\n",
      "Epoch 3396/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 389068506.6055 - val_loss: 1124526897.7598\n",
      "Epoch 3397/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 379456014.3343 - val_loss: 1337076731.6973\n",
      "Epoch 3398/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 417953945.0310 - val_loss: 1385969553.9308\n",
      "Epoch 3399/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 677430786.4131 - val_loss: 1343891463.1291\n",
      "Epoch 3400/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1099080362.6066 - val_loss: 4433744029.3086\n",
      "Epoch 3401/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 901492829.2628 - val_loss: 1256664090.6442\n",
      "Epoch 3402/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 445159202.6832 - val_loss: 1220757476.1857\n",
      "Epoch 3403/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 588742134.7521 - val_loss: 1241707349.5494\n",
      "Epoch 3404/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 270856206.1148 - val_loss: 1002379386.2391\n",
      "Epoch 3405/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 321572194.5931 - val_loss: 2818812373.2253\n",
      "Epoch 3406/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 531166196.7676 - val_loss: 1274012790.2245\n",
      "Epoch 3407/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 435359135.1165 - val_loss: 1431211917.0610\n",
      "Epoch 3408/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 867094737.3866 - val_loss: 1150951059.0290\n",
      "Epoch 3409/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 330995946.1925 - val_loss: 1134156672.1260\n",
      "Epoch 3410/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 614169107.2324 - val_loss: 2898292325.8239\n",
      "Epoch 3411/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1653632506.5436 - val_loss: 2718485240.9924\n",
      "Epoch 3412/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 671063310.4783 - val_loss: 1349594920.8664\n",
      "Epoch 3413/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 560708844.3534 - val_loss: 1897878610.6059\n",
      "Epoch 3414/10000\n",
      "3554/3554 [==============================] - 0s 130us/step - loss: 446370893.5059 - val_loss: 6205856169.3705\n",
      "Epoch 3415/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1019513591.0703 - val_loss: 1078488501.1983\n",
      "Epoch 3416/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 660121144.5267 - val_loss: 1144249661.2501\n",
      "Epoch 3417/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 426956040.3376 - val_loss: 1753917737.1184\n",
      "Epoch 3418/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 322134615.2752 - val_loss: 1104622395.4453\n",
      "Epoch 3419/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 906567269.1683 - val_loss: 2760624517.2208\n",
      "Epoch 3420/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 981803769.3011 - val_loss: 2281773802.1806\n",
      "Epoch 3421/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 834323610.8317 - val_loss: 1101861538.4754\n",
      "Epoch 3422/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 377925693.4564 - val_loss: 1051099122.1018\n",
      "Epoch 3423/10000\n",
      "3554/3554 [==============================] - 0s 134us/step - loss: 302221177.1075 - val_loss: 1091318898.3719\n",
      "Epoch 3424/10000\n",
      "3554/3554 [==============================] - 1s 144us/step - loss: 601735549.0850 - val_loss: 1148992023.7547\n",
      "Epoch 3425/10000\n",
      "3554/3554 [==============================] - 1s 183us/step - loss: 272338670.9083 - val_loss: 1994415755.6478\n",
      "Epoch 3426/10000\n",
      "3554/3554 [==============================] - 1s 175us/step - loss: 485955911.3112 - val_loss: 2148122254.5823\n",
      "Epoch 3427/10000\n",
      "3554/3554 [==============================] - 1s 141us/step - loss: 1043381005.5239 - val_loss: 1236365116.2014\n",
      "Epoch 3428/10000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 482694736.4524 - val_loss: 1461915562.2346\n",
      "Epoch 3429/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 881649634.6111 - val_loss: 3915211291.9404\n",
      "Epoch 3430/10000\n",
      "3554/3554 [==============================] - 1s 157us/step - loss: 1538952089.1435 - val_loss: 1594895496.5333\n",
      "Epoch 3431/10000\n",
      "3554/3554 [==============================] - 1s 143us/step - loss: 359852620.9116 - val_loss: 1344735165.0295\n",
      "Epoch 3432/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 299849484.3185 - val_loss: 1131860411.8414\n",
      "Epoch 3433/10000\n",
      "3554/3554 [==============================] - 1s 219us/step - loss: 360753260.4975 - val_loss: 1784160871.8042\n",
      "Epoch 3434/10000\n",
      "3554/3554 [==============================] - 1s 256us/step - loss: 395278401.1638 - val_loss: 1658246835.7761\n",
      "Epoch 3435/10000\n",
      "3554/3554 [==============================] - 1s 262us/step - loss: 451100230.1227 - val_loss: 1511795341.1331\n",
      "Epoch 3436/10000\n",
      "3554/3554 [==============================] - 1s 206us/step - loss: 314505970.7462 - val_loss: 1084295910.0399\n",
      "Epoch 3437/10000\n",
      "3554/3554 [==============================] - 1s 188us/step - loss: 325836527.1708 - val_loss: 2767496193.8723\n",
      "Epoch 3438/10000\n",
      "3554/3554 [==============================] - 1s 197us/step - loss: 616894854.4761 - val_loss: 1405904462.8163\n",
      "Epoch 3439/10000\n",
      "3554/3554 [==============================] - 1s 218us/step - loss: 394303460.3579 - val_loss: 1163443709.6236\n",
      "Epoch 3440/10000\n",
      "3554/3554 [==============================] - 1s 176us/step - loss: 835006734.8925 - val_loss: 1067830105.2129\n",
      "Epoch 3441/10000\n",
      "3554/3554 [==============================] - 1s 216us/step - loss: 588381456.2071 - val_loss: 1815139981.5381\n",
      "Epoch 3442/10000\n",
      "3554/3554 [==============================] - 1s 227us/step - loss: 715777147.8042 - val_loss: 3029164523.2788\n",
      "Epoch 3443/10000\n",
      "3554/3554 [==============================] - 1s 222us/step - loss: 484412802.7552 - val_loss: 1423065215.8920\n",
      "Epoch 3444/10000\n",
      "3554/3554 [==============================] - 1s 254us/step - loss: 1023782496.3782 - val_loss: 2874670442.5046\n",
      "Epoch 3445/10000\n",
      "3554/3554 [==============================] - 0s 137us/step - loss: 660149310.2352 - val_loss: 8895312580.5907\n",
      "Epoch 3446/10000\n",
      "3554/3554 [==============================] - 1s 155us/step - loss: 1506301074.9803 - val_loss: 3442374695.8402\n",
      "Epoch 3447/10000\n",
      "3554/3554 [==============================] - 1s 211us/step - loss: 567165889.9629 - val_loss: 1124933327.1584\n",
      "Epoch 3448/10000\n",
      "3554/3554 [==============================] - 1s 274us/step - loss: 247798268.6607 - val_loss: 1047013212.1564\n",
      "Epoch 3449/10000\n",
      "3554/3554 [==============================] - 1s 186us/step - loss: 390893463.3742 - val_loss: 1076943544.2948\n",
      "Epoch 3450/10000\n",
      "3554/3554 [==============================] - 1s 168us/step - loss: 628660522.8227 - val_loss: 1607473677.3221\n",
      "Epoch 3451/10000\n",
      "3554/3554 [==============================] - 1s 154us/step - loss: 1074729592.1486 - val_loss: 4496415971.9876\n",
      "Epoch 3452/10000\n",
      "3554/3554 [==============================] - 1s 164us/step - loss: 1098292715.9752 - val_loss: 1926983359.3069\n",
      "Epoch 3453/10000\n",
      "3554/3554 [==============================] - 1s 177us/step - loss: 497540582.5369 - val_loss: 1294734451.8841\n",
      "Epoch 3454/10000\n",
      "3554/3554 [==============================] - 1s 165us/step - loss: 918328430.5864 - val_loss: 3842744835.2405\n",
      "Epoch 3455/10000\n",
      "3554/3554 [==============================] - 1s 180us/step - loss: 408520391.9055 - val_loss: 1163298629.3828\n",
      "Epoch 3456/10000\n",
      "3554/3554 [==============================] - 1s 200us/step - loss: 301112120.1125 - val_loss: 1578555181.3671\n",
      "Epoch 3457/10000\n",
      "3554/3554 [==============================] - 1s 189us/step - loss: 529072239.1086 - val_loss: 1492033190.4180\n",
      "Epoch 3458/10000\n",
      "3554/3554 [==============================] - 1s 179us/step - loss: 304691819.5431 - val_loss: 2415565434.0861\n",
      "Epoch 3459/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 438937974.6190 - val_loss: 1082327657.3345\n",
      "Epoch 3460/10000\n",
      "3554/3554 [==============================] - 0s 130us/step - loss: 256873013.6815 - val_loss: 1055644896.8821\n",
      "Epoch 3461/10000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 286362071.9505 - val_loss: 1186493550.5913\n",
      "Epoch 3462/10000\n",
      "3554/3554 [==============================] - 1s 151us/step - loss: 537675815.8829 - val_loss: 1255005237.5449\n",
      "Epoch 3463/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 267496240.1981 - val_loss: 1199328487.1201\n",
      "Epoch 3464/10000\n",
      "3554/3554 [==============================] - 1s 152us/step - loss: 780763566.0281 - val_loss: 1949441818.2121\n",
      "Epoch 3465/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 1386081816.6213 - val_loss: 1931342863.8785\n",
      "Epoch 3466/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 118us/step - loss: 416325679.9730 - val_loss: 1552804200.8124\n",
      "Epoch 3467/10000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 333593766.5369 - val_loss: 1073436922.6172\n",
      "Epoch 3468/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 352696352.3421 - val_loss: 10462208561.3997\n",
      "Epoch 3469/10000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 3196547744.9904 - val_loss: 2303791409.9758\n",
      "Epoch 3470/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 586661872.1790 - val_loss: 1279364162.1783\n",
      "Epoch 3471/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 332037803.7681 - val_loss: 4650075749.4999\n",
      "Epoch 3472/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 976499268.5380 - val_loss: 2048056618.1896\n",
      "Epoch 3473/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 1416240850.6922 - val_loss: 1006012181.3873\n",
      "Epoch 3474/10000\n",
      "3554/3554 [==============================] - 1s 169us/step - loss: 215642436.9274 - val_loss: 1256387520.2340\n",
      "Epoch 3475/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 203734272.1666 - val_loss: 978806969.6990\n",
      "Epoch 3476/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 222816571.3044 - val_loss: 1172673382.6700\n",
      "Epoch 3477/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 298061134.4603 - val_loss: 1493664659.6771\n",
      "Epoch 3478/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 484367246.4243 - val_loss: 1053135642.0681\n",
      "Epoch 3479/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 269553046.1137 - val_loss: 2284582858.2526\n",
      "Epoch 3480/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 671053246.3073 - val_loss: 4763366516.6402\n",
      "Epoch 3481/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1051057865.1750 - val_loss: 1147680108.4489\n",
      "Epoch 3482/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 298421031.1491 - val_loss: 1285393536.0360\n",
      "Epoch 3483/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 307797942.7124 - val_loss: 1005761005.4211\n",
      "Epoch 3484/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 481439503.4688 - val_loss: 2325062229.7654\n",
      "Epoch 3485/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 1104132559.9010 - val_loss: 1942363464.0113\n",
      "Epoch 3486/10000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 567277491.5566 - val_loss: 1091221038.2492\n",
      "Epoch 3487/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 335072493.7220 - val_loss: 1181270076.0754\n",
      "Epoch 3488/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 458325987.8087 - val_loss: 1306532876.4039\n",
      "Epoch 3489/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 359152351.8019 - val_loss: 8565656329.6495\n",
      "Epoch 3490/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2482707298.5751 - val_loss: 1655715258.9772\n",
      "Epoch 3491/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 773106119.6894 - val_loss: 2100936637.0295\n",
      "Epoch 3492/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 384843315.9167 - val_loss: 1245087182.0602\n",
      "Epoch 3493/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 562886591.0276 - val_loss: 1332643731.0470\n",
      "Epoch 3494/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 351185568.3061 - val_loss: 1177310054.5800\n",
      "Epoch 3495/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 303312441.7513 - val_loss: 1037929664.9902\n",
      "Epoch 3496/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 604406455.6173 - val_loss: 2055497300.1091\n",
      "Epoch 3497/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 465296707.8177 - val_loss: 1023915310.0512\n",
      "Epoch 3498/10000\n",
      "3554/3554 [==============================] - 0s 132us/step - loss: 1274806506.2825 - val_loss: 4405581759.7660\n",
      "Epoch 3499/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 696268000.9544 - val_loss: 1240792529.9128\n",
      "Epoch 3500/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 961400453.5644 - val_loss: 1521630150.4630\n",
      "Epoch 3501/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 434006195.7107 - val_loss: 1374046944.9271\n",
      "Epoch 3502/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 266368549.4924 - val_loss: 2346496324.4647\n",
      "Epoch 3503/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 522061578.2465 - val_loss: 1151132322.6914\n",
      "Epoch 3504/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 584190562.8610 - val_loss: 1199922337.5212\n",
      "Epoch 3505/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 288790944.7383 - val_loss: 2111149512.3173\n",
      "Epoch 3506/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 391595503.3607 - val_loss: 1197831581.6281\n",
      "Epoch 3507/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 445769293.7040 - val_loss: 2416306726.7331\n",
      "Epoch 3508/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 595428560.7383 - val_loss: 2618932298.8917\n",
      "Epoch 3509/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 500845226.7552 - val_loss: 1062153408.8641\n",
      "Epoch 3510/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 485211670.1497 - val_loss: 1403032954.0051\n",
      "Epoch 3511/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1095308617.5262 - val_loss: 1521949469.3221\n",
      "Epoch 3512/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 743947736.3467 - val_loss: 1229076390.3280\n",
      "Epoch 3513/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 673885841.0580 - val_loss: 1671206332.3634\n",
      "Epoch 3514/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 1109970262.7259 - val_loss: 3649758578.2819\n",
      "Epoch 3515/10000\n",
      "3554/3554 [==============================] - 0s 134us/step - loss: 827491359.5588 - val_loss: 1636931156.6672\n",
      "Epoch 3516/10000\n",
      "3554/3554 [==============================] - 0s 136us/step - loss: 289922326.5639 - val_loss: 1053676173.5921\n",
      "Epoch 3517/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 311027023.8469 - val_loss: 2862958846.5958\n",
      "Epoch 3518/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 720895990.6359 - val_loss: 28762740939.9359\n",
      "Epoch 3519/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 1966649694.7935 - val_loss: 1226118361.1679\n",
      "Epoch 3520/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 231940964.0023 - val_loss: 1027755506.4079\n",
      "Epoch 3521/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 297755644.8666 - val_loss: 1319547319.5657\n",
      "Epoch 3522/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 428988772.3759 - val_loss: 1729661987.9539\n",
      "Epoch 3523/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 798017937.5037 - val_loss: 1060583958.6475\n",
      "Epoch 3524/10000\n",
      "3554/3554 [==============================] - 0s 138us/step - loss: 317632093.9471 - val_loss: 1225495009.5752\n",
      "Epoch 3525/10000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 422148691.3360 - val_loss: 1068317542.5170\n",
      "Epoch 3526/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 372522372.4299 - val_loss: 1101655319.7637\n",
      "Epoch 3527/10000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 487518272.558 - 0s 85us/step - loss: 511815794.5301 - val_loss: 1834688229.7879\n",
      "Epoch 3528/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 686995335.9055 - val_loss: 1699463463.8582\n",
      "Epoch 3529/10000\n",
      "3554/3554 [==============================] - 0s 139us/step - loss: 395178369.3686 - val_loss: 1123659729.3367\n",
      "Epoch 3530/10000\n",
      "3554/3554 [==============================] - 1s 151us/step - loss: 960358072.1306 - val_loss: 1015712352.4771\n",
      "Epoch 3531/10000\n",
      "3554/3554 [==============================] - 0s 138us/step - loss: 519947938.5256 - val_loss: 1142663272.0653\n",
      "Epoch 3532/10000\n",
      "3554/3554 [==============================] - 1s 204us/step - loss: 385179861.0782 - val_loss: 1027325459.3890\n",
      "Epoch 3533/10000\n",
      "3554/3554 [==============================] - 1s 258us/step - loss: 433080059.1739 - val_loss: 1229023745.9803\n",
      "Epoch 3534/10000\n",
      "3554/3554 [==============================] - 1s 229us/step - loss: 511824199.8154 - val_loss: 3990124964.4737\n",
      "Epoch 3535/10000\n",
      "3554/3554 [==============================] - 1s 417us/step - loss: 1709487701.2808 - val_loss: 1176100692.4692\n",
      "Epoch 3536/10000\n",
      "3554/3554 [==============================] - 2s 462us/step - loss: 485350892.3894 - val_loss: 1280446313.7125\n",
      "Epoch 3537/10000\n",
      "3554/3554 [==============================] - 2s 466us/step - loss: 305159463.2032 - val_loss: 1982976099.5916\n",
      "Epoch 3538/10000\n",
      "3554/3554 [==============================] - 2s 433us/step - loss: 349900718.7845 - val_loss: 1099948300.7820\n",
      "Epoch 3539/10000\n",
      "3554/3554 [==============================] - 2s 457us/step - loss: 447280925.9651 - val_loss: 1338239471.8695\n",
      "Epoch 3540/10000\n",
      "3554/3554 [==============================] - 1s 402us/step - loss: 546397336.5267 - val_loss: 2422365045.3063\n",
      "Epoch 3541/10000\n",
      "3554/3554 [==============================] - 1s 412us/step - loss: 1280169238.1857 - val_loss: 3588025022.6318\n",
      "Epoch 3542/10000\n",
      "3554/3554 [==============================] - 2s 494us/step - loss: 1913223811.9257 - val_loss: 1057093686.3865\n",
      "Epoch 3543/10000\n",
      "3554/3554 [==============================] - 1s 418us/step - loss: 324207575.9730 - val_loss: 1681501186.9525\n",
      "Epoch 3544/10000\n",
      "3554/3554 [==============================] - 2s 425us/step - loss: 309499400.4817 - val_loss: 1230708289.2962\n",
      "Epoch 3545/10000\n",
      "3554/3554 [==============================] - 1s 356us/step - loss: 452301738.0304 - val_loss: 4364201022.0737\n",
      "Epoch 3546/10000\n",
      "3554/3554 [==============================] - 1s 175us/step - loss: 741446386.7462 - val_loss: 7421372855.2686\n",
      "Epoch 3547/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 2339216974.4423 - val_loss: 1179565246.4338\n",
      "Epoch 3548/10000\n",
      "3554/3554 [==============================] - 0s 139us/step - loss: 315859303.2392 - val_loss: 1165692524.6290\n",
      "Epoch 3549/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 290707725.3258 - val_loss: 998978811.9134\n",
      "Epoch 3550/10000\n",
      "3554/3554 [==============================] - 1s 161us/step - loss: 518478565.8571 - val_loss: 1038544242.4979\n",
      "Epoch 3551/10000\n",
      "3554/3554 [==============================] - 1s 161us/step - loss: 370926490.0214 - val_loss: 1068055430.8411\n",
      "Epoch 3552/10000\n",
      "3554/3554 [==============================] - 1s 213us/step - loss: 247582813.1187 - val_loss: 1095564990.6408\n",
      "Epoch 3553/10000\n",
      "3554/3554 [==============================] - 1s 213us/step - loss: 272771330.4221 - val_loss: 1153002146.1333\n",
      "Epoch 3554/10000\n",
      "3554/3554 [==============================] - 1s 168us/step - loss: 397676858.8768 - val_loss: 1178975148.4669\n",
      "Epoch 3555/10000\n",
      "3554/3554 [==============================] - 1s 199us/step - loss: 458024111.3247 - val_loss: 1686984455.0571\n",
      "Epoch 3556/10000\n",
      "3554/3554 [==============================] - 1s 206us/step - loss: 682896105.7603 - val_loss: 3979223307.1077\n",
      "Epoch 3557/10000\n",
      "3554/3554 [==============================] - 1s 285us/step - loss: 963846137.8053 - val_loss: 1663226258.1828\n",
      "Epoch 3558/10000\n",
      "3554/3554 [==============================] - 1s 238us/step - loss: 1561936728.0945 - val_loss: 1109373157.0498\n",
      "Epoch 3559/10000\n",
      "3554/3554 [==============================] - 1s 183us/step - loss: 632288179.7783 - val_loss: 1101452709.1218\n",
      "Epoch 3560/10000\n",
      "3554/3554 [==============================] - 1s 153us/step - loss: 342270711.1401 - val_loss: 1565436359.6872\n",
      "Epoch 3561/10000\n",
      "3554/3554 [==============================] - 1s 205us/step - loss: 668877163.3180 - val_loss: 1123356109.9162\n",
      "Epoch 3562/10000\n",
      "3554/3554 [==============================] - 1s 283us/step - loss: 510572253.2808 - val_loss: 2627713493.8374\n",
      "Epoch 3563/10000\n",
      "3554/3554 [==============================] - 1s 297us/step - loss: 472518512.8557 - val_loss: 1171241977.6270\n",
      "Epoch 3564/10000\n",
      "3554/3554 [==============================] - 1s 290us/step - loss: 327573330.7248 - val_loss: 1020720943.1314\n",
      "Epoch 3565/10000\n",
      "3554/3554 [==============================] - 1s 409us/step - loss: 264598739.3945 - val_loss: 1035276026.0591\n",
      "Epoch 3566/10000\n",
      "3554/3554 [==============================] - 1s 348us/step - loss: 500184229.1863 - val_loss: 2295206295.5837\n",
      "Epoch 3567/10000\n",
      "3554/3554 [==============================] - 1s 280us/step - loss: 629586055.3787 - val_loss: 3186802106.4191\n",
      "Epoch 3568/10000\n",
      "3554/3554 [==============================] - 1s 215us/step - loss: 504914643.4305 - val_loss: 1192807133.1466\n",
      "Epoch 3569/10000\n",
      "3554/3554 [==============================] - 1s 213us/step - loss: 520772864.1936 - val_loss: 1168785220.6987\n",
      "Epoch 3570/10000\n",
      "3554/3554 [==============================] - 1s 190us/step - loss: 292768921.0400 - val_loss: 1727035289.2399\n",
      "Epoch 3571/10000\n",
      "3554/3554 [==============================] - 1s 256us/step - loss: 395730703.1986 - val_loss: 2329844443.2023\n",
      "Epoch 3572/10000\n",
      "3554/3554 [==============================] - 1s 273us/step - loss: 1276261536.8464 - val_loss: 1194716023.9257\n",
      "Epoch 3573/10000\n",
      "3554/3554 [==============================] - 1s 248us/step - loss: 296165624.8554 - val_loss: 1006873953.0712\n",
      "Epoch 3574/10000\n",
      "3554/3554 [==============================] - 1s 195us/step - loss: 612210286.5256 - val_loss: 1078898015.0909\n",
      "Epoch 3575/10000\n",
      "3554/3554 [==============================] - 1s 255us/step - loss: 713428312.4052 - val_loss: 1066255253.0993\n",
      "Epoch 3576/10000\n",
      "3554/3554 [==============================] - 1s 354us/step - loss: 397041135.6488 - val_loss: 1363097131.7918\n",
      "Epoch 3577/10000\n",
      "3554/3554 [==============================] - 1s 363us/step - loss: 713948676.3579 - val_loss: 1091063897.7620\n",
      "Epoch 3578/10000\n",
      "3554/3554 [==============================] - 1s 344us/step - loss: 288719704.8509 - val_loss: 2040856435.1460\n",
      "Epoch 3579/10000\n",
      "3554/3554 [==============================] - 1s 391us/step - loss: 721701774.1902 - val_loss: 1130593364.0731\n",
      "Epoch 3580/10000\n",
      "3554/3554 [==============================] - 1s 337us/step - loss: 375320913.1795 - val_loss: 1165912897.3322\n",
      "Epoch 3581/10000\n",
      "3554/3554 [==============================] - 1s 338us/step - loss: 881704569.1210 - val_loss: 1246156921.8340\n",
      "Epoch 3582/10000\n",
      "3554/3554 [==============================] - 1s 326us/step - loss: 503200288.8824 - val_loss: 2330145822.2807\n",
      "Epoch 3583/10000\n",
      "3554/3554 [==============================] - 1s 306us/step - loss: 823263561.0760 - val_loss: 1165850494.5238\n",
      "Epoch 3584/10000\n",
      "3554/3554 [==============================] - 1s 304us/step - loss: 528572758.9420 - val_loss: 6057269210.8062\n",
      "Epoch 3585/10000\n",
      "3554/3554 [==============================] - 1s 372us/step - loss: 1658451319.3112 - val_loss: 1115342942.7623\n",
      "Epoch 3586/10000\n",
      "3554/3554 [==============================] - 1s 342us/step - loss: 746856035.7636 - val_loss: 1339857606.5710\n",
      "Epoch 3587/10000\n",
      "3554/3554 [==============================] - 1s 261us/step - loss: 329568723.7006 - val_loss: 2282743829.3333\n",
      "Epoch 3588/10000\n",
      "3554/3554 [==============================] - 1s 186us/step - loss: 621663528.6978 - val_loss: 1620513691.8323\n",
      "Epoch 3589/10000\n",
      "3554/3554 [==============================] - 1s 183us/step - loss: 417637765.9966 - val_loss: 1518568867.7536\n",
      "Epoch 3590/10000\n",
      "3554/3554 [==============================] - 1s 183us/step - loss: 538977220.3421 - val_loss: 2096703718.3280\n",
      "Epoch 3591/10000\n",
      "3554/3554 [==============================] - 1s 209us/step - loss: 264983830.7530 - val_loss: 1342873094.4810\n",
      "Epoch 3592/10000\n",
      "3554/3554 [==============================] - 1s 188us/step - loss: 361499127.4012 - val_loss: 1131685337.4020\n",
      "Epoch 3593/10000\n",
      "3554/3554 [==============================] - 0s 136us/step - loss: 453639278.1362 - val_loss: 3157638946.5654\n",
      "Epoch 3594/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 122us/step - loss: 874049277.6230 - val_loss: 1546611167.7750\n",
      "Epoch 3595/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 545390317.1998 - val_loss: 2170088770.6284\n",
      "Epoch 3596/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 671415199.4778 - val_loss: 2347976535.1336\n",
      "Epoch 3597/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 398065041.2335 - val_loss: 1115702202.3291\n",
      "Epoch 3598/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 701099448.1711 - val_loss: 1087649208.6549\n",
      "Epoch 3599/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 537870073.2651 - val_loss: 2074477919.5229\n",
      "Epoch 3600/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 1482360473.8143 - val_loss: 1064019247.7975\n",
      "Epoch 3601/10000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 442049751.2302 - val_loss: 1388479357.1556\n",
      "Epoch 3602/10000\n",
      "3554/3554 [==============================] - 0s 130us/step - loss: 660354074.1474 - val_loss: 3564976701.3356\n",
      "Epoch 3603/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 644932469.9516 - val_loss: 983245218.2774\n",
      "Epoch 3604/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 235936337.8458 - val_loss: 1069723711.8380\n",
      "Epoch 3605/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 650704971.6331 - val_loss: 1947161989.2928\n",
      "Epoch 3606/10000\n",
      "3554/3554 [==============================] - 1s 153us/step - loss: 598989705.2560 - val_loss: 1052706264.8259\n",
      "Epoch 3607/10000\n",
      "3554/3554 [==============================] - 1s 166us/step - loss: 571289855.5498 - val_loss: 960240109.3311\n",
      "Epoch 3608/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 1318813122.2060 - val_loss: 13330587657.2174\n",
      "Epoch 3609/10000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 1411876163.0974 - val_loss: 1428205617.3997\n",
      "Epoch 3610/10000\n",
      "3554/3554 [==============================] - 1s 155us/step - loss: 516559993.8053 - val_loss: 2554686253.6911\n",
      "Epoch 3611/10000\n",
      "3554/3554 [==============================] - 1s 141us/step - loss: 414071725.9403 - val_loss: 966168544.3691\n",
      "Epoch 3612/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 251771238.8655 - val_loss: 1177885639.9662\n",
      "Epoch 3613/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 262181466.4491 - val_loss: 1164473201.2737\n",
      "Epoch 3614/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 260888337.0535 - val_loss: 1071139163.7783\n",
      "Epoch 3615/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 322121826.0529 - val_loss: 1557158617.5100\n",
      "Epoch 3616/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 411207840.0720 - val_loss: 2092995816.3038\n",
      "Epoch 3617/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 831320182.5279 - val_loss: 3677983566.2942\n",
      "Epoch 3618/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 394357322.9592 - val_loss: 1059630911.5679\n",
      "Epoch 3619/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 338005139.7727 - val_loss: 1197531743.3069\n",
      "Epoch 3620/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 431209174.7349 - val_loss: 1051826253.3401\n",
      "Epoch 3621/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 413066426.1024 - val_loss: 3091565688.7089\n",
      "Epoch 3622/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 962215955.7102 - val_loss: 984012498.0568\n",
      "Epoch 3623/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 240057576.2836 - val_loss: 1990121594.4191\n",
      "Epoch 3624/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 761186655.4778 - val_loss: 1003670678.4495\n",
      "Epoch 3625/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 443586485.0152 - val_loss: 5882297679.5724\n",
      "Epoch 3626/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1288120061.2988 - val_loss: 1047789406.2177\n",
      "Epoch 3627/10000\n",
      "3554/3554 [==============================] - 0s 136us/step - loss: 379689090.7552 - val_loss: 1050911907.2135\n",
      "Epoch 3628/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 298052205.1818 - val_loss: 1090577618.7049\n",
      "Epoch 3629/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 272251327.4598 - val_loss: 4152292114.7229\n",
      "Epoch 3630/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 582713963.1739 - val_loss: 1043114834.5789\n",
      "Epoch 3631/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 417740022.0236 - val_loss: 2107503852.5570\n",
      "Epoch 3632/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 2381384055.6083 - val_loss: 2393572339.7581\n",
      "Epoch 3633/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 345215394.3950 - val_loss: 1497053174.4585\n",
      "Epoch 3634/10000\n",
      "3554/3554 [==============================] - 1s 141us/step - loss: 273166719.3270 - val_loss: 1051576920.4838\n",
      "Epoch 3635/10000\n",
      "3554/3554 [==============================] - 0s 131us/step - loss: 249959075.5115 - val_loss: 1724263738.0681\n",
      "Epoch 3636/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 444739828.7383 - val_loss: 1041679148.6650\n",
      "Epoch 3637/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 329613089.3326 - val_loss: 1353261448.5963\n",
      "Epoch 3638/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 303428000.2161 - val_loss: 1525173084.1564\n",
      "Epoch 3639/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 385362534.3154 - val_loss: 1089760189.5696\n",
      "Epoch 3640/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 470071141.6950 - val_loss: 1304096492.8450\n",
      "Epoch 3641/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 794008294.0687 - val_loss: 1592750225.1837\n",
      "Epoch 3642/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 480070373.3483 - val_loss: 1440442805.4684\n",
      "Epoch 3643/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 500221706.2825 - val_loss: 1049126478.0962\n",
      "Epoch 3644/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 488768729.8953 - val_loss: 1148514310.4090\n",
      "Epoch 3645/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 1117097071.4147 - val_loss: 1362630846.3077\n",
      "Epoch 3646/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 811754171.4530 - val_loss: 1556697672.1553\n",
      "Epoch 3647/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 317084060.1643 - val_loss: 2535699236.3657\n",
      "Epoch 3648/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 730583125.1685 - val_loss: 1200725765.6529\n",
      "Epoch 3649/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 373205179.7862 - val_loss: 1741471678.4338\n",
      "Epoch 3650/10000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 1177895067.5656 - val_loss: 1695911067.6208\n",
      "Epoch 3651/10000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 326196827.2279 - val_loss: 2183844486.4090\n",
      "Epoch 3652/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 395917749.0512 - val_loss: 2993595607.2056\n",
      "Epoch 3653/10000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 2153128862.7575 - val_loss: 3650357285.0408\n",
      "Epoch 3654/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 603477445.6365 - val_loss: 1170362664.5783\n",
      "Epoch 3655/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 357167679.6579 - val_loss: 2365962074.8602\n",
      "Epoch 3656/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 379860014.3512 - val_loss: 987319483.8233\n",
      "Epoch 3657/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 300578628.3579 - val_loss: 2748381770.4146\n",
      "Epoch 3658/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 495446214.3376 - val_loss: 1175659072.9541\n",
      "Epoch 3659/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 330029348.8261 - val_loss: 2949670738.7409\n",
      "Epoch 3660/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 1230857732.7541 - val_loss: 1697617453.9252\n",
      "Epoch 3661/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 394713116.3624 - val_loss: 1108070463.6399\n",
      "Epoch 3662/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 790585809.8818 - val_loss: 1631330658.3134\n",
      "Epoch 3663/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 491220874.0844 - val_loss: 3733263459.4475\n",
      "Epoch 3664/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 383988805.0782 - val_loss: 1788406066.7679\n",
      "Epoch 3665/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 314187781.7985 - val_loss: 1005867604.5232\n",
      "Epoch 3666/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 528687495.4192 - val_loss: 1056462027.0177\n",
      "Epoch 3667/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 582969826.9893 - val_loss: 1266862069.3063\n",
      "Epoch 3668/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 436760661.6275 - val_loss: 1201144603.5803\n",
      "Epoch 3669/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 488534183.4553 - val_loss: 2445391551.4959\n",
      "Epoch 3670/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 488553852.1711 - val_loss: 1267873457.5797\n",
      "Epoch 3671/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1182813842.3680 - val_loss: 2550377678.2762\n",
      "Epoch 3672/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1061009368.6944 - val_loss: 1201127202.8624\n",
      "Epoch 3673/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 284489008.5582 - val_loss: 1061402608.4366\n",
      "Epoch 3674/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 256296830.1272 - val_loss: 2038104912.8686\n",
      "Epoch 3675/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 622936460.5065 - val_loss: 1082590064.3736\n",
      "Epoch 3676/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 248599787.9617 - val_loss: 1325657887.6129\n",
      "Epoch 3677/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 386263460.9702 - val_loss: 4387023824.7606\n",
      "Epoch 3678/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 844400581.7355 - val_loss: 1011444071.8402\n",
      "Epoch 3679/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 315803174.3208 - val_loss: 2061366242.6689\n",
      "Epoch 3680/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 731155352.2026 - val_loss: 1291687664.7156\n",
      "Epoch 3681/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 584688530.7867 - val_loss: 1198857768.7944\n",
      "Epoch 3682/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 796213181.8751 - val_loss: 4325543273.4245\n",
      "Epoch 3683/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1336756398.0642 - val_loss: 1152918202.6577\n",
      "Epoch 3684/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 283431393.5127 - val_loss: 1290050991.3474\n",
      "Epoch 3685/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 339164416.5042 - val_loss: 1011894425.1139\n",
      "Epoch 3686/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 576358572.6595 - val_loss: 2847583439.2484\n",
      "Epoch 3687/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 349285330.6292 - val_loss: 1473946780.1879\n",
      "Epoch 3688/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 349667780.9387 - val_loss: 1498165242.3831\n",
      "Epoch 3689/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 705486744.2386 - val_loss: 1681121766.1570\n",
      "Epoch 3690/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 387525512.3557 - val_loss: 4039894692.1136\n",
      "Epoch 3691/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 1283660950.8970 - val_loss: 4705349036.8990\n",
      "Epoch 3692/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 1298590836.0608 - val_loss: 1846567015.7322\n",
      "Epoch 3693/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 430035144.4524 - val_loss: 951542801.8633\n",
      "Epoch 3694/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 258231334.8970 - val_loss: 2699039880.5873\n",
      "Epoch 3695/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 533752054.3478 - val_loss: 1916648758.5395\n",
      "Epoch 3696/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 516506231.5003 - val_loss: 1689269773.9342\n",
      "Epoch 3697/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 795792783.6398 - val_loss: 2813083920.8686\n",
      "Epoch 3698/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 500091967.2212 - val_loss: 994645828.5997\n",
      "Epoch 3699/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 547765633.7670 - val_loss: 1086835689.9015\n",
      "Epoch 3700/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 470802950.3928 - val_loss: 1495218168.7179\n",
      "Epoch 3701/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 378479839.2077 - val_loss: 955815129.6540\n",
      "Epoch 3702/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 313706852.1688 - val_loss: 1013719886.3842\n",
      "Epoch 3703/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 331481056.5402 - val_loss: 1102585261.9432\n",
      "Epoch 3704/10000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 277939233.2065 - val_loss: 2605374882.3854\n",
      "Epoch 3705/10000\n",
      "3554/3554 [==============================] - 0s 140us/step - loss: 754524518.2307 - val_loss: 1674599433.5235\n",
      "Epoch 3706/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 664977048.4187 - val_loss: 2035039210.8557\n",
      "Epoch 3707/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 687231167.9100 - val_loss: 1710164504.5018\n",
      "Epoch 3708/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 921571406.5144 - val_loss: 2737043378.2278\n",
      "Epoch 3709/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 800220126.9781 - val_loss: 1883176859.1122\n",
      "Epoch 3710/10000\n",
      "3554/3554 [==============================] - 0s 131us/step - loss: 490659665.3956 - val_loss: 2349141987.7896\n",
      "Epoch 3711/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 552467789.3979 - val_loss: 1131893288.6684\n",
      "Epoch 3712/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 294843902.4873 - val_loss: 1646074780.0844\n",
      "Epoch 3713/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 437831472.1103 - val_loss: 1493020584.3713\n",
      "Epoch 3714/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 415602211.0433 - val_loss: 1009069786.0141\n",
      "Epoch 3715/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 333827038.5774 - val_loss: 1404013616.2970\n",
      "Epoch 3716/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1058468223.9640 - val_loss: 1929346277.5539\n",
      "Epoch 3717/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 688767609.1570 - val_loss: 7505192323.4565\n",
      "Epoch 3718/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1304278121.4451 - val_loss: 2955107412.6492\n",
      "Epoch 3719/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 551068589.4215 - val_loss: 1051810105.3030\n",
      "Epoch 3720/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 262921560.9499 - val_loss: 1733198081.7283\n",
      "Epoch 3721/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 316776546.1429 - val_loss: 2931966661.3288\n",
      "Epoch 3722/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 109us/step - loss: 1134148175.7569 - val_loss: 2102892394.1986\n",
      "Epoch 3723/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 366727019.8312 - val_loss: 2121704086.5035\n",
      "Epoch 3724/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 873033795.1154 - val_loss: 1328114931.3080\n",
      "Epoch 3725/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 376877095.9010 - val_loss: 1081897406.1727\n",
      "Epoch 3726/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 652390197.1232 - val_loss: 1111400409.5460\n",
      "Epoch 3727/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 385896148.3399 - val_loss: 1687355748.3747\n",
      "Epoch 3728/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 321875700.3984 - val_loss: 937835603.2270\n",
      "Epoch 3729/10000\n",
      "3554/3554 [==============================] - 0s 134us/step - loss: 283930665.1660 - val_loss: 977269984.5851\n",
      "Epoch 3730/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 539089340.3984 - val_loss: 3676537805.9162\n",
      "Epoch 3731/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 1056390445.1503 - val_loss: 1437515935.9460\n",
      "Epoch 3732/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 624720515.6016 - val_loss: 1493900250.6082\n",
      "Epoch 3733/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 596470758.2487 - val_loss: 1645502551.7097\n",
      "Epoch 3734/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 310587249.1030 - val_loss: 1345220168.1193\n",
      "Epoch 3735/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 445416746.2825 - val_loss: 4074463410.1918\n",
      "Epoch 3736/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1374873061.5892 - val_loss: 1090665789.4256\n",
      "Epoch 3737/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 698985605.0242 - val_loss: 1065569839.8155\n",
      "Epoch 3738/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 261275627.7794 - val_loss: 1569123528.4793\n",
      "Epoch 3739/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 250292680.6685 - val_loss: 1843021338.1401\n",
      "Epoch 3740/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 428968479.6398 - val_loss: 1801328181.8824\n",
      "Epoch 3741/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 764096335.6849 - val_loss: 1383385672.7314\n",
      "Epoch 3742/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 588030637.4609 - val_loss: 2326790335.9820\n",
      "Epoch 3743/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 422882813.4429 - val_loss: 1602914710.3235\n",
      "Epoch 3744/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 363745626.0574 - val_loss: 1762775617.9623\n",
      "Epoch 3745/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 412546952.7158 - val_loss: 1391737029.5629\n",
      "Epoch 3746/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1080822915.7546 - val_loss: 2220599015.6602\n",
      "Epoch 3747/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 476020369.1210 - val_loss: 1227400399.3924\n",
      "Epoch 3748/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 248172952.5267 - val_loss: 1824314824.9114\n",
      "Epoch 3749/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 585420335.4868 - val_loss: 1163897367.2056\n",
      "Epoch 3750/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 424096221.3708 - val_loss: 1484572863.2259\n",
      "Epoch 3751/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 470185614.9330 - val_loss: 4268702032.1485\n",
      "Epoch 3752/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 833686095.7749 - val_loss: 1660081124.1451\n",
      "Epoch 3753/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 309195032.7473 - val_loss: 1052846583.1066\n",
      "Epoch 3754/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 583341700.5920 - val_loss: 1276113494.6655\n",
      "Epoch 3755/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 836748460.6775 - val_loss: 1501069488.6796\n",
      "Epoch 3756/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 510607566.6134 - val_loss: 1256661521.7148\n",
      "Epoch 3757/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 274209802.3725 - val_loss: 1059342159.5724\n",
      "Epoch 3758/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 284703178.8610 - val_loss: 1370920800.9271\n",
      "Epoch 3759/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 259476573.4429 - val_loss: 1058385901.1511\n",
      "Epoch 3760/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 386793727.4282 - val_loss: 4316029674.5406\n",
      "Epoch 3761/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 1059305576.5709 - val_loss: 2265994559.7300\n",
      "Epoch 3762/10000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 1022255762.8723 - val_loss: 2197626278.4180\n",
      "Epoch 3763/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 705639298.3635 - val_loss: 3416873452.1969\n",
      "Epoch 3764/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 1569935787.3360 - val_loss: 1429235331.3665\n",
      "Epoch 3765/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 364150803.5476 - val_loss: 1058483329.8903\n",
      "Epoch 3766/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 258131365.8526 - val_loss: 1323790898.1918\n",
      "Epoch 3767/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 285989170.4581 - val_loss: 1684959168.6481\n",
      "Epoch 3768/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 525823509.0332 - val_loss: 1631132870.4630\n",
      "Epoch 3769/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 425175285.7895 - val_loss: 1027632408.3038\n",
      "Epoch 3770/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 283599627.1649 - val_loss: 954967658.3426\n",
      "Epoch 3771/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 634371169.6027 - val_loss: 1318062301.3266\n",
      "Epoch 3772/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 1977410082.0574 - val_loss: 2647650128.3556\n",
      "Epoch 3773/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 691822517.9156 - val_loss: 1368541983.5409\n",
      "Epoch 3774/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 234754678.0597 - val_loss: 1494659854.4293\n",
      "Epoch 3775/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 762624621.0557 - val_loss: 13501977440.1350\n",
      "Epoch 3776/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1870490686.3410 - val_loss: 1129709743.5544\n",
      "Epoch 3777/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 271161755.1019 - val_loss: 1043753146.9592\n",
      "Epoch 3778/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 220389645.5959 - val_loss: 1081828347.0852\n",
      "Epoch 3779/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 210331248.4783 - val_loss: 905282194.4889\n",
      "Epoch 3780/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 228007394.3388 - val_loss: 1009733972.3252\n",
      "Epoch 3781/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 420754341.9201 - val_loss: 1618816400.8506\n",
      "Epoch 3782/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 435702811.0478 - val_loss: 1448214330.5812\n",
      "Epoch 3783/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 344159481.2583 - val_loss: 1135033180.0844\n",
      "Epoch 3784/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 263336684.9162 - val_loss: 998099083.4678\n",
      "Epoch 3785/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 645507522.4851 - val_loss: 2062245365.3423\n",
      "Epoch 3786/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 917583792.1711 - val_loss: 1329449405.3401\n",
      "Epoch 3787/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 449332885.9516 - val_loss: 1413986559.4779\n",
      "Epoch 3788/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 308191165.0467 - val_loss: 991202543.8155\n",
      "Epoch 3789/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 334521783.1761 - val_loss: 1079324821.6934\n",
      "Epoch 3790/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 272813838.8385 - val_loss: 2262650826.2616\n",
      "Epoch 3791/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1255016427.1289 - val_loss: 1321593912.5288\n",
      "Epoch 3792/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 353463120.9274 - val_loss: 1148567840.3691\n",
      "Epoch 3793/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 337332194.6472 - val_loss: 1170191910.9221\n",
      "Epoch 3794/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 436161313.3146 - val_loss: 1150912067.1505\n",
      "Epoch 3795/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 758324049.1345 - val_loss: 1028338107.1032\n",
      "Epoch 3796/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 291749222.5864 - val_loss: 919366106.7702\n",
      "Epoch 3797/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 447702465.9809 - val_loss: 1170875896.0788\n",
      "Epoch 3798/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1451211739.5070 - val_loss: 6728156570.8962\n",
      "Epoch 3799/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 522077983.9820 - val_loss: 5919996880.3286\n",
      "Epoch 3800/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 550514336.2881 - val_loss: 1300050506.8917\n",
      "Epoch 3801/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 292012856.7248 - val_loss: 985343538.4889\n",
      "Epoch 3802/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 285133206.1497 - val_loss: 4931556103.5612\n",
      "Epoch 3803/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 4254701870.6224 - val_loss: 1087805118.2537\n",
      "Epoch 3804/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 225677206.6224 - val_loss: 1128864913.5167\n",
      "Epoch 3805/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 242695524.3939 - val_loss: 1087495089.6068\n",
      "Epoch 3806/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 255343954.9083 - val_loss: 1358878447.9415\n",
      "Epoch 3807/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 304898067.4845 - val_loss: 1038764295.3812\n",
      "Epoch 3808/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 364295648.5582 - val_loss: 1005913946.6712\n",
      "Epoch 3809/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 252669123.1626 - val_loss: 1491355807.1899\n",
      "Epoch 3810/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 273108374.1137 - val_loss: 3722706078.1727\n",
      "Epoch 3811/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 843525848.2499 - val_loss: 1379411424.9992\n",
      "Epoch 3812/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 506600352.8104 - val_loss: 1155374812.0844\n",
      "Epoch 3813/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 975916149.9516 - val_loss: 1239751590.9221\n",
      "Epoch 3814/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 489026923.0433 - val_loss: 1409660358.2110\n",
      "Epoch 3815/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 287929199.8649 - val_loss: 1792492882.9300\n",
      "Epoch 3816/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 338482596.2228 - val_loss: 1620858234.2121\n",
      "Epoch 3817/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 373543835.7501 - val_loss: 1876595077.2208\n",
      "Epoch 3818/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 476814137.1210 - val_loss: 1229667513.0869\n",
      "Epoch 3819/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 629382745.5352 - val_loss: 1501705018.3651\n",
      "Epoch 3820/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 676855733.5374 - val_loss: 1815167461.9139\n",
      "Epoch 3821/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 548866569.4902 - val_loss: 2196875663.0143\n",
      "Epoch 3822/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1040956329.7648 - val_loss: 1344209719.3857\n",
      "Epoch 3823/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 226780988.8036 - val_loss: 974597491.3440\n",
      "Epoch 3824/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 196189598.5954 - val_loss: 2459294837.0993\n",
      "Epoch 3825/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 842282614.1823 - val_loss: 1150638364.8855\n",
      "Epoch 3826/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 555584308.8261 - val_loss: 1157158969.6090\n",
      "Epoch 3827/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 291898417.6792 - val_loss: 1415919187.7491\n",
      "Epoch 3828/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 731441530.2015 - val_loss: 1832029088.2790\n",
      "Epoch 3829/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 471765494.6359 - val_loss: 987417691.1077\n",
      "Epoch 3830/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 295659575.1401 - val_loss: 2053959105.7013\n",
      "Epoch 3831/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 504231990.1497 - val_loss: 1279089175.8357\n",
      "Epoch 3832/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 592544319.9460 - val_loss: 1350101384.2813\n",
      "Epoch 3833/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 588041748.3399 - val_loss: 1488173887.1179\n",
      "Epoch 3834/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 348791263.9640 - val_loss: 1280357302.7421\n",
      "Epoch 3835/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 909454640.8914 - val_loss: 993723059.4655\n",
      "Epoch 3836/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 673720481.2065 - val_loss: 2440760140.1159\n",
      "Epoch 3837/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 513577970.3860 - val_loss: 1504845654.3415\n",
      "Epoch 3838/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 2443470347.5971 - val_loss: 1445141626.8512\n",
      "Epoch 3839/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 529489436.7327 - val_loss: 1100646445.1150\n",
      "Epoch 3840/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 253114203.4485 - val_loss: 978783866.7252\n",
      "Epoch 3841/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 381831729.1615 - val_loss: 1441429032.2543\n",
      "Epoch 3842/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 650751505.5577 - val_loss: 1089030211.8166\n",
      "Epoch 3843/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 936291307.4170 - val_loss: 1373710487.9437\n",
      "Epoch 3844/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 308301962.5706 - val_loss: 1018352328.4703\n",
      "Epoch 3845/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 324035817.4811 - val_loss: 1235643345.4987\n",
      "Epoch 3846/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 273293561.4882 - val_loss: 1091189218.7094\n",
      "Epoch 3847/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 534836058.0754 - val_loss: 1614274904.4748\n",
      "Epoch 3848/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 314787878.7530 - val_loss: 1887488696.2768\n",
      "Epoch 3849/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 881280235.6601 - val_loss: 1794481149.8397\n",
      "Epoch 3850/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 399341700.6640 - val_loss: 1260695334.9581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3851/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 226670332.5650 - val_loss: 1401625435.5533\n",
      "Epoch 3852/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 286480803.4125 - val_loss: 1126334964.2082\n",
      "Epoch 3853/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 362867876.7721 - val_loss: 1364779871.9190\n",
      "Epoch 3854/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 414969332.7811 - val_loss: 1473820411.7153\n",
      "Epoch 3855/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 502569358.0461 - val_loss: 2527397129.4335\n",
      "Epoch 3856/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 675923145.9043 - val_loss: 3540042112.8281\n",
      "Epoch 3857/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1111932957.9426 - val_loss: 1106055958.1975\n",
      "Epoch 3858/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 259802460.1283 - val_loss: 949241301.3693\n",
      "Epoch 3859/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 316456263.4553 - val_loss: 1089363727.3429\n",
      "Epoch 3860/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 675828378.0799 - val_loss: 1030339448.4388\n",
      "Epoch 3861/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 441606803.6646 - val_loss: 3471874791.7322\n",
      "Epoch 3862/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 502935823.8649 - val_loss: 2705216377.4110\n",
      "Epoch 3863/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 709854029.6365 - val_loss: 1148620444.6605\n",
      "Epoch 3864/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 327096267.7952 - val_loss: 1245622484.4242\n",
      "Epoch 3865/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 249176007.3945 - val_loss: 1057154956.1249\n",
      "Epoch 3866/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 695895779.2977 - val_loss: 1379758927.3024\n",
      "Epoch 3867/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 455368661.5734 - val_loss: 3458755977.5415\n",
      "Epoch 3868/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 1034021141.8391 - val_loss: 1123498495.2619\n",
      "Epoch 3869/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 618131077.3371 - val_loss: 940281258.6667\n",
      "Epoch 3870/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 612245867.0208 - val_loss: 4541902151.5072\n",
      "Epoch 3871/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1038345876.5650 - val_loss: 1123550441.4605\n",
      "Epoch 3872/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 311436331.1694 - val_loss: 1534498517.3693\n",
      "Epoch 3873/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 395629204.5650 - val_loss: 926111231.5589\n",
      "Epoch 3874/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 344495382.4018 - val_loss: 2304850635.7108\n",
      "Epoch 3875/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1467972462.8925 - val_loss: 1556479676.8135\n",
      "Epoch 3876/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 380093577.7963 - val_loss: 6820353730.5024\n",
      "Epoch 3877/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1170100859.7254 - val_loss: 1217027171.2990\n",
      "Epoch 3878/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 231205310.1542 - val_loss: 957877915.4903\n",
      "Epoch 3879/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 528237944.1441 - val_loss: 1105453471.9730\n",
      "Epoch 3880/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 227331355.1705 - val_loss: 1793048090.3561\n",
      "Epoch 3881/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 377181756.4389 - val_loss: 1387902435.0740\n",
      "Epoch 3882/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 442232854.0056 - val_loss: 1415149800.3263\n",
      "Epoch 3883/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 391130815.0186 - val_loss: 907464697.9331\n",
      "Epoch 3884/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 279718978.2330 - val_loss: 1095122928.3646\n",
      "Epoch 3885/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 626883269.8526 - val_loss: 1066558652.0754\n",
      "Epoch 3886/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1019141624.0765 - val_loss: 1804036659.1640\n",
      "Epoch 3887/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 480665857.9268 - val_loss: 2027228626.3899\n",
      "Epoch 3888/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 332063437.4564 - val_loss: 979568683.4408\n",
      "Epoch 3889/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 395763425.0445 - val_loss: 1145464648.0203\n",
      "Epoch 3890/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 423387468.3807 - val_loss: 1572358384.2295\n",
      "Epoch 3891/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 792207966.7935 - val_loss: 3616680966.6970\n",
      "Epoch 3892/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1063480339.0433 - val_loss: 1024954433.5122\n",
      "Epoch 3893/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 295129672.9083 - val_loss: 908309828.3927\n",
      "Epoch 3894/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 247645950.1452 - val_loss: 2143267847.7232\n",
      "Epoch 3895/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 599991471.4868 - val_loss: 1886763431.0301\n",
      "Epoch 3896/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 745000714.8542 - val_loss: 1479819747.1595\n",
      "Epoch 3897/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 517145505.3686 - val_loss: 1145674877.6416\n",
      "Epoch 3898/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 429729653.5622 - val_loss: 2238328208.9677\n",
      "Epoch 3899/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 791254859.7659 - val_loss: 1025370906.0591\n",
      "Epoch 3900/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 341392964.5290 - val_loss: 1275069899.2158\n",
      "Epoch 3901/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 909355481.4271 - val_loss: 8491328884.7302\n",
      "Epoch 3902/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1869824009.2560 - val_loss: 2608145534.5238\n",
      "Epoch 3903/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 797649726.5594 - val_loss: 2269579903.5409\n",
      "Epoch 3904/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 750008172.0833 - val_loss: 1955916426.2616\n",
      "Epoch 3905/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 648950087.7074 - val_loss: 1141499425.5932\n",
      "Epoch 3906/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 333471585.6657 - val_loss: 1111111651.5286\n",
      "Epoch 3907/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 222604698.0225 - val_loss: 940897780.0101\n",
      "Epoch 3908/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 198765801.9764 - val_loss: 1283306995.6231\n",
      "Epoch 3909/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 422608351.0096 - val_loss: 1077099043.8256\n",
      "Epoch 3910/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 345999646.7755 - val_loss: 2322679373.4121\n",
      "Epoch 3911/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 450466560.0732 - val_loss: 1696247563.0357\n",
      "Epoch 3912/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1797694933.8616 - val_loss: 1856368425.7665\n",
      "Epoch 3913/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 478915007.4057 - val_loss: 1491857550.3392\n",
      "Epoch 3914/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 800635126.9330 - val_loss: 1041395526.1570\n",
      "Epoch 3915/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 199053830.5729 - val_loss: 942719030.7286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3916/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 302801006.4198 - val_loss: 1634446900.5615\n",
      "Epoch 3917/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 517740567.2482 - val_loss: 1249467885.6011\n",
      "Epoch 3918/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 263372414.3433 - val_loss: 1010404724.7122\n",
      "Epoch 3919/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1036461249.8008 - val_loss: 4604256881.4762\n",
      "Epoch 3920/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 717777671.1851 - val_loss: 1566164923.3013\n",
      "Epoch 3921/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 575024938.5661 - val_loss: 1281029765.0678\n",
      "Epoch 3922/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 257877000.7248 - val_loss: 2335614224.2790\n",
      "Epoch 3923/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 325026877.5509 - val_loss: 996968943.0053\n",
      "Epoch 3924/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 493605597.1367 - val_loss: 988755870.7128\n",
      "Epoch 3925/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 594219655.7209 - val_loss: 1161125893.5359\n",
      "Epoch 3926/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 353321158.3748 - val_loss: 2172092830.0647\n",
      "Epoch 3927/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 442501739.9122 - val_loss: 996789135.3744\n",
      "Epoch 3928/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 352857759.3754 - val_loss: 936003715.6546\n",
      "Epoch 3929/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 586015009.7107 - val_loss: 1773825997.8082\n",
      "Epoch 3930/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1147683323.8402 - val_loss: 1515580519.2529\n",
      "Epoch 3931/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 477122079.8199 - val_loss: 1652460604.7775\n",
      "Epoch 3932/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 322919545.6792 - val_loss: 2125641559.2056\n",
      "Epoch 3933/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 656159238.8846 - val_loss: 1812257864.6053\n",
      "Epoch 3934/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 500705170.5481 - val_loss: 2653140282.9772\n",
      "Epoch 3935/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1581183552.2521 - val_loss: 1296506684.0034\n",
      "Epoch 3936/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 406816923.7141 - val_loss: 894370480.9857\n",
      "Epoch 3937/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 334410284.2859 - val_loss: 2532185709.2051\n",
      "Epoch 3938/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 530757126.1609 - val_loss: 1079572938.9907\n",
      "Epoch 3939/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 217267131.8762 - val_loss: 1478166010.7342\n",
      "Epoch 3940/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 767062195.2054 - val_loss: 1777692336.4276\n",
      "Epoch 3941/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1008151741.7490 - val_loss: 921496096.8371\n",
      "Epoch 3942/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 344679291.7321 - val_loss: 1424840965.1128\n",
      "Epoch 3943/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 414133120.6685 - val_loss: 1105044106.5767\n",
      "Epoch 3944/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 311722663.1131 - val_loss: 3809412333.5651\n",
      "Epoch 3945/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 744309664.3962 - val_loss: 1515132634.9277\n",
      "Epoch 3946/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 542974029.7670 - val_loss: 1004892911.2934\n",
      "Epoch 3947/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 615604265.9944 - val_loss: 1140148961.8813\n",
      "Epoch 3948/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 344689866.5706 - val_loss: 2333935435.2068\n",
      "Epoch 3949/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 737655731.1964 - val_loss: 1176278807.2776\n",
      "Epoch 3950/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 394228437.6455 - val_loss: 918584953.1949\n",
      "Epoch 3951/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 588986852.6730 - val_loss: 1331687214.8163\n",
      "Epoch 3952/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 298183170.9893 - val_loss: 2858261116.7955\n",
      "Epoch 3953/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 767457640.9049 - val_loss: 1489083186.1288\n",
      "Epoch 3954/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 739041413.2133 - val_loss: 960827340.3319\n",
      "Epoch 3955/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 385521942.4468 - val_loss: 898437894.1120\n",
      "Epoch 3956/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 522983798.4738 - val_loss: 1296096567.1246\n",
      "Epoch 3957/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 336020231.0467 - val_loss: 1059045608.5603\n",
      "Epoch 3958/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 356330786.7642 - val_loss: 1597272688.8416\n",
      "Epoch 3959/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1004690305.3686 - val_loss: 2223746954.4776\n",
      "Epoch 3960/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1527073191.7198 - val_loss: 3372386467.2495\n",
      "Epoch 3961/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1019623830.6911 - val_loss: 1461922685.8757\n",
      "Epoch 3962/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 428952588.6775 - val_loss: 1092719258.8602\n",
      "Epoch 3963/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 674340083.7141 - val_loss: 969152180.5682\n",
      "Epoch 3964/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 252360717.5779 - val_loss: 1033877074.5609\n",
      "Epoch 3965/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 335049950.5774 - val_loss: 4195634696.2093\n",
      "Epoch 3966/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1148398175.6669 - val_loss: 3296734215.6332\n",
      "Epoch 3967/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 526541738.8261 - val_loss: 953111301.9409\n",
      "Epoch 3968/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 268454014.6674 - val_loss: 3685815233.4942\n",
      "Epoch 3969/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 436539879.9415 - val_loss: 6267374813.8487\n",
      "Epoch 3970/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 2397190218.0124 - val_loss: 1121057200.6796\n",
      "Epoch 3971/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 549062147.6826 - val_loss: 1948778339.3755\n",
      "Epoch 3972/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 315386031.0636 - val_loss: 1002538935.3406\n",
      "Epoch 3973/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 205289051.5442 - val_loss: 1088532554.6127\n",
      "Epoch 3974/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 334489220.0563 - val_loss: 3259207957.1713\n",
      "Epoch 3975/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 350708099.9854 - val_loss: 891125297.1117\n",
      "Epoch 3976/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 284858363.1379 - val_loss: 1173871924.4985\n",
      "Epoch 3977/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 530540332.3309 - val_loss: 984113078.9446\n",
      "Epoch 3978/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 247861534.3748 - val_loss: 1240070235.9854\n",
      "Epoch 3979/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 244342677.5779 - val_loss: 955264568.8979\n",
      "Epoch 3980/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 211685986.2082 - val_loss: 935288173.8397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3981/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 244525676.7136 - val_loss: 1623449739.4498\n",
      "Epoch 3982/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1109501007.6669 - val_loss: 1020235439.2394\n",
      "Epoch 3983/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 590464748.8216 - val_loss: 1372637051.0852\n",
      "Epoch 3984/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 518121692.1283 - val_loss: 1567387262.3077\n",
      "Epoch 3985/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 597454083.7276 - val_loss: 1486881608.8394\n",
      "Epoch 3986/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 738809093.1750 - val_loss: 1397961891.3935\n",
      "Epoch 3987/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 288770874.8588 - val_loss: 1009894690.3134\n",
      "Epoch 3988/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 643074009.0310 - val_loss: 2804088964.5727\n",
      "Epoch 3989/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 691395670.4378 - val_loss: 5682002557.0115\n",
      "Epoch 3990/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 2676137332.1868 - val_loss: 1328841368.0158\n",
      "Epoch 3991/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 268860544.8284 - val_loss: 1686504789.8284\n",
      "Epoch 3992/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 413730214.5245 - val_loss: 936459984.2745\n",
      "Epoch 3993/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 204339336.8599 - val_loss: 2908949886.1997\n",
      "Epoch 3994/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 523327012.6640 - val_loss: 1070310045.3446\n",
      "Epoch 3995/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 227348975.2707 - val_loss: 1151336055.4127\n",
      "Epoch 3996/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 342960762.8948 - val_loss: 1079650802.8129\n",
      "Epoch 3997/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 284969547.3945 - val_loss: 1142824726.0174\n",
      "Epoch 3998/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 316457161.0940 - val_loss: 1117471471.9505\n",
      "Epoch 3999/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 589524004.9162 - val_loss: 1269647219.4700\n",
      "Epoch 4000/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 562132533.3033 - val_loss: 1411202102.1885\n",
      "Epoch 4001/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 422140837.2763 - val_loss: 1130333023.1449\n",
      "Epoch 4002/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 444327667.6871 - val_loss: 3161360659.6096\n",
      "Epoch 4003/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 385918637.5329 - val_loss: 1310447477.8104\n",
      "Epoch 4004/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 286377756.7361 - val_loss: 2986927055.2124\n",
      "Epoch 4005/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 835327059.7727 - val_loss: 7052520219.0762\n",
      "Epoch 4006/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 908058943.0276 - val_loss: 1845339592.9834\n",
      "Epoch 4007/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 412035621.5284 - val_loss: 1661369274.0771\n",
      "Epoch 4008/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 487936243.9347 - val_loss: 1512403610.0321\n",
      "Epoch 4009/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 483346092.8216 - val_loss: 1822506039.2686\n",
      "Epoch 4010/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1515725899.9122 - val_loss: 2323270664.1193\n",
      "Epoch 4011/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 432880795.1649 - val_loss: 969095943.9932\n",
      "Epoch 4012/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 211725394.4041 - val_loss: 1348457132.1924\n",
      "Epoch 4013/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 291305465.6702 - val_loss: 1713569228.9080\n",
      "Epoch 4014/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 312101546.4806 - val_loss: 1228545086.3077\n",
      "Epoch 4015/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 338418888.9589 - val_loss: 980223970.8714\n",
      "Epoch 4016/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 357144678.1407 - val_loss: 5171134558.1187\n",
      "Epoch 4017/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 981757136.4592 - val_loss: 7875193619.6591\n",
      "Epoch 4018/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 1198240790.0416 - val_loss: 1141151774.6498\n",
      "Epoch 4019/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 511848779.5971 - val_loss: 1286423887.9145\n",
      "Epoch 4020/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 305353928.5718 - val_loss: 1003277911.5027\n",
      "Epoch 4021/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 358639785.2741 - val_loss: 1654420206.9513\n",
      "Epoch 4022/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 342512030.5256 - val_loss: 1039554630.0489\n",
      "Epoch 4023/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 255921617.2515 - val_loss: 2473308283.1392\n",
      "Epoch 4024/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 761805932.0113 - val_loss: 1110466490.3021\n",
      "Epoch 4025/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 225524461.1908 - val_loss: 1317646824.7674\n",
      "Epoch 4026/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 504774444.2904 - val_loss: 1418967681.1522\n",
      "Epoch 4027/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 564284108.0473 - val_loss: 3972190459.1752\n",
      "Epoch 4028/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1303572367.8514 - val_loss: 3839872265.5775\n",
      "Epoch 4029/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 731461712.7833 - val_loss: 2785376135.2731\n",
      "Epoch 4030/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 402884497.3596 - val_loss: 937658207.6219\n",
      "Epoch 4031/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 214923044.6280 - val_loss: 916823015.6242\n",
      "Epoch 4032/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 242313593.4451 - val_loss: 2301560650.4506\n",
      "Epoch 4033/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 780444899.4237 - val_loss: 1066953830.9041\n",
      "Epoch 4034/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 198494188.4615 - val_loss: 892700158.5598\n",
      "Epoch 4035/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 259414332.9207 - val_loss: 1123857297.9758\n",
      "Epoch 4036/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 516323447.6984 - val_loss: 1118540304.7786\n",
      "Epoch 4037/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 514390775.8244 - val_loss: 2569592935.8582\n",
      "Epoch 4038/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 417045009.7738 - val_loss: 941305117.4346\n",
      "Epoch 4039/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 324008231.7974 - val_loss: 1121773203.0110\n",
      "Epoch 4040/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 513521080.4277 - val_loss: 1033842039.2686\n",
      "Epoch 4041/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 390807631.0906 - val_loss: 960498363.6613\n",
      "Epoch 4042/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 317721286.0867 - val_loss: 2721782295.1876\n",
      "Epoch 4043/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 782132676.7631 - val_loss: 1804337789.4616\n",
      "Epoch 4044/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 591983667.9347 - val_loss: 1554695419.3193\n",
      "Epoch 4045/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 910670861.6275 - val_loss: 2741998478.7623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4046/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 832118412.2724 - val_loss: 4998754908.8945\n",
      "Epoch 4047/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1413652202.8182 - val_loss: 1017616091.7963\n",
      "Epoch 4048/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 309025454.1722 - val_loss: 1210690000.3286\n",
      "Epoch 4049/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 416458901.9516 - val_loss: 1076784007.8132\n",
      "Epoch 4050/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 408148300.2532 - val_loss: 982688124.2644\n",
      "Epoch 4051/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 240737452.2746 - val_loss: 916967086.9693\n",
      "Epoch 4052/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 239150953.3101 - val_loss: 2795937330.5879\n",
      "Epoch 4053/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1285690854.0687 - val_loss: 6992961730.1423\n",
      "Epoch 4054/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1246154416.4772 - val_loss: 1752060322.8084\n",
      "Epoch 4055/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 361192092.3534 - val_loss: 1001806340.1586\n",
      "Epoch 4056/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 309644741.5104 - val_loss: 2395404688.7786\n",
      "Epoch 4057/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 620505558.7440 - val_loss: 901035677.9927\n",
      "Epoch 4058/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 401355654.8633 - val_loss: 997293975.0976\n",
      "Epoch 4059/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 276264567.9325 - val_loss: 1219622630.4000\n",
      "Epoch 4060/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 411467079.4373 - val_loss: 1049515554.4484\n",
      "Epoch 4061/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 556164517.0332 - val_loss: 1042105546.5586\n",
      "Epoch 4062/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 212931575.9865 - val_loss: 1935016416.3150\n",
      "Epoch 4063/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 411229127.3292 - val_loss: 974272759.8627\n",
      "Epoch 4064/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 354038853.4024 - val_loss: 1081347424.5131\n",
      "Epoch 4065/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 425138876.3444 - val_loss: 1453897924.1586\n",
      "Epoch 4066/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 792887376.6213 - val_loss: 2984402609.2917\n",
      "Epoch 4067/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 860425766.8340 - val_loss: 1445361401.8070\n",
      "Epoch 4068/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 216608342.8340 - val_loss: 2479764071.7682\n",
      "Epoch 4069/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 518578870.6719 - val_loss: 1733824759.0166\n",
      "Epoch 4070/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 748948619.3720 - val_loss: 944807465.8205\n",
      "Epoch 4071/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 252139378.9994 - val_loss: 890901872.4096\n",
      "Epoch 4072/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 266704354.3050 - val_loss: 1444487845.8059\n",
      "Epoch 4073/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 314171910.9150 - val_loss: 1400298924.3949\n",
      "Epoch 4074/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 559814662.0326 - val_loss: 1595712203.8098\n",
      "Epoch 4075/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 579088758.4558 - val_loss: 1223529171.8436\n",
      "Epoch 4076/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 634764835.5836 - val_loss: 1221136257.1882\n",
      "Epoch 4077/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 646961763.9530 - val_loss: 933395417.7890\n",
      "Epoch 4078/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 452718095.7749 - val_loss: 1279722339.0515\n",
      "Epoch 4079/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 917837135.3067 - val_loss: 3001042058.4776\n",
      "Epoch 4080/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 815806635.0028 - val_loss: 1601286265.6630\n",
      "Epoch 4081/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 397572807.2482 - val_loss: 882676226.1423\n",
      "Epoch 4082/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 228157356.5875 - val_loss: 977862274.4124\n",
      "Epoch 4083/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 547881222.1407 - val_loss: 967843685.2118\n",
      "Epoch 4084/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 596391626.3365 - val_loss: 13908497099.7198\n",
      "Epoch 4085/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 3457735079.0321 - val_loss: 976636044.9980\n",
      "Epoch 4086/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 267518119.4733 - val_loss: 1327740293.2208\n",
      "Epoch 4087/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 553762653.3078 - val_loss: 974004680.5873\n",
      "Epoch 4088/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 276867965.9111 - val_loss: 1000189696.6931\n",
      "Epoch 4089/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 214387112.0135 - val_loss: 1907792226.9255\n",
      "Epoch 4090/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 370607605.7355 - val_loss: 930255980.3049\n",
      "Epoch 4091/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 277628675.6736 - val_loss: 4997546325.8734\n",
      "Epoch 4092/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 737065197.2898 - val_loss: 1084932355.2045\n",
      "Epoch 4093/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 302995330.6607 - val_loss: 919527607.7547\n",
      "Epoch 4094/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 299014040.9499 - val_loss: 2446524932.1046\n",
      "Epoch 4095/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 1298373893.8120 - val_loss: 1006233237.6124\n",
      "Epoch 4096/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 255883363.1784 - val_loss: 2263245583.1944\n",
      "Epoch 4097/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 360119442.4761 - val_loss: 909236006.7691\n",
      "Epoch 4098/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 269723260.6505 - val_loss: 1500456502.2605\n",
      "Epoch 4099/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1060231018.7957 - val_loss: 1059053447.8852\n",
      "Epoch 4100/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 392466433.1345 - val_loss: 1780284790.9626\n",
      "Epoch 4101/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 490994200.2251 - val_loss: 884237403.1122\n",
      "Epoch 4102/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 206263688.5898 - val_loss: 927249296.9226\n",
      "Epoch 4103/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 524377281.0445 - val_loss: 1160841319.0481\n",
      "Epoch 4104/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 337513518.5504 - val_loss: 1188917880.8979\n",
      "Epoch 4105/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 912501859.8357 - val_loss: 2004046421.6304\n",
      "Epoch 4106/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 606968157.0287 - val_loss: 940359112.5153\n",
      "Epoch 4107/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 261342997.1232 - val_loss: 859573063.5162\n",
      "Epoch 4108/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 213131927.4192 - val_loss: 898664227.1415\n",
      "Epoch 4109/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 312033386.7507 - val_loss: 3456037169.5257\n",
      "Epoch 4110/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1337466232.6348 - val_loss: 1926145544.8574\n",
      "Epoch 4111/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 84us/step - loss: 391123899.8154 - val_loss: 1699510563.2855\n",
      "Epoch 4112/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 297808401.5397 - val_loss: 1195375634.5969\n",
      "Epoch 4113/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 433403810.7079 - val_loss: 1016080616.6323\n",
      "Epoch 4114/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 669020763.0929 - val_loss: 1019838236.4084\n",
      "Epoch 4115/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 522171602.1159 - val_loss: 1115165459.3845\n",
      "Epoch 4116/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 390556327.6894 - val_loss: 12191358467.2405\n",
      "Epoch 4117/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1584134115.4800 - val_loss: 1238886773.9364\n",
      "Epoch 4118/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 570144978.6922 - val_loss: 1461087079.9842\n",
      "Epoch 4119/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 719735901.8931 - val_loss: 1308742658.3764\n",
      "Epoch 4120/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 340352138.8047 - val_loss: 1416160797.2456\n",
      "Epoch 4121/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 388534935.2673 - val_loss: 1170203218.2008\n",
      "Epoch 4122/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 268988307.4710 - val_loss: 1051860502.9716\n",
      "Epoch 4123/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 425583922.6382 - val_loss: 4579002575.6444\n",
      "Epoch 4124/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 650909779.3405 - val_loss: 979617677.2141\n",
      "Epoch 4125/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 630063444.4569 - val_loss: 1116702700.0349\n",
      "Epoch 4126/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 415113247.6533 - val_loss: 1564390020.6897\n",
      "Epoch 4127/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 693270831.9325 - val_loss: 873913817.9060\n",
      "Epoch 4128/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 615797003.4080 - val_loss: 3834865826.0253\n",
      "Epoch 4129/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 852482504.5537 - val_loss: 1105129677.8532\n",
      "Epoch 4130/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 280316920.7608 - val_loss: 1063533658.3471\n",
      "Epoch 4131/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 509084759.4463 - val_loss: 1368653294.8793\n",
      "Epoch 4132/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 705649903.2527 - val_loss: 2981653671.4442\n",
      "Epoch 4133/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1015814061.9201 - val_loss: 1493409225.6180\n",
      "Epoch 4134/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 623139152.3151 - val_loss: 1726191442.0478\n",
      "Epoch 4135/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 511006777.3731 - val_loss: 1552173402.0231\n",
      "Epoch 4136/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 265164644.4299 - val_loss: 1055754906.1761\n",
      "Epoch 4137/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 305125754.4896 - val_loss: 1000739173.5989\n",
      "Epoch 4138/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 215332362.3005 - val_loss: 1062082233.6990\n",
      "Epoch 4139/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 309409009.0174 - val_loss: 952099102.2087\n",
      "Epoch 4140/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 629046683.1199 - val_loss: 2277925092.7797\n",
      "Epoch 4141/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 417673347.0433 - val_loss: 992342782.0287\n",
      "Epoch 4142/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 274747526.7530 - val_loss: 3490196775.9662\n",
      "Epoch 4143/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 715876609.5847 - val_loss: 972361530.2841\n",
      "Epoch 4144/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 867888747.9212 - val_loss: 1121763801.9871\n",
      "Epoch 4145/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 397081888.7023 - val_loss: 1364716880.2925\n",
      "Epoch 4146/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 503100814.8520 - val_loss: 4425458708.8113\n",
      "Epoch 4147/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 386712207.5678 - val_loss: 1018219395.6726\n",
      "Epoch 4148/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 324987171.0433 - val_loss: 1753887241.1094\n",
      "Epoch 4149/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 899052042.2285 - val_loss: 1226209052.3364\n",
      "Epoch 4150/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 368504857.5779 - val_loss: 1929784315.3103\n",
      "Epoch 4151/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 272812704.4862 - val_loss: 1506161608.5063\n",
      "Epoch 4152/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 804158084.2859 - val_loss: 4075731056.1935\n",
      "Epoch 4153/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1018131868.0563 - val_loss: 1982453525.5314\n",
      "Epoch 4154/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 398010152.1216 - val_loss: 3207103486.0557\n",
      "Epoch 4155/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1037344566.7259 - val_loss: 2111833948.2194\n",
      "Epoch 4156/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 501237408.9949 - val_loss: 1459897679.1494\n",
      "Epoch 4157/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 187301210.2555 - val_loss: 1326185840.2475\n",
      "Epoch 4158/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 354740309.6095 - val_loss: 1066615557.5089\n",
      "Epoch 4159/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 296841231.2414 - val_loss: 1508432837.8869\n",
      "Epoch 4160/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 522161151.6128 - val_loss: 1725347326.0197\n",
      "Epoch 4161/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 330903754.6967 - val_loss: 1218412613.8824\n",
      "Epoch 4162/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 637843283.1964 - val_loss: 1056339921.4987\n",
      "Epoch 4163/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 375034215.7254 - val_loss: 1498957831.7232\n",
      "Epoch 4164/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 944607263.2617 - val_loss: 1265301017.2399\n",
      "Epoch 4165/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 480519266.8182 - val_loss: 1667232703.7300\n",
      "Epoch 4166/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 385178221.5869 - val_loss: 1203390071.6017\n",
      "Epoch 4167/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 590373561.7153 - val_loss: 1657369409.2422\n",
      "Epoch 4168/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 295893996.9252 - val_loss: 1106082749.7857\n",
      "Epoch 4169/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 317126915.3855 - val_loss: 1121878982.3910\n",
      "Epoch 4170/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 410128205.7456 - val_loss: 941266679.8807\n",
      "Epoch 4171/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 769916204.1913 - val_loss: 1167968353.8903\n",
      "Epoch 4172/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 271873445.6365 - val_loss: 2270193725.7857\n",
      "Epoch 4173/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 735477910.2577 - val_loss: 1173252782.8613\n",
      "Epoch 4174/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 431679141.6488 - val_loss: 967872610.1333\n",
      "Epoch 4175/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 717968480.7440 - val_loss: 1644194339.3035\n",
      "Epoch 4176/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 97us/step - loss: 433026782.4356 - val_loss: 1330581056.0180\n",
      "Epoch 4177/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 377563160.7608 - val_loss: 2003866055.8132\n",
      "Epoch 4178/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 299544347.6601 - val_loss: 3538545379.9876\n",
      "Epoch 4179/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 588267772.5425 - val_loss: 1459670249.1094\n",
      "Epoch 4180/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 417548575.3697 - val_loss: 1033630185.2985\n",
      "Epoch 4181/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 480385659.6061 - val_loss: 3447552583.1471\n",
      "Epoch 4182/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1590791708.9207 - val_loss: 2817182969.4470\n",
      "Epoch 4183/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 523074573.6140 - val_loss: 4250049756.8585\n",
      "Epoch 4184/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 591893245.4789 - val_loss: 2041917039.2934\n",
      "Epoch 4185/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 786104510.4288 - val_loss: 881266044.5885\n",
      "Epoch 4186/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 185256498.0979 - val_loss: 1036601043.6951\n",
      "Epoch 4187/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 291967086.7803 - val_loss: 1248980535.8807\n",
      "Epoch 4188/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 268206038.7710 - val_loss: 980819763.6141\n",
      "Epoch 4189/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 660654881.2245 - val_loss: 1394467762.4619\n",
      "Epoch 4190/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 765469469.9471 - val_loss: 1219751810.6284\n",
      "Epoch 4191/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 511516684.0293 - val_loss: 4445442881.6293\n",
      "Epoch 4192/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 536049388.8396 - val_loss: 1004013100.5030\n",
      "Epoch 4193/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 687286713.0040 - val_loss: 975411642.2571\n",
      "Epoch 4194/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 272953929.2560 - val_loss: 1356575243.0897\n",
      "Epoch 4195/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 322862425.2470 - val_loss: 1000626915.9876\n",
      "Epoch 4196/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 351903066.5796 - val_loss: 1273297039.4104\n",
      "Epoch 4197/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 489559342.5324 - val_loss: 2247623678.9378\n",
      "Epoch 4198/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 374152076.2690 - val_loss: 2908560831.3879\n",
      "Epoch 4199/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 1170226066.0799 - val_loss: 2689965521.9128\n",
      "Epoch 4200/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 776497218.5931 - val_loss: 3022476458.6307\n",
      "Epoch 4201/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 496720035.2009 - val_loss: 2036587227.5083\n",
      "Epoch 4202/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 318079322.5796 - val_loss: 1089040978.8129\n",
      "Epoch 4203/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 356239769.0310 - val_loss: 1153025977.0149\n",
      "Epoch 4204/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 828815454.8655 - val_loss: 11660124680.9294\n",
      "Epoch 4205/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1462707018.0124 - val_loss: 1120373053.0295\n",
      "Epoch 4206/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 350464175.8289 - val_loss: 1411409116.7145\n",
      "Epoch 4207/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 732300122.1474 - val_loss: 1634526201.7350\n",
      "Epoch 4208/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 445137182.3613 - val_loss: 1283342178.9795\n",
      "Epoch 4209/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 376897299.0523 - val_loss: 961342813.6686\n",
      "Epoch 4210/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 285023283.9910 - val_loss: 958920701.6866\n",
      "Epoch 4211/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 312369333.0332 - val_loss: 1450738950.1930\n",
      "Epoch 4212/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 432310016.8644 - val_loss: 1205406387.6321\n",
      "Epoch 4213/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 705668357.8346 - val_loss: 1833149498.8647\n",
      "Epoch 4214/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 269432661.1683 - val_loss: 1291399846.8321\n",
      "Epoch 4215/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 470272162.5031 - val_loss: 2817328673.4492\n",
      "Epoch 4216/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 437182667.7231 - val_loss: 913801635.2855\n",
      "Epoch 4217/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 374006744.7023 - val_loss: 1922183663.8515\n",
      "Epoch 4218/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 767229359.3247 - val_loss: 1597967007.7570\n",
      "Epoch 4219/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 737986126.7901 - val_loss: 1011246884.7977\n",
      "Epoch 4220/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 220386977.9629 - val_loss: 1250763124.9463\n",
      "Epoch 4221/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 798058153.7153 - val_loss: 1153009206.7195\n",
      "Epoch 4222/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 304160931.8717 - val_loss: 2429464924.6785\n",
      "Epoch 4223/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 723230311.5093 - val_loss: 1325512004.5187\n",
      "Epoch 4224/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 378883103.3337 - val_loss: 1663229627.7108\n",
      "Epoch 4225/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1261281013.7715 - val_loss: 2096608909.7451\n",
      "Epoch 4226/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 529983052.8126 - val_loss: 1038331522.6284\n",
      "Epoch 4227/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 453043722.4806 - val_loss: 1222228858.7972\n",
      "Epoch 4228/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 331894404.9252 - val_loss: 1678626498.3584\n",
      "Epoch 4229/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 484725175.2032 - val_loss: 945798094.4923\n",
      "Epoch 4230/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 290792243.9347 - val_loss: 1336819856.5626\n",
      "Epoch 4231/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 275548472.6258 - val_loss: 1571379441.9578\n",
      "Epoch 4232/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 360986216.8779 - val_loss: 2271873928.5693\n",
      "Epoch 4233/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 678930733.0197 - val_loss: 1064810084.9058\n",
      "Epoch 4234/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 875597510.7856 - val_loss: 1048029455.2664\n",
      "Epoch 4235/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 934553036.9432 - val_loss: 3904979583.4599\n",
      "Epoch 4236/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 826612348.2814 - val_loss: 1174872040.5873\n",
      "Epoch 4237/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 392142320.7653 - val_loss: 1649136131.3125\n",
      "Epoch 4238/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 345534806.3838 - val_loss: 1606292729.5910\n",
      "Epoch 4239/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 450981738.9488 - val_loss: 1341129123.9426\n",
      "Epoch 4240/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 373818274.7867 - val_loss: 1038602281.0824\n",
      "Epoch 4241/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 82us/step - loss: 255588968.4997 - val_loss: 1506818158.7713\n",
      "Epoch 4242/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 361292052.4930 - val_loss: 1755164272.8416\n",
      "Epoch 4243/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 351505753.5217 - val_loss: 1150767727.8875\n",
      "Epoch 4244/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 544186543.9235 - val_loss: 1699151155.9921\n",
      "Epoch 4245/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 425874564.4299 - val_loss: 3004610222.8433\n",
      "Epoch 4246/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1064163309.1277 - val_loss: 7616737801.0014\n",
      "Epoch 4247/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1023254698.8768 - val_loss: 944189397.3873\n",
      "Epoch 4248/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 293508227.5926 - val_loss: 929463566.6093\n",
      "Epoch 4249/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 290092788.5290 - val_loss: 2614743800.0788\n",
      "Epoch 4250/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 345376232.7023 - val_loss: 1127785755.7963\n",
      "Epoch 4251/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 330382484.1531 - val_loss: 1109189727.1629\n",
      "Epoch 4252/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 389230331.0478 - val_loss: 1459827428.3117\n",
      "Epoch 4253/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 850558362.1474 - val_loss: 9592627057.2737\n",
      "Epoch 4254/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 3691642074.7597 - val_loss: 1216381896.0833\n",
      "Epoch 4255/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 559482739.9887 - val_loss: 986525049.4830\n",
      "Epoch 4256/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 242508803.1514 - val_loss: 1050709718.9356\n",
      "Epoch 4257/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 241332367.2549 - val_loss: 954332536.2408\n",
      "Epoch 4258/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 309477642.5886 - val_loss: 1925965631.9820\n",
      "Epoch 4259/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1755608102.7530 - val_loss: 1398919521.1072\n",
      "Epoch 4260/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 349776674.2420 - val_loss: 945842055.8582\n",
      "Epoch 4261/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 222855175.2122 - val_loss: 1001768901.4008\n",
      "Epoch 4262/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 454966480.4772 - val_loss: 2264610420.5142\n",
      "Epoch 4263/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 629845753.7333 - val_loss: 1813667751.9302\n",
      "Epoch 4264/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 550614323.8627 - val_loss: 980631011.8076\n",
      "Epoch 4265/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 251381108.9882 - val_loss: 1066469800.4253\n",
      "Epoch 4266/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 227276883.9122 - val_loss: 1181602527.5049\n",
      "Epoch 4267/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1132420127.6939 - val_loss: 4789856564.9103\n",
      "Epoch 4268/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 917647732.2589 - val_loss: 6828796961.9893\n",
      "Epoch 4269/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2975069764.8621 - val_loss: 961615774.8478\n",
      "Epoch 4270/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 172842267.2684 - val_loss: 1105039901.1286\n",
      "Epoch 4271/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 215864379.1199 - val_loss: 897769560.2858\n",
      "Epoch 4272/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 532052178.1024 - val_loss: 1620979555.9876\n",
      "Epoch 4273/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 268109911.5993 - val_loss: 864729821.1466\n",
      "Epoch 4274/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 176192836.2859 - val_loss: 4015852687.9955\n",
      "Epoch 4275/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 2643421240.3647 - val_loss: 2378876871.3992\n",
      "Epoch 4276/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 462841413.2043 - val_loss: 864018089.6945\n",
      "Epoch 4277/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 161705626.7417 - val_loss: 923995846.3370\n",
      "Epoch 4278/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 390834184.7113 - val_loss: 1232868132.1496\n",
      "Epoch 4279/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 324916101.6185 - val_loss: 1815733545.2624\n",
      "Epoch 4280/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 408099800.9432 - val_loss: 903868856.2228\n",
      "Epoch 4281/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 135317077.6095 - val_loss: 890997386.1356\n",
      "Epoch 4282/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 240115791.3945 - val_loss: 844418782.9288\n",
      "Epoch 4283/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 162863687.0636 - val_loss: 1248504237.4391\n",
      "Epoch 4284/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 475494612.1216 - val_loss: 987830004.8833\n",
      "Epoch 4285/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 201077322.6517 - val_loss: 853455682.7544\n",
      "Epoch 4286/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 864140049.1435 - val_loss: 4853717737.4605\n",
      "Epoch 4287/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 3061096479.4980 - val_loss: 1204472142.3572\n",
      "Epoch 4288/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 218912066.8723 - val_loss: 919264422.7060\n",
      "Epoch 4289/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 222617139.3495 - val_loss: 1518757333.8464\n",
      "Epoch 4290/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 266534913.5892 - val_loss: 1011845266.4079\n",
      "Epoch 4291/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 258961188.9904 - val_loss: 992502603.6838\n",
      "Epoch 4292/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 164601606.9150 - val_loss: 1565945916.4354\n",
      "Epoch 4293/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 419993850.0574 - val_loss: 2397045290.7747\n",
      "Epoch 4294/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1068045660.3984 - val_loss: 919000485.1938\n",
      "Epoch 4295/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 312408630.9240 - val_loss: 2079486763.4228\n",
      "Epoch 4296/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 827981805.1638 - val_loss: 1098343212.7190\n",
      "Epoch 4297/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 335787763.5385 - val_loss: 1229402973.9027\n",
      "Epoch 4298/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 496279394.0799 - val_loss: 1323081737.5685\n",
      "Epoch 4299/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 319251218.0169 - val_loss: 2070892317.9567\n",
      "Epoch 4300/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 270938791.0411 - val_loss: 1334294840.0248\n",
      "Epoch 4301/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 261616200.0791 - val_loss: 983344640.7651\n",
      "Epoch 4302/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 347528448.5402 - val_loss: 1607110032.2295\n",
      "Epoch 4303/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 287817729.7648 - val_loss: 1154671293.1015\n",
      "Epoch 4304/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 252626730.3883 - val_loss: 1106372041.9015\n",
      "Epoch 4305/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 875569589.1593 - val_loss: 1283862374.4720\n",
      "Epoch 4306/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1449259538.9443 - val_loss: 2158494680.5558\n",
      "Epoch 4307/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1225249218.9679 - val_loss: 968484164.4332\n",
      "Epoch 4308/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 195530875.4620 - val_loss: 901503012.9598\n",
      "Epoch 4309/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 244406756.8441 - val_loss: 1048888729.7935\n",
      "Epoch 4310/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 460490031.7299 - val_loss: 957879026.3449\n",
      "Epoch 4311/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 968816678.3208 - val_loss: 1453714013.7947\n",
      "Epoch 4312/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1081814909.0310 - val_loss: 982355480.3488\n",
      "Epoch 4313/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 242419090.3140 - val_loss: 875008295.7232\n",
      "Epoch 4314/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 223289735.7254 - val_loss: 1098194343.7142\n",
      "Epoch 4315/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 799486524.4367 - val_loss: 1194090391.7817\n",
      "Epoch 4316/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 354371976.5718 - val_loss: 1406622823.3316\n",
      "Epoch 4317/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 491227439.6488 - val_loss: 1722722265.7080\n",
      "Epoch 4318/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 847282150.0687 - val_loss: 2798363367.8143\n",
      "Epoch 4319/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 510508135.2887 - val_loss: 887799407.9775\n",
      "Epoch 4320/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 707190898.9668 - val_loss: 1366019686.3280\n",
      "Epoch 4321/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 686500629.4609 - val_loss: 1042242104.1688\n",
      "Epoch 4322/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 402161007.0332 - val_loss: 1742088688.7336\n",
      "Epoch 4323/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 280773529.8863 - val_loss: 912589106.9300\n",
      "Epoch 4324/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 206735628.5335 - val_loss: 1211910140.7505\n",
      "Epoch 4325/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 337120846.9195 - val_loss: 931870894.5553\n",
      "Epoch 4326/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 205030055.7254 - val_loss: 2233257692.2824\n",
      "Epoch 4327/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 375836323.9077 - val_loss: 2228816752.9857\n",
      "Epoch 4328/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 336150446.7304 - val_loss: 849242180.6267\n",
      "Epoch 4329/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 343947477.0512 - val_loss: 1166439493.2028\n",
      "Epoch 4330/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 350896241.2741 - val_loss: 2566415695.4284\n",
      "Epoch 4331/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 774039592.9589 - val_loss: 1146831410.9615\n",
      "Epoch 4332/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 440694647.5003 - val_loss: 1823937714.4439\n",
      "Epoch 4333/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1563669532.1283 - val_loss: 888032668.2644\n",
      "Epoch 4334/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 300042517.8255 - val_loss: 1053730226.2999\n",
      "Epoch 4335/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 238498577.5847 - val_loss: 859334867.9291\n",
      "Epoch 4336/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 479128707.1334 - val_loss: 1193309993.7665\n",
      "Epoch 4337/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 368215588.6640 - val_loss: 921308586.1626\n",
      "Epoch 4338/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 256628430.1182 - val_loss: 1417203688.2363\n",
      "Epoch 4339/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 989815049.7243 - val_loss: 990252086.3325\n",
      "Epoch 4340/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 407011391.6522 - val_loss: 924823486.9153\n",
      "Epoch 4341/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 230356415.6038 - val_loss: 1181128198.9131\n",
      "Epoch 4342/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 835079807.4237 - val_loss: 2116662379.5848\n",
      "Epoch 4343/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1244146758.1587 - val_loss: 2149237003.8819\n",
      "Epoch 4344/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 587865799.5993 - val_loss: 917274028.6470\n",
      "Epoch 4345/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 324766721.0625 - val_loss: 949228463.8695\n",
      "Epoch 4346/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 194725341.0917 - val_loss: 882972886.8456\n",
      "Epoch 4347/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 236684360.7518 - val_loss: 1835685652.6312\n",
      "Epoch 4348/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 635091250.6607 - val_loss: 2060675971.4520\n",
      "Epoch 4349/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1073599882.3545 - val_loss: 1212822571.3418\n",
      "Epoch 4350/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 744196743.5813 - val_loss: 1427774572.2959\n",
      "Epoch 4351/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 267532376.3467 - val_loss: 1635167643.5443\n",
      "Epoch 4352/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 287231738.3455 - val_loss: 1734817864.8754\n",
      "Epoch 4353/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 623948876.3534 - val_loss: 1381266378.9907\n",
      "Epoch 4354/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 449917162.3905 - val_loss: 860928338.9300\n",
      "Epoch 4355/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 232406853.7085 - val_loss: 1571629316.7887\n",
      "Epoch 4356/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 409110764.7451 - val_loss: 2777945332.2262\n",
      "Epoch 4357/10000\n",
      "3554/3554 [==============================] - 1s 142us/step - loss: 1124333711.3427 - val_loss: 6030072319.8560\n",
      "Epoch 4358/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1410005290.3185 - val_loss: 1074403371.3508\n",
      "Epoch 4359/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 343940467.8177 - val_loss: 930650452.0371\n",
      "Epoch 4360/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 197641821.7310 - val_loss: 947256201.6495\n",
      "Epoch 4361/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 258883544.9612 - val_loss: 895961184.8911\n",
      "Epoch 4362/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 414494073.6612 - val_loss: 999304459.4768\n",
      "Epoch 4363/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 662189923.3461 - val_loss: 3127525300.0506\n",
      "Epoch 4364/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 282194566.8970 - val_loss: 879626949.7609\n",
      "Epoch 4365/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 260927154.7034 - val_loss: 1332188712.9024\n",
      "Epoch 4366/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 299216345.6432 - val_loss: 2113278745.2039\n",
      "Epoch 4367/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1207946143.1806 - val_loss: 916466550.8726\n",
      "Epoch 4368/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 294115374.0732 - val_loss: 1195479795.6321\n",
      "Epoch 4369/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 263357659.2999 - val_loss: 1540198356.5232\n",
      "Epoch 4370/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 376795980.7586 - val_loss: 1031754969.7530\n",
      "Epoch 4371/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 89us/step - loss: 331790038.7980 - val_loss: 1361018971.8864\n",
      "Epoch 4372/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 251903101.6657 - val_loss: 1653899373.7091\n",
      "Epoch 4373/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 447643583.0456 - val_loss: 1322434531.6276\n",
      "Epoch 4374/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 2006240579.8537 - val_loss: 3325211627.5488\n",
      "Epoch 4375/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1341867401.3281 - val_loss: 1713960379.1392\n",
      "Epoch 4376/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 509020693.5104 - val_loss: 1662838551.0076\n",
      "Epoch 4377/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 375759749.5374 - val_loss: 906634548.0281\n",
      "Epoch 4378/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 362599424.0900 - val_loss: 1315618138.8062\n",
      "Epoch 4379/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 326138725.5104 - val_loss: 1754020052.1271\n",
      "Epoch 4380/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 449748384.7338 - val_loss: 1617926965.9364\n",
      "Epoch 4381/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 965135017.7062 - val_loss: 1122014148.7347\n",
      "Epoch 4382/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 442384214.9961 - val_loss: 1014667368.9204\n",
      "Epoch 4383/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 219268242.4581 - val_loss: 975371189.8284\n",
      "Epoch 4384/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 202503513.0670 - val_loss: 1074501168.9857\n",
      "Epoch 4385/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 307236406.5639 - val_loss: 1734165684.7122\n",
      "Epoch 4386/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 508243321.3731 - val_loss: 4460103674.6712\n",
      "Epoch 4387/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 1822053855.5543 - val_loss: 1388336949.9364\n",
      "Epoch 4388/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 249410797.7175 - val_loss: 944220505.1499\n",
      "Epoch 4389/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 203100772.7164 - val_loss: 1115634473.5415\n",
      "Epoch 4390/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 375492828.7766 - val_loss: 3064312893.8577\n",
      "Epoch 4391/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2026224378.8858 - val_loss: 1995915929.3480\n",
      "Epoch 4392/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 393773980.5065 - val_loss: 911693451.6928\n",
      "Epoch 4393/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 246508724.0253 - val_loss: 1040309859.5195\n",
      "Epoch 4394/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 437247986.4266 - val_loss: 910521864.3893\n",
      "Epoch 4395/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 205549313.9133 - val_loss: 957291559.8852\n",
      "Epoch 4396/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 295338869.9516 - val_loss: 1862667890.5609\n",
      "Epoch 4397/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 635853752.5132 - val_loss: 1436077532.5705\n",
      "Epoch 4398/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 299110187.4170 - val_loss: 2295583899.7603\n",
      "Epoch 4399/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 519342655.0366 - val_loss: 1749149262.9243\n",
      "Epoch 4400/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 698127838.0011 - val_loss: 1031229267.0830\n",
      "Epoch 4401/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 441347285.9032 - val_loss: 2734716772.0236\n",
      "Epoch 4402/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 356688427.0028 - val_loss: 1183106075.0942\n",
      "Epoch 4403/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 401487878.2487 - val_loss: 1005009099.3058\n",
      "Epoch 4404/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 362728645.1503 - val_loss: 1743877735.9842\n",
      "Epoch 4405/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 598820009.2606 - val_loss: 1325015610.4011\n",
      "Epoch 4406/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 273905814.6899 - val_loss: 1124423901.0925\n",
      "Epoch 4407/10000\n",
      "3554/3554 [==============================] - 1s 146us/step - loss: 268060253.8931 - val_loss: 1148782220.1519\n",
      "Epoch 4408/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 387579916.7856 - val_loss: 1194854770.6419\n",
      "Epoch 4409/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 869541797.0298 - val_loss: 1038644145.6338\n",
      "Epoch 4410/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 218077113.9133 - val_loss: 846063884.8720\n",
      "Epoch 4411/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 287797062.2814 - val_loss: 1135647524.6537\n",
      "Epoch 4412/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 321269721.3191 - val_loss: 1051794963.7671\n",
      "Epoch 4413/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 705587103.5138 - val_loss: 1004285203.4250\n",
      "Epoch 4414/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 332501465.6432 - val_loss: 4086181374.0467\n",
      "Epoch 4415/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 711803799.3742 - val_loss: 2831789004.5840\n",
      "Epoch 4416/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 695849711.9190 - val_loss: 1047366649.8610\n",
      "Epoch 4417/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 569463088.0732 - val_loss: 1474314900.6492\n",
      "Epoch 4418/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1059980948.3849 - val_loss: 7329393356.8720\n",
      "Epoch 4419/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1405337600.5042 - val_loss: 2523666937.4470\n",
      "Epoch 4420/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 382333916.4615 - val_loss: 972504784.0225\n",
      "Epoch 4421/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 270215754.5976 - val_loss: 1642778605.5561\n",
      "Epoch 4422/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 335534421.2133 - val_loss: 981413269.8194\n",
      "Epoch 4423/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 431888449.4721 - val_loss: 851857989.7249\n",
      "Epoch 4424/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 166899072.3692 - val_loss: 1023908644.0236\n",
      "Epoch 4425/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 397123634.4221 - val_loss: 1217612843.6388\n",
      "Epoch 4426/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 487761660.3984 - val_loss: 9613388840.0383\n",
      "Epoch 4427/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1472325043.8807 - val_loss: 2265479120.6886\n",
      "Epoch 4428/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 481743566.1182 - val_loss: 1832667289.4110\n",
      "Epoch 4429/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 264768031.6579 - val_loss: 1473978820.5907\n",
      "Epoch 4430/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1605452562.0439 - val_loss: 1923247966.0467\n",
      "Epoch 4431/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 257838779.2999 - val_loss: 937846272.1440\n",
      "Epoch 4432/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 229697736.1576 - val_loss: 1399242604.8450\n",
      "Epoch 4433/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 325369113.6342 - val_loss: 1428003066.3111\n",
      "Epoch 4434/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 412129389.4519 - val_loss: 2380494079.4959\n",
      "Epoch 4435/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 913792116.8981 - val_loss: 2545397750.2065\n",
      "Epoch 4436/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 93us/step - loss: 429601803.9662 - val_loss: 882917907.1190\n",
      "Epoch 4437/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 369388221.1187 - val_loss: 963426433.6743\n",
      "Epoch 4438/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 347160321.3866 - val_loss: 850009459.3440\n",
      "Epoch 4439/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 286714881.8908 - val_loss: 1172499613.6956\n",
      "Epoch 4440/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 297595708.7226 - val_loss: 1217881904.9136\n",
      "Epoch 4441/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 355098753.1705 - val_loss: 928378830.5283\n",
      "Epoch 4442/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 687567774.8655 - val_loss: 4015273110.0714\n",
      "Epoch 4443/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1129567688.8467 - val_loss: 906196612.9868\n",
      "Epoch 4444/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 222456847.1266 - val_loss: 1475145176.8439\n",
      "Epoch 4445/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 278938229.5307 - val_loss: 1214044971.5308\n",
      "Epoch 4446/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 193769113.9403 - val_loss: 1086493427.7941\n",
      "Epoch 4447/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 289829847.2482 - val_loss: 1184772852.9283\n",
      "Epoch 4448/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 561204598.3118 - val_loss: 1877045867.8368\n",
      "Epoch 4449/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1176808588.0698 - val_loss: 885917344.7651\n",
      "Epoch 4450/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 376797324.4615 - val_loss: 1425032463.4824\n",
      "Epoch 4451/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 389200900.7361 - val_loss: 1006800711.9392\n",
      "Epoch 4452/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 344896834.8272 - val_loss: 924992251.7513\n",
      "Epoch 4453/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 417676690.7552 - val_loss: 1129629479.7412\n",
      "Epoch 4454/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 238293731.3315 - val_loss: 5818318721.3322\n",
      "Epoch 4455/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 5037057982.7394 - val_loss: 4368295161.1589\n",
      "Epoch 4456/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1487620058.5166 - val_loss: 1055334410.3696\n",
      "Epoch 4457/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 240782648.3714 - val_loss: 914421046.8366\n",
      "Epoch 4458/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 201722324.4569 - val_loss: 1301675058.2143\n",
      "Epoch 4459/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 310161012.5290 - val_loss: 1041403527.1651\n",
      "Epoch 4460/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 239943109.5442 - val_loss: 874712380.6875\n",
      "Epoch 4461/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 210141814.4671 - val_loss: 874282419.6141\n",
      "Epoch 4462/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 260593005.9651 - val_loss: 1204363171.4655\n",
      "Epoch 4463/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 225846336.4502 - val_loss: 871111002.6802\n",
      "Epoch 4464/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 211481271.9145 - val_loss: 947905606.3550\n",
      "Epoch 4465/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 256570180.3039 - val_loss: 1172215454.3887\n",
      "Epoch 4466/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 185784043.2549 - val_loss: 2193558464.8461\n",
      "Epoch 4467/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 791915836.0473 - val_loss: 1253528939.8729\n",
      "Epoch 4468/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 782296304.6933 - val_loss: 1797324991.2079\n",
      "Epoch 4469/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 411998594.2510 - val_loss: 1027172610.6644\n",
      "Epoch 4470/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 331898021.2133 - val_loss: 959932619.0897\n",
      "Epoch 4471/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 237693698.6111 - val_loss: 1190194298.2436\n",
      "Epoch 4472/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 244484426.9218 - val_loss: 1084252172.3319\n",
      "Epoch 4473/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 396056337.0366 - val_loss: 4360213362.2819\n",
      "Epoch 4474/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 530921399.4282 - val_loss: 2095860275.4160\n",
      "Epoch 4475/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 497025514.4626 - val_loss: 1301872441.6090\n",
      "Epoch 4476/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 472214261.8075 - val_loss: 1421026740.8203\n",
      "Epoch 4477/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2815463934.1609 - val_loss: 1317651378.4439\n",
      "Epoch 4478/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 291393927.8064 - val_loss: 896139850.7477\n",
      "Epoch 4479/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 211421664.7743 - val_loss: 1109915899.4723\n",
      "Epoch 4480/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 276929768.5718 - val_loss: 820558311.5342\n",
      "Epoch 4481/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 214552158.3523 - val_loss: 964447888.3105\n",
      "Epoch 4482/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 348139250.4761 - val_loss: 1261387876.4557\n",
      "Epoch 4483/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 237310994.2240 - val_loss: 2794843618.9255\n",
      "Epoch 4484/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1595677511.1739 - val_loss: 6607974286.9423\n",
      "Epoch 4485/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1042166628.1868 - val_loss: 993337807.8605\n",
      "Epoch 4486/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 209624841.3641 - val_loss: 2193649979.5893\n",
      "Epoch 4487/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 801020082.8903 - val_loss: 1173925821.1826\n",
      "Epoch 4488/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 433051591.9325 - val_loss: 927229168.8236\n",
      "Epoch 4489/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 174335185.1795 - val_loss: 934457906.3539\n",
      "Epoch 4490/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 435442458.4356 - val_loss: 2747581416.9384\n",
      "Epoch 4491/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 587635911.3742 - val_loss: 1202479773.8487\n",
      "Epoch 4492/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 383554695.0051 - val_loss: 1315742376.5603\n",
      "Epoch 4493/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 353249349.6095 - val_loss: 960992170.5226\n",
      "Epoch 4494/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 284286568.4007 - val_loss: 3258263687.8132\n",
      "Epoch 4495/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 640082808.3579 - val_loss: 879542521.4560\n",
      "Epoch 4496/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 254289169.1165 - val_loss: 1107075240.7404\n",
      "Epoch 4497/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 164017186.0349 - val_loss: 1139462915.1820\n",
      "Epoch 4498/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 436051359.1176 - val_loss: 1446444679.2371\n",
      "Epoch 4499/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 409952231.9415 - val_loss: 2104518203.8323\n",
      "Epoch 4500/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 914613904.9454 - val_loss: 3037386796.5210\n",
      "Epoch 4501/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1118983094.2397 - val_loss: 6739933030.7601\n",
      "Epoch 4502/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1287887399.0411 - val_loss: 2597736003.4160\n",
      "Epoch 4503/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 2523573443.9617 - val_loss: 886604041.1454\n",
      "Epoch 4504/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 188155844.5920 - val_loss: 1717073147.7513\n",
      "Epoch 4505/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 441006495.6038 - val_loss: 973705233.6968\n",
      "Epoch 4506/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 331130769.2786 - val_loss: 1240444827.6838\n",
      "Epoch 4507/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 341440705.0411 - val_loss: 1308992126.7308\n",
      "Epoch 4508/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 284269847.8796 - val_loss: 907885271.4217\n",
      "Epoch 4509/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 363614417.2515 - val_loss: 909435462.6430\n",
      "Epoch 4510/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 285036059.5993 - val_loss: 859580309.4954\n",
      "Epoch 4511/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 248797033.8233 - val_loss: 883908710.3820\n",
      "Epoch 4512/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 323731196.0743 - val_loss: 908099447.3226\n",
      "Epoch 4513/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 269797187.8897 - val_loss: 3190197262.5463\n",
      "Epoch 4514/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 417566917.0771 - val_loss: 1070262754.8354\n",
      "Epoch 4515/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 214170596.3039 - val_loss: 971438965.4684\n",
      "Epoch 4516/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 871630316.9837 - val_loss: 2506626140.1024\n",
      "Epoch 4517/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 782035338.6427 - val_loss: 1231654242.4394\n",
      "Epoch 4518/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 638408651.1694 - val_loss: 1577734220.4759\n",
      "Epoch 4519/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 404719123.9617 - val_loss: 5348187534.3662\n",
      "Epoch 4520/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 460237303.8965 - val_loss: 1019662703.7975\n",
      "Epoch 4521/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 197779142.0506 - val_loss: 1112937822.6948\n",
      "Epoch 4522/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 263413663.1356 - val_loss: 1340312766.3977\n",
      "Epoch 4523/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 521089520.3782 - val_loss: 2264561403.3913\n",
      "Epoch 4524/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 477286901.8436 - val_loss: 2286224916.4872\n",
      "Epoch 4525/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 229830213.4724 - val_loss: 918616162.3494\n",
      "Epoch 4526/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 360271668.5830 - val_loss: 1633708323.7896\n",
      "Epoch 4527/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2041276429.1998 - val_loss: 1825069049.1049\n",
      "Epoch 4528/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 376112168.6528 - val_loss: 862131736.8619\n",
      "Epoch 4529/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 318756673.1525 - val_loss: 1641247312.9857\n",
      "Epoch 4530/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 1007729115.7321 - val_loss: 1423934871.2596\n",
      "Epoch 4531/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 452089524.6190 - val_loss: 1797761848.1328\n",
      "Epoch 4532/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 360589219.5701 - val_loss: 986922857.9466\n",
      "Epoch 4533/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 238877820.2634 - val_loss: 1831885958.7691\n",
      "Epoch 4534/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 374144367.8025 - val_loss: 1357435591.8492\n",
      "Epoch 4535/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 816545374.1272 - val_loss: 1461917526.1975\n",
      "Epoch 4536/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 383103132.9207 - val_loss: 1454806282.5136\n",
      "Epoch 4537/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 816504598.4018 - val_loss: 2944880727.5657\n",
      "Epoch 4538/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 501512993.8067 - val_loss: 906179581.6596\n",
      "Epoch 4539/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 235224548.4479 - val_loss: 1339242267.9404\n",
      "Epoch 4540/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 509610924.9477 - val_loss: 1054619431.0481\n",
      "Epoch 4541/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 419218417.2876 - val_loss: 1013711570.8309\n",
      "Epoch 4542/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 315079120.4142 - val_loss: 1034438709.5764\n",
      "Epoch 4543/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 1007697443.8177 - val_loss: 1719764104.4928\n",
      "Epoch 4544/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 437371625.1030 - val_loss: 1703028626.7409\n",
      "Epoch 4545/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 377899431.6939 - val_loss: 1196593719.4847\n",
      "Epoch 4546/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 247733818.4446 - val_loss: 1111959448.1598\n",
      "Epoch 4547/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 453802297.8053 - val_loss: 1135227719.1111\n",
      "Epoch 4548/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 339544172.2994 - val_loss: 1061519716.3207\n",
      "Epoch 4549/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1372271613.0197 - val_loss: 1032403864.1778\n",
      "Epoch 4550/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 304428257.8908 - val_loss: 2721465339.1212\n",
      "Epoch 4551/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 468339485.6050 - val_loss: 1547107528.2453\n",
      "Epoch 4552/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 540192357.8368 - val_loss: 1241419143.5972\n",
      "Epoch 4553/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 277139717.9471 - val_loss: 1290218556.9215\n",
      "Epoch 4554/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 170043346.4401 - val_loss: 1411538369.4042\n",
      "Epoch 4555/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 432929581.8143 - val_loss: 958408053.8464\n",
      "Epoch 4556/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 314346471.8334 - val_loss: 1433942506.9907\n",
      "Epoch 4557/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 374646221.0197 - val_loss: 1766063780.9058\n",
      "Epoch 4558/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 888566923.2459 - val_loss: 1215881522.8759\n",
      "Epoch 4559/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 287722713.6072 - val_loss: 1936750028.3679\n",
      "Epoch 4560/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 944206113.7828 - val_loss: 4928302812.3544\n",
      "Epoch 4561/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1173830707.5521 - val_loss: 1038054596.0056\n",
      "Epoch 4562/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 328190206.9465 - val_loss: 1010282444.8000\n",
      "Epoch 4563/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 228280033.2786 - val_loss: 1030216605.3806\n",
      "Epoch 4564/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 599667503.6038 - val_loss: 999305645.6461\n",
      "Epoch 4565/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 394981797.9426 - val_loss: 950632011.2968\n",
      "Epoch 4566/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 96us/step - loss: 151759907.1919 - val_loss: 883779141.1758\n",
      "Epoch 4567/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 175898571.8064 - val_loss: 1547104839.4712\n",
      "Epoch 4568/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 302990440.1396 - val_loss: 905815305.3795\n",
      "Epoch 4569/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 297428374.9420 - val_loss: 1054262958.5193\n",
      "Epoch 4570/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 372478121.6927 - val_loss: 1308204536.4838\n",
      "Epoch 4571/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 375893804.5155 - val_loss: 3558054743.4577\n",
      "Epoch 4572/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 1351294130.1339 - val_loss: 1781241994.2616\n",
      "Epoch 4573/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 695578937.6432 - val_loss: 3472893153.1252\n",
      "Epoch 4574/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 843406345.1300 - val_loss: 1074704303.6534\n",
      "Epoch 4575/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 313292179.0884 - val_loss: 963313638.6880\n",
      "Epoch 4576/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 441585770.1384 - val_loss: 853929089.5932\n",
      "Epoch 4577/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 750402390.4198 - val_loss: 1338355977.8475\n",
      "Epoch 4578/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 305361714.1654 - val_loss: 843224066.4844\n",
      "Epoch 4579/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 197394059.2234 - val_loss: 872399223.6647\n",
      "Epoch 4580/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 206784778.1925 - val_loss: 871898023.1921\n",
      "Epoch 4581/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 245430806.5020 - val_loss: 881349013.7924\n",
      "Epoch 4582/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 319775980.3354 - val_loss: 1610400844.0979\n",
      "Epoch 4583/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 414751457.4316 - val_loss: 919877388.9260\n",
      "Epoch 4584/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 343894279.3652 - val_loss: 1736786610.0118\n",
      "Epoch 4585/10000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 484271665.7378 - val_loss: 2187525150.4248\n",
      "Epoch 4586/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 335290545.5847 - val_loss: 840303958.6205\n",
      "Epoch 4587/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 389898614.9060 - val_loss: 1204188731.4813\n",
      "Epoch 4588/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1045583849.8323 - val_loss: 5048937372.6965\n",
      "Epoch 4589/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 726375064.8869 - val_loss: 1453666737.0037\n",
      "Epoch 4590/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 757458789.7085 - val_loss: 2551726141.4616\n",
      "Epoch 4591/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 509821603.0974 - val_loss: 874065907.8841\n",
      "Epoch 4592/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 183435836.4524 - val_loss: 1009894085.0588\n",
      "Epoch 4593/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 679278268.0743 - val_loss: 1034154348.9530\n",
      "Epoch 4594/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 436805278.1362 - val_loss: 1333106051.2405\n",
      "Epoch 4595/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 340540417.4406 - val_loss: 929413557.7024\n",
      "Epoch 4596/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 753527305.8323 - val_loss: 3449286461.3716\n",
      "Epoch 4597/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 591912749.2853 - val_loss: 1183793802.4821\n",
      "Epoch 4598/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 179454713.8863 - val_loss: 834506677.2523\n",
      "Epoch 4599/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 222327224.4007 - val_loss: 887042828.5030\n",
      "Epoch 4600/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 770315599.3067 - val_loss: 1533688823.3226\n",
      "Epoch 4601/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 555153500.8486 - val_loss: 1230044664.2948\n",
      "Epoch 4602/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 493568224.0000 - val_loss: 953877936.2115\n",
      "Epoch 4603/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 368358280.7653 - val_loss: 1141556730.0681\n",
      "Epoch 4604/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 254587181.8481 - val_loss: 1199037011.9651\n",
      "Epoch 4605/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 893073044.0428 - val_loss: 997549454.4473\n",
      "Epoch 4606/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 457992926.6899 - val_loss: 924297396.7392\n",
      "Epoch 4607/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 319012491.0388 - val_loss: 864087257.3615\n",
      "Epoch 4608/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 333647419.3731 - val_loss: 884668355.2045\n",
      "Epoch 4609/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 602110738.1699 - val_loss: 1932556409.7710\n",
      "Epoch 4610/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 509582069.9696 - val_loss: 1094659304.5243\n",
      "Epoch 4611/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 243959206.3208 - val_loss: 1676642639.4284\n",
      "Epoch 4612/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 359218335.7209 - val_loss: 1525420078.2672\n",
      "Epoch 4613/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 885007295.4958 - val_loss: 1330748889.7980\n",
      "Epoch 4614/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 519427874.6472 - val_loss: 10846652464.9677\n",
      "Epoch 4615/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1432470326.4918 - val_loss: 1510262101.8644\n",
      "Epoch 4616/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 294752664.1238 - val_loss: 963240814.0692\n",
      "Epoch 4617/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 188123522.6652 - val_loss: 3692656644.1406\n",
      "Epoch 4618/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1225007584.3061 - val_loss: 957985525.9724\n",
      "Epoch 4619/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 289988702.9916 - val_loss: 1297978092.3409\n",
      "Epoch 4620/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 368285307.6241 - val_loss: 1401943985.9668\n",
      "Epoch 4621/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 218726331.3990 - val_loss: 1020633996.7460\n",
      "Epoch 4622/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 502408725.1773 - val_loss: 2268722736.5176\n",
      "Epoch 4623/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 554836095.6624 - val_loss: 1309335089.6158\n",
      "Epoch 4624/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 413623729.2335 - val_loss: 1213873455.8155\n",
      "Epoch 4625/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 624425248.4052 - val_loss: 2428268589.5111\n",
      "Epoch 4626/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 591616603.2752 - val_loss: 880317656.9339\n",
      "Epoch 4627/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 364712773.8706 - val_loss: 2876038254.6813\n",
      "Epoch 4628/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 575329340.6820 - val_loss: 1214689919.0999\n",
      "Epoch 4629/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 234157286.3028 - val_loss: 880065995.4948\n",
      "Epoch 4630/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 331690361.9223 - val_loss: 1105052400.8596\n",
      "Epoch 4631/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 366439425.5487 - val_loss: 1166242185.5415\n",
      "Epoch 4632/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 380893258.8993 - val_loss: 1537444917.1533\n",
      "Epoch 4633/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 330738651.9752 - val_loss: 1005141331.4520\n",
      "Epoch 4634/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 281738565.5284 - val_loss: 2099186849.2692\n",
      "Epoch 4635/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1387597374.6584 - val_loss: 1086567990.7826\n",
      "Epoch 4636/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 440821370.4536 - val_loss: 1826909472.3691\n",
      "Epoch 4637/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 998319728.9454 - val_loss: 6761823112.2093\n",
      "Epoch 4638/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1346734671.4508 - val_loss: 2062509205.2433\n",
      "Epoch 4639/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 421964304.7113 - val_loss: 3889375733.9184\n",
      "Epoch 4640/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 644861271.1652 - val_loss: 1952917411.4655\n",
      "Epoch 4641/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 426122170.1294 - val_loss: 5310107360.3871\n",
      "Epoch 4642/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1681423056.2746 - val_loss: 1036040144.9226\n",
      "Epoch 4643/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 307379419.8672 - val_loss: 847062358.9176\n",
      "Epoch 4644/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 298455911.6984 - val_loss: 888323896.4028\n",
      "Epoch 4645/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 279453390.0304 - val_loss: 1237267838.1637\n",
      "Epoch 4646/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 220328439.2774 - val_loss: 835575225.6360\n",
      "Epoch 4647/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 279820529.1615 - val_loss: 2163026149.2838\n",
      "Epoch 4648/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 713325523.7006 - val_loss: 1570580183.6017\n",
      "Epoch 4649/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 216996373.3573 - val_loss: 3459829362.7679\n",
      "Epoch 4650/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 762424303.1149 - val_loss: 1433721047.6737\n",
      "Epoch 4651/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 509135055.9752 - val_loss: 1685075686.7601\n",
      "Epoch 4652/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 270520016.3039 - val_loss: 920085264.6526\n",
      "Epoch 4653/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 205745093.7985 - val_loss: 1958657955.7266\n",
      "Epoch 4654/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 570853864.2454 - val_loss: 1197800869.5359\n",
      "Epoch 4655/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 196909846.9623 - val_loss: 843609588.6852\n",
      "Epoch 4656/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 288821297.3416 - val_loss: 984621431.7547\n",
      "Epoch 4657/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 434708610.9240 - val_loss: 915162766.7443\n",
      "Epoch 4658/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 423307913.1120 - val_loss: 1657710415.4644\n",
      "Epoch 4659/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 502954330.8497 - val_loss: 1315088288.3691\n",
      "Epoch 4660/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 318821327.6308 - val_loss: 1346644441.8340\n",
      "Epoch 4661/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 314801224.9679 - val_loss: 932561378.8714\n",
      "Epoch 4662/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 234780182.8160 - val_loss: 1599972161.7373\n",
      "Epoch 4663/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 552165006.4873 - val_loss: 1249360704.4861\n",
      "Epoch 4664/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1349333343.8739 - val_loss: 1949961638.8501\n",
      "Epoch 4665/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 491887927.8604 - val_loss: 832694598.5620\n",
      "Epoch 4666/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 524573798.8610 - val_loss: 1384717597.8847\n",
      "Epoch 4667/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 453669516.2273 - val_loss: 958364201.7485\n",
      "Epoch 4668/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 282808056.9769 - val_loss: 1499019123.3980\n",
      "Epoch 4669/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 344022985.8323 - val_loss: 5861025353.3075\n",
      "Epoch 4670/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 678427031.4823 - val_loss: 1056151424.1440\n",
      "Epoch 4671/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 795930381.5419 - val_loss: 1108934677.6664\n",
      "Epoch 4672/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 440329387.0748 - val_loss: 827908836.0416\n",
      "Epoch 4673/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 208544731.6241 - val_loss: 1052890908.4714\n",
      "Epoch 4674/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 288612043.9032 - val_loss: 1152806503.5072\n",
      "Epoch 4675/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 262640038.6629 - val_loss: 1564602050.7994\n",
      "Epoch 4676/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 504405615.6128 - val_loss: 1998304782.3302\n",
      "Epoch 4677/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 829643313.9178 - val_loss: 1665605644.4940\n",
      "Epoch 4678/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 280610300.6505 - val_loss: 2186137232.8956\n",
      "Epoch 4679/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 436265383.1986 - val_loss: 1060815699.3530\n",
      "Epoch 4680/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 456774466.5121 - val_loss: 1429546627.2045\n",
      "Epoch 4681/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1466336948.6550 - val_loss: 1454490452.5772\n",
      "Epoch 4682/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 654931487.3787 - val_loss: 880459693.5291\n",
      "Epoch 4683/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 145654542.8745 - val_loss: 1021149683.7581\n",
      "Epoch 4684/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 331784827.8942 - val_loss: 1460813770.2436\n",
      "Epoch 4685/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 736773657.1750 - val_loss: 1025133590.5035\n",
      "Epoch 4686/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 460830686.2105 - val_loss: 1701984758.9446\n",
      "Epoch 4687/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 322698471.4147 - val_loss: 1222853419.8549\n",
      "Epoch 4688/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 413950544.0810 - val_loss: 1909032140.2239\n",
      "Epoch 4689/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 397321680.6258 - val_loss: 1638082482.9930\n",
      "Epoch 4690/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 519982793.8568 - val_loss: 1214759817.5775\n",
      "Epoch 4691/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 278368252.6505 - val_loss: 2653671069.0565\n",
      "Epoch 4692/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 312914793.1300 - val_loss: 1334072957.6551\n",
      "Epoch 4693/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 720596579.7997 - val_loss: 6411786312.6413\n",
      "Epoch 4694/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1571231084.1463 - val_loss: 857736049.0487\n",
      "Epoch 4695/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 264658069.3078 - val_loss: 857217434.9682\n",
      "Epoch 4696/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 96us/step - loss: 224504169.6702 - val_loss: 2039411776.0270\n",
      "Epoch 4697/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 501331027.1784 - val_loss: 943835902.6318\n",
      "Epoch 4698/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 592363819.7231 - val_loss: 2023535869.7677\n",
      "Epoch 4699/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 326841628.7091 - val_loss: 835996018.3359\n",
      "Epoch 4700/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 269228928.8104 - val_loss: 1004021631.8560\n",
      "Epoch 4701/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 407958074.5616 - val_loss: 1015173984.6751\n",
      "Epoch 4702/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 375001367.7310 - val_loss: 1085730403.8886\n",
      "Epoch 4703/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 289627619.8357 - val_loss: 1177381448.8574\n",
      "Epoch 4704/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 361285303.1761 - val_loss: 940475832.5288\n",
      "Epoch 4705/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 421305423.1626 - val_loss: 2505757506.7544\n",
      "Epoch 4706/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 322283731.2684 - val_loss: 905587575.7187\n",
      "Epoch 4707/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 493665598.2127 - val_loss: 1213191537.5617\n",
      "Epoch 4708/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 494069468.4164 - val_loss: 1408334446.4653\n",
      "Epoch 4709/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1513094079.8289 - val_loss: 1491736232.8844\n",
      "Epoch 4710/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 488881542.8520 - val_loss: 913285526.2155\n",
      "Epoch 4711/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 634738621.9111 - val_loss: 1065897898.7927\n",
      "Epoch 4712/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 325947391.2167 - val_loss: 802175242.2436\n",
      "Epoch 4713/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 454897799.1311 - val_loss: 2241110229.7744\n",
      "Epoch 4714/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 874919890.4941 - val_loss: 2230417066.4866\n",
      "Epoch 4715/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 569069050.8858 - val_loss: 1165474527.6669\n",
      "Epoch 4716/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 881296700.2093 - val_loss: 1417377446.8231\n",
      "Epoch 4717/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 192156416.2183 - val_loss: 830336000.1800\n",
      "Epoch 4718/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 270075060.0878 - val_loss: 1444238633.5505\n",
      "Epoch 4719/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 231960930.6652 - val_loss: 894681062.6880\n",
      "Epoch 4720/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 211255092.3309 - val_loss: 1694822664.3083\n",
      "Epoch 4721/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 490764832.7743 - val_loss: 7264889798.0309\n",
      "Epoch 4722/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 1554509008.8475 - val_loss: 1311326188.1609\n",
      "Epoch 4723/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 195407685.3573 - val_loss: 821737697.9353\n",
      "Epoch 4724/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 320027455.9280 - val_loss: 1034520555.6208\n",
      "Epoch 4725/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 393988808.6798 - val_loss: 932495919.0954\n",
      "Epoch 4726/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 352659097.4451 - val_loss: 1688395230.1547\n",
      "Epoch 4727/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 620747276.3894 - val_loss: 2020296978.6509\n",
      "Epoch 4728/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1127489189.4924 - val_loss: 1130129670.6250\n",
      "Epoch 4729/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 220953799.0951 - val_loss: 885612106.3156\n",
      "Epoch 4730/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 187777868.3444 - val_loss: 1054881359.1494\n",
      "Epoch 4731/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 312097004.5965 - val_loss: 973341583.1224\n",
      "Epoch 4732/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 257910059.0658 - val_loss: 1216278857.1634\n",
      "Epoch 4733/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 244856836.5110 - val_loss: 1280159924.8563\n",
      "Epoch 4734/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 802915090.0079 - val_loss: 2765627945.3345\n",
      "Epoch 4735/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 696235175.0411 - val_loss: 1821270028.0079\n",
      "Epoch 4736/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 522523704.1125 - val_loss: 1076236030.5058\n",
      "Epoch 4737/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 296056698.8768 - val_loss: 1003686284.8540\n",
      "Epoch 4738/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 217022470.5008 - val_loss: 2092894600.5333\n",
      "Epoch 4739/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 382793088.7923 - val_loss: 1275469263.2124\n",
      "Epoch 4740/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 432397048.8869 - val_loss: 1253516583.4622\n",
      "Epoch 4741/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 775187090.6877 - val_loss: 902892783.3294\n",
      "Epoch 4742/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 241427165.0287 - val_loss: 2657208291.6276\n",
      "Epoch 4743/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 747195357.8751 - val_loss: 1946922235.7513\n",
      "Epoch 4744/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 563300521.6882 - val_loss: 928163289.2940\n",
      "Epoch 4745/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 512324941.4339 - val_loss: 1332690198.7466\n",
      "Epoch 4746/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 527456859.0118 - val_loss: 2378779751.5522\n",
      "Epoch 4747/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1126347044.5920 - val_loss: 1656277439.1539\n",
      "Epoch 4748/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 871083349.8593 - val_loss: 1077878103.0076\n",
      "Epoch 4749/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 226153260.3174 - val_loss: 876066942.4338\n",
      "Epoch 4750/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 230073440.4142 - val_loss: 1333980326.5890\n",
      "Epoch 4751/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 241039033.4001 - val_loss: 1056129479.2911\n",
      "Epoch 4752/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 384594370.1210 - val_loss: 1099306489.3795\n",
      "Epoch 4753/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 237485564.6415 - val_loss: 910157457.7238\n",
      "Epoch 4754/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 338271078.7935 - val_loss: 1206156449.0892\n",
      "Epoch 4755/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 297485792.5582 - val_loss: 1145306305.0622\n",
      "Epoch 4756/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 508669446.4108 - val_loss: 27179942125.3491\n",
      "Epoch 4757/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 3421907184.7518 - val_loss: 876316817.9668\n",
      "Epoch 4758/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 158443603.3067 - val_loss: 1180257004.7100\n",
      "Epoch 4759/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 362871459.1919 - val_loss: 1043337646.1412\n",
      "Epoch 4760/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 237076491.1739 - val_loss: 989559760.5626\n",
      "Epoch 4761/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 95us/step - loss: 241703642.8047 - val_loss: 857417879.6827\n",
      "Epoch 4762/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 207052487.6511 - val_loss: 958821606.4000\n",
      "Epoch 4763/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 202013518.7485 - val_loss: 786633158.9221\n",
      "Epoch 4764/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 365867580.9026 - val_loss: 1000775718.4540\n",
      "Epoch 4765/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 317375641.8233 - val_loss: 1735865894.8861\n",
      "Epoch 4766/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 478057183.9640 - val_loss: 1071458605.8172\n",
      "Epoch 4767/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 288360524.3410 - val_loss: 1628470083.2045\n",
      "Epoch 4768/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 997328786.6562 - val_loss: 1779461478.9041\n",
      "Epoch 4769/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 207443197.4699 - val_loss: 1008133922.9435\n",
      "Epoch 4770/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 291000934.7530 - val_loss: 1069207461.9949\n",
      "Epoch 4771/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 487025685.8976 - val_loss: 2597319311.8065\n",
      "Epoch 4772/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 777438876.2183 - val_loss: 1112656337.0487\n",
      "Epoch 4773/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 366804863.1716 - val_loss: 1303608149.8734\n",
      "Epoch 4774/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 481131839.7839 - val_loss: 977474452.0911\n",
      "Epoch 4775/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 225521258.0664 - val_loss: 1115457472.2880\n",
      "Epoch 4776/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 442978025.7873 - val_loss: 1457924569.3480\n",
      "Epoch 4777/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 327730113.1975 - val_loss: 1009893417.1634\n",
      "Epoch 4778/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 982725987.7366 - val_loss: 1680347091.1370\n",
      "Epoch 4779/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 624464380.5425 - val_loss: 949674820.3027\n",
      "Epoch 4780/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 625255750.0146 - val_loss: 2307793636.7077\n",
      "Epoch 4781/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 861280514.9353 - val_loss: 818107484.2644\n",
      "Epoch 4782/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 221035326.3770 - val_loss: 1058383421.3536\n",
      "Epoch 4783/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 226934940.3804 - val_loss: 2588868950.9176\n",
      "Epoch 4784/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 378999336.4975 - val_loss: 864919136.5851\n",
      "Epoch 4785/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 217802558.1092 - val_loss: 849001530.3111\n",
      "Epoch 4786/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 249865238.2217 - val_loss: 1884440274.0838\n",
      "Epoch 4787/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 520526262.2757 - val_loss: 2972491709.4256\n",
      "Epoch 4788/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 543167382.8340 - val_loss: 927570989.9072\n",
      "Epoch 4789/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 505678320.8734 - val_loss: 875542124.6380\n",
      "Epoch 4790/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 831070363.0838 - val_loss: 1163998428.2644\n",
      "Epoch 4791/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 386624613.9606 - val_loss: 1296828454.1480\n",
      "Epoch 4792/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 369430825.2020 - val_loss: 1518120932.8338\n",
      "Epoch 4793/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1853518647.7074 - val_loss: 4606832211.7671\n",
      "Epoch 4794/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 528151410.0169 - val_loss: 1949766945.7733\n",
      "Epoch 4795/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 372540062.4873 - val_loss: 925433406.4158\n",
      "Epoch 4796/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 207957584.6438 - val_loss: 933395694.0422\n",
      "Epoch 4797/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 215854955.5250 - val_loss: 889196439.7817\n",
      "Epoch 4798/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 236257455.4328 - val_loss: 1761067604.7212\n",
      "Epoch 4799/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 845548547.9077 - val_loss: 1072462283.7963\n",
      "Epoch 4800/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 266424799.7479 - val_loss: 2544723969.6563\n",
      "Epoch 4801/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 577200377.2358 - val_loss: 931100422.4810\n",
      "Epoch 4802/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 201686525.4249 - val_loss: 1027877797.6484\n",
      "Epoch 4803/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 272865579.9572 - val_loss: 1994946337.7373\n",
      "Epoch 4804/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 432699631.3967 - val_loss: 964531985.7868\n",
      "Epoch 4805/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 280337621.3573 - val_loss: 949358435.6276\n",
      "Epoch 4806/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 233566746.7845 - val_loss: 1494127527.9302\n",
      "Epoch 4807/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 610667251.8627 - val_loss: 943518220.8180\n",
      "Epoch 4808/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 222596645.7445 - val_loss: 10385987594.5857\n",
      "Epoch 4809/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2276359148.5155 - val_loss: 1149974446.1232\n",
      "Epoch 4810/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 423969932.4254 - val_loss: 938586371.9696\n",
      "Epoch 4811/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 219335436.0293 - val_loss: 928578008.5288\n",
      "Epoch 4812/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 202081174.8880 - val_loss: 1033133436.2914\n",
      "Epoch 4813/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 356173107.1424 - val_loss: 1031729238.6385\n",
      "Epoch 4814/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 253324068.9432 - val_loss: 971510683.7243\n",
      "Epoch 4815/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 278585655.3022 - val_loss: 1025208235.2248\n",
      "Epoch 4816/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 249991377.8998 - val_loss: 972777137.1567\n",
      "Epoch 4817/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 394088475.0838 - val_loss: 930619687.0481\n",
      "Epoch 4818/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 329052721.6117 - val_loss: 1326266980.5457\n",
      "Epoch 4819/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 709764147.2864 - val_loss: 1659773992.4343\n",
      "Epoch 4820/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1472830116.3759 - val_loss: 966923855.0684\n",
      "Epoch 4821/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 270692095.3877 - val_loss: 985694405.5269\n",
      "Epoch 4822/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 292420765.6410 - val_loss: 1046389076.0371\n",
      "Epoch 4823/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 336995819.3385 - val_loss: 1094370057.7395\n",
      "Epoch 4824/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 182631013.5284 - val_loss: 1648956647.1651\n",
      "Epoch 4825/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 721794459.8402 - val_loss: 1001428750.5103\n",
      "Epoch 4826/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 390622759.3292 - val_loss: 5955924953.1139\n",
      "Epoch 4827/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 995435864.5447 - val_loss: 1143447600.0225\n",
      "Epoch 4828/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 338759161.4631 - val_loss: 786247896.8259\n",
      "Epoch 4829/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 274988235.2369 - val_loss: 876717319.1156\n",
      "Epoch 4830/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 273026437.2943 - val_loss: 1135663100.3229\n",
      "Epoch 4831/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1119474804.4029 - val_loss: 2130148782.9513\n",
      "Epoch 4832/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 355881737.1840 - val_loss: 3342152403.8571\n",
      "Epoch 4833/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 618755603.0073 - val_loss: 835001431.5657\n",
      "Epoch 4834/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 266573156.9252 - val_loss: 949734872.0878\n",
      "Epoch 4835/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 228145475.1514 - val_loss: 936583600.2295\n",
      "Epoch 4836/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 432622969.9403 - val_loss: 891036591.7075\n",
      "Epoch 4837/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 582815387.5250 - val_loss: 1407554083.2540\n",
      "Epoch 4838/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 698960577.7378 - val_loss: 2037521911.8087\n",
      "Epoch 4839/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 638712690.3050 - val_loss: 2106871649.9713\n",
      "Epoch 4840/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 347142322.4513 - val_loss: 951984335.2304\n",
      "Epoch 4841/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 353494655.1356 - val_loss: 11340413312.7561\n",
      "Epoch 4842/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 3691524565.4834 - val_loss: 1430922523.7243\n",
      "Epoch 4843/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 264534999.7524 - val_loss: 1287117069.7812\n",
      "Epoch 4844/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 181789645.5824 - val_loss: 803433014.7646\n",
      "Epoch 4845/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 143387042.8452 - val_loss: 1076866428.4534\n",
      "Epoch 4846/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 339126701.0602 - val_loss: 847833849.3570\n",
      "Epoch 4847/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 167239397.2223 - val_loss: 906692960.6796\n",
      "Epoch 4848/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 721500070.3928 - val_loss: 3060335381.9274\n",
      "Epoch 4849/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 632646591.3787 - val_loss: 1083425040.0585\n",
      "Epoch 4850/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 300892547.7907 - val_loss: 1112431265.1207\n",
      "Epoch 4851/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 381903584.9544 - val_loss: 874467788.6020\n",
      "Epoch 4852/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 181192587.0388 - val_loss: 901172669.4166\n",
      "Epoch 4853/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 248851956.3354 - val_loss: 3222481503.6309\n",
      "Epoch 4854/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 413895989.2718 - val_loss: 1310093291.3328\n",
      "Epoch 4855/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 285332848.0450 - val_loss: 2553831168.9722\n",
      "Epoch 4856/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 416082441.7963 - val_loss: 855302397.5696\n",
      "Epoch 4857/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 252524708.1958 - val_loss: 801599635.0920\n",
      "Epoch 4858/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 315288744.5898 - val_loss: 7218622234.2121\n",
      "Epoch 4859/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1327087324.7406 - val_loss: 1727667541.1713\n",
      "Epoch 4860/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 975043269.1052 - val_loss: 864660948.0731\n",
      "Epoch 4861/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 217568961.8863 - val_loss: 902948987.0942\n",
      "Epoch 4862/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 215572546.1249 - val_loss: 1132591022.6903\n",
      "Epoch 4863/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 371773700.1598 - val_loss: 1232387175.8762\n",
      "Epoch 4864/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 283814773.0872 - val_loss: 2382271950.9603\n",
      "Epoch 4865/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1244001952.0540 - val_loss: 4125182495.6309\n",
      "Epoch 4866/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1132731893.5644 - val_loss: 1742244525.9162\n",
      "Epoch 4867/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 283295418.4446 - val_loss: 1355625668.3387\n",
      "Epoch 4868/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 292816993.5712 - val_loss: 820455960.9339\n",
      "Epoch 4869/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 169744146.9173 - val_loss: 1623063259.3103\n",
      "Epoch 4870/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 303181164.6055 - val_loss: 1407751991.6557\n",
      "Epoch 4871/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 454606761.6162 - val_loss: 980894516.7032\n",
      "Epoch 4872/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 210900159.2122 - val_loss: 877504911.5904\n",
      "Epoch 4873/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 254226697.6162 - val_loss: 7190899056.2655\n",
      "Epoch 4874/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2214197231.1266 - val_loss: 2144738973.5246\n",
      "Epoch 4875/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 430114573.2898 - val_loss: 1256402661.4278\n",
      "Epoch 4876/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 259298103.1761 - val_loss: 1108629782.6475\n",
      "Epoch 4877/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 220132473.2290 - val_loss: 3992170521.4920\n",
      "Epoch 4878/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 883015720.5627 - val_loss: 824351662.0152\n",
      "Epoch 4879/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 234393736.1829 - val_loss: 1014539592.2453\n",
      "Epoch 4880/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 192419759.0906 - val_loss: 1008363035.4363\n",
      "Epoch 4881/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 243297403.6421 - val_loss: 1096524554.0996\n",
      "Epoch 4882/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 257378014.9736 - val_loss: 1224852170.4506\n",
      "Epoch 4883/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 669425312.2757 - val_loss: 1039328341.4954\n",
      "Epoch 4884/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 234732427.7051 - val_loss: 3415671413.0903\n",
      "Epoch 4885/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 792291316.8531 - val_loss: 942548469.2703\n",
      "Epoch 4886/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 295052272.5132 - val_loss: 1006356639.2799\n",
      "Epoch 4887/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 324402300.2364 - val_loss: 1100093850.9772\n",
      "Epoch 4888/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 489629799.6832 - val_loss: 1015592195.2225\n",
      "Epoch 4889/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 483260771.9077 - val_loss: 6897453826.8084\n",
      "Epoch 4890/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1055709181.6320 - val_loss: 894607441.2287\n",
      "Epoch 4891/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 81us/step - loss: 491890473.2335 - val_loss: 973592456.3713\n",
      "Epoch 4892/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 223311092.4209 - val_loss: 1165632277.2523\n",
      "Epoch 4893/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 276910843.5791 - val_loss: 919118484.6672\n",
      "Epoch 4894/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 150164167.5093 - val_loss: 1268376089.1679\n",
      "Epoch 4895/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 280827749.2943 - val_loss: 1317346000.3286\n",
      "Epoch 4896/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 227542021.4024 - val_loss: 923192642.6464\n",
      "Epoch 4897/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 548754112.6483 - val_loss: 3196506927.8875\n",
      "Epoch 4898/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1207242221.6590 - val_loss: 2224058407.6332\n",
      "Epoch 4899/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1232431471.5633 - val_loss: 943761033.1814\n",
      "Epoch 4900/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 249767823.3697 - val_loss: 1301727691.0987\n",
      "Epoch 4901/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 463158064.4187 - val_loss: 961148915.3620\n",
      "Epoch 4902/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 210955842.5931 - val_loss: 1839763576.3848\n",
      "Epoch 4903/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 587767674.0574 - val_loss: 1020264946.4079\n",
      "Epoch 4904/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 296849279.2077 - val_loss: 2729490064.4546\n",
      "Epoch 4905/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1282598906.2375 - val_loss: 2582654123.7108\n",
      "Epoch 4906/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 732652609.4586 - val_loss: 1001464799.3474\n",
      "Epoch 4907/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 260562900.4750 - val_loss: 944398658.3224\n",
      "Epoch 4908/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 274347214.4536 - val_loss: 1327748737.2602\n",
      "Epoch 4909/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 276945994.4806 - val_loss: 861553569.9713\n",
      "Epoch 4910/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 453142935.0681 - val_loss: 804504700.0754\n",
      "Epoch 4911/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 180049349.0481 - val_loss: 844716307.6231\n",
      "Epoch 4912/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 511823176.4052 - val_loss: 920188611.3485\n",
      "Epoch 4913/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 442860691.8807 - val_loss: 886503024.0315\n",
      "Epoch 4914/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 309510977.6387 - val_loss: 1129982330.8152\n",
      "Epoch 4915/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 510142685.5689 - val_loss: 2080291133.2636\n",
      "Epoch 4916/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1384180769.2425 - val_loss: 961323358.0107\n",
      "Epoch 4917/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 361142835.0838 - val_loss: 1045808246.0805\n",
      "Epoch 4918/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 239469659.5115 - val_loss: 779160524.0799\n",
      "Epoch 4919/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 168445267.3585 - val_loss: 836609224.2363\n",
      "Epoch 4920/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 489785780.2926 - val_loss: 3579011909.0588\n",
      "Epoch 4921/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1166485738.5346 - val_loss: 990143763.5691\n",
      "Epoch 4922/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 225277343.0748 - val_loss: 894356980.5232\n",
      "Epoch 4923/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 173131253.1593 - val_loss: 826801168.8506\n",
      "Epoch 4924/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 173115451.2414 - val_loss: 970724015.2034\n",
      "Epoch 4925/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 293162233.3866 - val_loss: 862990841.0914\n",
      "Epoch 4926/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 185640682.2150 - val_loss: 1045605600.5131\n",
      "Epoch 4927/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 419676136.8891 - val_loss: 1379857257.7485\n",
      "Epoch 4928/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 301409652.9071 - val_loss: 1743543466.9187\n",
      "Epoch 4929/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2244093877.2673 - val_loss: 1442601516.8630\n",
      "Epoch 4930/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 305411718.8908 - val_loss: 850208088.5108\n",
      "Epoch 4931/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 197602503.9595 - val_loss: 3776807119.3924\n",
      "Epoch 4932/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1095144176.8014 - val_loss: 1097099058.6779\n",
      "Epoch 4933/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 225101692.3579 - val_loss: 838983224.3083\n",
      "Epoch 4934/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 215622545.7378 - val_loss: 882585364.5052\n",
      "Epoch 4935/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 260277999.8019 - val_loss: 1039584352.6751\n",
      "Epoch 4936/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 409291598.6584 - val_loss: 1269632028.8765\n",
      "Epoch 4937/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 753947898.0394 - val_loss: 1234090575.2124\n",
      "Epoch 4938/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 589681720.2566 - val_loss: 1705604492.0619\n",
      "Epoch 4939/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 477477596.6050 - val_loss: 859543157.2613\n",
      "Epoch 4940/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 345728620.9927 - val_loss: 1186386874.4011\n",
      "Epoch 4941/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 216442357.9516 - val_loss: 898431853.8802\n",
      "Epoch 4942/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 199612326.8790 - val_loss: 1165264493.1961\n",
      "Epoch 4943/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 325540277.3393 - val_loss: 858191866.4191\n",
      "Epoch 4944/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 233746359.6083 - val_loss: 983700100.7797\n",
      "Epoch 4945/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 379260628.0653 - val_loss: 1619972140.1429\n",
      "Epoch 4946/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 341524849.6657 - val_loss: 1163374206.6138\n",
      "Epoch 4947/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 962627225.7333 - val_loss: 1177652533.5539\n",
      "Epoch 4948/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 295146775.9392 - val_loss: 1396758093.8802\n",
      "Epoch 4949/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 245957279.1176 - val_loss: 909588206.9873\n",
      "Epoch 4950/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 282089987.1514 - val_loss: 905334164.9193\n",
      "Epoch 4951/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 259259307.7411 - val_loss: 931420297.5865\n",
      "Epoch 4952/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 999242513.0174 - val_loss: 1048197582.5463\n",
      "Epoch 4953/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 699234790.8610 - val_loss: 1407394444.2869\n",
      "Epoch 4954/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 564567667.2504 - val_loss: 1849451500.6470\n",
      "Epoch 4955/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 858307745.9989 - val_loss: 1134837382.8141\n",
      "Epoch 4956/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 847265178.5526 - val_loss: 1071631555.5826\n",
      "Epoch 4957/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 463607025.8773 - val_loss: 789350801.9758\n",
      "Epoch 4958/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 294231147.7006 - val_loss: 904013985.7373\n",
      "Epoch 4959/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 206355532.4524 - val_loss: 1788448878.0692\n",
      "Epoch 4960/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 237038476.6190 - val_loss: 1061351014.5800\n",
      "Epoch 4961/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 350642227.3303 - val_loss: 820893526.3595\n",
      "Epoch 4962/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 466156338.2420 - val_loss: 2694715012.3927\n",
      "Epoch 4963/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 911000759.3382 - val_loss: 1684537387.2248\n",
      "Epoch 4964/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 283297760.1564 - val_loss: 816766347.2338\n",
      "Epoch 4965/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 173655902.9015 - val_loss: 811270461.0925\n",
      "Epoch 4966/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 249961888.6303 - val_loss: 968714306.8895\n",
      "Epoch 4967/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 368158676.4569 - val_loss: 4250571767.6467\n",
      "Epoch 4968/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 2009876830.9195 - val_loss: 2012682760.5693\n",
      "Epoch 4969/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 293960766.8835 - val_loss: 942672905.9916\n",
      "Epoch 4970/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 295366587.8312 - val_loss: 1044627533.8442\n",
      "Epoch 4971/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 484275186.7822 - val_loss: 4233304186.7792\n",
      "Epoch 4972/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 843195799.2279 - val_loss: 1550101826.4754\n",
      "Epoch 4973/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 229508133.3776 - val_loss: 929759969.1792\n",
      "Epoch 4974/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 175585291.3540 - val_loss: 785848514.7994\n",
      "Epoch 4975/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 164762490.0326 - val_loss: 862789275.2608\n",
      "Epoch 4976/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 184139863.2257 - val_loss: 808935434.7837\n",
      "Epoch 4977/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 259374979.6556 - val_loss: 1235081857.8003\n",
      "Epoch 4978/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 572387705.0580 - val_loss: 1007293485.1691\n",
      "Epoch 4979/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 800013076.2589 - val_loss: 1012388363.4858\n",
      "Epoch 4980/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 277755820.9657 - val_loss: 7402497528.0788\n",
      "Epoch 4981/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 2593334389.8436 - val_loss: 3574387344.7426\n",
      "Epoch 4982/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1421520925.4609 - val_loss: 984749506.8444\n",
      "Epoch 4983/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 176976498.9522 - val_loss: 826908516.2397\n",
      "Epoch 4984/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 166038752.6010 - val_loss: 833826551.3046\n",
      "Epoch 4985/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 132713257.1806 - val_loss: 813752936.6414\n",
      "Epoch 4986/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 141342010.1024 - val_loss: 1248496714.8917\n",
      "Epoch 4987/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 313505343.5757 - val_loss: 994268314.8242\n",
      "Epoch 4988/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 212887371.4080 - val_loss: 1990338500.5367\n",
      "Epoch 4989/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 308097058.4086 - val_loss: 818810717.5336\n",
      "Epoch 4990/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 193199265.8188 - val_loss: 854338115.5871\n",
      "Epoch 4991/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 254119027.7546 - val_loss: 1238350556.1744\n",
      "Epoch 4992/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1332645263.3607 - val_loss: 4671759546.0771\n",
      "Epoch 4993/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 460735621.0062 - val_loss: 1346888908.3319\n",
      "Epoch 4994/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 394784799.1041 - val_loss: 936814317.9612\n",
      "Epoch 4995/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 244365418.3005 - val_loss: 870372684.6020\n",
      "Epoch 4996/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 349328825.3011 - val_loss: 10806780120.8979\n",
      "Epoch 4997/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1262988370.4266 - val_loss: 850436221.4436\n",
      "Epoch 4998/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 268263747.4226 - val_loss: 1109958204.2014\n",
      "Epoch 4999/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 223494779.1199 - val_loss: 1002823818.6937\n",
      "Epoch 5000/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 310711535.7569 - val_loss: 1006407714.2053\n",
      "Epoch 5001/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1609099362.3050 - val_loss: 4225849776.1395\n",
      "Epoch 5002/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1341551552.4322 - val_loss: 957948019.3980\n",
      "Epoch 5003/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 296557444.9927 - val_loss: 1555612575.5499\n",
      "Epoch 5004/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 210228126.3703 - val_loss: 837102833.7328\n",
      "Epoch 5005/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 229104082.0799 - val_loss: 768415957.9454\n",
      "Epoch 5006/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 342272866.9533 - val_loss: 806488658.7139\n",
      "Epoch 5007/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 309304163.5115 - val_loss: 816420525.6551\n",
      "Epoch 5008/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 189535026.6382 - val_loss: 1174141833.3255\n",
      "Epoch 5009/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 328640388.7541 - val_loss: 1032554429.3356\n",
      "Epoch 5010/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1399453033.3821 - val_loss: 2894542904.0158\n",
      "Epoch 5011/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 525586812.0113 - val_loss: 1555529313.1432\n",
      "Epoch 5012/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 435935231.4553 - val_loss: 972422678.3595\n",
      "Epoch 5013/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 166059630.2082 - val_loss: 821218674.8940\n",
      "Epoch 5014/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 162020233.2200 - val_loss: 779154090.0726\n",
      "Epoch 5015/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 173994636.2814 - val_loss: 1463270751.9460\n",
      "Epoch 5016/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 291716226.7124 - val_loss: 849543212.5120\n",
      "Epoch 5017/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 244376275.0884 - val_loss: 1446128066.3494\n",
      "Epoch 5018/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 327018020.8801 - val_loss: 4094561247.3069\n",
      "Epoch 5019/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1412462807.0681 - val_loss: 1759030695.7637\n",
      "Epoch 5020/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 527205431.4012 - val_loss: 905907511.8447\n",
      "Epoch 5021/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 90us/step - loss: 145806088.9319 - val_loss: 898445590.2335\n",
      "Epoch 5022/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 294530138.8903 - val_loss: 1060152934.7691\n",
      "Epoch 5023/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 711524319.6579 - val_loss: 1562796508.7145\n",
      "Epoch 5024/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 479465873.6365 - val_loss: 1338315374.7173\n",
      "Epoch 5025/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 293459400.1576 - val_loss: 1051779238.0129\n",
      "Epoch 5026/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 416131588.9342 - val_loss: 1367975305.5055\n",
      "Epoch 5027/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 548316300.4795 - val_loss: 2751008992.2790\n",
      "Epoch 5028/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 331861815.5093 - val_loss: 2006341235.6591\n",
      "Epoch 5029/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1527696987.5160 - val_loss: 1064625976.2588\n",
      "Epoch 5030/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 275341399.6083 - val_loss: 1531307925.0453\n",
      "Epoch 5031/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 323824878.5684 - val_loss: 874856486.6565\n",
      "Epoch 5032/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 204621195.3765 - val_loss: 943606434.2954\n",
      "Epoch 5033/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 183297294.5414 - val_loss: 960783523.7716\n",
      "Epoch 5034/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 329581963.5476 - val_loss: 2269735755.3418\n",
      "Epoch 5035/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 496978821.8976 - val_loss: 845437263.0323\n",
      "Epoch 5036/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 210230353.0355 - val_loss: 947232548.0776\n",
      "Epoch 5037/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 409447624.7878 - val_loss: 1275737548.0079\n",
      "Epoch 5038/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 542933833.0219 - val_loss: 891680581.0498\n",
      "Epoch 5039/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 265957660.4705 - val_loss: 2082104341.3063\n",
      "Epoch 5040/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1017183729.7198 - val_loss: 1275137767.3722\n",
      "Epoch 5041/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 329506234.2105 - val_loss: 1386527552.6661\n",
      "Epoch 5042/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 484010251.3089 - val_loss: 884139273.2895\n",
      "Epoch 5043/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 229954890.6607 - val_loss: 868275693.6011\n",
      "Epoch 5044/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 204563669.2673 - val_loss: 3483230875.0402\n",
      "Epoch 5045/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 971062025.2921 - val_loss: 1996868782.3032\n",
      "Epoch 5046/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1004847978.7687 - val_loss: 846844464.8776\n",
      "Epoch 5047/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 211893327.2988 - val_loss: 871872437.8374\n",
      "Epoch 5048/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 256062185.1525 - val_loss: 1482968698.2751\n",
      "Epoch 5049/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 637284103.3022 - val_loss: 897975702.9446\n",
      "Epoch 5050/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1005288139.8762 - val_loss: 1290747601.0667\n",
      "Epoch 5051/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 247268350.5774 - val_loss: 798196162.2954\n",
      "Epoch 5052/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 587357454.5864 - val_loss: 1848126060.4129\n",
      "Epoch 5053/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 956436366.0371 - val_loss: 888968093.0835\n",
      "Epoch 5054/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 185992102.7259 - val_loss: 776741332.6402\n",
      "Epoch 5055/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 169042417.4316 - val_loss: 1391649296.2745\n",
      "Epoch 5056/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 459275733.2425 - val_loss: 951975929.7800\n",
      "Epoch 5057/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 186549465.9854 - val_loss: 791156631.3226\n",
      "Epoch 5058/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 295407573.4609 - val_loss: 1485932636.1024\n",
      "Epoch 5059/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 379173166.4423 - val_loss: 1000663402.3741\n",
      "Epoch 5060/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 252746505.5802 - val_loss: 867925681.9308\n",
      "Epoch 5061/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 431266412.5757 - val_loss: 4078526623.4329\n",
      "Epoch 5062/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 968672135.2752 - val_loss: 1565141504.4321\n",
      "Epoch 5063/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 621181537.7316 - val_loss: 824040878.4833\n",
      "Epoch 5064/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 139318028.1013 - val_loss: 3543226030.4113\n",
      "Epoch 5065/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 826606531.6736 - val_loss: 1945397587.9291\n",
      "Epoch 5066/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 334757612.5695 - val_loss: 856485343.0098\n",
      "Epoch 5067/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 255349621.8255 - val_loss: 1142052029.0025\n",
      "Epoch 5068/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 207076307.1424 - val_loss: 1008683270.1120\n",
      "Epoch 5069/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 249224924.8666 - val_loss: 1062680701.9117\n",
      "Epoch 5070/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 625982198.1677 - val_loss: 1948541912.8979\n",
      "Epoch 5071/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 505617276.0383 - val_loss: 3572253357.3941\n",
      "Epoch 5072/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1932057903.2167 - val_loss: 1231814323.3080\n",
      "Epoch 5073/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 345045844.3489 - val_loss: 2002404902.1660\n",
      "Epoch 5074/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 618414597.7940 - val_loss: 1481094645.6304\n",
      "Epoch 5075/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 373881060.6100 - val_loss: 816016849.5077\n",
      "Epoch 5076/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 848970543.3427 - val_loss: 802370658.7994\n",
      "Epoch 5077/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 208537454.1362 - val_loss: 900020251.5803\n",
      "Epoch 5078/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 163166084.3219 - val_loss: 2189514932.6042\n",
      "Epoch 5079/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 744606922.5391 - val_loss: 798835688.0203\n",
      "Epoch 5080/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 205484523.9752 - val_loss: 810434705.0667\n",
      "Epoch 5081/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 162826475.2594 - val_loss: 931316606.7578\n",
      "Epoch 5082/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 221026723.1840 - val_loss: 924056503.1606\n",
      "Epoch 5083/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 227062225.9629 - val_loss: 1662517447.4352\n",
      "Epoch 5084/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1233826756.6820 - val_loss: 2016724204.3409\n",
      "Epoch 5085/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 630043615.0501 - val_loss: 889673074.3179\n",
      "Epoch 5086/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 170617475.9212 - val_loss: 955585956.9418\n",
      "Epoch 5087/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 142715687.8537 - val_loss: 836762511.6624\n",
      "Epoch 5088/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 248200176.3061 - val_loss: 903758268.8585\n",
      "Epoch 5089/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 217644480.7563 - val_loss: 3898253336.2678\n",
      "Epoch 5090/10000\n",
      "3554/3554 [==============================] - 0s 140us/step - loss: 1585963489.0985 - val_loss: 3025078221.9522\n",
      "Epoch 5091/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1360250724.0698 - val_loss: 822026392.2048\n",
      "Epoch 5092/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 197440485.2223 - val_loss: 773062001.3637\n",
      "Epoch 5093/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 262695453.4609 - val_loss: 1378585487.0504\n",
      "Epoch 5094/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 535124538.0889 - val_loss: 972299767.8267\n",
      "Epoch 5095/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 247185471.2437 - val_loss: 818130557.1736\n",
      "Epoch 5096/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 167464870.9690 - val_loss: 2952179508.6402\n",
      "Epoch 5097/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1478015139.5656 - val_loss: 822290184.1643\n",
      "Epoch 5098/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 233693888.5267 - val_loss: 2083742804.2532\n",
      "Epoch 5099/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 331500768.9994 - val_loss: 772853970.5519\n",
      "Epoch 5100/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 198585548.4885 - val_loss: 870501740.9710\n",
      "Epoch 5101/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 179040080.2161 - val_loss: 1076069103.7255\n",
      "Epoch 5102/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 277576940.7676 - val_loss: 879674300.6515\n",
      "Epoch 5103/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 353119627.7907 - val_loss: 865432202.7747\n",
      "Epoch 5104/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 269062918.3928 - val_loss: 1051188537.9060\n",
      "Epoch 5105/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 625516895.4057 - val_loss: 6496276573.3626\n",
      "Epoch 5106/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 935827691.4665 - val_loss: 1018609439.3069\n",
      "Epoch 5107/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 321397761.1705 - val_loss: 1650402462.2627\n",
      "Epoch 5108/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 274832055.5543 - val_loss: 1737731320.7179\n",
      "Epoch 5109/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 309154029.5419 - val_loss: 774601616.5446\n",
      "Epoch 5110/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 270739378.7822 - val_loss: 2157665367.4037\n",
      "Epoch 5111/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 512302825.8593 - val_loss: 1283936148.7167\n",
      "Epoch 5112/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 667431732.0788 - val_loss: 1162531954.8399\n",
      "Epoch 5113/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 484512349.9651 - val_loss: 903356471.1156\n",
      "Epoch 5114/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 407471591.3292 - val_loss: 1189747777.0352\n",
      "Epoch 5115/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 361215410.4941 - val_loss: 1237123720.8844\n",
      "Epoch 5116/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 365940537.0400 - val_loss: 1438491769.5550\n",
      "Epoch 5117/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 256555196.4524 - val_loss: 1714884990.9378\n",
      "Epoch 5118/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 277924741.8737 - val_loss: 1506132233.6855\n",
      "Epoch 5119/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 603555390.4603 - val_loss: 3844957788.8225\n",
      "Epoch 5120/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 515515577.5712 - val_loss: 981812151.6017\n",
      "Epoch 5121/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 240693542.4288 - val_loss: 927365885.0070\n",
      "Epoch 5122/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 231045355.6511 - val_loss: 857932945.1747\n",
      "Epoch 5123/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 480620667.7862 - val_loss: 1011019480.3938\n",
      "Epoch 5124/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 760120974.6224 - val_loss: 2252711848.5063\n",
      "Epoch 5125/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 591167432.6213 - val_loss: 933332846.5733\n",
      "Epoch 5126/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 365441686.3523 - val_loss: 1494738619.8774\n",
      "Epoch 5127/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 342972064.8734 - val_loss: 857562541.6191\n",
      "Epoch 5128/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 201051934.7034 - val_loss: 805069784.1418\n",
      "Epoch 5129/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 354103679.1356 - val_loss: 2152009320.0563\n",
      "Epoch 5130/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 554044250.9758 - val_loss: 2351979676.6965\n",
      "Epoch 5131/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1482625822.7485 - val_loss: 924905476.2847\n",
      "Epoch 5132/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 421484895.8920 - val_loss: 1337412783.9415\n",
      "Epoch 5133/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 211970959.0726 - val_loss: 1050804065.4222\n",
      "Epoch 5134/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 298854411.9932 - val_loss: 1378238604.5300\n",
      "Epoch 5135/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 271818527.7119 - val_loss: 936895113.1814\n",
      "Epoch 5136/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 215466856.5988 - val_loss: 774865573.6979\n",
      "Epoch 5137/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 261340986.1294 - val_loss: 921515899.1032\n",
      "Epoch 5138/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1321533039.9370 - val_loss: 2536854988.2959\n",
      "Epoch 5139/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1342954348.2814 - val_loss: 1014139223.0931\n",
      "Epoch 5140/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 404296087.2302 - val_loss: 2675896822.9266\n",
      "Epoch 5141/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 575723950.8565 - val_loss: 1330087080.0743\n",
      "Epoch 5142/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 203064168.7620 - val_loss: 948826815.7480\n",
      "Epoch 5143/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 184484996.5098 - val_loss: 876970163.4880\n",
      "Epoch 5144/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 340558707.0523 - val_loss: 859092755.6591\n",
      "Epoch 5145/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 266003269.7175 - val_loss: 2136112461.7722\n",
      "Epoch 5146/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 513486633.3461 - val_loss: 13341912100.0776\n",
      "Epoch 5147/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 3333649947.6961 - val_loss: 1101295897.2219\n",
      "Epoch 5148/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 234146416.2679 - val_loss: 911468453.8419\n",
      "Epoch 5149/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 148777399.2532 - val_loss: 825983551.6895\n",
      "Epoch 5150/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 215699979.3450 - val_loss: 865046243.9516\n",
      "Epoch 5151/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 94us/step - loss: 176587378.8520 - val_loss: 800296408.2228\n",
      "Epoch 5152/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 218925709.0557 - val_loss: 1321773246.8433\n",
      "Epoch 5153/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 576355014.6449 - val_loss: 898205360.3556\n",
      "Epoch 5154/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 302508522.9668 - val_loss: 1527210542.5913\n",
      "Epoch 5155/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 266375048.0495 - val_loss: 1522442673.9668\n",
      "Epoch 5156/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 594931248.6753 - val_loss: 898287704.5018\n",
      "Epoch 5157/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 166649035.2639 - val_loss: 749767815.8582\n",
      "Epoch 5158/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 141214751.5138 - val_loss: 938914196.9013\n",
      "Epoch 5159/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 250013787.5723 - val_loss: 815875437.1623\n",
      "Epoch 5160/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 310229522.2780 - val_loss: 1135871291.1212\n",
      "Epoch 5161/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 561896704.6843 - val_loss: 1645904179.3170\n",
      "Epoch 5162/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 476728838.7710 - val_loss: 1044850303.5679\n",
      "Epoch 5163/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 467399265.2425 - val_loss: 1045771780.4107\n",
      "Epoch 5164/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 354074628.6370 - val_loss: 2129033791.2079\n",
      "Epoch 5165/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1003999997.8391 - val_loss: 948692105.5055\n",
      "Epoch 5166/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 254626838.3793 - val_loss: 955327607.5027\n",
      "Epoch 5167/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 207020708.0158 - val_loss: 1093701308.3634\n",
      "Epoch 5168/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 254881184.1441 - val_loss: 870116021.3063\n",
      "Epoch 5169/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 183696654.0101 - val_loss: 6626338496.5581\n",
      "Epoch 5170/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1537681924.2859 - val_loss: 939467047.5342\n",
      "Epoch 5171/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 396534740.3050 - val_loss: 1528091867.6163\n",
      "Epoch 5172/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 308951412.9972 - val_loss: 1516202630.3370\n",
      "Epoch 5173/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 294151358.4513 - val_loss: 934208915.9381\n",
      "Epoch 5174/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 194242334.1182 - val_loss: 1380306534.6340\n",
      "Epoch 5175/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 490268302.3523 - val_loss: 1848162284.5210\n",
      "Epoch 5176/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 754578515.3765 - val_loss: 1450416982.7286\n",
      "Epoch 5177/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 528685566.6359 - val_loss: 855945968.5536\n",
      "Epoch 5178/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 180955175.3652 - val_loss: 908044745.2895\n",
      "Epoch 5179/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 227843658.9128 - val_loss: 6024953402.6172\n",
      "Epoch 5180/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1400249365.1773 - val_loss: 6893307706.8692\n",
      "Epoch 5181/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1074407998.7394 - val_loss: 1059620746.3336\n",
      "Epoch 5182/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 186043500.8756 - val_loss: 825400985.3300\n",
      "Epoch 5183/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 213868996.8306 - val_loss: 962772030.5823\n",
      "Epoch 5184/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 203186986.1835 - val_loss: 1080123481.5820\n",
      "Epoch 5185/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 442601532.4524 - val_loss: 1454768891.9404\n",
      "Epoch 5186/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 2081174529.0084 - val_loss: 1718649182.0467\n",
      "Epoch 5187/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 310119221.1458 - val_loss: 966140859.4273\n",
      "Epoch 5188/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 234698211.4440 - val_loss: 804506858.5406\n",
      "Epoch 5189/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 146057417.4924 - val_loss: 1072324102.1570\n",
      "Epoch 5190/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 186297704.5267 - val_loss: 1037523892.3702\n",
      "Epoch 5191/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 331789568.5222 - val_loss: 1021823190.3955\n",
      "Epoch 5192/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 288758800.7833 - val_loss: 3834231348.1361\n",
      "Epoch 5193/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 707563978.9128 - val_loss: 10045543248.1485\n",
      "Epoch 5194/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 2265865421.0017 - val_loss: 1135386234.7117\n",
      "Epoch 5195/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 188907087.5228 - val_loss: 1165208375.8267\n",
      "Epoch 5196/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 366653758.6517 - val_loss: 820144892.1564\n",
      "Epoch 5197/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 161084108.7631 - val_loss: 970868551.0751\n",
      "Epoch 5198/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 145313181.1953 - val_loss: 743659541.7114\n",
      "Epoch 5199/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 142261518.4930 - val_loss: 878123435.4408\n",
      "Epoch 5200/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 147076482.7732 - val_loss: 1323364419.2045\n",
      "Epoch 5201/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 526479274.2465 - val_loss: 992228741.2208\n",
      "Epoch 5202/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 405697947.0501 - val_loss: 843207798.7105\n",
      "Epoch 5203/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 331015483.3180 - val_loss: 1785636744.7854\n",
      "Epoch 5204/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 2108215566.3568 - val_loss: 1021066370.1243\n",
      "Epoch 5205/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 180514027.7923 - val_loss: 805785650.9120\n",
      "Epoch 5206/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 414626252.9747 - val_loss: 1690571710.5423\n",
      "Epoch 5207/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 892399528.8059 - val_loss: 1127170001.7823\n",
      "Epoch 5208/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 284892556.2273 - val_loss: 812925823.6219\n",
      "Epoch 5209/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 142168143.4868 - val_loss: 1107377396.8743\n",
      "Epoch 5210/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 145413089.6477 - val_loss: 816387284.5682\n",
      "Epoch 5211/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 157155730.2780 - val_loss: 1336485123.4430\n",
      "Epoch 5212/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 442859890.4221 - val_loss: 2276725634.7364\n",
      "Epoch 5213/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 570421538.3905 - val_loss: 2194812603.3013\n",
      "Epoch 5214/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 443336395.1469 - val_loss: 885263828.5232\n",
      "Epoch 5215/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 800073677.6500 - val_loss: 2452748433.1747\n",
      "Epoch 5216/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 861298953.4361 - val_loss: 1079274201.9105\n",
      "Epoch 5217/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 171760437.0557 - val_loss: 804821335.9662\n",
      "Epoch 5218/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 131252230.5684 - val_loss: 774946850.4934\n",
      "Epoch 5219/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 256353828.6280 - val_loss: 1223939084.1879\n",
      "Epoch 5220/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 216969337.9032 - val_loss: 805671876.2487\n",
      "Epoch 5221/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 830328317.2268 - val_loss: 2738143599.5454\n",
      "Epoch 5222/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 623258093.0602 - val_loss: 1087120877.8892\n",
      "Epoch 5223/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 468374444.7316 - val_loss: 1701647573.7744\n",
      "Epoch 5224/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 544488615.8334 - val_loss: 906189271.3947\n",
      "Epoch 5225/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 480529698.2645 - val_loss: 859402068.6402\n",
      "Epoch 5226/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 281334034.1519 - val_loss: 2375873369.1499\n",
      "Epoch 5227/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 677425034.0484 - val_loss: 1654661298.1558\n",
      "Epoch 5228/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 526696817.4699 - val_loss: 762706565.5179\n",
      "Epoch 5229/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 151828372.4299 - val_loss: 1399723315.7041\n",
      "Epoch 5230/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 312935707.1829 - val_loss: 858588682.5136\n",
      "Epoch 5231/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 299951437.0557 - val_loss: 1142981284.5097\n",
      "Epoch 5232/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 261944657.6117 - val_loss: 1304321005.1871\n",
      "Epoch 5233/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 276393557.9381 - val_loss: 782320647.3451\n",
      "Epoch 5234/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 349720146.6922 - val_loss: 2265991986.7679\n",
      "Epoch 5235/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1493363427.6196 - val_loss: 2321402571.7198\n",
      "Epoch 5236/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 670593180.1103 - val_loss: 1262479812.4107\n",
      "Epoch 5237/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 860225229.9831 - val_loss: 897110493.0745\n",
      "Epoch 5238/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 252432305.1829 - val_loss: 874377071.7885\n",
      "Epoch 5239/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 209624716.4840 - val_loss: 774541270.2335\n",
      "Epoch 5240/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 216817975.5723 - val_loss: 803669882.1491\n",
      "Epoch 5241/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 562603523.6511 - val_loss: 794879680.1710\n",
      "Epoch 5242/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 134429514.4806 - val_loss: 1230728562.3989\n",
      "Epoch 5243/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 262174469.2853 - val_loss: 789627003.5353\n",
      "Epoch 5244/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 490870025.2178 - val_loss: 891289608.1373\n",
      "Epoch 5245/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 213172888.7608 - val_loss: 1045300774.0579\n",
      "Epoch 5246/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 269625775.9190 - val_loss: 1401222257.3097\n",
      "Epoch 5247/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 691776742.7890 - val_loss: 1302112429.8352\n",
      "Epoch 5248/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 681165965.7760 - val_loss: 1306411853.8442\n",
      "Epoch 5249/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 728744990.7800 - val_loss: 850536297.1544\n",
      "Epoch 5250/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 189844885.5374 - val_loss: 1384798031.6084\n",
      "Epoch 5251/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 322940070.4209 - val_loss: 922450897.6248\n",
      "Epoch 5252/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 218106593.8008 - val_loss: 1022167367.5792\n",
      "Epoch 5253/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 195049180.1148 - val_loss: 840890018.7634\n",
      "Epoch 5254/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 570123419.2459 - val_loss: 1448399915.5668\n",
      "Epoch 5255/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 743835868.0563 - val_loss: 857599236.8428\n",
      "Epoch 5256/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 376886780.3984 - val_loss: 993764211.6456\n",
      "Epoch 5257/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 580508082.2870 - val_loss: 826125006.3842\n",
      "Epoch 5258/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 335279735.6984 - val_loss: 836612216.5378\n",
      "Epoch 5259/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 283848616.1936 - val_loss: 2771987130.7252\n",
      "Epoch 5260/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 333472128.0810 - val_loss: 1057897645.4751\n",
      "Epoch 5261/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 469060743.2077 - val_loss: 1057860688.9406\n",
      "Epoch 5262/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 209354402.3950 - val_loss: 2704222775.4082\n",
      "Epoch 5263/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1523111368.2476 - val_loss: 1454043197.9207\n",
      "Epoch 5264/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 605067579.9302 - val_loss: 1309081940.3432\n",
      "Epoch 5265/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 150713981.8796 - val_loss: 777443257.1949\n",
      "Epoch 5266/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 186395849.8824 - val_loss: 819740877.7722\n",
      "Epoch 5267/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 541418902.8070 - val_loss: 1577642502.6700\n",
      "Epoch 5268/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 224558286.4783 - val_loss: 1085048665.8160\n",
      "Epoch 5269/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 350657031.5633 - val_loss: 8630266400.0720\n",
      "Epoch 5270/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1044133241.8413 - val_loss: 1049453071.5184\n",
      "Epoch 5271/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 197162004.3849 - val_loss: 1804454519.0346\n",
      "Epoch 5272/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 416761007.0096 - val_loss: 954579773.0205\n",
      "Epoch 5273/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 192713733.4035 - val_loss: 1068475130.5992\n",
      "Epoch 5274/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 494656773.3303 - val_loss: 983265291.9809\n",
      "Epoch 5275/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 302650761.5172 - val_loss: 989198461.7316\n",
      "Epoch 5276/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 262838226.6562 - val_loss: 881168212.1451\n",
      "Epoch 5277/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 424253952.5042 - val_loss: 1344028478.4698\n",
      "Epoch 5278/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 360597431.9865 - val_loss: 4134306524.3544\n",
      "Epoch 5279/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 482461691.5611 - val_loss: 809416168.0923\n",
      "Epoch 5280/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 448218992.7293 - val_loss: 1311650744.7089\n",
      "Epoch 5281/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 92us/step - loss: 487748845.6680 - val_loss: 877936965.4549\n",
      "Epoch 5282/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 303524838.6044 - val_loss: 2076967087.4194\n",
      "Epoch 5283/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 667768161.2425 - val_loss: 2971747956.6582\n",
      "Epoch 5284/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 520500064.0360 - val_loss: 914437829.5989\n",
      "Epoch 5285/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 213635845.9066 - val_loss: 1079165414.9041\n",
      "Epoch 5286/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 511744089.8233 - val_loss: 1991101066.8197\n",
      "Epoch 5287/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 984915967.1536 - val_loss: 824745744.6616\n",
      "Epoch 5288/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 250871435.7411 - val_loss: 2771063957.0273\n",
      "Epoch 5289/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1000812155.4620 - val_loss: 1135185196.6650\n",
      "Epoch 5290/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 790277354.4108 - val_loss: 874413084.5255\n",
      "Epoch 5291/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 195074573.2088 - val_loss: 902827926.8546\n",
      "Epoch 5292/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 215056576.8374 - val_loss: 971065886.4968\n",
      "Epoch 5293/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 251901002.4266 - val_loss: 1266744307.4790\n",
      "Epoch 5294/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 228536667.2774 - val_loss: 901920628.1541\n",
      "Epoch 5295/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 201322470.6989 - val_loss: 834062251.0897\n",
      "Epoch 5296/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 313082628.3534 - val_loss: 1055304376.0248\n",
      "Epoch 5297/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 210762012.8936 - val_loss: 1087750825.8385\n",
      "Epoch 5298/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 395854043.6961 - val_loss: 1594044489.9376\n",
      "Epoch 5299/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 481992824.3647 - val_loss: 1671431263.3789\n",
      "Epoch 5300/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 539398680.8644 - val_loss: 824181218.3944\n",
      "Epoch 5301/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 752643383.6466 - val_loss: 1276855972.3117\n",
      "Epoch 5302/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 344444509.0647 - val_loss: 1066180940.3319\n",
      "Epoch 5303/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 445484529.7760 - val_loss: 977542169.9060\n",
      "Epoch 5304/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 270713197.9201 - val_loss: 915936915.1910\n",
      "Epoch 5305/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 545311045.4069 - val_loss: 1150201337.9601\n",
      "Epoch 5306/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 308622093.3348 - val_loss: 1044178644.8653\n",
      "Epoch 5307/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 228842844.2532 - val_loss: 840663750.1390\n",
      "Epoch 5308/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 206036001.3506 - val_loss: 1513416672.2430\n",
      "Epoch 5309/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 841381177.8503 - val_loss: 1120265510.4090\n",
      "Epoch 5310/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 256109912.5808 - val_loss: 895498503.2281\n",
      "Epoch 5311/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 296652769.8188 - val_loss: 2283507054.9153\n",
      "Epoch 5312/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 691569100.6280 - val_loss: 992787826.8669\n",
      "Epoch 5313/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 288190479.8875 - val_loss: 1200256715.3778\n",
      "Epoch 5314/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 321160452.3399 - val_loss: 1224655810.4574\n",
      "Epoch 5315/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 257410349.1277 - val_loss: 1026143874.5204\n",
      "Epoch 5316/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 615858530.3230 - val_loss: 1443211300.0776\n",
      "Epoch 5317/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 461395800.2476 - val_loss: 1843921211.6613\n",
      "Epoch 5318/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1093934069.8436 - val_loss: 1006209693.0880\n",
      "Epoch 5319/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 305520856.3737 - val_loss: 877347148.5120\n",
      "Epoch 5320/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 310248130.5571 - val_loss: 10407560018.2729\n",
      "Epoch 5321/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1638851596.7946 - val_loss: 760190914.7004\n",
      "Epoch 5322/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 163636437.6995 - val_loss: 910814096.6346\n",
      "Epoch 5323/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 158845389.7456 - val_loss: 963046128.2835\n",
      "Epoch 5324/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 469830979.8897 - val_loss: 1185508388.3297\n",
      "Epoch 5325/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 345630208.3061 - val_loss: 1420963309.7992\n",
      "Epoch 5326/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 429361777.5937 - val_loss: 1177795059.5331\n",
      "Epoch 5327/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 231710516.8621 - val_loss: 806660602.0411\n",
      "Epoch 5328/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 245364101.5104 - val_loss: 931603958.8186\n",
      "Epoch 5329/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 233678324.5155 - val_loss: 794655626.6352\n",
      "Epoch 5330/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 349291901.2628 - val_loss: 876899012.7257\n",
      "Epoch 5331/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 461837845.8075 - val_loss: 1746383639.5567\n",
      "Epoch 5332/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 339787157.0332 - val_loss: 2730208221.8667\n",
      "Epoch 5333/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1645848485.9786 - val_loss: 1945237454.9603\n",
      "Epoch 5334/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 371249426.8678 - val_loss: 807859559.8582\n",
      "Epoch 5335/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 162887325.8210 - val_loss: 1246396530.9390\n",
      "Epoch 5336/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 286563950.2262 - val_loss: 3071385511.2821\n",
      "Epoch 5337/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 547230991.0726 - val_loss: 1042294107.1302\n",
      "Epoch 5338/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 295227862.0777 - val_loss: 1160910491.3643\n",
      "Epoch 5339/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 410275518.0191 - val_loss: 12556258008.7539\n",
      "Epoch 5340/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 4617152166.9690 - val_loss: 857567588.4737\n",
      "Epoch 5341/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 206749604.1058 - val_loss: 768056749.8442\n",
      "Epoch 5342/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 155974932.1328 - val_loss: 780278472.1103\n",
      "Epoch 5343/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 248590712.5853 - val_loss: 775137856.9541\n",
      "Epoch 5344/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 142818000.8194 - val_loss: 1133008436.8563\n",
      "Epoch 5345/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 161989526.7349 - val_loss: 990544123.8774\n",
      "Epoch 5346/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 155525348.3579 - val_loss: 1563306680.9969\n",
      "Epoch 5347/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 276691382.9961 - val_loss: 820608734.7758\n",
      "Epoch 5348/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 248834427.4440 - val_loss: 2062595650.3944\n",
      "Epoch 5349/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 570171532.3984 - val_loss: 993742484.2262\n",
      "Epoch 5350/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 184772158.3613 - val_loss: 796929248.1980\n",
      "Epoch 5351/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 338741810.6382 - val_loss: 1432861869.5831\n",
      "Epoch 5352/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 635201564.5965 - val_loss: 5389793333.5764\n",
      "Epoch 5353/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 924747848.9814 - val_loss: 1081006048.6841\n",
      "Epoch 5354/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 252094269.9471 - val_loss: 2781775401.8385\n",
      "Epoch 5355/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 396437362.2600 - val_loss: 1351451035.1302\n",
      "Epoch 5356/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 341589862.0597 - val_loss: 955421356.4309\n",
      "Epoch 5357/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 375596073.1300 - val_loss: 2203988290.1333\n",
      "Epoch 5358/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1070851408.2814 - val_loss: 1072530341.2478\n",
      "Epoch 5359/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 172933486.0236 - val_loss: 1228563691.5488\n",
      "Epoch 5360/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 187547389.2268 - val_loss: 1254329835.6928\n",
      "Epoch 5361/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 456725522.2786 - val_loss: 781042433.9488\n",
      "Epoch 5362/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 245217576.5898 - val_loss: 1025559781.7879\n",
      "Epoch 5363/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 604380527.2167 - val_loss: 3678995759.3834\n",
      "Epoch 5364/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 610213574.2307 - val_loss: 812432267.2788\n",
      "Epoch 5365/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 172265350.2915 - val_loss: 1196259725.6281\n",
      "Epoch 5366/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 293837419.0929 - val_loss: 2874272760.9159\n",
      "Epoch 5367/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 641220894.1092 - val_loss: 3012358778.5632\n",
      "Epoch 5368/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 840904984.1216 - val_loss: 906731548.4264\n",
      "Epoch 5369/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 235068223.9820 - val_loss: 795771990.7376\n",
      "Epoch 5370/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 216087973.6995 - val_loss: 887163517.5156\n",
      "Epoch 5371/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 288412489.1581 - val_loss: 1011617403.2023\n",
      "Epoch 5372/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 429378217.0580 - val_loss: 1425051965.4841\n",
      "Epoch 5373/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1194586735.1176 - val_loss: 846812807.4352\n",
      "Epoch 5374/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 338108684.3894 - val_loss: 935959804.3184\n",
      "Epoch 5375/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 237493433.2921 - val_loss: 930056205.2141\n",
      "Epoch 5376/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 242590458.1654 - val_loss: 957756886.8276\n",
      "Epoch 5377/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 417500050.4783 - val_loss: 923869315.5916\n",
      "Epoch 5378/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 224273893.1683 - val_loss: 838817619.1280\n",
      "Epoch 5379/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 300456981.7715 - val_loss: 936478077.1916\n",
      "Epoch 5380/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 629330644.9848 - val_loss: 1243430967.7637\n",
      "Epoch 5381/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 501786531.4755 - val_loss: 1554878213.3558\n",
      "Epoch 5382/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 534981911.0681 - val_loss: 815599896.4478\n",
      "Epoch 5383/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 232734054.4288 - val_loss: 6357271424.3961\n",
      "Epoch 5384/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 910429577.3101 - val_loss: 951305451.0582\n",
      "Epoch 5385/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 638101805.4699 - val_loss: 850028192.5851\n",
      "Epoch 5386/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 284210791.6624 - val_loss: 1040684658.4619\n",
      "Epoch 5387/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 324240896.7563 - val_loss: 1070383331.8436\n",
      "Epoch 5388/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1408919632.3151 - val_loss: 1367010564.1496\n",
      "Epoch 5389/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 529633047.3787 - val_loss: 753584592.2565\n",
      "Epoch 5390/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 144278611.7141 - val_loss: 755406197.0093\n",
      "Epoch 5391/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 176972606.9690 - val_loss: 821593321.8385\n",
      "Epoch 5392/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 588821539.1874 - val_loss: 1271635950.5193\n",
      "Epoch 5393/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 273292680.9589 - val_loss: 823062637.8532\n",
      "Epoch 5394/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 197547472.3151 - val_loss: 795316915.8031\n",
      "Epoch 5395/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 251042093.1638 - val_loss: 1020284194.7094\n",
      "Epoch 5396/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 283259178.0664 - val_loss: 1939869806.6093\n",
      "Epoch 5397/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 840558188.5155 - val_loss: 1336316778.2616\n",
      "Epoch 5398/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 796124062.7214 - val_loss: 1564259181.4751\n",
      "Epoch 5399/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 351956389.2212 - val_loss: 1303200472.6188\n",
      "Epoch 5400/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 498655034.6337 - val_loss: 2132612790.4045\n",
      "Epoch 5401/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 461649066.6730 - val_loss: 869200101.5179\n",
      "Epoch 5402/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 281535779.3585 - val_loss: 1049257958.8321\n",
      "Epoch 5403/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 2946536967.4913 - val_loss: 4440365233.0037\n",
      "Epoch 5404/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 476409977.0490 - val_loss: 1062564596.4062\n",
      "Epoch 5405/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 288863624.8059 - val_loss: 972943387.0222\n",
      "Epoch 5406/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 145384994.5121 - val_loss: 1540798952.9564\n",
      "Epoch 5407/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 162405116.8126 - val_loss: 1763770325.5044\n",
      "Epoch 5408/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 164009007.4553 - val_loss: 727048305.3727\n",
      "Epoch 5409/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 123368684.4885 - val_loss: 895961172.1001\n",
      "Epoch 5410/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 266009566.6494 - val_loss: 1668803593.1814\n",
      "Epoch 5411/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 96us/step - loss: 316793305.5397 - val_loss: 1017395353.9060\n",
      "Epoch 5412/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 217068551.7704 - val_loss: 805748075.0537\n",
      "Epoch 5413/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 275923566.0495 - val_loss: 939870801.6518\n",
      "Epoch 5414/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 308305178.1564 - val_loss: 1235938214.4180\n",
      "Epoch 5415/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 255642591.7794 - val_loss: 1033694665.1094\n",
      "Epoch 5416/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 337259166.4693 - val_loss: 6029829301.5404\n",
      "Epoch 5417/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1352984208.2071 - val_loss: 2821216039.3902\n",
      "Epoch 5418/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 679232275.8402 - val_loss: 1111821564.2914\n",
      "Epoch 5419/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 576773547.3810 - val_loss: 998684762.2301\n",
      "Epoch 5420/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 318338937.8773 - val_loss: 1040556385.3412\n",
      "Epoch 5421/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 595456302.6764 - val_loss: 1795304131.7626\n",
      "Epoch 5422/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1000069249.6387 - val_loss: 1949140095.3879\n",
      "Epoch 5423/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 404921961.7062 - val_loss: 2741891208.8574\n",
      "Epoch 5424/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 439484124.9207 - val_loss: 1398115518.1097\n",
      "Epoch 5425/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 248984010.0326 - val_loss: 736611343.0504\n",
      "Epoch 5426/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 111351129.3776 - val_loss: 868901727.0639\n",
      "Epoch 5427/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 164582269.2290 - val_loss: 804210340.8878\n",
      "Epoch 5428/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 236283113.1210 - val_loss: 797954328.4568\n",
      "Epoch 5429/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 746344580.6213 - val_loss: 3000957137.1207\n",
      "Epoch 5430/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 3316161841.5824 - val_loss: 890121975.4037\n",
      "Epoch 5431/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 136696446.7431 - val_loss: 763573640.1553\n",
      "Epoch 5432/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 190334744.7833 - val_loss: 877772389.2388\n",
      "Epoch 5433/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 214548555.6151 - val_loss: 816955236.0686\n",
      "Epoch 5434/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 168830523.1469 - val_loss: 954942484.2352\n",
      "Epoch 5435/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 139202214.4198 - val_loss: 1051414868.2892\n",
      "Epoch 5436/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 231898201.7153 - val_loss: 2946067777.8183\n",
      "Epoch 5437/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 413032940.3500 - val_loss: 741066000.4816\n",
      "Epoch 5438/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 152832695.2662 - val_loss: 811742687.8380\n",
      "Epoch 5439/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 253187090.4491 - val_loss: 847662865.0037\n",
      "Epoch 5440/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 257971567.7929 - val_loss: 1581721423.1404\n",
      "Epoch 5441/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 715095140.9522 - val_loss: 2805581693.2996\n",
      "Epoch 5442/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1240093403.8582 - val_loss: 3820463336.1643\n",
      "Epoch 5443/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 743465410.7372 - val_loss: 1364049475.3305\n",
      "Epoch 5444/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 355689128.9004 - val_loss: 1049802799.1944\n",
      "Epoch 5445/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 215675412.8216 - val_loss: 800232389.0858\n",
      "Epoch 5446/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 201290868.0248 - val_loss: 781252126.0287\n",
      "Epoch 5447/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 281769556.9837 - val_loss: 776169617.8678\n",
      "Epoch 5448/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1965353729.5127 - val_loss: 1003701112.4096\n",
      "Epoch 5449/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 459080866.9713 - val_loss: 964557822.6498\n",
      "Epoch 5450/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 271840462.5594 - val_loss: 1294953558.8456\n",
      "Epoch 5451/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 399848906.0754 - val_loss: 996340872.4253\n",
      "Epoch 5452/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 173818143.9100 - val_loss: 1570231176.3533\n",
      "Epoch 5453/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 651631548.5785 - val_loss: 2800440467.5871\n",
      "Epoch 5454/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1176334413.2358 - val_loss: 811188061.8892\n",
      "Epoch 5455/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 133240150.7743 - val_loss: 734740230.6340\n",
      "Epoch 5456/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 115040041.0670 - val_loss: 814479917.9612\n",
      "Epoch 5457/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 234323276.9477 - val_loss: 1496792770.7634\n",
      "Epoch 5458/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 854390094.5864 - val_loss: 3106237049.2669\n",
      "Epoch 5459/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1070018917.5284 - val_loss: 1112945106.6509\n",
      "Epoch 5460/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 362203941.7310 - val_loss: 813696879.0594\n",
      "Epoch 5461/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 147930038.5786 - val_loss: 974920150.5980\n",
      "Epoch 5462/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 209841191.6533 - val_loss: 1181356305.9218\n",
      "Epoch 5463/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 310463076.4052 - val_loss: 947123276.6200\n",
      "Epoch 5464/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 316563969.3776 - val_loss: 1284403972.5547\n",
      "Epoch 5465/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 585845615.9910 - val_loss: 1738750351.8965\n",
      "Epoch 5466/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 233176090.9308 - val_loss: 1057982124.8720\n",
      "Epoch 5467/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 228603009.9629 - val_loss: 917008622.4653\n",
      "Epoch 5468/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 180571074.5594 - val_loss: 750402153.0914\n",
      "Epoch 5469/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 859786718.4693 - val_loss: 2303816696.0068\n",
      "Epoch 5470/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 380803552.2881 - val_loss: 825550471.5792\n",
      "Epoch 5471/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 353414247.2392 - val_loss: 1093223462.4270\n",
      "Epoch 5472/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 509099932.8216 - val_loss: 1019447697.6068\n",
      "Epoch 5473/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 318311070.2082 - val_loss: 1270258213.8779\n",
      "Epoch 5474/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 173859893.2538 - val_loss: 1214939027.3890\n",
      "Epoch 5475/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 328047103.2077 - val_loss: 923665192.2093\n",
      "Epoch 5476/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 677596680.6078 - val_loss: 2439505426.8309\n",
      "Epoch 5477/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 573650928.1778 - val_loss: 1283748924.1564\n",
      "Epoch 5478/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 654754446.1182 - val_loss: 1282129941.8914\n",
      "Epoch 5479/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 508470581.9606 - val_loss: 1134155811.3755\n",
      "Epoch 5480/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 372362691.9077 - val_loss: 797239968.4231\n",
      "Epoch 5481/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 270654434.7552 - val_loss: 1547110968.7449\n",
      "Epoch 5482/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1541792919.6263 - val_loss: 1065609488.9767\n",
      "Epoch 5483/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 363436954.8768 - val_loss: 1083328597.2073\n",
      "Epoch 5484/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 186965645.8120 - val_loss: 766916085.8374\n",
      "Epoch 5485/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 163147089.0388 - val_loss: 965080689.7778\n",
      "Epoch 5486/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 404913210.3028 - val_loss: 946670303.9010\n",
      "Epoch 5487/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 177221178.4761 - val_loss: 884209281.3142\n",
      "Epoch 5488/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 182796931.1576 - val_loss: 1578522642.4169\n",
      "Epoch 5489/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 848293909.1818 - val_loss: 1863916969.9105\n",
      "Epoch 5490/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1090186767.4868 - val_loss: 1300572426.5136\n",
      "Epoch 5491/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 214308324.1958 - val_loss: 961339217.8408\n",
      "Epoch 5492/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 970308531.0163 - val_loss: 1353266518.5035\n",
      "Epoch 5493/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 294696007.8334 - val_loss: 2135152486.1750\n",
      "Epoch 5494/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 355670053.5014 - val_loss: 1040483804.6695\n",
      "Epoch 5495/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 443180714.3185 - val_loss: 2269215408.7156\n",
      "Epoch 5496/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 342157331.7591 - val_loss: 851187102.9738\n",
      "Epoch 5497/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 124232232.3376 - val_loss: 1255541005.2141\n",
      "Epoch 5498/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 305527360.0180 - val_loss: 858396978.7679\n",
      "Epoch 5499/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 546539293.2876 - val_loss: 1497282014.9198\n",
      "Epoch 5500/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 360038678.8970 - val_loss: 1152111299.6546\n",
      "Epoch 5501/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 210783955.6646 - val_loss: 3953841314.3134\n",
      "Epoch 5502/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 879176185.4811 - val_loss: 1604704011.2158\n",
      "Epoch 5503/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 268174475.7302 - val_loss: 1127392948.5322\n",
      "Epoch 5504/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 217470608.9319 - val_loss: 847508763.7108\n",
      "Epoch 5505/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 153446911.2617 - val_loss: 747673944.3128\n",
      "Epoch 5506/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 167420348.5020 - val_loss: 960075064.9519\n",
      "Epoch 5507/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 271714337.2876 - val_loss: 1921557905.6248\n",
      "Epoch 5508/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 835977523.7727 - val_loss: 1069757708.6380\n",
      "Epoch 5509/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 275162028.4918 - val_loss: 1013481536.6481\n",
      "Epoch 5510/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 666438833.0535 - val_loss: 3080815822.9603\n",
      "Epoch 5511/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 621366224.8554 - val_loss: 822546662.3100\n",
      "Epoch 5512/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1957015673.8413 - val_loss: 1662829780.5772\n",
      "Epoch 5513/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 505946225.5352 - val_loss: 895181751.8942\n",
      "Epoch 5514/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 155419231.2077 - val_loss: 1278256586.0546\n",
      "Epoch 5515/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 333566980.5335 - val_loss: 914590811.4588\n",
      "Epoch 5516/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 165561621.2223 - val_loss: 790254926.4203\n",
      "Epoch 5517/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 138213633.5082 - val_loss: 765474703.4014\n",
      "Epoch 5518/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 152439491.3360 - val_loss: 857915390.0827\n",
      "Epoch 5519/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 237909941.5374 - val_loss: 1144827386.5271\n",
      "Epoch 5520/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 219262342.3545 - val_loss: 913100831.5859\n",
      "Epoch 5521/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 215599485.8886 - val_loss: 1745876950.8096\n",
      "Epoch 5522/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 605013151.0771 - val_loss: 1123520095.3609\n",
      "Epoch 5523/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 235835622.9330 - val_loss: 2210413339.6433\n",
      "Epoch 5524/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1022530932.5830 - val_loss: 1618002260.8653\n",
      "Epoch 5525/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 331428507.2684 - val_loss: 912933679.9550\n",
      "Epoch 5526/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 318702405.6905 - val_loss: 946824115.6681\n",
      "Epoch 5527/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 794188689.7918 - val_loss: 1623262651.6253\n",
      "Epoch 5528/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1348657583.1379 - val_loss: 803773772.8720\n",
      "Epoch 5529/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 230933660.6866 - val_loss: 1881349327.9685\n",
      "Epoch 5530/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 362969643.7591 - val_loss: 1137085877.1713\n",
      "Epoch 5531/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 298931229.6016 - val_loss: 1336543142.5980\n",
      "Epoch 5532/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 392591033.7243 - val_loss: 1028994947.3665\n",
      "Epoch 5533/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 171051253.3573 - val_loss: 881442757.7429\n",
      "Epoch 5534/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 245071734.2757 - val_loss: 784969597.3806\n",
      "Epoch 5535/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 161446285.7400 - val_loss: 785156249.1454\n",
      "Epoch 5536/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 380358695.0681 - val_loss: 748668855.9437\n",
      "Epoch 5537/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 604930095.1986 - val_loss: 794268048.0945\n",
      "Epoch 5538/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 180664153.7558 - val_loss: 1090732183.4847\n",
      "Epoch 5539/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 287124303.0546 - val_loss: 838350526.8208\n",
      "Epoch 5540/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 450468895.6218 - val_loss: 3363462640.4456\n",
      "Epoch 5541/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 95us/step - loss: 1173930592.2341 - val_loss: 908750682.4461\n",
      "Epoch 5542/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 185347405.2921 - val_loss: 782839032.4298\n",
      "Epoch 5543/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 416745358.5144 - val_loss: 1164262340.4107\n",
      "Epoch 5544/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1033663186.3320 - val_loss: 2277078126.6093\n",
      "Epoch 5545/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 836274319.7569 - val_loss: 1030754784.4051\n",
      "Epoch 5546/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 162347256.3196 - val_loss: 914608672.7381\n",
      "Epoch 5547/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 209477341.4969 - val_loss: 761816229.5539\n",
      "Epoch 5548/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 422006342.4468 - val_loss: 1396964961.5752\n",
      "Epoch 5549/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 765483714.8452 - val_loss: 1340996938.1986\n",
      "Epoch 5550/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 271240748.4615 - val_loss: 1322747173.5539\n",
      "Epoch 5551/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 174205385.1075 - val_loss: 778064122.2571\n",
      "Epoch 5552/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 190591244.7091 - val_loss: 1098368246.6205\n",
      "Epoch 5553/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 467640271.5408 - val_loss: 802861317.5269\n",
      "Epoch 5554/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 300242939.8582 - val_loss: 1949050283.6748\n",
      "Epoch 5555/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1517613477.2763 - val_loss: 821191188.4062\n",
      "Epoch 5556/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 290011331.2729 - val_loss: 888761897.0104\n",
      "Epoch 5557/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 209112399.5228 - val_loss: 850248276.5817\n",
      "Epoch 5558/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 265331864.5537 - val_loss: 835062186.8287\n",
      "Epoch 5559/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 252503977.1480 - val_loss: 890100890.7184\n",
      "Epoch 5560/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 309629990.4468 - val_loss: 870923487.4239\n",
      "Epoch 5561/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 349251747.2234 - val_loss: 2120460733.0835\n",
      "Epoch 5562/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 1327792886.7980 - val_loss: 972748133.0273\n",
      "Epoch 5563/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 192964286.7980 - val_loss: 752970935.6467\n",
      "Epoch 5564/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 116433671.2437 - val_loss: 1085154647.2056\n",
      "Epoch 5565/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 413400287.7344 - val_loss: 872717269.2253\n",
      "Epoch 5566/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 178855779.2110 - val_loss: 735040868.1677\n",
      "Epoch 5567/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 171536301.4879 - val_loss: 1233144292.1226\n",
      "Epoch 5568/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 224784900.1733 - val_loss: 798719837.5876\n",
      "Epoch 5569/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 426806947.9797 - val_loss: 1171980795.4093\n",
      "Epoch 5570/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 753954213.8976 - val_loss: 1136196609.0442\n",
      "Epoch 5571/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 426254622.6562 - val_loss: 1143612507.2551\n",
      "Epoch 5572/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 516737730.2690 - val_loss: 1497820739.5466\n",
      "Epoch 5573/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 404755253.1863 - val_loss: 1644827409.7508\n",
      "Epoch 5574/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 625468485.9066 - val_loss: 3799487752.2813\n",
      "Epoch 5575/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 823432854.3731 - val_loss: 749539279.4689\n",
      "Epoch 5576/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 182307734.4969 - val_loss: 1261441089.9443\n",
      "Epoch 5577/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 626038642.6021 - val_loss: 881119499.4318\n",
      "Epoch 5578/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 211332606.3545 - val_loss: 772177713.8678\n",
      "Epoch 5579/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 211756187.5881 - val_loss: 878895937.4762\n",
      "Epoch 5580/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 439293446.0687 - val_loss: 1499648758.7466\n",
      "Epoch 5581/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 440146439.2032 - val_loss: 1471407553.8363\n",
      "Epoch 5582/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 355386838.1857 - val_loss: 1108325250.8985\n",
      "Epoch 5583/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 349788785.7153 - val_loss: 777797450.8017\n",
      "Epoch 5584/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 374909538.2510 - val_loss: 1606812590.1052\n",
      "Epoch 5585/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 3382362880.3241 - val_loss: 1204193413.7789\n",
      "Epoch 5586/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 294607387.9662 - val_loss: 790011251.7041\n",
      "Epoch 5587/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 184425956.3759 - val_loss: 963380807.3091\n",
      "Epoch 5588/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 173419775.8672 - val_loss: 879568018.4349\n",
      "Epoch 5589/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 138806539.6871 - val_loss: 850543242.3876\n",
      "Epoch 5590/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 230139806.3703 - val_loss: 830567679.9370\n",
      "Epoch 5591/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 119358067.8807 - val_loss: 716238920.9294\n",
      "Epoch 5592/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 314449472.8284 - val_loss: 1694565510.0895\n",
      "Epoch 5593/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 728452389.1593 - val_loss: 1417623721.0194\n",
      "Epoch 5594/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 303248569.0895 - val_loss: 925030184.3353\n",
      "Epoch 5595/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 261960688.6213 - val_loss: 1221404270.5463\n",
      "Epoch 5596/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 535657526.4918 - val_loss: 1460330112.4681\n",
      "Epoch 5597/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1444190432.5943 - val_loss: 1018568259.6546\n",
      "Epoch 5598/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 714372168.4637 - val_loss: 1221584548.1677\n",
      "Epoch 5599/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 329234043.1379 - val_loss: 822008028.8405\n",
      "Epoch 5600/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 213652522.2487 - val_loss: 803036774.9401\n",
      "Epoch 5601/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 135312000.7001 - val_loss: 811540324.9868\n",
      "Epoch 5602/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 258097182.0326 - val_loss: 900706707.1190\n",
      "Epoch 5603/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 126817505.3202 - val_loss: 824196314.7252\n",
      "Epoch 5604/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 191468541.6410 - val_loss: 955356052.9733\n",
      "Epoch 5605/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 223569661.2268 - val_loss: 1457464630.5125\n",
      "Epoch 5606/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 391383249.4299 - val_loss: 1763207299.8031\n",
      "Epoch 5607/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 585683967.7299 - val_loss: 1065488019.7311\n",
      "Epoch 5608/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 716425657.0388 - val_loss: 994618942.6858\n",
      "Epoch 5609/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1019404172.6460 - val_loss: 5243171141.5989\n",
      "Epoch 5610/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 914563120.6978 - val_loss: 1454901477.6079\n",
      "Epoch 5611/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 262718912.6342 - val_loss: 1742028394.4191\n",
      "Epoch 5612/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 331534974.6134 - val_loss: 1579534323.6861\n",
      "Epoch 5613/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 283954092.6235 - val_loss: 1036290194.9390\n",
      "Epoch 5614/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 300118788.9342 - val_loss: 2313611387.9359\n",
      "Epoch 5615/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 370633925.4930 - val_loss: 1056388111.4194\n",
      "Epoch 5616/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 263401079.8751 - val_loss: 910683859.8571\n",
      "Epoch 5617/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 237649783.7704 - val_loss: 798270644.5232\n",
      "Epoch 5618/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 207914318.8756 - val_loss: 1271939817.6045\n",
      "Epoch 5619/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 649789765.9876 - val_loss: 1146196808.2273\n",
      "Epoch 5620/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 802122288.1891 - val_loss: 2221932116.0596\n",
      "Epoch 5621/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 588200531.4057 - val_loss: 841654425.5595\n",
      "Epoch 5622/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 162629343.8739 - val_loss: 2495832951.2506\n",
      "Epoch 5623/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 805857228.1733 - val_loss: 3091019807.2979\n",
      "Epoch 5624/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 549503928.1486 - val_loss: 1582943248.5986\n",
      "Epoch 5625/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 669999477.3618 - val_loss: 932661709.5741\n",
      "Epoch 5626/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 187360724.3579 - val_loss: 872746401.3952\n",
      "Epoch 5627/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 284830645.6635 - val_loss: 781752072.9114\n",
      "Epoch 5628/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 190825404.4344 - val_loss: 1306304463.1044\n",
      "Epoch 5629/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 413699706.5436 - val_loss: 971108145.8993\n",
      "Epoch 5630/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 322729533.9831 - val_loss: 1115360723.5871\n",
      "Epoch 5631/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 190158414.8700 - val_loss: 838727826.5339\n",
      "Epoch 5632/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 837715008.8284 - val_loss: 876369193.6765\n",
      "Epoch 5633/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 613035232.1418 - val_loss: 2259291019.5128\n",
      "Epoch 5634/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 651240605.3348 - val_loss: 4250795620.1677\n",
      "Epoch 5635/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 508599123.4755 - val_loss: 1017838158.6633\n",
      "Epoch 5636/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 221405162.4356 - val_loss: 906339244.7865\n",
      "Epoch 5637/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 256996236.9567 - val_loss: 746395973.1308\n",
      "Epoch 5638/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 182780515.3225 - val_loss: 840495986.3539\n",
      "Epoch 5639/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 232789953.2245 - val_loss: 766929513.7845\n",
      "Epoch 5640/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 734993960.0495 - val_loss: 5597578935.9167\n",
      "Epoch 5641/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1454343746.4761 - val_loss: 1165828614.0219\n",
      "Epoch 5642/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 198024844.9207 - val_loss: 1072211678.6588\n",
      "Epoch 5643/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 265352762.0867 - val_loss: 915726099.0110\n",
      "Epoch 5644/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 299057916.4254 - val_loss: 900800209.8948\n",
      "Epoch 5645/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 579840771.9347 - val_loss: 1295851074.7634\n",
      "Epoch 5646/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 566662900.4569 - val_loss: 1422931318.8546\n",
      "Epoch 5647/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 323836860.7172 - val_loss: 818758320.2475\n",
      "Epoch 5648/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 205771593.8683 - val_loss: 1163408002.0883\n",
      "Epoch 5649/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 473714822.0506 - val_loss: 940711317.2343\n",
      "Epoch 5650/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 682554960.8554 - val_loss: 2399994846.4608\n",
      "Epoch 5651/10000\n",
      "3554/3554 [==============================] - 1s 146us/step - loss: 250997081.2966 - val_loss: 1757344283.5983\n",
      "Epoch 5652/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 292710933.6635 - val_loss: 978031700.6492\n",
      "Epoch 5653/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 357163991.9100 - val_loss: 730861830.7150\n",
      "Epoch 5654/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 188877830.5909 - val_loss: 734451802.8962\n",
      "Epoch 5655/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 142321322.1024 - val_loss: 861157934.7983\n",
      "Epoch 5656/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 232311507.2774 - val_loss: 1172044664.6008\n",
      "Epoch 5657/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 363633496.7721 - val_loss: 1076464093.5966\n",
      "Epoch 5658/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 167969652.6674 - val_loss: 912721673.4335\n",
      "Epoch 5659/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 443319943.5993 - val_loss: 4283145371.5443\n",
      "Epoch 5660/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 1784482827.3765 - val_loss: 1427769903.3834\n",
      "Epoch 5661/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 574482825.1908 - val_loss: 2949511779.3755\n",
      "Epoch 5662/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 401846545.9719 - val_loss: 846876484.7527\n",
      "Epoch 5663/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 228460572.2003 - val_loss: 770843095.9257\n",
      "Epoch 5664/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 297365785.1593 - val_loss: 902961267.4160\n",
      "Epoch 5665/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 253877638.3523 - val_loss: 858074762.4416\n",
      "Epoch 5666/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 210212406.8655 - val_loss: 1912806623.7750\n",
      "Epoch 5667/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 1322820805.2223 - val_loss: 16994231998.2537\n",
      "Epoch 5668/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1850806813.8210 - val_loss: 979050258.0568\n",
      "Epoch 5669/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 304115635.8267 - val_loss: 795051240.3443\n",
      "Epoch 5670/10000\n",
      "3554/3554 [==============================] - 0s 140us/step - loss: 173690284.0743 - val_loss: 784318864.1305\n",
      "Epoch 5671/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 125us/step - loss: 155458933.8264 - val_loss: 961183873.6203\n",
      "Epoch 5672/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 448047765.1773 - val_loss: 1760792030.6228\n",
      "Epoch 5673/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 313792998.5189 - val_loss: 1036350277.3288\n",
      "Epoch 5674/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 304564969.5723 - val_loss: 2512841400.6729\n",
      "Epoch 5675/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 369806851.4530 - val_loss: 754678764.7010\n",
      "Epoch 5676/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 272622161.5307 - val_loss: 805920625.1207\n",
      "Epoch 5677/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 337406875.1064 - val_loss: 2669304047.0774\n",
      "Epoch 5678/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 252189699.0107 - val_loss: 1324408293.3693\n",
      "Epoch 5679/10000\n",
      "3554/3554 [==============================] - 0s 140us/step - loss: 289303517.8210 - val_loss: 3225637239.0886\n",
      "Epoch 5680/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 845209379.7276 - val_loss: 1448480205.4121\n",
      "Epoch 5681/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 543679168.0585 - val_loss: 830779662.5823\n",
      "Epoch 5682/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 252341082.3545 - val_loss: 837192461.9432\n",
      "Epoch 5683/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 384702426.0394 - val_loss: 1257902115.8616\n",
      "Epoch 5684/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1513846020.0428 - val_loss: 2219219954.5339\n",
      "Epoch 5685/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 595873914.5976 - val_loss: 1349222871.5297\n",
      "Epoch 5686/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 231871248.6573 - val_loss: 826912262.2830\n",
      "Epoch 5687/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 284220701.0974 - val_loss: 936748732.4985\n",
      "Epoch 5688/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 317439128.3827 - val_loss: 1007746908.2734\n",
      "Epoch 5689/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 185630693.9741 - val_loss: 962812226.8039\n",
      "Epoch 5690/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 184142749.6162 - val_loss: 1454302589.6686\n",
      "Epoch 5691/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 218571926.1992 - val_loss: 1231673024.9091\n",
      "Epoch 5692/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1229975862.2127 - val_loss: 1974951663.7975\n",
      "Epoch 5693/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 367814748.1283 - val_loss: 3614288352.1710\n",
      "Epoch 5694/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 710846137.1750 - val_loss: 807029619.2630\n",
      "Epoch 5695/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 317556017.2200 - val_loss: 2629659904.2205\n",
      "Epoch 5696/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 569624502.7259 - val_loss: 834116302.5665\n",
      "Epoch 5697/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 164004982.0551 - val_loss: 786212655.4194\n",
      "Epoch 5698/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 178247705.5779 - val_loss: 801375110.0489\n",
      "Epoch 5699/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 159649670.8621 - val_loss: 718119909.2343\n",
      "Epoch 5700/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 463368408.7383 - val_loss: 910032281.4020\n",
      "Epoch 5701/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 344993657.4631 - val_loss: 921539808.5716\n",
      "Epoch 5702/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 180672224.7158 - val_loss: 914049152.9992\n",
      "Epoch 5703/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 293227490.3950 - val_loss: 1083264917.4594\n",
      "Epoch 5704/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 471786999.1041 - val_loss: 1610526358.1075\n",
      "Epoch 5705/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 371440996.0934 - val_loss: 780426838.6655\n",
      "Epoch 5706/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 196405701.0782 - val_loss: 802262929.2467\n",
      "Epoch 5707/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 235440731.2279 - val_loss: 2167481632.6571\n",
      "Epoch 5708/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 983002274.5031 - val_loss: 5681620527.1674\n",
      "Epoch 5709/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1150468935.4192 - val_loss: 929236672.4861\n",
      "Epoch 5710/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 262015871.5385 - val_loss: 1206376772.3387\n",
      "Epoch 5711/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 301642948.3579 - val_loss: 1379340325.8059\n",
      "Epoch 5712/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 401090847.2977 - val_loss: 1666452258.4574\n",
      "Epoch 5713/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 712086599.0231 - val_loss: 16541133149.6866\n",
      "Epoch 5714/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 3945001009.7243 - val_loss: 1294623533.7451\n",
      "Epoch 5715/10000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 276923838.476 - 0s 85us/step - loss: 249719674.9353 - val_loss: 732380585.9376\n",
      "Epoch 5716/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 113953162.8407 - val_loss: 1232098360.2183\n",
      "Epoch 5717/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 130567209.6342 - val_loss: 705237526.1030\n",
      "Epoch 5718/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 125275339.6556 - val_loss: 726586845.8037\n",
      "Epoch 5719/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 148540197.8976 - val_loss: 864910191.2011\n",
      "Epoch 5720/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 166121390.0642 - val_loss: 738144239.0684\n",
      "Epoch 5721/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 225412246.1497 - val_loss: 1256782784.4501\n",
      "Epoch 5722/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 210910235.4800 - val_loss: 1097814611.7896\n",
      "Epoch 5723/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 261212005.0062 - val_loss: 856308918.5305\n",
      "Epoch 5724/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 321420853.1953 - val_loss: 1489595980.1519\n",
      "Epoch 5725/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 466907916.7608 - val_loss: 1153890260.6492\n",
      "Epoch 5726/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 213146029.5059 - val_loss: 2271855269.3558\n",
      "Epoch 5727/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 289950298.2915 - val_loss: 2801554480.1035\n",
      "Epoch 5728/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1732752584.0495 - val_loss: 1576852601.2850\n",
      "Epoch 5729/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 955241945.8503 - val_loss: 1390600661.8104\n",
      "Epoch 5730/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 409524605.0670 - val_loss: 818960893.5336\n",
      "Epoch 5731/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 138417983.8199 - val_loss: 710247288.4298\n",
      "Epoch 5732/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 429215096.0855 - val_loss: 1160147076.0866\n",
      "Epoch 5733/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 330004880.6033 - val_loss: 754828439.8177\n",
      "Epoch 5734/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 575078428.7766 - val_loss: 852615757.8037\n",
      "Epoch 5735/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 337361216.6415 - val_loss: 758466585.1589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5736/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 138753023.2167 - val_loss: 1035876165.5989\n",
      "Epoch 5737/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 244281447.4733 - val_loss: 1158573570.4124\n",
      "Epoch 5738/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 481822054.8250 - val_loss: 921649666.5204\n",
      "Epoch 5739/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 864081111.8965 - val_loss: 874864742.5440\n",
      "Epoch 5740/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 282411431.7299 - val_loss: 782681576.9024\n",
      "Epoch 5741/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 315012216.8329 - val_loss: 807376621.8442\n",
      "Epoch 5742/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 166331902.8655 - val_loss: 1954990735.8065\n",
      "Epoch 5743/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 362308641.1885 - val_loss: 1369369949.5066\n",
      "Epoch 5744/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 456027560.5087 - val_loss: 1505372277.2298\n",
      "Epoch 5745/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1170634747.6781 - val_loss: 9280697565.7947\n",
      "Epoch 5746/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1165332413.9111 - val_loss: 1244679215.0774\n",
      "Epoch 5747/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 302988951.7411 - val_loss: 730846073.0239\n",
      "Epoch 5748/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 154192721.1255 - val_loss: 1335474920.4163\n",
      "Epoch 5749/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 381875175.8244 - val_loss: 1354675256.3848\n",
      "Epoch 5750/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 322672943.4328 - val_loss: 1372197164.7190\n",
      "Epoch 5751/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 926021318.6629 - val_loss: 4605668297.4875\n",
      "Epoch 5752/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 689190841.6972 - val_loss: 843765353.3705\n",
      "Epoch 5753/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 142737292.2555 - val_loss: 704368833.8543\n",
      "Epoch 5754/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 141204334.3883 - val_loss: 922135942.7331\n",
      "Epoch 5755/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 212756750.7665 - val_loss: 883523440.1755\n",
      "Epoch 5756/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 542187336.1756 - val_loss: 764570635.4048\n",
      "Epoch 5757/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 355537972.1024 - val_loss: 737258282.6847\n",
      "Epoch 5758/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 248525767.4440 - val_loss: 778687900.3364\n",
      "Epoch 5759/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 186384856.6348 - val_loss: 825901193.6765\n",
      "Epoch 5760/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 312318551.4823 - val_loss: 1024360213.4053\n",
      "Epoch 5761/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 255343581.3438 - val_loss: 749001568.9181\n",
      "Epoch 5762/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 225355816.6978 - val_loss: 1588646330.8692\n",
      "Epoch 5763/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 539680627.0163 - val_loss: 1539743388.0394\n",
      "Epoch 5764/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 609169140.7631 - val_loss: 4342243315.9741\n",
      "Epoch 5765/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1086716586.6066 - val_loss: 990700882.3989\n",
      "Epoch 5766/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 303649533.4609 - val_loss: 892284042.7117\n",
      "Epoch 5767/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 360984243.3945 - val_loss: 843937890.5474\n",
      "Epoch 5768/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 303476902.1587 - val_loss: 900056798.9558\n",
      "Epoch 5769/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 219954588.0383 - val_loss: 763480465.6068\n",
      "Epoch 5770/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 285889754.6517 - val_loss: 885093051.6613\n",
      "Epoch 5771/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 426238912.3602 - val_loss: 4674045763.0425\n",
      "Epoch 5772/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 1125865076.7721 - val_loss: 1129234430.9738\n",
      "Epoch 5773/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 532125809.5937 - val_loss: 2827201345.0262\n",
      "Epoch 5774/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 1931845191.1300 - val_loss: 779172923.1932\n",
      "Epoch 5775/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 175912207.8109 - val_loss: 732117677.8982\n",
      "Epoch 5776/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 223585999.4080 - val_loss: 735908961.1027\n",
      "Epoch 5777/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 200666212.3399 - val_loss: 1572277198.1682\n",
      "Epoch 5778/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 292449475.3799 - val_loss: 1231103212.6560\n",
      "Epoch 5779/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 850555356.3804 - val_loss: 1037326816.5761\n",
      "Epoch 5780/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 228265735.7096 - val_loss: 811181616.1035\n",
      "Epoch 5781/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 164212983.7209 - val_loss: 832040746.5406\n",
      "Epoch 5782/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 330638078.5909 - val_loss: 870317514.6667\n",
      "Epoch 5783/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 248516525.3708 - val_loss: 999512414.1907\n",
      "Epoch 5784/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 641134127.7929 - val_loss: 932579400.6954\n",
      "Epoch 5785/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 605348106.4176 - val_loss: 912899732.0506\n",
      "Epoch 5786/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 197267462.4108 - val_loss: 1165903749.5089\n",
      "Epoch 5787/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 411345018.3095 - val_loss: 1120415454.4968\n",
      "Epoch 5788/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 713634872.5380 - val_loss: 866398668.8900\n",
      "Epoch 5789/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 280506614.1902 - val_loss: 769397636.4827\n",
      "Epoch 5790/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 393362220.4209 - val_loss: 1566380174.1502\n",
      "Epoch 5791/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 521674203.0298 - val_loss: 1880455514.6262\n",
      "Epoch 5792/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 224424429.4429 - val_loss: 773652098.1018\n",
      "Epoch 5793/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 210036030.7060 - val_loss: 850724447.1629\n",
      "Epoch 5794/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 255868320.0090 - val_loss: 1783586596.1857\n",
      "Epoch 5795/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 3953937193.3101 - val_loss: 1460263077.0858\n",
      "Epoch 5796/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 369057043.2144 - val_loss: 895993487.5454\n",
      "Epoch 5797/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 151762409.8098 - val_loss: 736758444.8900\n",
      "Epoch 5798/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 146668832.9184 - val_loss: 764527197.7857\n",
      "Epoch 5799/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 116077521.6207 - val_loss: 820044853.4143\n",
      "Epoch 5800/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 190910128.8734 - val_loss: 787827450.5541\n",
      "Epoch 5801/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 149937972.0428 - val_loss: 1439399927.3586\n",
      "Epoch 5802/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 251165129.1480 - val_loss: 784617358.7623\n",
      "Epoch 5803/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 281210023.5903 - val_loss: 801788894.1007\n",
      "Epoch 5804/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 193565206.6359 - val_loss: 1073825361.5617\n",
      "Epoch 5805/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 224245664.7383 - val_loss: 1969477463.7097\n",
      "Epoch 5806/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 691784124.0743 - val_loss: 2648041217.7283\n",
      "Epoch 5807/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 547935873.9449 - val_loss: 1317917231.0594\n",
      "Epoch 5808/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 774080183.6804 - val_loss: 4869695789.1871\n",
      "Epoch 5809/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 895194013.0737 - val_loss: 769842024.7674\n",
      "Epoch 5810/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 288314142.6674 - val_loss: 2757233503.8830\n",
      "Epoch 5811/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 287790121.0580 - val_loss: 1721563938.9615\n",
      "Epoch 5812/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 281926666.6111 - val_loss: 984376896.7741\n",
      "Epoch 5813/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 221232526.9826 - val_loss: 790626800.0675\n",
      "Epoch 5814/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 192615984.5402 - val_loss: 838346948.6087\n",
      "Epoch 5815/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 331768828.1823 - val_loss: 2098847700.7572\n",
      "Epoch 5816/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1287952965.4384 - val_loss: 4629941402.0861\n",
      "Epoch 5817/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 954321257.8818 - val_loss: 900443328.3421\n",
      "Epoch 5818/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 174528752.3421 - val_loss: 869436376.0788\n",
      "Epoch 5819/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 151054038.1857 - val_loss: 1978827061.0363\n",
      "Epoch 5820/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 894198446.3523 - val_loss: 1673012260.7977\n",
      "Epoch 5821/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 321676956.9645 - val_loss: 743934890.9457\n",
      "Epoch 5822/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 152731248.1171 - val_loss: 815317692.5615\n",
      "Epoch 5823/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 333048405.8075 - val_loss: 1979660773.2838\n",
      "Epoch 5824/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 465106021.9246 - val_loss: 1122084609.3592\n",
      "Epoch 5825/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 281823003.9167 - val_loss: 1200071201.7913\n",
      "Epoch 5826/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 242335879.0951 - val_loss: 733096269.4661\n",
      "Epoch 5827/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 198586833.6117 - val_loss: 904285673.8385\n",
      "Epoch 5828/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 832653019.8762 - val_loss: 1583503724.4129\n",
      "Epoch 5829/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 640441822.8655 - val_loss: 1540010935.0166\n",
      "Epoch 5830/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 346203790.2802 - val_loss: 1892690603.8098\n",
      "Epoch 5831/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 271374925.4339 - val_loss: 811139270.5350\n",
      "Epoch 5832/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 486700988.2093 - val_loss: 1383098860.2329\n",
      "Epoch 5833/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 270679335.8694 - val_loss: 1987580694.1435\n",
      "Epoch 5834/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 604259005.1728 - val_loss: 832240570.2211\n",
      "Epoch 5835/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 874092624.7743 - val_loss: 1513445113.9150\n",
      "Epoch 5836/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 291361104.0270 - val_loss: 867488113.4177\n",
      "Epoch 5837/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 228407998.1272 - val_loss: 1453451687.4262\n",
      "Epoch 5838/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 286989017.5532 - val_loss: 1632043657.6855\n",
      "Epoch 5839/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 510211566.0191 - val_loss: 791169073.1207\n",
      "Epoch 5840/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 216957661.0287 - val_loss: 827681824.1710\n",
      "Epoch 5841/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 328327322.4716 - val_loss: 947718184.2543\n",
      "Epoch 5842/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1115719587.5115 - val_loss: 2049737213.1736\n",
      "Epoch 5843/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 780333060.5695 - val_loss: 2139984190.0377\n",
      "Epoch 5844/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 283724125.2808 - val_loss: 714023223.3406\n",
      "Epoch 5845/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 175304874.5521 - val_loss: 867391656.2588\n",
      "Epoch 5846/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 169588773.0062 - val_loss: 1269986950.0039\n",
      "Epoch 5847/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 290632088.9049 - val_loss: 891513590.2065\n",
      "Epoch 5848/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 408868890.5436 - val_loss: 885714727.4082\n",
      "Epoch 5849/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 486809028.3219 - val_loss: 1421141860.8878\n",
      "Epoch 5850/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 385288083.3180 - val_loss: 1015786740.7842\n",
      "Epoch 5851/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 479824783.3247 - val_loss: 851159503.4824\n",
      "Epoch 5852/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 356614810.3995 - val_loss: 2379134912.3601\n",
      "Epoch 5853/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 525669576.8239 - val_loss: 3286346339.5195\n",
      "Epoch 5854/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 502724009.0039 - val_loss: 911712825.8880\n",
      "Epoch 5855/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 244361195.6061 - val_loss: 804149653.0813\n",
      "Epoch 5856/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 213007192.8869 - val_loss: 1561389895.3271\n",
      "Epoch 5857/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 795176026.0394 - val_loss: 947885349.1578\n",
      "Epoch 5858/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 598620022.5661 - val_loss: 1145737145.5910\n",
      "Epoch 5859/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 281163946.5855 - val_loss: 763086495.5769\n",
      "Epoch 5860/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 133051648.3241 - val_loss: 1330036740.5817\n",
      "Epoch 5861/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 485959272.9589 - val_loss: 1390166638.5373\n",
      "Epoch 5862/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 192318232.5447 - val_loss: 1958249410.3584\n",
      "Epoch 5863/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 504601661.4339 - val_loss: 965689458.8354\n",
      "Epoch 5864/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 226324093.4665 - val_loss: 807533355.8368\n",
      "Epoch 5865/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 268643154.2600 - val_loss: 875532495.4824\n",
      "Epoch 5866/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 87us/step - loss: 900782760.1216 - val_loss: 2806414456.2588\n",
      "Epoch 5867/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1762464432.3331 - val_loss: 1244195185.2557\n",
      "Epoch 5868/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 292859404.1013 - val_loss: 818257886.7848\n",
      "Epoch 5869/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 185709154.0169 - val_loss: 784538857.1544\n",
      "Epoch 5870/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 152509393.3281 - val_loss: 735463608.2768\n",
      "Epoch 5871/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 154173706.1958 - val_loss: 701113726.1637\n",
      "Epoch 5872/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 259217314.4851 - val_loss: 803972875.5218\n",
      "Epoch 5873/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 678289794.1609 - val_loss: 1470505899.4138\n",
      "Epoch 5874/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 436597395.7727 - val_loss: 1226320240.1935\n",
      "Epoch 5875/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 215575295.0186 - val_loss: 939479135.0098\n",
      "Epoch 5876/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 283894280.3557 - val_loss: 1051220855.8987\n",
      "Epoch 5877/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 390134671.3247 - val_loss: 870807608.8889\n",
      "Epoch 5878/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 686782751.0096 - val_loss: 1220357288.0203\n",
      "Epoch 5879/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 285724881.7017 - val_loss: 764017189.9139\n",
      "Epoch 5880/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 262977797.6905 - val_loss: 1893741280.7471\n",
      "Epoch 5881/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1170441299.2324 - val_loss: 2487781329.1567\n",
      "Epoch 5882/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 354242386.7327 - val_loss: 735200648.4613\n",
      "Epoch 5883/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 231691586.2690 - val_loss: 2987389027.2315\n",
      "Epoch 5884/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1740531876.5279 - val_loss: 950538232.9564\n",
      "Epoch 5885/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 243991453.1052 - val_loss: 901408463.7705\n",
      "Epoch 5886/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 274937777.5667 - val_loss: 2858232930.2414\n",
      "Epoch 5887/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 235605427.9527 - val_loss: 787173614.1412\n",
      "Epoch 5888/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 136445711.9910 - val_loss: 710933751.9347\n",
      "Epoch 5889/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 161946513.6117 - val_loss: 1098708974.1952\n",
      "Epoch 5890/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 428078348.6866 - val_loss: 741634332.6515\n",
      "Epoch 5891/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 195425987.6016 - val_loss: 11931348237.8982\n",
      "Epoch 5892/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1911157337.0445 - val_loss: 961630772.8743\n",
      "Epoch 5893/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 688941063.2392 - val_loss: 6395258342.6520\n",
      "Epoch 5894/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 801347654.8610 - val_loss: 1355086937.6270\n",
      "Epoch 5895/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 232625925.4845 - val_loss: 845118687.3069\n",
      "Epoch 5896/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 152177195.2009 - val_loss: 708092646.7601\n",
      "Epoch 5897/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 185994375.8087 - val_loss: 738954096.2295\n",
      "Epoch 5898/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 121194035.9887 - val_loss: 864303194.2571\n",
      "Epoch 5899/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 242879959.8784 - val_loss: 913735730.1198\n",
      "Epoch 5900/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 322237679.6488 - val_loss: 850717829.0588\n",
      "Epoch 5901/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 333180392.2296 - val_loss: 5156683533.5021\n",
      "Epoch 5902/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1461860463.0366 - val_loss: 2009273945.0779\n",
      "Epoch 5903/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 345474997.3213 - val_loss: 871889841.8498\n",
      "Epoch 5904/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 185048594.7327 - val_loss: 959881950.1547\n",
      "Epoch 5905/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 215574523.7378 - val_loss: 762577174.5440\n",
      "Epoch 5906/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 150323422.3433 - val_loss: 1021993509.4549\n",
      "Epoch 5907/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 168225271.9370 - val_loss: 1013973339.5443\n",
      "Epoch 5908/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 361070551.1806 - val_loss: 1357146588.9125\n",
      "Epoch 5909/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 255147099.5340 - val_loss: 765353012.0056\n",
      "Epoch 5910/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 342825148.9252 - val_loss: 988306316.0934\n",
      "Epoch 5911/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 1031740547.8177 - val_loss: 20629169349.1668\n",
      "Epoch 5912/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 2399891957.8301 - val_loss: 894523000.1553\n",
      "Epoch 5913/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 190525597.5239 - val_loss: 977846455.6647\n",
      "Epoch 5914/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 157939657.9223 - val_loss: 746646698.3246\n",
      "Epoch 5915/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 247420663.8244 - val_loss: 768094450.4619\n",
      "Epoch 5916/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 131512147.4305 - val_loss: 777632679.3271\n",
      "Epoch 5917/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 592712397.5397 - val_loss: 1476908318.8388\n",
      "Epoch 5918/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 279489458.0799 - val_loss: 1385463484.5975\n",
      "Epoch 5919/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 688812583.8694 - val_loss: 788415454.1457\n",
      "Epoch 5920/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 252474131.3945 - val_loss: 736311196.7775\n",
      "Epoch 5921/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 114479817.8371 - val_loss: 736814909.2366\n",
      "Epoch 5922/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 144920556.8689 - val_loss: 1559359378.9030\n",
      "Epoch 5923/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 338759086.5222 - val_loss: 1593084349.4616\n",
      "Epoch 5924/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 406982753.5307 - val_loss: 1342715803.1752\n",
      "Epoch 5925/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 248736460.5875 - val_loss: 1132820585.8745\n",
      "Epoch 5926/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 350776992.6303 - val_loss: 950725407.6940\n",
      "Epoch 5927/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 247984623.5048 - val_loss: 1062750082.3404\n",
      "Epoch 5928/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 488514831.0906 - val_loss: 824711352.0878\n",
      "Epoch 5929/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 343459335.7074 - val_loss: 1806419548.6875\n",
      "Epoch 5930/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 536644677.2043 - val_loss: 1166782184.5243\n",
      "Epoch 5931/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 905780310.9781 - val_loss: 1169656357.1218\n",
      "Epoch 5932/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 555946019.5276 - val_loss: 783165930.2706\n",
      "Epoch 5933/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 200115698.0400 - val_loss: 722028488.5873\n",
      "Epoch 5934/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 299938808.2206 - val_loss: 1447474105.6990\n",
      "Epoch 5935/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 545092094.5594 - val_loss: 1690281740.4219\n",
      "Epoch 5936/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 709825730.7732 - val_loss: 2755919930.8332\n",
      "Epoch 5937/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 705820407.8604 - val_loss: 903147697.9038\n",
      "Epoch 5938/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 788877257.1390 - val_loss: 2758225007.4194\n",
      "Epoch 5939/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 358662643.6514 - val_loss: 815966031.8245\n",
      "Epoch 5940/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 288448863.6579 - val_loss: 1573760695.3947\n",
      "Epoch 5941/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 312270682.6944 - val_loss: 1271007153.6968\n",
      "Epoch 5942/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 239502417.5127 - val_loss: 899328439.1876\n",
      "Epoch 5943/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 237655745.2651 - val_loss: 901268978.8669\n",
      "Epoch 5944/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 258652441.7153 - val_loss: 8124959504.0585\n",
      "Epoch 5945/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2361547432.6438 - val_loss: 1707108103.4892\n",
      "Epoch 5946/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 281030093.5869 - val_loss: 713869623.0886\n",
      "Epoch 5947/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 208992479.6218 - val_loss: 1136045007.8695\n",
      "Epoch 5948/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 251424744.1936 - val_loss: 1310630855.9572\n",
      "Epoch 5949/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 450827457.2606 - val_loss: 1190063336.3443\n",
      "Epoch 5950/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 403101652.4209 - val_loss: 1518097587.2360\n",
      "Epoch 5951/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 300027143.4845 - val_loss: 717848646.1120\n",
      "Epoch 5952/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 218558812.5391 - val_loss: 773010698.8242\n",
      "Epoch 5953/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 264061332.6730 - val_loss: 2294641111.1696\n",
      "Epoch 5954/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 458794208.1621 - val_loss: 1301669024.9812\n",
      "Epoch 5955/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 265580732.3714 - val_loss: 738894396.0664\n",
      "Epoch 5956/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 354576737.1705 - val_loss: 3200366287.8245\n",
      "Epoch 5957/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 337932145.6387 - val_loss: 1186380982.9086\n",
      "Epoch 5958/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 178730476.8497 - val_loss: 872471556.8473\n",
      "Epoch 5959/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 230889171.8447 - val_loss: 2487435097.6180\n",
      "Epoch 5960/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 467396816.6033 - val_loss: 1634779716.7122\n",
      "Epoch 5961/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 556780772.3579 - val_loss: 1057016301.3491\n",
      "Epoch 5962/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 477949843.7727 - val_loss: 4325583493.7969\n",
      "Epoch 5963/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 881716432.8194 - val_loss: 972851664.1080\n",
      "Epoch 5964/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 735520690.2420 - val_loss: 787233626.5361\n",
      "Epoch 5965/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 170986787.7772 - val_loss: 1032058657.1972\n",
      "Epoch 5966/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 412210469.7805 - val_loss: 770868706.3854\n",
      "Epoch 5967/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 186372884.8734 - val_loss: 999305618.7049\n",
      "Epoch 5968/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 317136166.8610 - val_loss: 1030506730.0546\n",
      "Epoch 5969/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 188073877.7321 - val_loss: 925951956.1812\n",
      "Epoch 5970/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 276139149.4879 - val_loss: 1471626286.7713\n",
      "Epoch 5971/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 334619958.6359 - val_loss: 880997164.1969\n",
      "Epoch 5972/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 956413303.1401 - val_loss: 1443452199.8650\n",
      "Epoch 5973/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 449084372.9792 - val_loss: 739869159.5162\n",
      "Epoch 5974/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 378679554.7732 - val_loss: 1203373680.0900\n",
      "Epoch 5975/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 272225570.2510 - val_loss: 876155345.4537\n",
      "Epoch 5976/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 338316936.6798 - val_loss: 821878614.8996\n",
      "Epoch 5977/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 271997569.9539 - val_loss: 1077276327.3902\n",
      "Epoch 5978/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 749766663.9325 - val_loss: 2487532496.8506\n",
      "Epoch 5979/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 485501275.2032 - val_loss: 1127606363.8864\n",
      "Epoch 5980/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 258224042.2825 - val_loss: 1497135211.1707\n",
      "Epoch 5981/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 684371932.9162 - val_loss: 803150382.9693\n",
      "Epoch 5982/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 161168333.3731 - val_loss: 1137974703.6759\n",
      "Epoch 5983/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 223949652.1238 - val_loss: 977889716.5502\n",
      "Epoch 5984/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 247362936.7488 - val_loss: 1198531303.4622\n",
      "Epoch 5985/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 252096311.3382 - val_loss: 839626818.1153\n",
      "Epoch 5986/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 288805925.1683 - val_loss: 2599320911.5544\n",
      "Epoch 5987/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 682317442.3050 - val_loss: 1110774233.1499\n",
      "Epoch 5988/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 674983982.2769 - val_loss: 783239805.8712\n",
      "Epoch 5989/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 278722282.6213 - val_loss: 848690381.0565\n",
      "Epoch 5990/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 215780277.5419 - val_loss: 950557758.1457\n",
      "Epoch 5991/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 345398252.2994 - val_loss: 758508380.1429\n",
      "Epoch 5992/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 579605764.2859 - val_loss: 1114089744.1710\n",
      "Epoch 5993/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 701548116.9207 - val_loss: 771255038.4158\n",
      "Epoch 5994/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 182162406.2712 - val_loss: 1463860275.7851\n",
      "Epoch 5995/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 763036894.0732 - val_loss: 910279859.7761\n",
      "Epoch 5996/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 89us/step - loss: 592302663.5993 - val_loss: 1264685913.2940\n",
      "Epoch 5997/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 574626996.1868 - val_loss: 1327776305.0217\n",
      "Epoch 5998/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 615527219.9167 - val_loss: 789519256.2138\n",
      "Epoch 5999/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 277282037.5914 - val_loss: 812922484.2487\n",
      "Epoch 6000/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 141865058.9983 - val_loss: 910531838.9198\n",
      "Epoch 6001/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 179382458.6066 - val_loss: 942188065.9893\n",
      "Epoch 6002/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 223049542.3388 - val_loss: 1317924927.4959\n",
      "Epoch 6003/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 282815870.1841 - val_loss: 1027463966.6228\n",
      "Epoch 6004/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 604326336.9724 - val_loss: 903433561.2039\n",
      "Epoch 6005/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 668955803.7321 - val_loss: 1223742516.3162\n",
      "Epoch 6006/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 616099221.9876 - val_loss: 3298148977.7778\n",
      "Epoch 6007/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 298488319.5678 - val_loss: 929144593.4740\n",
      "Epoch 6008/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 231570833.7254 - val_loss: 802200756.7302\n",
      "Epoch 6009/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 236939295.1536 - val_loss: 9651612209.5797\n",
      "Epoch 6010/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2515073330.5661 - val_loss: 1546358599.1561\n",
      "Epoch 6011/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 243315823.8289 - val_loss: 2487710299.7783\n",
      "Epoch 6012/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 333641935.7974 - val_loss: 871976046.1727\n",
      "Epoch 6013/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 184964877.1039 - val_loss: 846697107.3665\n",
      "Epoch 6014/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 119673000.0540 - val_loss: 923419202.0006\n",
      "Epoch 6015/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 173381756.7046 - val_loss: 2577435080.1913\n",
      "Epoch 6016/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1078777196.8396 - val_loss: 1184393148.6335\n",
      "Epoch 6017/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 203632069.6522 - val_loss: 703145586.5204\n",
      "Epoch 6018/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 409650212.7721 - val_loss: 6245051447.8447\n",
      "Epoch 6019/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1102295748.3602 - val_loss: 736043409.4987\n",
      "Epoch 6020/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 174138454.7223 - val_loss: 804555904.6931\n",
      "Epoch 6021/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 296222015.6804 - val_loss: 1142728281.1904\n",
      "Epoch 6022/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 273352575.9910 - val_loss: 883908381.4886\n",
      "Epoch 6023/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 181709180.7361 - val_loss: 728178057.4875\n",
      "Epoch 6024/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 180908154.7777 - val_loss: 6042343813.1488\n",
      "Epoch 6025/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1197052700.9297 - val_loss: 775812606.9468\n",
      "Epoch 6026/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 164233186.2690 - val_loss: 828810820.0596\n",
      "Epoch 6027/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 205995565.5554 - val_loss: 825132881.7643\n",
      "Epoch 6028/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 182339209.8683 - val_loss: 882132320.0090\n",
      "Epoch 6029/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 164724587.0546 - val_loss: 739522511.2034\n",
      "Epoch 6030/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1020105143.8244 - val_loss: 7266865855.1899\n",
      "Epoch 6031/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 633223445.2853 - val_loss: 903011449.4470\n",
      "Epoch 6032/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 155574023.5464 - val_loss: 776997280.6841\n",
      "Epoch 6033/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 157918544.0765 - val_loss: 1003022714.1626\n",
      "Epoch 6034/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 167610502.9415 - val_loss: 750475510.8366\n",
      "Epoch 6035/10000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 411375450.090 - 0s 85us/step - loss: 412049768.8779 - val_loss: 2405613373.8937\n",
      "Epoch 6036/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 534752350.7935 - val_loss: 1065203752.4523\n",
      "Epoch 6037/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 424032151.8424 - val_loss: 893442893.6461\n",
      "Epoch 6038/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 225300714.3005 - val_loss: 1128984562.0658\n",
      "Epoch 6039/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 222398862.3298 - val_loss: 1069322147.1235\n",
      "Epoch 6040/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 329570586.0889 - val_loss: 1109323624.4073\n",
      "Epoch 6041/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 198454821.1773 - val_loss: 2056479306.3246\n",
      "Epoch 6042/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 536121317.8886 - val_loss: 2648190302.3347\n",
      "Epoch 6043/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 819562363.0478 - val_loss: 1508723251.4880\n",
      "Epoch 6044/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 351952531.4665 - val_loss: 1161508610.3404\n",
      "Epoch 6045/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 212093398.5661 - val_loss: 798589925.7969\n",
      "Epoch 6046/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2275671759.6128 - val_loss: 1252685795.4093\n",
      "Epoch 6047/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 214743949.3033 - val_loss: 1201018606.7353\n",
      "Epoch 6048/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 159908888.4637 - val_loss: 1157296189.8352\n",
      "Epoch 6049/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 132508864.2881 - val_loss: 1013085729.7823\n",
      "Epoch 6050/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 813231585.5667 - val_loss: 1577115647.1899\n",
      "Epoch 6051/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 369836036.7473 - val_loss: 748679996.2374\n",
      "Epoch 6052/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 268001040.9409 - val_loss: 1813250257.0487\n",
      "Epoch 6053/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 313356865.8548 - val_loss: 1403863131.7828\n",
      "Epoch 6054/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 239930814.5324 - val_loss: 880189583.7345\n",
      "Epoch 6055/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 172501343.8019 - val_loss: 770862484.3792\n",
      "Epoch 6056/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 469550417.9719 - val_loss: 2186158213.5629\n",
      "Epoch 6057/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 549056851.1244 - val_loss: 991844684.7730\n",
      "Epoch 6058/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 428101829.6455 - val_loss: 847823765.8644\n",
      "Epoch 6059/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 262303585.2245 - val_loss: 1454412699.6388\n",
      "Epoch 6060/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 312121853.6365 - val_loss: 1051964345.7440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6061/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 233334460.2904 - val_loss: 2497576693.6664\n",
      "Epoch 6062/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 405008883.3421 - val_loss: 1936612558.5283\n",
      "Epoch 6063/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 176864429.3182 - val_loss: 1600164284.3364\n",
      "Epoch 6064/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1092724002.2870 - val_loss: 2219159736.2048\n",
      "Epoch 6065/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 639428227.6871 - val_loss: 1128316566.5035\n",
      "Epoch 6066/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 187765228.7046 - val_loss: 964335998.7308\n",
      "Epoch 6067/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 340804661.1604 - val_loss: 1210771583.8740\n",
      "Epoch 6068/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 431725818.8362 - val_loss: 1486108080.5176\n",
      "Epoch 6069/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 500674996.8171 - val_loss: 2257091730.6239\n",
      "Epoch 6070/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1321702246.4288 - val_loss: 3405065014.4045\n",
      "Epoch 6071/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 669761700.6010 - val_loss: 1374481785.3390\n",
      "Epoch 6072/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 313533629.9865 - val_loss: 1344885277.1826\n",
      "Epoch 6073/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 202081365.0332 - val_loss: 1376588697.6698\n",
      "Epoch 6074/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 253686429.5959 - val_loss: 831808747.5758\n",
      "Epoch 6075/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 272613510.4288 - val_loss: 2177951029.2523\n",
      "Epoch 6076/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 230660037.7625 - val_loss: 1600778824.1553\n",
      "Epoch 6077/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 340983130.5886 - val_loss: 1690891448.5288\n",
      "Epoch 6078/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 348711536.6078 - val_loss: 1693519086.5013\n",
      "Epoch 6079/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 269661370.4896 - val_loss: 919216125.1916\n",
      "Epoch 6080/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 358626819.2752 - val_loss: 957471282.7319\n",
      "Epoch 6081/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 490798826.7181 - val_loss: 1274386076.1294\n",
      "Epoch 6082/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 212953738.8768 - val_loss: 2535072024.6188\n",
      "Epoch 6083/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 2870569645.3078 - val_loss: 1669614435.6816\n",
      "Epoch 6084/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 502404549.3754 - val_loss: 1263203801.2489\n",
      "Epoch 6085/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 298367543.4418 - val_loss: 1064416803.0065\n",
      "Epoch 6086/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 257636788.4029 - val_loss: 817575941.5809\n",
      "Epoch 6087/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 378060688.7833 - val_loss: 1324912107.5758\n",
      "Epoch 6088/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 503392126.2172 - val_loss: 1328591749.6754\n",
      "Epoch 6089/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 511671578.9668 - val_loss: 1298502273.2602\n",
      "Epoch 6090/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 217060691.8987 - val_loss: 841585497.5280\n",
      "Epoch 6091/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 224321672.6078 - val_loss: 1017301459.5511\n",
      "Epoch 6092/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 205702124.1553 - val_loss: 2442908651.0492\n",
      "Epoch 6093/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 757016774.9510 - val_loss: 988410231.5747\n",
      "Epoch 6094/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 222974339.1604 - val_loss: 747808292.4557\n",
      "Epoch 6095/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 190147892.0428 - val_loss: 1644798163.3530\n",
      "Epoch 6096/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 290356083.6106 - val_loss: 809273012.1947\n",
      "Epoch 6097/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 314944000.3602 - val_loss: 4716685324.0979\n",
      "Epoch 6098/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1870396705.0805 - val_loss: 1022096548.5457\n",
      "Epoch 6099/10000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 166260187.1829 - val_loss: 936037495.2596\n",
      "Epoch 6100/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 301769473.2110 - val_loss: 2074781050.2571\n",
      "Epoch 6101/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 286696796.8846 - val_loss: 1956144944.0315\n",
      "Epoch 6102/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 310231312.6483 - val_loss: 712859829.8959\n",
      "Epoch 6103/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 129136272.5853 - val_loss: 1041963823.7660\n",
      "Epoch 6104/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 324900804.5020 - val_loss: 2586323753.5505\n",
      "Epoch 6105/10000\n",
      "3554/3554 [==============================] - 0s 135us/step - loss: 731617672.4997 - val_loss: 3072960602.4056\n",
      "Epoch 6106/10000\n",
      "3554/3554 [==============================] - 0s 138us/step - loss: 588407970.7192 - val_loss: 1371652479.4959\n",
      "Epoch 6107/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 360014006.7800 - val_loss: 801519981.0430\n",
      "Epoch 6108/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 612202712.0225 - val_loss: 1023309717.7834\n",
      "Epoch 6109/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 318487235.3495 - val_loss: 1991623430.9851\n",
      "Epoch 6110/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 401843592.3557 - val_loss: 1842401078.0805\n",
      "Epoch 6111/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 325423209.7603 - val_loss: 1174616936.3443\n",
      "Epoch 6112/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 260566249.0546 - val_loss: 747007676.1834\n",
      "Epoch 6113/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 599502480.4232 - val_loss: 2047770394.1108\n",
      "Epoch 6114/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 272712712.6438 - val_loss: 8902043990.3415\n",
      "Epoch 6115/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1359874732.1733 - val_loss: 1000207536.1125\n",
      "Epoch 6116/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 484875901.9201 - val_loss: 779733503.2979\n",
      "Epoch 6117/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 144390540.6595 - val_loss: 1686354052.1406\n",
      "Epoch 6118/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 169686708.9972 - val_loss: 958489283.2495\n",
      "Epoch 6119/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 131161285.0332 - val_loss: 1017883008.3241\n",
      "Epoch 6120/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 173495328.0242 - val_loss: 891635500.7145\n",
      "Epoch 6121/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 559879347.4305 - val_loss: 1056643890.6239\n",
      "Epoch 6122/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 604914950.5549 - val_loss: 1357437409.3682\n",
      "Epoch 6123/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 623522205.9831 - val_loss: 3313717215.5589\n",
      "Epoch 6124/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 277950909.7490 - val_loss: 728427802.2751\n",
      "Epoch 6125/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 193627488.0191 - val_loss: 732991703.8312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6126/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 240220257.9088 - val_loss: 1633204161.8003\n",
      "Epoch 6127/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 407831227.3540 - val_loss: 2442369883.6703\n",
      "Epoch 6128/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1427259622.9330 - val_loss: 2835966745.3480\n",
      "Epoch 6129/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 325600887.5228 - val_loss: 743332431.6534\n",
      "Epoch 6130/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 163956352.6325 - val_loss: 798496944.9857\n",
      "Epoch 6131/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 157238226.0799 - val_loss: 888727435.0447\n",
      "Epoch 6132/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 2606210404.8801 - val_loss: 977635298.3899\n",
      "Epoch 6133/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 267739494.2364 - val_loss: 723421310.3617\n",
      "Epoch 6134/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 142335235.3134 - val_loss: 1257905518.0152\n",
      "Epoch 6135/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 164885139.0343 - val_loss: 725458298.3201\n",
      "Epoch 6136/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 105566738.9623 - val_loss: 776704933.2343\n",
      "Epoch 6137/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 293252440.2926 - val_loss: 978986677.3603\n",
      "Epoch 6138/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 183743197.1728 - val_loss: 1387217739.3958\n",
      "Epoch 6139/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 722425037.7580 - val_loss: 891888049.8363\n",
      "Epoch 6140/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 143678112.3512 - val_loss: 2118578494.0377\n",
      "Epoch 6141/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 410204071.0861 - val_loss: 973858293.4053\n",
      "Epoch 6142/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 361855084.0473 - val_loss: 8901045571.8346\n",
      "Epoch 6143/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1650161086.6269 - val_loss: 1121151016.7381\n",
      "Epoch 6144/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 222455231.0388 - val_loss: 751262338.9705\n",
      "Epoch 6145/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 248912178.6156 - val_loss: 739541824.6301\n",
      "Epoch 6146/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 236728784.8050 - val_loss: 1400774380.8090\n",
      "Epoch 6147/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 539948886.2577 - val_loss: 1378760426.9862\n",
      "Epoch 6148/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 492394227.2144 - val_loss: 1068630258.3899\n",
      "Epoch 6149/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 598861776.2071 - val_loss: 865507014.5215\n",
      "Epoch 6150/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 509718415.8829 - val_loss: 1185944949.5224\n",
      "Epoch 6151/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 508200334.5582 - val_loss: 716586894.0017\n",
      "Epoch 6152/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 178400806.5954 - val_loss: 863527778.6644\n",
      "Epoch 6153/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 140479429.7535 - val_loss: 772286701.7249\n",
      "Epoch 6154/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 140487438.9871 - val_loss: 789042302.8478\n",
      "Epoch 6155/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 322237820.7732 - val_loss: 1445766711.4487\n",
      "Epoch 6156/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 650661745.1615 - val_loss: 3134818688.2520\n",
      "Epoch 6157/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1434330140.1058 - val_loss: 974334754.5294\n",
      "Epoch 6158/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 241656695.7321 - val_loss: 1414592006.8771\n",
      "Epoch 6159/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 193015520.6078 - val_loss: 714898298.5001\n",
      "Epoch 6160/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 249238317.9381 - val_loss: 773003608.6819\n",
      "Epoch 6161/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 360640194.7715 - val_loss: 725619112.1958\n",
      "Epoch 6162/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 213783908.3399 - val_loss: 1084048073.6315\n",
      "Epoch 6163/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 682604267.9392 - val_loss: 1423632720.0405\n",
      "Epoch 6164/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 214065407.8627 - val_loss: 981039094.3685\n",
      "Epoch 6165/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 369986400.7788 - val_loss: 731240268.2509\n",
      "Epoch 6166/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 122363994.0394 - val_loss: 783730258.4349\n",
      "Epoch 6167/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 195683296.8734 - val_loss: 2408843097.4380\n",
      "Epoch 6168/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 417761577.5622 - val_loss: 1218671451.7963\n",
      "Epoch 6169/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 961262773.4879 - val_loss: 957717049.2850\n",
      "Epoch 6170/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 226115884.9533 - val_loss: 788197542.8141\n",
      "Epoch 6171/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 262728603.2369 - val_loss: 1021560432.7966\n",
      "Epoch 6172/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 180670526.4783 - val_loss: 856354947.6141\n",
      "Epoch 6173/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 311348468.3399 - val_loss: 799948097.3592\n",
      "Epoch 6174/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 282130901.6905 - val_loss: 1039606081.4447\n",
      "Epoch 6175/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 386874403.4035 - val_loss: 756011242.9007\n",
      "Epoch 6176/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 150290635.7051 - val_loss: 961674430.8838\n",
      "Epoch 6177/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 434213996.4615 - val_loss: 2385445449.3795\n",
      "Epoch 6178/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 779686007.9854 - val_loss: 1025512298.3021\n",
      "Epoch 6179/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 257264200.8149 - val_loss: 766780586.1716\n",
      "Epoch 6180/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 203633866.2735 - val_loss: 918314468.9148\n",
      "Epoch 6181/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 309579403.4890 - val_loss: 3015262389.5044\n",
      "Epoch 6182/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 540711082.0484 - val_loss: 868916811.5668\n",
      "Epoch 6183/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 468518548.3309 - val_loss: 4397042000.2025\n",
      "Epoch 6184/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1057429116.7856 - val_loss: 1157770542.9333\n",
      "Epoch 6185/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 346014923.5971 - val_loss: 1178742635.0987\n",
      "Epoch 6186/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 662062878.5976 - val_loss: 1667354620.9755\n",
      "Epoch 6187/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 705786289.0355 - val_loss: 1148388419.2225\n",
      "Epoch 6188/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 270547917.9651 - val_loss: 740631249.3097\n",
      "Epoch 6189/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 350032966.4558 - val_loss: 993704686.1772\n",
      "Epoch 6190/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 210129148.3557 - val_loss: 862037110.2425\n",
      "Epoch 6191/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 637167820.2093 - val_loss: 4195378596.8338\n",
      "Epoch 6192/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1237506974.4513 - val_loss: 979478766.9063\n",
      "Epoch 6193/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 150251996.2724 - val_loss: 1315680270.5598\n",
      "Epoch 6194/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 215393493.5599 - val_loss: 715128002.3179\n",
      "Epoch 6195/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 136117315.4575 - val_loss: 763622186.3291\n",
      "Epoch 6196/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 788264816.8104 - val_loss: 1003507242.6757\n",
      "Epoch 6197/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 272907595.6646 - val_loss: 1165765758.7578\n",
      "Epoch 6198/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 174527821.9977 - val_loss: 1148718152.4613\n",
      "Epoch 6199/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 319084740.5470 - val_loss: 800563663.8965\n",
      "Epoch 6200/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 235416078.1137 - val_loss: 1014170894.9963\n",
      "Epoch 6201/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 497130129.8863 - val_loss: 1441526489.3120\n",
      "Epoch 6202/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 271984266.5189 - val_loss: 1264475726.1682\n",
      "Epoch 6203/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 279064315.1694 - val_loss: 876261273.2039\n",
      "Epoch 6204/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 326220983.8604 - val_loss: 2009255805.8217\n",
      "Epoch 6205/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 359869123.0974 - val_loss: 855598113.9893\n",
      "Epoch 6206/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 319340306.2521 - val_loss: 892973247.9190\n",
      "Epoch 6207/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 290133641.2921 - val_loss: 873772225.1342\n",
      "Epoch 6208/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 217475137.4001 - val_loss: 785150531.1550\n",
      "Epoch 6209/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 487991286.0597 - val_loss: 1435088766.0557\n",
      "Epoch 6210/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 674934398.4513 - val_loss: 1580532613.6529\n",
      "Epoch 6211/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 328737278.9645 - val_loss: 960700255.0909\n",
      "Epoch 6212/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 331490109.1908 - val_loss: 1055650017.6293\n",
      "Epoch 6213/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 368315630.4603 - val_loss: 860927926.9446\n",
      "Epoch 6214/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 293471709.4249 - val_loss: 827446534.3685\n",
      "Epoch 6215/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 185814732.3962 - val_loss: 990620125.0205\n",
      "Epoch 6216/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 425855577.0490 - val_loss: 1289764761.1949\n",
      "Epoch 6217/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 462786581.9381 - val_loss: 895655331.2135\n",
      "Epoch 6218/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 471494996.8891 - val_loss: 804680287.9865\n",
      "Epoch 6219/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 265454913.1165 - val_loss: 1627007666.3426\n",
      "Epoch 6220/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 307660140.2454 - val_loss: 1168904043.3463\n",
      "Epoch 6221/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 327070107.6781 - val_loss: 780868892.7145\n",
      "Epoch 6222/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 244841312.6663 - val_loss: 4528631216.0675\n",
      "Epoch 6223/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 766824514.7012 - val_loss: 1780108006.6520\n",
      "Epoch 6224/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 774437008.7811 - val_loss: 2350640847.5004\n",
      "Epoch 6225/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 990840398.2262 - val_loss: 3513521479.2551\n",
      "Epoch 6226/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 320603998.5414 - val_loss: 717548324.7662\n",
      "Epoch 6227/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 193803863.0366 - val_loss: 972197115.3013\n",
      "Epoch 6228/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 149340317.2518 - val_loss: 695912582.7308\n",
      "Epoch 6229/10000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 111760309.888 - 0s 85us/step - loss: 112181115.2819 - val_loss: 1101151799.5747\n",
      "Epoch 6230/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 904034766.6584 - val_loss: 6289617383.0841\n",
      "Epoch 6231/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2805010120.4637 - val_loss: 1881833044.2532\n",
      "Epoch 6232/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 241924926.9285 - val_loss: 1020415657.6585\n",
      "Epoch 6233/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 137049848.7158 - val_loss: 760729305.7440\n",
      "Epoch 6234/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 135110978.5256 - val_loss: 720582277.2703\n",
      "Epoch 6235/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 139934801.3956 - val_loss: 10411117234.1558\n",
      "Epoch 6236/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2906829110.1677 - val_loss: 784685541.1398\n",
      "Epoch 6237/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 125462959.1446 - val_loss: 752734374.7871\n",
      "Epoch 6238/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 102711134.7935 - val_loss: 770683308.0889\n",
      "Epoch 6239/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 177781269.4024 - val_loss: 1002444462.9963\n",
      "Epoch 6240/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 145784602.9308 - val_loss: 733715821.5426\n",
      "Epoch 6241/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 128434443.0748 - val_loss: 752967010.7994\n",
      "Epoch 6242/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 126005040.2183 - val_loss: 780838549.8779\n",
      "Epoch 6243/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 158378298.5549 - val_loss: 1474790984.5063\n",
      "Epoch 6244/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 340947106.8993 - val_loss: 1246992767.9640\n",
      "Epoch 6245/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 254515448.5144 - val_loss: 861664607.2439\n",
      "Epoch 6246/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 486596618.2566 - val_loss: 916262614.0444\n",
      "Epoch 6247/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 323547243.2189 - val_loss: 5782006982.7511\n",
      "Epoch 6248/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 516777142.0433 - val_loss: 801616274.0433\n",
      "Epoch 6249/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 288788046.2802 - val_loss: 919613264.2565\n",
      "Epoch 6250/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 303268335.5588 - val_loss: 822083376.4726\n",
      "Epoch 6251/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 302303445.6815 - val_loss: 3765135766.5755\n",
      "Epoch 6252/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 571295362.1609 - val_loss: 4644025414.5710\n",
      "Epoch 6253/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 755767583.2178 - val_loss: 829722030.9063\n",
      "Epoch 6254/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 169812894.6156 - val_loss: 729133839.4644\n",
      "Epoch 6255/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 135348092.7406 - val_loss: 2049941073.5527\n",
      "Epoch 6256/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 84us/step - loss: 494780484.9252 - val_loss: 917916237.3896\n",
      "Epoch 6257/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 426342519.5363 - val_loss: 850663116.9440\n",
      "Epoch 6258/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 616946081.8278 - val_loss: 6511434622.2357\n",
      "Epoch 6259/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1288320847.8920 - val_loss: 861383492.9238\n",
      "Epoch 6260/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 221232447.1896 - val_loss: 1232435147.0717\n",
      "Epoch 6261/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 461712261.5104 - val_loss: 4311457650.4979\n",
      "Epoch 6262/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1755762067.9707 - val_loss: 779358743.8447\n",
      "Epoch 6263/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 163393057.2696 - val_loss: 739683976.6774\n",
      "Epoch 6264/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 119573665.6387 - val_loss: 749310992.9586\n",
      "Epoch 6265/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 240083345.0985 - val_loss: 753674058.9097\n",
      "Epoch 6266/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 116716293.7670 - val_loss: 772174238.6318\n",
      "Epoch 6267/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 142041788.3804 - val_loss: 1164812700.0664\n",
      "Epoch 6268/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 212479921.0174 - val_loss: 805379196.2464\n",
      "Epoch 6269/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 307412127.3337 - val_loss: 3387839973.4278\n",
      "Epoch 6270/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 525609020.5875 - val_loss: 1612016550.1840\n",
      "Epoch 6271/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 781793429.4114 - val_loss: 1787480413.4706\n",
      "Epoch 6272/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1279463984.4547 - val_loss: 1214989452.8900\n",
      "Epoch 6273/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 202275741.8627 - val_loss: 1014712991.2709\n",
      "Epoch 6274/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 269261174.3478 - val_loss: 2848553437.6866\n",
      "Epoch 6275/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 645279140.6866 - val_loss: 950527507.9246\n",
      "Epoch 6276/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 125580657.7687 - val_loss: 878273995.7243\n",
      "Epoch 6277/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 171970741.8976 - val_loss: 785529908.6222\n",
      "Epoch 6278/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 191846208.8464 - val_loss: 871633899.5443\n",
      "Epoch 6279/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 212516306.2600 - val_loss: 1290599437.1421\n",
      "Epoch 6280/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 192017038.4333 - val_loss: 842196631.9257\n",
      "Epoch 6281/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 486457119.1491 - val_loss: 917471515.4363\n",
      "Epoch 6282/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 239452352.8014 - val_loss: 734932004.1136\n",
      "Epoch 6283/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 323498811.0388 - val_loss: 754901748.2622\n",
      "Epoch 6284/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 447169160.7181 - val_loss: 797958988.2239\n",
      "Epoch 6285/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 679044120.0585 - val_loss: 1418667072.3060\n",
      "Epoch 6286/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 396024963.4755 - val_loss: 1401993510.3910\n",
      "Epoch 6287/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 237751844.0743 - val_loss: 853663778.0343\n",
      "Epoch 6288/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 160258875.6151 - val_loss: 1248808518.8321\n",
      "Epoch 6289/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1231543734.6179 - val_loss: 1673134201.8790\n",
      "Epoch 6290/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 775235126.5279 - val_loss: 782543499.6838\n",
      "Epoch 6291/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 274132030.4153 - val_loss: 844179249.5257\n",
      "Epoch 6292/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 232894911.5498 - val_loss: 977249432.4298\n",
      "Epoch 6293/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 170947651.6106 - val_loss: 1246452077.0250\n",
      "Epoch 6294/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 219942623.9100 - val_loss: 1085696633.5550\n",
      "Epoch 6295/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 251895306.6246 - val_loss: 10258107622.4000\n",
      "Epoch 6296/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1236417158.1227 - val_loss: 2277612500.9733\n",
      "Epoch 6297/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 438791589.9156 - val_loss: 722840614.4630\n",
      "Epoch 6298/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 269179616.5582 - val_loss: 1334909611.6838\n",
      "Epoch 6299/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 429431463.3596 - val_loss: 1173594190.7083\n",
      "Epoch 6300/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 246572624.3810 - val_loss: 734553637.4323\n",
      "Epoch 6301/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 332009013.3934 - val_loss: 2090249660.5660\n",
      "Epoch 6302/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 441790215.3742 - val_loss: 1352728765.7677\n",
      "Epoch 6303/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 656747330.6292 - val_loss: 1073354802.1378\n",
      "Epoch 6304/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 211723586.7057 - val_loss: 673447370.9547\n",
      "Epoch 6305/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 165521236.8351 - val_loss: 813865129.4200\n",
      "Epoch 6306/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 513620114.3680 - val_loss: 3633069423.8335\n",
      "Epoch 6307/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 798396541.3168 - val_loss: 792826803.9291\n",
      "Epoch 6308/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 149316948.4688 - val_loss: 715976682.0996\n",
      "Epoch 6309/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 147997317.2921 - val_loss: 918667603.1370\n",
      "Epoch 6310/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 189936686.6550 - val_loss: 903349350.3550\n",
      "Epoch 6311/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 343680312.3376 - val_loss: 1378567250.0208\n",
      "Epoch 6312/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 422759199.2617 - val_loss: 787879215.4757\n",
      "Epoch 6313/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 337636264.6258 - val_loss: 809921620.6042\n",
      "Epoch 6314/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 341816013.8120 - val_loss: 930228357.4188\n",
      "Epoch 6315/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 191782493.5149 - val_loss: 824719976.9474\n",
      "Epoch 6316/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 373802896.2859 - val_loss: 880854359.4217\n",
      "Epoch 6317/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 250332332.1272 - val_loss: 863172760.8979\n",
      "Epoch 6318/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 567309808.4029 - val_loss: 2892418332.8765\n",
      "Epoch 6319/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 935171768.4367 - val_loss: 2029146885.1848\n",
      "Epoch 6320/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 246846952.7338 - val_loss: 773963341.2141\n",
      "Epoch 6321/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 171833410.8858 - val_loss: 1485683459.9246\n",
      "Epoch 6322/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 357603492.8801 - val_loss: 960497520.8956\n",
      "Epoch 6323/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 213684809.3551 - val_loss: 949675191.6647\n",
      "Epoch 6324/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 636232681.2020 - val_loss: 2067053433.0509\n",
      "Epoch 6325/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1879693033.7062 - val_loss: 788607241.7935\n",
      "Epoch 6326/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 169521577.8863 - val_loss: 1102721211.9314\n",
      "Epoch 6327/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 179629103.3585 - val_loss: 920349028.4647\n",
      "Epoch 6328/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 364131097.5622 - val_loss: 830059810.1783\n",
      "Epoch 6329/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 597147400.2026 - val_loss: 959612030.6588\n",
      "Epoch 6330/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 305967579.1019 - val_loss: 751409564.9845\n",
      "Epoch 6331/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 250447796.1970 - val_loss: 1193900118.3595\n",
      "Epoch 6332/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 701797763.9482 - val_loss: 1176418691.0245\n",
      "Epoch 6333/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 390770469.1683 - val_loss: 922181075.6771\n",
      "Epoch 6334/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 282668693.3821 - val_loss: 736265006.8163\n",
      "Epoch 6335/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 140559160.9949 - val_loss: 1937642738.6419\n",
      "Epoch 6336/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 198614697.7062 - val_loss: 1161300371.3260\n",
      "Epoch 6337/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 771265801.3754 - val_loss: 945002124.4219\n",
      "Epoch 6338/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 190877892.9342 - val_loss: 691021057.2152\n",
      "Epoch 6339/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 186132838.3568 - val_loss: 1030601848.5288\n",
      "Epoch 6340/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 377897759.4418 - val_loss: 812989075.4520\n",
      "Epoch 6341/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 774429662.4513 - val_loss: 774668444.9688\n",
      "Epoch 6342/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 194127515.6173 - val_loss: 829592891.4633\n",
      "Epoch 6343/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 179204109.2718 - val_loss: 896164132.3342\n",
      "Epoch 6344/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 299378229.4834 - val_loss: 807690564.8743\n",
      "Epoch 6345/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 598293334.2938 - val_loss: 3719130550.3325\n",
      "Epoch 6346/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1416319461.4114 - val_loss: 828798696.6639\n",
      "Epoch 6347/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 206122944.6573 - val_loss: 812915011.7986\n",
      "Epoch 6348/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 185354080.5672 - val_loss: 1713785371.7333\n",
      "Epoch 6349/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 322092244.9814 - val_loss: 783658857.2264\n",
      "Epoch 6350/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 362461686.4918 - val_loss: 1619555718.7871\n",
      "Epoch 6351/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 622902388.8531 - val_loss: 954826825.2444\n",
      "Epoch 6352/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 404827142.4468 - val_loss: 2265525998.1772\n",
      "Epoch 6353/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 384119535.9910 - val_loss: 828693359.4284\n",
      "Epoch 6354/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 161691670.4401 - val_loss: 836985252.6717\n",
      "Epoch 6355/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 423444108.4569 - val_loss: 808346515.8414\n",
      "Epoch 6356/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 333357702.8970 - val_loss: 1307701838.0242\n",
      "Epoch 6357/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 669508362.8407 - val_loss: 952910738.9750\n",
      "Epoch 6358/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 263306850.1880 - val_loss: 1333338920.3803\n",
      "Epoch 6359/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 212070459.3894 - val_loss: 880667713.2782\n",
      "Epoch 6360/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 342889733.0422 - val_loss: 1950368439.3406\n",
      "Epoch 6361/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 922544487.7254 - val_loss: 5396038136.4388\n",
      "Epoch 6362/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2932079150.6044 - val_loss: 943473761.8903\n",
      "Epoch 6363/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 250148493.6590 - val_loss: 744124066.2414\n",
      "Epoch 6364/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 123673705.6162 - val_loss: 720735185.8948\n",
      "Epoch 6365/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 198697079.9165 - val_loss: 697153413.4526\n",
      "Epoch 6366/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 105911904.6640 - val_loss: 687615340.9800\n",
      "Epoch 6367/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 173190935.0304 - val_loss: 1399943732.1541\n",
      "Epoch 6368/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 241445465.1165 - val_loss: 954786720.8461\n",
      "Epoch 6369/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 209881843.8920 - val_loss: 751333221.4346\n",
      "Epoch 6370/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 153607015.7727 - val_loss: 1016045920.9406\n",
      "Epoch 6371/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 217505947.7772 - val_loss: 775299980.1339\n",
      "Epoch 6372/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 195610919.6353 - val_loss: 1239279755.9179\n",
      "Epoch 6373/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 697377140.7631 - val_loss: 2848853726.2987\n",
      "Epoch 6374/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1293791565.3979 - val_loss: 953382092.5660\n",
      "Epoch 6375/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 538314363.0478 - val_loss: 2292134656.2520\n",
      "Epoch 6376/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 611459803.1379 - val_loss: 764160081.6473\n",
      "Epoch 6377/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 109269122.7518 - val_loss: 732970327.4577\n",
      "Epoch 6378/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 121858236.6685 - val_loss: 710452788.6661\n",
      "Epoch 6379/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 309092922.4266 - val_loss: 1453119358.2177\n",
      "Epoch 6380/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 255487620.3759 - val_loss: 1242214260.3072\n",
      "Epoch 6381/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 465456808.1812 - val_loss: 1023881039.7345\n",
      "Epoch 6382/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 472321127.8210 - val_loss: 1418105854.4518\n",
      "Epoch 6383/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 254285007.1896 - val_loss: 858672858.8287\n",
      "Epoch 6384/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 341345197.3438 - val_loss: 931020029.7586\n",
      "Epoch 6385/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 350764117.7636 - val_loss: 1455711302.8591\n",
      "Epoch 6386/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 87us/step - loss: 454762834.6922 - val_loss: 2411791996.5075\n",
      "Epoch 6387/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 483098024.9522 - val_loss: 853241982.3887\n",
      "Epoch 6388/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 179668710.1677 - val_loss: 1356926429.3896\n",
      "Epoch 6389/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 745012210.4311 - val_loss: 1121908501.1241\n",
      "Epoch 6390/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 173868469.1773 - val_loss: 771947936.0270\n",
      "Epoch 6391/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 120436256.0945 - val_loss: 903383560.1373\n",
      "Epoch 6392/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 897014358.5098 - val_loss: 1247729854.6048\n",
      "Epoch 6393/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1394466898.7102 - val_loss: 3306369962.8107\n",
      "Epoch 6394/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 513768393.2245 - val_loss: 1003143638.2470\n",
      "Epoch 6395/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 325448137.1390 - val_loss: 1087611341.8172\n",
      "Epoch 6396/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 373175358.3883 - val_loss: 1906145195.8368\n",
      "Epoch 6397/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 614481674.1024 - val_loss: 867725090.8759\n",
      "Epoch 6398/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 143398039.8154 - val_loss: 745956960.7111\n",
      "Epoch 6399/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 222643788.8576 - val_loss: 1182398246.7060\n",
      "Epoch 6400/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 307806586.3185 - val_loss: 707249171.5691\n",
      "Epoch 6401/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 291594454.7259 - val_loss: 1506157805.4751\n",
      "Epoch 6402/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 745257528.0765 - val_loss: 1512814743.4397\n",
      "Epoch 6403/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 525386096.8464 - val_loss: 854278902.7646\n",
      "Epoch 6404/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 723012442.6877 - val_loss: 1679309604.9058\n",
      "Epoch 6405/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 671691618.4316 - val_loss: 1363008939.1662\n",
      "Epoch 6406/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 253630487.1941 - val_loss: 722542719.8605\n",
      "Epoch 6407/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 157748952.1035 - val_loss: 808508149.7384\n",
      "Epoch 6408/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 181718361.9764 - val_loss: 1106810471.1921\n",
      "Epoch 6409/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 263233636.4029 - val_loss: 811099434.4416\n",
      "Epoch 6410/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 492596009.8998 - val_loss: 1191334311.7682\n",
      "Epoch 6411/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 293536102.8250 - val_loss: 1688760490.0816\n",
      "Epoch 6412/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 617708104.7518 - val_loss: 868839694.0107\n",
      "Epoch 6413/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 285861319.0231 - val_loss: 6210170040.1328\n",
      "Epoch 6414/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1280931356.6286 - val_loss: 831489597.4436\n",
      "Epoch 6415/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 440647889.7873 - val_loss: 762683829.0273\n",
      "Epoch 6416/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 128898219.5295 - val_loss: 896579694.3392\n",
      "Epoch 6417/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 106570112.0900 - val_loss: 779363156.8428\n",
      "Epoch 6418/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 421827163.6781 - val_loss: 1242870680.3353\n",
      "Epoch 6419/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 251739405.0917 - val_loss: 916998004.2802\n",
      "Epoch 6420/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 296395647.2122 - val_loss: 2136743297.4762\n",
      "Epoch 6421/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 475047189.6635 - val_loss: 865460819.4880\n",
      "Epoch 6422/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 176889796.4299 - val_loss: 723410753.3502\n",
      "Epoch 6423/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1705767181.0929 - val_loss: 3840566903.1066\n",
      "Epoch 6424/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 885585557.1280 - val_loss: 728477726.5553\n",
      "Epoch 6425/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 125574656.8374 - val_loss: 794837381.7204\n",
      "Epoch 6426/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 136734653.0107 - val_loss: 1486363239.1651\n",
      "Epoch 6427/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 789318015.3157 - val_loss: 920725332.8203\n",
      "Epoch 6428/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 389376672.9814 - val_loss: 827671394.9727\n",
      "Epoch 6429/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 197862196.4750 - val_loss: 860989839.0188\n",
      "Epoch 6430/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 256562132.2499 - val_loss: 709505895.8492\n",
      "Epoch 6431/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 192170175.9460 - val_loss: 1055263232.3331\n",
      "Epoch 6432/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 255398942.3073 - val_loss: 713321323.0402\n",
      "Epoch 6433/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 245030530.9803 - val_loss: 1014966219.7558\n",
      "Epoch 6434/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 365584776.7698 - val_loss: 2638746968.7899\n",
      "Epoch 6435/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 520748533.0512 - val_loss: 1449716124.1924\n",
      "Epoch 6436/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 552782416.3782 - val_loss: 1236861414.5440\n",
      "Epoch 6437/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 302231123.1941 - val_loss: 862617359.6579\n",
      "Epoch 6438/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 625665598.1992 - val_loss: 2770621420.5480\n",
      "Epoch 6439/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 679678915.9122 - val_loss: 1543583161.1139\n",
      "Epoch 6440/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 232769828.1643 - val_loss: 739173684.2622\n",
      "Epoch 6441/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 375712909.4609 - val_loss: 924221827.6636\n",
      "Epoch 6442/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 461933572.9702 - val_loss: 887424506.8152\n",
      "Epoch 6443/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 253707917.0737 - val_loss: 3681523778.8985\n",
      "Epoch 6444/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 404526901.0152 - val_loss: 774625445.5584\n",
      "Epoch 6445/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 283847164.6505 - val_loss: 1140859304.4703\n",
      "Epoch 6446/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 274498348.3557 - val_loss: 814249529.7350\n",
      "Epoch 6447/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 126386378.3208 - val_loss: 789461115.4543\n",
      "Epoch 6448/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 159088436.7271 - val_loss: 1412912723.1010\n",
      "Epoch 6449/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 656394299.6241 - val_loss: 785204881.9336\n",
      "Epoch 6450/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 244703462.3478 - val_loss: 874787199.7840\n",
      "Epoch 6451/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 186575261.5869 - val_loss: 3039740143.2214\n",
      "Epoch 6452/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2044776570.9578 - val_loss: 1578849746.2729\n",
      "Epoch 6453/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 283059606.3298 - val_loss: 2420698315.3193\n",
      "Epoch 6454/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 332307794.8362 - val_loss: 1013588213.0408\n",
      "Epoch 6455/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 612388478.7214 - val_loss: 728653379.1685\n",
      "Epoch 6456/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 236300624.1396 - val_loss: 846345905.8858\n",
      "Epoch 6457/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 239712483.2594 - val_loss: 992747343.9865\n",
      "Epoch 6458/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 175335755.4935 - val_loss: 718787776.8821\n",
      "Epoch 6459/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 286715753.0760 - val_loss: 1354492298.4866\n",
      "Epoch 6460/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 326997929.1840 - val_loss: 1278348432.8146\n",
      "Epoch 6461/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 475857567.2099 - val_loss: 1370958964.5682\n",
      "Epoch 6462/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 164179306.0124 - val_loss: 1098287843.5195\n",
      "Epoch 6463/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 339234569.8683 - val_loss: 1123256118.1795\n",
      "Epoch 6464/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 323732742.9690 - val_loss: 832082597.9139\n",
      "Epoch 6465/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 819495103.4598 - val_loss: 4399436797.8397\n",
      "Epoch 6466/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 631550859.7681 - val_loss: 2115778556.2554\n",
      "Epoch 6467/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 523287027.1604 - val_loss: 3637878194.5159\n",
      "Epoch 6468/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 360212629.8616 - val_loss: 1585562164.5052\n",
      "Epoch 6469/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 230645384.4097 - val_loss: 700044621.1556\n",
      "Epoch 6470/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 306133664.2701 - val_loss: 4099706518.0714\n",
      "Epoch 6471/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 800371881.9927 - val_loss: 881315796.5232\n",
      "Epoch 6472/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 238209184.1981 - val_loss: 4349095702.8276\n",
      "Epoch 6473/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 561830898.6292 - val_loss: 781960991.4509\n",
      "Epoch 6474/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 624399688.0675 - val_loss: 4047561433.1859\n",
      "Epoch 6475/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1238417420.7316 - val_loss: 818411385.5415\n",
      "Epoch 6476/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 226574327.4643 - val_loss: 1804854217.1319\n",
      "Epoch 6477/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 303253308.2994 - val_loss: 695115743.5319\n",
      "Epoch 6478/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 182667182.5324 - val_loss: 800686058.4551\n",
      "Epoch 6479/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 129954888.8149 - val_loss: 972784820.7212\n",
      "Epoch 6480/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 233421216.0732 - val_loss: 719964483.0650\n",
      "Epoch 6481/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 125291113.9584 - val_loss: 812184416.5626\n",
      "Epoch 6482/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 151376915.1559 - val_loss: 1191532701.4323\n",
      "Epoch 6483/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 975839617.7169 - val_loss: 2256194633.7845\n",
      "Epoch 6484/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 811432996.9814 - val_loss: 1481717798.6340\n",
      "Epoch 6485/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 183132101.7265 - val_loss: 732336844.8945\n",
      "Epoch 6486/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 213270488.2386 - val_loss: 2240747410.7589\n",
      "Epoch 6487/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 462261475.5926 - val_loss: 955586730.3235\n",
      "Epoch 6488/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 180859557.0872 - val_loss: 862310401.4425\n",
      "Epoch 6489/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 678850537.6702 - val_loss: 847672890.6082\n",
      "Epoch 6490/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 355176237.9381 - val_loss: 930166130.1378\n",
      "Epoch 6491/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 347377328.5627 - val_loss: 1633155281.4087\n",
      "Epoch 6492/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 323561572.3039 - val_loss: 844458493.8307\n",
      "Epoch 6493/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 659314737.8818 - val_loss: 839159752.4388\n",
      "Epoch 6494/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 183926863.2347 - val_loss: 779322002.3629\n",
      "Epoch 6495/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 159432868.6100 - val_loss: 783121072.0495\n",
      "Epoch 6496/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 809797495.1401 - val_loss: 1622967534.2852\n",
      "Epoch 6497/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 363872889.4451 - val_loss: 771831092.1384\n",
      "Epoch 6498/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 284104684.7856 - val_loss: 896344000.1350\n",
      "Epoch 6499/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 284666481.9178 - val_loss: 902135107.0222\n",
      "Epoch 6500/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 306205825.5403 - val_loss: 1355716477.8757\n",
      "Epoch 6501/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 226302903.7400 - val_loss: 1140190239.2169\n",
      "Epoch 6502/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 468113466.2960 - val_loss: 682414383.5139\n",
      "Epoch 6503/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 485914812.1463 - val_loss: 1367401553.7688\n",
      "Epoch 6504/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 763554312.5290 - val_loss: 919232416.9361\n",
      "Epoch 6505/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 116954047.4170 - val_loss: 731480243.4700\n",
      "Epoch 6506/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 211261988.6595 - val_loss: 760693773.7586\n",
      "Epoch 6507/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 734560499.7907 - val_loss: 3435523598.2852\n",
      "Epoch 6508/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 719034066.0349 - val_loss: 766977144.2948\n",
      "Epoch 6509/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 213344717.8301 - val_loss: 838687141.0183\n",
      "Epoch 6510/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 157672962.6947 - val_loss: 1404592033.1657\n",
      "Epoch 6511/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 506475701.3708 - val_loss: 846155974.2470\n",
      "Epoch 6512/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 350051794.2735 - val_loss: 861162485.5944\n",
      "Epoch 6513/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 422901490.7867 - val_loss: 827144904.5153\n",
      "Epoch 6514/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 368148274.9038 - val_loss: 824791716.6852\n",
      "Epoch 6515/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 388175589.0962 - val_loss: 1098051581.9117\n",
      "Epoch 6516/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 86us/step - loss: 328780567.8520 - val_loss: 1093633047.5612\n",
      "Epoch 6517/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 330228117.1885 - val_loss: 1175857097.2264\n",
      "Epoch 6518/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 301315991.9955 - val_loss: 740771131.6253\n",
      "Epoch 6519/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 289628927.4598 - val_loss: 976378591.2349\n",
      "Epoch 6520/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 418269255.6353 - val_loss: 982186570.4056\n",
      "Epoch 6521/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 304642279.3652 - val_loss: 765304908.4489\n",
      "Epoch 6522/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 250800812.9848 - val_loss: 702053567.6579\n",
      "Epoch 6523/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 175232856.5357 - val_loss: 889837969.4312\n",
      "Epoch 6524/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 424141195.1649 - val_loss: 886532960.6121\n",
      "Epoch 6525/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 613986921.1840 - val_loss: 1679064618.0186\n",
      "Epoch 6526/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 542712845.1367 - val_loss: 1678862049.3952\n",
      "Epoch 6527/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 408876929.2741 - val_loss: 792811199.5826\n",
      "Epoch 6528/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 326530981.6500 - val_loss: 872047230.7398\n",
      "Epoch 6529/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 315363950.2082 - val_loss: 935118687.1989\n",
      "Epoch 6530/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 606256153.8953 - val_loss: 5215207815.7412\n",
      "Epoch 6531/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 499173904.3512 - val_loss: 1484764974.5913\n",
      "Epoch 6532/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 575031926.3939 - val_loss: 796035384.6098\n",
      "Epoch 6533/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 260969469.6550 - val_loss: 703589935.8470\n",
      "Epoch 6534/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 160182132.4558 - val_loss: 835648382.9558\n",
      "Epoch 6535/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 391875928.0315 - val_loss: 768951381.2883\n",
      "Epoch 6536/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 381520539.7006 - val_loss: 1447291827.2540\n",
      "Epoch 6537/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 749539323.8222 - val_loss: 3575360247.4307\n",
      "Epoch 6538/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 857148077.7220 - val_loss: 704431241.0869\n",
      "Epoch 6539/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 156280786.5661 - val_loss: 1231806131.9201\n",
      "Epoch 6540/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 567926212.3219 - val_loss: 1309431662.0332\n",
      "Epoch 6541/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 144553417.7828 - val_loss: 1036014103.6197\n",
      "Epoch 6542/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 178403358.0732 - val_loss: 1257444558.9423\n",
      "Epoch 6543/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 212959831.5543 - val_loss: 663824106.4146\n",
      "Epoch 6544/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 493638378.6809 - val_loss: 764105971.2630\n",
      "Epoch 6545/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 203544672.8014 - val_loss: 1537522108.9935\n",
      "Epoch 6546/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 468939324.7946 - val_loss: 1428852228.9328\n",
      "Epoch 6547/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 320001744.7867 - val_loss: 892007230.6318\n",
      "Epoch 6548/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 167572355.1559 - val_loss: 816571976.8574\n",
      "Epoch 6549/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 133157420.0833 - val_loss: 956561222.7781\n",
      "Epoch 6550/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1084499588.3219 - val_loss: 1800846958.8636\n",
      "Epoch 6551/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1389834447.2797 - val_loss: 724650568.8259\n",
      "Epoch 6552/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 203221970.2240 - val_loss: 2437146990.4833\n",
      "Epoch 6553/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 321761697.2065 - val_loss: 734654102.4000\n",
      "Epoch 6554/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 199054040.7670 - val_loss: 821981921.0014\n",
      "Epoch 6555/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 180419020.9297 - val_loss: 1022306495.9640\n",
      "Epoch 6556/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 420103894.2577 - val_loss: 1471052325.1038\n",
      "Epoch 6557/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1099028319.9100 - val_loss: 1245761764.5412\n",
      "Epoch 6558/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 483113298.1185 - val_loss: 856997114.4506\n",
      "Epoch 6559/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 254366721.8233 - val_loss: 740150848.8731\n",
      "Epoch 6560/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 370335910.1002 - val_loss: 1401710341.2388\n",
      "Epoch 6561/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 161801467.7366 - val_loss: 767485593.3750\n",
      "Epoch 6562/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 641747456.9364 - val_loss: 5142476755.7131\n",
      "Epoch 6563/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1318787900.8666 - val_loss: 2904716896.9271\n",
      "Epoch 6564/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 356610599.1401 - val_loss: 752475194.9198\n",
      "Epoch 6565/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 125952414.2893 - val_loss: 786054239.3069\n",
      "Epoch 6566/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 157260471.8807 - val_loss: 866129452.3139\n",
      "Epoch 6567/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 99222762.3016 - val_loss: 761431523.9179\n",
      "Epoch 6568/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 286787313.4947 - val_loss: 946384342.1435\n",
      "Epoch 6569/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 685355760.3647 - val_loss: 701959630.1727\n",
      "Epoch 6570/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 265578626.7462 - val_loss: 737649417.5415\n",
      "Epoch 6571/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 200884008.2859 - val_loss: 1187921748.7212\n",
      "Epoch 6572/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 171173228.3894 - val_loss: 1013148770.6194\n",
      "Epoch 6573/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 171117272.0585 - val_loss: 2211079947.3778\n",
      "Epoch 6574/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 724819647.6759 - val_loss: 1523192824.2228\n",
      "Epoch 6575/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 419259524.3759 - val_loss: 1369146318.5103\n",
      "Epoch 6576/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 323287512.4367 - val_loss: 798483351.3767\n",
      "Epoch 6577/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 167949293.8751 - val_loss: 677475428.8023\n",
      "Epoch 6578/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 162400312.7665 - val_loss: 752699138.2594\n",
      "Epoch 6579/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 841147807.4237 - val_loss: 2160926842.9682\n",
      "Epoch 6580/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 366173564.4344 - val_loss: 969986140.8608\n",
      "Epoch 6581/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 244255091.5295 - val_loss: 1543338415.4554\n",
      "Epoch 6582/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 241493377.9426 - val_loss: 694042860.0619\n",
      "Epoch 6583/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 207593878.3714 - val_loss: 1183834947.3665\n",
      "Epoch 6584/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 582348506.7597 - val_loss: 1523543969.3412\n",
      "Epoch 6585/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 963771721.2560 - val_loss: 5501946270.9288\n",
      "Epoch 6586/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1413557815.3922 - val_loss: 838570458.7612\n",
      "Epoch 6587/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 295203675.6781 - val_loss: 781971049.1904\n",
      "Epoch 6588/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 215246097.9358 - val_loss: 1095880523.3575\n",
      "Epoch 6589/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 158236117.5464 - val_loss: 1033874043.6838\n",
      "Epoch 6590/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 251792152.7788 - val_loss: 846550296.9519\n",
      "Epoch 6591/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 493156060.0203 - val_loss: 809230176.0675\n",
      "Epoch 6592/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 188977060.1407 - val_loss: 726872396.0169\n",
      "Epoch 6593/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 216994913.1201 - val_loss: 1473871778.8534\n",
      "Epoch 6594/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 516029693.1908 - val_loss: 1748809048.2678\n",
      "Epoch 6595/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 698219258.2043 - val_loss: 788069873.6383\n",
      "Epoch 6596/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 221397583.0906 - val_loss: 1004410436.9148\n",
      "Epoch 6597/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 545781209.0310 - val_loss: 1068294681.2579\n",
      "Epoch 6598/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 364581543.5681 - val_loss: 808747053.0070\n",
      "Epoch 6599/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 242727020.2814 - val_loss: 739545995.9674\n",
      "Epoch 6600/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 179280917.4024 - val_loss: 850249663.9415\n",
      "Epoch 6601/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 434267742.5053 - val_loss: 951715061.6709\n",
      "Epoch 6602/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 280518405.4024 - val_loss: 1158059364.8338\n",
      "Epoch 6603/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 455312916.8171 - val_loss: 2091001490.1648\n",
      "Epoch 6604/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 760125858.6472 - val_loss: 1508457406.5598\n",
      "Epoch 6605/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 482464455.2392 - val_loss: 2395308294.0850\n",
      "Epoch 6606/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 948031662.2442 - val_loss: 1086768131.7536\n",
      "Epoch 6607/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 402936893.4159 - val_loss: 1697572967.8402\n",
      "Epoch 6608/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 240936148.4615 - val_loss: 719538201.5235\n",
      "Epoch 6609/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 322608162.2870 - val_loss: 693664859.9179\n",
      "Epoch 6610/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 283873781.9336 - val_loss: 729475419.1797\n",
      "Epoch 6611/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 584045478.6809 - val_loss: 11963227011.5646\n",
      "Epoch 6612/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 3519695532.3624 - val_loss: 1298624543.9730\n",
      "Epoch 6613/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 552066441.0411 - val_loss: 747498749.3311\n",
      "Epoch 6614/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 121501405.4969 - val_loss: 808906770.2188\n",
      "Epoch 6615/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 257417398.2667 - val_loss: 1094641560.8259\n",
      "Epoch 6616/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 165896906.8047 - val_loss: 708227699.9291\n",
      "Epoch 6617/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 98656824.5312 - val_loss: 671216789.5674\n",
      "Epoch 6618/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 115291804.2634 - val_loss: 1265703636.2892\n",
      "Epoch 6619/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 422794913.2425 - val_loss: 2369385837.7451\n",
      "Epoch 6620/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 440174318.6044 - val_loss: 672600643.7153\n",
      "Epoch 6621/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 153028538.8002 - val_loss: 670174689.7373\n",
      "Epoch 6622/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 389031180.5110 - val_loss: 2361467705.9691\n",
      "Epoch 6623/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 256181973.6860 - val_loss: 1200100159.7300\n",
      "Epoch 6624/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 206360377.1975 - val_loss: 739981400.4388\n",
      "Epoch 6625/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 295452227.5656 - val_loss: 1145772841.3210\n",
      "Epoch 6626/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 473383326.0011 - val_loss: 4529947861.1533\n",
      "Epoch 6627/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 897407952.2971 - val_loss: 1328475795.0830\n",
      "Epoch 6628/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 136481258.0349 - val_loss: 721812434.0568\n",
      "Epoch 6629/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 220696271.0546 - val_loss: 2008963413.9814\n",
      "Epoch 6630/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 525083786.9510 - val_loss: 740223734.9086\n",
      "Epoch 6631/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 112236936.8779 - val_loss: 943583134.9468\n",
      "Epoch 6632/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 396087101.4429 - val_loss: 984812180.7842\n",
      "Epoch 6633/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 693146736.9589 - val_loss: 845791547.0492\n",
      "Epoch 6634/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 265796891.9662 - val_loss: 1220712802.4934\n",
      "Epoch 6635/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 204797404.4029 - val_loss: 700816070.3910\n",
      "Epoch 6636/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 240160530.7057 - val_loss: 935560486.3640\n",
      "Epoch 6637/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 236943270.5729 - val_loss: 783058492.5795\n",
      "Epoch 6638/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1397632829.4429 - val_loss: 1326788493.3221\n",
      "Epoch 6639/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 300896677.6815 - val_loss: 878257234.3696\n",
      "Epoch 6640/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 196586134.8002 - val_loss: 1013070655.5139\n",
      "Epoch 6641/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 143738604.2454 - val_loss: 1045134091.1842\n",
      "Epoch 6642/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 181123539.6753 - val_loss: 841303111.0391\n",
      "Epoch 6643/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 592567222.9499 - val_loss: 737663040.2520\n",
      "Epoch 6644/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 225802192.8014 - val_loss: 1078644966.5350\n",
      "Epoch 6645/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 707963774.0101 - val_loss: 878505365.8824\n",
      "Epoch 6646/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 93us/step - loss: 279277191.2752 - val_loss: 1408386517.8374\n",
      "Epoch 6647/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 327138614.4423 - val_loss: 1071718579.5421\n",
      "Epoch 6648/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 235303711.2077 - val_loss: 1030570627.6073\n",
      "Epoch 6649/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 275679199.9100 - val_loss: 806621885.7496\n",
      "Epoch 6650/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 355884451.0433 - val_loss: 1225261545.6855\n",
      "Epoch 6651/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 609707114.5436 - val_loss: 795027515.6928\n",
      "Epoch 6652/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 251942593.4811 - val_loss: 896609637.0318\n",
      "Epoch 6653/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 208770347.7591 - val_loss: 2704993155.4565\n",
      "Epoch 6654/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 546667532.3174 - val_loss: 850919967.7030\n",
      "Epoch 6655/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 190907272.4187 - val_loss: 749988868.8428\n",
      "Epoch 6656/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 254608788.3489 - val_loss: 1056842649.8430\n",
      "Epoch 6657/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1167740108.7136 - val_loss: 1963505108.9913\n",
      "Epoch 6658/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2187975530.9713 - val_loss: 994654607.3001\n",
      "Epoch 6659/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 295169895.7974 - val_loss: 805244079.5229\n",
      "Epoch 6660/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 143265228.7766 - val_loss: 1005443591.6152\n",
      "Epoch 6661/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 156306221.1728 - val_loss: 1094692289.2962\n",
      "Epoch 6662/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 692449570.8272 - val_loss: 1396390758.5980\n",
      "Epoch 6663/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 204429007.2347 - val_loss: 769418485.0543\n",
      "Epoch 6664/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 157507559.3472 - val_loss: 730794249.2850\n",
      "Epoch 6665/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 167931316.3354 - val_loss: 695987554.5654\n",
      "Epoch 6666/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 190204487.4778 - val_loss: 1352910506.9187\n",
      "Epoch 6667/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 649835894.0619 - val_loss: 848264487.2821\n",
      "Epoch 6668/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 402264239.9370 - val_loss: 1588696248.0608\n",
      "Epoch 6669/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 498260818.8723 - val_loss: 1738216368.8956\n",
      "Epoch 6670/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 657748649.2020 - val_loss: 1001455314.3269\n",
      "Epoch 6671/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 144396619.3540 - val_loss: 788509443.1685\n",
      "Epoch 6672/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 240069950.2983 - val_loss: 925528716.7550\n",
      "Epoch 6673/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 239063730.8903 - val_loss: 908637103.7165\n",
      "Epoch 6674/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 290375903.0096 - val_loss: 730235719.5252\n",
      "Epoch 6675/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 230774320.9499 - val_loss: 810018703.5544\n",
      "Epoch 6676/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 155179785.5217 - val_loss: 868922878.7218\n",
      "Epoch 6677/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 219559396.5560 - val_loss: 13813677681.0577\n",
      "Epoch 6678/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2410480214.3118 - val_loss: 1476016379.8233\n",
      "Epoch 6679/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 232446657.6567 - val_loss: 827461589.8644\n",
      "Epoch 6680/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 219802446.3343 - val_loss: 1217131515.9674\n",
      "Epoch 6681/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 428763874.6337 - val_loss: 747426900.0889\n",
      "Epoch 6682/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 294700764.9612 - val_loss: 720601326.6250\n",
      "Epoch 6683/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 266670289.0636 - val_loss: 733402286.4630\n",
      "Epoch 6684/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 144227564.4975 - val_loss: 708695845.6709\n",
      "Epoch 6685/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 271112621.3663 - val_loss: 863065517.1871\n",
      "Epoch 6686/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 124652748.0394 - val_loss: 700850262.3055\n",
      "Epoch 6687/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 169866894.9736 - val_loss: 2887781140.4512\n",
      "Epoch 6688/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 905824087.0141 - val_loss: 1388177981.4976\n",
      "Epoch 6689/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 259229801.4181 - val_loss: 1007004788.1980\n",
      "Epoch 6690/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 444003546.2555 - val_loss: 1088449526.2065\n",
      "Epoch 6691/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 330614908.0315 - val_loss: 804173543.2506\n",
      "Epoch 6692/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 154474352.4367 - val_loss: 761327363.5466\n",
      "Epoch 6693/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 142009915.3405 - val_loss: 692875771.6568\n",
      "Epoch 6694/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 222318760.2296 - val_loss: 1124644828.2824\n",
      "Epoch 6695/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 460794740.0914 - val_loss: 877892229.3108\n",
      "Epoch 6696/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 213390439.6984 - val_loss: 1380242670.6903\n",
      "Epoch 6697/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 301092648.2296 - val_loss: 2625048107.5668\n",
      "Epoch 6698/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 501499440.3692 - val_loss: 760016194.6914\n",
      "Epoch 6699/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 173272997.0917 - val_loss: 945769056.3601\n",
      "Epoch 6700/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 585612257.8908 - val_loss: 1066783541.5811\n",
      "Epoch 6701/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1054679010.8993 - val_loss: 2616265491.3485\n",
      "Epoch 6702/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 495852016.5402 - val_loss: 3487887709.0520\n",
      "Epoch 6703/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 296665206.0506 - val_loss: 812809620.7347\n",
      "Epoch 6704/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 256015549.3708 - val_loss: 888064193.0262\n",
      "Epoch 6705/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1140665327.2707 - val_loss: 1209889163.5803\n",
      "Epoch 6706/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 646338997.7355 - val_loss: 1169898504.9654\n",
      "Epoch 6707/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 129885858.4100 - val_loss: 670428071.7277\n",
      "Epoch 6708/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 88313788.9342 - val_loss: 729637527.0346\n",
      "Epoch 6709/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 845182064.2251 - val_loss: 1081742983.4442\n",
      "Epoch 6710/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1183794344.8059 - val_loss: 1489994251.0177\n",
      "Epoch 6711/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 259254668.6055 - val_loss: 865076286.4338\n",
      "Epoch 6712/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 332743553.9820 - val_loss: 741743484.5817\n",
      "Epoch 6713/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 120818608.4907 - val_loss: 1202665520.7381\n",
      "Epoch 6714/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 187089350.4108 - val_loss: 814027152.5806\n",
      "Epoch 6715/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 163544485.0568 - val_loss: 952287425.1162\n",
      "Epoch 6716/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 795888724.2769 - val_loss: 4567013037.3671\n",
      "Epoch 6717/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 658300745.0219 - val_loss: 673930717.7091\n",
      "Epoch 6718/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 308748802.1069 - val_loss: 1364825752.9519\n",
      "Epoch 6719/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 157046221.5284 - val_loss: 733544334.2762\n",
      "Epoch 6720/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 164923285.7400 - val_loss: 1179394141.1195\n",
      "Epoch 6721/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 258562629.1322 - val_loss: 1959919987.9201\n",
      "Epoch 6722/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 373302097.2628 - val_loss: 785947306.7252\n",
      "Epoch 6723/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 313375035.9707 - val_loss: 720048707.9044\n",
      "Epoch 6724/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 394637713.9899 - val_loss: 1364905111.4037\n",
      "Epoch 6725/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 310148920.8025 - val_loss: 2223561529.2850\n",
      "Epoch 6726/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 511716053.9201 - val_loss: 1047670186.9660\n",
      "Epoch 6727/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 664579770.4176 - val_loss: 1785256183.8245\n",
      "Epoch 6728/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1182349602.2690 - val_loss: 1095172713.6158\n",
      "Epoch 6729/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 267994694.3647 - val_loss: 895434843.0132\n",
      "Epoch 6730/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 173104058.7597 - val_loss: 773472381.4076\n",
      "Epoch 6731/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 253237057.7378 - val_loss: 771059898.0951\n",
      "Epoch 6732/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 161013781.0602 - val_loss: 730631106.1243\n",
      "Epoch 6733/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 458692422.1947 - val_loss: 798770906.6374\n",
      "Epoch 6734/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 315524590.6494 - val_loss: 836522310.2155\n",
      "Epoch 6735/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 141532745.4609 - val_loss: 710252744.6774\n",
      "Epoch 6736/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 382796867.6016 - val_loss: 704058103.4757\n",
      "Epoch 6737/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 313744540.7181 - val_loss: 971664013.3131\n",
      "Epoch 6738/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1949548835.6196 - val_loss: 1318217815.8717\n",
      "Epoch 6739/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 328379910.6697 - val_loss: 890933183.5454\n",
      "Epoch 6740/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 143331098.4192 - val_loss: 744992149.1443\n",
      "Epoch 6741/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 257980770.7012 - val_loss: 759973664.3871\n",
      "Epoch 6742/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 173073162.7957 - val_loss: 734595698.6802\n",
      "Epoch 6743/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 375855221.1232 - val_loss: 945356128.3241\n",
      "Epoch 6744/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 491753855.3765 - val_loss: 891216259.2765\n",
      "Epoch 6745/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 211196517.7400 - val_loss: 711408349.6641\n",
      "Epoch 6746/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 236666214.8430 - val_loss: 899870514.4619\n",
      "Epoch 6747/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 312680003.9167 - val_loss: 1336437546.4506\n",
      "Epoch 6748/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 441625556.9972 - val_loss: 1214855898.8557\n",
      "Epoch 6749/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 617252487.8334 - val_loss: 1087628431.7142\n",
      "Epoch 6750/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 248170191.9752 - val_loss: 780429406.3347\n",
      "Epoch 6751/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 162336217.3551 - val_loss: 1283444257.0532\n",
      "Epoch 6752/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 289181811.3585 - val_loss: 1833015351.5927\n",
      "Epoch 6753/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 317670104.8329 - val_loss: 1724129630.1187\n",
      "Epoch 6754/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 573461396.9972 - val_loss: 785000148.0011\n",
      "Epoch 6755/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 342096095.6939 - val_loss: 1481373793.5842\n",
      "Epoch 6756/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 876236386.5301 - val_loss: 4665422704.5536\n",
      "Epoch 6757/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1108791719.3292 - val_loss: 720794365.3986\n",
      "Epoch 6758/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 244443285.0900 - val_loss: 810327265.0014\n",
      "Epoch 6759/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 217369435.8222 - val_loss: 1559919844.0056\n",
      "Epoch 6760/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 432013889.3506 - val_loss: 973853613.3311\n",
      "Epoch 6761/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 213467052.3849 - val_loss: 796766737.2377\n",
      "Epoch 6762/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 182407580.9567 - val_loss: 1873146572.0439\n",
      "Epoch 6763/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 373305490.6852 - val_loss: 921266930.3719\n",
      "Epoch 6764/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 215182010.0034 - val_loss: 1293335240.1733\n",
      "Epoch 6765/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 344039613.5599 - val_loss: 956848765.4211\n",
      "Epoch 6766/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 339061382.3208 - val_loss: 909476765.0205\n",
      "Epoch 6767/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 521920735.6128 - val_loss: 1662990831.8695\n",
      "Epoch 6768/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 622701424.6663 - val_loss: 1216178038.1345\n",
      "Epoch 6769/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 255482645.2853 - val_loss: 2070110703.4419\n",
      "Epoch 6770/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 682159519.8739 - val_loss: 1912709921.7373\n",
      "Epoch 6771/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 290416949.4789 - val_loss: 1197891080.1598\n",
      "Epoch 6772/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 219418425.2786 - val_loss: 826827254.7376\n",
      "Epoch 6773/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 297293092.3039 - val_loss: 1085112029.6866\n",
      "Epoch 6774/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 498852339.0884 - val_loss: 1651999631.6264\n",
      "Epoch 6775/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 291635305.0400 - val_loss: 1034198111.9100\n",
      "Epoch 6776/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 85us/step - loss: 600495058.2600 - val_loss: 1694082836.9553\n",
      "Epoch 6777/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 322255278.8925 - val_loss: 1219514586.7702\n",
      "Epoch 6778/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 276976420.0338 - val_loss: 3942913663.8920\n",
      "Epoch 6779/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1072414811.2639 - val_loss: 902936753.7058\n",
      "Epoch 6780/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 211376579.8852 - val_loss: 817594556.9485\n",
      "Epoch 6781/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 243169380.8441 - val_loss: 784133395.9831\n",
      "Epoch 6782/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 282639715.9437 - val_loss: 1838323499.5128\n",
      "Epoch 6783/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 263784006.2847 - val_loss: 1168472539.9944\n",
      "Epoch 6784/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 254233241.7513 - val_loss: 1141703349.1803\n",
      "Epoch 6785/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 417902675.2741 - val_loss: 1437641931.6478\n",
      "Epoch 6786/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 540008972.1193 - val_loss: 1395781282.2504\n",
      "Epoch 6787/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 754561286.7079 - val_loss: 1310371099.3103\n",
      "Epoch 6788/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 168595626.0304 - val_loss: 775713650.4000\n",
      "Epoch 6789/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 257643831.2122 - val_loss: 707374185.5055\n",
      "Epoch 6790/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 247905915.9302 - val_loss: 1267282228.8923\n",
      "Epoch 6791/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 429181099.9223 - val_loss: 893802978.0478\n",
      "Epoch 6792/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 646674081.4992 - val_loss: 1405640262.0129\n",
      "Epoch 6793/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 589518251.7231 - val_loss: 1452082072.3758\n",
      "Epoch 6794/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 488789754.9578 - val_loss: 670596877.6101\n",
      "Epoch 6795/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 118881111.4733 - val_loss: 1188767404.7640\n",
      "Epoch 6796/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 239635834.9218 - val_loss: 2744881504.4051\n",
      "Epoch 6797/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 468775384.7068 - val_loss: 794932320.6121\n",
      "Epoch 6798/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 117520274.7372 - val_loss: 1447024263.8132\n",
      "Epoch 6799/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 264947556.4750 - val_loss: 1359858180.4602\n",
      "Epoch 6800/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 415111004.8846 - val_loss: 1137398409.3705\n",
      "Epoch 6801/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 306373636.2769 - val_loss: 969711355.4678\n",
      "Epoch 6802/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 621259487.9460 - val_loss: 1488564393.1634\n",
      "Epoch 6803/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 339688460.6145 - val_loss: 723968768.6571\n",
      "Epoch 6804/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 147467316.3309 - val_loss: 910145098.3696\n",
      "Epoch 6805/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 416212425.4001 - val_loss: 1199860619.9719\n",
      "Epoch 6806/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 608078985.5082 - val_loss: 2353746111.6940\n",
      "Epoch 6807/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 2361331597.2943 - val_loss: 910317962.6757\n",
      "Epoch 6808/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 123209512.8059 - val_loss: 831293481.6416\n",
      "Epoch 6809/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 193171369.5442 - val_loss: 764036922.4371\n",
      "Epoch 6810/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 162346173.3033 - val_loss: 999855807.8560\n",
      "Epoch 6811/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 297916564.7091 - val_loss: 4569560653.3401\n",
      "Epoch 6812/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 2057551821.0017 - val_loss: 3757203746.9255\n",
      "Epoch 6813/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 662203287.8019 - val_loss: 687420948.7392\n",
      "Epoch 6814/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 109273867.4305 - val_loss: 691849000.2363\n",
      "Epoch 6815/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 108293844.4035 - val_loss: 832947683.8796\n",
      "Epoch 6816/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 119365652.0788 - val_loss: 949169764.8158\n",
      "Epoch 6817/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 206704328.8734 - val_loss: 823104618.0276\n",
      "Epoch 6818/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 157096618.5324 - val_loss: 710509897.8835\n",
      "Epoch 6819/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 116415197.6342 - val_loss: 811664244.2847\n",
      "Epoch 6820/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 296260389.9122 - val_loss: 989844200.1103\n",
      "Epoch 6821/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 178120955.4761 - val_loss: 1127819060.3612\n",
      "Epoch 6822/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 313434735.5453 - val_loss: 771855106.9795\n",
      "Epoch 6823/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 208249087.4958 - val_loss: 28077322365.2996\n",
      "Epoch 6824/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 2499659464.7518 - val_loss: 1079136751.0053\n",
      "Epoch 6825/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 215282620.6145 - val_loss: 943369954.5474\n",
      "Epoch 6826/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 200807760.2431 - val_loss: 861402747.6073\n",
      "Epoch 6827/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 125370494.8835 - val_loss: 858493818.9907\n",
      "Epoch 6828/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 290562943.5318 - val_loss: 1205869371.5173\n",
      "Epoch 6829/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 420951863.0321 - val_loss: 874273823.3609\n",
      "Epoch 6830/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 290664439.0231 - val_loss: 959029861.4819\n",
      "Epoch 6831/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 155902682.7642 - val_loss: 843577323.8008\n",
      "Epoch 6832/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 323073012.8756 - val_loss: 902972674.6914\n",
      "Epoch 6833/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 301895371.9527 - val_loss: 1236599540.3994\n",
      "Epoch 6834/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 276424687.3934 - val_loss: 2211184606.4338\n",
      "Epoch 6835/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 292187161.0692 - val_loss: 852232661.5674\n",
      "Epoch 6836/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 136617539.1964 - val_loss: 1024304359.4622\n",
      "Epoch 6837/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 308124838.0687 - val_loss: 1343018302.9288\n",
      "Epoch 6838/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 570759169.0174 - val_loss: 1220647299.1482\n",
      "Epoch 6839/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 209413523.5774 - val_loss: 883027520.5581\n",
      "Epoch 6840/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 194653419.2572 - val_loss: 718433663.1539\n",
      "Epoch 6841/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 358828699.9122 - val_loss: 1424806389.5224\n",
      "Epoch 6842/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 558911997.7333 - val_loss: 925030874.9682\n",
      "Epoch 6843/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 230561676.6055 - val_loss: 1211143052.8000\n",
      "Epoch 6844/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 244598187.3540 - val_loss: 879438198.7105\n",
      "Epoch 6845/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 349224476.0923 - val_loss: 1411640022.3550\n",
      "Epoch 6846/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 485235025.0895 - val_loss: 1452133908.2712\n",
      "Epoch 6847/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 443475925.5734 - val_loss: 2503109371.6433\n",
      "Epoch 6848/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 428144124.3984 - val_loss: 1235859708.4354\n",
      "Epoch 6849/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 371279277.4879 - val_loss: 1548525354.4236\n",
      "Epoch 6850/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 421032105.1660 - val_loss: 1014159207.5837\n",
      "Epoch 6851/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 396268140.2828 - val_loss: 790124516.6177\n",
      "Epoch 6852/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 184813321.1120 - val_loss: 1374951468.0979\n",
      "Epoch 6853/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 864219596.9207 - val_loss: 1172228049.2242\n",
      "Epoch 6854/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 514513472.7833 - val_loss: 783875389.9679\n",
      "Epoch 6855/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 187442634.2330 - val_loss: 1237221620.6942\n",
      "Epoch 6856/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 172256545.9449 - val_loss: 1719504027.4003\n",
      "Epoch 6857/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 382068168.0360 - val_loss: 763443363.8616\n",
      "Epoch 6858/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 303855870.8317 - val_loss: 902603374.1097\n",
      "Epoch 6859/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 178089402.5796 - val_loss: 684322795.7536\n",
      "Epoch 6860/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 178673936.5447 - val_loss: 1016809037.4841\n",
      "Epoch 6861/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 409127842.6472 - val_loss: 5632610207.8380\n",
      "Epoch 6862/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1669611239.7324 - val_loss: 1181393756.9305\n",
      "Epoch 6863/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 226461168.2926 - val_loss: 831374352.2745\n",
      "Epoch 6864/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 183411718.2487 - val_loss: 982440212.5502\n",
      "Epoch 6865/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 310890662.5864 - val_loss: 665529445.7857\n",
      "Epoch 6866/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 150533307.1030 - val_loss: 757241918.9221\n",
      "Epoch 6867/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 284242132.2769 - val_loss: 2627735511.3857\n",
      "Epoch 6868/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 491083094.3568 - val_loss: 969605566.3437\n",
      "Epoch 6869/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 260107819.4958 - val_loss: 1450193657.1229\n",
      "Epoch 6870/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 540827788.1781 - val_loss: 770566580.2442\n",
      "Epoch 6871/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 130680870.7265 - val_loss: 1416882071.3857\n",
      "Epoch 6872/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1549432125.0141 - val_loss: 3667513489.9308\n",
      "Epoch 6873/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 813467780.2217 - val_loss: 756876512.0540\n",
      "Epoch 6874/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 121856266.9758 - val_loss: 693760925.7767\n",
      "Epoch 6875/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 232407255.1941 - val_loss: 1258960947.6501\n",
      "Epoch 6876/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 413220447.0096 - val_loss: 819702694.1817\n",
      "Epoch 6877/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 148102854.1002 - val_loss: 679340888.8034\n",
      "Epoch 6878/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 139717012.4930 - val_loss: 970812812.5210\n",
      "Epoch 6879/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 237064301.8255 - val_loss: 1202307318.3004\n",
      "Epoch 6880/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 257221849.8683 - val_loss: 1960148298.3876\n",
      "Epoch 6881/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 485576061.0073 - val_loss: 1187746200.1958\n",
      "Epoch 6882/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 166631710.1564 - val_loss: 975346467.3418\n",
      "Epoch 6883/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 213475033.2375 - val_loss: 827277787.9584\n",
      "Epoch 6884/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 258058463.6038 - val_loss: 1200498965.0363\n",
      "Epoch 6885/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 491139410.7642 - val_loss: 7404368813.2411\n",
      "Epoch 6886/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1278577523.2504 - val_loss: 1088145432.7314\n",
      "Epoch 6887/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 400176520.2971 - val_loss: 892946247.8357\n",
      "Epoch 6888/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 167359098.3725 - val_loss: 679695452.2284\n",
      "Epoch 6889/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 210187961.9854 - val_loss: 1066318054.8231\n",
      "Epoch 6890/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 281938572.2634 - val_loss: 809717185.5572\n",
      "Epoch 6891/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 336507046.6607 - val_loss: 1348728485.5359\n",
      "Epoch 6892/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 257266539.3360 - val_loss: 901516404.6042\n",
      "Epoch 6893/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 732166089.4541 - val_loss: 1728342990.6543\n",
      "Epoch 6894/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 810939845.5464 - val_loss: 840491018.3674\n",
      "Epoch 6895/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 165089052.8846 - val_loss: 742532490.9232\n",
      "Epoch 6896/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 188571787.4274 - val_loss: 1126408929.9893\n",
      "Epoch 6897/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 279579091.9887 - val_loss: 757435332.6774\n",
      "Epoch 6898/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 208457322.3365 - val_loss: 792073537.1702\n",
      "Epoch 6899/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 253793235.7186 - val_loss: 875813095.1291\n",
      "Epoch 6900/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 159681356.5695 - val_loss: 923826344.6008\n",
      "Epoch 6901/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 412017689.1148 - val_loss: 1188013676.4850\n",
      "Epoch 6902/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 1140050103.3922 - val_loss: 1042705477.1218\n",
      "Epoch 6903/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 411078982.9195 - val_loss: 713454217.6765\n",
      "Epoch 6904/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 119434857.8683 - val_loss: 925595324.8675\n",
      "Epoch 6905/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 164551352.0945 - val_loss: 1283465579.0267\n",
      "Epoch 6906/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 92us/step - loss: 879205147.2909 - val_loss: 1221131200.2340\n",
      "Epoch 6907/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 225341859.1514 - val_loss: 748509562.8827\n",
      "Epoch 6908/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 613883646.0461 - val_loss: 2724321698.8174\n",
      "Epoch 6909/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 419551640.0945 - val_loss: 807311845.4999\n",
      "Epoch 6910/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 204900233.0940 - val_loss: 850057152.8911\n",
      "Epoch 6911/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 383208677.4384 - val_loss: 949726448.4456\n",
      "Epoch 6912/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 219033374.2622 - val_loss: 933661219.2945\n",
      "Epoch 6913/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 202785458.5616 - val_loss: 748677194.9435\n",
      "Epoch 6914/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 197425278.4783 - val_loss: 726740368.0968\n",
      "Epoch 6915/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 164838726.2487 - val_loss: 1597297988.1316\n",
      "Epoch 6916/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 385529030.6359 - val_loss: 895657467.2563\n",
      "Epoch 6917/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 120453856.5222 - val_loss: 3108897550.3122\n",
      "Epoch 6918/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 389808568.7248 - val_loss: 3932995391.4059\n",
      "Epoch 6919/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 864858190.6044 - val_loss: 897693377.4357\n",
      "Epoch 6920/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 299915951.4508 - val_loss: 892735548.7055\n",
      "Epoch 6921/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 329786361.0129 - val_loss: 1263599610.4191\n",
      "Epoch 6922/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 502380702.4153 - val_loss: 1831115819.4633\n",
      "Epoch 6923/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 568532506.1474 - val_loss: 1213297500.1744\n",
      "Epoch 6924/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 525237395.8087 - val_loss: 3105982858.0456\n",
      "Epoch 6925/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 1448497270.3478 - val_loss: 2486737659.6073\n",
      "Epoch 6926/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 573151097.0264 - val_loss: 859494196.3972\n",
      "Epoch 6927/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 215037738.0844 - val_loss: 1792942722.1603\n",
      "Epoch 6928/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 515541041.0264 - val_loss: 871655065.8520\n",
      "Epoch 6929/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 306084687.2347 - val_loss: 1226500615.4172\n",
      "Epoch 6930/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 175583705.5352 - val_loss: 705857143.8740\n",
      "Epoch 6931/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 137637000.8419 - val_loss: 813922137.6720\n",
      "Epoch 6932/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 161392392.6078 - val_loss: 1717576447.4959\n",
      "Epoch 6933/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 481972687.6308 - val_loss: 1942659255.3947\n",
      "Epoch 6934/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 294320653.9741 - val_loss: 2324530542.8343\n",
      "Epoch 6935/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 685778475.0796 - val_loss: 918529785.8487\n",
      "Epoch 6936/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 139463260.3264 - val_loss: 755120934.0399\n",
      "Epoch 6937/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 213926291.0523 - val_loss: 878368502.4720\n",
      "Epoch 6938/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 192099166.4513 - val_loss: 880948564.5412\n",
      "Epoch 6939/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 555968208.8194 - val_loss: 12944978367.1899\n",
      "Epoch 6940/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1797596671.4237 - val_loss: 2718890540.9530\n",
      "Epoch 6941/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 318106320.3692 - val_loss: 682655979.1437\n",
      "Epoch 6942/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 142326942.3714 - val_loss: 850501869.1871\n",
      "Epoch 6943/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 143451218.6922 - val_loss: 815065202.8309\n",
      "Epoch 6944/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 137997903.1266 - val_loss: 1476588713.8655\n",
      "Epoch 6945/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 479756857.9100 - val_loss: 921333011.8166\n",
      "Epoch 6946/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 676317316.7901 - val_loss: 6882661491.0740\n",
      "Epoch 6947/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 883657575.7569 - val_loss: 1515970156.8810\n",
      "Epoch 6948/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 295145933.1818 - val_loss: 2548875461.9319\n",
      "Epoch 6949/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 418808969.9133 - val_loss: 944705377.5392\n",
      "Epoch 6950/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 148540957.3258 - val_loss: 693625614.1592\n",
      "Epoch 6951/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 160648407.4913 - val_loss: 774518860.6830\n",
      "Epoch 6952/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 330355755.5262 - val_loss: 4841841851.0852\n",
      "Epoch 6953/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1164805112.9977 - val_loss: 1053582083.7806\n",
      "Epoch 6954/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 194346729.4012 - val_loss: 758278264.3128\n",
      "Epoch 6955/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 439755471.6120 - val_loss: 723102553.1499\n",
      "Epoch 6956/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 139414422.1767 - val_loss: 750998713.4627\n",
      "Epoch 6957/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 119302301.0377 - val_loss: 888671913.6585\n",
      "Epoch 6958/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 282261255.9066 - val_loss: 710135377.6608\n",
      "Epoch 6959/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 245767536.0810 - val_loss: 1784891881.7125\n",
      "Epoch 6960/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 262544915.3765 - val_loss: 935313122.4461\n",
      "Epoch 6961/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 571962282.4491 - val_loss: 1129644225.4582\n",
      "Epoch 6962/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 356172635.7681 - val_loss: 901374842.8782\n",
      "Epoch 6963/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 388312178.9983 - val_loss: 2180794248.1553\n",
      "Epoch 6964/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 791549728.0990 - val_loss: 801202319.0436\n",
      "Epoch 6965/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 515780200.1936 - val_loss: 1019038579.2720\n",
      "Epoch 6966/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 561074603.9842 - val_loss: 1137705418.7837\n",
      "Epoch 6967/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 170240715.4890 - val_loss: 740083000.7179\n",
      "Epoch 6968/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 159883691.1109 - val_loss: 793712956.2824\n",
      "Epoch 6969/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 260981230.4423 - val_loss: 806093418.1491\n",
      "Epoch 6970/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 598722563.9257 - val_loss: 1022368027.8143\n",
      "Epoch 6971/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 505083584.4524 - val_loss: 1078687081.4155\n",
      "Epoch 6972/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 262345624.5267 - val_loss: 1166866867.6141\n",
      "Epoch 6973/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 426722473.0535 - val_loss: 2264226425.8790\n",
      "Epoch 6974/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 825607207.1446 - val_loss: 843942460.4940\n",
      "Epoch 6975/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 251293069.5779 - val_loss: 832266937.0262\n",
      "Epoch 6976/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 326594668.6570 - val_loss: 1572880610.5114\n",
      "Epoch 6977/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 484696790.7800 - val_loss: 989211578.6532\n",
      "Epoch 6978/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 243139706.3016 - val_loss: 1206358286.8883\n",
      "Epoch 6979/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 357550538.4266 - val_loss: 1301627654.8771\n",
      "Epoch 6980/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 261170200.0090 - val_loss: 2004405295.8155\n",
      "Epoch 6981/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1373148310.4918 - val_loss: 846809419.7828\n",
      "Epoch 6982/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 186456155.2729 - val_loss: 733203940.5907\n",
      "Epoch 6983/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 141756911.2167 - val_loss: 2118340357.4999\n",
      "Epoch 6984/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 248066843.7546 - val_loss: 691556890.1986\n",
      "Epoch 6985/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 260628659.2977 - val_loss: 765641592.7809\n",
      "Epoch 6986/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 123210640.9994 - val_loss: 2304820074.3606\n",
      "Epoch 6987/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 714639295.5678 - val_loss: 1864035504.8956\n",
      "Epoch 6988/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1414239029.4778 - val_loss: 805862268.2644\n",
      "Epoch 6989/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 245960253.0107 - val_loss: 979544692.2239\n",
      "Epoch 6990/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 222484988.7136 - val_loss: 868132308.7752\n",
      "Epoch 6991/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 217346686.0551 - val_loss: 850973504.0135\n",
      "Epoch 6992/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 274755236.2881 - val_loss: 811251685.7384\n",
      "Epoch 6993/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 206896046.1002 - val_loss: 2519881135.5454\n",
      "Epoch 6994/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 432473893.0062 - val_loss: 822878697.4965\n",
      "Epoch 6995/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 323701168.2071 - val_loss: 875463453.1466\n",
      "Epoch 6996/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 215970482.7147 - val_loss: 957429227.5871\n",
      "Epoch 6997/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 218937483.1649 - val_loss: 3459742639.5634\n",
      "Epoch 6998/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 592133042.2600 - val_loss: 711540096.1879\n",
      "Epoch 6999/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 162025607.1491 - val_loss: 743158323.7603\n",
      "Epoch 7000/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 364922405.4564 - val_loss: 1879208691.1100\n",
      "Epoch 7001/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 717781719.0501 - val_loss: 1623949395.1190\n",
      "Epoch 7002/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 253166766.7316 - val_loss: 667079543.7592\n",
      "Epoch 7003/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 209134135.0366 - val_loss: 773549505.7508\n",
      "Epoch 7004/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 232932987.8244 - val_loss: 676343269.0993\n",
      "Epoch 7005/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 408722187.2347 - val_loss: 720745134.7173\n",
      "Epoch 7006/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 163356046.0371 - val_loss: 730991560.6729\n",
      "Epoch 7007/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 196664724.8531 - val_loss: 896984351.7885\n",
      "Epoch 7008/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 691966667.1469 - val_loss: 2406356399.1674\n",
      "Epoch 7009/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1292964098.6652 - val_loss: 2356946319.1314\n",
      "Epoch 7010/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 654629819.5160 - val_loss: 773262082.5609\n",
      "Epoch 7011/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 168125848.2026 - val_loss: 1292060932.6042\n",
      "Epoch 7012/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 172172595.2549 - val_loss: 699185171.4655\n",
      "Epoch 7013/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 304546351.9640 - val_loss: 2289901376.4411\n",
      "Epoch 7014/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 873442990.4536 - val_loss: 1391249858.9165\n",
      "Epoch 7015/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 240025488.7833 - val_loss: 712297977.8385\n",
      "Epoch 7016/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 234564455.5093 - val_loss: 1038101987.5916\n",
      "Epoch 7017/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 256972248.3827 - val_loss: 823541867.9449\n",
      "Epoch 7018/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1009485351.9055 - val_loss: 3729813184.4771\n",
      "Epoch 7019/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 430033421.2639 - val_loss: 710604058.3809\n",
      "Epoch 7020/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 102462431.2797 - val_loss: 1405935636.0011\n",
      "Epoch 7021/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 512186593.6477 - val_loss: 831211316.4332\n",
      "Epoch 7022/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 260162263.8143 - val_loss: 1413961425.8408\n",
      "Epoch 7023/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 291562670.5639 - val_loss: 740987425.6653\n",
      "Epoch 7024/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 292107398.1770 - val_loss: 757327621.5089\n",
      "Epoch 7025/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 133391594.7237 - val_loss: 880181270.7533\n",
      "Epoch 7026/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 293187343.1356 - val_loss: 941895910.6520\n",
      "Epoch 7027/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 299249388.2994 - val_loss: 1997637173.0003\n",
      "Epoch 7028/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 2089215349.6635 - val_loss: 1676497997.5201\n",
      "Epoch 7029/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 380295664.0416 - val_loss: 797681412.9778\n",
      "Epoch 7030/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 413816759.5903 - val_loss: 699958246.1300\n",
      "Epoch 7031/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 202680593.7062 - val_loss: 910085217.7733\n",
      "Epoch 7032/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 140461704.9409 - val_loss: 1060536534.2695\n",
      "Epoch 7033/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 195650381.5779 - val_loss: 1308386249.3525\n",
      "Epoch 7034/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 201669943.0321 - val_loss: 3285413292.2509\n",
      "Epoch 7035/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 530610921.5982 - val_loss: 2525656884.6402\n",
      "Epoch 7036/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 89us/step - loss: 710787943.9055 - val_loss: 1011350141.9837\n",
      "Epoch 7037/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 200451573.4159 - val_loss: 1000180021.3918\n",
      "Epoch 7038/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 311442955.3450 - val_loss: 716050043.3688\n",
      "Epoch 7039/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 280152379.3180 - val_loss: 1671737811.9606\n",
      "Epoch 7040/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 436663020.3444 - val_loss: 781021879.9083\n",
      "Epoch 7041/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 307366270.1812 - val_loss: 795227475.3710\n",
      "Epoch 7042/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 262336420.4811 - val_loss: 1304659375.0774\n",
      "Epoch 7043/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 326636689.5062 - val_loss: 669542759.0076\n",
      "Epoch 7044/10000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 174494380.7946 - val_loss: 912599161.5100\n",
      "Epoch 7045/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 157307292.3624 - val_loss: 2213149605.1578\n",
      "Epoch 7046/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 702591117.5239 - val_loss: 1128287930.0343\n",
      "Epoch 7047/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 347616493.7760 - val_loss: 1044540180.8248\n",
      "Epoch 7048/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 790865669.1142 - val_loss: 1034108430.9063\n",
      "Epoch 7049/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 680957012.5830 - val_loss: 797085120.7471\n",
      "Epoch 7050/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 344847320.7518 - val_loss: 727753410.2188\n",
      "Epoch 7051/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 146940109.4249 - val_loss: 1158602054.3179\n",
      "Epoch 7052/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 304002120.5132 - val_loss: 1125101795.3215\n",
      "Epoch 7053/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 462425367.5183 - val_loss: 5241801620.8293\n",
      "Epoch 7054/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1196712434.3320 - val_loss: 741489774.0782\n",
      "Epoch 7055/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 131920618.5121 - val_loss: 745270534.5058\n",
      "Epoch 7056/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 206091367.3472 - val_loss: 714247057.9128\n",
      "Epoch 7057/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 142998592.1441 - val_loss: 1800251206.2920\n",
      "Epoch 7058/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 311502478.1902 - val_loss: 1457248318.4698\n",
      "Epoch 7059/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1073312479.2257 - val_loss: 1093798892.3409\n",
      "Epoch 7060/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 420769458.4592 - val_loss: 688220089.5010\n",
      "Epoch 7061/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 105204295.3472 - val_loss: 785426883.4993\n",
      "Epoch 7062/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 110482864.9634 - val_loss: 1125606489.4380\n",
      "Epoch 7063/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 274114010.1474 - val_loss: 2160122861.3221\n",
      "Epoch 7064/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 596807099.2752 - val_loss: 748042332.9035\n",
      "Epoch 7065/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 135298788.3219 - val_loss: 966397521.1927\n",
      "Epoch 7066/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 655436474.2375 - val_loss: 1021011173.8397\n",
      "Epoch 7067/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 576592332.3894 - val_loss: 1845662077.4796\n",
      "Epoch 7068/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 400948247.3517 - val_loss: 703963711.1876\n",
      "Epoch 7069/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 275722894.1902 - val_loss: 7548594080.8011\n",
      "Epoch 7070/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1338871143.0051 - val_loss: 716318556.1941\n",
      "Epoch 7071/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 192987597.0737 - val_loss: 1326865275.5983\n",
      "Epoch 7072/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 266402131.6151 - val_loss: 880720999.8402\n",
      "Epoch 7073/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 152162867.5611 - val_loss: 897177230.6025\n",
      "Epoch 7074/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 341858861.1458 - val_loss: 1243614966.4225\n",
      "Epoch 7075/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 226571382.6179 - val_loss: 696851438.7173\n",
      "Epoch 7076/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 276683929.5577 - val_loss: 739397055.0897\n",
      "Epoch 7077/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 198635292.5830 - val_loss: 741422551.6219\n",
      "Epoch 7078/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 165291328.0540 - val_loss: 870010998.6745\n",
      "Epoch 7079/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 191204597.7535 - val_loss: 828170647.7277\n",
      "Epoch 7080/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 668621157.4924 - val_loss: 1191758611.1730\n",
      "Epoch 7081/10000\n",
      "3554/3554 [==============================] - 1s 149us/step - loss: 565143706.8329 - val_loss: 805017582.9513\n",
      "Epoch 7082/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 224516437.2043 - val_loss: 667504107.1381\n",
      "Epoch 7083/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 139501306.8768 - val_loss: 766905864.5063\n",
      "Epoch 7084/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 214243355.0118 - val_loss: 977243956.1722\n",
      "Epoch 7085/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 288857923.0613 - val_loss: 1061611592.9834\n",
      "Epoch 7086/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 2920128713.3686 - val_loss: 1371517765.5719\n",
      "Epoch 7087/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 362551330.8588 - val_loss: 694126435.8256\n",
      "Epoch 7088/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 123614369.7738 - val_loss: 653419064.3668\n",
      "Epoch 7089/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 220739983.4395 - val_loss: 767686975.4419\n",
      "Epoch 7090/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 206519587.9133 - val_loss: 706351751.3496\n",
      "Epoch 7091/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 101468318.0371 - val_loss: 848645620.1789\n",
      "Epoch 7092/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 244582197.9471 - val_loss: 1076780044.1339\n",
      "Epoch 7093/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 182989771.0568 - val_loss: 1205904722.0928\n",
      "Epoch 7094/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 283005443.7347 - val_loss: 827343703.0751\n",
      "Epoch 7095/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 153330839.4249 - val_loss: 817421370.7229\n",
      "Epoch 7096/10000\n",
      "3554/3554 [==============================] - 0s 130us/step - loss: 111897302.7912 - val_loss: 826538456.3556\n",
      "Epoch 7097/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 588398306.4457 - val_loss: 4140221955.0245\n",
      "Epoch 7098/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1043877896.9184 - val_loss: 1486191397.5989\n",
      "Epoch 7099/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 461176567.3832 - val_loss: 3253591111.5792\n",
      "Epoch 7100/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 372880441.8458 - val_loss: 865525199.3305\n",
      "Epoch 7101/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 202669586.4221 - val_loss: 1078333377.6180\n",
      "Epoch 7102/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 169995339.3506 - val_loss: 1486656760.2678\n",
      "Epoch 7103/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1205057972.2172 - val_loss: 728713695.7480\n",
      "Epoch 7104/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 150387262.6494 - val_loss: 757521614.5373\n",
      "Epoch 7105/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 349215922.4806 - val_loss: 1283504900.1947\n",
      "Epoch 7106/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 161697423.6297 - val_loss: 663171639.1381\n",
      "Epoch 7107/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 245247614.5909 - val_loss: 1040182584.2948\n",
      "Epoch 7108/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 243311014.4131 - val_loss: 695829582.3077\n",
      "Epoch 7109/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 129981136.2791 - val_loss: 3158594394.5541\n",
      "Epoch 7110/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 702218980.9927 - val_loss: 1076424065.7733\n",
      "Epoch 7111/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 372397516.8756 - val_loss: 1040833685.0993\n",
      "Epoch 7112/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 230709160.0023 - val_loss: 714508550.0219\n",
      "Epoch 7113/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 512881124.9702 - val_loss: 2433040660.1271\n",
      "Epoch 7114/10000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 351664729.1078 - val_loss: 878166473.6855\n",
      "Epoch 7115/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 354292525.7490 - val_loss: 763800350.7218\n",
      "Epoch 7116/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 132331823.9550 - val_loss: 1444434167.0751\n",
      "Epoch 7117/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 182616141.0557 - val_loss: 749462950.5812\n",
      "Epoch 7118/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 496940759.2842 - val_loss: 832331625.3525\n",
      "Epoch 7119/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 379518845.5059 - val_loss: 947834727.9887\n",
      "Epoch 7120/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 303441746.2600 - val_loss: 2050534102.4495\n",
      "Epoch 7121/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 482005952.7845 - val_loss: 3026158102.8276\n",
      "Epoch 7122/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 564556614.1137 - val_loss: 1131128424.8619\n",
      "Epoch 7123/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 322665315.0433 - val_loss: 1691235548.9665\n",
      "Epoch 7124/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 256024842.0225 - val_loss: 709406533.8284\n",
      "Epoch 7125/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 306393813.3844 - val_loss: 704092108.6425\n",
      "Epoch 7126/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 261395108.3039 - val_loss: 695392679.9122\n",
      "Epoch 7127/10000\n",
      "3554/3554 [==============================] - 0s 132us/step - loss: 357690526.8782 - val_loss: 730307218.8883\n",
      "Epoch 7128/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 129824103.0861 - val_loss: 783657320.3848\n",
      "Epoch 7129/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 195424975.2797 - val_loss: 807055107.0020\n",
      "Epoch 7130/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 205809453.4564 - val_loss: 751757900.1564\n",
      "Epoch 7131/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 807436961.2966 - val_loss: 3259603952.3736\n",
      "Epoch 7132/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 780402569.5802 - val_loss: 4329670745.7080\n",
      "Epoch 7133/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 1542918278.6629 - val_loss: 2364269725.9207\n",
      "Epoch 7134/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 333345716.5830 - val_loss: 2738447517.4166\n",
      "Epoch 7135/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 345528636.2364 - val_loss: 749941318.9671\n",
      "Epoch 7136/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 201378147.8042 - val_loss: 832532080.8416\n",
      "Epoch 7137/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 111569146.3635 - val_loss: 1637414259.8661\n",
      "Epoch 7138/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 171414547.2594 - val_loss: 734926374.9941\n",
      "Epoch 7139/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 176288292.7473 - val_loss: 770579474.8940\n",
      "Epoch 7140/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 1425436086.6359 - val_loss: 2468958779.1122\n",
      "Epoch 7141/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 250007382.2217 - val_loss: 942714761.0127\n",
      "Epoch 7142/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 194807189.1412 - val_loss: 1834199104.7291\n",
      "Epoch 7143/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 959407445.7175 - val_loss: 1116423862.8456\n",
      "Epoch 7144/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 456541247.0996 - val_loss: 1049060474.5947\n",
      "Epoch 7145/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 167402289.8886 - val_loss: 735986715.2698\n",
      "Epoch 7146/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 124775060.3849 - val_loss: 832092547.0278\n",
      "Epoch 7147/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 222587950.8385 - val_loss: 789686218.7297\n",
      "Epoch 7148/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 589397635.4361 - val_loss: 1174350731.8323\n",
      "Epoch 7149/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 250651149.7940 - val_loss: 1536789607.7142\n",
      "Epoch 7150/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 269066778.8137 - val_loss: 882263334.0399\n",
      "Epoch 7151/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 685249891.3315 - val_loss: 1030413095.8042\n",
      "Epoch 7152/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 161306606.5053 - val_loss: 717774522.7297\n",
      "Epoch 7153/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 192979529.1007 - val_loss: 984234724.8113\n",
      "Epoch 7154/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 211321297.0895 - val_loss: 1910706031.5994\n",
      "Epoch 7155/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 2005694705.8368 - val_loss: 1967036900.1136\n",
      "Epoch 7156/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 272925678.8925 - val_loss: 722376675.5651\n",
      "Epoch 7157/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 119514393.1210 - val_loss: 776654526.7961\n",
      "Epoch 7158/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 260626146.4986 - val_loss: 885236684.5750\n",
      "Epoch 7159/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 167025105.4586 - val_loss: 823332512.7291\n",
      "Epoch 7160/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 127575587.3236 - val_loss: 1821650217.2444\n",
      "Epoch 7161/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 229690967.5633 - val_loss: 817569432.1373\n",
      "Epoch 7162/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 251699330.9533 - val_loss: 724974251.7108\n",
      "Epoch 7163/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 212600051.3945 - val_loss: 1386279140.7797\n",
      "Epoch 7164/10000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 603764938.8407 - val_loss: 704593938.9840\n",
      "Epoch 7165/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 143903523.9730 - val_loss: 738942562.2616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7166/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 158876617.8548 - val_loss: 712557488.5558\n",
      "Epoch 7167/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 324529240.4187 - val_loss: 1197546119.8830\n",
      "Epoch 7168/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1545341619.7546 - val_loss: 1466908270.7516\n",
      "Epoch 7169/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 275093297.8908 - val_loss: 724704663.5882\n",
      "Epoch 7170/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 110360700.9387 - val_loss: 1733130335.3429\n",
      "Epoch 7171/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 209350735.1666 - val_loss: 758785096.0068\n",
      "Epoch 7172/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 261998054.6089 - val_loss: 906371188.5187\n",
      "Epoch 7173/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 162148315.8247 - val_loss: 698521039.7333\n",
      "Epoch 7174/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 220619885.1097 - val_loss: 1448913244.9148\n",
      "Epoch 7175/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 447621162.8137 - val_loss: 692447108.2723\n",
      "Epoch 7176/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 304497815.7794 - val_loss: 748218438.9446\n",
      "Epoch 7177/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 217411610.5391 - val_loss: 1110231983.9865\n",
      "Epoch 7178/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 342658665.8773 - val_loss: 790891641.2129\n",
      "Epoch 7179/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 1796958876.2904 - val_loss: 1441498884.9058\n",
      "Epoch 7180/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 311098927.0276 - val_loss: 729784620.8990\n",
      "Epoch 7181/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 160250415.7141 - val_loss: 985524020.4062\n",
      "Epoch 7182/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 239274540.3534 - val_loss: 1560337485.8442\n",
      "Epoch 7183/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 385766761.3101 - val_loss: 1750398833.9488\n",
      "Epoch 7184/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 275339268.0923 - val_loss: 1452118213.7429\n",
      "Epoch 7185/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 187453656.0585 - val_loss: 1710049471.8380\n",
      "Epoch 7186/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 796545590.9375 - val_loss: 672131385.4942\n",
      "Epoch 7187/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 182187936.1981 - val_loss: 815167312.3105\n",
      "Epoch 7188/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 226295795.7727 - val_loss: 845706111.7435\n",
      "Epoch 7189/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 542600365.0467 - val_loss: 2660241733.4549\n",
      "Epoch 7190/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 296571635.9212 - val_loss: 675419888.4253\n",
      "Epoch 7191/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 117281200.0293 - val_loss: 723396946.8309\n",
      "Epoch 7192/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 393844849.9539 - val_loss: 885988891.8684\n",
      "Epoch 7193/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 274530458.6877 - val_loss: 888460494.4045\n",
      "Epoch 7194/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 274667454.6950 - val_loss: 783401021.7406\n",
      "Epoch 7195/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 272471885.7580 - val_loss: 1211316973.0475\n",
      "Epoch 7196/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 298924275.1559 - val_loss: 975690890.9142\n",
      "Epoch 7197/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 302344483.3675 - val_loss: 1239912590.5643\n",
      "Epoch 7198/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 597912537.8773 - val_loss: 872111609.0419\n",
      "Epoch 7199/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 342564546.3917 - val_loss: 1363302366.2177\n",
      "Epoch 7200/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 247720672.6303 - val_loss: 870029390.4023\n",
      "Epoch 7201/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 318209390.7124 - val_loss: 1563889074.6599\n",
      "Epoch 7202/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 588074662.2847 - val_loss: 3589515532.8360\n",
      "Epoch 7203/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 661613076.4209 - val_loss: 1426240197.8059\n",
      "Epoch 7204/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 487442932.5155 - val_loss: 913380262.7994\n",
      "Epoch 7205/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 467291286.2577 - val_loss: 2688835336.0563\n",
      "Epoch 7206/10000\n",
      "3554/3554 [==============================] - 0s 134us/step - loss: 1809258714.8858 - val_loss: 1302452047.1224\n",
      "Epoch 7207/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 230954993.4102 - val_loss: 717614412.9103\n",
      "Epoch 7208/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 102202207.8739 - val_loss: 1109826995.1370\n",
      "Epoch 7209/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 264657040.6843 - val_loss: 705390120.8214\n",
      "Epoch 7210/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 152607657.8244 - val_loss: 709911847.9842\n",
      "Epoch 7211/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 106698212.7001 - val_loss: 892149683.8323\n",
      "Epoch 7212/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 194278838.9690 - val_loss: 683716442.7162\n",
      "Epoch 7213/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 147537047.9865 - val_loss: 829790269.7868\n",
      "Epoch 7214/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 234855608.2926 - val_loss: 1183806604.7460\n",
      "Epoch 7215/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1449332319.0051 - val_loss: 1167874882.4754\n",
      "Epoch 7216/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 343986527.5183 - val_loss: 1455426240.0360\n",
      "Epoch 7217/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 146032678.6089 - val_loss: 1122910695.3361\n",
      "Epoch 7218/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 488969061.2673 - val_loss: 710241883.4633\n",
      "Epoch 7219/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 150062411.8402 - val_loss: 730181678.0377\n",
      "Epoch 7220/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 202267506.4266 - val_loss: 843390959.6039\n",
      "Epoch 7221/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 284341398.5729 - val_loss: 926516471.3294\n",
      "Epoch 7222/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 381597201.9730 - val_loss: 662582890.3066\n",
      "Epoch 7223/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 275979850.9668 - val_loss: 2539533060.1767\n",
      "Epoch 7224/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 817268787.3405 - val_loss: 994671382.7105\n",
      "Epoch 7225/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 250551584.8464 - val_loss: 1616969934.1412\n",
      "Epoch 7226/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 387953262.2442 - val_loss: 1027854324.8596\n",
      "Epoch 7227/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 214362485.8481 - val_loss: 703234776.2723\n",
      "Epoch 7228/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 350608654.6899 - val_loss: 916843760.6841\n",
      "Epoch 7229/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 196807264.9904 - val_loss: 1113732741.2703\n",
      "Epoch 7230/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 329459118.7034 - val_loss: 3370324385.1252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7231/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 798341975.9505 - val_loss: 788547535.1854\n",
      "Epoch 7232/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 173710250.6877 - val_loss: 1212230601.0554\n",
      "Epoch 7233/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 385620488.5718 - val_loss: 1067977582.3977\n",
      "Epoch 7234/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 244083619.7411 - val_loss: 1054404119.8222\n",
      "Epoch 7235/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 264304539.3360 - val_loss: 3216021936.7876\n",
      "Epoch 7236/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 567350107.0028 - val_loss: 955130626.8602\n",
      "Epoch 7237/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 220095245.8413 - val_loss: 688767902.5238\n",
      "Epoch 7238/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 203323287.5363 - val_loss: 2989420279.0346\n",
      "Epoch 7239/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 872450913.9809 - val_loss: 2556348242.0208\n",
      "Epoch 7240/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 699855569.2606 - val_loss: 1058848987.7828\n",
      "Epoch 7241/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 321895060.9612 - val_loss: 952807144.3623\n",
      "Epoch 7242/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 309063317.1593 - val_loss: 844675103.8110\n",
      "Epoch 7243/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 145833138.2375 - val_loss: 1596083415.3316\n",
      "Epoch 7244/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 402711960.0630 - val_loss: 700692049.4121\n",
      "Epoch 7245/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 301025945.0760 - val_loss: 796391569.2692\n",
      "Epoch 7246/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 188004482.2780 - val_loss: 738656403.2270\n",
      "Epoch 7247/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 180337413.0692 - val_loss: 660653946.9412\n",
      "Epoch 7248/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 188614638.2622 - val_loss: 3020982434.7454\n",
      "Epoch 7249/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 1051605662.0011 - val_loss: 835787115.6501\n",
      "Epoch 7250/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 328543081.8773 - val_loss: 754188379.8143\n",
      "Epoch 7251/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 459025368.5785 - val_loss: 1997568354.3674\n",
      "Epoch 7252/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 950963221.5374 - val_loss: 3401186415.9055\n",
      "Epoch 7253/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 478698578.9713 - val_loss: 740772404.8068\n",
      "Epoch 7254/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 124428560.0090 - val_loss: 1123188476.0574\n",
      "Epoch 7255/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 307860901.6365 - val_loss: 900999629.8892\n",
      "Epoch 7256/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 662451876.0878 - val_loss: 5406759610.9412\n",
      "Epoch 7257/10000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 907765614.7102 - val_loss: 1203388169.1454\n",
      "Epoch 7258/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 325956538.1733 - val_loss: 763869331.1482\n",
      "Epoch 7259/10000\n",
      "3554/3554 [==============================] - 0s 135us/step - loss: 122645248.6123 - val_loss: 3758968842.6577\n",
      "Epoch 7260/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 796007955.2144 - val_loss: 1904070751.8110\n",
      "Epoch 7261/10000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 297360301.5959 - val_loss: 699041651.4903\n",
      "Epoch 7262/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 954172128.0180 - val_loss: 1048657847.5342\n",
      "Epoch 7263/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 260184533.6995 - val_loss: 834008280.9519\n",
      "Epoch 7264/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 147583344.6213 - val_loss: 2272079632.9586\n",
      "Epoch 7265/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 1033199084.2634 - val_loss: 931981431.2506\n",
      "Epoch 7266/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 252294785.2245 - val_loss: 686506877.3581\n",
      "Epoch 7267/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 107949100.8846 - val_loss: 723297289.7080\n",
      "Epoch 7268/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 281972184.4367 - val_loss: 995531661.7181\n",
      "Epoch 7269/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 383793305.9539 - val_loss: 930780812.2284\n",
      "Epoch 7270/10000\n",
      "3554/3554 [==============================] - 1s 145us/step - loss: 183919681.1795 - val_loss: 1748162995.9561\n",
      "Epoch 7271/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 333756719.4688 - val_loss: 920732470.8546\n",
      "Epoch 7272/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 402842039.8360 - val_loss: 707053592.4613\n",
      "Epoch 7273/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 521202388.0968 - val_loss: 866777809.0346\n",
      "Epoch 7274/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 342652225.0535 - val_loss: 925986916.1677\n",
      "Epoch 7275/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 184810452.5256 - val_loss: 830058681.1634\n",
      "Epoch 7276/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 161569013.5318 - val_loss: 675008690.0028\n",
      "Epoch 7277/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 189016170.8588 - val_loss: 1784389306.3111\n",
      "Epoch 7278/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 338579460.3759 - val_loss: 4212741090.5474\n",
      "Epoch 7279/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 600026353.6972 - val_loss: 939445687.9527\n",
      "Epoch 7280/10000\n",
      "3554/3554 [==============================] - 0s 134us/step - loss: 307136577.9088 - val_loss: 826653685.5764\n",
      "Epoch 7281/10000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 733313368.9198 - val_loss: 788300990.6903\n",
      "Epoch 7282/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 266068942.0203 - val_loss: 763966030.6858\n",
      "Epoch 7283/10000\n",
      "3554/3554 [==============================] - 1s 159us/step - loss: 177441828.1148 - val_loss: 959739295.0549\n",
      "Epoch 7284/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 113569555.9527 - val_loss: 707922194.7460\n",
      "Epoch 7285/10000\n",
      "3554/3554 [==============================] - 1s 143us/step - loss: 154180617.2679 - val_loss: 652912414.9367\n",
      "Epoch 7286/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 253454540.8216 - val_loss: 929019475.8729\n",
      "Epoch 7287/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 222726149.6410 - val_loss: 707765282.7342\n",
      "Epoch 7288/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 3140432182.2217 - val_loss: 1323970678.3595\n",
      "Epoch 7289/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 298830809.8953 - val_loss: 697858179.7828\n",
      "Epoch 7290/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 141253617.7516 - val_loss: 653650728.4546\n",
      "Epoch 7291/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 78276168.7462 - val_loss: 723469968.9406\n",
      "Epoch 7292/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 117099841.5824 - val_loss: 694111472.8191\n",
      "Epoch 7293/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 90085650.0394 - val_loss: 690896703.0639\n",
      "Epoch 7294/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 294429515.8762 - val_loss: 1410230053.8329\n",
      "Epoch 7295/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 424365407.8604 - val_loss: 845609822.6858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7296/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 141823236.5245 - val_loss: 806099634.2414\n",
      "Epoch 7297/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 373150927.9550 - val_loss: 1428287797.5944\n",
      "Epoch 7298/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 559397950.1677 - val_loss: 1176109688.0068\n",
      "Epoch 7299/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 195578550.5549 - val_loss: 768809173.6169\n",
      "Epoch 7300/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 309416479.0636 - val_loss: 1674775514.7297\n",
      "Epoch 7301/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 268841854.2150 - val_loss: 649435373.2945\n",
      "Epoch 7302/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 175909602.1069 - val_loss: 904562054.4810\n",
      "Epoch 7303/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 745500061.6230 - val_loss: 818991549.5606\n",
      "Epoch 7304/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 174571283.4935 - val_loss: 1447667034.7342\n",
      "Epoch 7305/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 380359337.0017 - val_loss: 1558520057.1139\n",
      "Epoch 7306/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 277687117.6590 - val_loss: 749210935.2956\n",
      "Epoch 7307/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 180397756.5650 - val_loss: 816856415.3204\n",
      "Epoch 7308/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1124783958.4378 - val_loss: 4649384150.9176\n",
      "Epoch 7309/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 796416631.1401 - val_loss: 846103943.1876\n",
      "Epoch 7310/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 157991606.3950 - val_loss: 1552493776.2025\n",
      "Epoch 7311/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 175555276.0293 - val_loss: 751406323.3508\n",
      "Epoch 7312/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 108228463.8402 - val_loss: 677456841.1814\n",
      "Epoch 7313/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 137139866.8678 - val_loss: 1013751412.0821\n",
      "Epoch 7314/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 271332096.1936 - val_loss: 2481028757.7834\n",
      "Epoch 7315/10000\n",
      "3554/3554 [==============================] - 0s 132us/step - loss: 561757831.2392 - val_loss: 1401434863.2574\n",
      "Epoch 7316/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 321889333.7355 - val_loss: 1235021667.1359\n",
      "Epoch 7317/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 686510484.6156 - val_loss: 874033009.0217\n",
      "Epoch 7318/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 150261685.1232 - val_loss: 2764649295.1404\n",
      "Epoch 7319/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 670655837.9921 - val_loss: 675435053.5966\n",
      "Epoch 7320/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 223539292.8846 - val_loss: 1131962581.6844\n",
      "Epoch 7321/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 299235375.2167 - val_loss: 798625511.7496\n",
      "Epoch 7322/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 207385527.0028 - val_loss: 705548357.8295\n",
      "Epoch 7323/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 174874250.9848 - val_loss: 752836458.5001\n",
      "Epoch 7324/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 343139899.0793 - val_loss: 687493297.6518\n",
      "Epoch 7325/10000\n",
      "3554/3554 [==============================] - 0s 139us/step - loss: 137415992.4389 - val_loss: 654090513.7665\n",
      "Epoch 7326/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 143732741.3303 - val_loss: 1746512213.1893\n",
      "Epoch 7327/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 496117174.7079 - val_loss: 826199681.9308\n",
      "Epoch 7328/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 359514217.9584 - val_loss: 797215763.4385\n",
      "Epoch 7329/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 371258816.4052 - val_loss: 879365466.8242\n",
      "Epoch 7330/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 223785358.8025 - val_loss: 1178576770.7004\n",
      "Epoch 7331/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 482928872.2971 - val_loss: 1398663269.9319\n",
      "Epoch 7332/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 943186815.8739 - val_loss: 1563177972.9823\n",
      "Epoch 7333/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 337748884.7001 - val_loss: 1447350051.1955\n",
      "Epoch 7334/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 197718932.2881 - val_loss: 727081071.1167\n",
      "Epoch 7335/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 139375944.4277 - val_loss: 1135374412.9812\n",
      "Epoch 7336/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 332655569.7107 - val_loss: 799886822.0759\n",
      "Epoch 7337/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 218423860.2409 - val_loss: 1033790293.6574\n",
      "Epoch 7338/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 447469794.5751 - val_loss: 1047600388.4107\n",
      "Epoch 7339/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1185347586.3860 - val_loss: 727300488.4748\n",
      "Epoch 7340/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 280913104.7034 - val_loss: 790753376.7921\n",
      "Epoch 7341/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 113844812.3568 - val_loss: 685715130.9322\n",
      "Epoch 7342/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 125213993.4721 - val_loss: 1169734291.1190\n",
      "Epoch 7343/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 576860014.1972 - val_loss: 761734103.6596\n",
      "Epoch 7344/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 171714831.3889 - val_loss: 1219434511.7075\n",
      "Epoch 7345/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 809028545.4637 - val_loss: 798800063.6354\n",
      "Epoch 7346/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 129415376.8824 - val_loss: 911913279.9460\n",
      "Epoch 7347/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 226267546.3635 - val_loss: 1769295768.6278\n",
      "Epoch 7348/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1000336542.6359 - val_loss: 689213811.3755\n",
      "Epoch 7349/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 285614619.9482 - val_loss: 669180950.6903\n",
      "Epoch 7350/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 113608100.4660 - val_loss: 1275779274.5316\n",
      "Epoch 7351/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 133753610.1497 - val_loss: 715044127.4532\n",
      "Epoch 7352/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 464607408.0900 - val_loss: 925431650.6554\n",
      "Epoch 7353/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 341615248.4131 - val_loss: 736097383.8188\n",
      "Epoch 7354/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 125270409.9764 - val_loss: 942975317.5854\n",
      "Epoch 7355/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 373350414.0352 - val_loss: 683839580.6425\n",
      "Epoch 7356/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 440864087.1581 - val_loss: 1635266335.6669\n",
      "Epoch 7357/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 845512036.3399 - val_loss: 3438430630.7601\n",
      "Epoch 7358/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 535399287.5093 - val_loss: 1387119029.6844\n",
      "Epoch 7359/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 267045972.0608 - val_loss: 1314640344.5378\n",
      "Epoch 7360/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 456799842.5391 - val_loss: 862868871.2011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7361/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 275582980.0158 - val_loss: 892606114.3134\n",
      "Epoch 7362/10000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 414340632.290 - 0s 85us/step - loss: 411552092.9026 - val_loss: 794755892.3477\n",
      "Epoch 7363/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 176316870.1092 - val_loss: 701747005.9567\n",
      "Epoch 7364/10000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 152347391.137 - 0s 100us/step - loss: 151269387.0720 - val_loss: 780730381.3131\n",
      "Epoch 7365/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 245200353.5622 - val_loss: 754513944.0473\n",
      "Epoch 7366/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 154376555.4260 - val_loss: 695885478.6633\n",
      "Epoch 7367/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 127112094.3433 - val_loss: 1234626747.3013\n",
      "Epoch 7368/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 577756678.6989 - val_loss: 1761474124.3184\n",
      "Epoch 7369/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 296667482.7957 - val_loss: 3359815005.4166\n",
      "Epoch 7370/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 495235563.6871 - val_loss: 2180408088.4208\n",
      "Epoch 7371/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 699836533.1052 - val_loss: 1080017914.2211\n",
      "Epoch 7372/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 518807795.4035 - val_loss: 960248859.9494\n",
      "Epoch 7373/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 299721814.4738 - val_loss: 1139461320.2993\n",
      "Epoch 7374/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 215108639.8379 - val_loss: 1123358291.1010\n",
      "Epoch 7375/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 189941206.8385 - val_loss: 657126870.1030\n",
      "Epoch 7376/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 681816719.8829 - val_loss: 3617840545.2962\n",
      "Epoch 7377/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1070855100.4569 - val_loss: 1486527795.0380\n",
      "Epoch 7378/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 225342212.3680 - val_loss: 938699896.3803\n",
      "Epoch 7379/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 137124738.3140 - val_loss: 793819133.7316\n",
      "Epoch 7380/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 249437699.6016 - val_loss: 8151686257.8498\n",
      "Epoch 7381/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1216218807.5273 - val_loss: 853754904.9778\n",
      "Epoch 7382/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 183356826.0867 - val_loss: 882566843.0042\n",
      "Epoch 7383/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 122951063.7074 - val_loss: 686762960.4906\n",
      "Epoch 7384/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 151650456.4097 - val_loss: 756170943.3204\n",
      "Epoch 7385/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 251718942.4142 - val_loss: 875658682.0793\n",
      "Epoch 7386/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 106812757.0197 - val_loss: 988885069.1241\n",
      "Epoch 7387/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 178680649.4721 - val_loss: 1663691582.6318\n",
      "Epoch 7388/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 530059196.8936 - val_loss: 943923024.2565\n",
      "Epoch 7389/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 604585155.6376 - val_loss: 17941846933.7114\n",
      "Epoch 7390/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 2457435163.1806 - val_loss: 1049129153.4987\n",
      "Epoch 7391/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 139637804.5177 - val_loss: 677737861.9702\n",
      "Epoch 7392/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 124956171.5611 - val_loss: 664145254.8276\n",
      "Epoch 7393/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 124479999.5903 - val_loss: 659271301.5629\n",
      "Epoch 7394/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 331031599.3247 - val_loss: 1412221247.8020\n",
      "Epoch 7395/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 886500622.6944 - val_loss: 2670232582.2830\n",
      "Epoch 7396/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 593996621.1638 - val_loss: 1147678408.3173\n",
      "Epoch 7397/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 201265006.4423 - val_loss: 831191641.9826\n",
      "Epoch 7398/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 261856524.7856 - val_loss: 676168235.9156\n",
      "Epoch 7399/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 171364010.2757 - val_loss: 865201431.5567\n",
      "Epoch 7400/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 192782691.2684 - val_loss: 1075815537.1972\n",
      "Epoch 7401/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 222868221.4249 - val_loss: 924615759.7930\n",
      "Epoch 7402/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 213088905.4091 - val_loss: 866910961.5527\n",
      "Epoch 7403/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 253118465.4766 - val_loss: 1161233243.0042\n",
      "Epoch 7404/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 224540341.6005 - val_loss: 1088690209.0149\n",
      "Epoch 7405/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 243986992.9454 - val_loss: 691804039.3406\n",
      "Epoch 7406/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 180981024.9364 - val_loss: 679521704.0383\n",
      "Epoch 7407/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 164253350.7935 - val_loss: 865232862.5238\n",
      "Epoch 7408/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 221940697.1075 - val_loss: 1166742614.1795\n",
      "Epoch 7409/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 590912963.2684 - val_loss: 1989930885.0408\n",
      "Epoch 7410/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 587218147.0343 - val_loss: 978078879.5949\n",
      "Epoch 7411/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 170809883.4080 - val_loss: 2126658318.8343\n",
      "Epoch 7412/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1053526877.1953 - val_loss: 4465929784.2048\n",
      "Epoch 7413/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 446509928.0495 - val_loss: 687747761.8745\n",
      "Epoch 7414/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 385720664.2296 - val_loss: 714089733.6439\n",
      "Epoch 7415/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 163229438.9420 - val_loss: 803267669.9342\n",
      "Epoch 7416/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 169649137.1615 - val_loss: 1004041271.4487\n",
      "Epoch 7417/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 260893416.7473 - val_loss: 752952474.2436\n",
      "Epoch 7418/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 185524813.4249 - val_loss: 885159474.5969\n",
      "Epoch 7419/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 303963992.0734 - val_loss: 1375919210.8782\n",
      "Epoch 7420/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 167284905.2268 - val_loss: 741125982.6678\n",
      "Epoch 7421/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 564997162.4446 - val_loss: 993331357.6146\n",
      "Epoch 7422/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 781722049.3506 - val_loss: 2823453468.1834\n",
      "Epoch 7423/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 486746498.3050 - val_loss: 691313533.5077\n",
      "Epoch 7424/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 111140452.3391 - val_loss: 681023137.5302\n",
      "Epoch 7425/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 135248504.6438 - val_loss: 886661961.5865\n",
      "Epoch 7426/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 160688921.5678 - val_loss: 670327036.8225\n",
      "Epoch 7427/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 210538893.2178 - val_loss: 747385656.1823\n",
      "Epoch 7428/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 198434818.2870 - val_loss: 905760876.7190\n",
      "Epoch 7429/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 315302259.9707 - val_loss: 4358388996.9328\n",
      "Epoch 7430/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1948425473.6567 - val_loss: 4104969894.0940\n",
      "Epoch 7431/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 686201614.1002 - val_loss: 945849698.2774\n",
      "Epoch 7432/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 211213707.1829 - val_loss: 738678964.5502\n",
      "Epoch 7433/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 200722244.2724 - val_loss: 766783075.4835\n",
      "Epoch 7434/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 118990728.3016 - val_loss: 692403415.6197\n",
      "Epoch 7435/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 93439453.6415 - val_loss: 702597885.1758\n",
      "Epoch 7436/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 494412180.7901 - val_loss: 1270807342.8253\n",
      "Epoch 7437/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 167935546.1654 - val_loss: 738804505.8475\n",
      "Epoch 7438/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 158708464.1621 - val_loss: 1064503418.6082\n",
      "Epoch 7439/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 273609664.8284 - val_loss: 6498283633.2017\n",
      "Epoch 7440/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 946382328.6348 - val_loss: 1227220259.7266\n",
      "Epoch 7441/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 310155714.0529 - val_loss: 1943371720.6954\n",
      "Epoch 7442/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 770985235.2324 - val_loss: 2074465932.9980\n",
      "Epoch 7443/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 591412467.1941 - val_loss: 804982396.7415\n",
      "Epoch 7444/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 170202369.6747 - val_loss: 1137790645.5944\n",
      "Epoch 7445/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 142706266.0079 - val_loss: 904790211.7266\n",
      "Epoch 7446/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 190198323.3838 - val_loss: 668326013.8802\n",
      "Epoch 7447/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 139687858.4536 - val_loss: 1843487820.8900\n",
      "Epoch 7448/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 306474855.2752 - val_loss: 935356014.3572\n",
      "Epoch 7449/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 269873354.5886 - val_loss: 965649527.2146\n",
      "Epoch 7450/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 793089983.8199 - val_loss: 2099804496.9767\n",
      "Epoch 7451/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 470241503.7614 - val_loss: 1275163977.1364\n",
      "Epoch 7452/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 884736637.2088 - val_loss: 911588088.9519\n",
      "Epoch 7453/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 216126083.6916 - val_loss: 710549765.3198\n",
      "Epoch 7454/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 160005893.6185 - val_loss: 710408538.2571\n",
      "Epoch 7455/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 255878177.7468 - val_loss: 1402316236.1069\n",
      "Epoch 7456/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 490346656.0450 - val_loss: 880346697.0104\n",
      "Epoch 7457/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 262059232.3782 - val_loss: 735608940.9170\n",
      "Epoch 7458/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 679527725.2358 - val_loss: 2365437641.2714\n",
      "Epoch 7459/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 489623818.2825 - val_loss: 665087858.5069\n",
      "Epoch 7460/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 130171117.5239 - val_loss: 5540686718.4878\n",
      "Epoch 7461/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 2252393759.7659 - val_loss: 1250672652.1699\n",
      "Epoch 7462/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 311234700.9600 - val_loss: 766656694.9896\n",
      "Epoch 7463/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 142374621.5959 - val_loss: 692703144.6121\n",
      "Epoch 7464/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 139829173.0152 - val_loss: 665895378.4574\n",
      "Epoch 7465/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 144067397.4676 - val_loss: 782196183.6512\n",
      "Epoch 7466/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 148445206.6269 - val_loss: 732909924.8788\n",
      "Epoch 7467/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 135916955.1041 - val_loss: 1061744019.9111\n",
      "Epoch 7468/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 233518767.4328 - val_loss: 1619958752.7651\n",
      "Epoch 7469/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 348213380.9882 - val_loss: 902831224.8529\n",
      "Epoch 7470/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 213112550.2577 - val_loss: 767625495.8537\n",
      "Epoch 7471/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 351830995.3945 - val_loss: 800964090.9997\n",
      "Epoch 7472/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 235114047.7209 - val_loss: 1842293494.9266\n",
      "Epoch 7473/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 369629566.1632 - val_loss: 1616980320.8011\n",
      "Epoch 7474/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 712715639.3382 - val_loss: 774577609.3896\n",
      "Epoch 7475/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 155218570.0574 - val_loss: 1087738305.8723\n",
      "Epoch 7476/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1178954133.9696 - val_loss: 1920264240.1395\n",
      "Epoch 7477/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 280568619.0433 - val_loss: 769991279.8155\n",
      "Epoch 7478/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 88228548.3129 - val_loss: 943895687.3992\n",
      "Epoch 7479/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 174047549.0557 - val_loss: 1368639025.2557\n",
      "Epoch 7480/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 181976688.5380 - val_loss: 776126528.5288\n",
      "Epoch 7481/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 157431277.7513 - val_loss: 1306599800.2228\n",
      "Epoch 7482/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 571777629.3168 - val_loss: 2276530516.4332\n",
      "Epoch 7483/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 2284709736.9859 - val_loss: 1553611587.8526\n",
      "Epoch 7484/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 245774305.3191 - val_loss: 823657981.1781\n",
      "Epoch 7485/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 159308894.4333 - val_loss: 1924916188.3904\n",
      "Epoch 7486/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 217473223.9932 - val_loss: 680482054.1592\n",
      "Epoch 7487/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 133449174.7440 - val_loss: 737727600.0675\n",
      "Epoch 7488/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 88085613.7321 - val_loss: 658612203.9089\n",
      "Epoch 7489/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 594770811.9302 - val_loss: 936392352.8191\n",
      "Epoch 7490/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 93us/step - loss: 372632062.2352 - val_loss: 2364707408.5446\n",
      "Epoch 7491/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 510948859.9899 - val_loss: 719612307.5871\n",
      "Epoch 7492/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 144090890.6134 - val_loss: 738294643.0380\n",
      "Epoch 7493/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 158779933.2718 - val_loss: 753231357.3086\n",
      "Epoch 7494/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 148377575.0411 - val_loss: 675389162.0636\n",
      "Epoch 7495/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 190236727.8965 - val_loss: 920279482.8242\n",
      "Epoch 7496/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 535007960.1981 - val_loss: 1050675093.5314\n",
      "Epoch 7497/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 284148664.5763 - val_loss: 1066026430.9288\n",
      "Epoch 7498/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 240787747.4913 - val_loss: 694531327.3744\n",
      "Epoch 7499/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 188841208.8734 - val_loss: 743070903.3361\n",
      "Epoch 7500/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 183439795.0929 - val_loss: 809575648.1710\n",
      "Epoch 7501/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 224713930.1024 - val_loss: 2204223107.4925\n",
      "Epoch 7502/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 292536506.2893 - val_loss: 913274143.5927\n",
      "Epoch 7503/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 598654712.6348 - val_loss: 822833051.4385\n",
      "Epoch 7504/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 616556960.5582 - val_loss: 6269078618.7342\n",
      "Epoch 7505/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1751098475.0298 - val_loss: 784065372.9125\n",
      "Epoch 7506/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 135255670.6984 - val_loss: 1267080035.8526\n",
      "Epoch 7507/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 212441862.3568 - val_loss: 771421382.3190\n",
      "Epoch 7508/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 161551366.6899 - val_loss: 685766574.6374\n",
      "Epoch 7509/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 158575482.1474 - val_loss: 826628078.6093\n",
      "Epoch 7510/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 89613598.4513 - val_loss: 1087519060.6222\n",
      "Epoch 7511/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 177641835.2099 - val_loss: 939376973.4166\n",
      "Epoch 7512/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 374077166.2802 - val_loss: 1277639435.2383\n",
      "Epoch 7513/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 591848219.1199 - val_loss: 920616648.9204\n",
      "Epoch 7514/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 277210174.3523 - val_loss: 1049748084.4332\n",
      "Epoch 7515/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 294583051.0748 - val_loss: 855588923.2833\n",
      "Epoch 7516/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 383050900.6370 - val_loss: 1342412862.4698\n",
      "Epoch 7517/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 986872114.4204 - val_loss: 1241512603.8323\n",
      "Epoch 7518/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 272696969.9764 - val_loss: 642843585.1747\n",
      "Epoch 7519/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 144124734.2555 - val_loss: 712493213.5066\n",
      "Epoch 7520/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 149416909.7220 - val_loss: 883137924.9868\n",
      "Epoch 7521/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 206701694.7304 - val_loss: 1391306134.1435\n",
      "Epoch 7522/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 534847535.5588 - val_loss: 1493191791.2934\n",
      "Epoch 7523/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 358389169.4136 - val_loss: 889010641.7148\n",
      "Epoch 7524/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 456201148.7091 - val_loss: 1404119527.9662\n",
      "Epoch 7525/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 320661470.8295 - val_loss: 1063643964.4354\n",
      "Epoch 7526/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 154323982.8025 - val_loss: 776535822.5958\n",
      "Epoch 7527/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 263964218.1846 - val_loss: 917319368.0158\n",
      "Epoch 7528/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 360333927.1311 - val_loss: 2085584105.3165\n",
      "Epoch 7529/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 905849365.1052 - val_loss: 929133604.7347\n",
      "Epoch 7530/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 364444864.5582 - val_loss: 957624000.6841\n",
      "Epoch 7531/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1049733903.5318 - val_loss: 805600521.7755\n",
      "Epoch 7532/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 143815659.3270 - val_loss: 852318330.0996\n",
      "Epoch 7533/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 228706203.6646 - val_loss: 1034433630.6970\n",
      "Epoch 7534/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 154250988.4885 - val_loss: 847403877.2073\n",
      "Epoch 7535/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 162374162.0259 - val_loss: 711880130.3876\n",
      "Epoch 7536/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 136773135.4890 - val_loss: 741916244.7561\n",
      "Epoch 7537/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 136804139.2369 - val_loss: 3888012568.6999\n",
      "Epoch 7538/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1842955332.1418 - val_loss: 3768641695.2889\n",
      "Epoch 7539/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 935143468.4164 - val_loss: 1172896092.5480\n",
      "Epoch 7540/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 170487119.6579 - val_loss: 1072430654.3797\n",
      "Epoch 7541/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 141911456.4592 - val_loss: 781429289.6675\n",
      "Epoch 7542/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 108373455.8154 - val_loss: 827389760.7359\n",
      "Epoch 7543/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 167978992.8779 - val_loss: 940841581.9432\n",
      "Epoch 7544/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 150015737.8503 - val_loss: 719868998.2245\n",
      "Epoch 7545/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 229027835.8042 - val_loss: 1103720925.3491\n",
      "Epoch 7546/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 215900491.5070 - val_loss: 1136639071.5364\n",
      "Epoch 7547/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 348114935.8424 - val_loss: 1228565402.8062\n",
      "Epoch 7548/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 274856304.7293 - val_loss: 849225369.6630\n",
      "Epoch 7549/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 221262089.4046 - val_loss: 699307122.8399\n",
      "Epoch 7550/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 317673155.7591 - val_loss: 1055360470.8051\n",
      "Epoch 7551/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 205283052.1553 - val_loss: 2012065403.7153\n",
      "Epoch 7552/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 662916230.9150 - val_loss: 773406715.8774\n",
      "Epoch 7553/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 225965878.4108 - val_loss: 705941447.2551\n",
      "Epoch 7554/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 275998738.5481 - val_loss: 1072141397.7114\n",
      "Epoch 7555/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 285300161.7107 - val_loss: 1320949818.0141\n",
      "Epoch 7556/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 730990946.4671 - val_loss: 1512337203.6321\n",
      "Epoch 7557/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 237698719.9122 - val_loss: 916230906.0231\n",
      "Epoch 7558/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 142403716.7181 - val_loss: 772180972.3049\n",
      "Epoch 7559/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 324453133.4541 - val_loss: 966363210.7927\n",
      "Epoch 7560/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 384623045.2853 - val_loss: 1327538165.9544\n",
      "Epoch 7561/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 212076381.5329 - val_loss: 675478428.6065\n",
      "Epoch 7562/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 248399198.1688 - val_loss: 782004844.8788\n",
      "Epoch 7563/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 130107387.9122 - val_loss: 1127557507.4025\n",
      "Epoch 7564/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 445060064.8464 - val_loss: 998456912.3015\n",
      "Epoch 7565/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 369297362.2060 - val_loss: 996583384.3398\n",
      "Epoch 7566/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 348478193.1255 - val_loss: 1221148464.6256\n",
      "Epoch 7567/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 438680473.0129 - val_loss: 696633055.8414\n",
      "Epoch 7568/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 454314645.5039 - val_loss: 1093140930.4124\n",
      "Epoch 7569/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 414823551.6939 - val_loss: 747803403.3058\n",
      "Epoch 7570/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 260282739.6151 - val_loss: 730396557.0970\n",
      "Epoch 7571/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 193518484.1193 - val_loss: 659801721.7890\n",
      "Epoch 7572/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 220903445.3393 - val_loss: 806811264.5581\n",
      "Epoch 7573/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 692041722.1317 - val_loss: 816951726.8903\n",
      "Epoch 7574/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 274372300.7901 - val_loss: 729510993.3030\n",
      "Epoch 7575/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 183821405.6230 - val_loss: 914411653.3288\n",
      "Epoch 7576/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 153282362.2780 - val_loss: 659358573.4515\n",
      "Epoch 7577/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 198808881.6657 - val_loss: 938867686.9311\n",
      "Epoch 7578/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 608740730.7417 - val_loss: 992152300.4669\n",
      "Epoch 7579/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 659631690.3770 - val_loss: 1298826885.3648\n",
      "Epoch 7580/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 169998280.9522 - val_loss: 700447402.3876\n",
      "Epoch 7581/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 148904390.6269 - val_loss: 2198958875.0672\n",
      "Epoch 7582/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 942825349.9336 - val_loss: 856744623.9235\n",
      "Epoch 7583/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 440765889.8728 - val_loss: 1093738805.7204\n",
      "Epoch 7584/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 310478661.2403 - val_loss: 876459256.6008\n",
      "Epoch 7585/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 407784016.7113 - val_loss: 2586817799.0481\n",
      "Epoch 7586/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 487443887.5858 - val_loss: 740612311.8267\n",
      "Epoch 7587/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 112153683.5115 - val_loss: 869554005.6473\n",
      "Epoch 7588/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 291709369.9854 - val_loss: 765985187.5826\n",
      "Epoch 7589/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 333466521.0985 - val_loss: 1345582400.7449\n",
      "Epoch 7590/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 786742475.2777 - val_loss: 1093257073.3007\n",
      "Epoch 7591/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 144220536.8194 - val_loss: 725375791.4239\n",
      "Epoch 7592/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 110332150.0957 - val_loss: 691661659.9471\n",
      "Epoch 7593/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 276599776.4524 - val_loss: 856155178.0388\n",
      "Epoch 7594/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 194319134.3343 - val_loss: 780582098.5114\n",
      "Epoch 7595/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 131240595.5926 - val_loss: 1184178812.2284\n",
      "Epoch 7596/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 256210246.0867 - val_loss: 1007577897.5775\n",
      "Epoch 7597/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 304525507.1874 - val_loss: 1545615474.8309\n",
      "Epoch 7598/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 628480695.4102 - val_loss: 963035251.5871\n",
      "Epoch 7599/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 534693687.8514 - val_loss: 1994884631.6197\n",
      "Epoch 7600/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 876497044.4930 - val_loss: 764375640.4017\n",
      "Epoch 7601/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 632227200.6843 - val_loss: 941714525.6776\n",
      "Epoch 7602/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 203460890.6697 - val_loss: 815420867.3935\n",
      "Epoch 7603/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 148774315.5385 - val_loss: 785077253.7609\n",
      "Epoch 7604/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 199206734.2893 - val_loss: 1049968197.9004\n",
      "Epoch 7605/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 145086036.6190 - val_loss: 723546681.9421\n",
      "Epoch 7606/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 135458665.6027 - val_loss: 709747821.7496\n",
      "Epoch 7607/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 260036916.5338 - val_loss: 660983024.5266\n",
      "Epoch 7608/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 281669322.3095 - val_loss: 3883212586.2706\n",
      "Epoch 7609/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1084426433.1953 - val_loss: 792770925.7001\n",
      "Epoch 7610/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 450705832.9859 - val_loss: 1135749795.2180\n",
      "Epoch 7611/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 449243679.4598 - val_loss: 703203107.3935\n",
      "Epoch 7612/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 131127425.5658 - val_loss: 740143515.3778\n",
      "Epoch 7613/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 166762175.9190 - val_loss: 1457573983.3429\n",
      "Epoch 7614/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 585681633.5993 - val_loss: 764569755.1752\n",
      "Epoch 7615/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 147566864.3331 - val_loss: 677875690.9277\n",
      "Epoch 7616/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 114026734.6404 - val_loss: 786623218.9615\n",
      "Epoch 7617/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 329904546.7192 - val_loss: 1121745781.8464\n",
      "Epoch 7618/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 158197480.5571 - val_loss: 849073486.5440\n",
      "Epoch 7619/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 329459909.4384 - val_loss: 874310513.2917\n",
      "Epoch 7620/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 89us/step - loss: 2042852130.4311 - val_loss: 2695289741.8622\n",
      "Epoch 7621/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 2004742181.0242 - val_loss: 2760684585.4425\n",
      "Epoch 7622/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 435577656.1283 - val_loss: 666919987.1977\n",
      "Epoch 7623/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 96962427.7727 - val_loss: 722831327.2484\n",
      "Epoch 7624/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 108410788.8081 - val_loss: 701208758.2065\n",
      "Epoch 7625/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 75268725.5374 - val_loss: 717711965.4301\n",
      "Epoch 7626/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 189793909.2313 - val_loss: 1313447588.7617\n",
      "Epoch 7627/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 189179180.8948 - val_loss: 792790203.4813\n",
      "Epoch 7628/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 146308528.1351 - val_loss: 1125170375.9662\n",
      "Epoch 7629/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 226570546.6292 - val_loss: 688815305.3885\n",
      "Epoch 7630/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 203456081.7625 - val_loss: 919981241.2219\n",
      "Epoch 7631/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 197736014.0664 - val_loss: 749452425.8115\n",
      "Epoch 7632/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 275315402.8531 - val_loss: 1593293700.7077\n",
      "Epoch 7633/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2254225445.3123 - val_loss: 1098380799.1179\n",
      "Epoch 7634/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 512229127.5993 - val_loss: 1754149488.1845\n",
      "Epoch 7635/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 426913917.9133 - val_loss: 800415871.3339\n",
      "Epoch 7636/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 102991738.7338 - val_loss: 715577088.7156\n",
      "Epoch 7637/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 104533857.3776 - val_loss: 673607657.8217\n",
      "Epoch 7638/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 106043039.8829 - val_loss: 634998121.2827\n",
      "Epoch 7639/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 119564198.1947 - val_loss: 681011227.9044\n",
      "Epoch 7640/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 129423987.4755 - val_loss: 711227470.1075\n",
      "Epoch 7641/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 419216379.0298 - val_loss: 5361111500.4039\n",
      "Epoch 7642/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2361933405.8751 - val_loss: 715773956.7302\n",
      "Epoch 7643/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 171135233.1975 - val_loss: 719576315.4678\n",
      "Epoch 7644/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 147057649.0084 - val_loss: 941740217.2309\n",
      "Epoch 7645/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 193888631.1941 - val_loss: 1926415164.6245\n",
      "Epoch 7646/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 298245743.0006 - val_loss: 705403781.2343\n",
      "Epoch 7647/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 164757791.3697 - val_loss: 1432936311.8897\n",
      "Epoch 7648/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 582921040.2431 - val_loss: 5669518527.2619\n",
      "Epoch 7649/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2146368613.4789 - val_loss: 739361725.1556\n",
      "Epoch 7650/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 98876980.5650 - val_loss: 803791001.9691\n",
      "Epoch 7651/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 156156871.8334 - val_loss: 708351228.3724\n",
      "Epoch 7652/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 95662164.2701 - val_loss: 652022311.0661\n",
      "Epoch 7653/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 95736793.1210 - val_loss: 846582392.9159\n",
      "Epoch 7654/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 632467727.5869 - val_loss: 682799004.2003\n",
      "Epoch 7655/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 142638790.3298 - val_loss: 1686037585.3052\n",
      "Epoch 7656/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 263049297.6927 - val_loss: 658177146.7274\n",
      "Epoch 7657/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 136346988.0113 - val_loss: 785843328.2363\n",
      "Epoch 7658/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 183681117.7130 - val_loss: 682698674.1918\n",
      "Epoch 7659/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 116594818.0070 - val_loss: 688678708.5840\n",
      "Epoch 7660/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 524328146.7642 - val_loss: 1117557733.5269\n",
      "Epoch 7661/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 359617382.4288 - val_loss: 1577325419.6928\n",
      "Epoch 7662/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1688600402.3680 - val_loss: 1815249042.8669\n",
      "Epoch 7663/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 590846563.4035 - val_loss: 883882578.7049\n",
      "Epoch 7664/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 216547780.2589 - val_loss: 738358212.2667\n",
      "Epoch 7665/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 136999195.1199 - val_loss: 2528630220.4940\n",
      "Epoch 7666/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 400386521.2831 - val_loss: 1067481077.7609\n",
      "Epoch 7667/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 236486597.5104 - val_loss: 1056477020.5705\n",
      "Epoch 7668/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 291088889.8154 - val_loss: 905102727.2079\n",
      "Epoch 7669/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 126087282.1429 - val_loss: 702193420.9958\n",
      "Epoch 7670/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 90770851.4395 - val_loss: 660298145.1229\n",
      "Epoch 7671/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 264766935.5138 - val_loss: 1168147967.0594\n",
      "Epoch 7672/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 857305171.9887 - val_loss: 5183913442.5474\n",
      "Epoch 7673/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 978179854.6314 - val_loss: 867973117.3626\n",
      "Epoch 7674/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 158074880.9364 - val_loss: 2036974392.3848\n",
      "Epoch 7675/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 271194856.9769 - val_loss: 860030989.2321\n",
      "Epoch 7676/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 122243784.3022 - val_loss: 757373274.3156\n",
      "Epoch 7677/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 168961316.3039 - val_loss: 1040313007.0954\n",
      "Epoch 7678/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 218396856.6888 - val_loss: 2576054029.6821\n",
      "Epoch 7679/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 734981509.4204 - val_loss: 1333063869.7496\n",
      "Epoch 7680/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 367447906.4311 - val_loss: 971871995.5893\n",
      "Epoch 7681/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 392606816.0653 - val_loss: 676581976.9069\n",
      "Epoch 7682/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 221308288.3917 - val_loss: 1203455912.6053\n",
      "Epoch 7683/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 213555825.0535 - val_loss: 2898838848.2430\n",
      "Epoch 7684/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 707519809.2696 - val_loss: 903438934.1210\n",
      "Epoch 7685/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 167587432.2296 - val_loss: 911786645.8014\n",
      "Epoch 7686/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 617768279.7704 - val_loss: 965957578.7117\n",
      "Epoch 7687/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 181803680.1576 - val_loss: 829746728.6864\n",
      "Epoch 7688/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 127945224.7878 - val_loss: 5909808990.9108\n",
      "Epoch 7689/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 624361315.8357 - val_loss: 2978022451.9201\n",
      "Epoch 7690/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 1338020183.0861 - val_loss: 958462335.3159\n",
      "Epoch 7691/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 284762222.1716 - val_loss: 1149723565.0430\n",
      "Epoch 7692/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 261087070.3883 - val_loss: 1738364967.5792\n",
      "Epoch 7693/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 340985731.6556 - val_loss: 777178370.0996\n",
      "Epoch 7694/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 166141961.1885 - val_loss: 672428098.6824\n",
      "Epoch 7695/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 242633078.7980 - val_loss: 805840508.2194\n",
      "Epoch 7696/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 325857205.0692 - val_loss: 1051355164.2374\n",
      "Epoch 7697/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 236587964.7766 - val_loss: 818591170.1558\n",
      "Epoch 7698/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 187103440.1171 - val_loss: 705895480.6256\n",
      "Epoch 7699/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 393942394.5121 - val_loss: 1705797281.5820\n",
      "Epoch 7700/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 521492880.2071 - val_loss: 802976836.6357\n",
      "Epoch 7701/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 252411646.2082 - val_loss: 2806442522.9142\n",
      "Epoch 7702/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 607822239.6579 - val_loss: 1737650064.0900\n",
      "Epoch 7703/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 892960770.7462 - val_loss: 940147485.5617\n",
      "Epoch 7704/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 941617146.3095 - val_loss: 2534872026.3381\n",
      "Epoch 7705/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 480883162.3455 - val_loss: 736388904.6779\n",
      "Epoch 7706/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 141442324.1666 - val_loss: 709739515.7131\n",
      "Epoch 7707/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 106547107.2279 - val_loss: 748197513.9882\n",
      "Epoch 7708/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 127139343.7952 - val_loss: 956627059.4340\n",
      "Epoch 7709/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 106993743.8244 - val_loss: 813226629.5758\n",
      "Epoch 7710/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 171988268.2769 - val_loss: 770642005.1173\n",
      "Epoch 7711/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 146203145.8683 - val_loss: 766632424.1328\n",
      "Epoch 7712/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 174597213.4249 - val_loss: 730496634.7049\n",
      "Epoch 7713/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 265089034.5526 - val_loss: 1010168281.0509\n",
      "Epoch 7714/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 317196620.1013 - val_loss: 1296928691.4520\n",
      "Epoch 7715/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 340095868.8891 - val_loss: 976899834.8872\n",
      "Epoch 7716/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 755369872.2431 - val_loss: 1197444645.6034\n",
      "Epoch 7717/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 920939162.0574 - val_loss: 962613959.1696\n",
      "Epoch 7718/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 391911310.8385 - val_loss: 803847344.9356\n",
      "Epoch 7719/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 304982408.5087 - val_loss: 1176741707.6298\n",
      "Epoch 7720/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 271805778.5571 - val_loss: 772329998.2717\n",
      "Epoch 7721/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 398470802.6359 - val_loss: 669616865.1747\n",
      "Epoch 7722/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 165880525.2946 - val_loss: 799112859.1212\n",
      "Epoch 7723/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 177184063.9010 - val_loss: 1383764044.4940\n",
      "Epoch 7724/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 247003004.7361 - val_loss: 1114154664.2948\n",
      "Epoch 7725/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 159837598.7226 - val_loss: 758560193.1432\n",
      "Epoch 7726/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 812707467.4890 - val_loss: 1071088675.6096\n",
      "Epoch 7727/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 954557637.9786 - val_loss: 1892770422.8501\n",
      "Epoch 7728/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 438118041.6612 - val_loss: 641318421.1218\n",
      "Epoch 7729/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 109057921.7288 - val_loss: 888166926.3505\n",
      "Epoch 7730/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 245458147.7603 - val_loss: 1114856295.9617\n",
      "Epoch 7731/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 107005061.1277 - val_loss: 1029056761.4830\n",
      "Epoch 7732/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 432734184.2792 - val_loss: 825120046.9986\n",
      "Epoch 7733/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 208254037.3123 - val_loss: 770191012.5412\n",
      "Epoch 7734/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 375579800.5267 - val_loss: 2671951409.3997\n",
      "Epoch 7735/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1409034517.5014 - val_loss: 3172318674.5789\n",
      "Epoch 7736/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 326846018.9364 - val_loss: 919312785.4717\n",
      "Epoch 7737/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 149360992.4502 - val_loss: 1335393048.1418\n",
      "Epoch 7738/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 139584865.1345 - val_loss: 656847214.8973\n",
      "Epoch 7739/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 93786033.1975 - val_loss: 855655509.3153\n",
      "Epoch 7740/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 248290015.4192 - val_loss: 716887705.2534\n",
      "Epoch 7741/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 251006092.1418 - val_loss: 5906522867.3980\n",
      "Epoch 7742/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 733515421.1840 - val_loss: 1317278669.9522\n",
      "Epoch 7743/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 293175500.6573 - val_loss: 696290380.3859\n",
      "Epoch 7744/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 150778171.9302 - val_loss: 2144557717.5314\n",
      "Epoch 7745/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 897262648.7248 - val_loss: 1600301559.2911\n",
      "Epoch 7746/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 729769337.0715 - val_loss: 733601000.1913\n",
      "Epoch 7747/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 128667709.2718 - val_loss: 895934293.8014\n",
      "Epoch 7748/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 208504376.8329 - val_loss: 1113809014.9086\n",
      "Epoch 7749/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 157977994.9634 - val_loss: 827298585.1319\n",
      "Epoch 7750/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 102us/step - loss: 251782077.6950 - val_loss: 2431449421.3671\n",
      "Epoch 7751/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 619786885.0512 - val_loss: 803653881.1769\n",
      "Epoch 7752/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 583565150.2465 - val_loss: 1558124571.1842\n",
      "Epoch 7753/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 188497661.7310 - val_loss: 816414217.6495\n",
      "Epoch 7754/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 149523020.8576 - val_loss: 674092004.0709\n",
      "Epoch 7755/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 132664280.7698 - val_loss: 652296922.5091\n",
      "Epoch 7756/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 245257061.1187 - val_loss: 1249743785.5685\n",
      "Epoch 7757/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 313410694.1047 - val_loss: 2670034743.6647\n",
      "Epoch 7758/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 854822798.8385 - val_loss: 844317267.6726\n",
      "Epoch 7759/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 454966444.6550 - val_loss: 823127725.5921\n",
      "Epoch 7760/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 184675838.7383 - val_loss: 1464582794.1896\n",
      "Epoch 7761/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 237342817.0985 - val_loss: 755955485.6574\n",
      "Epoch 7762/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 264879418.1609 - val_loss: 854588664.7932\n",
      "Epoch 7763/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 269378839.9145 - val_loss: 854300196.5637\n",
      "Epoch 7764/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 591513597.4339 - val_loss: 1268197163.3328\n",
      "Epoch 7765/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 368136060.7586 - val_loss: 1650166054.8861\n",
      "Epoch 7766/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 650960827.4260 - val_loss: 824028096.4456\n",
      "Epoch 7767/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 302130635.4890 - val_loss: 863652775.9640\n",
      "Epoch 7768/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 432628861.3438 - val_loss: 1231614113.1072\n",
      "Epoch 7769/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 448431971.7546 - val_loss: 838527655.6186\n",
      "Epoch 7770/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 241708611.0433 - val_loss: 722829108.5390\n",
      "Epoch 7771/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 189940055.6849 - val_loss: 855077065.6180\n",
      "Epoch 7772/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 229032916.8137 - val_loss: 784314846.1727\n",
      "Epoch 7773/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 166704001.0805 - val_loss: 853058022.3460\n",
      "Epoch 7774/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 303799717.7445 - val_loss: 1762544069.9589\n",
      "Epoch 7775/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1227993209.4631 - val_loss: 773854925.1713\n",
      "Epoch 7776/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 198655001.9268 - val_loss: 711693472.1575\n",
      "Epoch 7777/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 133907833.0242 - val_loss: 715964798.5598\n",
      "Epoch 7778/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 173553713.1255 - val_loss: 3363198549.2973\n",
      "Epoch 7779/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 697144111.4688 - val_loss: 3839087697.6068\n",
      "Epoch 7780/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 877861088.6843 - val_loss: 919519714.5294\n",
      "Epoch 7781/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 201145694.6809 - val_loss: 792182137.1454\n",
      "Epoch 7782/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 124883996.5425 - val_loss: 673780693.8374\n",
      "Epoch 7783/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 116342128.0540 - val_loss: 661095478.7398\n",
      "Epoch 7784/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 113731765.8796 - val_loss: 710747270.0602\n",
      "Epoch 7785/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 242439354.6877 - val_loss: 1018735418.7612\n",
      "Epoch 7786/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 691462865.6117 - val_loss: 973823038.7938\n",
      "Epoch 7787/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 532008543.0591 - val_loss: 947301624.6031\n",
      "Epoch 7788/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 356932752.2431 - val_loss: 836881565.0970\n",
      "Epoch 7789/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 154252742.0506 - val_loss: 860135063.3339\n",
      "Epoch 7790/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 177477745.3776 - val_loss: 1286233199.5454\n",
      "Epoch 7791/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 456078265.0850 - val_loss: 2278489780.0461\n",
      "Epoch 7792/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 891160221.2763 - val_loss: 1106859874.0883\n",
      "Epoch 7793/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 304197761.3011 - val_loss: 1031897610.4731\n",
      "Epoch 7794/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 162604885.6500 - val_loss: 660301186.9997\n",
      "Epoch 7795/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 202312429.1728 - val_loss: 918011614.4158\n",
      "Epoch 7796/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 234923456.6303 - val_loss: 702224098.9637\n",
      "Epoch 7797/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 703981898.6967 - val_loss: 2157707950.7623\n",
      "Epoch 7798/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1066775826.6967 - val_loss: 751736158.8973\n",
      "Epoch 7799/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 228326144.0225 - val_loss: 887201979.2473\n",
      "Epoch 7800/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 136670698.6382 - val_loss: 701019031.5949\n",
      "Epoch 7801/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 177904553.3596 - val_loss: 798615006.5328\n",
      "Epoch 7802/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 147850165.3348 - val_loss: 687013217.0622\n",
      "Epoch 7803/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 280253264.8554 - val_loss: 905842523.6748\n",
      "Epoch 7804/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 120850947.8667 - val_loss: 642292708.3634\n",
      "Epoch 7805/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 173998382.5594 - val_loss: 1331806757.8374\n",
      "Epoch 7806/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 226690392.7293 - val_loss: 707073346.4596\n",
      "Epoch 7807/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 270785269.5554 - val_loss: 813667484.6065\n",
      "Epoch 7808/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 798118105.3934 - val_loss: 801415641.4065\n",
      "Epoch 7809/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 216635731.4485 - val_loss: 2181537170.8669\n",
      "Epoch 7810/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 482605924.3950 - val_loss: 691789440.1080\n",
      "Epoch 7811/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 187408212.6370 - val_loss: 865753478.2717\n",
      "Epoch 7812/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 160189264.8194 - val_loss: 892955478.7105\n",
      "Epoch 7813/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 549096194.3050 - val_loss: 1474797731.5105\n",
      "Epoch 7814/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 886385641.2515 - val_loss: 1221427059.2180\n",
      "Epoch 7815/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 230413820.5110 - val_loss: 708387640.9699\n",
      "Epoch 7816/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 359075886.4603 - val_loss: 1782415018.9007\n",
      "Epoch 7817/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 404621581.7670 - val_loss: 1088297256.8641\n",
      "Epoch 7818/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 265401115.0208 - val_loss: 1363934036.3612\n",
      "Epoch 7819/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 282624240.6798 - val_loss: 764358054.0512\n",
      "Epoch 7820/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 149858529.9989 - val_loss: 2250185174.0895\n",
      "Epoch 7821/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1347542248.2836 - val_loss: 815156705.1702\n",
      "Epoch 7822/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 178699784.3421 - val_loss: 721268497.2242\n",
      "Epoch 7823/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 134712935.0411 - val_loss: 2185125244.0214\n",
      "Epoch 7824/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 902231377.8818 - val_loss: 1046812785.9207\n",
      "Epoch 7825/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 220839005.8030 - val_loss: 1294103825.5617\n",
      "Epoch 7826/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 183542871.6263 - val_loss: 2327173922.0613\n",
      "Epoch 7827/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 390994359.4733 - val_loss: 691449943.9077\n",
      "Epoch 7828/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 209743264.1441 - val_loss: 4146330161.9758\n",
      "Epoch 7829/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 530352457.7378 - val_loss: 1042107247.3294\n",
      "Epoch 7830/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 231638482.0259 - val_loss: 828080980.6537\n",
      "Epoch 7831/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 224490119.6357 - val_loss: 1439459908.4107\n",
      "Epoch 7832/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 382779842.6292 - val_loss: 1046952214.6835\n",
      "Epoch 7833/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 141527786.8588 - val_loss: 686953124.3567\n",
      "Epoch 7834/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 308983470.6764 - val_loss: 1296890493.3243\n",
      "Epoch 7835/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 439198535.2752 - val_loss: 1540654983.0211\n",
      "Epoch 7836/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 688635209.7963 - val_loss: 949808191.6039\n",
      "Epoch 7837/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 707432044.1013 - val_loss: 1344822313.8385\n",
      "Epoch 7838/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 285725415.0895 - val_loss: 773338661.1173\n",
      "Epoch 7839/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 702596262.4288 - val_loss: 681953007.7232\n",
      "Epoch 7840/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 290212191.3652 - val_loss: 1008363921.6743\n",
      "Epoch 7841/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 150546753.9854 - val_loss: 1160870107.6163\n",
      "Epoch 7842/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 615645087.6218 - val_loss: 4062473643.1707\n",
      "Epoch 7843/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 665362888.7383 - val_loss: 680410710.6858\n",
      "Epoch 7844/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 243005566.6224 - val_loss: 1030230015.7480\n",
      "Epoch 7845/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 274098211.5881 - val_loss: 725251052.5210\n",
      "Epoch 7846/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 210409195.0568 - val_loss: 840486878.9491\n",
      "Epoch 7847/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 236528486.9015 - val_loss: 1124323971.0785\n",
      "Epoch 7848/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 263975795.8267 - val_loss: 1124381966.3032\n",
      "Epoch 7849/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1079739029.4159 - val_loss: 727941101.5707\n",
      "Epoch 7850/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 125853410.4491 - val_loss: 1337077897.5595\n",
      "Epoch 7851/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 124806069.2335 - val_loss: 668908357.8127\n",
      "Epoch 7852/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 169726899.8897 - val_loss: 802836132.7100\n",
      "Epoch 7853/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 329220874.3455 - val_loss: 795348129.2647\n",
      "Epoch 7854/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 431885112.3106 - val_loss: 1186491013.9443\n",
      "Epoch 7855/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1062560549.4564 - val_loss: 1540712442.1041\n",
      "Epoch 7856/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 491069667.7659 - val_loss: 678932836.7010\n",
      "Epoch 7857/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 115773871.9640 - val_loss: 770897127.8425\n",
      "Epoch 7858/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 270232179.3461 - val_loss: 944406239.4554\n",
      "Epoch 7859/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 203679849.6522 - val_loss: 798494830.0962\n",
      "Epoch 7860/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 256236032.1930 - val_loss: 1140204399.6985\n",
      "Epoch 7861/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 981025824.9364 - val_loss: 1539878692.7122\n",
      "Epoch 7862/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 221014639.3607 - val_loss: 1614351760.6346\n",
      "Epoch 7863/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 920250823.1019 - val_loss: 837605611.7108\n",
      "Epoch 7864/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 437925714.1880 - val_loss: 2638428881.9488\n",
      "Epoch 7865/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 439166867.9617 - val_loss: 710825014.2695\n",
      "Epoch 7866/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 102449821.0557 - val_loss: 657610494.3471\n",
      "Epoch 7867/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 121992135.0456 - val_loss: 701942843.5060\n",
      "Epoch 7868/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 104417954.9702 - val_loss: 1083241496.2543\n",
      "Epoch 7869/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 235382940.3647 - val_loss: 800486605.8127\n",
      "Epoch 7870/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 493164347.9122 - val_loss: 1051473835.9269\n",
      "Epoch 7871/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 171541575.0501 - val_loss: 746094785.2759\n",
      "Epoch 7872/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 385756126.9071 - val_loss: 1005476340.8923\n",
      "Epoch 7873/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 513744061.6230 - val_loss: 3543650055.6692\n",
      "Epoch 7874/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1036657911.8829 - val_loss: 1012557954.3044\n",
      "Epoch 7875/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 212543223.3337 - val_loss: 715621567.2439\n",
      "Epoch 7876/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 129920948.8205 - val_loss: 667907692.9530\n",
      "Epoch 7877/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 204666948.4412 - val_loss: 675252055.2169\n",
      "Epoch 7878/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 181588282.3815 - val_loss: 1045664590.9963\n",
      "Epoch 7879/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 134653982.7935 - val_loss: 1319133118.5148\n",
      "Epoch 7880/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 91us/step - loss: 582223544.1846 - val_loss: 862958098.8084\n",
      "Epoch 7881/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 523093896.8599 - val_loss: 1197705216.5581\n",
      "Epoch 7882/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 356887632.2037 - val_loss: 738018360.9474\n",
      "Epoch 7883/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 112437601.7062 - val_loss: 999154040.9969\n",
      "Epoch 7884/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 329836461.5239 - val_loss: 968296026.9592\n",
      "Epoch 7885/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1008931430.7349 - val_loss: 1034668081.3187\n",
      "Epoch 7886/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 666726746.1835 - val_loss: 2165929505.3412\n",
      "Epoch 7887/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 339390565.8481 - val_loss: 650642376.1328\n",
      "Epoch 7888/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 182103286.3568 - val_loss: 841544192.4771\n",
      "Epoch 7889/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 95275942.2228 - val_loss: 771631720.8574\n",
      "Epoch 7890/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 181967533.4316 - val_loss: 747424353.1702\n",
      "Epoch 7891/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 146532287.4057 - val_loss: 688762929.7181\n",
      "Epoch 7892/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 134360954.6427 - val_loss: 928677052.3814\n",
      "Epoch 7893/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 258420206.9375 - val_loss: 970718074.7072\n",
      "Epoch 7894/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 240832779.1649 - val_loss: 1816534393.6630\n",
      "Epoch 7895/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 509532950.5144 - val_loss: 1197231746.0073\n",
      "Epoch 7896/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 178142035.1964 - val_loss: 706835626.6847\n",
      "Epoch 7897/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 300200308.6415 - val_loss: 753130258.2999\n",
      "Epoch 7898/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 503659610.6427 - val_loss: 935499634.3449\n",
      "Epoch 7899/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 305984523.4170 - val_loss: 812222811.3125\n",
      "Epoch 7900/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 456403509.2369 - val_loss: 10335301960.0833\n",
      "Epoch 7901/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1964448692.1328 - val_loss: 1013891081.8655\n",
      "Epoch 7902/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 410142009.7243 - val_loss: 1124681492.5907\n",
      "Epoch 7903/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 160490007.9145 - val_loss: 3086867588.3117\n",
      "Epoch 7904/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 897953048.2251 - val_loss: 840199744.7381\n",
      "Epoch 7905/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 107497972.2918 - val_loss: 703981573.5854\n",
      "Epoch 7906/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 77750720.3737 - val_loss: 872313138.3539\n",
      "Epoch 7907/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 95069991.9505 - val_loss: 650713627.8987\n",
      "Epoch 7908/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 225712022.6989 - val_loss: 768772028.9035\n",
      "Epoch 7909/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 397078531.9178 - val_loss: 812485946.8287\n",
      "Epoch 7910/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 205453567.8379 - val_loss: 872664868.6402\n",
      "Epoch 7911/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 354118419.8807 - val_loss: 1456155084.7280\n",
      "Epoch 7912/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1018123538.3140 - val_loss: 696323033.9949\n",
      "Epoch 7913/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 155526394.9668 - val_loss: 687967005.4008\n",
      "Epoch 7914/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 121905933.3799 - val_loss: 778089438.5058\n",
      "Epoch 7915/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 247887541.8796 - val_loss: 722396392.9609\n",
      "Epoch 7916/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 296224494.1362 - val_loss: 861347389.0925\n",
      "Epoch 7917/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 155742978.0259 - val_loss: 1207439542.9266\n",
      "Epoch 7918/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 335535087.7209 - val_loss: 1585396911.5634\n",
      "Epoch 7919/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 627564044.4615 - val_loss: 1581865933.1961\n",
      "Epoch 7920/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 369345915.1626 - val_loss: 719147098.3179\n",
      "Epoch 7921/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 323812141.1277 - val_loss: 1990485522.4709\n",
      "Epoch 7922/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 879246235.8784 - val_loss: 697729506.8309\n",
      "Epoch 7923/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 176476820.8621 - val_loss: 868964890.4731\n",
      "Epoch 7924/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 138776547.1109 - val_loss: 767208649.7305\n",
      "Epoch 7925/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 83640308.9972 - val_loss: 1592364008.2183\n",
      "Epoch 7926/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 399263781.2133 - val_loss: 888572264.5063\n",
      "Epoch 7927/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 168222031.6579 - val_loss: 972423094.0174\n",
      "Epoch 7928/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 182272522.8452 - val_loss: 3060414284.8360\n",
      "Epoch 7929/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1065841110.5639 - val_loss: 1429327401.3345\n",
      "Epoch 7930/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 327970466.1880 - val_loss: 700656193.4762\n",
      "Epoch 7931/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 354939001.9494 - val_loss: 2618050271.4869\n",
      "Epoch 7932/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 377573636.2679 - val_loss: 1033498263.0436\n",
      "Epoch 7933/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 204023373.7857 - val_loss: 2344099074.0793\n",
      "Epoch 7934/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 236921927.2617 - val_loss: 697079933.1781\n",
      "Epoch 7935/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 719893255.9055 - val_loss: 789571542.4855\n",
      "Epoch 7936/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 170078154.4266 - val_loss: 731766146.0073\n",
      "Epoch 7937/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 327509204.5470 - val_loss: 685522021.4909\n",
      "Epoch 7938/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 315533913.8053 - val_loss: 1530238730.1896\n",
      "Epoch 7939/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 388979826.5684 - val_loss: 976413297.9488\n",
      "Epoch 7940/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 326317904.0810 - val_loss: 2320648863.2529\n",
      "Epoch 7941/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 204314175.3562 - val_loss: 869468993.4605\n",
      "Epoch 7942/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 696188939.4980 - val_loss: 1588397725.8667\n",
      "Epoch 7943/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 465279860.4254 - val_loss: 702758255.4914\n",
      "Epoch 7944/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 706414984.9071 - val_loss: 922699944.3803\n",
      "Epoch 7945/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 277938545.5577 - val_loss: 1402814307.4295\n",
      "Epoch 7946/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 313107800.4952 - val_loss: 774058542.0647\n",
      "Epoch 7947/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 112937803.7243 - val_loss: 673535814.1311\n",
      "Epoch 7948/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 109683651.4170 - val_loss: 735535850.6937\n",
      "Epoch 7949/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 344232778.2037 - val_loss: 980230651.0132\n",
      "Epoch 7950/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 392987228.4569 - val_loss: 980552234.2481\n",
      "Epoch 7951/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 146109686.1362 - val_loss: 968435136.1440\n",
      "Epoch 7952/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 251241545.4811 - val_loss: 954668464.2700\n",
      "Epoch 7953/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 173710850.9555 - val_loss: 726143507.4475\n",
      "Epoch 7954/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 200275733.9606 - val_loss: 2609044587.7648\n",
      "Epoch 7955/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1307889512.0675 - val_loss: 4248036263.2101\n",
      "Epoch 7956/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 647423325.7895 - val_loss: 813101657.0284\n",
      "Epoch 7957/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 176088783.2752 - val_loss: 775659275.6298\n",
      "Epoch 7958/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 201263133.0647 - val_loss: 1192927645.5066\n",
      "Epoch 7959/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 397881024.8284 - val_loss: 1736144967.2191\n",
      "Epoch 7960/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 560336946.3793 - val_loss: 1338858768.5086\n",
      "Epoch 7961/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 669484351.9460 - val_loss: 738276178.2323\n",
      "Epoch 7962/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 284510295.6117 - val_loss: 858849899.9449\n",
      "Epoch 7963/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 143805588.1216 - val_loss: 1696068929.5302\n",
      "Epoch 7964/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 777797015.0861 - val_loss: 1202057123.8346\n",
      "Epoch 7965/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 498803318.1677 - val_loss: 969560620.7190\n",
      "Epoch 7966/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 436890008.0855 - val_loss: 820887773.9724\n",
      "Epoch 7967/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 133771392.7518 - val_loss: 1158664056.8776\n",
      "Epoch 7968/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 242518144.8644 - val_loss: 738020693.6574\n",
      "Epoch 7969/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 101884288.4502 - val_loss: 705193792.4253\n",
      "Epoch 7970/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 252131556.4479 - val_loss: 4163896704.8281\n",
      "Epoch 7971/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 798049899.9572 - val_loss: 748813941.9589\n",
      "Epoch 7972/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 195816866.3950 - val_loss: 1228971466.1806\n",
      "Epoch 7973/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1800978659.6376 - val_loss: 1968212917.7564\n",
      "Epoch 7974/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 281066876.6415 - val_loss: 691095521.7373\n",
      "Epoch 7975/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 100468633.7130 - val_loss: 682242546.7702\n",
      "Epoch 7976/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 99307634.4896 - val_loss: 828092586.3426\n",
      "Epoch 7977/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 279791267.7456 - val_loss: 2318768129.5122\n",
      "Epoch 7978/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 249496964.4029 - val_loss: 688658242.7387\n",
      "Epoch 7979/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 157726955.2729 - val_loss: 817521905.0903\n",
      "Epoch 7980/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 302374971.7591 - val_loss: 3177766169.8160\n",
      "Epoch 7981/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 726675087.6308 - val_loss: 3849844472.2588\n",
      "Epoch 7982/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1323030248.5104 - val_loss: 956409733.3626\n",
      "Epoch 7983/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 195506354.9443 - val_loss: 1104073176.8439\n",
      "Epoch 7984/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 143277013.4620 - val_loss: 715028048.9283\n",
      "Epoch 7985/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 82483018.8858 - val_loss: 766800731.1482\n",
      "Epoch 7986/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 264338440.6258 - val_loss: 757147974.2740\n",
      "Epoch 7987/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 122974172.7001 - val_loss: 739300585.6360\n",
      "Epoch 7988/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 332058824.5267 - val_loss: 1703125118.7218\n",
      "Epoch 7989/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 519206611.8627 - val_loss: 992036327.2821\n",
      "Epoch 7990/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 424773751.7164 - val_loss: 1986263141.4459\n",
      "Epoch 7991/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 448668661.1232 - val_loss: 1184279601.1297\n",
      "Epoch 7992/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 226998629.9212 - val_loss: 824781169.4717\n",
      "Epoch 7993/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 151221040.4772 - val_loss: 1474990474.8017\n",
      "Epoch 7994/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 263168188.5785 - val_loss: 651627014.6610\n",
      "Epoch 7995/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 174574568.8374 - val_loss: 761119488.5536\n",
      "Epoch 7996/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 170380643.1874 - val_loss: 770379299.6276\n",
      "Epoch 7997/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 316382979.2437 - val_loss: 1307709202.1468\n",
      "Epoch 7998/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 186229097.3281 - val_loss: 798185514.3179\n",
      "Epoch 7999/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 334349407.6173 - val_loss: 1511515716.5232\n",
      "Epoch 8000/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 542472035.7636 - val_loss: 1478465634.1873\n",
      "Epoch 8001/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 326392185.2470 - val_loss: 900704573.5359\n",
      "Epoch 8002/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 147190161.7738 - val_loss: 708345486.7331\n",
      "Epoch 8003/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 201403128.7788 - val_loss: 1235687457.7013\n",
      "Epoch 8004/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1863952998.7530 - val_loss: 4170679378.5249\n",
      "Epoch 8005/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1851715149.6590 - val_loss: 911397457.8678\n",
      "Epoch 8006/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 157192102.7169 - val_loss: 694766853.6371\n",
      "Epoch 8007/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 90023570.3410 - val_loss: 793632356.5277\n",
      "Epoch 8008/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 137519762.1745 - val_loss: 691603445.1421\n",
      "Epoch 8009/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 82034428.8182 - val_loss: 672047303.5927\n",
      "Epoch 8010/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 95us/step - loss: 92725876.9679 - val_loss: 928132217.0104\n",
      "Epoch 8011/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 147632123.3540 - val_loss: 767695869.1331\n",
      "Epoch 8012/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 194886189.8731 - val_loss: 3268942895.3834\n",
      "Epoch 8013/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1158970235.5340 - val_loss: 941181282.7004\n",
      "Epoch 8014/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 271261916.9567 - val_loss: 726375532.6087\n",
      "Epoch 8015/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 109689154.3275 - val_loss: 839873971.6051\n",
      "Epoch 8016/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 117679629.2499 - val_loss: 1025040393.7890\n",
      "Epoch 8017/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 255538678.2037 - val_loss: 958880382.4698\n",
      "Epoch 8018/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 154604333.6500 - val_loss: 676000578.2301\n",
      "Epoch 8019/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 147827207.1784 - val_loss: 897884146.2368\n",
      "Epoch 8020/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 783517253.3483 - val_loss: 800386740.7392\n",
      "Epoch 8021/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 321979453.0467 - val_loss: 1495513361.9848\n",
      "Epoch 8022/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 231864149.1232 - val_loss: 659950049.6630\n",
      "Epoch 8023/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 107043840.7923 - val_loss: 672254838.0647\n",
      "Epoch 8024/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 291156315.2831 - val_loss: 1021016203.4138\n",
      "Epoch 8025/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 259767126.7530 - val_loss: 834753568.0090\n",
      "Epoch 8026/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 163153670.2746 - val_loss: 950295027.0020\n",
      "Epoch 8027/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 216407400.4479 - val_loss: 754582933.2433\n",
      "Epoch 8028/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 207640427.8458 - val_loss: 735418781.7429\n",
      "Epoch 8029/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 135651793.8165 - val_loss: 734681823.6309\n",
      "Epoch 8030/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 388194767.8199 - val_loss: 1487285363.7221\n",
      "Epoch 8031/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 530981840.9634 - val_loss: 1106033439.6962\n",
      "Epoch 8032/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1038976524.7068 - val_loss: 738462984.6774\n",
      "Epoch 8033/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 358369258.1024 - val_loss: 1302855937.7418\n",
      "Epoch 8034/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 297804638.5954 - val_loss: 932419853.6686\n",
      "Epoch 8035/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 212556626.5841 - val_loss: 1060900925.7857\n",
      "Epoch 8036/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 226377687.4463 - val_loss: 859466888.6368\n",
      "Epoch 8037/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1403079227.6781 - val_loss: 1967976204.9170\n",
      "Epoch 8038/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 678848875.8942 - val_loss: 863521142.1345\n",
      "Epoch 8039/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 217714373.8188 - val_loss: 815162116.5187\n",
      "Epoch 8040/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 116130813.4474 - val_loss: 638808950.7150\n",
      "Epoch 8041/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 204015799.4373 - val_loss: 804279933.3536\n",
      "Epoch 8042/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 181734525.9572 - val_loss: 689984624.3466\n",
      "Epoch 8043/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 101645158.7530 - val_loss: 760746718.4878\n",
      "Epoch 8044/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 276687950.1362 - val_loss: 731978463.4734\n",
      "Epoch 8045/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 252044139.2189 - val_loss: 1284251326.7443\n",
      "Epoch 8046/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 601432442.8931 - val_loss: 1079530369.8160\n",
      "Epoch 8047/10000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 285433295.636 - 0s 100us/step - loss: 265626672.4592 - val_loss: 771306076.8743\n",
      "Epoch 8048/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 432879727.9910 - val_loss: 1220939482.9862\n",
      "Epoch 8049/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 485639611.6061 - val_loss: 825077560.5221\n",
      "Epoch 8050/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 254765026.9713 - val_loss: 728402537.0869\n",
      "Epoch 8051/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 201211304.4705 - val_loss: 844223095.4127\n",
      "Epoch 8052/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 220725011.3315 - val_loss: 909112186.9502\n",
      "Epoch 8053/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 783198055.3652 - val_loss: 937739054.0152\n",
      "Epoch 8054/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 716996443.5476 - val_loss: 1115323965.6731\n",
      "Epoch 8055/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 186060355.2054 - val_loss: 746599865.2129\n",
      "Epoch 8056/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 196955514.4896 - val_loss: 1111684649.8025\n",
      "Epoch 8057/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 393088014.8385 - val_loss: 1023021831.4667\n",
      "Epoch 8058/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1010398107.8762 - val_loss: 1502178549.7474\n",
      "Epoch 8059/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 915914463.7119 - val_loss: 866884256.1710\n",
      "Epoch 8060/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 241775236.3455 - val_loss: 632923547.4053\n",
      "Epoch 8061/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 100470815.4046 - val_loss: 926544255.2034\n",
      "Epoch 8062/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 120345168.6936 - val_loss: 706576988.2059\n",
      "Epoch 8063/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 115529011.4125 - val_loss: 761874972.7786\n",
      "Epoch 8064/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 138842295.7907 - val_loss: 747538736.5378\n",
      "Epoch 8065/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 138573210.6517 - val_loss: 727296950.4518\n",
      "Epoch 8066/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 184405507.1514 - val_loss: 766626326.8501\n",
      "Epoch 8067/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 202872059.7997 - val_loss: 716703066.7342\n",
      "Epoch 8068/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 338389373.1007 - val_loss: 879256635.3823\n",
      "Epoch 8069/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 983891630.1722 - val_loss: 3529950664.9114\n",
      "Epoch 8070/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 738799889.4316 - val_loss: 1581642380.0349\n",
      "Epoch 8071/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 926418496.0476 - val_loss: 835469903.4554\n",
      "Epoch 8072/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 148629904.7293 - val_loss: 775141892.7212\n",
      "Epoch 8073/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 160331604.2161 - val_loss: 1301763510.0174\n",
      "Epoch 8074/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 160783829.6185 - val_loss: 718589665.3547\n",
      "Epoch 8075/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 302125012.8891 - val_loss: 781970231.4397\n",
      "Epoch 8076/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 136222368.4097 - val_loss: 726578994.1041\n",
      "Epoch 8077/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 233337061.0602 - val_loss: 2312775660.3409\n",
      "Epoch 8078/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 894445383.0051 - val_loss: 1399938269.6686\n",
      "Epoch 8079/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 364777344.2566 - val_loss: 761885346.0748\n",
      "Epoch 8080/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 189791613.9133 - val_loss: 1033060607.5274\n",
      "Epoch 8081/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 263100718.2082 - val_loss: 857168650.3055\n",
      "Epoch 8082/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 299923470.3523 - val_loss: 953612568.1463\n",
      "Epoch 8083/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 114510013.2088 - val_loss: 666832636.5547\n",
      "Epoch 8084/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 272257663.6488 - val_loss: 1594617843.2315\n",
      "Epoch 8085/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 413032133.7625 - val_loss: 822176379.1595\n",
      "Epoch 8086/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 386855276.8756 - val_loss: 1199748263.0920\n",
      "Epoch 8087/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 610612188.7046 - val_loss: 889161733.6889\n",
      "Epoch 8088/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 301086283.1986 - val_loss: 776230841.0374\n",
      "Epoch 8089/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 192426835.4935 - val_loss: 748670216.0113\n",
      "Epoch 8090/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 182493885.9291 - val_loss: 1163439546.0051\n",
      "Epoch 8091/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 2702379648.6483 - val_loss: 1569018110.8478\n",
      "Epoch 8092/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 287019803.2921 - val_loss: 650512878.7983\n",
      "Epoch 8093/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 136810873.3191 - val_loss: 881213889.6473\n",
      "Epoch 8094/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 130633239.2020 - val_loss: 673319177.8835\n",
      "Epoch 8095/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 173612205.2628 - val_loss: 742849370.2616\n",
      "Epoch 8096/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 93840936.2285 - val_loss: 675443584.4321\n",
      "Epoch 8097/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 139867701.5914 - val_loss: 1518993966.1232\n",
      "Epoch 8098/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 271183928.8925 - val_loss: 848659424.2880\n",
      "Epoch 8099/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 181053418.0990 - val_loss: 804125819.7603\n",
      "Epoch 8100/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 128933410.3365 - val_loss: 673498030.0692\n",
      "Epoch 8101/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 196681098.0056 - val_loss: 672673129.0408\n",
      "Epoch 8102/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 99775402.8059 - val_loss: 663870888.5685\n",
      "Epoch 8103/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 432239498.1564 - val_loss: 4101770571.1437\n",
      "Epoch 8104/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 692232640.0540 - val_loss: 737417134.0962\n",
      "Epoch 8105/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 105087566.6134 - val_loss: 808306555.9674\n",
      "Epoch 8106/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 357396750.0101 - val_loss: 1247263196.4264\n",
      "Epoch 8107/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 326555595.7411 - val_loss: 803889241.3120\n",
      "Epoch 8108/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 4399180101.0782 - val_loss: 6060258283.6208\n",
      "Epoch 8109/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1138695639.5183 - val_loss: 875437089.5662\n",
      "Epoch 8110/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 118113999.0321 - val_loss: 699807981.5696\n",
      "Epoch 8111/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 127602298.9488 - val_loss: 685376303.0740\n",
      "Epoch 8112/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 135909324.7136 - val_loss: 661681320.6278\n",
      "Epoch 8113/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 84338113.7648 - val_loss: 643533004.7055\n",
      "Epoch 8114/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 127861155.5453 - val_loss: 948169450.6093\n",
      "Epoch 8115/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 165084640.4682 - val_loss: 718440597.4594\n",
      "Epoch 8116/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 186015531.0253 - val_loss: 659889606.5699\n",
      "Epoch 8117/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 174273709.5599 - val_loss: 1309062414.3752\n",
      "Epoch 8118/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 288592268.7136 - val_loss: 723107510.3595\n",
      "Epoch 8119/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 211966046.3343 - val_loss: 2357999659.1887\n",
      "Epoch 8120/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 329969380.5290 - val_loss: 1110402739.5871\n",
      "Epoch 8121/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 252444345.8689 - val_loss: 832174527.6219\n",
      "Epoch 8122/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 140102049.4046 - val_loss: 788045591.0886\n",
      "Epoch 8123/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 571272456.4547 - val_loss: 2373771653.6889\n",
      "Epoch 8124/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1568910640.4232 - val_loss: 8727422928.7966\n",
      "Epoch 8125/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1220283374.9994 - val_loss: 672199259.2563\n",
      "Epoch 8126/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 102081986.2420 - val_loss: 1184168570.6869\n",
      "Epoch 8127/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 166671871.8379 - val_loss: 902830839.1066\n",
      "Epoch 8128/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 142237695.8559 - val_loss: 672330032.2948\n",
      "Epoch 8129/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 139485014.4108 - val_loss: 885483983.9820\n",
      "Epoch 8130/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 195770747.4800 - val_loss: 2079757254.3550\n",
      "Epoch 8131/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 513612846.1362 - val_loss: 2044759402.1446\n",
      "Epoch 8132/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 657252350.8835 - val_loss: 783250812.5890\n",
      "Epoch 8133/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 265189598.0416 - val_loss: 733080771.0155\n",
      "Epoch 8134/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 106910312.7338 - val_loss: 1212662556.5210\n",
      "Epoch 8135/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 513180443.9527 - val_loss: 797513219.4543\n",
      "Epoch 8136/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 153056976.6033 - val_loss: 777891051.8053\n",
      "Epoch 8137/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 247973692.1458 - val_loss: 673421837.5494\n",
      "Epoch 8138/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 88772411.4800 - val_loss: 841927722.5767\n",
      "Epoch 8139/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 278289023.6331 - val_loss: 823216142.5778\n",
      "Epoch 8140/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 87us/step - loss: 527040322.9893 - val_loss: 2371184514.1423\n",
      "Epoch 8141/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 887485124.1238 - val_loss: 783793946.2211\n",
      "Epoch 8142/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 193441094.7169 - val_loss: 734647789.8892\n",
      "Epoch 8143/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 174061716.9353 - val_loss: 654344946.3741\n",
      "Epoch 8144/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 597540284.4344 - val_loss: 1161963182.6903\n",
      "Epoch 8145/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 491195543.0321 - val_loss: 671226835.3530\n",
      "Epoch 8146/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 230851288.4277 - val_loss: 1418869543.5342\n",
      "Epoch 8147/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 142833142.8790 - val_loss: 687183512.2644\n",
      "Epoch 8148/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 668591545.5172 - val_loss: 1935839152.4366\n",
      "Epoch 8149/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 667338549.4114 - val_loss: 1960171404.4579\n",
      "Epoch 8150/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 851404463.4508 - val_loss: 716866012.7145\n",
      "Epoch 8151/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 159441202.5526 - val_loss: 1068683950.2852\n",
      "Epoch 8152/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 309547390.5526 - val_loss: 956511311.9505\n",
      "Epoch 8153/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 150370781.3663 - val_loss: 925199508.5592\n",
      "Epoch 8154/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 150200478.7665 - val_loss: 726445475.5466\n",
      "Epoch 8155/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 169626529.0535 - val_loss: 826045467.7828\n",
      "Epoch 8156/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 369285193.2155 - val_loss: 1098015417.2850\n",
      "Epoch 8157/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 186449286.3703 - val_loss: 669548844.8484\n",
      "Epoch 8158/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 135443862.9240 - val_loss: 1182560904.0743\n",
      "Epoch 8159/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 157244190.8655 - val_loss: 992127576.0518\n",
      "Epoch 8160/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 266429531.1041 - val_loss: 1457355462.9131\n",
      "Epoch 8161/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1360564395.4530 - val_loss: 815367063.0211\n",
      "Epoch 8162/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 164419603.0253 - val_loss: 817009988.6267\n",
      "Epoch 8163/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 172628851.1604 - val_loss: 812086672.7572\n",
      "Epoch 8164/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 253390598.5098 - val_loss: 943974745.1769\n",
      "Epoch 8165/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 188921428.1463 - val_loss: 2924906557.8937\n",
      "Epoch 8166/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 386193012.4750 - val_loss: 813742799.1134\n",
      "Epoch 8167/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 343465832.6258 - val_loss: 824120889.2895\n",
      "Epoch 8168/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 262851756.7316 - val_loss: 795316567.0706\n",
      "Epoch 8169/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 404662083.7096 - val_loss: 885723562.4551\n",
      "Epoch 8170/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 691536398.4738 - val_loss: 1957937533.9657\n",
      "Epoch 8171/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 447624698.8317 - val_loss: 980378205.5426\n",
      "Epoch 8172/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 431698834.9263 - val_loss: 795857114.8287\n",
      "Epoch 8173/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 132970227.3618 - val_loss: 808525916.2779\n",
      "Epoch 8174/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 114873706.7057 - val_loss: 634173911.1212\n",
      "Epoch 8175/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 210676507.3089 - val_loss: 760019573.5741\n",
      "Epoch 8176/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 244939909.7625 - val_loss: 959846411.1730\n",
      "Epoch 8177/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 1465201571.2954 - val_loss: 6290477334.8276\n",
      "Epoch 8178/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 2454505426.5121 - val_loss: 961837475.9561\n",
      "Epoch 8179/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 179510861.2898 - val_loss: 656058199.9431\n",
      "Epoch 8180/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 69935030.3582 - val_loss: 654992145.0037\n",
      "Epoch 8181/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 130297114.8497 - val_loss: 1030823509.3513\n",
      "Epoch 8182/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 95669642.4806 - val_loss: 624577913.2399\n",
      "Epoch 8183/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 220439630.5144 - val_loss: 744683148.5660\n",
      "Epoch 8184/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 100729985.1176 - val_loss: 724871363.8729\n",
      "Epoch 8185/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 116389427.0895 - val_loss: 712725058.1513\n",
      "Epoch 8186/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 183617741.3438 - val_loss: 733170036.9463\n",
      "Epoch 8187/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 178871717.1818 - val_loss: 740730520.7674\n",
      "Epoch 8188/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 172778269.4339 - val_loss: 671915772.1058\n",
      "Epoch 8189/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 232030357.7085 - val_loss: 988620083.0695\n",
      "Epoch 8190/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 444975312.0540 - val_loss: 892078734.0602\n",
      "Epoch 8191/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 159253366.5999 - val_loss: 719673822.9761\n",
      "Epoch 8192/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 235490650.3331 - val_loss: 1310301794.4844\n",
      "Epoch 8193/10000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 353388474.891 - 0s 86us/step - loss: 338180475.6286 - val_loss: 1230176443.5893\n",
      "Epoch 8194/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 402256598.7845 - val_loss: 693036096.0664\n",
      "Epoch 8195/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 151185772.2814 - val_loss: 1037680153.5347\n",
      "Epoch 8196/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 232518568.0253 - val_loss: 1236819621.4504\n",
      "Epoch 8197/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1082915547.5160 - val_loss: 910916092.3004\n",
      "Epoch 8198/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 230914974.2676 - val_loss: 1170678328.8979\n",
      "Epoch 8199/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 157748101.9156 - val_loss: 663273281.1702\n",
      "Epoch 8200/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 180805547.3270 - val_loss: 815127813.0948\n",
      "Epoch 8201/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 370647118.0237 - val_loss: 703172126.9750\n",
      "Epoch 8202/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 257330662.2487 - val_loss: 874534263.9617\n",
      "Epoch 8203/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 266849767.0771 - val_loss: 2514723607.1516\n",
      "Epoch 8204/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 376728631.2752 - val_loss: 1645241673.2895\n",
      "Epoch 8205/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 432618141.4069 - val_loss: 4144859923.9471\n",
      "Epoch 8206/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 589578278.6449 - val_loss: 846801011.8672\n",
      "Epoch 8207/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 227079418.7417 - val_loss: 2626850506.0636\n",
      "Epoch 8208/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 666955343.1503 - val_loss: 4628907308.3589\n",
      "Epoch 8209/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 432170685.7445 - val_loss: 936826831.4622\n",
      "Epoch 8210/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 127241276.5785 - val_loss: 696068684.9722\n",
      "Epoch 8211/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 172713215.1176 - val_loss: 690015155.9651\n",
      "Epoch 8212/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 207696925.1998 - val_loss: 1893746280.0641\n",
      "Epoch 8213/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1087596139.9032 - val_loss: 901729916.0214\n",
      "Epoch 8214/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 691878791.9505 - val_loss: 723635922.7589\n",
      "Epoch 8215/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 140008559.5048 - val_loss: 732848253.9027\n",
      "Epoch 8216/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 241853328.3872 - val_loss: 1238974405.6619\n",
      "Epoch 8217/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 158895038.8137 - val_loss: 1255525150.7848\n",
      "Epoch 8218/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 430970008.6978 - val_loss: 1069958084.6627\n",
      "Epoch 8219/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 311672402.8452 - val_loss: 644601250.5767\n",
      "Epoch 8220/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 133999086.8385 - val_loss: 707781273.9646\n",
      "Epoch 8221/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 126440000.4142 - val_loss: 792015968.8056\n",
      "Epoch 8222/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 213018087.8773 - val_loss: 684628483.5781\n",
      "Epoch 8223/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 168185296.5200 - val_loss: 2163927914.5406\n",
      "Epoch 8224/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1001089762.5211 - val_loss: 805957068.4309\n",
      "Epoch 8225/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 821405226.3185 - val_loss: 1158781765.2298\n",
      "Epoch 8226/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 337560560.7653 - val_loss: 1099399722.3336\n",
      "Epoch 8227/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 269366281.2290 - val_loss: 799494635.8447\n",
      "Epoch 8228/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 138232198.3208 - val_loss: 809161975.0706\n",
      "Epoch 8229/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 185847401.8233 - val_loss: 905792925.2231\n",
      "Epoch 8230/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 162094559.2437 - val_loss: 1008827895.9089\n",
      "Epoch 8231/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 271094453.0827 - val_loss: 2137680654.6543\n",
      "Epoch 8232/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 335377658.9038 - val_loss: 1234865456.0495\n",
      "Epoch 8233/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2210396099.8357 - val_loss: 1633579742.9108\n",
      "Epoch 8234/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 361215681.0219 - val_loss: 664824002.2954\n",
      "Epoch 8235/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 106798257.4947 - val_loss: 668557457.2309\n",
      "Epoch 8236/10000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 104154914.139 - 0s 100us/step - loss: 102842721.4406 - val_loss: 788330615.4802\n",
      "Epoch 8237/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 184233899.0388 - val_loss: 937436848.5176\n",
      "Epoch 8238/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 329691402.4671 - val_loss: 647042174.3269\n",
      "Epoch 8239/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 414928810.4266 - val_loss: 1020717973.7204\n",
      "Epoch 8240/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 226632012.0743 - val_loss: 1124652718.3595\n",
      "Epoch 8241/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 321987097.6432 - val_loss: 692478193.7755\n",
      "Epoch 8242/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 216499945.9460 - val_loss: 643136272.4838\n",
      "Epoch 8243/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 114434659.2414 - val_loss: 653767449.8790\n",
      "Epoch 8244/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 133093528.1396 - val_loss: 890594776.5221\n",
      "Epoch 8245/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 484445194.0124 - val_loss: 1296505446.4180\n",
      "Epoch 8246/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 1232842883.5295 - val_loss: 6900298596.8878\n",
      "Epoch 8247/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1153384501.5464 - val_loss: 701413325.2703\n",
      "Epoch 8248/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 106131930.5256 - val_loss: 1028207337.0284\n",
      "Epoch 8249/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 176784278.1232 - val_loss: 647754405.0903\n",
      "Epoch 8250/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 178535479.0954 - val_loss: 752183816.2633\n",
      "Epoch 8251/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 106908476.8846 - val_loss: 703787353.1522\n",
      "Epoch 8252/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 185186361.8053 - val_loss: 729729140.9733\n",
      "Epoch 8253/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 122786859.8447 - val_loss: 794783722.0478\n",
      "Epoch 8254/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 121478324.7394 - val_loss: 1716001407.8560\n",
      "Epoch 8255/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 484534027.2819 - val_loss: 702651926.2650\n",
      "Epoch 8256/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 155015682.1970 - val_loss: 2003427524.4467\n",
      "Epoch 8257/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 458072773.3416 - val_loss: 760682838.5260\n",
      "Epoch 8258/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 142877768.5324 - val_loss: 683926288.6290\n",
      "Epoch 8259/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 154661298.9724 - val_loss: 655637690.8242\n",
      "Epoch 8260/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 384049462.5459 - val_loss: 1142569341.3176\n",
      "Epoch 8261/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 735825148.0023 - val_loss: 1325245845.7474\n",
      "Epoch 8262/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 255472637.3528 - val_loss: 785692002.6498\n",
      "Epoch 8263/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 247535633.8998 - val_loss: 759114646.9356\n",
      "Epoch 8264/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 379029369.0895 - val_loss: 1073222520.7764\n",
      "Epoch 8265/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 168150170.2915 - val_loss: 2609384878.2672\n",
      "Epoch 8266/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 578725352.9612 - val_loss: 652830810.5857\n",
      "Epoch 8267/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 393469809.2245 - val_loss: 1857156802.5744\n",
      "Epoch 8268/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 332087509.5239 - val_loss: 670479298.1176\n",
      "Epoch 8269/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 266065678.7394 - val_loss: 1531165605.6529\n",
      "Epoch 8270/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 103us/step - loss: 250423432.8779 - val_loss: 878428827.4048\n",
      "Epoch 8271/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 261910117.2808 - val_loss: 772093459.2945\n",
      "Epoch 8272/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 144218675.5836 - val_loss: 844568753.9060\n",
      "Epoch 8273/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 332072881.8458 - val_loss: 945973752.3668\n",
      "Epoch 8274/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 692216328.3354 - val_loss: 852548441.5280\n",
      "Epoch 8275/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 133330092.5087 - val_loss: 672485844.8023\n",
      "Epoch 8276/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 562541350.6089 - val_loss: 1073724748.0169\n",
      "Epoch 8277/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 777560821.6095 - val_loss: 1694834471.7142\n",
      "Epoch 8278/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 184567302.0101 - val_loss: 691887555.7243\n",
      "Epoch 8279/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 112465878.9007 - val_loss: 636996335.1269\n",
      "Epoch 8280/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 90675338.3689 - val_loss: 820554544.1451\n",
      "Epoch 8281/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 276464629.4947 - val_loss: 753918501.8059\n",
      "Epoch 8282/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 583652316.6866 - val_loss: 1204625396.5502\n",
      "Epoch 8283/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1424236767.6038 - val_loss: 1765217651.3800\n",
      "Epoch 8284/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 239508779.4350 - val_loss: 853573445.3063\n",
      "Epoch 8285/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 219368064.4322 - val_loss: 680892222.4878\n",
      "Epoch 8286/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 77325516.6235 - val_loss: 695086968.5918\n",
      "Epoch 8287/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 552560195.2954 - val_loss: 1567439857.5797\n",
      "Epoch 8288/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 171297143.0872 - val_loss: 695075844.5738\n",
      "Epoch 8289/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 143182275.6669 - val_loss: 853564418.8895\n",
      "Epoch 8290/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 136882873.6252 - val_loss: 1965706636.3859\n",
      "Epoch 8291/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 507273444.3804 - val_loss: 2130316337.8948\n",
      "Epoch 8292/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1023254171.8762 - val_loss: 2656212807.9392\n",
      "Epoch 8293/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 335852736.5492 - val_loss: 943655388.4985\n",
      "Epoch 8294/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 164394191.4913 - val_loss: 826544001.7958\n",
      "Epoch 8295/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 176478821.7085 - val_loss: 3367377909.0903\n",
      "Epoch 8296/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 835654433.4406 - val_loss: 1446907054.4399\n",
      "Epoch 8297/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 246767536.4502 - val_loss: 820668589.1691\n",
      "Epoch 8298/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 203496333.6511 - val_loss: 681928756.9159\n",
      "Epoch 8299/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 360855324.7766 - val_loss: 2006427592.5153\n",
      "Epoch 8300/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 253446506.9038 - val_loss: 679689288.8850\n",
      "Epoch 8301/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 103767673.8593 - val_loss: 1424269205.1713\n",
      "Epoch 8302/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 320055682.6742 - val_loss: 726683105.0082\n",
      "Epoch 8303/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 123423055.4418 - val_loss: 998887593.2985\n",
      "Epoch 8304/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 345481032.7518 - val_loss: 11470152762.4011\n",
      "Epoch 8305/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1380087728.2971 - val_loss: 1303962176.2160\n",
      "Epoch 8306/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1000001907.0523 - val_loss: 1226938189.5201\n",
      "Epoch 8307/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 159436253.1007 - val_loss: 744860623.3204\n",
      "Epoch 8308/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 85689660.5515 - val_loss: 687978368.5716\n",
      "Epoch 8309/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 135575933.7310 - val_loss: 875465391.2034\n",
      "Epoch 8310/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 344349406.4513 - val_loss: 701090709.7474\n",
      "Epoch 8311/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 229759977.9133 - val_loss: 842273076.7122\n",
      "Epoch 8312/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 193134620.0203 - val_loss: 994206766.3032\n",
      "Epoch 8313/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 352138286.6224 - val_loss: 894961169.4965\n",
      "Epoch 8314/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 222906358.9240 - val_loss: 903967025.8397\n",
      "Epoch 8315/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 372201900.7136 - val_loss: 1240808123.9314\n",
      "Epoch 8316/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 226406370.0304 - val_loss: 1472963260.5255\n",
      "Epoch 8317/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 656873079.7704 - val_loss: 949191749.1848\n",
      "Epoch 8318/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 979751701.6095 - val_loss: 1921945895.7772\n",
      "Epoch 8319/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2245558443.9809 - val_loss: 764636875.2698\n",
      "Epoch 8320/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 145441605.2313 - val_loss: 694998135.7547\n",
      "Epoch 8321/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 72320857.7603 - val_loss: 786619207.1156\n",
      "Epoch 8322/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 106274951.8604 - val_loss: 668031637.3131\n",
      "Epoch 8323/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 205079949.5779 - val_loss: 1741914655.5319\n",
      "Epoch 8324/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1806925867.4879 - val_loss: 854384494.2515\n",
      "Epoch 8325/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 125970461.3348 - val_loss: 1108060423.4352\n",
      "Epoch 8326/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 162027793.3641 - val_loss: 752262227.1010\n",
      "Epoch 8327/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 130416482.4041 - val_loss: 879304333.8059\n",
      "Epoch 8328/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 130295554.0034 - val_loss: 656252603.9831\n",
      "Epoch 8329/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 72089800.8126 - val_loss: 657614309.2478\n",
      "Epoch 8330/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 123071619.0253 - val_loss: 842287515.1640\n",
      "Epoch 8331/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 189713356.2904 - val_loss: 716800661.2186\n",
      "Epoch 8332/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 117531089.9133 - val_loss: 752333850.3280\n",
      "Epoch 8333/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 486357406.9195 - val_loss: 802122101.3783\n",
      "Epoch 8334/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 177937826.0889 - val_loss: 667897430.5114\n",
      "Epoch 8335/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 351353346.7192 - val_loss: 1068967529.2805\n",
      "Epoch 8336/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 187189669.9696 - val_loss: 1055221781.5854\n",
      "Epoch 8337/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 287105543.3562 - val_loss: 716908095.6399\n",
      "Epoch 8338/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 317502189.3573 - val_loss: 806627421.2591\n",
      "Epoch 8339/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 741784303.7929 - val_loss: 1256210855.5792\n",
      "Epoch 8340/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 290028352.4457 - val_loss: 1297292945.0127\n",
      "Epoch 8341/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 266753079.1986 - val_loss: 657598623.3519\n",
      "Epoch 8342/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 149158781.8751 - val_loss: 804568930.1558\n",
      "Epoch 8343/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 772998393.3708 - val_loss: 857580149.8689\n",
      "Epoch 8344/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 495937355.7321 - val_loss: 1012882238.1547\n",
      "Epoch 8345/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 614222329.9674 - val_loss: 983554751.7660\n",
      "Epoch 8346/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 259427156.8407 - val_loss: 1033160648.2543\n",
      "Epoch 8347/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 429883786.5796 - val_loss: 904734030.1525\n",
      "Epoch 8348/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 138806251.0613 - val_loss: 711019222.2886\n",
      "Epoch 8349/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 260313454.0822 - val_loss: 908357118.7488\n",
      "Epoch 8350/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 351542037.4564 - val_loss: 806563204.8968\n",
      "Epoch 8351/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 261763784.8599 - val_loss: 885637659.9179\n",
      "Epoch 8352/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 487409091.6916 - val_loss: 717805531.4790\n",
      "Epoch 8353/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 129951667.1064 - val_loss: 1113627459.0785\n",
      "Epoch 8354/10000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 299111986.4221 - val_loss: 906528393.0183\n",
      "Epoch 8355/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 385840231.6804 - val_loss: 757658634.6487\n",
      "Epoch 8356/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 264114070.4738 - val_loss: 899128103.5477\n",
      "Epoch 8357/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 538449700.7361 - val_loss: 1078669465.3660\n",
      "Epoch 8358/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 311367737.5082 - val_loss: 949843336.1350\n",
      "Epoch 8359/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 967372608.8014 - val_loss: 1327353665.4942\n",
      "Epoch 8360/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 385724858.2645 - val_loss: 665560317.0385\n",
      "Epoch 8361/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 127788304.6640 - val_loss: 668037283.9539\n",
      "Epoch 8362/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 116705060.3939 - val_loss: 638471217.5662\n",
      "Epoch 8363/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 163051552.9814 - val_loss: 687719638.9446\n",
      "Epoch 8364/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 677344017.4721 - val_loss: 991240246.2605\n",
      "Epoch 8365/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 137838634.9848 - val_loss: 895751983.8155\n",
      "Epoch 8366/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 169706840.8149 - val_loss: 650270729.3322\n",
      "Epoch 8367/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 137003248.6753 - val_loss: 1006153094.9131\n",
      "Epoch 8368/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 122773282.8137 - val_loss: 879698425.4470\n",
      "Epoch 8369/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 369387823.1806 - val_loss: 1081280246.6025\n",
      "Epoch 8370/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 902946400.1621 - val_loss: 821030303.9280\n",
      "Epoch 8371/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 190551113.0467 - val_loss: 629374368.6155\n",
      "Epoch 8372/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 225231156.0698 - val_loss: 972783221.9364\n",
      "Epoch 8373/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 397366215.8154 - val_loss: 5513119455.9010\n",
      "Epoch 8374/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 2790074958.9465 - val_loss: 1260995596.4579\n",
      "Epoch 8375/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 226611848.8621 - val_loss: 1693299163.6276\n",
      "Epoch 8376/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 307117339.6624 - val_loss: 830153462.6970\n",
      "Epoch 8377/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 134223063.2662 - val_loss: 1084074605.6641\n",
      "Epoch 8378/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 239462240.4142 - val_loss: 641775610.2729\n",
      "Epoch 8379/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 108718010.7845 - val_loss: 920037787.2203\n",
      "Epoch 8380/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 112063776.0293 - val_loss: 637614384.4534\n",
      "Epoch 8381/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 128572313.7062 - val_loss: 768501429.0183\n",
      "Epoch 8382/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 365204532.0822 - val_loss: 990344540.3544\n",
      "Epoch 8383/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 174665545.0490 - val_loss: 747076398.1232\n",
      "Epoch 8384/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 216327935.0276 - val_loss: 1871825479.8672\n",
      "Epoch 8385/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 390222729.6702 - val_loss: 720045205.0903\n",
      "Epoch 8386/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 170588183.5003 - val_loss: 689466868.8788\n",
      "Epoch 8387/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 225815455.4947 - val_loss: 810172975.8245\n",
      "Epoch 8388/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 100987292.2110 - val_loss: 735551576.5986\n",
      "Epoch 8389/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 114470917.1187 - val_loss: 932896853.6394\n",
      "Epoch 8390/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 568588802.0619 - val_loss: 762380620.3792\n",
      "Epoch 8391/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 164868021.6185 - val_loss: 1133844337.6068\n",
      "Epoch 8392/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 966564482.0529 - val_loss: 1436768162.2414\n",
      "Epoch 8393/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 288504932.3759 - val_loss: 2186687237.5269\n",
      "Epoch 8394/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 273851346.1880 - val_loss: 1456067031.0931\n",
      "Epoch 8395/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 264917606.5819 - val_loss: 1471609382.1840\n",
      "Epoch 8396/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 199561394.8362 - val_loss: 847708498.3044\n",
      "Epoch 8397/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 418069247.7710 - val_loss: 698761443.0312\n",
      "Epoch 8398/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 357722778.7822 - val_loss: 1117879964.4399\n",
      "Epoch 8399/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 456608357.5284 - val_loss: 3188533009.3547\n",
      "Epoch 8400/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 87us/step - loss: 553047523.3405 - val_loss: 789882642.3629\n",
      "Epoch 8401/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 188031401.5982 - val_loss: 1748423989.1803\n",
      "Epoch 8402/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 433166270.4873 - val_loss: 778534408.3938\n",
      "Epoch 8403/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 117649088.5853 - val_loss: 723314843.5195\n",
      "Epoch 8404/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 125493469.3281 - val_loss: 626615537.1724\n",
      "Epoch 8405/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 220545647.8109 - val_loss: 1116464060.0304\n",
      "Epoch 8406/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 250548142.3185 - val_loss: 719750056.1103\n",
      "Epoch 8407/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 231219791.2797 - val_loss: 1176059360.5311\n",
      "Epoch 8408/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 597327112.3557 - val_loss: 2281135324.4264\n",
      "Epoch 8409/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1125993047.7839 - val_loss: 742310946.3809\n",
      "Epoch 8410/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 189843525.7625 - val_loss: 869887749.1668\n",
      "Epoch 8411/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 210444106.8858 - val_loss: 710173943.1516\n",
      "Epoch 8412/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 234103930.7226 - val_loss: 971552538.5947\n",
      "Epoch 8413/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 227571633.0355 - val_loss: 956754365.0385\n",
      "Epoch 8414/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 218531506.7476 - val_loss: 1045853304.5705\n",
      "Epoch 8415/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 146824426.5436 - val_loss: 1065035048.7764\n",
      "Epoch 8416/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 596963384.0473 - val_loss: 862311079.8087\n",
      "Epoch 8417/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 272983148.9972 - val_loss: 783113669.5584\n",
      "Epoch 8418/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 198497026.4091 - val_loss: 904728110.5913\n",
      "Epoch 8419/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 250398120.9499 - val_loss: 1116487267.3305\n",
      "Epoch 8420/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 438130801.9629 - val_loss: 769971335.9077\n",
      "Epoch 8421/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 247997005.4249 - val_loss: 1549001404.9215\n",
      "Epoch 8422/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 258604087.5993 - val_loss: 696214828.6897\n",
      "Epoch 8423/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 271942394.7710 - val_loss: 913848111.2416\n",
      "Epoch 8424/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 380164011.7051 - val_loss: 769272436.4872\n",
      "Epoch 8425/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 250164572.6325 - val_loss: 1152924987.3733\n",
      "Epoch 8426/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 835749373.5149 - val_loss: 810971874.5744\n",
      "Epoch 8427/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 223097077.6185 - val_loss: 1599778537.9646\n",
      "Epoch 8428/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 346325609.5262 - val_loss: 993067151.4284\n",
      "Epoch 8429/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 471567689.2425 - val_loss: 656737304.6819\n",
      "Epoch 8430/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 175285559.9010 - val_loss: 955278689.4402\n",
      "Epoch 8431/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 404390577.1210 - val_loss: 1143433622.7376\n",
      "Epoch 8432/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 805704571.1199 - val_loss: 729812112.3421\n",
      "Epoch 8433/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 216692835.2380 - val_loss: 801635842.3764\n",
      "Epoch 8434/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 270101813.0017 - val_loss: 1021681005.2231\n",
      "Epoch 8435/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 538045616.8554 - val_loss: 1139873535.2484\n",
      "Epoch 8436/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 210313624.4457 - val_loss: 1234315725.0543\n",
      "Epoch 8437/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 169263563.2144 - val_loss: 1034842507.7783\n",
      "Epoch 8438/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 134024088.7608 - val_loss: 873853416.2183\n",
      "Epoch 8439/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 282823638.0416 - val_loss: 1358612522.9120\n",
      "Epoch 8440/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 986479597.4339 - val_loss: 838320743.8447\n",
      "Epoch 8441/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 286400034.8633 - val_loss: 2514568875.9269\n",
      "Epoch 8442/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 720442052.3579 - val_loss: 5541851307.7828\n",
      "Epoch 8443/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 695594071.6154 - val_loss: 643345339.3992\n",
      "Epoch 8444/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 83107154.7203 - val_loss: 692649447.6489\n",
      "Epoch 8445/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 123039081.5802 - val_loss: 650725047.8717\n",
      "Epoch 8446/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 132544887.4463 - val_loss: 1472171969.2782\n",
      "Epoch 8447/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 235860818.9128 - val_loss: 1026440930.8186\n",
      "Epoch 8448/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 221856615.8188 - val_loss: 700027812.7437\n",
      "Epoch 8449/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 135302196.0653 - val_loss: 629413501.5387\n",
      "Epoch 8450/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 242662131.7952 - val_loss: 716593342.7004\n",
      "Epoch 8451/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 456203027.0703 - val_loss: 4158501050.0051\n",
      "Epoch 8452/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1056480743.7974 - val_loss: 12013687895.9977\n",
      "Epoch 8453/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1927479966.7394 - val_loss: 694814904.2453\n",
      "Epoch 8454/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 122932707.5340 - val_loss: 626749955.1865\n",
      "Epoch 8455/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 155093211.4080 - val_loss: 1777943771.4183\n",
      "Epoch 8456/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 154535081.2335 - val_loss: 1497303820.0619\n",
      "Epoch 8457/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 171349073.9088 - val_loss: 754321425.0307\n",
      "Epoch 8458/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 111588714.5886 - val_loss: 851606144.1035\n",
      "Epoch 8459/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 111051356.2183 - val_loss: 635263590.3910\n",
      "Epoch 8460/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 211250261.6635 - val_loss: 1573356603.7693\n",
      "Epoch 8461/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 371507147.2684 - val_loss: 789969502.6318\n",
      "Epoch 8462/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 479326206.6314 - val_loss: 717854149.9893\n",
      "Epoch 8463/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 236238023.0377 - val_loss: 854828745.5595\n",
      "Epoch 8464/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 263938248.4817 - val_loss: 678102104.6706\n",
      "Epoch 8465/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 652811521.1131 - val_loss: 1801277064.3533\n",
      "Epoch 8466/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 305143887.9190 - val_loss: 706018257.8408\n",
      "Epoch 8467/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 266609914.4536 - val_loss: 745432880.8034\n",
      "Epoch 8468/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 212699256.8239 - val_loss: 2729143900.4624\n",
      "Epoch 8469/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 502906595.6196 - val_loss: 3513935671.4127\n",
      "Epoch 8470/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 846719141.9066 - val_loss: 700252868.2757\n",
      "Epoch 8471/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 100911170.0990 - val_loss: 616565729.6709\n",
      "Epoch 8472/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 98354301.2425 - val_loss: 754525740.7955\n",
      "Epoch 8473/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 465516458.4986 - val_loss: 2558412500.3612\n",
      "Epoch 8474/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 735099109.5869 - val_loss: 1265910920.4973\n",
      "Epoch 8475/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 226624533.0917 - val_loss: 852385765.2838\n",
      "Epoch 8476/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 245213680.1306 - val_loss: 698273622.5193\n",
      "Epoch 8477/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 272719679.9460 - val_loss: 2743739694.8613\n",
      "Epoch 8478/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 990044288.9364 - val_loss: 2015065418.2436\n",
      "Epoch 8479/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 615290559.1536 - val_loss: 975789473.9533\n",
      "Epoch 8480/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 231304221.0827 - val_loss: 709178179.3035\n",
      "Epoch 8481/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 104955085.1919 - val_loss: 872111968.3803\n",
      "Epoch 8482/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 215187797.2043 - val_loss: 1327312801.3727\n",
      "Epoch 8483/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 137829533.4789 - val_loss: 938709596.9677\n",
      "Epoch 8484/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 212463994.6111 - val_loss: 651910142.0647\n",
      "Epoch 8485/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 120573953.0290 - val_loss: 634952302.2672\n",
      "Epoch 8486/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 89049592.5920 - val_loss: 632383168.6031\n",
      "Epoch 8487/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 93844401.7963 - val_loss: 1172071434.2976\n",
      "Epoch 8488/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 220797863.6784 - val_loss: 816598941.7496\n",
      "Epoch 8489/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 189763510.8149 - val_loss: 2720245668.5277\n",
      "Epoch 8490/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 851400461.9066 - val_loss: 1460834729.3952\n",
      "Epoch 8491/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 921273191.7929 - val_loss: 667270617.9837\n",
      "Epoch 8492/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 529791961.8663 - val_loss: 719831413.0363\n",
      "Epoch 8493/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 169220133.2403 - val_loss: 7084575670.6205\n",
      "Epoch 8494/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 842891728.2285 - val_loss: 1067613244.2824\n",
      "Epoch 8495/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 163235850.9758 - val_loss: 792114282.8062\n",
      "Epoch 8496/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 182273605.7670 - val_loss: 704198462.5283\n",
      "Epoch 8497/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 124987608.8216 - val_loss: 743592442.7837\n",
      "Epoch 8498/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 342191260.0383 - val_loss: 2140219273.4695\n",
      "Epoch 8499/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1298406787.1694 - val_loss: 692033716.9148\n",
      "Epoch 8500/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 200984847.0051 - val_loss: 804092363.8706\n",
      "Epoch 8501/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 175901869.3979 - val_loss: 1633312722.7769\n",
      "Epoch 8502/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 238662178.8568 - val_loss: 634632779.1212\n",
      "Epoch 8503/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 160031026.2465 - val_loss: 677026685.4661\n",
      "Epoch 8504/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 169740733.8706 - val_loss: 666458525.0475\n",
      "Epoch 8505/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 156909861.3196 - val_loss: 830219413.3367\n",
      "Epoch 8506/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 295562445.5779 - val_loss: 1407430460.2734\n",
      "Epoch 8507/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 738250798.8385 - val_loss: 1919624417.6023\n",
      "Epoch 8508/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 294503119.4373 - val_loss: 3394097924.3207\n",
      "Epoch 8509/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 764091861.1412 - val_loss: 2673768376.8529\n",
      "Epoch 8510/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1235900195.4305 - val_loss: 1131450304.3781\n",
      "Epoch 8511/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 210759251.0884 - val_loss: 871639650.8534\n",
      "Epoch 8512/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 159682955.7276 - val_loss: 744923307.1527\n",
      "Epoch 8513/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 188531160.1576 - val_loss: 709608503.0256\n",
      "Epoch 8514/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 232641697.7783 - val_loss: 669957870.3167\n",
      "Epoch 8515/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 133464593.6702 - val_loss: 689660296.0349\n",
      "Epoch 8516/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 236293871.7096 - val_loss: 831328865.8633\n",
      "Epoch 8517/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 198230404.2679 - val_loss: 673623181.6821\n",
      "Epoch 8518/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 133691281.7017 - val_loss: 666464509.0183\n",
      "Epoch 8519/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 175139354.8700 - val_loss: 1035615923.7491\n",
      "Epoch 8520/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 275132000.2971 - val_loss: 977559111.3722\n",
      "Epoch 8521/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 613171583.9280 - val_loss: 1035629751.4543\n",
      "Epoch 8522/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 972546155.2189 - val_loss: 1054929924.6807\n",
      "Epoch 8523/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 485571746.1429 - val_loss: 1233075999.3564\n",
      "Epoch 8524/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 389327411.5566 - val_loss: 711326101.3412\n",
      "Epoch 8525/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 178569837.5599 - val_loss: 941612796.6672\n",
      "Epoch 8526/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 186375926.3028 - val_loss: 1154261305.0869\n",
      "Epoch 8527/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 127524167.0186 - val_loss: 673582025.6624\n",
      "Epoch 8528/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 193947960.5267 - val_loss: 849971365.3198\n",
      "Epoch 8529/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 522424023.5003 - val_loss: 798948258.6374\n",
      "Epoch 8530/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 88us/step - loss: 416643240.2206 - val_loss: 859996832.6031\n",
      "Epoch 8531/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 310724701.2088 - val_loss: 999331733.1916\n",
      "Epoch 8532/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 196388294.1317 - val_loss: 715745598.3167\n",
      "Epoch 8533/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 147486269.7940 - val_loss: 831153266.3854\n",
      "Epoch 8534/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 654692628.4750 - val_loss: 836219074.1423\n",
      "Epoch 8535/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 267716775.1761 - val_loss: 893221838.0782\n",
      "Epoch 8536/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 225719333.4519 - val_loss: 1148496317.0205\n",
      "Epoch 8537/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 311635368.8059 - val_loss: 932096702.3617\n",
      "Epoch 8538/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 698302469.5059 - val_loss: 1160436150.4225\n",
      "Epoch 8539/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 263359857.9584 - val_loss: 693847334.3111\n",
      "Epoch 8540/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 209764192.5222 - val_loss: 925014817.4852\n",
      "Epoch 8541/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 349540934.0146 - val_loss: 1584803059.7941\n",
      "Epoch 8542/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 248895322.4716 - val_loss: 634462936.0405\n",
      "Epoch 8543/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 118120213.6545 - val_loss: 798382038.0714\n",
      "Epoch 8544/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 285090087.7704 - val_loss: 1077134714.5812\n",
      "Epoch 8545/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 371376050.4041 - val_loss: 4749532956.8045\n",
      "Epoch 8546/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1168877775.6038 - val_loss: 710930973.0138\n",
      "Epoch 8547/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 131640450.2240 - val_loss: 707823809.3941\n",
      "Epoch 8548/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 98274421.4294 - val_loss: 2000084193.4312\n",
      "Epoch 8549/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 246623347.1874 - val_loss: 844241433.4200\n",
      "Epoch 8550/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 221633662.1992 - val_loss: 706151469.7412\n",
      "Epoch 8551/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 295160127.7434 - val_loss: 1118055668.2262\n",
      "Epoch 8552/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 264722829.8402 - val_loss: 740154751.7187\n",
      "Epoch 8553/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 492928858.1835 - val_loss: 922897246.3077\n",
      "Epoch 8554/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1753207076.1125 - val_loss: 1042171873.5257\n",
      "Epoch 8555/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 207354153.3663 - val_loss: 796551315.8256\n",
      "Epoch 8556/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 89708371.6702 - val_loss: 655110334.0872\n",
      "Epoch 8557/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 101000628.6911 - val_loss: 772484790.1075\n",
      "Epoch 8558/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 371662797.3618 - val_loss: 1313092857.8917\n",
      "Epoch 8559/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 444949957.1652 - val_loss: 726949682.1738\n",
      "Epoch 8560/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 127495848.5492 - val_loss: 773069361.7418\n",
      "Epoch 8561/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 143894545.5853 - val_loss: 675268083.8436\n",
      "Epoch 8562/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 226589063.3112 - val_loss: 1235925720.4838\n",
      "Epoch 8563/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 322019848.6798 - val_loss: 642413166.4653\n",
      "Epoch 8564/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 369416846.9105 - val_loss: 14459926351.4284\n",
      "Epoch 8565/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2968534020.7541 - val_loss: 969878330.9862\n",
      "Epoch 8566/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 235077080.9319 - val_loss: 719294228.2577\n",
      "Epoch 8567/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 93338646.5549 - val_loss: 967778030.3887\n",
      "Epoch 8568/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 137568799.5498 - val_loss: 731454397.3851\n",
      "Epoch 8569/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 117473413.3483 - val_loss: 668425311.7817\n",
      "Epoch 8570/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 113113767.5003 - val_loss: 756466101.0633\n",
      "Epoch 8571/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 132420603.8424 - val_loss: 1122441952.0090\n",
      "Epoch 8572/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 128040292.7361 - val_loss: 700530156.9530\n",
      "Epoch 8573/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 113140678.1947 - val_loss: 1018570244.6447\n",
      "Epoch 8574/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 475476369.5397 - val_loss: 727868073.9882\n",
      "Epoch 8575/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 254038640.5492 - val_loss: 1296267300.4557\n",
      "Epoch 8576/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 935960808.4277 - val_loss: 717016082.2340\n",
      "Epoch 8577/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 247423792.8374 - val_loss: 651853722.8512\n",
      "Epoch 8578/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 166415645.0107 - val_loss: 776090310.4720\n",
      "Epoch 8579/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 149411397.6635 - val_loss: 656968338.6869\n",
      "Epoch 8580/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 173173662.4086 - val_loss: 723918888.2723\n",
      "Epoch 8581/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 147471405.0658 - val_loss: 686206927.5679\n",
      "Epoch 8582/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 126408927.9685 - val_loss: 702884424.1350\n",
      "Epoch 8583/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 182824179.0461 - val_loss: 695075915.0357\n",
      "Epoch 8584/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 377423183.8469 - val_loss: 894199165.1556\n",
      "Epoch 8585/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1777039041.9088 - val_loss: 4121893300.7482\n",
      "Epoch 8586/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 632108811.0028 - val_loss: 1477305867.0357\n",
      "Epoch 8587/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 231955931.2639 - val_loss: 704484870.0174\n",
      "Epoch 8588/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 115739998.1857 - val_loss: 826525812.0101\n",
      "Epoch 8589/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 210921289.0219 - val_loss: 975972635.2113\n",
      "Epoch 8590/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 210797791.6702 - val_loss: 881419944.0563\n",
      "Epoch 8591/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 113860805.6365 - val_loss: 1063473291.1100\n",
      "Epoch 8592/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 155465732.2589 - val_loss: 1681316762.4821\n",
      "Epoch 8593/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 769790137.4902 - val_loss: 1782074251.7558\n",
      "Epoch 8594/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 448793962.0664 - val_loss: 989549285.4459\n",
      "Epoch 8595/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 261949106.1609 - val_loss: 1786916681.5235\n",
      "Epoch 8596/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 686576415.4778 - val_loss: 1653582298.8962\n",
      "Epoch 8597/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 633856621.2358 - val_loss: 1108866590.1007\n",
      "Epoch 8598/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 227846041.4811 - val_loss: 1230298388.5412\n",
      "Epoch 8599/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 217140235.2572 - val_loss: 1561886510.9153\n",
      "Epoch 8600/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 273415959.5903 - val_loss: 1745104132.9328\n",
      "Epoch 8601/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 535790034.9263 - val_loss: 694101039.8020\n",
      "Epoch 8602/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 253909602.0439 - val_loss: 1455210823.6006\n",
      "Epoch 8603/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 376218444.1013 - val_loss: 1007098024.6504\n",
      "Epoch 8604/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 238669182.8835 - val_loss: 955656422.5125\n",
      "Epoch 8605/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 309556143.9145 - val_loss: 1853238348.1677\n",
      "Epoch 8606/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 451924436.9026 - val_loss: 1351645390.7623\n",
      "Epoch 8607/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 135134282.9178 - val_loss: 665613736.7629\n",
      "Epoch 8608/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 117477766.3230 - val_loss: 661563883.5848\n",
      "Epoch 8609/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 220697732.6325 - val_loss: 1254562011.6163\n",
      "Epoch 8610/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 388476635.9122 - val_loss: 1361439094.0534\n",
      "Epoch 8611/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 237801602.7192 - val_loss: 697283364.8383\n",
      "Epoch 8612/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 588521122.3770 - val_loss: 770852013.4166\n",
      "Epoch 8613/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 310846706.2060 - val_loss: 2425948678.5350\n",
      "Epoch 8614/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 2134877085.2268 - val_loss: 909069412.1046\n",
      "Epoch 8615/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 151509218.4851 - val_loss: 762988423.1111\n",
      "Epoch 8616/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 288579304.4457 - val_loss: 1910647623.7232\n",
      "Epoch 8617/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 192048512.3602 - val_loss: 851370468.5232\n",
      "Epoch 8618/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 122586939.9268 - val_loss: 810410698.0028\n",
      "Epoch 8619/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 122511303.6579 - val_loss: 650868850.0591\n",
      "Epoch 8620/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 96842833.7524 - val_loss: 996796900.0056\n",
      "Epoch 8621/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 295177093.9516 - val_loss: 878944434.9210\n",
      "Epoch 8622/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 205686163.5363 - val_loss: 1238680329.4785\n",
      "Epoch 8623/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 190910003.9370 - val_loss: 1398974866.4034\n",
      "Epoch 8624/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 411532706.3950 - val_loss: 2189572932.5907\n",
      "Epoch 8625/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 871514266.7777 - val_loss: 686953843.8751\n",
      "Epoch 8626/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 379090650.5436 - val_loss: 985274430.3662\n",
      "Epoch 8627/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 248928649.1393 - val_loss: 708051352.0360\n",
      "Epoch 8628/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 152624309.5802 - val_loss: 1680477179.7333\n",
      "Epoch 8629/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 135777047.0968 - val_loss: 1141180567.1156\n",
      "Epoch 8630/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 296355676.1643 - val_loss: 2832379495.0301\n",
      "Epoch 8631/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 763738377.7963 - val_loss: 765656464.4546\n",
      "Epoch 8632/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 171322248.0225 - val_loss: 1497799593.6495\n",
      "Epoch 8633/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 310290148.6528 - val_loss: 719608254.5328\n",
      "Epoch 8634/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 473654797.5059 - val_loss: 3240928208.6166\n",
      "Epoch 8635/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1274394670.5324 - val_loss: 1022740825.2759\n",
      "Epoch 8636/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 756547492.2150 - val_loss: 1063360884.7302\n",
      "Epoch 8637/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 183934428.9522 - val_loss: 1238642011.8774\n",
      "Epoch 8638/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 508927798.6967 - val_loss: 945847501.9612\n",
      "Epoch 8639/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 127118407.5532 - val_loss: 739194872.0383\n",
      "Epoch 8640/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 322541541.8886 - val_loss: 997662851.8031\n",
      "Epoch 8641/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 143185294.8565 - val_loss: 678815296.6639\n",
      "Epoch 8642/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 165045652.3489 - val_loss: 762864351.0380\n",
      "Epoch 8643/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 164396864.9004 - val_loss: 713311657.4605\n",
      "Epoch 8644/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 488825010.0349 - val_loss: 1745210952.2633\n",
      "Epoch 8645/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 323109321.2527 - val_loss: 1333337043.3440\n",
      "Epoch 8646/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 339971527.5183 - val_loss: 646383649.1342\n",
      "Epoch 8647/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 682181585.6117 - val_loss: 1443380994.0703\n",
      "Epoch 8648/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 954087689.5622 - val_loss: 849379720.3713\n",
      "Epoch 8649/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 139820029.1007 - val_loss: 652989894.1570\n",
      "Epoch 8650/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 99149447.7974 - val_loss: 689105724.6740\n",
      "Epoch 8651/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 218415775.8379 - val_loss: 901531828.8653\n",
      "Epoch 8652/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 165238316.2634 - val_loss: 955251662.9423\n",
      "Epoch 8653/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 172053674.8227 - val_loss: 1206017976.3308\n",
      "Epoch 8654/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 784201677.6545 - val_loss: 691087082.4371\n",
      "Epoch 8655/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 83523546.5706 - val_loss: 696981112.7842\n",
      "Epoch 8656/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 590333042.9533 - val_loss: 746423654.0399\n",
      "Epoch 8657/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 169674928.1891 - val_loss: 1664273482.7117\n",
      "Epoch 8658/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 179919818.3815 - val_loss: 1143635542.0895\n",
      "Epoch 8659/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 167073110.9420 - val_loss: 1417261075.8211\n",
      "Epoch 8660/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 88us/step - loss: 524381458.1407 - val_loss: 689855494.7215\n",
      "Epoch 8661/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 196394998.6269 - val_loss: 728677808.7831\n",
      "Epoch 8662/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 222508612.6100 - val_loss: 764867659.7918\n",
      "Epoch 8663/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1070477946.7327 - val_loss: 3391657557.2613\n",
      "Epoch 8664/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 703304779.1469 - val_loss: 853102551.1426\n",
      "Epoch 8665/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 212529667.6196 - val_loss: 966606545.0127\n",
      "Epoch 8666/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 191760194.3860 - val_loss: 932089213.8442\n",
      "Epoch 8667/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 215264161.4226 - val_loss: 1240030388.9103\n",
      "Epoch 8668/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 385547157.3934 - val_loss: 652963400.0270\n",
      "Epoch 8669/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 604899226.0394 - val_loss: 1532583001.9060\n",
      "Epoch 8670/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 233943027.6826 - val_loss: 632615598.0557\n",
      "Epoch 8671/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 129144255.8402 - val_loss: 728617380.2757\n",
      "Epoch 8672/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 282100674.3770 - val_loss: 2271031211.0087\n",
      "Epoch 8673/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 299334841.2831 - val_loss: 1356221274.0501\n",
      "Epoch 8674/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 284264033.2065 - val_loss: 669445462.5755\n",
      "Epoch 8675/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 141684634.3905 - val_loss: 685102874.0681\n",
      "Epoch 8676/10000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 863909819.8402 - val_loss: 1322175255.7637\n",
      "Epoch 8677/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 337117261.1548 - val_loss: 1056497420.9755\n",
      "Epoch 8678/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 253852931.4575 - val_loss: 750783942.8411\n",
      "Epoch 8679/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 134251724.0743 - val_loss: 653950728.5153\n",
      "Epoch 8680/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 110339507.9977 - val_loss: 1147367229.1736\n",
      "Epoch 8681/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 447435576.6528 - val_loss: 939574845.9657\n",
      "Epoch 8682/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 740891023.2797 - val_loss: 995326512.8619\n",
      "Epoch 8683/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 174343336.3196 - val_loss: 847618352.3105\n",
      "Epoch 8684/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 153358497.8548 - val_loss: 881663546.1581\n",
      "Epoch 8685/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 164808379.8672 - val_loss: 852101109.1128\n",
      "Epoch 8686/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 367265728.9904 - val_loss: 1432982861.3851\n",
      "Epoch 8687/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 771060117.0692 - val_loss: 1752521322.2346\n",
      "Epoch 8688/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 416060680.6033 - val_loss: 962821475.9246\n",
      "Epoch 8689/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 173821919.1896 - val_loss: 1007204445.6146\n",
      "Epoch 8690/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 324839961.2425 - val_loss: 1389714353.1319\n",
      "Epoch 8691/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 239426841.9944 - val_loss: 1107653784.8439\n",
      "Epoch 8692/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 286420092.0743 - val_loss: 708793408.6098\n",
      "Epoch 8693/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 182049380.6449 - val_loss: 761854952.7584\n",
      "Epoch 8694/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 251022723.6916 - val_loss: 788639678.7578\n",
      "Epoch 8695/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 219818541.5239 - val_loss: 2471936373.6664\n",
      "Epoch 8696/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 667803147.3472 - val_loss: 693937438.8636\n",
      "Epoch 8697/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 132934185.1840 - val_loss: 939499478.1615\n",
      "Epoch 8698/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 132375389.5082 - val_loss: 634389841.8880\n",
      "Epoch 8699/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 293095392.4502 - val_loss: 1360568613.2118\n",
      "Epoch 8700/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 514297818.9645 - val_loss: 1004067747.7266\n",
      "Epoch 8701/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 163883210.6145 - val_loss: 1312915820.5750\n",
      "Epoch 8702/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 364296024.4007 - val_loss: 943727146.6397\n",
      "Epoch 8703/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 411181370.3275 - val_loss: 855110692.8428\n",
      "Epoch 8704/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 516117251.0073 - val_loss: 1125105048.6909\n",
      "Epoch 8705/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 405830107.8762 - val_loss: 1392805502.8838\n",
      "Epoch 8706/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 510925585.4856 - val_loss: 1209475450.5902\n",
      "Epoch 8707/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 419781138.2960 - val_loss: 677834702.9705\n",
      "Epoch 8708/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 174575757.2943 - val_loss: 1365649939.1550\n",
      "Epoch 8709/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 274824150.4738 - val_loss: 959850027.4588\n",
      "Epoch 8710/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 229502247.9460 - val_loss: 855960147.0560\n",
      "Epoch 8711/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 89804128.6303 - val_loss: 714472067.9696\n",
      "Epoch 8712/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 154804826.8768 - val_loss: 645836262.7466\n",
      "Epoch 8713/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 353229898.2645 - val_loss: 1786713580.3229\n",
      "Epoch 8714/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1212707878.3860 - val_loss: 1700374974.1637\n",
      "Epoch 8715/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 200008741.9854 - val_loss: 736538627.5015\n",
      "Epoch 8716/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 109348524.1148 - val_loss: 888840946.1918\n",
      "Epoch 8717/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 117888687.1289 - val_loss: 1251962496.6841\n",
      "Epoch 8718/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 201615817.6342 - val_loss: 1732227249.2197\n",
      "Epoch 8719/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 520173964.6775 - val_loss: 1640045594.6262\n",
      "Epoch 8720/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1031221724.2724 - val_loss: 803398840.4793\n",
      "Epoch 8721/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 112634069.9403 - val_loss: 670216682.8827\n",
      "Epoch 8722/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 112339180.6156 - val_loss: 660106450.8129\n",
      "Epoch 8723/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 110780967.0748 - val_loss: 873353250.4844\n",
      "Epoch 8724/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 169981319.9595 - val_loss: 964997870.9693\n",
      "Epoch 8725/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 761941642.0124 - val_loss: 14140809834.8647\n",
      "Epoch 8726/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 1711967144.9139 - val_loss: 728702895.4368\n",
      "Epoch 8727/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 161451166.4176 - val_loss: 673866689.7665\n",
      "Epoch 8728/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 87323922.4581 - val_loss: 1174811095.4397\n",
      "Epoch 8729/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 102110126.0371 - val_loss: 1115430640.8866\n",
      "Epoch 8730/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 288271649.9629 - val_loss: 795024684.9620\n",
      "Epoch 8731/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 271130676.2544 - val_loss: 782317358.0512\n",
      "Epoch 8732/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 242774234.1835 - val_loss: 771324751.6534\n",
      "Epoch 8733/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 364907120.7366 - val_loss: 784010418.8489\n",
      "Epoch 8734/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 147371147.1649 - val_loss: 699743414.0174\n",
      "Epoch 8735/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 219426519.1941 - val_loss: 3556392973.0340\n",
      "Epoch 8736/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 2799624315.1896 - val_loss: 935862191.5589\n",
      "Epoch 8737/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 153866627.3281 - val_loss: 1092233950.7792\n",
      "Epoch 8738/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 190826926.4513 - val_loss: 633073575.5252\n",
      "Epoch 8739/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 91885958.8745 - val_loss: 911176147.8481\n",
      "Epoch 8740/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 113166475.3562 - val_loss: 1017967468.8135\n",
      "Epoch 8741/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 134067554.6258 - val_loss: 1884527033.8250\n",
      "Epoch 8742/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 215121460.3219 - val_loss: 1178657668.9665\n",
      "Epoch 8743/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 202281105.7198 - val_loss: 3031342478.6543\n",
      "Epoch 8744/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 549740736.8014 - val_loss: 989125407.3879\n",
      "Epoch 8745/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 257150203.6877 - val_loss: 778729234.5204\n",
      "Epoch 8746/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 270969539.0523 - val_loss: 1422246284.6740\n",
      "Epoch 8747/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 147921413.9516 - val_loss: 996586641.4582\n",
      "Epoch 8748/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 254637045.8075 - val_loss: 1450154161.6518\n",
      "Epoch 8749/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 258725583.4511 - val_loss: 810482775.8897\n",
      "Epoch 8750/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 130738888.5898 - val_loss: 721443339.1257\n",
      "Epoch 8751/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 224360730.1294 - val_loss: 3541986174.2357\n",
      "Epoch 8752/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 545070403.1064 - val_loss: 881440899.6096\n",
      "Epoch 8753/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 441196847.5566 - val_loss: 1133200721.4627\n",
      "Epoch 8754/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 243095168.4322 - val_loss: 681596594.9075\n",
      "Epoch 8755/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 425225677.4249 - val_loss: 1015356186.4281\n",
      "Epoch 8756/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 146934259.5205 - val_loss: 680781556.8203\n",
      "Epoch 8757/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 159319171.9617 - val_loss: 1110909918.6768\n",
      "Epoch 8758/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 551332807.8154 - val_loss: 944428633.8430\n",
      "Epoch 8759/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 199852356.9702 - val_loss: 1867735133.3086\n",
      "Epoch 8760/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1234692858.3095 - val_loss: 825464104.9744\n",
      "Epoch 8761/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 235579977.0805 - val_loss: 1028920555.3238\n",
      "Epoch 8762/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 165678808.3106 - val_loss: 1234057816.4478\n",
      "Epoch 8763/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 206513168.9961 - val_loss: 759382360.5198\n",
      "Epoch 8764/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 108943505.9719 - val_loss: 674833734.0624\n",
      "Epoch 8765/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 206846353.4924 - val_loss: 660311654.4270\n",
      "Epoch 8766/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 456188081.5307 - val_loss: 669827524.8473\n",
      "Epoch 8767/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 116842131.4575 - val_loss: 1048482862.9131\n",
      "Epoch 8768/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 152438234.6517 - val_loss: 917164811.0987\n",
      "Epoch 8769/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 350881241.5712 - val_loss: 1510871384.3398\n",
      "Epoch 8770/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 179509561.0670 - val_loss: 1249047012.8473\n",
      "Epoch 8771/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 382378813.8751 - val_loss: 1870955242.0726\n",
      "Epoch 8772/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2426857450.1024 - val_loss: 1204643501.1871\n",
      "Epoch 8773/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 309514536.9274 - val_loss: 1114965071.8245\n",
      "Epoch 8774/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 174772263.5093 - val_loss: 709521487.7063\n",
      "Epoch 8775/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 177818549.6972 - val_loss: 1455790405.2028\n",
      "Epoch 8776/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 192179748.6685 - val_loss: 787412816.4906\n",
      "Epoch 8777/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 128357737.4012 - val_loss: 655365725.6731\n",
      "Epoch 8778/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 165748589.1390 - val_loss: 1020249473.1162\n",
      "Epoch 8779/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 674463377.8458 - val_loss: 937558606.1592\n",
      "Epoch 8780/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 445369834.8970 - val_loss: 981789995.7626\n",
      "Epoch 8781/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 98628590.0506 - val_loss: 724758639.1606\n",
      "Epoch 8782/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 94759907.9572 - val_loss: 778082038.1502\n",
      "Epoch 8783/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 83195705.9854 - val_loss: 1369905112.6819\n",
      "Epoch 8784/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 254231004.5245 - val_loss: 1074130201.3570\n",
      "Epoch 8785/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 376355736.8869 - val_loss: 1445626951.5207\n",
      "Epoch 8786/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 385693574.0146 - val_loss: 1819002665.9466\n",
      "Epoch 8787/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 372574915.0884 - val_loss: 1645845662.4428\n",
      "Epoch 8788/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 301956286.5504 - val_loss: 637796296.9879\n",
      "Epoch 8789/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 197026219.6511 - val_loss: 2531546766.5913\n",
      "Epoch 8790/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 95us/step - loss: 887454150.1497 - val_loss: 704761304.5378\n",
      "Epoch 8791/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 137606720.0518 - val_loss: 840083901.4301\n",
      "Epoch 8792/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 327532205.8120 - val_loss: 881062229.2613\n",
      "Epoch 8793/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 295679040.6483 - val_loss: 3708226329.8160\n",
      "Epoch 8794/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 895584609.1840 - val_loss: 694054106.9232\n",
      "Epoch 8795/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 109049235.7997 - val_loss: 703664928.6414\n",
      "Epoch 8796/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 128807518.0101 - val_loss: 1295409770.5857\n",
      "Epoch 8797/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 158643074.7755 - val_loss: 700240217.2129\n",
      "Epoch 8798/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 160050393.6500 - val_loss: 649619295.8796\n",
      "Epoch 8799/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 193775644.2589 - val_loss: 702609050.6965\n",
      "Epoch 8800/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 189043581.1998 - val_loss: 941744991.4509\n",
      "Epoch 8801/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 735321158.1587 - val_loss: 1342773455.7885\n",
      "Epoch 8802/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 323509736.7845 - val_loss: 715208909.7496\n",
      "Epoch 8803/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 181587358.7755 - val_loss: 718871693.1466\n",
      "Epoch 8804/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 200408740.8081 - val_loss: 1629452914.7184\n",
      "Epoch 8805/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 576449958.9420 - val_loss: 728929877.1111\n",
      "Epoch 8806/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 220402229.3033 - val_loss: 1134904375.0121\n",
      "Epoch 8807/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 315453829.3123 - val_loss: 676576089.8453\n",
      "Epoch 8808/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 234193979.9302 - val_loss: 689913200.6526\n",
      "Epoch 8809/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 190532810.3928 - val_loss: 665998167.5938\n",
      "Epoch 8810/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 300043996.2634 - val_loss: 968568627.4498\n",
      "Epoch 8811/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 867444513.3146 - val_loss: 3400930125.7001\n",
      "Epoch 8812/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1832684561.4316 - val_loss: 881192294.8411\n",
      "Epoch 8813/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 334143550.6055 - val_loss: 748110678.8501\n",
      "Epoch 8814/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 93845146.3995 - val_loss: 674819932.2914\n",
      "Epoch 8815/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 101010680.1576 - val_loss: 1110545197.4211\n",
      "Epoch 8816/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 137538748.1733 - val_loss: 834354675.2270\n",
      "Epoch 8817/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 297235826.6742 - val_loss: 2355471902.4248\n",
      "Epoch 8818/10000\n",
      "3554/3554 [==============================] - 1s 141us/step - loss: 673422339.5602 - val_loss: 1082602834.5249\n",
      "Epoch 8819/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 120549350.2060 - val_loss: 650855393.1612\n",
      "Epoch 8820/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 165241075.8627 - val_loss: 632561485.8025\n",
      "Epoch 8821/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 118085964.6415 - val_loss: 632596791.2591\n",
      "Epoch 8822/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 82570163.1964 - val_loss: 871925117.1601\n",
      "Epoch 8823/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 757478390.7800 - val_loss: 4226977769.5505\n",
      "Epoch 8824/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2349223394.2240 - val_loss: 715666989.3896\n",
      "Epoch 8825/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 186437357.2358 - val_loss: 1505329276.0574\n",
      "Epoch 8826/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 366960200.3106 - val_loss: 656877056.6278\n",
      "Epoch 8827/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 104881604.0428 - val_loss: 881770549.8644\n",
      "Epoch 8828/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 278781881.8818 - val_loss: 674517692.9395\n",
      "Epoch 8829/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 117414024.1756 - val_loss: 885135334.9198\n",
      "Epoch 8830/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 203875836.3849 - val_loss: 1111320715.6838\n",
      "Epoch 8831/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 164067683.5656 - val_loss: 697651547.2821\n",
      "Epoch 8832/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 107772079.3319 - val_loss: 664457057.7193\n",
      "Epoch 8833/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 160575332.9994 - val_loss: 658256138.2368\n",
      "Epoch 8834/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 166879246.1902 - val_loss: 2192108604.7145\n",
      "Epoch 8835/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 546461820.1216 - val_loss: 926536751.3789\n",
      "Epoch 8836/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 208654519.7524 - val_loss: 1221868609.6504\n",
      "Epoch 8837/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1463938047.9640 - val_loss: 1154604320.2610\n",
      "Epoch 8838/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 211234704.9274 - val_loss: 1255540479.6759\n",
      "Epoch 8839/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 330916603.8745 - val_loss: 693236260.4579\n",
      "Epoch 8840/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 231526094.8835 - val_loss: 647615143.7862\n",
      "Epoch 8841/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 87120631.9910 - val_loss: 663998874.1041\n",
      "Epoch 8842/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 204330844.3945 - val_loss: 4794396572.4084\n",
      "Epoch 8843/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1159194435.7006 - val_loss: 1368790005.0543\n",
      "Epoch 8844/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 183007907.7907 - val_loss: 826044271.9055\n",
      "Epoch 8845/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 104232563.6961 - val_loss: 652682686.6712\n",
      "Epoch 8846/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 81554849.6882 - val_loss: 698262812.3612\n",
      "Epoch 8847/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 202490094.5574 - val_loss: 644000817.6315\n",
      "Epoch 8848/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 109520315.6736 - val_loss: 1081919555.2945\n",
      "Epoch 8849/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 156415391.5318 - val_loss: 875727938.9210\n",
      "Epoch 8850/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 167263829.4114 - val_loss: 751018867.5961\n",
      "Epoch 8851/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 237243805.2606 - val_loss: 1138209650.2639\n",
      "Epoch 8852/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 142006534.2757 - val_loss: 792001516.9710\n",
      "Epoch 8853/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 532859155.7907 - val_loss: 726413377.9015\n",
      "Epoch 8854/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 956299998.7214 - val_loss: 2362275741.0565\n",
      "Epoch 8855/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 494495200.3421 - val_loss: 730387735.6174\n",
      "Epoch 8856/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 214429293.6590 - val_loss: 750867088.7291\n",
      "Epoch 8857/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 205579235.5836 - val_loss: 807638002.1378\n",
      "Epoch 8858/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 356821187.5881 - val_loss: 932320946.6824\n",
      "Epoch 8859/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 261411936.5943 - val_loss: 1634117444.8878\n",
      "Epoch 8860/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 341696502.7662 - val_loss: 662196439.5229\n",
      "Epoch 8861/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 103246029.7400 - val_loss: 727959325.8408\n",
      "Epoch 8862/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 214696540.3320 - val_loss: 2336578518.8996\n",
      "Epoch 8863/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 337623463.6905 - val_loss: 891173921.5752\n",
      "Epoch 8864/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 254788320.2791 - val_loss: 1268101933.3491\n",
      "Epoch 8865/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 446413276.6685 - val_loss: 4373916577.8453\n",
      "Epoch 8866/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 909787431.2032 - val_loss: 741592345.8565\n",
      "Epoch 8867/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 157990195.2099 - val_loss: 859724055.0796\n",
      "Epoch 8868/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 241797037.9055 - val_loss: 1011779109.1488\n",
      "Epoch 8869/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 125941590.4288 - val_loss: 805426949.0228\n",
      "Epoch 8870/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 451266806.2397 - val_loss: 1685201729.7463\n",
      "Epoch 8871/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1097964339.4305 - val_loss: 1038394750.1502\n",
      "Epoch 8872/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 211485187.3483 - val_loss: 1061380404.2082\n",
      "Epoch 8873/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 119764494.3703 - val_loss: 675668523.4025\n",
      "Epoch 8874/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 79145635.7546 - val_loss: 702436788.5862\n",
      "Epoch 8875/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 246898785.3866 - val_loss: 1224549495.3947\n",
      "Epoch 8876/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 502986080.9184 - val_loss: 1224070054.9131\n",
      "Epoch 8877/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 426607173.9944 - val_loss: 695702200.5153\n",
      "Epoch 8878/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 473692033.3011 - val_loss: 797719391.9055\n",
      "Epoch 8879/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 173684156.3984 - val_loss: 1338581941.1083\n",
      "Epoch 8880/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 316558654.7124 - val_loss: 1297882783.7052\n",
      "Epoch 8881/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 230519665.5284 - val_loss: 634138449.1994\n",
      "Epoch 8882/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 129612720.1891 - val_loss: 751977936.7606\n",
      "Epoch 8883/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1689686412.3174 - val_loss: 3298634810.4731\n",
      "Epoch 8884/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 575032307.6466 - val_loss: 709369489.8925\n",
      "Epoch 8885/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 134726489.7586 - val_loss: 709757993.9994\n",
      "Epoch 8886/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 100197396.4434 - val_loss: 879140469.5134\n",
      "Epoch 8887/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 113731984.8734 - val_loss: 707333170.5969\n",
      "Epoch 8888/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 188340847.1761 - val_loss: 656684843.3733\n",
      "Epoch 8889/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 308457346.7732 - val_loss: 711079685.6934\n",
      "Epoch 8890/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 195992439.4373 - val_loss: 740036753.0847\n",
      "Epoch 8891/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 202428336.9229 - val_loss: 1047089555.8031\n",
      "Epoch 8892/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 172301371.4935 - val_loss: 865990672.0540\n",
      "Epoch 8893/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1784643970.8813 - val_loss: 4133516138.6307\n",
      "Epoch 8894/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1304085475.6376 - val_loss: 949931100.1294\n",
      "Epoch 8895/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 209318290.7552 - val_loss: 699583975.2349\n",
      "Epoch 8896/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 72587927.0951 - val_loss: 819707004.6245\n",
      "Epoch 8897/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 147354145.6140 - val_loss: 887973565.4121\n",
      "Epoch 8898/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 94843122.1519 - val_loss: 666129104.2121\n",
      "Epoch 8899/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 111459914.2645 - val_loss: 723327205.2523\n",
      "Epoch 8900/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 294953504.0090 - val_loss: 674251278.9930\n",
      "Epoch 8901/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 774879107.9257 - val_loss: 3877756109.3761\n",
      "Epoch 8902/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1044670470.5504 - val_loss: 743990811.0987\n",
      "Epoch 8903/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 177970038.7980 - val_loss: 644137973.5066\n",
      "Epoch 8904/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 128315774.1317 - val_loss: 683148447.8931\n",
      "Epoch 8905/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 149645124.0338 - val_loss: 805423805.0745\n",
      "Epoch 8906/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 131550391.6804 - val_loss: 726300030.6610\n",
      "Epoch 8907/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 140642284.3534 - val_loss: 835280199.6602\n",
      "Epoch 8908/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 206619955.1694 - val_loss: 788822937.2501\n",
      "Epoch 8909/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 209049910.7079 - val_loss: 859568294.4180\n",
      "Epoch 8910/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 423381771.7862 - val_loss: 732213793.2602\n",
      "Epoch 8911/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 513168901.8706 - val_loss: 3885042112.0180\n",
      "Epoch 8912/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1736709939.4913 - val_loss: 696547713.7193\n",
      "Epoch 8913/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 109847448.8014 - val_loss: 984778322.6644\n",
      "Epoch 8914/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 127553058.1699 - val_loss: 1287939414.8726\n",
      "Epoch 8915/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 236528134.0687 - val_loss: 718945264.6149\n",
      "Epoch 8916/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 94722325.8751 - val_loss: 628610589.1826\n",
      "Epoch 8917/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 82929711.4282 - val_loss: 622433049.4864\n",
      "Epoch 8918/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 90745096.9071 - val_loss: 1173725875.3980\n",
      "Epoch 8919/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 394466746.2105 - val_loss: 781989518.1885\n",
      "Epoch 8920/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 97us/step - loss: 128418405.8030 - val_loss: 750280514.5519\n",
      "Epoch 8921/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 148583056.4322 - val_loss: 781568286.3707\n",
      "Epoch 8922/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 721747410.5166 - val_loss: 694767942.0759\n",
      "Epoch 8923/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 480415426.4491 - val_loss: 781988978.7139\n",
      "Epoch 8924/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 349533286.5279 - val_loss: 1537563031.4937\n",
      "Epoch 8925/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 150373294.2960 - val_loss: 931216928.9722\n",
      "Epoch 8926/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 125776439.4463 - val_loss: 1032369569.8138\n",
      "Epoch 8927/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 621681222.6629 - val_loss: 713530230.4000\n",
      "Epoch 8928/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 131763535.6725 - val_loss: 761736524.9868\n",
      "Epoch 8929/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 190064477.1773 - val_loss: 754968362.8669\n",
      "Epoch 8930/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 677545355.8672 - val_loss: 871890817.4425\n",
      "Epoch 8931/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 190931865.2313 - val_loss: 946326276.3015\n",
      "Epoch 8932/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 192544459.6691 - val_loss: 722002098.5699\n",
      "Epoch 8933/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 195938702.2847 - val_loss: 1162560757.3873\n",
      "Epoch 8934/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 817810023.4373 - val_loss: 1562593220.4287\n",
      "Epoch 8935/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 419970674.9263 - val_loss: 712271682.5271\n",
      "Epoch 8936/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 262515743.8852 - val_loss: 638146271.9471\n",
      "Epoch 8937/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 795338514.8430 - val_loss: 770117840.9316\n",
      "Epoch 8938/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 137955165.0512 - val_loss: 675510567.2821\n",
      "Epoch 8939/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 125513037.2386 - val_loss: 714898468.2295\n",
      "Epoch 8940/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 86194701.2887 - val_loss: 622148584.1851\n",
      "Epoch 8941/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 122058758.1317 - val_loss: 742555157.1173\n",
      "Epoch 8942/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 204652515.4665 - val_loss: 1086904274.5339\n",
      "Epoch 8943/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 328700473.3776 - val_loss: 1093239194.2031\n",
      "Epoch 8944/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 385321481.6140 - val_loss: 931573781.7024\n",
      "Epoch 8945/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 830158591.4328 - val_loss: 913940096.7471\n",
      "Epoch 8946/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 666714400.1261 - val_loss: 1316560214.7736\n",
      "Epoch 8947/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 479224984.6573 - val_loss: 1074443750.6070\n",
      "Epoch 8948/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 261706431.3337 - val_loss: 797179198.3949\n",
      "Epoch 8949/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 797823371.1604 - val_loss: 829953581.9274\n",
      "Epoch 8950/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 80337641.6747 - val_loss: 649179905.8937\n",
      "Epoch 8951/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 189842542.4603 - val_loss: 736363255.6489\n",
      "Epoch 8952/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 302749202.4401 - val_loss: 889296670.0973\n",
      "Epoch 8953/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 173604499.0523 - val_loss: 639986503.5308\n",
      "Epoch 8954/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 242557215.6218 - val_loss: 2619445653.2613\n",
      "Epoch 8955/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 721075711.2482 - val_loss: 644530421.3716\n",
      "Epoch 8956/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 103893436.1508 - val_loss: 715917449.5280\n",
      "Epoch 8957/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 143490166.5605 - val_loss: 649359512.1541\n",
      "Epoch 8958/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 104206487.2459 - val_loss: 661221139.9291\n",
      "Epoch 8959/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 93217619.1604 - val_loss: 728212488.3758\n",
      "Epoch 8960/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 180269362.6933 - val_loss: 750810067.2068\n",
      "Epoch 8961/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 248862526.7642 - val_loss: 643624298.7612\n",
      "Epoch 8962/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 393680824.4457 - val_loss: 1288560234.9367\n",
      "Epoch 8963/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 599833785.9944 - val_loss: 852930962.5902\n",
      "Epoch 8964/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 168865482.5976 - val_loss: 824781407.4599\n",
      "Epoch 8965/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 507932344.2386 - val_loss: 887160608.6751\n",
      "Epoch 8966/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 682065321.3821 - val_loss: 1847444417.2962\n",
      "Epoch 8967/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 224417613.7186 - val_loss: 651790692.3736\n",
      "Epoch 8968/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 88383631.3607 - val_loss: 776047862.7429\n",
      "Epoch 8969/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 106001118.1587 - val_loss: 686871846.1412\n",
      "Epoch 8970/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 183223779.2684 - val_loss: 817648073.5685\n",
      "Epoch 8971/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 148898019.5926 - val_loss: 1103429777.1207\n",
      "Epoch 8972/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 250461141.6815 - val_loss: 1110560527.3744\n",
      "Epoch 8973/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 568838566.8655 - val_loss: 970886977.6045\n",
      "Epoch 8974/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 263284535.1311 - val_loss: 859268850.5384\n",
      "Epoch 8975/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 382819887.5048 - val_loss: 653255094.6321\n",
      "Epoch 8976/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 170893920.8194 - val_loss: 622695323.4599\n",
      "Epoch 8977/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 251114106.1294 - val_loss: 1168105314.7364\n",
      "Epoch 8978/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 975050138.5256 - val_loss: 1258823042.8444\n",
      "Epoch 8979/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1273720180.2544 - val_loss: 1468770582.8456\n",
      "Epoch 8980/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 245651696.5492 - val_loss: 631872788.1992\n",
      "Epoch 8981/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 127913518.5504 - val_loss: 788810352.6076\n",
      "Epoch 8982/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 173655864.3151 - val_loss: 656541033.9443\n",
      "Epoch 8983/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 79530927.9482 - val_loss: 1081302939.7423\n",
      "Epoch 8984/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 202525005.3618 - val_loss: 1548458557.9342\n",
      "Epoch 8985/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 462290132.6550 - val_loss: 698460146.9468\n",
      "Epoch 8986/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 104321641.6342 - val_loss: 786042089.2073\n",
      "Epoch 8987/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 427798324.9026 - val_loss: 798949992.6864\n",
      "Epoch 8988/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 142299002.5886 - val_loss: 654523745.6000\n",
      "Epoch 8989/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 101105861.3528 - val_loss: 976008956.8675\n",
      "Epoch 8990/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 137737399.0771 - val_loss: 676988016.3353\n",
      "Epoch 8991/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1717676183.1941 - val_loss: 6261601608.9474\n",
      "Epoch 8992/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 645969548.4592 - val_loss: 766013394.6194\n",
      "Epoch 8993/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 102023667.5566 - val_loss: 1945550915.4205\n",
      "Epoch 8994/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 292925320.4457 - val_loss: 662830477.9302\n",
      "Epoch 8995/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 140523256.9769 - val_loss: 1441604812.7989\n",
      "Epoch 8996/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 208387601.0231 - val_loss: 623014231.6917\n",
      "Epoch 8997/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 107496023.4373 - val_loss: 717405677.0340\n",
      "Epoch 8998/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 164113856.1306 - val_loss: 870047305.2759\n",
      "Epoch 8999/10000\n",
      "3554/3554 [==============================] - 0s 140us/step - loss: 369969737.6533 - val_loss: 659509971.0042\n",
      "Epoch 9000/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 245500328.3917 - val_loss: 879491882.2515\n",
      "Epoch 9001/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 221726812.0743 - val_loss: 1020722705.3457\n",
      "Epoch 9002/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 269549661.2358 - val_loss: 1176042180.8428\n",
      "Epoch 9003/10000\n",
      "3554/3554 [==============================] - 0s 138us/step - loss: 585404509.2538 - val_loss: 806427932.2869\n",
      "Epoch 9004/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 187865788.5222 - val_loss: 887046596.5705\n",
      "Epoch 9005/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 785132945.8998 - val_loss: 2388286351.6624\n",
      "Epoch 9006/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 443021945.4766 - val_loss: 718787940.2442\n",
      "Epoch 9007/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 165186410.0124 - val_loss: 1287792982.6520\n",
      "Epoch 9008/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 933477089.2786 - val_loss: 796237408.3691\n",
      "Epoch 9009/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 180244650.4266 - val_loss: 849421670.4900\n",
      "Epoch 9010/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 129300577.4170 - val_loss: 851397575.6287\n",
      "Epoch 9011/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 100974811.3810 - val_loss: 682654859.4003\n",
      "Epoch 9012/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 174189767.6353 - val_loss: 1146029077.7474\n",
      "Epoch 9013/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 310872526.6179 - val_loss: 875583585.8003\n",
      "Epoch 9014/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 193227930.5436 - val_loss: 794555859.4970\n",
      "Epoch 9015/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 230780342.2938 - val_loss: 726205385.9961\n",
      "Epoch 9016/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 408146278.9690 - val_loss: 1511769068.2689\n",
      "Epoch 9017/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 619847583.1086 - val_loss: 1124684857.4605\n",
      "Epoch 9018/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 264861439.9640 - val_loss: 4561570905.2219\n",
      "Epoch 9019/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1126144868.1598 - val_loss: 759542323.0605\n",
      "Epoch 9020/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 166992764.5965 - val_loss: 791670339.2383\n",
      "Epoch 9021/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 88241283.4800 - val_loss: 669190985.3795\n",
      "Epoch 9022/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 104661228.0698 - val_loss: 637472243.0605\n",
      "Epoch 9023/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 113453434.9263 - val_loss: 977627161.2669\n",
      "Epoch 9024/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 212544217.5827 - val_loss: 1160621640.9204\n",
      "Epoch 9025/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 282569575.4733 - val_loss: 743637412.8523\n",
      "Epoch 9026/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 651789659.7141 - val_loss: 1816729970.0298\n",
      "Epoch 9027/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 208433639.3652 - val_loss: 926029107.9381\n",
      "Epoch 9028/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 269305875.3483 - val_loss: 681259963.8436\n",
      "Epoch 9029/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 96237577.9223 - val_loss: 1162009686.8366\n",
      "Epoch 9030/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 347564425.2690 - val_loss: 1605825738.3516\n",
      "Epoch 9031/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 235070264.9229 - val_loss: 1554214628.4242\n",
      "Epoch 9032/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 1341894793.3821 - val_loss: 1187419709.2816\n",
      "Epoch 9033/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 289301508.6933 - val_loss: 711486674.3699\n",
      "Epoch 9034/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 176616497.5667 - val_loss: 1040708860.5975\n",
      "Epoch 9035/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 174854580.6607 - val_loss: 633324237.7001\n",
      "Epoch 9036/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 322138108.0248 - val_loss: 2941632121.3210\n",
      "Epoch 9037/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 352251312.0630 - val_loss: 729378715.6163\n",
      "Epoch 9038/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 155589394.4761 - val_loss: 723937877.6911\n",
      "Epoch 9039/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 135750242.9398 - val_loss: 646995454.3887\n",
      "Epoch 9040/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 115455775.4057 - val_loss: 768042143.3609\n",
      "Epoch 9041/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 458000383.0726 - val_loss: 1300591528.9069\n",
      "Epoch 9042/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 653366501.8526 - val_loss: 1242660923.0582\n",
      "Epoch 9043/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 405628390.6629 - val_loss: 778833693.4661\n",
      "Epoch 9044/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 202809654.6545 - val_loss: 670384139.7783\n",
      "Epoch 9045/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 413590774.4693 - val_loss: 4810406314.3786\n",
      "Epoch 9046/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 571494175.2527 - val_loss: 854668880.1440\n",
      "Epoch 9047/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 211652291.4665 - val_loss: 845877729.3750\n",
      "Epoch 9048/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 213037658.6472 - val_loss: 1461848419.5466\n",
      "Epoch 9049/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 394898031.0366 - val_loss: 776942788.2807\n",
      "Epoch 9050/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 93us/step - loss: 290866506.5301 - val_loss: 691422531.1578\n",
      "Epoch 9051/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 299360075.8492 - val_loss: 1014630640.2115\n",
      "Epoch 9052/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 488583761.7017 - val_loss: 712890191.9820\n",
      "Epoch 9053/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 147156335.5048 - val_loss: 712266393.6596\n",
      "Epoch 9054/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 624661413.3889 - val_loss: 805968933.3311\n",
      "Epoch 9055/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 240428409.0495 - val_loss: 731341380.9733\n",
      "Epoch 9056/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 100117758.8520 - val_loss: 1003537647.5814\n",
      "Epoch 9057/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 873326155.6331 - val_loss: 1107827402.6374\n",
      "Epoch 9058/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 311609040.6573 - val_loss: 721468977.2557\n",
      "Epoch 9059/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 251588488.3309 - val_loss: 788293927.1201\n",
      "Epoch 9060/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 113804369.5037 - val_loss: 871134072.9226\n",
      "Epoch 9061/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 147779624.7878 - val_loss: 972739114.9412\n",
      "Epoch 9062/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 615480786.0619 - val_loss: 963840880.6436\n",
      "Epoch 9063/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 208666843.3748 - val_loss: 646376822.7105\n",
      "Epoch 9064/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 64911333.6590 - val_loss: 662554256.7854\n",
      "Epoch 9065/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 102059549.4249 - val_loss: 655032610.6262\n",
      "Epoch 9066/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 288307135.4237 - val_loss: 5487580077.2591\n",
      "Epoch 9067/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1576655194.9398 - val_loss: 1103447500.4624\n",
      "Epoch 9068/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 197235873.8008 - val_loss: 666999150.9131\n",
      "Epoch 9069/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 109073725.8374 - val_loss: 742508664.6098\n",
      "Epoch 9070/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 498464148.5380 - val_loss: 1739545283.7266\n",
      "Epoch 9071/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 237559030.1317 - val_loss: 680683469.6911\n",
      "Epoch 9072/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 106203559.4282 - val_loss: 636650331.9246\n",
      "Epoch 9073/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 133219856.7473 - val_loss: 917670414.9063\n",
      "Epoch 9074/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 344711186.0889 - val_loss: 757897633.6743\n",
      "Epoch 9075/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 192502934.0056 - val_loss: 1198773962.6037\n",
      "Epoch 9076/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 529212518.5931 - val_loss: 1247352510.0602\n",
      "Epoch 9077/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 243542877.2898 - val_loss: 836031689.9060\n",
      "Epoch 9078/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 227734055.1221 - val_loss: 819559130.5406\n",
      "Epoch 9079/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 310676225.9989 - val_loss: 736959205.6743\n",
      "Epoch 9080/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 273909064.2206 - val_loss: 694241645.9252\n",
      "Epoch 9081/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 230955022.6899 - val_loss: 687406164.6684\n",
      "Epoch 9082/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 179408913.8098 - val_loss: 677454530.6633\n",
      "Epoch 9083/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 136668557.2088 - val_loss: 948795367.9797\n",
      "Epoch 9084/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 560840933.9966 - val_loss: 7143598731.2698\n",
      "Epoch 9085/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 837232380.1283 - val_loss: 964056002.1873\n",
      "Epoch 9086/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 314890109.4159 - val_loss: 1085588694.1030\n",
      "Epoch 9087/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 312860343.3787 - val_loss: 980228005.4143\n",
      "Epoch 9088/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 147906535.4373 - val_loss: 1463352998.5710\n",
      "Epoch 9089/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 782327310.7935 - val_loss: 1027420401.4357\n",
      "Epoch 9090/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 180199359.0996 - val_loss: 793404246.4473\n",
      "Epoch 9091/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 142096040.7378 - val_loss: 838566131.7198\n",
      "Epoch 9092/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 166297833.1210 - val_loss: 660380993.9826\n",
      "Epoch 9093/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 315416629.4395 - val_loss: 688694625.8970\n",
      "Epoch 9094/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 125704804.4524 - val_loss: 788334415.1809\n",
      "Epoch 9095/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 159869305.2290 - val_loss: 3799504342.3055\n",
      "Epoch 9096/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 595591129.4091 - val_loss: 824819412.4242\n",
      "Epoch 9097/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 162668701.4789 - val_loss: 1164713094.2470\n",
      "Epoch 9098/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1213944082.8002 - val_loss: 872051991.8627\n",
      "Epoch 9099/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 212823082.6427 - val_loss: 1957999854.5553\n",
      "Epoch 9100/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 219598255.9370 - val_loss: 1588101512.3893\n",
      "Epoch 9101/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 137119946.6269 - val_loss: 673535257.2709\n",
      "Epoch 9102/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 160387686.8970 - val_loss: 679058163.4115\n",
      "Epoch 9103/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 134945170.8239 - val_loss: 632357973.9184\n",
      "Epoch 9104/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 141973604.1643 - val_loss: 711227268.2217\n",
      "Epoch 9105/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 157387728.9094 - val_loss: 710877806.6104\n",
      "Epoch 9106/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 123128278.8160 - val_loss: 728562398.8951\n",
      "Epoch 9107/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 430747289.1075 - val_loss: 684189239.5657\n",
      "Epoch 9108/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 598737596.4750 - val_loss: 1372507418.3831\n",
      "Epoch 9109/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 901558871.4643 - val_loss: 903004142.8793\n",
      "Epoch 9110/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 277625485.0557 - val_loss: 748483012.2307\n",
      "Epoch 9111/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 141942122.0383 - val_loss: 779949090.9716\n",
      "Epoch 9112/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 189662397.2268 - val_loss: 792288354.2639\n",
      "Epoch 9113/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 159475227.2071 - val_loss: 635641555.1662\n",
      "Epoch 9114/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 111919516.7034 - val_loss: 636566932.0911\n",
      "Epoch 9115/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 122268401.2718 - val_loss: 912694693.3693\n",
      "Epoch 9116/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 463999813.6905 - val_loss: 1430672967.4419\n",
      "Epoch 9117/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 861936404.3039 - val_loss: 1116263375.0999\n",
      "Epoch 9118/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 206340351.1382 - val_loss: 666121072.2250\n",
      "Epoch 9119/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 576810558.4063 - val_loss: 1594977514.5046\n",
      "Epoch 9120/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 215680582.2847 - val_loss: 617753445.5539\n",
      "Epoch 9121/10000\n",
      "3554/3554 [==============================] - 0s 131us/step - loss: 266518595.6016 - val_loss: 1130557356.5120\n",
      "Epoch 9122/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 233744439.8244 - val_loss: 892416797.3986\n",
      "Epoch 9123/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 376572033.3686 - val_loss: 4871835864.6098\n",
      "Epoch 9124/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1681722081.7209 - val_loss: 686401466.6982\n",
      "Epoch 9125/10000\n",
      "3554/3554 [==============================] - 0s 132us/step - loss: 177293731.1075 - val_loss: 692419052.0968\n",
      "Epoch 9126/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 100397741.6140 - val_loss: 777174320.3105\n",
      "Epoch 9127/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 139984203.6669 - val_loss: 793847095.1336\n",
      "Epoch 9128/10000\n",
      "3554/3554 [==============================] - 0s 132us/step - loss: 222315847.7659 - val_loss: 816284375.5342\n",
      "Epoch 9129/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 160318543.2122 - val_loss: 683727839.8200\n",
      "Epoch 9130/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 187340419.4755 - val_loss: 1346079778.4754\n",
      "Epoch 9131/10000\n",
      "3554/3554 [==============================] - 1s 151us/step - loss: 500157708.9702 - val_loss: 663131470.8793\n",
      "Epoch 9132/10000\n",
      "3554/3554 [==============================] - 0s 140us/step - loss: 101698716.4032 - val_loss: 732957996.4557\n",
      "Epoch 9133/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 106140870.6201 - val_loss: 838455215.1021\n",
      "Epoch 9134/10000\n",
      "3554/3554 [==============================] - 1s 220us/step - loss: 126498357.0512 - val_loss: 701065855.8549\n",
      "Epoch 9135/10000\n",
      "3554/3554 [==============================] - 1s 153us/step - loss: 240378781.6275 - val_loss: 865291305.2624\n",
      "Epoch 9136/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 545543080.5357 - val_loss: 842356150.7691\n",
      "Epoch 9137/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 171468049.5667 - val_loss: 691080303.6489\n",
      "Epoch 9138/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 194756614.6449 - val_loss: 1101465075.0380\n",
      "Epoch 9139/10000\n",
      "3554/3554 [==============================] - 1s 182us/step - loss: 266394322.2600 - val_loss: 1019163877.1218\n",
      "Epoch 9140/10000\n",
      "3554/3554 [==============================] - 1s 146us/step - loss: 683974286.2622 - val_loss: 890988291.1325\n",
      "Epoch 9141/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 721680314.0979 - val_loss: 838009364.7612\n",
      "Epoch 9142/10000\n",
      "3554/3554 [==============================] - 1s 155us/step - loss: 142529699.5931 - val_loss: 1300736829.9387\n",
      "Epoch 9143/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 269402254.4851 - val_loss: 816282282.8017\n",
      "Epoch 9144/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 250176274.1069 - val_loss: 1034729915.7783\n",
      "Epoch 9145/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 260639141.7805 - val_loss: 882549795.2810\n",
      "Epoch 9146/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 110524997.0242 - val_loss: 1795577504.0810\n",
      "Epoch 9147/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 286134438.3500 - val_loss: 2980867686.7781\n",
      "Epoch 9148/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 264037719.1761 - val_loss: 705046477.7249\n",
      "Epoch 9149/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 272490294.5279 - val_loss: 1076115864.5570\n",
      "Epoch 9150/10000\n",
      "3554/3554 [==============================] - 0s 134us/step - loss: 879668676.4299 - val_loss: 1440067856.4186\n",
      "Epoch 9151/10000\n",
      "3554/3554 [==============================] - 1s 169us/step - loss: 1270839804.6511 - val_loss: 862614974.5508\n",
      "Epoch 9152/10000\n",
      "3554/3554 [==============================] - 0s 137us/step - loss: 146756040.9679 - val_loss: 661611247.6805\n",
      "Epoch 9153/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 73848408.9071 - val_loss: 668069511.3193\n",
      "Epoch 9154/10000\n",
      "3554/3554 [==============================] - 1s 147us/step - loss: 78779293.5723 - val_loss: 1019701291.6208\n",
      "Epoch 9155/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 120315416.7608 - val_loss: 639261518.8163\n",
      "Epoch 9156/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 258127697.7378 - val_loss: 1099848155.3463\n",
      "Epoch 9157/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 265834328.3467 - val_loss: 1814122059.8999\n",
      "Epoch 9158/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 290740562.4547 - val_loss: 807081677.3086\n",
      "Epoch 9159/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 268892498.4041 - val_loss: 10455949674.2886\n",
      "Epoch 9160/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 4052937064.9049 - val_loss: 741604263.4442\n",
      "Epoch 9161/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 129034010.8047 - val_loss: 701930982.7994\n",
      "Epoch 9162/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 86710605.9291 - val_loss: 628327626.0686\n",
      "Epoch 9163/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 89428735.5273 - val_loss: 605797645.9150\n",
      "Epoch 9164/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 77786186.7732 - val_loss: 1043364859.1122\n",
      "Epoch 9165/10000\n",
      "3554/3554 [==============================] - 1s 152us/step - loss: 88936896.4232 - val_loss: 704077165.2512\n",
      "Epoch 9166/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 88758963.7231 - val_loss: 620186641.7418\n",
      "Epoch 9167/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 83377344.6902 - val_loss: 649678203.6028\n",
      "Epoch 9168/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 211195623.5633 - val_loss: 831115317.4132\n",
      "Epoch 9169/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 338951410.1452 - val_loss: 945526871.5522\n",
      "Epoch 9170/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 88470843.2414 - val_loss: 824349404.7752\n",
      "Epoch 9171/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 114647916.6460 - val_loss: 678627758.8883\n",
      "Epoch 9172/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 136852045.7085 - val_loss: 685547174.2335\n",
      "Epoch 9173/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 152480417.1795 - val_loss: 632020850.9075\n",
      "Epoch 9174/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 238236916.8711 - val_loss: 1622735579.2383\n",
      "Epoch 9175/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 753842448.7473 - val_loss: 916608166.2425\n",
      "Epoch 9176/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 930032113.4657 - val_loss: 775895834.2706\n",
      "Epoch 9177/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 179698472.8149 - val_loss: 730970819.0650\n",
      "Epoch 9178/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 155117097.3191 - val_loss: 657131681.8622\n",
      "Epoch 9179/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 102594256.4277 - val_loss: 932656312.1373\n",
      "Epoch 9180/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 122us/step - loss: 194095063.0861 - val_loss: 1833429537.4672\n",
      "Epoch 9181/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 425365162.0146 - val_loss: 1110314723.5556\n",
      "Epoch 9182/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 239952089.5543 - val_loss: 716165247.0481\n",
      "Epoch 9183/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 242473392.5853 - val_loss: 7754503340.2509\n",
      "Epoch 9184/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1202552794.7732 - val_loss: 1986850274.6374\n",
      "Epoch 9185/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 239097594.9173 - val_loss: 819707184.2948\n",
      "Epoch 9186/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 399718791.8965 - val_loss: 696980474.6948\n",
      "Epoch 9187/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 110319856.7203 - val_loss: 643980264.5592\n",
      "Epoch 9188/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 117743809.0805 - val_loss: 814753407.7660\n",
      "Epoch 9189/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 548265106.6382 - val_loss: 1282054219.0537\n",
      "Epoch 9190/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 1022575795.1064 - val_loss: 1641820536.9879\n",
      "Epoch 9191/10000\n",
      "3554/3554 [==============================] - 0s 136us/step - loss: 693639562.2465 - val_loss: 769173754.2211\n",
      "Epoch 9192/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 155812186.2825 - val_loss: 750227681.3058\n",
      "Epoch 9193/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 507634908.7631 - val_loss: 721884319.2439\n",
      "Epoch 9194/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 113787321.2324 - val_loss: 622704449.1466\n",
      "Epoch 9195/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 131336918.6179 - val_loss: 640744448.9103\n",
      "Epoch 9196/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 138632681.7783 - val_loss: 901475351.1156\n",
      "Epoch 9197/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 89851307.7321 - val_loss: 1650247096.8709\n",
      "Epoch 9198/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 800971993.0490 - val_loss: 1872176892.9755\n",
      "Epoch 9199/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 275598694.1407 - val_loss: 971642712.7854\n",
      "Epoch 9200/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 89347545.9223 - val_loss: 703980692.0619\n",
      "Epoch 9201/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 131155594.6427 - val_loss: 708566282.0703\n",
      "Epoch 9202/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 243587363.0433 - val_loss: 655197815.9527\n",
      "Epoch 9203/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 235461906.0439 - val_loss: 4760789942.5485\n",
      "Epoch 9204/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 2479462400.0720 - val_loss: 720363143.3902\n",
      "Epoch 9205/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 110037973.9516 - val_loss: 673933105.2017\n",
      "Epoch 9206/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 85081534.1182 - val_loss: 840359862.4968\n",
      "Epoch 9207/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 92186855.2482 - val_loss: 1041766282.0546\n",
      "Epoch 9208/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 150470713.1750 - val_loss: 649040941.2096\n",
      "Epoch 9209/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 111272331.3810 - val_loss: 755613088.4681\n",
      "Epoch 9210/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 155531057.8458 - val_loss: 977285865.0352\n",
      "Epoch 9211/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 115923916.8604 - val_loss: 680877020.5975\n",
      "Epoch 9212/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 374882576.7850 - val_loss: 631828050.0411\n",
      "Epoch 9213/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 198799648.6483 - val_loss: 950890297.6450\n",
      "Epoch 9214/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 712757375.2932 - val_loss: 1198475514.8512\n",
      "Epoch 9215/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 486524486.9330 - val_loss: 751536660.6942\n",
      "Epoch 9216/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 178063554.6972 - val_loss: 636606143.2366\n",
      "Epoch 9217/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 132333947.8402 - val_loss: 687375423.2821\n",
      "Epoch 9218/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 450462533.1503 - val_loss: 4845982603.3418\n",
      "Epoch 9219/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 519761687.4008 - val_loss: 756357976.3128\n",
      "Epoch 9220/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 155496633.1300 - val_loss: 727619537.6473\n",
      "Epoch 9221/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 105035843.6196 - val_loss: 726954190.7781\n",
      "Epoch 9222/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 216365045.2133 - val_loss: 913295291.5623\n",
      "Epoch 9223/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 253364466.0619 - val_loss: 1078039976.2408\n",
      "Epoch 9224/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1205387937.6027 - val_loss: 1598787739.6703\n",
      "Epoch 9225/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 507334736.4997 - val_loss: 954673927.5319\n",
      "Epoch 9226/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 106931643.5521 - val_loss: 1038942102.4225\n",
      "Epoch 9227/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 423051751.5453 - val_loss: 2269398320.6436\n",
      "Epoch 9228/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1321357902.1182 - val_loss: 719408222.7466\n",
      "Epoch 9229/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 129333069.1593 - val_loss: 626607655.7812\n",
      "Epoch 9230/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 133660335.5858 - val_loss: 1256248863.8200\n",
      "Epoch 9231/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 111805437.5959 - val_loss: 686809154.3539\n",
      "Epoch 9232/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 132947456.6179 - val_loss: 1140842971.8323\n",
      "Epoch 9233/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 271181152.0113 - val_loss: 664101518.9041\n",
      "Epoch 9234/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 87126685.3663 - val_loss: 737702272.7921\n",
      "Epoch 9235/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 242274518.8835 - val_loss: 723083348.4107\n",
      "Epoch 9236/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 147916122.7552 - val_loss: 819743234.8647\n",
      "Epoch 9237/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 142199057.5307 - val_loss: 1475897021.4301\n",
      "Epoch 9238/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 274467177.8323 - val_loss: 972911810.0613\n",
      "Epoch 9239/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 295624819.5926 - val_loss: 842870235.9944\n",
      "Epoch 9240/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 211434929.9719 - val_loss: 872463548.9170\n",
      "Epoch 9241/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 298328127.5858 - val_loss: 939091691.7783\n",
      "Epoch 9242/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 286412142.7665 - val_loss: 1952472163.7536\n",
      "Epoch 9243/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 194709632.5672 - val_loss: 762376109.3536\n",
      "Epoch 9244/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 228856665.0940 - val_loss: 861464799.2349\n",
      "Epoch 9245/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 202409708.9477 - val_loss: 827929809.9083\n",
      "Epoch 9246/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 345726914.1609 - val_loss: 1354978143.2619\n",
      "Epoch 9247/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 414814278.0506 - val_loss: 991302143.8020\n",
      "Epoch 9248/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 516006679.1480 - val_loss: 703082344.0540\n",
      "Epoch 9249/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 307803826.1880 - val_loss: 2909011565.5831\n",
      "Epoch 9250/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1047389607.1716 - val_loss: 1376533782.9176\n",
      "Epoch 9251/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 186499517.5374 - val_loss: 710911316.6177\n",
      "Epoch 9252/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 200437501.3168 - val_loss: 849291192.8619\n",
      "Epoch 9253/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 144701952.5582 - val_loss: 1312759557.1038\n",
      "Epoch 9254/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 271587991.2302 - val_loss: 1990673320.5783\n",
      "Epoch 9255/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 498492167.4553 - val_loss: 875487326.3257\n",
      "Epoch 9256/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 276775145.3911 - val_loss: 1435509034.6127\n",
      "Epoch 9257/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 217900009.1013 - val_loss: 744084368.4973\n",
      "Epoch 9258/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 134255662.3804 - val_loss: 715962702.3032\n",
      "Epoch 9259/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 94688183.2347 - val_loss: 1022629644.6560\n",
      "Epoch 9260/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 715384777.0039 - val_loss: 1335193161.8835\n",
      "Epoch 9261/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 215519645.1773 - val_loss: 924770217.8453\n",
      "Epoch 9262/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1764916141.1998 - val_loss: 9307676765.3266\n",
      "Epoch 9263/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1303164879.9550 - val_loss: 941885172.2937\n",
      "Epoch 9264/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 122952755.7096 - val_loss: 610610557.6754\n",
      "Epoch 9265/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 92242505.0636 - val_loss: 616255037.3634\n",
      "Epoch 9266/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 151420663.0321 - val_loss: 1229096106.2616\n",
      "Epoch 9267/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 161907129.9088 - val_loss: 888346509.9702\n",
      "Epoch 9268/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 173122337.5037 - val_loss: 1096472793.4740\n",
      "Epoch 9269/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 170578077.1874 - val_loss: 843255349.0228\n",
      "Epoch 9270/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 240176450.5571 - val_loss: 753625409.3367\n",
      "Epoch 9271/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 129121956.2195 - val_loss: 697687831.9077\n",
      "Epoch 9272/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 171382133.8818 - val_loss: 670387036.8135\n",
      "Epoch 9273/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 139310034.9398 - val_loss: 725867098.2211\n",
      "Epoch 9274/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 270402572.5335 - val_loss: 802431777.9713\n",
      "Epoch 9275/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 226439734.3928 - val_loss: 1097557513.1724\n",
      "Epoch 9276/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 368422890.1114 - val_loss: 735520837.7271\n",
      "Epoch 9277/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 323457105.2335 - val_loss: 771633706.2459\n",
      "Epoch 9278/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 178361830.9916 - val_loss: 794801238.5215\n",
      "Epoch 9279/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 265707549.7400 - val_loss: 820312101.2748\n",
      "Epoch 9280/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 221262494.4018 - val_loss: 646224372.7775\n",
      "Epoch 9281/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 269669209.1975 - val_loss: 1829320042.3336\n",
      "Epoch 9282/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 584367018.1519 - val_loss: 3464051943.3361\n",
      "Epoch 9283/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 705288674.2150 - val_loss: 1355469461.3693\n",
      "Epoch 9284/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 296923987.0568 - val_loss: 955466755.7997\n",
      "Epoch 9285/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 193802308.2814 - val_loss: 666496476.2869\n",
      "Epoch 9286/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 135372637.8931 - val_loss: 2179895203.2855\n",
      "Epoch 9287/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 523341741.5526 - val_loss: 1388298509.0520\n",
      "Epoch 9288/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 265874296.3106 - val_loss: 2011299796.4332\n",
      "Epoch 9289/10000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 278377305.0129 - val_loss: 3154645507.2045\n",
      "Epoch 9290/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 611559861.5914 - val_loss: 681685415.9060\n",
      "Epoch 9291/10000\n",
      "3554/3554 [==============================] - 0s 134us/step - loss: 430024657.0174 - val_loss: 1061380227.5556\n",
      "Epoch 9292/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 537277048.5447 - val_loss: 1039466321.6068\n",
      "Epoch 9293/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 166016066.8689 - val_loss: 677872442.9435\n",
      "Epoch 9294/10000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 135923656.8531 - val_loss: 681989110.6464\n",
      "Epoch 9295/10000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 108644113.4902 - val_loss: 679539182.3550\n",
      "Epoch 9296/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 93453609.7243 - val_loss: 933631936.9632\n",
      "Epoch 9297/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 596148233.9764 - val_loss: 1132081987.7266\n",
      "Epoch 9298/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 483621775.7209 - val_loss: 648177884.0686\n",
      "Epoch 9299/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 132824618.4198 - val_loss: 727951996.1024\n",
      "Epoch 9300/10000\n",
      "3554/3554 [==============================] - 0s 137us/step - loss: 224074665.6275 - val_loss: 801032069.2568\n",
      "Epoch 9301/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 255235255.9955 - val_loss: 1782750931.8751\n",
      "Epoch 9302/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 552564738.9533 - val_loss: 674961777.2641\n",
      "Epoch 9303/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 135924026.9826 - val_loss: 633238292.9226\n",
      "Epoch 9304/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 209037253.3663 - val_loss: 1764761529.7530\n",
      "Epoch 9305/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 305304492.5155 - val_loss: 962884396.7387\n",
      "Epoch 9306/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 1105396490.5886 - val_loss: 1272330769.2039\n",
      "Epoch 9307/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 839332277.8593 - val_loss: 757319651.3125\n",
      "Epoch 9308/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 147372887.9865 - val_loss: 715198798.8850\n",
      "Epoch 9309/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 234623897.0447 - val_loss: 810159597.9342\n",
      "Epoch 9310/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 109us/step - loss: 87953363.4688 - val_loss: 743604090.0568\n",
      "Epoch 9311/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 137457638.1187 - val_loss: 612105804.9958\n",
      "Epoch 9312/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 123531657.8649 - val_loss: 748188001.8138\n",
      "Epoch 9313/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 155698616.5267 - val_loss: 834784902.0219\n",
      "Epoch 9314/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 314506211.1874 - val_loss: 918446400.3150\n",
      "Epoch 9315/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 194358397.3708 - val_loss: 1086958712.3488\n",
      "Epoch 9316/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 830452255.6083 - val_loss: 701763804.3904\n",
      "Epoch 9317/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 108262972.5605 - val_loss: 1038960396.0439\n",
      "Epoch 9318/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 178515164.8666 - val_loss: 692560980.2982\n",
      "Epoch 9319/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 175668900.6640 - val_loss: 2012956154.5632\n",
      "Epoch 9320/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 277477228.9842 - val_loss: 1034326080.1755\n",
      "Epoch 9321/10000\n",
      "3554/3554 [==============================] - 0s 132us/step - loss: 629704015.1986 - val_loss: 2712678241.9353\n",
      "Epoch 9322/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 484069748.0068 - val_loss: 2656514246.5440\n",
      "Epoch 9323/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 785785368.0000 - val_loss: 1190775405.4211\n",
      "Epoch 9324/10000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 218463185.8188 - val_loss: 684777059.4475\n",
      "Epoch 9325/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 92911926.3343 - val_loss: 721758009.3930\n",
      "Epoch 9326/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 108787426.6427 - val_loss: 743411696.9418\n",
      "Epoch 9327/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 140779967.6128 - val_loss: 1176961060.2217\n",
      "Epoch 9328/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 189928602.2285 - val_loss: 646401521.7373\n",
      "Epoch 9329/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 148713663.8920 - val_loss: 1383827413.7744\n",
      "Epoch 9330/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 316752596.5290 - val_loss: 658701681.2062\n",
      "Epoch 9331/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 511065077.4474 - val_loss: 15019602729.4065\n",
      "Epoch 9332/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 3879654858.4806 - val_loss: 1031734111.1809\n",
      "Epoch 9333/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 426185886.1812 - val_loss: 681459411.2383\n",
      "Epoch 9334/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 113394264.0765 - val_loss: 712282233.0869\n",
      "Epoch 9335/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 73773558.5616 - val_loss: 684859707.1449\n",
      "Epoch 9336/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 110269702.9285 - val_loss: 621770109.1643\n",
      "Epoch 9337/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 77990252.0338 - val_loss: 750160011.0357\n",
      "Epoch 9338/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 81422068.9882 - val_loss: 621910683.1752\n",
      "Epoch 9339/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 66521126.9364 - val_loss: 650496611.5895\n",
      "Epoch 9340/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 80464258.4896 - val_loss: 662205607.7232\n",
      "Epoch 9341/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 121977072.2611 - val_loss: 2706615238.2470\n",
      "Epoch 9342/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 336426803.7366 - val_loss: 3103203828.4062\n",
      "Epoch 9343/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 404404151.4215 - val_loss: 657889916.5648\n",
      "Epoch 9344/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 239952752.0180 - val_loss: 1152825584.8779\n",
      "Epoch 9345/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 280330305.2606 - val_loss: 1158275400.7696\n",
      "Epoch 9346/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 531471044.5920 - val_loss: 703676446.0467\n",
      "Epoch 9347/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 106962366.1699 - val_loss: 686226427.2630\n",
      "Epoch 9348/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 89559841.8469 - val_loss: 688452283.4672\n",
      "Epoch 9349/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 169247887.5768 - val_loss: 935285837.2951\n",
      "Epoch 9350/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 1104867027.2155 - val_loss: 763519747.8436\n",
      "Epoch 9351/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 104344773.4924 - val_loss: 637889037.2141\n",
      "Epoch 9352/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 111870517.5014 - val_loss: 1053032009.0262\n",
      "Epoch 9353/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 220269176.2341 - val_loss: 664108220.4557\n",
      "Epoch 9354/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 115078665.4136 - val_loss: 684059206.7432\n",
      "Epoch 9355/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 602690360.7968 - val_loss: 2811456996.8158\n",
      "Epoch 9356/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 225411854.3343 - val_loss: 775646156.2869\n",
      "Epoch 9357/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 171443172.6415 - val_loss: 676230950.5108\n",
      "Epoch 9358/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 155371256.7780 - val_loss: 842659724.4039\n",
      "Epoch 9359/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 157152927.6640 - val_loss: 878745113.5280\n",
      "Epoch 9360/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 274007436.0855 - val_loss: 775099690.6475\n",
      "Epoch 9361/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 385924488.1756 - val_loss: 4562003320.4028\n",
      "Epoch 9362/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 3459173435.0703 - val_loss: 798702963.2450\n",
      "Epoch 9363/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 148464673.7513 - val_loss: 647403206.0399\n",
      "Epoch 9364/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 96161164.4924 - val_loss: 613812608.0664\n",
      "Epoch 9365/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 72595309.3754 - val_loss: 652493568.6211\n",
      "Epoch 9366/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 94509220.3737 - val_loss: 740753004.1406\n",
      "Epoch 9367/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 136726072.5144 - val_loss: 906015599.7975\n",
      "Epoch 9368/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 129687613.0467 - val_loss: 1015654742.1435\n",
      "Epoch 9369/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 195305254.4986 - val_loss: 634238125.3052\n",
      "Epoch 9370/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 75987077.9021 - val_loss: 687551395.9966\n",
      "Epoch 9371/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 99056237.1187 - val_loss: 663627978.7477\n",
      "Epoch 9372/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 114168293.0872 - val_loss: 728741826.1570\n",
      "Epoch 9373/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 186834950.6753 - val_loss: 666161765.1668\n",
      "Epoch 9374/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 223544158.1812 - val_loss: 769416077.5381\n",
      "Epoch 9375/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 164410235.7141 - val_loss: 669168643.2990\n",
      "Epoch 9376/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 880671486.3613 - val_loss: 1095692013.0138\n",
      "Epoch 9377/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 369371306.9471 - val_loss: 4754569185.9713\n",
      "Epoch 9378/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 556287524.6235 - val_loss: 1281125211.0762\n",
      "Epoch 9379/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 279651217.0557 - val_loss: 637715624.5339\n",
      "Epoch 9380/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 120721086.1272 - val_loss: 727937884.1294\n",
      "Epoch 9381/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 2615276204.2994 - val_loss: 7538380607.7300\n",
      "Epoch 9382/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1562128112.2971 - val_loss: 791509517.0363\n",
      "Epoch 9383/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 112916094.7124 - val_loss: 723565766.7511\n",
      "Epoch 9384/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 132850627.9989 - val_loss: 829658692.5727\n",
      "Epoch 9385/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 93339658.3163 - val_loss: 716791739.5359\n",
      "Epoch 9386/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 102093763.5408 - val_loss: 905308853.8959\n",
      "Epoch 9387/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 103168759.2766 - val_loss: 689943998.0332\n",
      "Epoch 9388/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 106385146.9758 - val_loss: 772514142.2402\n",
      "Epoch 9389/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 177651746.1609 - val_loss: 833714677.8869\n",
      "Epoch 9390/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 130807758.5098 - val_loss: 731279246.0399\n",
      "Epoch 9391/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 412882776.5098 - val_loss: 952045398.5395\n",
      "Epoch 9392/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 374693090.4761 - val_loss: 770441294.6363\n",
      "Epoch 9393/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 257874022.1587 - val_loss: 671199228.6897\n",
      "Epoch 9394/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 323137615.9280 - val_loss: 850228554.6442\n",
      "Epoch 9395/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 279416452.5020 - val_loss: 798305547.3980\n",
      "Epoch 9396/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 137665854.4873 - val_loss: 687441551.2776\n",
      "Epoch 9397/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 122787644.0113 - val_loss: 855180227.5173\n",
      "Epoch 9398/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 766039388.5245 - val_loss: 2682633903.0233\n",
      "Epoch 9399/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 560294026.0844 - val_loss: 834868131.1190\n",
      "Epoch 9400/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 221369155.1941 - val_loss: 702439818.3246\n",
      "Epoch 9401/10000\n",
      "3554/3554 [==============================] - 1s 164us/step - loss: 100931526.5200 - val_loss: 690172741.8734\n",
      "Epoch 9402/10000\n",
      "3554/3554 [==============================] - 1s 145us/step - loss: 166850810.5957 - val_loss: 805729057.3322\n",
      "Epoch 9403/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 127110868.2093 - val_loss: 743558649.3525\n",
      "Epoch 9404/10000\n",
      "3554/3554 [==============================] - 1s 143us/step - loss: 161902534.5008 - val_loss: 950546311.4532\n",
      "Epoch 9405/10000\n",
      "3554/3554 [==============================] - 0s 134us/step - loss: 789613195.1356 - val_loss: 717312580.4028\n",
      "Epoch 9406/10000\n",
      "3554/3554 [==============================] - 1s 145us/step - loss: 127217969.2876 - val_loss: 837170270.0377\n",
      "Epoch 9407/10000\n",
      "3554/3554 [==============================] - 1s 152us/step - loss: 116825840.3512 - val_loss: 9628630382.2492\n",
      "Epoch 9408/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 1572672720.3061 - val_loss: 666813602.7769\n",
      "Epoch 9409/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 115355185.5217 - val_loss: 970436927.3429\n",
      "Epoch 9410/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 115313196.8666 - val_loss: 893836778.5451\n",
      "Epoch 9411/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 111233442.7642 - val_loss: 1617682689.4222\n",
      "Epoch 9412/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 215173218.8115 - val_loss: 727041290.8354\n",
      "Epoch 9413/10000\n",
      "3554/3554 [==============================] - 1s 143us/step - loss: 111873559.6353 - val_loss: 1390118754.9075\n",
      "Epoch 9414/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 241486711.9685 - val_loss: 709905403.6062\n",
      "Epoch 9415/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 166960629.8706 - val_loss: 1089695178.8017\n",
      "Epoch 9416/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 345877033.4271 - val_loss: 927702099.3440\n",
      "Epoch 9417/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 372056239.9539 - val_loss: 789437153.0020\n",
      "Epoch 9418/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 322633228.6055 - val_loss: 7258412328.5423\n",
      "Epoch 9419/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 912468769.5487 - val_loss: 2185229203.0470\n",
      "Epoch 9420/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 351087513.1728 - val_loss: 718119438.5463\n",
      "Epoch 9421/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 107087611.5836 - val_loss: 669053309.7541\n",
      "Epoch 9422/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 108205477.3979 - val_loss: 693667123.4430\n",
      "Epoch 9423/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 153561287.0343 - val_loss: 1049032460.2869\n",
      "Epoch 9424/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 195365503.1604 - val_loss: 744228837.7609\n",
      "Epoch 9425/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 269866385.0917 - val_loss: 756860223.4329\n",
      "Epoch 9426/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 193967051.1086 - val_loss: 711911961.8385\n",
      "Epoch 9427/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 229096759.5363 - val_loss: 6233501140.6492\n",
      "Epoch 9428/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 2284179083.1109 - val_loss: 906749703.2731\n",
      "Epoch 9429/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 235229823.6984 - val_loss: 970402554.6802\n",
      "Epoch 9430/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 172657171.4215 - val_loss: 644767628.5835\n",
      "Epoch 9431/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 89283975.9010 - val_loss: 638890703.1167\n",
      "Epoch 9432/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 90855581.3663 - val_loss: 927334802.2053\n",
      "Epoch 9433/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 141782486.5234 - val_loss: 775928284.3904\n",
      "Epoch 9434/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 97432523.8132 - val_loss: 985150591.6805\n",
      "Epoch 9435/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 166999952.2071 - val_loss: 2059607902.1187\n",
      "Epoch 9436/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 720384196.4840 - val_loss: 1390724980.6942\n",
      "Epoch 9437/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 379468868.4389 - val_loss: 1890943168.8821\n",
      "Epoch 9438/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 371622164.0023 - val_loss: 694493392.7111\n",
      "Epoch 9439/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 126449225.2741 - val_loss: 1465489752.1598\n",
      "Epoch 9440/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 89us/step - loss: 212974402.8317 - val_loss: 1412402316.5030\n",
      "Epoch 9441/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 458799986.5931 - val_loss: 3186641580.2869\n",
      "Epoch 9442/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 905360109.4091 - val_loss: 1299968452.6627\n",
      "Epoch 9443/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 258647115.5250 - val_loss: 1030582964.8383\n",
      "Epoch 9444/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 325063569.8278 - val_loss: 641771744.8619\n",
      "Epoch 9445/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 140238637.2448 - val_loss: 795705114.1041\n",
      "Epoch 9446/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 76113754.3635 - val_loss: 2677943927.0346\n",
      "Epoch 9447/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 514761344.5402 - val_loss: 961606634.3336\n",
      "Epoch 9448/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 364920573.3407 - val_loss: 630936274.9373\n",
      "Epoch 9449/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 94804260.5110 - val_loss: 786385813.7992\n",
      "Epoch 9450/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 451112396.0293 - val_loss: 2307171526.2110\n",
      "Epoch 9451/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 437401953.0310 - val_loss: 642300993.6698\n",
      "Epoch 9452/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 207813647.9910 - val_loss: 729828466.5643\n",
      "Epoch 9453/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 147477913.3981 - val_loss: 786604414.8489\n",
      "Epoch 9454/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 98585250.7237 - val_loss: 762060172.9440\n",
      "Epoch 9455/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 415553464.6168 - val_loss: 2424923535.2304\n",
      "Epoch 9456/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 550097102.7304 - val_loss: 5597946076.5705\n",
      "Epoch 9457/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 1103974949.6185 - val_loss: 1144174516.0281\n",
      "Epoch 9458/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 256977448.9004 - val_loss: 660925589.1533\n",
      "Epoch 9459/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 228424654.6044 - val_loss: 654515291.4768\n",
      "Epoch 9460/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 96287013.4350 - val_loss: 648686758.6093\n",
      "Epoch 9461/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 122602686.0371 - val_loss: 672663753.7530\n",
      "Epoch 9462/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 118745650.3905 - val_loss: 774542690.9435\n",
      "Epoch 9463/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 143360426.6246 - val_loss: 1177905050.7342\n",
      "Epoch 9464/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 398083046.5549 - val_loss: 9954082336.8371\n",
      "Epoch 9465/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1621556303.1086 - val_loss: 819687399.9263\n",
      "Epoch 9466/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 107770455.2279 - val_loss: 691925904.3150\n",
      "Epoch 9467/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 86443338.8948 - val_loss: 632575116.5941\n",
      "Epoch 9468/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 105762070.5369 - val_loss: 652423065.0734\n",
      "Epoch 9469/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 92128843.5588 - val_loss: 631115385.7013\n",
      "Epoch 9470/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 231588866.9128 - val_loss: 704432139.4757\n",
      "Epoch 9471/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 213564706.9353 - val_loss: 1183317202.5316\n",
      "Epoch 9472/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 232069998.7271 - val_loss: 692516215.0954\n",
      "Epoch 9473/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 142984508.7586 - val_loss: 1065436150.5035\n",
      "Epoch 9474/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 244906155.1289 - val_loss: 712996058.3159\n",
      "Epoch 9475/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 380839441.7918 - val_loss: 2319267548.4985\n",
      "Epoch 9476/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 627260194.5931 - val_loss: 922862913.5932\n",
      "Epoch 9477/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 673988628.9432 - val_loss: 1341515752.8236\n",
      "Epoch 9478/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 415286949.4744 - val_loss: 1033088230.8591\n",
      "Epoch 9479/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 531676711.6894 - val_loss: 1540658765.1601\n",
      "Epoch 9480/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 454135533.3799 - val_loss: 1021666012.7145\n",
      "Epoch 9481/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 176691723.2369 - val_loss: 710767634.7190\n",
      "Epoch 9482/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 159312206.2093 - val_loss: 668597740.1902\n",
      "Epoch 9483/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1083546598.6449 - val_loss: 18778078373.0498\n",
      "Epoch 9484/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2074465299.3044 - val_loss: 4910680474.1761\n",
      "Epoch 9485/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 402723141.5689 - val_loss: 686935926.5508\n",
      "Epoch 9486/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 102655357.1908 - val_loss: 653404185.8250\n",
      "Epoch 9487/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 102589395.0613 - val_loss: 669229507.7598\n",
      "Epoch 9488/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 98095483.1660 - val_loss: 635051050.7139\n",
      "Epoch 9489/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 68822033.8348 - val_loss: 666762917.8419\n",
      "Epoch 9490/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 65498284.0923 - val_loss: 645228276.2127\n",
      "Epoch 9491/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 568871984.6483 - val_loss: 897760368.6976\n",
      "Epoch 9492/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 121816844.0473 - val_loss: 653645909.4233\n",
      "Epoch 9493/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 130172696.6888 - val_loss: 780816278.2245\n",
      "Epoch 9494/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 273020122.6010 - val_loss: 676729475.0065\n",
      "Epoch 9495/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 84655469.8075 - val_loss: 667537988.9328\n",
      "Epoch 9496/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 288850479.1446 - val_loss: 935507445.0363\n",
      "Epoch 9497/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 544067108.2499 - val_loss: 623400967.3876\n",
      "Epoch 9498/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 107117068.3399 - val_loss: 919674133.0115\n",
      "Epoch 9499/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 178657865.2831 - val_loss: 2074744766.3977\n",
      "Epoch 9500/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 313447512.1936 - val_loss: 1181904537.4110\n",
      "Epoch 9501/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 396717427.0703 - val_loss: 1204495358.2312\n",
      "Epoch 9502/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 403768711.4192 - val_loss: 721479012.8990\n",
      "Epoch 9503/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 698701344.8104 - val_loss: 1397252711.0841\n",
      "Epoch 9504/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 331919576.6978 - val_loss: 1052317161.4650\n",
      "Epoch 9505/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 213172348.7496 - val_loss: 811596757.1983\n",
      "Epoch 9506/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 101056043.4508 - val_loss: 661857342.6937\n",
      "Epoch 9507/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 190885081.4947 - val_loss: 1025868349.3536\n",
      "Epoch 9508/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2125466662.1047 - val_loss: 1179406572.3060\n",
      "Epoch 9509/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 174423098.8098 - val_loss: 723636528.1755\n",
      "Epoch 9510/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 81176940.9218 - val_loss: 611620701.7365\n",
      "Epoch 9511/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 67386325.5302 - val_loss: 706019286.0098\n",
      "Epoch 9512/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 184962842.5698 - val_loss: 722389508.8585\n",
      "Epoch 9513/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 94814149.5352 - val_loss: 633898945.2602\n",
      "Epoch 9514/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 144282917.6905 - val_loss: 808571999.8762\n",
      "Epoch 9515/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 589385818.6427 - val_loss: 744112501.9364\n",
      "Epoch 9516/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 143654350.7372 - val_loss: 630965673.5944\n",
      "Epoch 9517/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 186808588.7586 - val_loss: 734848602.8557\n",
      "Epoch 9518/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 214210422.2127 - val_loss: 877751097.9286\n",
      "Epoch 9519/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 258094758.9803 - val_loss: 734064215.6473\n",
      "Epoch 9520/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 320035488.1981 - val_loss: 1137772302.7342\n",
      "Epoch 9521/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1245339828.3512 - val_loss: 2234402272.5311\n",
      "Epoch 9522/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1339794341.0433 - val_loss: 1945530425.6270\n",
      "Epoch 9523/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 140300367.6308 - val_loss: 665781524.1541\n",
      "Epoch 9524/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 189665030.2223 - val_loss: 619926671.4937\n",
      "Epoch 9525/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 77413313.3157 - val_loss: 657076489.8858\n",
      "Epoch 9526/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 115626239.7153 - val_loss: 734545999.0819\n",
      "Epoch 9527/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 155200842.1632 - val_loss: 836649793.1072\n",
      "Epoch 9528/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 183957483.8312 - val_loss: 677398145.3075\n",
      "Epoch 9529/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 203518212.5380 - val_loss: 909573232.7156\n",
      "Epoch 9530/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 303931791.0751 - val_loss: 1132738432.4501\n",
      "Epoch 9531/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 551483883.8312 - val_loss: 1666778257.5347\n",
      "Epoch 9532/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 638985039.3787 - val_loss: 1223359629.0700\n",
      "Epoch 9533/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 290314998.7079 - val_loss: 646930287.0245\n",
      "Epoch 9534/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 125983784.1351 - val_loss: 690008364.2745\n",
      "Epoch 9535/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 139574098.2420 - val_loss: 1042231362.2954\n",
      "Epoch 9536/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 158168784.2071 - val_loss: 742017903.5195\n",
      "Epoch 9537/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 98296527.6038 - val_loss: 1016804220.9305\n",
      "Epoch 9538/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 604858866.0529 - val_loss: 959476155.9190\n",
      "Epoch 9539/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 670692767.6218 - val_loss: 2513901919.4149\n",
      "Epoch 9540/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 577676686.3793 - val_loss: 669517097.7491\n",
      "Epoch 9541/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 215019008.4524 - val_loss: 946467334.9851\n",
      "Epoch 9542/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 175063080.5999 - val_loss: 673638170.7499\n",
      "Epoch 9543/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 103788360.9139 - val_loss: 832784955.9089\n",
      "Epoch 9544/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 338411093.8255 - val_loss: 677484552.5896\n",
      "Epoch 9545/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1795919739.8942 - val_loss: 3294821276.0124\n",
      "Epoch 9546/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 416384229.6320 - val_loss: 1119801459.6861\n",
      "Epoch 9547/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 132906289.1840 - val_loss: 668695564.9887\n",
      "Epoch 9548/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 89974833.6837 - val_loss: 624950042.6847\n",
      "Epoch 9549/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 119052248.9769 - val_loss: 874466817.6990\n",
      "Epoch 9550/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 199703326.1272 - val_loss: 652374543.2911\n",
      "Epoch 9551/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 93275889.1210 - val_loss: 706466904.1215\n",
      "Epoch 9552/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 74882193.5847 - val_loss: 663492848.2970\n",
      "Epoch 9553/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 352982109.7850 - val_loss: 5059368900.7347\n",
      "Epoch 9554/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1350434853.9876 - val_loss: 830981717.5617\n",
      "Epoch 9555/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 122241159.2077 - val_loss: 1277796695.4397\n",
      "Epoch 9556/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 200520810.2825 - val_loss: 1136086474.2796\n",
      "Epoch 9557/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 320704739.0613 - val_loss: 1267172604.8225\n",
      "Epoch 9558/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 367875688.1125 - val_loss: 1154516013.3581\n",
      "Epoch 9559/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 257696171.5160 - val_loss: 747692991.8233\n",
      "Epoch 9560/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 173841437.0017 - val_loss: 646396412.9778\n",
      "Epoch 9561/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 616867042.0169 - val_loss: 1881244889.7080\n",
      "Epoch 9562/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 476240491.4620 - val_loss: 1333913373.0205\n",
      "Epoch 9563/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 647018687.1716 - val_loss: 1758296128.8461\n",
      "Epoch 9564/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 429695835.3405 - val_loss: 754356759.9977\n",
      "Epoch 9565/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 90028796.0765 - val_loss: 663022415.8504\n",
      "Epoch 9566/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 102974917.8616 - val_loss: 920333932.6785\n",
      "Epoch 9567/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 118425638.7349 - val_loss: 741746022.4169\n",
      "Epoch 9568/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 232287369.1120 - val_loss: 766398715.1572\n",
      "Epoch 9569/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 333397300.4389 - val_loss: 701850394.0996\n",
      "Epoch 9570/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 88us/step - loss: 301930701.0377 - val_loss: 828564179.5195\n",
      "Epoch 9571/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 361477301.1052 - val_loss: 980781016.1238\n",
      "Epoch 9572/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 431307427.0793 - val_loss: 2492401500.6425\n",
      "Epoch 9573/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 360623885.6500 - val_loss: 1015216810.3269\n",
      "Epoch 9574/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 278060481.4902 - val_loss: 650240320.6436\n",
      "Epoch 9575/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 479655075.8717 - val_loss: 853363484.6065\n",
      "Epoch 9576/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 256405653.1953 - val_loss: 1211872350.2087\n",
      "Epoch 9577/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 746996371.5937 - val_loss: 1305905444.1857\n",
      "Epoch 9578/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 510982039.8053 - val_loss: 960011643.0312\n",
      "Epoch 9579/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 89020815.2617 - val_loss: 730176672.1350\n",
      "Epoch 9580/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 142262022.7349 - val_loss: 697684975.7376\n",
      "Epoch 9581/10000\n",
      "3554/3554 [==============================] - 1s 143us/step - loss: 81753887.0658 - val_loss: 655857262.9052\n",
      "Epoch 9582/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 112628968.3196 - val_loss: 868128903.2551\n",
      "Epoch 9583/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 164623536.3692 - val_loss: 1028376013.7215\n",
      "Epoch 9584/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 440376171.2684 - val_loss: 1085904468.5412\n",
      "Epoch 9585/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 380510432.5909 - val_loss: 903758449.3187\n",
      "Epoch 9586/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 184561559.2302 - val_loss: 1292232181.7024\n",
      "Epoch 9587/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 414518229.1412 - val_loss: 6934997494.3505\n",
      "Epoch 9588/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1088895431.1311 - val_loss: 1912607208.0788\n",
      "Epoch 9589/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 635109258.0124 - val_loss: 1367851545.5820\n",
      "Epoch 9590/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1085674873.3078 - val_loss: 932891063.9572\n",
      "Epoch 9591/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 213439100.7496 - val_loss: 886917438.9288\n",
      "Epoch 9592/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 149683738.8633 - val_loss: 619028812.8259\n",
      "Epoch 9593/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 62102638.4288 - val_loss: 620770614.4765\n",
      "Epoch 9594/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 88496813.0647 - val_loss: 688536090.8647\n",
      "Epoch 9595/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 171987831.3495 - val_loss: 1031125523.3260\n",
      "Epoch 9596/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 168226227.2437 - val_loss: 911995168.3241\n",
      "Epoch 9597/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 149449556.7451 - val_loss: 1463475119.1674\n",
      "Epoch 9598/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1020967015.6533 - val_loss: 3119361224.8034\n",
      "Epoch 9599/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 572632823.7524 - val_loss: 975358594.5654\n",
      "Epoch 9600/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 172555298.6111 - val_loss: 709580428.0889\n",
      "Epoch 9601/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 91928816.6708 - val_loss: 696642563.9190\n",
      "Epoch 9602/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 91568571.4080 - val_loss: 802293034.4326\n",
      "Epoch 9603/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 276552500.3455 - val_loss: 654973632.5356\n",
      "Epoch 9604/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 125358510.0506 - val_loss: 834191502.6228\n",
      "Epoch 9605/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 249892647.1401 - val_loss: 645206619.9089\n",
      "Epoch 9606/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 332596573.3168 - val_loss: 1317671885.9972\n",
      "Epoch 9607/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 559218167.4823 - val_loss: 767413224.0990\n",
      "Epoch 9608/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 214747668.7181 - val_loss: 820523350.5665\n",
      "Epoch 9609/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 333701275.6083 - val_loss: 1236797779.4903\n",
      "Epoch 9610/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 247906210.3793 - val_loss: 642354483.7423\n",
      "Epoch 9611/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 172580492.4975 - val_loss: 987829870.7353\n",
      "Epoch 9612/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1208928393.1840 - val_loss: 1419202248.6008\n",
      "Epoch 9613/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 297094751.9730 - val_loss: 809058664.1778\n",
      "Epoch 9614/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 107778549.3393 - val_loss: 941180966.6700\n",
      "Epoch 9615/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 195378574.9989 - val_loss: 618255431.4757\n",
      "Epoch 9616/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 66817052.8779 - val_loss: 1064771561.6585\n",
      "Epoch 9617/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 322876675.6556 - val_loss: 688045078.2290\n",
      "Epoch 9618/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 210229128.8768 - val_loss: 669057259.6253\n",
      "Epoch 9619/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 100805558.7980 - val_loss: 701606775.9111\n",
      "Epoch 9620/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 130662017.7648 - val_loss: 689588983.4779\n",
      "Epoch 9621/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 247909877.2223 - val_loss: 688545611.5083\n",
      "Epoch 9622/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 134231857.6050 - val_loss: 712288078.4473\n",
      "Epoch 9623/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 582416406.5279 - val_loss: 941730904.9969\n",
      "Epoch 9624/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1629409465.3686 - val_loss: 2253015108.1046\n",
      "Epoch 9625/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 374457461.0962 - val_loss: 876828742.5373\n",
      "Epoch 9626/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 282118788.6911 - val_loss: 711279010.4653\n",
      "Epoch 9627/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 138050428.2904 - val_loss: 648873124.0720\n",
      "Epoch 9628/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 94573447.3652 - val_loss: 631069245.3373\n",
      "Epoch 9629/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 147917089.1007 - val_loss: 695108282.6959\n",
      "Epoch 9630/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 118067446.4513 - val_loss: 710019300.6222\n",
      "Epoch 9631/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 136289832.2921 - val_loss: 624107848.8000\n",
      "Epoch 9632/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 332920605.9111 - val_loss: 1377788173.9454\n",
      "Epoch 9633/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 597203034.3275 - val_loss: 2275369961.3165\n",
      "Epoch 9634/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 319691175.4373 - val_loss: 1292284599.7772\n",
      "Epoch 9635/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1422389083.4080 - val_loss: 1098271209.0824\n",
      "Epoch 9636/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 583820439.1978 - val_loss: 808999663.5949\n",
      "Epoch 9637/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 126231550.0281 - val_loss: 698603141.4684\n",
      "Epoch 9638/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 150596301.6961 - val_loss: 670883154.1117\n",
      "Epoch 9639/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 104543981.7721 - val_loss: 707603804.8765\n",
      "Epoch 9640/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 129213824.1463 - val_loss: 828790193.2422\n",
      "Epoch 9641/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 149563788.7946 - val_loss: 707194577.6203\n",
      "Epoch 9642/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 428530035.2864 - val_loss: 2185592911.4374\n",
      "Epoch 9643/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 492393976.5582 - val_loss: 826605932.9755\n",
      "Epoch 9644/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 357631039.2437 - val_loss: 701399052.2802\n",
      "Epoch 9645/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 126501818.5526 - val_loss: 758093045.6101\n",
      "Epoch 9646/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 98259170.0619 - val_loss: 1326196707.5646\n",
      "Epoch 9647/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 298055912.4817 - val_loss: 1422663989.4774\n",
      "Epoch 9648/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 353691450.1880 - val_loss: 795693090.3848\n",
      "Epoch 9649/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 177091154.0529 - val_loss: 1777951828.6852\n",
      "Epoch 9650/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 604944250.9308 - val_loss: 1215768082.4169\n",
      "Epoch 9651/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 237917622.2037 - val_loss: 968338046.9828\n",
      "Epoch 9652/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 456812154.5796 - val_loss: 702360789.4695\n",
      "Epoch 9653/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 257693248.0630 - val_loss: 1609186240.1305\n",
      "Epoch 9654/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 867721667.8537 - val_loss: 3534497416.0293\n",
      "Epoch 9655/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1177768502.9510 - val_loss: 815849351.5747\n",
      "Epoch 9656/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 147368740.5110 - val_loss: 663519810.4484\n",
      "Epoch 9657/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 135851590.0191 - val_loss: 615860678.9491\n",
      "Epoch 9658/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 78182300.7338 - val_loss: 932558121.2624\n",
      "Epoch 9659/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 95076516.7451 - val_loss: 903171926.8906\n",
      "Epoch 9660/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 215861912.5898 - val_loss: 774507548.0776\n",
      "Epoch 9661/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 101206090.2915 - val_loss: 647218169.4920\n",
      "Epoch 9662/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 128070300.5425 - val_loss: 705437435.7828\n",
      "Epoch 9663/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 374674933.1953 - val_loss: 720083853.5831\n",
      "Epoch 9664/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 690534607.2459 - val_loss: 835603936.7381\n",
      "Epoch 9665/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 324538815.6173 - val_loss: 1141223836.0664\n",
      "Epoch 9666/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 160696440.0338 - val_loss: 901250168.2588\n",
      "Epoch 9667/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2169359734.0597 - val_loss: 17552121152.5941\n",
      "Epoch 9668/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 3010915216.5898 - val_loss: 658338772.6402\n",
      "Epoch 9669/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 105860379.1469 - val_loss: 683245804.3679\n",
      "Epoch 9670/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 97446809.8503 - val_loss: 624133282.3730\n",
      "Epoch 9671/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 89053769.4541 - val_loss: 631921448.8979\n",
      "Epoch 9672/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 63170357.8165 - val_loss: 765586792.9204\n",
      "Epoch 9673/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 71870063.8312 - val_loss: 604539418.5274\n",
      "Epoch 9674/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 74312392.9049 - val_loss: 703359525.2712\n",
      "Epoch 9675/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 97723803.0118 - val_loss: 775359374.0343\n",
      "Epoch 9676/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 100432771.5791 - val_loss: 785661865.1544\n",
      "Epoch 9677/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 64939249.9572 - val_loss: 665844764.0456\n",
      "Epoch 9678/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 79853980.0473 - val_loss: 651500177.5392\n",
      "Epoch 9679/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 103798920.8205 - val_loss: 690500773.3018\n",
      "Epoch 9680/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 114285612.3095 - val_loss: 733808317.1195\n",
      "Epoch 9681/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 258912332.1733 - val_loss: 2492260230.1750\n",
      "Epoch 9682/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 2910817436.0383 - val_loss: 1487688830.8478\n",
      "Epoch 9683/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 201981373.6086 - val_loss: 704797999.2574\n",
      "Epoch 9684/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 69622445.0974 - val_loss: 602174560.6655\n",
      "Epoch 9685/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 67844041.5892 - val_loss: 808293678.2627\n",
      "Epoch 9686/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 129853468.9288 - val_loss: 654994873.8318\n",
      "Epoch 9687/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 101723246.9105 - val_loss: 652735244.4782\n",
      "Epoch 9688/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 101625036.3894 - val_loss: 823176042.2549\n",
      "Epoch 9689/10000\n",
      "3554/3554 [==============================] - 0s 131us/step - loss: 155134748.3624 - val_loss: 1051812298.5316\n",
      "Epoch 9690/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 397215504.7158 - val_loss: 787571116.7100\n",
      "Epoch 9691/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 369418418.0315 - val_loss: 659019973.2591\n",
      "Epoch 9692/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 118108018.8903 - val_loss: 968760990.2627\n",
      "Epoch 9693/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 428282415.9550 - val_loss: 769779800.9069\n",
      "Epoch 9694/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 338777128.5177 - val_loss: 1671922009.3300\n",
      "Epoch 9695/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 322202658.3658 - val_loss: 746914597.4504\n",
      "Epoch 9696/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 200536951.5301 - val_loss: 685945773.8712\n",
      "Epoch 9697/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 116885795.4665 - val_loss: 729335238.9671\n",
      "Epoch 9698/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 404410567.0411 - val_loss: 1057053808.2115\n",
      "Epoch 9699/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 288408634.8227 - val_loss: 638063620.3567\n",
      "Epoch 9700/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 105us/step - loss: 633204863.1356 - val_loss: 1085357054.1637\n",
      "Epoch 9701/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 646746418.5481 - val_loss: 1619943072.3196\n",
      "Epoch 9702/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 301585414.6573 - val_loss: 748308270.5283\n",
      "Epoch 9703/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 84382332.7001 - val_loss: 935222812.2734\n",
      "Epoch 9704/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 370222809.8953 - val_loss: 1633407353.5955\n",
      "Epoch 9705/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 224618189.8661 - val_loss: 665521939.8008\n",
      "Epoch 9706/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 561589953.2245 - val_loss: 872430696.8034\n",
      "Epoch 9707/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 291096779.7231 - val_loss: 828494442.4686\n",
      "Epoch 9708/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 289369955.7648 - val_loss: 642271231.5904\n",
      "Epoch 9709/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 620880046.5324 - val_loss: 31372656053.8284\n",
      "Epoch 9710/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 6106468959.4868 - val_loss: 728956431.1539\n",
      "Epoch 9711/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 118766317.5385 - val_loss: 655779670.3359\n",
      "Epoch 9712/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 78819492.1080 - val_loss: 650356270.4411\n",
      "Epoch 9713/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 60242332.3433 - val_loss: 697913047.7120\n",
      "Epoch 9714/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 66452411.1570 - val_loss: 660674310.7769\n",
      "Epoch 9715/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 73196804.9252 - val_loss: 1076955608.0968\n",
      "Epoch 9716/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 109732477.3528 - val_loss: 613708991.6388\n",
      "Epoch 9717/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 64950291.5757 - val_loss: 656134959.4104\n",
      "Epoch 9718/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 73733149.6770 - val_loss: 771410626.1063\n",
      "Epoch 9719/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 250418722.2220 - val_loss: 615623422.9089\n",
      "Epoch 9720/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 67818352.9184 - val_loss: 1082803568.7066\n",
      "Epoch 9721/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 100392421.7921 - val_loss: 608392230.1378\n",
      "Epoch 9722/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 86596392.7968 - val_loss: 923034354.7859\n",
      "Epoch 9723/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 161304527.0084 - val_loss: 741197532.1339\n",
      "Epoch 9724/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 117864182.8880 - val_loss: 723225023.9775\n",
      "Epoch 9725/10000\n",
      "3554/3554 [==============================] - 0s 140us/step - loss: 215346737.9719 - val_loss: 1809470715.8053\n",
      "Epoch 9726/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 574966247.9707 - val_loss: 1743759088.2745\n",
      "Epoch 9727/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 703552773.8526 - val_loss: 1276861643.2518\n",
      "Epoch 9728/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 260562037.4294 - val_loss: 737066125.3603\n",
      "Epoch 9729/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 316905486.4063 - val_loss: 749425532.8596\n",
      "Epoch 9730/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 197394925.7040 - val_loss: 782669453.0385\n",
      "Epoch 9731/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 134933733.6140 - val_loss: 841700573.1218\n",
      "Epoch 9732/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 321751978.0124 - val_loss: 761991250.5857\n",
      "Epoch 9733/10000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 194544558.1902 - val_loss: 685746781.7958\n",
      "Epoch 9734/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 130903310.6967 - val_loss: 639680404.0866\n",
      "Epoch 9735/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 206246128.3557 - val_loss: 809544350.0737\n",
      "Epoch 9736/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 215294739.5791 - val_loss: 1854051497.6225\n",
      "Epoch 9737/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 388718923.3270 - val_loss: 1944194224.9677\n",
      "Epoch 9738/10000\n",
      "3554/3554 [==============================] - 1s 146us/step - loss: 678627938.8745 - val_loss: 906765285.3288\n",
      "Epoch 9739/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 107407111.8393 - val_loss: 771679706.0771\n",
      "Epoch 9740/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 293780322.8452 - val_loss: 823118699.8819\n",
      "Epoch 9741/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 168719388.4457 - val_loss: 894537830.9041\n",
      "Epoch 9742/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 141188901.7355 - val_loss: 1000773868.8405\n",
      "Epoch 9743/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 191715144.9454 - val_loss: 876600354.1761\n",
      "Epoch 9744/10000\n",
      "3554/3554 [==============================] - 0s 139us/step - loss: 621136934.0146 - val_loss: 718746844.2023\n",
      "Epoch 9745/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 625800844.0293 - val_loss: 2119570042.9232\n",
      "Epoch 9746/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 482961748.0878 - val_loss: 628062871.9336\n",
      "Epoch 9747/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 108549983.9280 - val_loss: 938522450.7679\n",
      "Epoch 9748/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 141610864.9634 - val_loss: 1294434794.6127\n",
      "Epoch 9749/10000\n",
      "3554/3554 [==============================] - 1s 150us/step - loss: 294999671.8604 - val_loss: 682317499.4408\n",
      "Epoch 9750/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 122122541.2819 - val_loss: 1113443062.1390\n",
      "Epoch 9751/10000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 517334334.3073 - val_loss: 1056113823.3294\n",
      "Epoch 9752/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 280362495.3517 - val_loss: 618946194.0523\n",
      "Epoch 9753/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 187953006.1947 - val_loss: 735337932.9260\n",
      "Epoch 9754/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 139606942.8633 - val_loss: 642851316.2318\n",
      "Epoch 9755/10000\n",
      "3554/3554 [==============================] - 0s 139us/step - loss: 140920194.3680 - val_loss: 808899151.7086\n",
      "Epoch 9756/10000\n",
      "3554/3554 [==============================] - 1s 141us/step - loss: 146834310.5008 - val_loss: 1931372772.6717\n",
      "Epoch 9757/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 595265289.7243 - val_loss: 1081755218.1018\n",
      "Epoch 9758/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 750941503.9280 - val_loss: 2379840703.2619\n",
      "Epoch 9759/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 356212181.6050 - val_loss: 1244682106.4911\n",
      "Epoch 9760/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 147564328.1711 - val_loss: 683018509.1376\n",
      "Epoch 9761/10000\n",
      "3554/3554 [==============================] - 0s 135us/step - loss: 304685100.2273 - val_loss: 1198315212.3634\n",
      "Epoch 9762/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 978354790.4288 - val_loss: 1037316402.7679\n",
      "Epoch 9763/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 213070442.5166 - val_loss: 628498969.4762\n",
      "Epoch 9764/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 92044753.0400 - val_loss: 889128587.8312\n",
      "Epoch 9765/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 388441930.9510 - val_loss: 696262197.4228\n",
      "Epoch 9766/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 156488316.7698 - val_loss: 906463063.3902\n",
      "Epoch 9767/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 177340936.5357 - val_loss: 899638583.7907\n",
      "Epoch 9768/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 199757290.0754 - val_loss: 1662493751.6827\n",
      "Epoch 9769/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1708334277.7265 - val_loss: 925159319.2754\n",
      "Epoch 9770/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 218154480.9781 - val_loss: 628493518.4293\n",
      "Epoch 9771/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 64720526.4716 - val_loss: 678183057.6405\n",
      "Epoch 9772/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 59276470.9668 - val_loss: 638979676.7685\n",
      "Epoch 9773/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 75602021.8458 - val_loss: 661475693.4504\n",
      "Epoch 9774/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 109010960.6528 - val_loss: 991949291.9359\n",
      "Epoch 9775/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 188516483.5611 - val_loss: 733084767.1117\n",
      "Epoch 9776/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 162432063.8559 - val_loss: 857775860.8743\n",
      "Epoch 9777/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 495579623.8694 - val_loss: 4828327875.7266\n",
      "Epoch 9778/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 2020587068.3286 - val_loss: 884043939.1775\n",
      "Epoch 9779/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 110164293.4772 - val_loss: 683622482.9210\n",
      "Epoch 9780/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 117135894.4558 - val_loss: 1560744135.2371\n",
      "Epoch 9781/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 574596912.9454 - val_loss: 5513194426.6892\n",
      "Epoch 9782/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 826891972.6348 - val_loss: 708351762.3550\n",
      "Epoch 9783/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 80583275.3596 - val_loss: 626756892.0595\n",
      "Epoch 9784/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 78095595.1064 - val_loss: 636975924.9868\n",
      "Epoch 9785/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 65856413.5644 - val_loss: 603607053.9935\n",
      "Epoch 9786/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 85595676.5695 - val_loss: 693646834.7972\n",
      "Epoch 9787/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 193335884.3714 - val_loss: 894368280.8045\n",
      "Epoch 9788/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 394543943.8987 - val_loss: 1134562846.1772\n",
      "Epoch 9789/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 165314562.1120 - val_loss: 963384384.1170\n",
      "Epoch 9790/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 134788173.1097 - val_loss: 5068366301.1105\n",
      "Epoch 9791/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1089471388.9927 - val_loss: 907248288.3511\n",
      "Epoch 9792/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 428759030.2757 - val_loss: 1183248881.8183\n",
      "Epoch 9793/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 269801735.6173 - val_loss: 1779524964.8518\n",
      "Epoch 9794/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 364870037.7580 - val_loss: 801487215.4374\n",
      "Epoch 9795/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 136104061.2234 - val_loss: 639143839.0667\n",
      "Epoch 9796/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 76485393.5695 - val_loss: 1206599003.9764\n",
      "Epoch 9797/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 707662914.1609 - val_loss: 2672773146.5541\n",
      "Epoch 9798/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 400878043.8852 - val_loss: 1356926835.1100\n",
      "Epoch 9799/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 429929374.9015 - val_loss: 1045229434.1851\n",
      "Epoch 9800/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 309132973.9741 - val_loss: 818334649.3840\n",
      "Epoch 9801/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 124116921.8171 - val_loss: 621972389.7395\n",
      "Epoch 9802/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 116100429.6905 - val_loss: 703983314.0354\n",
      "Epoch 9803/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 384547488.7428 - val_loss: 1423040514.7364\n",
      "Epoch 9804/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 502758842.5076 - val_loss: 1145341338.2751\n",
      "Epoch 9805/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 257878307.9797 - val_loss: 753267812.0191\n",
      "Epoch 9806/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 93446274.7057 - val_loss: 644291995.5899\n",
      "Epoch 9807/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 228024067.9257 - val_loss: 905321206.7105\n",
      "Epoch 9808/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 265016268.3939 - val_loss: 813456651.7243\n",
      "Epoch 9809/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 177070002.8633 - val_loss: 696193920.2205\n",
      "Epoch 9810/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 183643076.2499 - val_loss: 2213069267.4790\n",
      "Epoch 9811/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 434740307.1964 - val_loss: 915677047.2011\n",
      "Epoch 9812/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 213879939.2831 - val_loss: 1047203744.5221\n",
      "Epoch 9813/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 234832865.9268 - val_loss: 894364938.2571\n",
      "Epoch 9814/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 389595242.9758 - val_loss: 811541351.9021\n",
      "Epoch 9815/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 128328638.2532 - val_loss: 1061991971.9651\n",
      "Epoch 9816/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 267126406.2364 - val_loss: 810219595.8459\n",
      "Epoch 9817/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 576857817.9223 - val_loss: 1264282067.1460\n",
      "Epoch 9818/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 323631936.5245 - val_loss: 668080934.8793\n",
      "Epoch 9819/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 249180551.7434 - val_loss: 721802238.9198\n",
      "Epoch 9820/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 450220676.2499 - val_loss: 820033739.4082\n",
      "Epoch 9821/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 606757597.2808 - val_loss: 4634764933.0768\n",
      "Epoch 9822/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1105111652.6798 - val_loss: 995418862.9378\n",
      "Epoch 9823/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 149349575.0672 - val_loss: 965554002.4034\n",
      "Epoch 9824/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 354596840.3478 - val_loss: 639432516.0020\n",
      "Epoch 9825/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 102757960.6528 - val_loss: 619493502.3235\n",
      "Epoch 9826/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 809764763.8042 - val_loss: 9349157774.0782\n",
      "Epoch 9827/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1168812861.1367 - val_loss: 668002829.3446\n",
      "Epoch 9828/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 96052849.2088 - val_loss: 738203453.1556\n",
      "Epoch 9829/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 132895792.8666 - val_loss: 726073629.4526\n",
      "Epoch 9830/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 83us/step - loss: 99124993.5577 - val_loss: 962997712.3646\n",
      "Epoch 9831/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 157306554.1474 - val_loss: 722423295.0278\n",
      "Epoch 9832/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 210445968.4727 - val_loss: 761852392.2959\n",
      "Epoch 9833/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 287460253.3889 - val_loss: 2071261064.6999\n",
      "Epoch 9834/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 720238666.1204 - val_loss: 709203412.7527\n",
      "Epoch 9835/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 262551561.7558 - val_loss: 677065089.0802\n",
      "Epoch 9836/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 89821263.5318 - val_loss: 670340612.9598\n",
      "Epoch 9837/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 188614276.2183 - val_loss: 712054146.7004\n",
      "Epoch 9838/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 138420347.3180 - val_loss: 940104006.0669\n",
      "Epoch 9839/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 194471978.5234 - val_loss: 755791954.3572\n",
      "Epoch 9840/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 136360710.5256 - val_loss: 689042326.2830\n",
      "Epoch 9841/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 207815912.7338 - val_loss: 816659435.6118\n",
      "Epoch 9842/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 211578049.8165 - val_loss: 685549389.8734\n",
      "Epoch 9843/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 350788775.9415 - val_loss: 4206219023.2844\n",
      "Epoch 9844/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1175163327.9280 - val_loss: 1148798997.3513\n",
      "Epoch 9845/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 383078304.6933 - val_loss: 642076298.8917\n",
      "Epoch 9846/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 103789701.9426 - val_loss: 872729349.7136\n",
      "Epoch 9847/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 248965377.1210 - val_loss: 995160300.0259\n",
      "Epoch 9848/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 197814794.5675 - val_loss: 865977345.8700\n",
      "Epoch 9849/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1993128780.8576 - val_loss: 8101925008.7966\n",
      "Epoch 9850/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 844540721.6688 - val_loss: 665829062.4090\n",
      "Epoch 9851/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 77686057.3911 - val_loss: 1092230664.3443\n",
      "Epoch 9852/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 149430173.3889 - val_loss: 635087548.3454\n",
      "Epoch 9853/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 87004987.9325 - val_loss: 770181146.2751\n",
      "Epoch 9854/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 178539301.8255 - val_loss: 779943894.3775\n",
      "Epoch 9855/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 101616451.4215 - val_loss: 701058797.7958\n",
      "Epoch 9856/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 123427672.7822 - val_loss: 689371206.6790\n",
      "Epoch 9857/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 102212112.7473 - val_loss: 735174066.0726\n",
      "Epoch 9858/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 109608977.5307 - val_loss: 1514582005.6484\n",
      "Epoch 9859/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 559057334.6044 - val_loss: 768014328.4028\n",
      "Epoch 9860/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 483527111.1671 - val_loss: 887115600.8056\n",
      "Epoch 9861/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 267530077.9336 - val_loss: 662550492.6875\n",
      "Epoch 9862/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 202107746.1069 - val_loss: 817990196.8923\n",
      "Epoch 9863/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 131879826.8362 - val_loss: 704592089.7575\n",
      "Epoch 9864/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 184513470.3433 - val_loss: 1421673428.8113\n",
      "Epoch 9865/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1137169193.8683 - val_loss: 1158630598.8377\n",
      "Epoch 9866/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 552970331.2459 - val_loss: 1889120516.8428\n",
      "Epoch 9867/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 206336886.7597 - val_loss: 865094245.0273\n",
      "Epoch 9868/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 162483160.4727 - val_loss: 703635972.4062\n",
      "Epoch 9869/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 285677713.8638 - val_loss: 657885809.1589\n",
      "Epoch 9870/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 96729877.3258 - val_loss: 658165033.0802\n",
      "Epoch 9871/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 92902284.5605 - val_loss: 781467143.4082\n",
      "Epoch 9872/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 267096813.1367 - val_loss: 859539311.7345\n",
      "Epoch 9873/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 264442679.5903 - val_loss: 1775009944.3128\n",
      "Epoch 9874/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 303497597.0827 - val_loss: 818505217.1499\n",
      "Epoch 9875/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 269828021.1773 - val_loss: 1102113493.0633\n",
      "Epoch 9876/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 114222570.6517 - val_loss: 773581770.4090\n",
      "Epoch 9877/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 443815637.0692 - val_loss: 1115339891.2000\n",
      "Epoch 9878/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 588249492.0158 - val_loss: 635296319.1606\n",
      "Epoch 9879/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 96778271.9325 - val_loss: 760225549.1207\n",
      "Epoch 9880/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 287388614.8475 - val_loss: 1637665185.9713\n",
      "Epoch 9881/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 273330254.9015 - val_loss: 1711074519.6017\n",
      "Epoch 9882/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 537183337.1930 - val_loss: 708785336.7595\n",
      "Epoch 9883/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 187177873.6972 - val_loss: 1223617655.2956\n",
      "Epoch 9884/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 213880770.7710 - val_loss: 1278541167.5274\n",
      "Epoch 9885/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 714435948.2093 - val_loss: 1170374294.1165\n",
      "Epoch 9886/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 329970112.5965 - val_loss: 680691401.1094\n",
      "Epoch 9887/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 165020981.2358 - val_loss: 673423089.8588\n",
      "Epoch 9888/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 739300632.0945 - val_loss: 3958367176.8754\n",
      "Epoch 9889/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 361024117.7895 - val_loss: 697511870.9873\n",
      "Epoch 9890/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 128173770.6697 - val_loss: 659437000.8574\n",
      "Epoch 9891/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 110378649.4496 - val_loss: 675626410.2481\n",
      "Epoch 9892/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 297654342.2487 - val_loss: 2643970663.5162\n",
      "Epoch 9893/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 609565005.5599 - val_loss: 2043373358.8973\n",
      "Epoch 9894/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 959349324.8171 - val_loss: 956046749.3986\n",
      "Epoch 9895/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 189373091.4305 - val_loss: 852806220.5457\n",
      "Epoch 9896/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 132951050.1294 - val_loss: 739158901.3468\n",
      "Epoch 9897/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 142809708.1193 - val_loss: 635470430.6565\n",
      "Epoch 9898/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 155055234.2915 - val_loss: 734746715.5893\n",
      "Epoch 9899/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 209495788.5155 - val_loss: 800903261.2084\n",
      "Epoch 9900/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 429594413.4969 - val_loss: 818727815.2686\n",
      "Epoch 9901/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 212336966.2757 - val_loss: 1480999317.5314\n",
      "Epoch 9902/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 231309760.0822 - val_loss: 679118379.6444\n",
      "Epoch 9903/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 124182492.9927 - val_loss: 789753334.4405\n",
      "Epoch 9904/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 467676775.0951 - val_loss: 1277401933.8262\n",
      "Epoch 9905/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 392480212.9432 - val_loss: 710180198.9356\n",
      "Epoch 9906/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 224259081.3686 - val_loss: 681064864.9361\n",
      "Epoch 9907/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 109287518.9015 - val_loss: 749641499.2203\n",
      "Epoch 9908/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 144760169.9944 - val_loss: 1609283165.3266\n",
      "Epoch 9909/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1536533700.2499 - val_loss: 1722818972.6965\n",
      "Epoch 9910/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 253995883.6916 - val_loss: 772281995.8098\n",
      "Epoch 9911/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 314728824.2198 - val_loss: 714533697.5167\n",
      "Epoch 9912/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 92152709.9066 - val_loss: 659894894.3032\n",
      "Epoch 9913/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 140589394.3230 - val_loss: 648681546.7195\n",
      "Epoch 9914/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 90097263.4834 - val_loss: 622927494.0423\n",
      "Epoch 9915/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 78841508.3174 - val_loss: 634628199.7941\n",
      "Epoch 9916/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 234652209.5397 - val_loss: 824992131.8256\n",
      "Epoch 9917/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 345539203.4823 - val_loss: 757987331.8278\n",
      "Epoch 9918/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 842597120.5763 - val_loss: 1307198505.3345\n",
      "Epoch 9919/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 343423759.3067 - val_loss: 741649990.0534\n",
      "Epoch 9920/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 262352134.4153 - val_loss: 891953123.8976\n",
      "Epoch 9921/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 236497073.3416 - val_loss: 756171768.3724\n",
      "Epoch 9922/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 132661250.9252 - val_loss: 638048705.7294\n",
      "Epoch 9923/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 163199462.7169 - val_loss: 781443045.3198\n",
      "Epoch 9924/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 551245564.2093 - val_loss: 1236426777.9848\n",
      "Epoch 9925/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 251125359.9055 - val_loss: 768124849.0262\n",
      "Epoch 9926/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 448429029.3483 - val_loss: 2290467842.5384\n",
      "Epoch 9927/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1214979445.8255 - val_loss: 963396634.1041\n",
      "Epoch 9928/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 271789377.7828 - val_loss: 758178761.3705\n",
      "Epoch 9929/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 280673761.4271 - val_loss: 650597037.7795\n",
      "Epoch 9930/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 88684064.8104 - val_loss: 1224265417.6855\n",
      "Epoch 9931/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 589750047.0951 - val_loss: 1041598343.0211\n",
      "Epoch 9932/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 339209075.3630 - val_loss: 678364212.3769\n",
      "Epoch 9933/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 89307943.9595 - val_loss: 658911033.6045\n",
      "Epoch 9934/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 102397802.5166 - val_loss: 3570114579.4430\n",
      "Epoch 9935/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 682285160.8779 - val_loss: 664868944.1823\n",
      "Epoch 9936/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 137901910.1857 - val_loss: 843672023.1156\n",
      "Epoch 9937/10000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 106311211.945 - 0s 85us/step - loss: 108168287.9640 - val_loss: 2801279843.5916\n",
      "Epoch 9938/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 498949472.0000 - val_loss: 650050488.6073\n",
      "Epoch 9939/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 128309958.9522 - val_loss: 700910241.2827\n",
      "Epoch 9940/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 107801384.5492 - val_loss: 633144061.9522\n",
      "Epoch 9941/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 177690122.6967 - val_loss: 1321140855.8627\n",
      "Epoch 9942/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 510613930.9207 - val_loss: 1312738735.0053\n",
      "Epoch 9943/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 214982602.4491 - val_loss: 967472969.2354\n",
      "Epoch 9944/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 211097624.1711 - val_loss: 743964184.7269\n",
      "Epoch 9945/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 408066247.7434 - val_loss: 1155438287.2101\n",
      "Epoch 9946/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 230627067.4080 - val_loss: 802041474.9390\n",
      "Epoch 9947/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 173899962.1384 - val_loss: 1439212580.6357\n",
      "Epoch 9948/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 678755470.5684 - val_loss: 703127567.5454\n",
      "Epoch 9949/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 131222140.0383 - val_loss: 1703755331.2585\n",
      "Epoch 9950/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 469385612.5695 - val_loss: 963539073.6968\n",
      "Epoch 9951/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2972674154.1632 - val_loss: 793869919.1584\n",
      "Epoch 9952/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 148916207.4237 - val_loss: 892518237.7744\n",
      "Epoch 9953/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 78910726.2442 - val_loss: 777443765.5044\n",
      "Epoch 9954/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 100732465.4406 - val_loss: 618859461.6990\n",
      "Epoch 9955/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 94743206.2712 - val_loss: 931111085.4841\n",
      "Epoch 9956/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 246068203.1919 - val_loss: 657586417.9331\n",
      "Epoch 9957/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 70571360.8183 - val_loss: 677061760.1575\n",
      "Epoch 9958/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 64872067.7704 - val_loss: 677373290.1243\n",
      "Epoch 9959/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 202985256.7158 - val_loss: 690671709.4549\n",
      "Epoch 9960/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 95us/step - loss: 91378799.9460 - val_loss: 947938753.9263\n",
      "Epoch 9961/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 229093011.7839 - val_loss: 918461612.9980\n",
      "Epoch 9962/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 213273496.6258 - val_loss: 695100883.6096\n",
      "Epoch 9963/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 259815617.4676 - val_loss: 922935041.6563\n",
      "Epoch 9964/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 126862388.4569 - val_loss: 694190825.5865\n",
      "Epoch 9965/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 156569250.5571 - val_loss: 640570322.7409\n",
      "Epoch 9966/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 201760317.9831 - val_loss: 821751126.6295\n",
      "Epoch 9967/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 295207893.8616 - val_loss: 664780867.7198\n",
      "Epoch 9968/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 680205361.8458 - val_loss: 1249894555.8323\n",
      "Epoch 9969/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 622458106.3388 - val_loss: 695688199.2191\n",
      "Epoch 9970/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 184526061.0917 - val_loss: 715000506.1221\n",
      "Epoch 9971/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 107822492.4344 - val_loss: 790934455.2439\n",
      "Epoch 9972/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 129027457.7378 - val_loss: 1383913242.6172\n",
      "Epoch 9973/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 549280774.4828 - val_loss: 9840150950.4180\n",
      "Epoch 9974/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 1714316256.1857 - val_loss: 695924643.2551\n",
      "Epoch 9975/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 365614415.5464 - val_loss: 985884498.3359\n",
      "Epoch 9976/10000\n",
      "3554/3554 [==============================] - 1s 142us/step - loss: 496924855.8807 - val_loss: 829566793.6720\n",
      "Epoch 9977/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 147523411.4125 - val_loss: 2128255217.2737\n",
      "Epoch 9978/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 356745697.1435 - val_loss: 753725819.6231\n",
      "Epoch 9979/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 71820266.9330 - val_loss: 673220609.6917\n",
      "Epoch 9980/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 97128686.6044 - val_loss: 791324711.4532\n",
      "Epoch 9981/10000\n",
      "3554/3554 [==============================] - 0s 134us/step - loss: 107681776.0810 - val_loss: 757253888.8371\n",
      "Epoch 9982/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 205364392.6224 - val_loss: 694595139.3148\n",
      "Epoch 9983/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 68726376.5627 - val_loss: 849994701.2501\n",
      "Epoch 9984/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 410484556.7856 - val_loss: 837842358.6565\n",
      "Epoch 9985/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 378906450.2060 - val_loss: 675637990.6869\n",
      "Epoch 9986/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 151799907.6421 - val_loss: 1452152403.6591\n",
      "Epoch 9987/10000\n",
      "3554/3554 [==============================] - 1s 155us/step - loss: 202717167.4508 - val_loss: 1195309465.5190\n",
      "Epoch 9988/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 209745037.0917 - val_loss: 1572418869.7204\n",
      "Epoch 9989/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 309586287.5678 - val_loss: 1735632047.0774\n",
      "Epoch 9990/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 217977470.6674 - val_loss: 2680637578.2616\n",
      "Epoch 9991/10000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 279640779.1199 - val_loss: 761602572.3319\n",
      "Epoch 9992/10000\n",
      "3554/3554 [==============================] - 1s 142us/step - loss: 293426521.7693 - val_loss: 796958250.5496\n",
      "Epoch 9993/10000\n",
      "3554/3554 [==============================] - 0s 135us/step - loss: 239506580.4930 - val_loss: 1185179850.6217\n",
      "Epoch 9994/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 310271923.6106 - val_loss: 729526090.7331\n",
      "Epoch 9995/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 236407615.4147 - val_loss: 3856560270.5823\n",
      "Epoch 9996/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 796557421.2358 - val_loss: 1157392940.6470\n",
      "Epoch 9997/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 402179509.5093 - val_loss: 750578790.3325\n",
      "Epoch 9998/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 117556419.4575 - val_loss: 1165676917.3378\n",
      "Epoch 9999/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 255337550.8385 - val_loss: 1998236497.2827\n",
      "Epoch 10000/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 672733819.6061 - val_loss: 818816153.7845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbb1715f198>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile model\n",
    "model22.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(\"model22 loss:\",model22.loss)\n",
    "\n",
    "model_train22 = model22.fit(predictors,target, epochs=10000, validation_split=0.5, callbacks=[early_stopping_monitor], verbose=True)\n",
    "model_train22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbb160c8198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the plot\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(model_train22.history['val_loss'], 'r')\n",
    "plt.title(\"Adam only\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.savefig(\"adam_5_layrs_10000_epochs_only_with_800_callbacks\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model22.save(\"adam_5_layers_10000_epochs_only_with_800_callbacks.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('adam_5_layers_10000_epochs_only_with_800_callbacks.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing output file to neural4.csv\n"
     ]
    }
   ],
   "source": [
    "# Calculate predictions: predictions\n",
    "predictions = model.predict(X_test.values)\n",
    "predictions = pd.DataFrame(predictions)\n",
    "\n",
    "output = pd.DataFrame(data = {\"PRT_ID\":test[\"PRT_ID\"]})\n",
    "\n",
    "result = pd.concat([output, predictions], axis=1)\n",
    "\n",
    "result.columns = ['PRT_ID','SALES_PRICE']\n",
    "print(\"Writing output file to neural4.csv\")\n",
    "result.to_csv(\"../output/neural4.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
