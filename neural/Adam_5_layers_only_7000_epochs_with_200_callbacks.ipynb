{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#the less hidden layes didn't work out as per the graph above so using more hidden layers\n",
    "#as per above diagram using only adam and nadam\n",
    "#importing pandas to visualise the dataset in tabular format\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 150)\n",
    "\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#introducing stable analysis through random seed\n",
    "np.random.seed(42)\n",
    "#importing time function to create animated behaviour\n",
    "import time\n",
    "#importing regExp for data cleaning\n",
    "import re\n",
    "from numpy import NaN\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(patience=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/scaled_train.csv\")\n",
    "test = pd.read_csv(\"../data/scaled_test.csv\")\n",
    "\n",
    "X_train = df.drop(['PRT_ID','SALES_PRICE'],axis=1)\n",
    "y_train = df['SALES_PRICE']\n",
    "\n",
    "X_test = test.drop(['PRT_ID'],axis=1)\n",
    "\n",
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Specify the model\n",
    "predictors = X_train.values\n",
    "target = y_train.values.reshape((-1,1)).astype('int32')\n",
    "\n",
    "n_cols = predictors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model 2\n",
    "model22 = Sequential()\n",
    "model22.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "model22.add(Dense(80, kernel_initializer='normal', activation='relu'))\n",
    "model22.add(Dense(70, kernel_initializer='normal', activation='relu'))\n",
    "model22.add(Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "model22.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model22.add(Dense(1, kernel_initializer='normal'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model22 loss: mean_squared_error\n",
      "Train on 3554 samples, validate on 3555 samples\n",
      "Epoch 1/10000\n",
      "3554/3554 [==============================] - 1s 158us/step - loss: 133371024731922.5938 - val_loss: 131307119751277.4531\n",
      "Epoch 2/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 93254559874251.4062 - val_loss: 10493527908156.1289\n",
      "Epoch 3/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 8065208324997.2588 - val_loss: 6698304432197.7070\n",
      "Epoch 4/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 6279319453142.7979 - val_loss: 5763810609671.0566\n",
      "Epoch 5/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 5359008834886.7344 - val_loss: 5078142306712.4482\n",
      "Epoch 6/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 4786608320376.0049 - val_loss: 4660662262238.7305\n",
      "Epoch 7/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 4385432300187.2998 - val_loss: 4374429738252.7461\n",
      "Epoch 8/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 4111369019073.9087 - val_loss: 4156782138054.8950\n",
      "Epoch 9/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 3896842678661.5469 - val_loss: 3991567054181.4639\n",
      "Epoch 10/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 3716044202882.9531 - val_loss: 3936366025560.6460\n",
      "Epoch 11/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 3585803792506.1655 - val_loss: 3749884071490.1064\n",
      "Epoch 12/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 3449924859600.8916 - val_loss: 3619757530216.5605\n",
      "Epoch 13/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 3335835445140.8174 - val_loss: 3570739750746.6621\n",
      "Epoch 14/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 3232783961243.0117 - val_loss: 3423757804840.3984\n",
      "Epoch 15/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 3127385387268.4658 - val_loss: 3295178370499.3667\n",
      "Epoch 16/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3038563589890.4487 - val_loss: 3288102587910.1929\n",
      "Epoch 17/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 2938199352987.8765 - val_loss: 3156972433383.8042\n",
      "Epoch 18/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 2843546442697.2559 - val_loss: 3011721667465.6133\n",
      "Epoch 19/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2759974861437.3345 - val_loss: 2921461573360.6616\n",
      "Epoch 20/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 2668254123171.0791 - val_loss: 2865426912883.0742\n",
      "Epoch 21/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 2597653849608.3555 - val_loss: 2739091282265.0781\n",
      "Epoch 22/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2501001468555.1646 - val_loss: 2713751896262.1748\n",
      "Epoch 23/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2430732286824.4458 - val_loss: 2563415207202.0615\n",
      "Epoch 24/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 2353922486431.0454 - val_loss: 2477963174991.7886\n",
      "Epoch 25/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 2286701933376.1079 - val_loss: 2396331464224.1172\n",
      "Epoch 26/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 2191334562148.1238 - val_loss: 2323097137196.9351\n",
      "Epoch 27/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 2113367337479.7795 - val_loss: 2241577500436.9551\n",
      "Epoch 28/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2063234925963.8853 - val_loss: 2188531776867.7356\n",
      "Epoch 29/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1984302564425.1838 - val_loss: 2093534258241.9624\n",
      "Epoch 30/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1927562603209.4001 - val_loss: 2014898769368.1057\n",
      "Epoch 31/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1849374527126.1135 - val_loss: 1955311283573.0183\n",
      "Epoch 32/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1795751147355.1919 - val_loss: 1883987608243.3081\n",
      "Epoch 33/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1718164963742.9016 - val_loss: 1811265434271.7209\n",
      "Epoch 34/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1678293096933.2041 - val_loss: 1775000624223.3430\n",
      "Epoch 35/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1626193271204.6641 - val_loss: 1696714256848.3286\n",
      "Epoch 36/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1569577307567.6128 - val_loss: 1634838808233.2266\n",
      "Epoch 37/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1510598849316.4480 - val_loss: 1617130706353.5078\n",
      "Epoch 38/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1462896645412.1597 - val_loss: 1527698105511.3542\n",
      "Epoch 39/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1419503877120.5762 - val_loss: 1496203104022.1074\n",
      "Epoch 40/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1373859705129.3462 - val_loss: 1440414350323.0381\n",
      "Epoch 41/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1346588493407.9460 - val_loss: 1447675526052.6897\n",
      "Epoch 42/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1307532969936.7471 - val_loss: 1382427575262.8748\n",
      "Epoch 43/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1269073628969.6340 - val_loss: 1346322368141.5742\n",
      "Epoch 44/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1241797676251.5520 - val_loss: 1299866841423.2844\n",
      "Epoch 45/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1207887804500.1328 - val_loss: 1288320520538.8062\n",
      "Epoch 46/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1186272131488.0540 - val_loss: 1255991780454.8320\n",
      "Epoch 47/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1158447942359.2302 - val_loss: 1327510937708.3049\n",
      "Epoch 48/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1157313212280.0044 - val_loss: 1208389291480.1057\n",
      "Epoch 49/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1115360139352.7429 - val_loss: 1200028080403.9470\n",
      "Epoch 50/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1107399355745.2424 - val_loss: 1162948985389.6550\n",
      "Epoch 51/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1090835867909.6184 - val_loss: 1150429115666.5068\n",
      "Epoch 52/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1078761678021.6545 - val_loss: 1147121840891.8953\n",
      "Epoch 53/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1058828025800.6798 - val_loss: 1150007093396.0552\n",
      "Epoch 54/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1048504455184.1351 - val_loss: 1132365130926.8433\n",
      "Epoch 55/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1030254658826.8047 - val_loss: 1101732209411.9607\n",
      "Epoch 56/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1036429635945.8864 - val_loss: 1144251021793.0352\n",
      "Epoch 57/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1011129397019.8041 - val_loss: 1081691058746.3291\n",
      "Epoch 58/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1014846089219.4575 - val_loss: 1088495660372.7572\n",
      "Epoch 59/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1011336429005.5779 - val_loss: 1066155107675.0942\n",
      "Epoch 60/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 993112495534.4603 - val_loss: 1055290033713.3997\n",
      "Epoch 61/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 981251376588.4255 - val_loss: 1052583535617.4402\n",
      "Epoch 62/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 998228387290.2555 - val_loss: 1044469066272.4050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 979614520280.2386 - val_loss: 1037653737315.3035\n",
      "Epoch 64/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 966937700535.2482 - val_loss: 1032734486065.9758\n",
      "Epoch 65/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 961184264968.7878 - val_loss: 1039101000640.3420\n",
      "Epoch 66/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 972600361042.9803 - val_loss: 1023745044423.5432\n",
      "Epoch 67/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 960215691349.2853 - val_loss: 1016804632848.4906\n",
      "Epoch 68/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 951069815717.5284 - val_loss: 1019613675077.5629\n",
      "Epoch 69/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 964750748601.1210 - val_loss: 1008898835584.1801\n",
      "Epoch 70/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 947375945203.6105 - val_loss: 1018612628107.5579\n",
      "Epoch 71/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 948037549157.9966 - val_loss: 1024229544937.2444\n",
      "Epoch 72/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 944057583504.2072 - val_loss: 1014674034629.2388\n",
      "Epoch 73/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 937282071748.5020 - val_loss: 1010197701919.1809\n",
      "Epoch 74/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 924821920302.9646 - val_loss: 988620103184.5626\n",
      "Epoch 75/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 921066244500.5289 - val_loss: 987652279685.1488\n",
      "Epoch 76/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 922478246360.5267 - val_loss: 991025036150.6025\n",
      "Epoch 77/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 927728778738.4581 - val_loss: 991531025448.6144\n",
      "Epoch 78/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 918878244557.4340 - val_loss: 1041596478752.3330\n",
      "Epoch 79/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 911661954851.8716 - val_loss: 979476287521.4132\n",
      "Epoch 80/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 916292397797.0602 - val_loss: 989713856421.5538\n",
      "Epoch 81/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 908314020742.4109 - val_loss: 962034984301.5292\n",
      "Epoch 82/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 903215239239.4553 - val_loss: 963533450064.5806\n",
      "Epoch 83/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 901130571290.3635 - val_loss: 955467900108.2239\n",
      "Epoch 84/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 900816769427.3766 - val_loss: 958714148183.6377\n",
      "Epoch 85/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 894723475039.9460 - val_loss: 974959262172.4264\n",
      "Epoch 86/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 897080210636.5695 - val_loss: 945311842138.0861\n",
      "Epoch 87/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 879855845053.2988 - val_loss: 949178331323.8053\n",
      "Epoch 88/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 882207178650.5796 - val_loss: 938608764642.8354\n",
      "Epoch 89/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 886697498270.1813 - val_loss: 933612052403.9562\n",
      "Epoch 90/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 881471271347.6466 - val_loss: 953237506470.2739\n",
      "Epoch 91/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 876860309706.8407 - val_loss: 930970065015.2506\n",
      "Epoch 92/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 871990196460.2633 - val_loss: 924759112552.7764\n",
      "Epoch 93/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 867886326649.7333 - val_loss: 937015503738.0591\n",
      "Epoch 94/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 869821452931.0973 - val_loss: 921232367558.3910\n",
      "Epoch 95/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 864231469399.4463 - val_loss: 917936540641.7552\n",
      "Epoch 96/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 871379850790.3207 - val_loss: 914859315772.6334\n",
      "Epoch 97/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 859030139002.1655 - val_loss: 915992515321.5909\n",
      "Epoch 98/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 855663513228.8937 - val_loss: 907711949196.9260\n",
      "Epoch 99/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 849709771649.8008 - val_loss: 949731607528.0923\n",
      "Epoch 100/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 865889669993.5981 - val_loss: 913666371688.8484\n",
      "Epoch 101/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 849743617361.1074 - val_loss: 902665498249.5415\n",
      "Epoch 102/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 849743319950.4784 - val_loss: 912921475631.3834\n",
      "Epoch 103/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 847415108261.6725 - val_loss: 922829414213.3468\n",
      "Epoch 104/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 853910132548.1418 - val_loss: 905799806781.2816\n",
      "Epoch 105/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 842026017639.2932 - val_loss: 915945504440.7809\n",
      "Epoch 106/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 838275930551.1040 - val_loss: 891418086157.7542\n",
      "Epoch 107/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 843241469132.5695 - val_loss: 886596143443.3170\n",
      "Epoch 108/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 832896572365.8660 - val_loss: 898117506375.5072\n",
      "Epoch 109/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 837607780667.7861 - val_loss: 881372732575.8650\n",
      "Epoch 110/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 840811242675.2145 - val_loss: 889959627219.2090\n",
      "Epoch 111/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 832412880949.0151 - val_loss: 879803186725.3019\n",
      "Epoch 112/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 824029371941.1683 - val_loss: 923018518958.9153\n",
      "Epoch 113/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 837276916068.1238 - val_loss: 873245457699.2135\n",
      "Epoch 114/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 831223712489.6703 - val_loss: 875958592112.4816\n",
      "Epoch 115/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 821600353621.7175 - val_loss: 871095057136.9497\n",
      "Epoch 116/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 829927765380.9702 - val_loss: 894665318065.8678\n",
      "Epoch 117/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 831196627239.0410 - val_loss: 874351249005.3131\n",
      "Epoch 118/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 819225922309.3303 - val_loss: 875516456742.2379\n",
      "Epoch 119/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 828869330878.3073 - val_loss: 865733181790.2627\n",
      "Epoch 120/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 814082201043.3405 - val_loss: 872162690093.2230\n",
      "Epoch 121/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 815759086939.4800 - val_loss: 863185410540.5570\n",
      "Epoch 122/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 816794075246.6405 - val_loss: 861338587551.9370\n",
      "Epoch 123/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 809620516949.2853 - val_loss: 863798359485.0295\n",
      "Epoch 124/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 815595886736.0630 - val_loss: 860983571048.4163\n",
      "Epoch 125/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 809850751371.3090 - val_loss: 860190903127.4937\n",
      "Epoch 126/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 819812339469.9741 - val_loss: 872665080312.6549\n",
      "Epoch 127/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 809116794686.3794 - val_loss: 853475657698.6194\n",
      "Epoch 128/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 803190908405.9156 - val_loss: 869887280901.4009\n",
      "Epoch 129/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 813006098411.2549 - val_loss: 853026598131.9741\n",
      "Epoch 130/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 810066180336.8733 - val_loss: 856921115414.9716\n",
      "Epoch 131/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 802013084073.2740 - val_loss: 849491565147.1663\n",
      "Epoch 132/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 798646421991.5093 - val_loss: 922279793231.0684\n",
      "Epoch 133/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 813988503224.6888 - val_loss: 903947803941.5178\n",
      "Epoch 134/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 798250966113.3867 - val_loss: 862178286226.4708\n",
      "Epoch 135/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 804819584110.0641 - val_loss: 844144098060.6019\n",
      "Epoch 136/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 797867738733.1998 - val_loss: 852339595203.5105\n",
      "Epoch 137/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 800236482424.0045 - val_loss: 907840458001.9308\n",
      "Epoch 138/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 821365470237.3889 - val_loss: 860328882529.7192\n",
      "Epoch 139/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 833511091387.2819 - val_loss: 841827827873.3052\n",
      "Epoch 140/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 794232340858.0214 - val_loss: 853111685539.3936\n",
      "Epoch 141/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 797305185191.8334 - val_loss: 868859292146.3179\n",
      "Epoch 142/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 791511455982.5684 - val_loss: 841580750996.0552\n",
      "Epoch 143/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 806814224501.5554 - val_loss: 901470349667.4475\n",
      "Epoch 144/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 799228108094.6675 - val_loss: 838109484318.0287\n",
      "Epoch 145/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 797435529426.9083 - val_loss: 845247518733.2501\n",
      "Epoch 146/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 790147301080.9590 - val_loss: 847807846993.9489\n",
      "Epoch 147/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 797629684593.6658 - val_loss: 838391831840.9092\n",
      "Epoch 148/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 788868361541.5824 - val_loss: 851903947556.2217\n",
      "Epoch 149/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 785494409455.7209 - val_loss: 840541037841.3547\n",
      "Epoch 150/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 789728725290.4985 - val_loss: 836793145440.2070\n",
      "Epoch 151/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 782172461956.1057 - val_loss: 834020815971.3755\n",
      "Epoch 152/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 783737625402.3455 - val_loss: 831253469856.2970\n",
      "Epoch 153/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 789317751740.5785 - val_loss: 871928121586.5339\n",
      "Epoch 154/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 783223955432.9500 - val_loss: 827151868998.5710\n",
      "Epoch 155/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 783450928563.0703 - val_loss: 829456537037.1600\n",
      "Epoch 156/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 791785548065.2786 - val_loss: 831164425042.3088\n",
      "Epoch 157/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 785124057369.2111 - val_loss: 826424945732.8428\n",
      "Epoch 158/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 784419126632.1576 - val_loss: 831102921792.2340\n",
      "Epoch 159/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 785940354791.9415 - val_loss: 823851864774.8950\n",
      "Epoch 160/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 783301482658.5031 - val_loss: 823982108237.6282\n",
      "Epoch 161/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 783146619209.6161 - val_loss: 854196535208.4343\n",
      "Epoch 162/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 787964335313.1796 - val_loss: 833618008266.2076\n",
      "Epoch 163/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 779770542671.2346 - val_loss: 831858336930.7455\n",
      "Epoch 164/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 775566771494.4648 - val_loss: 826438118514.9299\n",
      "Epoch 165/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 780514894261.9517 - val_loss: 832793410302.7758\n",
      "Epoch 166/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 794821638652.2544 - val_loss: 822133160813.3851\n",
      "Epoch 167/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 784899417294.8744 - val_loss: 824167540450.8354\n",
      "Epoch 168/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 778830271909.2404 - val_loss: 826956385544.7134\n",
      "Epoch 169/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 778015708000.3782 - val_loss: 817976874624.9001\n",
      "Epoch 170/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 772237808595.6287 - val_loss: 822431590160.9226\n",
      "Epoch 171/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 780897081663.2437 - val_loss: 816987010216.5063\n",
      "Epoch 172/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 771459283793.3956 - val_loss: 880035703300.7527\n",
      "Epoch 173/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 786651759431.0231 - val_loss: 893488195017.7035\n",
      "Epoch 174/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 775882119607.1040 - val_loss: 817079760791.7277\n",
      "Epoch 175/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 769582551895.1582 - val_loss: 815866248238.9513\n",
      "Epoch 176/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 766470273440.0540 - val_loss: 821130410257.6427\n",
      "Epoch 177/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 775687407688.6077 - val_loss: 822235143816.3893\n",
      "Epoch 178/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 775266425344.8643 - val_loss: 820157672751.8875\n",
      "Epoch 179/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 765528080771.2415 - val_loss: 816987929379.6456\n",
      "Epoch 180/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 768477903927.8965 - val_loss: 824138076654.2853\n",
      "Epoch 181/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 774257464095.8379 - val_loss: 815186599274.6487\n",
      "Epoch 182/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 772159277322.2285 - val_loss: 844816953794.5024\n",
      "Epoch 183/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 775735151531.2909 - val_loss: 821577725893.8149\n",
      "Epoch 184/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 771351577202.9623 - val_loss: 808166515911.6152\n",
      "Epoch 185/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 778193272868.8802 - val_loss: 809288246992.4005\n",
      "Epoch 186/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 760271390082.6652 - val_loss: 810893410594.3494\n",
      "Epoch 187/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 772185232076.8575 - val_loss: 803880676213.4503\n",
      "Epoch 188/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 765784492159.9280 - val_loss: 864138052408.9609\n",
      "Epoch 189/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 82us/step - loss: 765865976789.9336 - val_loss: 804599979614.9109\n",
      "Epoch 190/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 763362057921.9089 - val_loss: 802413510319.5635\n",
      "Epoch 191/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 765532809943.2302 - val_loss: 804476289346.6104\n",
      "Epoch 192/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 770989713439.1176 - val_loss: 802169424662.9716\n",
      "Epoch 193/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 763758419797.4294 - val_loss: 814309890618.9052\n",
      "Epoch 194/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 763926739553.6748 - val_loss: 807007061290.7026\n",
      "Epoch 195/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 762047182047.0095 - val_loss: 835538339326.7039\n",
      "Epoch 196/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 776258145149.1908 - val_loss: 823385375379.0470\n",
      "Epoch 197/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 763377074480.2611 - val_loss: 806833314044.9036\n",
      "Epoch 198/10000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 768798871042.5931 - val_loss: 799918120865.5212\n",
      "Epoch 199/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 756058186230.4918 - val_loss: 799940641348.6987\n",
      "Epoch 200/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 749504010310.3027 - val_loss: 828958801141.1263\n",
      "Epoch 201/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 763325977700.8441 - val_loss: 803832439062.8275\n",
      "Epoch 202/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 763479363452.6145 - val_loss: 823095101470.5327\n",
      "Epoch 203/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 752413543099.5701 - val_loss: 822471891657.7755\n",
      "Epoch 204/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 755724894456.9409 - val_loss: 792548440982.8635\n",
      "Epoch 205/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 754594850625.8368 - val_loss: 804904305137.7418\n",
      "Epoch 206/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 755456348526.4963 - val_loss: 793801539528.6953\n",
      "Epoch 207/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 751645801638.5369 - val_loss: 801197811961.4470\n",
      "Epoch 208/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 750963509385.1481 - val_loss: 800244053266.5068\n",
      "Epoch 209/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 757163704384.5402 - val_loss: 789721310154.1356\n",
      "Epoch 210/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 758116377633.9989 - val_loss: 852473592570.1671\n",
      "Epoch 211/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 748430046698.3906 - val_loss: 791232434338.4574\n",
      "Epoch 212/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 753492597986.4670 - val_loss: 824444356080.8777\n",
      "Epoch 213/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 755441751147.7592 - val_loss: 787434785162.6217\n",
      "Epoch 214/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 748503145993.5082 - val_loss: 836564640695.7007\n",
      "Epoch 215/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 759361385197.1278 - val_loss: 879822409692.2825\n",
      "Epoch 216/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 753672469744.2971 - val_loss: 787851104930.0253\n",
      "Epoch 217/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 741983301312.7563 - val_loss: 788578571854.2042\n",
      "Epoch 218/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 742211747747.7997 - val_loss: 787274007482.0050\n",
      "Epoch 219/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 739311532614.0146 - val_loss: 793966113826.8534\n",
      "Epoch 220/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 741600044091.3539 - val_loss: 800382762132.3431\n",
      "Epoch 221/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 758486760116.6550 - val_loss: 783951296582.8591\n",
      "Epoch 222/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 744684695416.0045 - val_loss: 781117058379.5398\n",
      "Epoch 223/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 751612856542.4333 - val_loss: 785341779545.1499\n",
      "Epoch 224/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 736651876532.9432 - val_loss: 796217204641.5212\n",
      "Epoch 225/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 747996514653.2089 - val_loss: 795865057536.3601\n",
      "Epoch 226/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 754854045690.2374 - val_loss: 795358624344.8619\n",
      "Epoch 227/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 757502198193.3416 - val_loss: 805526727393.9713\n",
      "Epoch 228/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 736485241424.3872 - val_loss: 786360327097.4290\n",
      "Epoch 229/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 739238742697.1300 - val_loss: 786863898812.9575\n",
      "Epoch 230/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 735045492178.1880 - val_loss: 794642462989.0341\n",
      "Epoch 231/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 740781590508.4075 - val_loss: 775570548920.9249\n",
      "Epoch 232/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 738698967363.8536 - val_loss: 775744551416.0787\n",
      "Epoch 233/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 732939937518.8564 - val_loss: 779222977058.7095\n",
      "Epoch 234/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 735433214697.6703 - val_loss: 775014292510.8208\n",
      "Epoch 235/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 742213919489.8728 - val_loss: 777768964475.0673\n",
      "Epoch 236/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 733304223450.1113 - val_loss: 833623376093.2185\n",
      "Epoch 237/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 740645442879.8198 - val_loss: 771608582608.9047\n",
      "Epoch 238/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 744297472364.1914 - val_loss: 774522936820.9103\n",
      "Epoch 239/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 732362682471.7253 - val_loss: 772165140088.2588\n",
      "Epoch 240/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 732259076343.7883 - val_loss: 770012971588.6987\n",
      "Epoch 241/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 731280384539.3719 - val_loss: 769587897382.3099\n",
      "Epoch 242/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 727692296551.5813 - val_loss: 768492569944.7899\n",
      "Epoch 243/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 737694291521.9808 - val_loss: 830132496112.6616\n",
      "Epoch 244/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 739768620914.2419 - val_loss: 816157452740.2307\n",
      "Epoch 245/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 737945640190.1272 - val_loss: 768674093110.7285\n",
      "Epoch 246/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 726323470903.0321 - val_loss: 767229816323.8885\n",
      "Epoch 247/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 727182862671.3788 - val_loss: 766779914647.2957\n",
      "Epoch 248/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 728762169243.7322 - val_loss: 837313280665.3839\n",
      "Epoch 249/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 733566422069.5914 - val_loss: 790570982172.7325\n",
      "Epoch 250/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 733415659175.4012 - val_loss: 763782010224.9856\n",
      "Epoch 251/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 725016392927.0095 - val_loss: 810975631188.9012\n",
      "Epoch 252/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 80us/step - loss: 741575211239.6534 - val_loss: 770173265049.5280\n",
      "Epoch 253/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 727732972943.3427 - val_loss: 783759847344.4996\n",
      "Epoch 254/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 730266650595.1874 - val_loss: 766062000083.6411\n",
      "Epoch 255/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 720952757366.1317 - val_loss: 764244036563.9291\n",
      "Epoch 256/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 718117157280.0540 - val_loss: 763567026778.5902\n",
      "Epoch 257/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 719562269930.5345 - val_loss: 764326566080.9901\n",
      "Epoch 258/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 729424526769.9178 - val_loss: 760070146138.4462\n",
      "Epoch 259/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 723662977126.5729 - val_loss: 768877020219.0492\n",
      "Epoch 260/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 726476812751.3066 - val_loss: 760605189001.6135\n",
      "Epoch 261/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 720101520050.3500 - val_loss: 802866758857.9196\n",
      "Epoch 262/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 722489060133.6003 - val_loss: 758668416601.7261\n",
      "Epoch 263/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 726079396620.2454 - val_loss: 761553820172.8180\n",
      "Epoch 264/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 718781104598.2217 - val_loss: 768007543216.6436\n",
      "Epoch 265/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 727827874935.2842 - val_loss: 771679947538.3629\n",
      "Epoch 266/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 732338465960.8418 - val_loss: 785556822632.9924\n",
      "Epoch 267/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 721571267823.1447 - val_loss: 758651909620.3342\n",
      "Epoch 268/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 715183141225.8864 - val_loss: 757862163312.2655\n",
      "Epoch 269/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 713126270686.7214 - val_loss: 805764494472.2452\n",
      "Epoch 270/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 733940241183.8379 - val_loss: 771017980099.2946\n",
      "Epoch 271/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 712686973299.1063 - val_loss: 753642538061.4841\n",
      "Epoch 272/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 711580955852.5695 - val_loss: 753243031287.5747\n",
      "Epoch 273/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 719544013892.5740 - val_loss: 765708471445.4954\n",
      "Epoch 274/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 716233003475.9167 - val_loss: 753189727270.8861\n",
      "Epoch 275/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 720443371282.5841 - val_loss: 756247362238.2538\n",
      "Epoch 276/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 717838321884.1284 - val_loss: 794464296948.4781\n",
      "Epoch 277/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 714925997268.6371 - val_loss: 780597696571.3373\n",
      "Epoch 278/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 717447419477.5734 - val_loss: 759604007611.3733\n",
      "Epoch 279/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 720222484536.4728 - val_loss: 768648966723.5465\n",
      "Epoch 280/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 723522652306.3679 - val_loss: 758698492058.3921\n",
      "Epoch 281/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 716812215438.3342 - val_loss: 749601005213.1285\n",
      "Epoch 282/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 710922114957.9021 - val_loss: 760826809498.1041\n",
      "Epoch 283/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 713627678472.2117 - val_loss: 747556962103.5206\n",
      "Epoch 284/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 710150224601.5352 - val_loss: 771729127499.4678\n",
      "Epoch 285/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 711128553284.1418 - val_loss: 765528668240.0765\n",
      "Epoch 286/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 710359594243.8898 - val_loss: 747765014405.8689\n",
      "Epoch 287/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 713167613945.0850 - val_loss: 789180608865.7192\n",
      "Epoch 288/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 719449022413.2898 - val_loss: 774860468075.3688\n",
      "Epoch 289/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 709389651744.4142 - val_loss: 763655387842.8624\n",
      "Epoch 290/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 706559153859.0613 - val_loss: 773364253794.2234\n",
      "Epoch 291/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 718426199461.2404 - val_loss: 743402113741.2321\n",
      "Epoch 292/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 712958745328.5852 - val_loss: 745273947410.5068\n",
      "Epoch 293/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 714504582445.3799 - val_loss: 767206351336.5243\n",
      "Epoch 294/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 708189601395.5386 - val_loss: 752503971929.8700\n",
      "Epoch 295/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 715196913872.6031 - val_loss: 757505731424.7111\n",
      "Epoch 296/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 708326108291.9618 - val_loss: 744671299520.0540\n",
      "Epoch 297/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 709226781249.4047 - val_loss: 762965886485.7474\n",
      "Epoch 298/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 709231028476.3984 - val_loss: 761989861632.9362\n",
      "Epoch 299/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 708235871922.9263 - val_loss: 743118343363.5825\n",
      "Epoch 300/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 708410149471.3696 - val_loss: 762849320630.4766\n",
      "Epoch 301/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 704501993312.9545 - val_loss: 774392001881.9420\n",
      "Epoch 302/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 714271287483.8582 - val_loss: 759225318693.5178\n",
      "Epoch 303/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 704003643038.1813 - val_loss: 740465187004.3815\n",
      "Epoch 304/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 709844340438.6539 - val_loss: 770613107996.3004\n",
      "Epoch 305/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 709364910558.2892 - val_loss: 748993684463.0054\n",
      "Epoch 306/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 709493083078.9510 - val_loss: 756614326733.4481\n",
      "Epoch 307/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 698252299492.7721 - val_loss: 745813038393.6810\n",
      "Epoch 308/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 704983169320.1936 - val_loss: 754162999948.1339\n",
      "Epoch 309/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 703258621608.5537 - val_loss: 735342630925.2501\n",
      "Epoch 310/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 705693166502.6809 - val_loss: 741420336380.6155\n",
      "Epoch 311/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 706866221053.6951 - val_loss: 737685462438.5620\n",
      "Epoch 312/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 704937097106.5121 - val_loss: 748232471222.7645\n",
      "Epoch 313/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 705447195492.9882 - val_loss: 758728095045.2028\n",
      "Epoch 314/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 709046132021.4474 - val_loss: 735579546203.7423\n",
      "Epoch 315/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 95us/step - loss: 705964350782.6675 - val_loss: 770135929102.7623\n",
      "Epoch 316/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 698550477231.0365 - val_loss: 800078520061.9116\n",
      "Epoch 317/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 703254031952.9635 - val_loss: 752235019691.1708\n",
      "Epoch 318/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 712923529973.7715 - val_loss: 754557852843.3867\n",
      "Epoch 319/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 696485742332.6866 - val_loss: 743602916006.0580\n",
      "Epoch 320/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 697588277344.8103 - val_loss: 741304174286.0962\n",
      "Epoch 321/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 694191977261.6680 - val_loss: 751737332228.1766\n",
      "Epoch 322/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 702776191670.9601 - val_loss: 736817834138.9683\n",
      "Epoch 323/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 697291492755.9528 - val_loss: 745022390172.9125\n",
      "Epoch 324/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 693596879080.8058 - val_loss: 747609728354.0073\n",
      "Epoch 325/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 695653855971.9077 - val_loss: 745874827891.3621\n",
      "Epoch 326/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 700683391575.3021 - val_loss: 744401377924.6448\n",
      "Epoch 327/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 692535749916.0923 - val_loss: 731276057160.7313\n",
      "Epoch 328/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 695831541254.0507 - val_loss: 735959350706.0839\n",
      "Epoch 329/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 703727669688.2566 - val_loss: 729371074477.0431\n",
      "Epoch 330/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 692387476361.8683 - val_loss: 734276862664.0472\n",
      "Epoch 331/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 703316471699.6647 - val_loss: 745577725772.2599\n",
      "Epoch 332/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 692436876528.2971 - val_loss: 733861933197.7181\n",
      "Epoch 333/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 697898566258.9623 - val_loss: 736742794046.7218\n",
      "Epoch 334/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 717397390559.0095 - val_loss: 740182762250.8737\n",
      "Epoch 335/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 692651858100.9432 - val_loss: 731255355345.3367\n",
      "Epoch 336/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 692975456576.3962 - val_loss: 736878441670.4630\n",
      "Epoch 337/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 699899818972.8485 - val_loss: 726099201962.7386\n",
      "Epoch 338/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 689021854078.6315 - val_loss: 864523209566.4067\n",
      "Epoch 339/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 696963010170.4536 - val_loss: 728684239698.8850\n",
      "Epoch 340/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 695958126847.8558 - val_loss: 732326771000.8169\n",
      "Epoch 341/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 693841313856.5402 - val_loss: 731127184452.8428\n",
      "Epoch 342/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 688686760157.2808 - val_loss: 734351591505.2286\n",
      "Epoch 343/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 693933055995.3900 - val_loss: 725742091184.2115\n",
      "Epoch 344/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 690972201183.5858 - val_loss: 734306482924.3409\n",
      "Epoch 345/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 689929541416.4817 - val_loss: 764061365130.7656\n",
      "Epoch 346/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 703548571837.0107 - val_loss: 729257471597.8892\n",
      "Epoch 347/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 688053531262.4873 - val_loss: 759216133699.8346\n",
      "Epoch 348/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 696653298734.6765 - val_loss: 731750695508.8292\n",
      "Epoch 349/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 682020043131.1740 - val_loss: 724269359675.4813\n",
      "Epoch 350/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 685234596811.5610 - val_loss: 722553695425.2782\n",
      "Epoch 351/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 692697558631.8694 - val_loss: 733184244116.9913\n",
      "Epoch 352/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 687673545623.6984 - val_loss: 741322211745.0891\n",
      "Epoch 353/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 682476422203.3539 - val_loss: 727583901532.9666\n",
      "Epoch 354/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 688688678219.3450 - val_loss: 735805831335.6422\n",
      "Epoch 355/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 686849831624.2476 - val_loss: 728436266667.5308\n",
      "Epoch 356/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 682867360841.1841 - val_loss: 752087183008.5851\n",
      "Epoch 357/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 684070556521.5981 - val_loss: 726483341269.3694\n",
      "Epoch 358/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 686290098025.0220 - val_loss: 731694324520.2543\n",
      "Epoch 359/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 681093560397.2178 - val_loss: 766577725291.3688\n",
      "Epoch 360/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 680707294944.7383 - val_loss: 724554271570.8850\n",
      "Epoch 361/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 683879339770.3816 - val_loss: 728646745346.9525\n",
      "Epoch 362/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 691126696554.8948 - val_loss: 731825448039.9843\n",
      "Epoch 363/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 679430120903.8154 - val_loss: 720758148769.7373\n",
      "Epoch 364/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 687507452911.2887 - val_loss: 725726875463.6512\n",
      "Epoch 365/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 680342841112.3466 - val_loss: 734364888416.2791\n",
      "Epoch 366/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 683910002762.9128 - val_loss: 747649261890.6104\n",
      "Epoch 367/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 689305359624.4998 - val_loss: 732064125055.8920\n",
      "Epoch 368/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 683726423481.9854 - val_loss: 726628616496.7516\n",
      "Epoch 369/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 691068002456.1306 - val_loss: 729460225697.1611\n",
      "Epoch 370/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 691571847197.9651 - val_loss: 718519074615.5206\n",
      "Epoch 371/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 681026582473.8323 - val_loss: 719501187619.8616\n",
      "Epoch 372/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 685927119116.5334 - val_loss: 727828602790.1300\n",
      "Epoch 373/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 681540333335.1942 - val_loss: 719925666637.7002\n",
      "Epoch 374/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 683086141687.7883 - val_loss: 723832277749.5583\n",
      "Epoch 375/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 678921948379.5520 - val_loss: 718467791246.0782\n",
      "Epoch 376/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 689648345359.9910 - val_loss: 722411212614.4990\n",
      "Epoch 377/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 679216344094.5414 - val_loss: 751400306626.3584\n",
      "Epoch 378/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 99us/step - loss: 680449082063.1627 - val_loss: 717204592442.4011\n",
      "Epoch 379/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 678010330781.0287 - val_loss: 726959268515.1775\n",
      "Epoch 380/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 687278564116.3129 - val_loss: 725593997770.5676\n",
      "Epoch 381/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 681796261008.6393 - val_loss: 764672786835.2631\n",
      "Epoch 382/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 680937717870.6405 - val_loss: 716915756998.3910\n",
      "Epoch 383/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 684875080583.5632 - val_loss: 714706749525.8374\n",
      "Epoch 384/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 675648491805.8210 - val_loss: 716248701397.5133\n",
      "Epoch 385/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 682363348847.9370 - val_loss: 717781207477.2523\n",
      "Epoch 386/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 685787789396.1329 - val_loss: 717587979194.5812\n",
      "Epoch 387/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 686709008405.8976 - val_loss: 730586104438.2424\n",
      "Epoch 388/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 683306882994.7822 - val_loss: 724420666906.3561\n",
      "Epoch 389/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 682780423501.6500 - val_loss: 718782423166.7397\n",
      "Epoch 390/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 677059050810.0574 - val_loss: 716560815066.2661\n",
      "Epoch 391/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 680411172234.7327 - val_loss: 741472223736.6549\n",
      "Epoch 392/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 674747259521.9448 - val_loss: 721561045992.6683\n",
      "Epoch 393/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 677448487923.8988 - val_loss: 718021340878.6722\n",
      "Epoch 394/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 676584787357.1729 - val_loss: 719676518060.1069\n",
      "Epoch 395/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 674739560876.7316 - val_loss: 719029158484.8292\n",
      "Epoch 396/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 674067483669.3213 - val_loss: 719893232723.8210\n",
      "Epoch 397/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 669513757347.3674 - val_loss: 717512594587.8324\n",
      "Epoch 398/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 674236067141.5824 - val_loss: 735940288682.5227\n",
      "Epoch 399/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 688171824295.6895 - val_loss: 714482273076.9282\n",
      "Epoch 400/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 670547294568.7339 - val_loss: 715993711559.8312\n",
      "Epoch 401/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 678659820036.3219 - val_loss: 722192659394.0703\n",
      "Epoch 402/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 682273403195.7861 - val_loss: 717572814731.0537\n",
      "Epoch 403/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 668186395979.3450 - val_loss: 715196271682.5385\n",
      "Epoch 404/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 670718330694.4469 - val_loss: 717157930613.3783\n",
      "Epoch 405/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 672448672898.8092 - val_loss: 729821648049.7238\n",
      "Epoch 406/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 678813136970.9128 - val_loss: 714914164446.8029\n",
      "Epoch 407/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 673198651568.3331 - val_loss: 711879954549.5223\n",
      "Epoch 408/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 676829913535.1716 - val_loss: 710728131533.5922\n",
      "Epoch 409/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 673167123312.5132 - val_loss: 738979990689.0172\n",
      "Epoch 410/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 681636408521.1119 - val_loss: 745690325146.3921\n",
      "Epoch 411/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 668554158992.7833 - val_loss: 713530140589.6191\n",
      "Epoch 412/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 670312746275.0073 - val_loss: 708963661977.8160\n",
      "Epoch 413/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 669892478108.1644 - val_loss: 709025094336.5581\n",
      "Epoch 414/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 677854464966.9510 - val_loss: 720911536898.8085\n",
      "Epoch 415/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 679797037107.8627 - val_loss: 712290913152.9722\n",
      "Epoch 416/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 671775340858.6337 - val_loss: 711446015354.7792\n",
      "Epoch 417/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 665222135268.6281 - val_loss: 710067200936.7224\n",
      "Epoch 418/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 670513805875.5745 - val_loss: 711591338556.6334\n",
      "Epoch 419/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 669963528352.1981 - val_loss: 732348402867.4520\n",
      "Epoch 420/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 677828689809.3595 - val_loss: 720413961289.4514\n",
      "Epoch 421/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 679810463606.8519 - val_loss: 802632945379.4115\n",
      "Epoch 422/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 679051682589.5330 - val_loss: 713947780831.9550\n",
      "Epoch 423/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 670764449450.8586 - val_loss: 706508385136.8417\n",
      "Epoch 424/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 678285840473.8954 - val_loss: 719492575151.3474\n",
      "Epoch 425/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 666528238885.3123 - val_loss: 725059806905.9331\n",
      "Epoch 426/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 676453466010.5796 - val_loss: 720417811521.3862\n",
      "Epoch 427/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 671176095689.8323 - val_loss: 708187178559.2258\n",
      "Epoch 428/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 664774102567.4733 - val_loss: 721833692065.2332\n",
      "Epoch 429/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 668563892706.8993 - val_loss: 730567593430.9536\n",
      "Epoch 430/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 670045235074.3771 - val_loss: 706604037276.9845\n",
      "Epoch 431/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 664975214000.7654 - val_loss: 715693219728.2385\n",
      "Epoch 432/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 669987942660.4659 - val_loss: 705682307232.7291\n",
      "Epoch 433/10000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 665235316119.39 - 0s 101us/step - loss: 667720815696.0990 - val_loss: 708610717539.8796\n",
      "Epoch 434/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 680854563935.0815 - val_loss: 752511007046.6431\n",
      "Epoch 435/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 671581553018.0214 - val_loss: 708774794099.7220\n",
      "Epoch 436/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 666497810266.0394 - val_loss: 729115896511.4059\n",
      "Epoch 437/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 669787368077.4700 - val_loss: 709024965570.0703\n",
      "Epoch 438/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 665383393599.2437 - val_loss: 719891101807.1854\n",
      "Epoch 439/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 670881292025.2290 - val_loss: 706281638071.7727\n",
      "Epoch 440/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 669613355600.3872 - val_loss: 710114532161.6023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 672413731008.4683 - val_loss: 753099245255.1831\n",
      "Epoch 442/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 664359703281.7378 - val_loss: 710926818090.5586\n",
      "Epoch 443/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 659359447211.7231 - val_loss: 707490822495.9910\n",
      "Epoch 444/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 659706334040.3105 - val_loss: 777597059191.8268\n",
      "Epoch 445/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 670865858011.4081 - val_loss: 732489794552.2228\n",
      "Epoch 446/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 662797290964.4929 - val_loss: 747726876511.8469\n",
      "Epoch 447/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 667994375997.2268 - val_loss: 717042784251.9674\n",
      "Epoch 448/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 667966269222.1768 - val_loss: 718939250363.0852\n",
      "Epoch 449/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 660568884370.9443 - val_loss: 714432167734.3685\n",
      "Epoch 450/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 668848733203.0164 - val_loss: 742056601592.5109\n",
      "Epoch 451/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 661462223953.2516 - val_loss: 713868125460.8113\n",
      "Epoch 452/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 663636931336.7878 - val_loss: 713633204725.7744\n",
      "Epoch 453/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 663760410934.0237 - val_loss: 703783822686.5508\n",
      "Epoch 454/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 661059556966.8610 - val_loss: 705209056966.6071\n",
      "Epoch 455/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 661214234549.0872 - val_loss: 707343923411.4250\n",
      "Epoch 456/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 660786026151.4012 - val_loss: 716905394840.8079\n",
      "Epoch 457/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 662189740375.4463 - val_loss: 731246615935.3879\n",
      "Epoch 458/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 674052966214.4469 - val_loss: 784223555297.1072\n",
      "Epoch 459/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 664936843081.9044 - val_loss: 708796494744.5918\n",
      "Epoch 460/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 661011350361.4631 - val_loss: 707583749442.3224\n",
      "Epoch 461/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 658221011734.6178 - val_loss: 705694659573.9185\n",
      "Epoch 462/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 662830040192.5043 - val_loss: 708443228382.9468\n",
      "Epoch 463/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 661081564394.5345 - val_loss: 707947366461.6416\n",
      "Epoch 464/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 663752194076.8126 - val_loss: 702361911208.4343\n",
      "Epoch 465/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 666446068275.5745 - val_loss: 858093046546.3629\n",
      "Epoch 466/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 662024440479.9100 - val_loss: 741716009545.3075\n",
      "Epoch 467/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 657589068684.1733 - val_loss: 706308001840.3916\n",
      "Epoch 468/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 660966667367.1492 - val_loss: 706882719173.6709\n",
      "Epoch 469/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 656970630604.4255 - val_loss: 707477724784.1935\n",
      "Epoch 470/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 657591521876.9972 - val_loss: 705004545918.3798\n",
      "Epoch 471/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 667972463535.9010 - val_loss: 708862669478.6340\n",
      "Epoch 472/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 656340371500.9478 - val_loss: 713458476858.4011\n",
      "Epoch 473/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 658903951907.4396 - val_loss: 707331870147.9426\n",
      "Epoch 474/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 658390856774.8790 - val_loss: 704716302086.5530\n",
      "Epoch 475/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 657787078281.4362 - val_loss: 703701497593.8790\n",
      "Epoch 476/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 660402705239.1582 - val_loss: 710752585358.7263\n",
      "Epoch 477/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 656323186879.3157 - val_loss: 699625806550.4495\n",
      "Epoch 478/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 666469819608.0945 - val_loss: 700453260003.1235\n",
      "Epoch 479/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 667789534700.6956 - val_loss: 734484434272.2791\n",
      "Epoch 480/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 661780470466.4851 - val_loss: 701327005231.0953\n",
      "Epoch 481/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 654874130184.2117 - val_loss: 703732544393.6135\n",
      "Epoch 482/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 653398548018.9983 - val_loss: 697904465071.4194\n",
      "Epoch 483/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 656558785341.8030 - val_loss: 698495087829.4414\n",
      "Epoch 484/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 651955267827.1785 - val_loss: 722522579584.6121\n",
      "Epoch 485/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 658769645897.6161 - val_loss: 698589707789.1061\n",
      "Epoch 486/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 662245068013.9921 - val_loss: 697423044154.0410\n",
      "Epoch 487/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 656392312561.1615 - val_loss: 696335974287.0863\n",
      "Epoch 488/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 656314136743.1130 - val_loss: 711063595275.8818\n",
      "Epoch 489/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 652050500228.2499 - val_loss: 695858745724.2194\n",
      "Epoch 490/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 654728229760.6483 - val_loss: 697244437993.3884\n",
      "Epoch 491/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 656496526715.7501 - val_loss: 704267343473.9218\n",
      "Epoch 492/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 652129890361.6252 - val_loss: 719979558442.4867\n",
      "Epoch 493/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 648868473582.2803 - val_loss: 698349520364.2689\n",
      "Epoch 494/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 657752936104.5537 - val_loss: 691746545435.8684\n",
      "Epoch 495/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 661490151905.7468 - val_loss: 693945309107.3800\n",
      "Epoch 496/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 648992513333.4474 - val_loss: 713350369871.0684\n",
      "Epoch 497/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 649261865500.5244 - val_loss: 687905805442.4844\n",
      "Epoch 498/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 641863877364.0427 - val_loss: 689915059793.0847\n",
      "Epoch 499/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 642038550544.1351 - val_loss: 699173679237.6528\n",
      "Epoch 500/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 640563103788.9478 - val_loss: 721721037425.6338\n",
      "Epoch 501/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 643337696884.6910 - val_loss: 702027341325.1061\n",
      "Epoch 502/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 637535738341.2043 - val_loss: 712532269753.6450\n",
      "Epoch 503/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 654231580549.8345 - val_loss: 701332681242.0681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 504/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 642568522455.2302 - val_loss: 695976854947.6815\n",
      "Epoch 505/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 632546705896.6617 - val_loss: 708772268129.3593\n",
      "Epoch 506/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 634875000971.4530 - val_loss: 683702106333.7947\n",
      "Epoch 507/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 638785554633.6882 - val_loss: 677531092658.4438\n",
      "Epoch 508/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 630353285421.9562 - val_loss: 673285016263.4712\n",
      "Epoch 509/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 635732478356.5289 - val_loss: 677210829045.4143\n",
      "Epoch 510/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 625212336325.0782 - val_loss: 667646399247.4824\n",
      "Epoch 511/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 629543843168.0901 - val_loss: 670867621114.3112\n",
      "Epoch 512/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 622716039474.5662 - val_loss: 670263940305.9849\n",
      "Epoch 513/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 622281746490.7777 - val_loss: 666581826726.7781\n",
      "Epoch 514/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 624519578061.0017 - val_loss: 660773645740.3229\n",
      "Epoch 515/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 613656112075.5610 - val_loss: 661546442612.5862\n",
      "Epoch 516/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 615890472524.3534 - val_loss: 656324084301.9161\n",
      "Epoch 517/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 620795343320.5267 - val_loss: 706517372385.3232\n",
      "Epoch 518/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 616632533402.2915 - val_loss: 656879247295.4779\n",
      "Epoch 519/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 605765807383.4823 - val_loss: 651039040778.4417\n",
      "Epoch 520/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 601685528887.1761 - val_loss: 642834870236.2825\n",
      "Epoch 521/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 598780576370.9623 - val_loss: 654531819966.4697\n",
      "Epoch 522/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 601488148681.6882 - val_loss: 649890670869.0992\n",
      "Epoch 523/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 595078318364.6685 - val_loss: 632288792595.5870\n",
      "Epoch 524/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 601092472583.0591 - val_loss: 632265848200.0293\n",
      "Epoch 525/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 591880851896.2566 - val_loss: 634594723181.5292\n",
      "Epoch 526/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 594828278139.1738 - val_loss: 626611374864.0585\n",
      "Epoch 527/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 590015657265.9899 - val_loss: 623052711531.0087\n",
      "Epoch 528/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 579367121682.0079 - val_loss: 622411217045.2073\n",
      "Epoch 529/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 583564557653.7175 - val_loss: 617050671173.7069\n",
      "Epoch 530/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 583949969669.6184 - val_loss: 623891118913.6023\n",
      "Epoch 531/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 585119103770.0754 - val_loss: 612848856471.5837\n",
      "Epoch 532/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 575734987887.2167 - val_loss: 608643700357.5089\n",
      "Epoch 533/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 570672070573.0197 - val_loss: 605680074611.4341\n",
      "Epoch 534/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 575957801325.3439 - val_loss: 608630761449.5325\n",
      "Epoch 535/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 567885993178.3995 - val_loss: 601857732777.3705\n",
      "Epoch 536/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 569132328285.7850 - val_loss: 621696341543.0302\n",
      "Epoch 537/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 563317242613.1953 - val_loss: 596347963540.0552\n",
      "Epoch 538/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 568402818879.5317 - val_loss: 595856537479.5972\n",
      "Epoch 539/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 557515757057.4407 - val_loss: 587337831260.6785\n",
      "Epoch 540/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 556022089828.2678 - val_loss: 643733923262.1818\n",
      "Epoch 541/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 552037206761.6702 - val_loss: 624997601732.8068\n",
      "Epoch 542/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 551231293604.8081 - val_loss: 583725598992.4906\n",
      "Epoch 543/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 557020947404.7136 - val_loss: 601214763402.0455\n",
      "Epoch 544/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 550820503409.0895 - val_loss: 575354839862.6565\n",
      "Epoch 545/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 544823744139.7411 - val_loss: 573226705997.4841\n",
      "Epoch 546/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 538721584505.4452 - val_loss: 577556766957.3491\n",
      "Epoch 547/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 537919218811.8942 - val_loss: 570048772072.3802\n",
      "Epoch 548/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 537750635528.6438 - val_loss: 583511979745.6832\n",
      "Epoch 549/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 536796025816.2386 - val_loss: 561025760436.6042\n",
      "Epoch 550/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 534909947519.0636 - val_loss: 575815957159.2101\n",
      "Epoch 551/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 527221999823.4508 - val_loss: 562161886485.9634\n",
      "Epoch 552/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 523696420800.6123 - val_loss: 574840102898.1738\n",
      "Epoch 553/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 538722873761.2065 - val_loss: 548550929453.7991\n",
      "Epoch 554/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 517431826963.3044 - val_loss: 546804018090.4506\n",
      "Epoch 555/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 515220344036.7721 - val_loss: 591008021804.4309\n",
      "Epoch 556/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 525180299414.9781 - val_loss: 578627688684.7729\n",
      "Epoch 557/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 520342315118.6404 - val_loss: 540643877050.6531\n",
      "Epoch 558/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 507270960613.7805 - val_loss: 545459813934.5193\n",
      "Epoch 559/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 509868373906.5121 - val_loss: 549001483301.1578\n",
      "Epoch 560/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 505155951510.5458 - val_loss: 536609634379.4678\n",
      "Epoch 561/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 502174735687.8875 - val_loss: 544804716221.3896\n",
      "Epoch 562/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 509198442021.1682 - val_loss: 532466932951.1696\n",
      "Epoch 563/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 495715456356.7001 - val_loss: 518292361498.2841\n",
      "Epoch 564/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 495485832559.0726 - val_loss: 524313809086.1097\n",
      "Epoch 565/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 491590218670.7485 - val_loss: 514609638611.7131\n",
      "Epoch 566/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 489152719524.5200 - val_loss: 542067057476.4827\n",
      "Epoch 567/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 80us/step - loss: 488806038952.6978 - val_loss: 522251155102.8568\n",
      "Epoch 568/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 486098337054.3973 - val_loss: 504130556094.1097\n",
      "Epoch 569/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 484089039547.5701 - val_loss: 505407035142.5530\n",
      "Epoch 570/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 480362615417.8773 - val_loss: 504170726878.4427\n",
      "Epoch 571/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 477713750906.8857 - val_loss: 551728574338.4124\n",
      "Epoch 572/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 482227693465.4271 - val_loss: 499714392382.0017\n",
      "Epoch 573/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 465429550427.4800 - val_loss: 497567571693.7811\n",
      "Epoch 574/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 469947173314.6292 - val_loss: 490309447176.4973\n",
      "Epoch 575/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 471508484667.6421 - val_loss: 488706052309.1533\n",
      "Epoch 576/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 467675001700.9882 - val_loss: 487192900836.4197\n",
      "Epoch 577/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 465616621279.8740 - val_loss: 488704820407.4847\n",
      "Epoch 578/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 453032534951.8334 - val_loss: 494763747420.7505\n",
      "Epoch 579/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 463852433262.7844 - val_loss: 481021532611.0785\n",
      "Epoch 580/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 453582731885.1998 - val_loss: 510127908228.5727\n",
      "Epoch 581/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 450867956300.9296 - val_loss: 476926825108.1992\n",
      "Epoch 582/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 455414199574.3298 - val_loss: 474394771027.3890\n",
      "Epoch 583/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 443988249220.2499 - val_loss: 473415455712.0270\n",
      "Epoch 584/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 447992755058.8182 - val_loss: 474212984685.0970\n",
      "Epoch 585/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 442459523416.5988 - val_loss: 474581216504.5828\n",
      "Epoch 586/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 447087097640.4818 - val_loss: 472833531297.9533\n",
      "Epoch 587/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 438938612025.4811 - val_loss: 462115243643.1392\n",
      "Epoch 588/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 437784377363.5926 - val_loss: 461503114958.6723\n",
      "Epoch 589/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 431640806888.0856 - val_loss: 463678618269.9927\n",
      "Epoch 590/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 433617120956.1463 - val_loss: 468026004825.9421\n",
      "Epoch 591/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 426717681752.7429 - val_loss: 455346069510.9131\n",
      "Epoch 592/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 442706000610.7552 - val_loss: 452345205889.3322\n",
      "Epoch 593/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 432171834068.9251 - val_loss: 467433163994.6262\n",
      "Epoch 594/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 422551846561.6387 - val_loss: 442443648661.0633\n",
      "Epoch 595/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 421048072552.7338 - val_loss: 439281697652.8743\n",
      "Epoch 596/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 408180262025.7242 - val_loss: 437744527300.6627\n",
      "Epoch 597/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 407472323468.7496 - val_loss: 458782407289.1229\n",
      "Epoch 598/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 402480248602.6517 - val_loss: 428949549110.1525\n",
      "Epoch 599/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 397353703614.1631 - val_loss: 421339634502.2110\n",
      "Epoch 600/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 396362134006.4918 - val_loss: 419085308278.4585\n",
      "Epoch 601/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 386758597148.5245 - val_loss: 452514245189.2748\n",
      "Epoch 602/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 386467966010.2015 - val_loss: 426653409941.3513\n",
      "Epoch 603/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 386196487537.3776 - val_loss: 401987271206.1660\n",
      "Epoch 604/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 382075148902.2847 - val_loss: 415121746275.4475\n",
      "Epoch 605/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 379824315858.1880 - val_loss: 397841682285.6732\n",
      "Epoch 606/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 371249375461.3483 - val_loss: 401327343558.9671\n",
      "Epoch 607/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 365150201582.8565 - val_loss: 399169798544.9587\n",
      "Epoch 608/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 370794544861.5690 - val_loss: 389542805264.3466\n",
      "Epoch 609/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 365425190887.7974 - val_loss: 390797646735.9505\n",
      "Epoch 610/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 359417597318.1227 - val_loss: 387925687130.9502\n",
      "Epoch 611/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 353426657323.7951 - val_loss: 412263153378.2593\n",
      "Epoch 612/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 354139438394.0574 - val_loss: 374987409180.4445\n",
      "Epoch 613/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 348693862009.3010 - val_loss: 373248359586.1693\n",
      "Epoch 614/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 348212399034.8497 - val_loss: 372121723981.4841\n",
      "Epoch 615/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 344711852212.9432 - val_loss: 375694600015.1404\n",
      "Epoch 616/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 342815647074.3950 - val_loss: 365097609350.2289\n",
      "Epoch 617/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 337504022488.8149 - val_loss: 368962251137.4042\n",
      "Epoch 618/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 335294318572.4074 - val_loss: 363083016374.6205\n",
      "Epoch 619/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 332414453777.2875 - val_loss: 363249887799.4487\n",
      "Epoch 620/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 332048570235.4620 - val_loss: 364550496465.6968\n",
      "Epoch 621/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 334477104134.3388 - val_loss: 362866426040.3488\n",
      "Epoch 622/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 327743609994.8768 - val_loss: 361041033777.6877\n",
      "Epoch 623/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 325708856504.9769 - val_loss: 347984950548.8113\n",
      "Epoch 624/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 318097476661.5915 - val_loss: 342778610512.0045\n",
      "Epoch 625/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 315354295262.0011 - val_loss: 341868873498.1401\n",
      "Epoch 626/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 313415970661.5645 - val_loss: 343516161954.0974\n",
      "Epoch 627/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 306072786129.1795 - val_loss: 332776352684.7550\n",
      "Epoch 628/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 303813479071.9100 - val_loss: 320265059132.9935\n",
      "Epoch 629/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 297577436009.5982 - val_loss: 322550497645.2411\n",
      "Epoch 630/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 77us/step - loss: 300189796747.3090 - val_loss: 312467522162.7859\n",
      "Epoch 631/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 285367857071.3247 - val_loss: 309995089907.3260\n",
      "Epoch 632/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 278040035798.2217 - val_loss: 302527197625.2850\n",
      "Epoch 633/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 271823442415.5768 - val_loss: 296760136129.3502\n",
      "Epoch 634/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 268773583212.7676 - val_loss: 335298352197.9949\n",
      "Epoch 635/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 258045909391.9190 - val_loss: 276472889572.1317\n",
      "Epoch 636/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 242561711593.2380 - val_loss: 262213101075.4430\n",
      "Epoch 637/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 236313387409.0715 - val_loss: 241945727980.7010\n",
      "Epoch 638/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 225851549229.2358 - val_loss: 255219939806.7308\n",
      "Epoch 639/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 223283340504.0945 - val_loss: 282480807873.2062\n",
      "Epoch 640/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 214046800859.6961 - val_loss: 222725750727.5432\n",
      "Epoch 641/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 198652523660.0292 - val_loss: 214831988975.6534\n",
      "Epoch 642/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 189264228759.9865 - val_loss: 215336423990.2965\n",
      "Epoch 643/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 185712951752.3917 - val_loss: 209617207872.6661\n",
      "Epoch 644/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 178357877880.4367 - val_loss: 191956776929.4672\n",
      "Epoch 645/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 173712462010.7057 - val_loss: 186697886212.7527\n",
      "Epoch 646/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 172128063992.7968 - val_loss: 183555644071.2101\n",
      "Epoch 647/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 170148097082.2014 - val_loss: 178505723026.0388\n",
      "Epoch 648/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 164487626528.4142 - val_loss: 172798020363.4498\n",
      "Epoch 649/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 162554501162.6426 - val_loss: 166856886120.4883\n",
      "Epoch 650/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 155895336773.2943 - val_loss: 168404183284.8383\n",
      "Epoch 651/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 157824185343.4238 - val_loss: 173350667043.0695\n",
      "Epoch 652/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 149368728781.7220 - val_loss: 159497667832.0067\n",
      "Epoch 653/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 150978499247.4688 - val_loss: 155117845016.3398\n",
      "Epoch 654/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 144433152790.6179 - val_loss: 192550323132.3094\n",
      "Epoch 655/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 150113147503.5048 - val_loss: 168378268101.3828\n",
      "Epoch 656/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 138718924060.0923 - val_loss: 149564467357.2726\n",
      "Epoch 657/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 139677553096.3917 - val_loss: 144373340933.6889\n",
      "Epoch 658/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 134492747915.4530 - val_loss: 150673107753.4065\n",
      "Epoch 659/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 130932605554.9623 - val_loss: 138238145266.6779\n",
      "Epoch 660/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 126434521484.4615 - val_loss: 152292791028.9823\n",
      "Epoch 661/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 126761035480.3827 - val_loss: 148245862195.4880\n",
      "Epoch 662/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 124346676894.1812 - val_loss: 136052802190.4383\n",
      "Epoch 663/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 122376992169.8503 - val_loss: 136448202860.3049\n",
      "Epoch 664/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 122484527475.1064 - val_loss: 141049804158.8118\n",
      "Epoch 665/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 119611135351.1401 - val_loss: 127484577649.7058\n",
      "Epoch 666/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 117597818813.1548 - val_loss: 124343470896.8956\n",
      "Epoch 667/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 115240824640.6843 - val_loss: 122843388682.8737\n",
      "Epoch 668/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 115694757783.1221 - val_loss: 134744935762.4529\n",
      "Epoch 669/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 109187666286.4963 - val_loss: 125850329894.5260\n",
      "Epoch 670/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 109248288100.7000 - val_loss: 125360985780.7482\n",
      "Epoch 671/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 107386728441.0850 - val_loss: 130708580404.5682\n",
      "Epoch 672/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 106043141466.3275 - val_loss: 125694663998.8658\n",
      "Epoch 673/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 108917578452.9252 - val_loss: 141746868810.1716\n",
      "Epoch 674/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 104187051393.5126 - val_loss: 119159489313.9173\n",
      "Epoch 675/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 103707740103.5273 - val_loss: 123473295344.4456\n",
      "Epoch 676/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 102329415139.4755 - val_loss: 131901431100.8495\n",
      "Epoch 677/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 101307407024.0450 - val_loss: 166511007031.6647\n",
      "Epoch 678/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 110788365845.0332 - val_loss: 148068936118.4045\n",
      "Epoch 679/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 102545359435.2009 - val_loss: 106805029936.1035\n",
      "Epoch 680/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 97023879091.9347 - val_loss: 107282471426.7364\n",
      "Epoch 681/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 95963009208.4007 - val_loss: 105828140116.3972\n",
      "Epoch 682/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 93378861787.8402 - val_loss: 102377793412.1406\n",
      "Epoch 683/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 94990583433.4361 - val_loss: 107814532112.9947\n",
      "Epoch 684/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 96448090100.4750 - val_loss: 102994876500.6852\n",
      "Epoch 685/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 91387900155.2459 - val_loss: 103337994391.5117\n",
      "Epoch 686/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 95028970752.4322 - val_loss: 143576229745.7058\n",
      "Epoch 687/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 94312031780.0158 - val_loss: 100587071909.1218\n",
      "Epoch 688/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 89667991539.3224 - val_loss: 104940030143.2619\n",
      "Epoch 689/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 91579215828.2048 - val_loss: 100679135411.7401\n",
      "Epoch 690/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 90346998392.4367 - val_loss: 98850273714.9480\n",
      "Epoch 691/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 88755981630.0912 - val_loss: 99337851151.3384\n",
      "Epoch 692/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 88122204238.3703 - val_loss: 115198885829.8149\n",
      "Epoch 693/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 91996691276.7856 - val_loss: 104088189701.6889\n",
      "Epoch 694/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 87735139070.4153 - val_loss: 94981509868.9170\n",
      "Epoch 695/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 88012867707.3179 - val_loss: 103901015927.7547\n",
      "Epoch 696/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 86399320916.8531 - val_loss: 103060575392.7291\n",
      "Epoch 697/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 88803450022.5368 - val_loss: 106475262298.8062\n",
      "Epoch 698/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 84431286126.7845 - val_loss: 102930819275.3598\n",
      "Epoch 699/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 84076621994.5706 - val_loss: 95462119838.2087\n",
      "Epoch 700/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 85222065105.3236 - val_loss: 116551559066.0321\n",
      "Epoch 701/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 91301364440.3827 - val_loss: 106945607155.1820\n",
      "Epoch 702/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 87280112498.8182 - val_loss: 93852633654.2965\n",
      "Epoch 703/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 81789312355.5476 - val_loss: 95382950977.9623\n",
      "Epoch 704/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 82799413945.2650 - val_loss: 91032031675.5893\n",
      "Epoch 705/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 80386479609.9493 - val_loss: 100099221214.2267\n",
      "Epoch 706/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 80628119003.4080 - val_loss: 94837524367.9505\n",
      "Epoch 707/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 81857112155.6241 - val_loss: 93861196874.6037\n",
      "Epoch 708/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 80511782873.8953 - val_loss: 93186922329.5100\n",
      "Epoch 709/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 81640266014.9735 - val_loss: 88776452813.2321\n",
      "Epoch 710/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 77831663261.0287 - val_loss: 93225841024.8281\n",
      "Epoch 711/10000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 79169343511.813 - 0s 86us/step - loss: 80422178076.0923 - val_loss: 123347145285.7069\n",
      "Epoch 712/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 81951134976.7203 - val_loss: 89234422397.1555\n",
      "Epoch 713/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 77072485235.9707 - val_loss: 103410453436.7415\n",
      "Epoch 714/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 83774408149.6455 - val_loss: 91958333477.4458\n",
      "Epoch 715/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 81994995519.5318 - val_loss: 108954389609.7125\n",
      "Epoch 716/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 81588305946.5076 - val_loss: 86455273815.9257\n",
      "Epoch 717/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 78474149323.8492 - val_loss: 93126894517.3963\n",
      "Epoch 718/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 76014611818.4626 - val_loss: 100827770738.2819\n",
      "Epoch 719/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 76915120419.5836 - val_loss: 86941032097.1612\n",
      "Epoch 720/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 74888778251.2369 - val_loss: 93146406711.5207\n",
      "Epoch 721/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 76352269661.2088 - val_loss: 98751756021.4144\n",
      "Epoch 722/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 75575191569.2876 - val_loss: 87824559848.0202\n",
      "Epoch 723/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 75451386705.9719 - val_loss: 96667813208.7899\n",
      "Epoch 724/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 76831355075.9257 - val_loss: 85132276341.0903\n",
      "Epoch 725/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 71204785768.0135 - val_loss: 84458788518.9221\n",
      "Epoch 726/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 78274128262.6989 - val_loss: 83552160122.4911\n",
      "Epoch 727/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 71460586040.1846 - val_loss: 84215276941.7902\n",
      "Epoch 728/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 72051664632.0765 - val_loss: 98418142225.7148\n",
      "Epoch 729/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 75623781887.1356 - val_loss: 87472608226.3314\n",
      "Epoch 730/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 74922912826.2015 - val_loss: 84654256674.7094\n",
      "Epoch 731/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 70644582813.7490 - val_loss: 88434154220.3409\n",
      "Epoch 732/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 72055264815.5408 - val_loss: 81676248537.2579\n",
      "Epoch 733/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 75844485610.9668 - val_loss: 92684335470.9693\n",
      "Epoch 734/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 75941057677.1818 - val_loss: 111354952018.1648\n",
      "Epoch 735/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 70216587928.9949 - val_loss: 79278687894.7916\n",
      "Epoch 736/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 69830011066.7057 - val_loss: 88037845046.1525\n",
      "Epoch 737/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 70249740007.9415 - val_loss: 83804479444.2172\n",
      "Epoch 738/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 74667484703.4057 - val_loss: 116232010374.9491\n",
      "Epoch 739/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 76224761431.3022 - val_loss: 90011227790.7263\n",
      "Epoch 740/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 70894822281.2921 - val_loss: 83861403210.7477\n",
      "Epoch 741/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 70163132500.1328 - val_loss: 83519979494.6520\n",
      "Epoch 742/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 66797686477.4339 - val_loss: 80295387846.8951\n",
      "Epoch 743/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 69848043868.0563 - val_loss: 93013961951.2349\n",
      "Epoch 744/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 72082778250.3005 - val_loss: 99203358623.5049\n",
      "Epoch 745/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 70573600395.7411 - val_loss: 80940339996.1564\n",
      "Epoch 746/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 68415296308.5830 - val_loss: 80650636578.0613\n",
      "Epoch 747/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 68029746036.5470 - val_loss: 78416780434.0388\n",
      "Epoch 748/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 71486478028.2814 - val_loss: 80825919223.5747\n",
      "Epoch 749/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 69364431473.8098 - val_loss: 78053117719.2596\n",
      "Epoch 750/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 68403440472.3106 - val_loss: 81496490132.6312\n",
      "Epoch 751/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 69427214475.4530 - val_loss: 80321393507.5916\n",
      "Epoch 752/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 66996700234.9128 - val_loss: 77443443537.7328\n",
      "Epoch 753/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 65431291294.3253 - val_loss: 74472633380.5817\n",
      "Epoch 754/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 70198112136.1396 - val_loss: 85428109886.9378\n",
      "Epoch 755/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 65472060494.9465 - val_loss: 111169792355.4475\n",
      "Epoch 756/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 71098544299.7231 - val_loss: 102750198773.3423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 757/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 65360107092.4209 - val_loss: 82785368077.2501\n",
      "Epoch 758/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 66080732645.7805 - val_loss: 76847242791.6062\n",
      "Epoch 759/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 65431693665.8188 - val_loss: 90582944228.4917\n",
      "Epoch 760/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 66062786338.7192 - val_loss: 90394261450.4236\n",
      "Epoch 761/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 64871789913.1750 - val_loss: 77786227722.6577\n",
      "Epoch 762/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 66135576174.9285 - val_loss: 84482579523.6906\n",
      "Epoch 763/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 66891395194.1655 - val_loss: 96615629690.0591\n",
      "Epoch 764/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 66038541303.3562 - val_loss: 85153060420.9868\n",
      "Epoch 765/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 66171416565.0332 - val_loss: 74268688563.7401\n",
      "Epoch 766/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 64271480316.8306 - val_loss: 74379218621.3896\n",
      "Epoch 767/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 68385057006.4243 - val_loss: 76571252069.4639\n",
      "Epoch 768/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 62311358874.2915 - val_loss: 73604024895.5139\n",
      "Epoch 769/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 66234625466.5616 - val_loss: 75774391478.3325\n",
      "Epoch 770/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 65760587315.4305 - val_loss: 83654032457.4515\n",
      "Epoch 771/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 62978840648.6078 - val_loss: 74130887248.2205\n",
      "Epoch 772/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 64223449749.5374 - val_loss: 83258910195.1820\n",
      "Epoch 773/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 62959541124.1058 - val_loss: 80587767579.8683\n",
      "Epoch 774/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 63856214329.4811 - val_loss: 74816615615.5499\n",
      "Epoch 775/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 60859274283.2189 - val_loss: 87502699501.2771\n",
      "Epoch 776/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 63041737042.8362 - val_loss: 76085358132.2802\n",
      "Epoch 777/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 62613627896.5087 - val_loss: 82122626437.7249\n",
      "Epoch 778/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 62943946354.3860 - val_loss: 73889567051.8279\n",
      "Epoch 779/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 63405787706.4896 - val_loss: 85370302383.3474\n",
      "Epoch 780/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 62736701434.2375 - val_loss: 73941152196.8067\n",
      "Epoch 781/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 61472943093.0512 - val_loss: 82231880220.3724\n",
      "Epoch 782/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 63410441209.6612 - val_loss: 80549083835.3733\n",
      "Epoch 783/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 61205977932.7856 - val_loss: 78588688998.6880\n",
      "Epoch 784/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 64525276277.1232 - val_loss: 72002981588.4332\n",
      "Epoch 785/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 62214846439.7974 - val_loss: 72758197414.7781\n",
      "Epoch 786/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 60407194353.7378 - val_loss: 70983608150.0535\n",
      "Epoch 787/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 60909436098.7732 - val_loss: 73183699916.1519\n",
      "Epoch 788/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 62130783955.1964 - val_loss: 88254742570.3426\n",
      "Epoch 789/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 63031279939.8537 - val_loss: 102894347509.7024\n",
      "Epoch 790/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 62348578272.0180 - val_loss: 72667564419.7086\n",
      "Epoch 791/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 59739574933.5374 - val_loss: 72014383998.6678\n",
      "Epoch 792/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 58278313476.8981 - val_loss: 90868221835.0537\n",
      "Epoch 793/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 62587587914.1925 - val_loss: 72425256513.5302\n",
      "Epoch 794/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 60394626311.3472 - val_loss: 93930304643.6366\n",
      "Epoch 795/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 62455393755.4080 - val_loss: 75415807560.4433\n",
      "Epoch 796/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 62247749292.0113 - val_loss: 68745202862.8433\n",
      "Epoch 797/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 59868684281.6612 - val_loss: 75899695056.7606\n",
      "Epoch 798/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 61018197054.8115 - val_loss: 70966766474.1896\n",
      "Epoch 799/10000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 65262120980.7451 - val_loss: 78978289863.6152\n",
      "Epoch 800/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 61844189306.1655 - val_loss: 73860068036.5907\n",
      "Epoch 801/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 56914190926.0822 - val_loss: 69173385027.6186\n",
      "Epoch 802/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 62434813791.8019 - val_loss: 114758098457.4920\n",
      "Epoch 803/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 59312821116.0383 - val_loss: 71708932511.3609\n",
      "Epoch 804/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 60164403119.3247 - val_loss: 87467938247.1111\n",
      "Epoch 805/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 60007082962.4761 - val_loss: 66728321965.3311\n",
      "Epoch 806/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 59429251119.2527 - val_loss: 71957117744.3195\n",
      "Epoch 807/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 58852936976.5672 - val_loss: 68867789284.4917\n",
      "Epoch 808/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 59516285779.5566 - val_loss: 69987742827.4408\n",
      "Epoch 809/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 56478462263.1761 - val_loss: 69258020104.1373\n",
      "Epoch 810/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 57091306672.9094 - val_loss: 73810545080.1328\n",
      "Epoch 811/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 63841477686.7440 - val_loss: 95735410885.0228\n",
      "Epoch 812/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 59185497636.0158 - val_loss: 71905921369.0779\n",
      "Epoch 813/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 56989768612.3759 - val_loss: 94309643252.7663\n",
      "Epoch 814/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 59558653364.2228 - val_loss: 79274568783.2124\n",
      "Epoch 815/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 59113862399.2797 - val_loss: 71629841096.0473\n",
      "Epoch 816/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 56482097639.5093 - val_loss: 66080039771.5263\n",
      "Epoch 817/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 57053829812.6550 - val_loss: 67021531474.1648\n",
      "Epoch 818/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 58606730332.7766 - val_loss: 97412923659.3058\n",
      "Epoch 819/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 63863468195.6556 - val_loss: 67019601043.1910\n",
      "Epoch 820/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 57744992224.8824 - val_loss: 74468796681.5775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 821/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 57959715101.8211 - val_loss: 68558363129.2309\n",
      "Epoch 822/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 57762965115.6061 - val_loss: 78388610908.9665\n",
      "Epoch 823/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 58630301012.5650 - val_loss: 84802138251.4138\n",
      "Epoch 824/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 60197103657.4902 - val_loss: 78168175706.1581\n",
      "Epoch 825/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 57008723456.2881 - val_loss: 73143957970.6329\n",
      "Epoch 826/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 55881318842.5616 - val_loss: 67595124919.1966\n",
      "Epoch 827/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 54482858235.2459 - val_loss: 78217524003.3575\n",
      "Epoch 828/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 60995007761.7197 - val_loss: 67380448586.9637\n",
      "Epoch 829/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 57293440698.9938 - val_loss: 66081594779.6163\n",
      "Epoch 830/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 58167207493.4384 - val_loss: 69483061530.8602\n",
      "Epoch 831/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 57343858864.3331 - val_loss: 66420059409.9308\n",
      "Epoch 832/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 55406901830.0146 - val_loss: 91323064218.6082\n",
      "Epoch 833/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 60576203148.4615 - val_loss: 66731780858.1671\n",
      "Epoch 834/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 56383852146.3860 - val_loss: 68126927724.2329\n",
      "Epoch 835/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 57133988145.4136 - val_loss: 77614975192.0338\n",
      "Epoch 836/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 56764985373.9651 - val_loss: 68545125363.0380\n",
      "Epoch 837/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 56322893507.0613 - val_loss: 65815861120.6841\n",
      "Epoch 838/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 55694617141.8796 - val_loss: 65937015085.2951\n",
      "Epoch 839/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 54203019819.5070 - val_loss: 66678676954.4101\n",
      "Epoch 840/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 57069789451.3810 - val_loss: 64235548769.9353\n",
      "Epoch 841/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 55962102256.7293 - val_loss: 71945037607.9662\n",
      "Epoch 842/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 55308156131.6196 - val_loss: 65454906273.2332\n",
      "Epoch 843/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 55790677799.3292 - val_loss: 71455957791.6129\n",
      "Epoch 844/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 55868142005.9516 - val_loss: 64699930841.1859\n",
      "Epoch 845/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 54102972753.6837 - val_loss: 64989289224.5693\n",
      "Epoch 846/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 55804230454.0236 - val_loss: 66650431597.4571\n",
      "Epoch 847/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 56898931037.2088 - val_loss: 64481231998.4518\n",
      "Epoch 848/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 55624968121.6972 - val_loss: 76165585943.9077\n",
      "Epoch 849/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 56937555888.4772 - val_loss: 71243067988.9733\n",
      "Epoch 850/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 57948247200.7743 - val_loss: 70638427426.6374\n",
      "Epoch 851/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 54816697945.0310 - val_loss: 64202934345.7395\n",
      "Epoch 852/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 54603900199.6173 - val_loss: 65839986015.1269\n",
      "Epoch 853/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 53600030977.8728 - val_loss: 64816620846.1592\n",
      "Epoch 854/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 54384745617.7918 - val_loss: 104012301021.7947\n",
      "Epoch 855/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 58894683692.0833 - val_loss: 76177547238.5080\n",
      "Epoch 856/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 54472536850.0079 - val_loss: 78788706649.6540\n",
      "Epoch 857/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 54833337066.8227 - val_loss: 72642612493.3221\n",
      "Epoch 858/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 54516800564.4389 - val_loss: 65660214537.8655\n",
      "Epoch 859/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 55580538597.6365 - val_loss: 63135043066.0951\n",
      "Epoch 860/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 52980105031.5993 - val_loss: 71319671115.5398\n",
      "Epoch 861/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 55322305899.6151 - val_loss: 90011895260.1384\n",
      "Epoch 862/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 58566685977.7873 - val_loss: 62579926034.7229\n",
      "Epoch 863/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 53804442881.5847 - val_loss: 76248977973.7204\n",
      "Epoch 864/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 53241586207.9820 - val_loss: 66166737709.4391\n",
      "Epoch 865/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 53986558145.6207 - val_loss: 68016991335.9842\n",
      "Epoch 866/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 52615883142.6989 - val_loss: 64668743442.0748\n",
      "Epoch 867/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 57138843276.8936 - val_loss: 62058137424.2925\n",
      "Epoch 868/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 52747956950.0777 - val_loss: 66956574044.8225\n",
      "Epoch 869/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 52389789055.2076 - val_loss: 76781155328.2880\n",
      "Epoch 870/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 53507530088.1576 - val_loss: 68742833376.3871\n",
      "Epoch 871/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 59485937131.5431 - val_loss: 65402844614.2470\n",
      "Epoch 872/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 52195059656.3917 - val_loss: 62814790220.7640\n",
      "Epoch 873/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 52572192773.7625 - val_loss: 81436738328.5558\n",
      "Epoch 874/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 53786650318.5864 - val_loss: 63429340976.0315\n",
      "Epoch 875/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 52910561301.8976 - val_loss: 63154032276.4872\n",
      "Epoch 876/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 52723415518.8655 - val_loss: 71244971884.5210\n",
      "Epoch 877/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 53628565560.4727 - val_loss: 89593169876.7932\n",
      "Epoch 878/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 66549320346.1474 - val_loss: 67451472218.2301\n",
      "Epoch 879/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 51790254391.1761 - val_loss: 63430286105.2759\n",
      "Epoch 880/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 53147990568.0495 - val_loss: 64460663247.4644\n",
      "Epoch 881/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 51225097391.7569 - val_loss: 62964963259.4453\n",
      "Epoch 882/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 52476090014.1812 - val_loss: 69258185882.6802\n",
      "Epoch 883/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 53188179976.0675 - val_loss: 67339824454.3550\n",
      "Epoch 884/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 53165572333.4159 - val_loss: 62167323105.6113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 885/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 52147052781.9921 - val_loss: 87595212290.4484\n",
      "Epoch 886/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 54448223782.3208 - val_loss: 65737735150.4293\n",
      "Epoch 887/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 51122094550.2217 - val_loss: 63986312732.6605\n",
      "Epoch 888/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 52593315975.9955 - val_loss: 75352046136.6008\n",
      "Epoch 889/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 54143430616.8149 - val_loss: 74200849098.3516\n",
      "Epoch 890/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 50777850436.8621 - val_loss: 80386200885.0723\n",
      "Epoch 891/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 53074080815.8289 - val_loss: 64437314441.0374\n",
      "Epoch 892/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 54708204379.7682 - val_loss: 70459536070.8951\n",
      "Epoch 893/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 53446840103.0411 - val_loss: 63899085877.8644\n",
      "Epoch 894/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 50289023802.9218 - val_loss: 61895868870.5350\n",
      "Epoch 895/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 50108210988.2274 - val_loss: 62186709117.5876\n",
      "Epoch 896/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 50840689261.1998 - val_loss: 61697025176.3758\n",
      "Epoch 897/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 50330883548.5605 - val_loss: 60608207935.0819\n",
      "Epoch 898/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 50737494455.6804 - val_loss: 67894875900.7595\n",
      "Epoch 899/10000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 51523362728.4097 - val_loss: 68964181543.0301\n",
      "Epoch 900/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 53498052815.4508 - val_loss: 69486014882.2413\n",
      "Epoch 901/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 50782533181.3708 - val_loss: 61632905438.9468\n",
      "Epoch 902/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 52804133963.4890 - val_loss: 60096447229.0475\n",
      "Epoch 903/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 49434131398.9510 - val_loss: 64233254265.6270\n",
      "Epoch 904/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 51673477878.3478 - val_loss: 62033454679.4217\n",
      "Epoch 905/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 52119195468.2093 - val_loss: 64372593598.6138\n",
      "Epoch 906/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 51503567818.4086 - val_loss: 80972307890.0838\n",
      "Epoch 907/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 53171581470.8295 - val_loss: 60534037343.5589\n",
      "Epoch 908/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 49868541310.0552 - val_loss: 65386725893.9049\n",
      "Epoch 909/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 49101682753.6927 - val_loss: 65367945158.3910\n",
      "Epoch 910/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 54881024803.2954 - val_loss: 79741718209.4222\n",
      "Epoch 911/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 52748402119.8154 - val_loss: 60006351124.5232\n",
      "Epoch 912/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 49361921406.0552 - val_loss: 67624088835.2405\n",
      "Epoch 913/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 50651298254.1542 - val_loss: 78499572986.8872\n",
      "Epoch 914/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 53842597239.1401 - val_loss: 66213919831.2776\n",
      "Epoch 915/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 51973591082.0664 - val_loss: 62224895455.0188\n",
      "Epoch 916/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 50631751779.4035 - val_loss: 69311265125.1758\n",
      "Epoch 917/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 51874464328.3196 - val_loss: 64964814342.1930\n",
      "Epoch 918/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 50220280290.8993 - val_loss: 62614157917.4706\n",
      "Epoch 919/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 52381456493.4879 - val_loss: 65711013499.7153\n",
      "Epoch 920/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 54590988655.6488 - val_loss: 60096231116.9440\n",
      "Epoch 921/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 55538403061.7715 - val_loss: 60981486409.0914\n",
      "Epoch 922/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 50166139321.4091 - val_loss: 62430747167.2529\n",
      "Epoch 923/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 50918788947.1244 - val_loss: 61902700363.1077\n",
      "Epoch 924/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 52169154103.6083 - val_loss: 64860264687.0774\n",
      "Epoch 925/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 50839042242.7732 - val_loss: 63108043987.1370\n",
      "Epoch 926/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 49365054899.0704 - val_loss: 60744893757.1376\n",
      "Epoch 927/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 49118112835.9977 - val_loss: 58606210018.9075\n",
      "Epoch 928/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 51347691961.4091 - val_loss: 61854666278.4540\n",
      "Epoch 929/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 48378791101.5869 - val_loss: 64342186983.8042\n",
      "Epoch 930/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 48595124195.7636 - val_loss: 65183787606.5575\n",
      "Epoch 931/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 49889001641.4181 - val_loss: 62662817505.1072\n",
      "Epoch 932/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 51648502611.8447 - val_loss: 76594014404.7347\n",
      "Epoch 933/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 49353574346.4086 - val_loss: 62040792940.5210\n",
      "Epoch 934/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 51553744960.5402 - val_loss: 61728834099.4160\n",
      "Epoch 935/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 48379146973.7130 - val_loss: 60139311622.4810\n",
      "Epoch 936/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 49575525507.9617 - val_loss: 80092575144.2903\n",
      "Epoch 937/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 52329408626.0979 - val_loss: 82836793855.8560\n",
      "Epoch 938/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 51729499431.6173 - val_loss: 60367305987.5285\n",
      "Epoch 939/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 49112861726.5414 - val_loss: 66397965880.3128\n",
      "Epoch 940/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 49304760790.2217 - val_loss: 110993418347.7288\n",
      "Epoch 941/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 55714424120.9049 - val_loss: 78550788405.3603\n",
      "Epoch 942/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 48123183857.7378 - val_loss: 68041140643.9696\n",
      "Epoch 943/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 50683629381.2943 - val_loss: 59979233907.3620\n",
      "Epoch 944/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 50891861657.5712 - val_loss: 61778536606.4248\n",
      "Epoch 945/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 49690361503.3337 - val_loss: 63163300730.0591\n",
      "Epoch 946/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 48514413044.1868 - val_loss: 59148516975.0414\n",
      "Epoch 947/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 50066161433.4992 - val_loss: 64264556045.1060\n",
      "Epoch 948/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 49094833569.7828 - val_loss: 58078424836.8248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 949/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 49202027107.9797 - val_loss: 59264713045.0453\n",
      "Epoch 950/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 47974700185.8593 - val_loss: 61661030448.9677\n",
      "Epoch 951/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 47647908563.7726 - val_loss: 67041807599.6534\n",
      "Epoch 952/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 47740760573.4069 - val_loss: 58227484249.1499\n",
      "Epoch 953/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 47082028223.8920 - val_loss: 62369403534.4383\n",
      "Epoch 954/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 48377132725.2313 - val_loss: 63344323971.9966\n",
      "Epoch 955/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 52269872126.2712 - val_loss: 65067477234.2458\n",
      "Epoch 956/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 48092753327.6128 - val_loss: 63168513549.3941\n",
      "Epoch 957/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 49104469478.9330 - val_loss: 60172818926.8613\n",
      "Epoch 958/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 48136482594.7192 - val_loss: 87121103371.6658\n",
      "Epoch 959/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 50631118993.2155 - val_loss: 60438659839.9280\n",
      "Epoch 960/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 52631226339.1874 - val_loss: 59380718640.6796\n",
      "Epoch 961/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 48101172343.2842 - val_loss: 57718468363.7378\n",
      "Epoch 962/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 48393835397.2583 - val_loss: 58617676315.2203\n",
      "Epoch 963/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 47731557692.3624 - val_loss: 58645164406.4585\n",
      "Epoch 964/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 46008401371.4080 - val_loss: 64455497240.9159\n",
      "Epoch 965/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 48609100366.0822 - val_loss: 57785887959.7457\n",
      "Epoch 966/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 47496421795.2234 - val_loss: 64819137270.1345\n",
      "Epoch 967/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 49699746338.2870 - val_loss: 58019078237.3266\n",
      "Epoch 968/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 47625567326.5053 - val_loss: 58245330568.3893\n",
      "Epoch 969/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 46625443898.2015 - val_loss: 58020613781.6394\n",
      "Epoch 970/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 46439525019.2999 - val_loss: 60359538152.8124\n",
      "Epoch 971/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 47504242175.1356 - val_loss: 63273290214.7961\n",
      "Epoch 972/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 47803273577.8863 - val_loss: 61995525069.5921\n",
      "Epoch 973/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 52190044086.2397 - val_loss: 61241970038.1705\n",
      "Epoch 974/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 47944739052.2634 - val_loss: 61305107288.0698\n",
      "Epoch 975/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 47673252301.0017 - val_loss: 59130405970.0928\n",
      "Epoch 976/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 47477257379.0793 - val_loss: 63633445543.7862\n",
      "Epoch 977/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 49308030170.3996 - val_loss: 81321063869.0295\n",
      "Epoch 978/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 55581419035.9482 - val_loss: 58104628451.2675\n",
      "Epoch 979/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 46771570124.4254 - val_loss: 86715797959.5432\n",
      "Epoch 980/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 52674548931.3495 - val_loss: 68146063965.7587\n",
      "Epoch 981/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 46793366109.0647 - val_loss: 61301254043.1842\n",
      "Epoch 982/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 48518835184.4412 - val_loss: 60121369127.3181\n",
      "Epoch 983/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 47588169452.5515 - val_loss: 60053822434.9075\n",
      "Epoch 984/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 46590777478.8430 - val_loss: 61062861055.7840\n",
      "Epoch 985/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 47545916541.0467 - val_loss: 64330847606.1705\n",
      "Epoch 986/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 46552768415.1896 - val_loss: 58099355235.5195\n",
      "Epoch 987/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 46854049370.1835 - val_loss: 57751356259.0155\n",
      "Epoch 988/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 48129813983.1536 - val_loss: 58014142526.2177\n",
      "Epoch 989/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 47019855696.8194 - val_loss: 57183785056.7831\n",
      "Epoch 990/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 46474050300.1103 - val_loss: 57662314455.0976\n",
      "Epoch 991/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 46625982541.2178 - val_loss: 58417323964.5975\n",
      "Epoch 992/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 48710842598.5008 - val_loss: 56806240241.0217\n",
      "Epoch 993/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 46252277054.6674 - val_loss: 81744569476.7887\n",
      "Epoch 994/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 47546162619.1379 - val_loss: 55842964461.8532\n",
      "Epoch 995/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 45264343220.9432 - val_loss: 58461546100.2262\n",
      "Epoch 996/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 46152689349.3663 - val_loss: 58106681157.9229\n",
      "Epoch 997/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 45550638657.9809 - val_loss: 64480822396.7235\n",
      "Epoch 998/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 47838221286.0686 - val_loss: 68015302472.2273\n",
      "Epoch 999/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 48286809441.2425 - val_loss: 66860126914.2864\n",
      "Epoch 1000/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 46485960380.0743 - val_loss: 59092368178.6239\n",
      "Epoch 1001/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 47622458710.2938 - val_loss: 64003920525.2861\n",
      "Epoch 1002/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 45469325864.0495 - val_loss: 57294361839.9415\n",
      "Epoch 1003/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 48329829760.3602 - val_loss: 79077942425.5280\n",
      "Epoch 1004/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 44736470305.8548 - val_loss: 60450947104.2610\n",
      "Epoch 1005/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 46492700927.8559 - val_loss: 61466590469.2568\n",
      "Epoch 1006/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 48649013598.3613 - val_loss: 56920249340.8315\n",
      "Epoch 1007/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 46301326675.4125 - val_loss: 68557625712.1215\n",
      "Epoch 1008/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 46903832231.4012 - val_loss: 72290353713.1117\n",
      "Epoch 1009/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 47941088631.7164 - val_loss: 55080855690.2616\n",
      "Epoch 1010/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 44049803456.4682 - val_loss: 57368034546.2458\n",
      "Epoch 1011/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 45208454176.8464 - val_loss: 55706193366.3775\n",
      "Epoch 1012/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 47449111135.3697 - val_loss: 61087112326.5170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1013/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 46242567219.2864 - val_loss: 56175241364.0551\n",
      "Epoch 1014/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 43650385847.9685 - val_loss: 65949774064.8056\n",
      "Epoch 1015/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 45153779292.4885 - val_loss: 54250780828.6965\n",
      "Epoch 1016/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 44211422458.3815 - val_loss: 54832555613.7587\n",
      "Epoch 1017/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 43597327132.3804 - val_loss: 54340943998.7398\n",
      "Epoch 1018/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 45406664082.8002 - val_loss: 54932294409.1454\n",
      "Epoch 1019/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 45486452481.8728 - val_loss: 55601031918.0692\n",
      "Epoch 1020/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 44688616750.5324 - val_loss: 54121435596.8720\n",
      "Epoch 1021/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 44271656867.7997 - val_loss: 54789250356.4962\n",
      "Epoch 1022/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 44688451090.7282 - val_loss: 69742051596.4579\n",
      "Epoch 1023/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 46446900588.7676 - val_loss: 55847198059.8008\n",
      "Epoch 1024/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 43426056552.0135 - val_loss: 61552117186.7904\n",
      "Epoch 1025/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 44775876293.9426 - val_loss: 54972868847.0774\n",
      "Epoch 1026/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 42854729175.9505 - val_loss: 53359755034.7162\n",
      "Epoch 1027/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 43982929260.7676 - val_loss: 59874928975.8605\n",
      "Epoch 1028/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 43528410633.5082 - val_loss: 63058553686.3415\n",
      "Epoch 1029/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 43947095894.5819 - val_loss: 54335960761.9331\n",
      "Epoch 1030/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 43546571510.3478 - val_loss: 59857643369.9286\n",
      "Epoch 1031/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 43104636614.8070 - val_loss: 53824381767.9392\n",
      "Epoch 1032/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 41081445915.9482 - val_loss: 54528359893.8014\n",
      "Epoch 1033/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 45840961471.4598 - val_loss: 59099583578.1581\n",
      "Epoch 1034/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 42988056107.5070 - val_loss: 51910717384.6954\n",
      "Epoch 1035/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 42790542852.8981 - val_loss: 57309119907.6816\n",
      "Epoch 1036/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 41706838107.3360 - val_loss: 58679669472.2430\n",
      "Epoch 1037/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 42914263927.4282 - val_loss: 54263860256.5491\n",
      "Epoch 1038/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 42864038012.4705 - val_loss: 52785242521.6000\n",
      "Epoch 1039/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 42280688421.6004 - val_loss: 51630784416.3691\n",
      "Epoch 1040/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 40721732978.5301 - val_loss: 53593634174.8118\n",
      "Epoch 1041/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 43292284788.5470 - val_loss: 56363483286.3595\n",
      "Epoch 1042/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 41112738341.7445 - val_loss: 60114140412.0394\n",
      "Epoch 1043/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 46824267794.4401 - val_loss: 52078138989.8892\n",
      "Epoch 1044/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 40316485245.9111 - val_loss: 49886363733.2613\n",
      "Epoch 1045/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 41228294670.6944 - val_loss: 50226451344.5266\n",
      "Epoch 1046/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 41595069314.9533 - val_loss: 54572144565.6844\n",
      "Epoch 1047/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 41567796079.3607 - val_loss: 49449610217.8205\n",
      "Epoch 1048/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 40565478968.7608 - val_loss: 50391588821.3693\n",
      "Epoch 1049/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 39164247590.8970 - val_loss: 52871507671.8897\n",
      "Epoch 1050/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 42677865984.2881 - val_loss: 54211972754.7589\n",
      "Epoch 1051/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 44008177509.5644 - val_loss: 59921836322.3494\n",
      "Epoch 1052/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 40953073031.8514 - val_loss: 59687723791.4824\n",
      "Epoch 1053/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 42222624205.5779 - val_loss: 49700200454.9131\n",
      "Epoch 1054/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 39354247271.7254 - val_loss: 61346833033.8295\n",
      "Epoch 1055/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 40574556465.4136 - val_loss: 50752689045.1353\n",
      "Epoch 1056/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 41491788084.8711 - val_loss: 48987038081.9803\n",
      "Epoch 1057/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 42257871680.1080 - val_loss: 61072072186.9592\n",
      "Epoch 1058/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 44369877098.0304 - val_loss: 50252572294.6610\n",
      "Epoch 1059/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 40328985821.8571 - val_loss: 51194514640.8326\n",
      "Epoch 1060/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 39712449272.6528 - val_loss: 49671749649.8588\n",
      "Epoch 1061/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 41854552206.9105 - val_loss: 56385367894.6295\n",
      "Epoch 1062/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 40274067181.1277 - val_loss: 57455146915.2495\n",
      "Epoch 1063/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 39108451895.6083 - val_loss: 48224280533.3693\n",
      "Epoch 1064/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 40520344674.5391 - val_loss: 50036555978.7837\n",
      "Epoch 1065/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 40637380418.9893 - val_loss: 50328611673.7980\n",
      "Epoch 1066/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 39702988073.9223 - val_loss: 56709469122.6464\n",
      "Epoch 1067/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 41545808887.3562 - val_loss: 51015871484.2554\n",
      "Epoch 1068/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 39825581290.5346 - val_loss: 49611843617.9893\n",
      "Epoch 1069/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 40757721971.5025 - val_loss: 49847877650.4349\n",
      "Epoch 1070/10000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 40386088584.2836 - val_loss: 48489109580.6200\n",
      "Epoch 1071/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 42489794368.6843 - val_loss: 49481632798.8208\n",
      "Epoch 1072/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 37948758206.1632 - val_loss: 47441430797.0340\n",
      "Epoch 1073/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 38067162778.7237 - val_loss: 50055039433.9916\n",
      "Epoch 1074/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 39003421196.3894 - val_loss: 54113795304.4523\n",
      "Epoch 1075/10000\n",
      "3554/3554 [==============================] - 1s 143us/step - loss: 38071174217.1840 - val_loss: 84825004797.0475\n",
      "Epoch 1076/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 43646241319.4733 - val_loss: 48643803405.0340\n",
      "Epoch 1077/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 38204745505.5667 - val_loss: 48117987114.2706\n",
      "Epoch 1078/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 39372839887.5948 - val_loss: 53877822934.3775\n",
      "Epoch 1079/10000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 38038931530.926 - 0s 85us/step - loss: 38096345642.3545 - val_loss: 59387049038.9243\n",
      "Epoch 1080/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 38991205078.3658 - val_loss: 46375583548.1294\n",
      "Epoch 1081/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 37665330018.6832 - val_loss: 65701055795.0560\n",
      "Epoch 1082/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 38261642154.1384 - val_loss: 49899960750.3392\n",
      "Epoch 1083/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 36750978003.9167 - val_loss: 45241189894.7691\n",
      "Epoch 1084/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 37312152688.3692 - val_loss: 45359420509.0385\n",
      "Epoch 1085/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 36306307838.4153 - val_loss: 57445395190.7105\n",
      "Epoch 1086/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 37727572142.0281 - val_loss: 47099110533.9409\n",
      "Epoch 1087/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 35550367255.3382 - val_loss: 44177978127.4824\n",
      "Epoch 1088/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 33531968510.2712 - val_loss: 46481195300.6537\n",
      "Epoch 1089/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 34021497061.6365 - val_loss: 45676122122.9457\n",
      "Epoch 1090/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 34054214324.6550 - val_loss: 42524755890.2279\n",
      "Epoch 1091/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 35094127133.1007 - val_loss: 46084714401.5212\n",
      "Epoch 1092/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 34655008637.7670 - val_loss: 41907112580.6447\n",
      "Epoch 1093/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 32826370438.6989 - val_loss: 40823176907.7918\n",
      "Epoch 1094/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 34150389889.0805 - val_loss: 43602204004.8878\n",
      "Epoch 1095/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 32301971512.4727 - val_loss: 40904827259.0672\n",
      "Epoch 1096/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 33397574363.1199 - val_loss: 44444937511.8222\n",
      "Epoch 1097/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 31195091895.9685 - val_loss: 40747549655.9617\n",
      "Epoch 1098/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 32888346924.8036 - val_loss: 40611673245.5606\n",
      "Epoch 1099/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 31280731656.3557 - val_loss: 41435482316.5120\n",
      "Epoch 1100/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 30889626651.6601 - val_loss: 50038748575.3609\n",
      "Epoch 1101/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 29688198053.5284 - val_loss: 48062754150.0399\n",
      "Epoch 1102/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 31214271781.3123 - val_loss: 40278426461.8307\n",
      "Epoch 1103/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 28890132830.3613 - val_loss: 40432173247.8380\n",
      "Epoch 1104/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 29320395062.0236 - val_loss: 35839730849.0172\n",
      "Epoch 1105/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 27209769217.8728 - val_loss: 38238654580.3702\n",
      "Epoch 1106/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 27637969652.0428 - val_loss: 35047043472.9586\n",
      "Epoch 1107/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 27411215016.8419 - val_loss: 51238724644.0056\n",
      "Epoch 1108/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 27721509539.3675 - val_loss: 40923057935.7705\n",
      "Epoch 1109/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 26689776887.2122 - val_loss: 34719468891.9584\n",
      "Epoch 1110/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 25413011708.1103 - val_loss: 36763471820.4399\n",
      "Epoch 1111/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 25233243288.7068 - val_loss: 34606169880.4118\n",
      "Epoch 1112/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 25102612566.4378 - val_loss: 34700780781.6371\n",
      "Epoch 1113/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 27160113725.9471 - val_loss: 41214384159.1089\n",
      "Epoch 1114/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 27883608369.3416 - val_loss: 32555127302.1930\n",
      "Epoch 1115/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 23689555347.9527 - val_loss: 34002370786.1153\n",
      "Epoch 1116/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 24162608869.6365 - val_loss: 36218465562.8602\n",
      "Epoch 1117/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 24177343757.1097 - val_loss: 31098743146.0726\n",
      "Epoch 1118/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 23876521183.8739 - val_loss: 42763016652.2959\n",
      "Epoch 1119/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 23183287293.1187 - val_loss: 33418700397.0250\n",
      "Epoch 1120/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 24307979703.6804 - val_loss: 30511114148.4017\n",
      "Epoch 1121/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 25652317629.4429 - val_loss: 41262993322.1626\n",
      "Epoch 1122/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 22982301510.4468 - val_loss: 29880968107.0267\n",
      "Epoch 1123/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 23083350242.4671 - val_loss: 30486017994.4236\n",
      "Epoch 1124/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 21619843231.5498 - val_loss: 30617487570.5609\n",
      "Epoch 1125/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 22188702936.0945 - val_loss: 28928443184.6076\n",
      "Epoch 1126/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 21971993111.9145 - val_loss: 28434230345.4515\n",
      "Epoch 1127/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 21204220813.4699 - val_loss: 28553481906.1558\n",
      "Epoch 1128/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 21069529414.1587 - val_loss: 34880376250.4371\n",
      "Epoch 1129/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 20864909905.5397 - val_loss: 27635244227.0065\n",
      "Epoch 1130/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 21534043607.9505 - val_loss: 27185107759.4554\n",
      "Epoch 1131/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 20198481737.9043 - val_loss: 29802305133.6011\n",
      "Epoch 1132/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 20718475402.8768 - val_loss: 28646387340.1339\n",
      "Epoch 1133/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 20334744735.3337 - val_loss: 28850711239.4712\n",
      "Epoch 1134/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 19176192335.9550 - val_loss: 25157945852.9755\n",
      "Epoch 1135/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 19272829095.5453 - val_loss: 28946456478.0647\n",
      "Epoch 1136/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 19269616821.5194 - val_loss: 26524524677.3648\n",
      "Epoch 1137/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 18360325836.2814 - val_loss: 27005873920.6481\n",
      "Epoch 1138/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 18511327309.0737 - val_loss: 26202810910.1007\n",
      "Epoch 1139/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 76us/step - loss: 17693783288.6528 - val_loss: 24743108022.9806\n",
      "Epoch 1140/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 16990031989.5554 - val_loss: 27228004358.6250\n",
      "Epoch 1141/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 16837234269.0647 - val_loss: 26223846952.7584\n",
      "Epoch 1142/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 16995267951.0726 - val_loss: 23353667300.8518\n",
      "Epoch 1143/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 16427300195.5476 - val_loss: 23668113050.5361\n",
      "Epoch 1144/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 16229514430.8835 - val_loss: 28634851558.7241\n",
      "Epoch 1145/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 16756739413.7175 - val_loss: 37157592630.0084\n",
      "Epoch 1146/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 19075923198.7034 - val_loss: 21733376068.8428\n",
      "Epoch 1147/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 14954547506.5661 - val_loss: 22144409918.5778\n",
      "Epoch 1148/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 15148680007.0231 - val_loss: 20580300474.5091\n",
      "Epoch 1149/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 14798206042.7597 - val_loss: 24452674229.0363\n",
      "Epoch 1150/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 14701885736.7698 - val_loss: 21428903490.9705\n",
      "Epoch 1151/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 14020236151.4283 - val_loss: 26010450074.9682\n",
      "Epoch 1152/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 14356496889.3731 - val_loss: 23329957625.3030\n",
      "Epoch 1153/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 14899361735.7074 - val_loss: 23366805254.5530\n",
      "Epoch 1154/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 12992160622.0101 - val_loss: 18769687439.3744\n",
      "Epoch 1155/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 11974337033.5082 - val_loss: 20185059595.3058\n",
      "Epoch 1156/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 12516647661.7040 - val_loss: 20905621703.3271\n",
      "Epoch 1157/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 12078112674.5031 - val_loss: 17515017531.9854\n",
      "Epoch 1158/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 11997120030.8295 - val_loss: 16706723004.9575\n",
      "Epoch 1159/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 11530210682.5976 - val_loss: 28580278934.5035\n",
      "Epoch 1160/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 13295487827.7006 - val_loss: 17516813107.2000\n",
      "Epoch 1161/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 11964224817.9899 - val_loss: 34653834295.0166\n",
      "Epoch 1162/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 12807314478.6764 - val_loss: 15642794306.0343\n",
      "Epoch 1163/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 11436865954.3590 - val_loss: 17798334863.2304\n",
      "Epoch 1164/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 9767996326.9690 - val_loss: 17177989430.2245\n",
      "Epoch 1165/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 10019643984.5312 - val_loss: 14570944683.0987\n",
      "Epoch 1166/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 11611576622.5324 - val_loss: 15570427977.8835\n",
      "Epoch 1167/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 9726472196.6100 - val_loss: 15672830174.9468\n",
      "Epoch 1168/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 9781550640.4052 - val_loss: 14805502941.4346\n",
      "Epoch 1169/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 10253301382.5549 - val_loss: 14161989235.9381\n",
      "Epoch 1170/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 9317383818.3005 - val_loss: 14602501197.4841\n",
      "Epoch 1171/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 10183375580.2724 - val_loss: 16475386236.2194\n",
      "Epoch 1172/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 9269214341.6905 - val_loss: 16201887233.4402\n",
      "Epoch 1173/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 8920041022.5234 - val_loss: 13407042693.9409\n",
      "Epoch 1174/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 9358018980.0878 - val_loss: 14501076296.0833\n",
      "Epoch 1175/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 9056090435.4215 - val_loss: 12932856239.2034\n",
      "Epoch 1176/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 8676522990.1362 - val_loss: 14012183648.4951\n",
      "Epoch 1177/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 8805623546.9578 - val_loss: 18573876491.0177\n",
      "Epoch 1178/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 8387572113.0715 - val_loss: 12742738066.6149\n",
      "Epoch 1179/10000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 8476639693.2898 - val_loss: 12426375265.0712\n",
      "Epoch 1180/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 8320144175.3967 - val_loss: 12699264311.2326\n",
      "Epoch 1181/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 7978910955.6871 - val_loss: 12127934986.8017\n",
      "Epoch 1182/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 8392322381.0737 - val_loss: 11418710577.8318\n",
      "Epoch 1183/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 8004284734.9555 - val_loss: 12470279897.5460\n",
      "Epoch 1184/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 7866197248.1441 - val_loss: 16138043179.2788\n",
      "Epoch 1185/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 7047669627.4440 - val_loss: 11499611938.9255\n",
      "Epoch 1186/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 7990647839.6939 - val_loss: 12281797473.8633\n",
      "Epoch 1187/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 7778285290.9668 - val_loss: 13603177582.6093\n",
      "Epoch 1188/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 7514144921.2831 - val_loss: 13538094431.8470\n",
      "Epoch 1189/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 7175364505.4271 - val_loss: 13013787550.3527\n",
      "Epoch 1190/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 7971633653.6275 - val_loss: 11197401359.3384\n",
      "Epoch 1191/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 7124737853.6590 - val_loss: 15339506359.6287\n",
      "Epoch 1192/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 7062504435.0343 - val_loss: 11824101320.6954\n",
      "Epoch 1193/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 7191420268.7676 - val_loss: 13540178246.6430\n",
      "Epoch 1194/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 7548493608.7698 - val_loss: 12628339398.6070\n",
      "Epoch 1195/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 6755108254.5414 - val_loss: 13846785403.3553\n",
      "Epoch 1196/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 7625894243.1154 - val_loss: 23091656295.4082\n",
      "Epoch 1197/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 7415715075.6736 - val_loss: 9529913899.8188\n",
      "Epoch 1198/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 7174141752.0405 - val_loss: 13773496479.2889\n",
      "Epoch 1199/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 6382317524.8036 - val_loss: 11767854119.3181\n",
      "Epoch 1200/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 6636619381.8436 - val_loss: 19728776990.1727\n",
      "Epoch 1201/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 8723170759.2392 - val_loss: 15099879690.1536\n",
      "Epoch 1202/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 6560407186.0799 - val_loss: 9888967888.2565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1203/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 6523853882.2015 - val_loss: 11792448855.2056\n",
      "Epoch 1204/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 6207593086.4873 - val_loss: 10634117462.4855\n",
      "Epoch 1205/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 6531716483.2009 - val_loss: 9948567850.4146\n",
      "Epoch 1206/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 6037057447.2572 - val_loss: 14559187539.1010\n",
      "Epoch 1207/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 7260687433.4721 - val_loss: 10038450148.7797\n",
      "Epoch 1208/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 7570383982.3523 - val_loss: 9475993625.9241\n",
      "Epoch 1209/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 5939289527.1311 - val_loss: 10217445751.2506\n",
      "Epoch 1210/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 5486023279.5768 - val_loss: 15051235261.5336\n",
      "Epoch 1211/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 5954455581.9651 - val_loss: 8726235986.3089\n",
      "Epoch 1212/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 5973371436.3714 - val_loss: 8799762729.0104\n",
      "Epoch 1213/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 5764694811.2279 - val_loss: 16840272785.1027\n",
      "Epoch 1214/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 6195213402.4716 - val_loss: 8965286768.9136\n",
      "Epoch 1215/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 6112645895.9235 - val_loss: 8973284728.3308\n",
      "Epoch 1216/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 6007462970.5616 - val_loss: 11982555181.4391\n",
      "Epoch 1217/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 6149927738.8497 - val_loss: 8243907381.7924\n",
      "Epoch 1218/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 5146236025.3011 - val_loss: 10458493861.8419\n",
      "Epoch 1219/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 5274550911.0636 - val_loss: 9179984124.2554\n",
      "Epoch 1220/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 5709153179.1559 - val_loss: 10409355169.8813\n",
      "Epoch 1221/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 6379035378.8903 - val_loss: 11134270989.6821\n",
      "Epoch 1222/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 6014917745.5217 - val_loss: 9130887583.7210\n",
      "Epoch 1223/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 5904105459.6871 - val_loss: 8388187368.9564\n",
      "Epoch 1224/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 5636917268.7451 - val_loss: 8844986545.7958\n",
      "Epoch 1225/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 5379180977.1975 - val_loss: 8923936222.2987\n",
      "Epoch 1226/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 5427604061.0647 - val_loss: 9075832863.3969\n",
      "Epoch 1227/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 5671974875.9842 - val_loss: 9459913741.8262\n",
      "Epoch 1228/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 5479363186.0979 - val_loss: 9889086377.8745\n",
      "Epoch 1229/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 5935995070.5594 - val_loss: 9391133319.2371\n",
      "Epoch 1230/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 5680861944.6528 - val_loss: 10406907058.0118\n",
      "Epoch 1231/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 6130795706.1294 - val_loss: 11314544612.9238\n",
      "Epoch 1232/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 4754677330.1159 - val_loss: 8029146524.9125\n",
      "Epoch 1233/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 5375974640.2971 - val_loss: 8502721256.1643\n",
      "Epoch 1234/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 5499738818.1970 - val_loss: 8708318673.7688\n",
      "Epoch 1235/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 5163307907.0433 - val_loss: 11461929723.6793\n",
      "Epoch 1236/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 5462055981.9561 - val_loss: 7460510441.9646\n",
      "Epoch 1237/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 4913976439.2842 - val_loss: 7456013951.2439\n",
      "Epoch 1238/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 4622940066.2150 - val_loss: 7310492153.3750\n",
      "Epoch 1239/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 4914019102.9736 - val_loss: 9279247305.4155\n",
      "Epoch 1240/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 5003417236.3849 - val_loss: 8934684163.8166\n",
      "Epoch 1241/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 5152406733.5059 - val_loss: 11183352806.3640\n",
      "Epoch 1242/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 5192534399.7119 - val_loss: 7494503100.8855\n",
      "Epoch 1243/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 5545807280.1891 - val_loss: 7573396654.8433\n",
      "Epoch 1244/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 5511709685.0512 - val_loss: 11893301415.2101\n",
      "Epoch 1245/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 5313090301.9831 - val_loss: 7056877741.7632\n",
      "Epoch 1246/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 5669875030.8700 - val_loss: 7752748466.3719\n",
      "Epoch 1247/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 4929977422.3703 - val_loss: 9991539221.6034\n",
      "Epoch 1248/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 4707097265.9088 - val_loss: 6998288575.4779\n",
      "Epoch 1249/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 4607142053.6725 - val_loss: 7968896871.3361\n",
      "Epoch 1250/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 4759531127.5003 - val_loss: 6816654153.2714\n",
      "Epoch 1251/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 5005313904.5132 - val_loss: 13176627793.3007\n",
      "Epoch 1252/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 5904221493.1593 - val_loss: 7235569823.5049\n",
      "Epoch 1253/10000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 4326596243.8087 - val_loss: 9043193729.6203\n",
      "Epoch 1254/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 4310443511.6443 - val_loss: 11523030374.3280\n",
      "Epoch 1255/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 5442868222.1272 - val_loss: 6537503011.5736\n",
      "Epoch 1256/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 4476326571.6061 - val_loss: 6597307277.8622\n",
      "Epoch 1257/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 4253422260.9792 - val_loss: 10109134971.4273\n",
      "Epoch 1258/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 5279442313.5802 - val_loss: 6568862002.5519\n",
      "Epoch 1259/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 4812510344.7878 - val_loss: 8399732797.0655\n",
      "Epoch 1260/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 4737425129.0940 - val_loss: 8337861698.2504\n",
      "Epoch 1261/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 4219376254.7980 - val_loss: 16575569755.9584\n",
      "Epoch 1262/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 4773720716.8936 - val_loss: 6911999937.2782\n",
      "Epoch 1263/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 4421440510.8385 - val_loss: 6999683156.3252\n",
      "Epoch 1264/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 4800095504.5672 - val_loss: 14441768387.9426\n",
      "Epoch 1265/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 5794585776.6213 - val_loss: 8706576509.8757\n",
      "Epoch 1266/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 4342852363.0929 - val_loss: 7159328565.7564\n",
      "Epoch 1267/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4393763755.2909 - val_loss: 8165569776.0135\n",
      "Epoch 1268/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 4516385743.5948 - val_loss: 8017577806.8523\n",
      "Epoch 1269/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 4136396162.5931 - val_loss: 7192347767.3947\n",
      "Epoch 1270/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 5167673432.1666 - val_loss: 10635516526.6093\n",
      "Epoch 1271/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 4506929428.1688 - val_loss: 13227335340.8990\n",
      "Epoch 1272/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 4928535726.1722 - val_loss: 8330932863.2799\n",
      "Epoch 1273/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 4523990651.8942 - val_loss: 11958292716.4850\n",
      "Epoch 1274/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 4473771885.4879 - val_loss: 8115917601.2692\n",
      "Epoch 1275/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 4457860554.3050 - val_loss: 9259501062.5530\n",
      "Epoch 1276/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 4669412335.2887 - val_loss: 16192146136.8979\n",
      "Epoch 1277/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 5280431193.1750 - val_loss: 6914848129.6203\n",
      "Epoch 1278/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 4232233014.5999 - val_loss: 6506472704.0720\n",
      "Epoch 1279/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 4250585222.2667 - val_loss: 16592371797.8374\n",
      "Epoch 1280/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 5115367855.0366 - val_loss: 6311576067.8886\n",
      "Epoch 1281/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 4840894030.6584 - val_loss: 7690910573.2411\n",
      "Epoch 1282/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 4174199424.1441 - val_loss: 7267839406.8433\n",
      "Epoch 1283/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 3961653929.3821 - val_loss: 7695540491.1617\n",
      "Epoch 1284/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 3689770183.0951 - val_loss: 9169865039.7165\n",
      "Epoch 1285/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 4128211294.3973 - val_loss: 10083712147.2630\n",
      "Epoch 1286/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 4721803267.6016 - val_loss: 6223723612.4264\n",
      "Epoch 1287/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 3956281320.0855 - val_loss: 6543809418.1896\n",
      "Epoch 1288/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 3803840524.2814 - val_loss: 9218482414.5013\n",
      "Epoch 1289/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 4237036196.5200 - val_loss: 6868812694.7916\n",
      "Epoch 1290/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 4263332764.5965 - val_loss: 7483514713.7980\n",
      "Epoch 1291/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 5091862636.9116 - val_loss: 11152987449.6810\n",
      "Epoch 1292/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 5159096582.9871 - val_loss: 11645252578.6194\n",
      "Epoch 1293/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 4720438345.7603 - val_loss: 6116877026.4754\n",
      "Epoch 1294/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 4048076818.2960 - val_loss: 5970484012.3589\n",
      "Epoch 1295/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 3700789303.6804 - val_loss: 6884974274.4304\n",
      "Epoch 1296/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 4129112054.2037 - val_loss: 8190263182.5823\n",
      "Epoch 1297/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 4520104423.2212 - val_loss: 7900471574.1075\n",
      "Epoch 1298/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 4626608249.0129 - val_loss: 8340463670.4405\n",
      "Epoch 1299/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 4930851091.3044 - val_loss: 6405291555.4295\n",
      "Epoch 1300/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 4572833699.5115 - val_loss: 6364458512.2745\n",
      "Epoch 1301/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3643885791.4057 - val_loss: 6426561464.5648\n",
      "Epoch 1302/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 3554462967.8604 - val_loss: 9269677279.9550\n",
      "Epoch 1303/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 4914783437.1097 - val_loss: 7018425937.0847\n",
      "Epoch 1304/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 3791834121.9403 - val_loss: 6386849937.1027\n",
      "Epoch 1305/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 4364102733.2178 - val_loss: 8360079094.1345\n",
      "Epoch 1306/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 3681661501.1548 - val_loss: 5877506821.0408\n",
      "Epoch 1307/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 3790023240.1035 - val_loss: 8182177850.4731\n",
      "Epoch 1308/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 3734164766.7034 - val_loss: 6852696232.2183\n",
      "Epoch 1309/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 3830420591.4688 - val_loss: 9595439230.4518\n",
      "Epoch 1310/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 3678075313.3416 - val_loss: 5709476518.2740\n",
      "Epoch 1311/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3800336235.9032 - val_loss: 7022060006.7961\n",
      "Epoch 1312/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 4132500730.5976 - val_loss: 10841489882.9862\n",
      "Epoch 1313/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 5152886454.3838 - val_loss: 6246373378.7364\n",
      "Epoch 1314/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 4165051432.0495 - val_loss: 19764499176.3083\n",
      "Epoch 1315/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 4429331987.3044 - val_loss: 6245174911.7480\n",
      "Epoch 1316/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3514375343.7569 - val_loss: 5895777393.0577\n",
      "Epoch 1317/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 4078636317.9651 - val_loss: 5579550740.8113\n",
      "Epoch 1318/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3562110450.5481 - val_loss: 6163610885.1848\n",
      "Epoch 1319/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 3429776507.0298 - val_loss: 5790226923.0447\n",
      "Epoch 1320/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3825136004.1058 - val_loss: 7125285590.5935\n",
      "Epoch 1321/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3951877852.9927 - val_loss: 7843112222.0287\n",
      "Epoch 1322/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 4300082306.8813 - val_loss: 6940447543.3046\n",
      "Epoch 1323/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 4524925138.3230 - val_loss: 6225499381.3423\n",
      "Epoch 1324/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 3408164979.3945 - val_loss: 7388577880.8619\n",
      "Epoch 1325/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3517681862.0146 - val_loss: 5351076612.4647\n",
      "Epoch 1326/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 3412391729.4496 - val_loss: 5899481607.3091\n",
      "Epoch 1327/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 3761672106.0664 - val_loss: 5965959999.8020\n",
      "Epoch 1328/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 3403122475.2369 - val_loss: 6409201518.2492\n",
      "Epoch 1329/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 3867620667.2099 - val_loss: 7800475035.6163\n",
      "Epoch 1330/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 4011900129.4586 - val_loss: 9893074327.0076\n",
      "Epoch 1331/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 83us/step - loss: 3919747475.6646 - val_loss: 6214316974.0512\n",
      "Epoch 1332/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 3799738911.1176 - val_loss: 13123794084.9058\n",
      "Epoch 1333/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 4338363379.2504 - val_loss: 7051217631.5949\n",
      "Epoch 1334/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3811205584.4592 - val_loss: 5237973466.1941\n",
      "Epoch 1335/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 3880515118.1002 - val_loss: 8427109586.2729\n",
      "Epoch 1336/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 3338764057.6252 - val_loss: 5752193527.7907\n",
      "Epoch 1337/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 3364237351.6894 - val_loss: 5824177591.7367\n",
      "Epoch 1338/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 3236136061.0467 - val_loss: 6852799463.3361\n",
      "Epoch 1339/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 4704834043.8222 - val_loss: 6921066203.0582\n",
      "Epoch 1340/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3367563217.4316 - val_loss: 5439028715.0447\n",
      "Epoch 1341/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3009973164.0113 - val_loss: 6597256994.9255\n",
      "Epoch 1342/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3752304693.4474 - val_loss: 5442213851.4903\n",
      "Epoch 1343/10000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 3630686066.9623 - val_loss: 11904219212.0439\n",
      "Epoch 1344/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 3493560771.8537 - val_loss: 5417796058.5541\n",
      "Epoch 1345/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 3449970765.2178 - val_loss: 7460693115.1392\n",
      "Epoch 1346/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 4292264569.8773 - val_loss: 5399720125.3176\n",
      "Epoch 1347/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 4341568802.3410 - val_loss: 7479112554.3606\n",
      "Epoch 1348/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 3571594320.6033 - val_loss: 7695317543.3181\n",
      "Epoch 1349/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3931121787.1739 - val_loss: 7858217298.4529\n",
      "Epoch 1350/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 3794020241.3596 - val_loss: 5393097044.3252\n",
      "Epoch 1351/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 3429385117.1728 - val_loss: 9127695804.7415\n",
      "Epoch 1352/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 4031100529.7051 - val_loss: 5368960583.6512\n",
      "Epoch 1353/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 3277990080.2881 - val_loss: 5191776022.1795\n",
      "Epoch 1354/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 3278294231.1581 - val_loss: 11938140652.8450\n",
      "Epoch 1355/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 4450769596.1463 - val_loss: 8526435435.2968\n",
      "Epoch 1356/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 3638057244.6685 - val_loss: 6511944442.3831\n",
      "Epoch 1357/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 4288327396.6280 - val_loss: 5702747211.5398\n",
      "Epoch 1358/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3142817289.5082 - val_loss: 5735011111.3181\n",
      "Epoch 1359/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 3329906747.4890 - val_loss: 5205178404.8698\n",
      "Epoch 1360/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 3677349989.9606 - val_loss: 5672321706.0186\n",
      "Epoch 1361/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2887504201.0400 - val_loss: 15847853016.2498\n",
      "Epoch 1362/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4247273770.2105 - val_loss: 13816019684.1316\n",
      "Epoch 1363/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 4178474187.4530 - val_loss: 5407406056.9564\n",
      "Epoch 1364/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 3002074278.9690 - val_loss: 6076032317.9297\n",
      "Epoch 1365/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 3340928357.8526 - val_loss: 13114100539.2653\n",
      "Epoch 1366/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 3365040254.7034 - val_loss: 6113521888.1710\n",
      "Epoch 1367/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 3567780558.0101 - val_loss: 12391735041.9443\n",
      "Epoch 1368/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 3705627749.2223 - val_loss: 5385085853.7046\n",
      "Epoch 1369/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 3225911165.3709 - val_loss: 7235896230.4180\n",
      "Epoch 1370/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 3120470584.3286 - val_loss: 6259435763.8661\n",
      "Epoch 1371/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 3854347771.9662 - val_loss: 7324738938.4191\n",
      "Epoch 1372/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 4159591711.4057 - val_loss: 5809691629.7091\n",
      "Epoch 1373/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 3661474397.6230 - val_loss: 5079131647.2799\n",
      "Epoch 1374/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 3301157660.3804 - val_loss: 7886770697.0734\n",
      "Epoch 1375/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 3779791303.9595 - val_loss: 6660236107.3958\n",
      "Epoch 1376/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2813876049.6117 - val_loss: 4790985740.4579\n",
      "Epoch 1377/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 3254406494.3613 - val_loss: 6979331557.2838\n",
      "Epoch 1378/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 4064284143.5768 - val_loss: 8106254555.9224\n",
      "Epoch 1379/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 3451473794.4491 - val_loss: 5109165792.4591\n",
      "Epoch 1380/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3421519540.0788 - val_loss: 5124117729.9713\n",
      "Epoch 1381/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 3365266820.6820 - val_loss: 5156275575.7547\n",
      "Epoch 1382/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3248526981.1142 - val_loss: 5972807487.0098\n",
      "Epoch 1383/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 3623587930.3275 - val_loss: 5509250316.6020\n",
      "Epoch 1384/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2901144053.2673 - val_loss: 6635516415.2079\n",
      "Epoch 1385/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3679137340.2183 - val_loss: 5933514924.6830\n",
      "Epoch 1386/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 3812015703.8784 - val_loss: 10243729946.9322\n",
      "Epoch 1387/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 4197464852.3129 - val_loss: 12184394834.0928\n",
      "Epoch 1388/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 3753967378.5841 - val_loss: 5788840315.4993\n",
      "Epoch 1389/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 3256052409.5532 - val_loss: 5763204884.3792\n",
      "Epoch 1390/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3012759342.7124 - val_loss: 6498926254.2672\n",
      "Epoch 1391/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 3852389749.5554 - val_loss: 6165808748.1249\n",
      "Epoch 1392/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3066173720.0585 - val_loss: 11917447785.6405\n",
      "Epoch 1393/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 3579312900.1958 - val_loss: 4696887467.9629\n",
      "Epoch 1394/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2980892772.4479 - val_loss: 4816709536.2970\n",
      "Epoch 1395/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2860279216.9094 - val_loss: 5065354710.2335\n",
      "Epoch 1396/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2614394663.6894 - val_loss: 8582031739.6433\n",
      "Epoch 1397/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3221696141.7940 - val_loss: 5472040392.6954\n",
      "Epoch 1398/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3111641361.7918 - val_loss: 10186221307.0312\n",
      "Epoch 1399/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 3668638342.5549 - val_loss: 8921757642.9277\n",
      "Epoch 1400/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3730784657.0715 - val_loss: 6671227048.5063\n",
      "Epoch 1401/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 3418703672.1216 - val_loss: 6715401351.2371\n",
      "Epoch 1402/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 3068339788.4434 - val_loss: 5474732795.5353\n",
      "Epoch 1403/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2902566823.8334 - val_loss: 5095221054.6498\n",
      "Epoch 1404/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 4382705297.5037 - val_loss: 5368008068.8608\n",
      "Epoch 1405/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2625370908.3804 - val_loss: 8744460677.9409\n",
      "Epoch 1406/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 3277207033.1570 - val_loss: 7385734889.1724\n",
      "Epoch 1407/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 3430762386.8002 - val_loss: 6292105447.8762\n",
      "Epoch 1408/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 3205045207.0861 - val_loss: 5352889776.2835\n",
      "Epoch 1409/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2878327004.9927 - val_loss: 6063676507.9584\n",
      "Epoch 1410/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 2730292238.4063 - val_loss: 5295335555.9966\n",
      "Epoch 1411/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 3290590665.9403 - val_loss: 5124771711.4599\n",
      "Epoch 1412/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2964499348.3849 - val_loss: 8696840655.6084\n",
      "Epoch 1413/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 3557905114.4806 - val_loss: 4653959440.4906\n",
      "Epoch 1414/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2855364408.9049 - val_loss: 5176390172.4804\n",
      "Epoch 1415/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2740370453.1773 - val_loss: 4949160917.8014\n",
      "Epoch 1416/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2635243944.4097 - val_loss: 5883615199.0188\n",
      "Epoch 1417/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3371915062.3118 - val_loss: 5860547978.5496\n",
      "Epoch 1418/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 3573230343.2752 - val_loss: 4496335630.1142\n",
      "Epoch 1419/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 3350474537.7783 - val_loss: 5477524744.9294\n",
      "Epoch 1420/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3119434055.3112 - val_loss: 5720017552.8866\n",
      "Epoch 1421/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3571088682.1024 - val_loss: 10966778633.5775\n",
      "Epoch 1422/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2950821203.7006 - val_loss: 8191932503.4217\n",
      "Epoch 1423/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 3172449047.7704 - val_loss: 8934489733.2928\n",
      "Epoch 1424/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 3435757229.4519 - val_loss: 5512839868.7415\n",
      "Epoch 1425/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 2980677688.1846 - val_loss: 8387033049.2579\n",
      "Epoch 1426/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 3044988680.3557 - val_loss: 6601791971.4835\n",
      "Epoch 1427/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2774073163.7772 - val_loss: 7208326817.0892\n",
      "Epoch 1428/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 3272814862.7665 - val_loss: 8244550258.2098\n",
      "Epoch 1429/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 3025979795.6646 - val_loss: 5632216271.4644\n",
      "Epoch 1430/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 3431448566.5999 - val_loss: 5348717491.5961\n",
      "Epoch 1431/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 3553415049.4361 - val_loss: 6810111855.4014\n",
      "Epoch 1432/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 2741259336.6078 - val_loss: 4626883671.2056\n",
      "Epoch 1433/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 3025646949.0602 - val_loss: 4612727663.9775\n",
      "Epoch 1434/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2762222811.9842 - val_loss: 5916690412.4850\n",
      "Epoch 1435/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 3141061946.9218 - val_loss: 6885199847.6242\n",
      "Epoch 1436/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 4344664108.0833 - val_loss: 5418412168.5333\n",
      "Epoch 1437/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2827412715.1109 - val_loss: 6517455097.7350\n",
      "Epoch 1438/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 3100923215.0771 - val_loss: 7033203802.8782\n",
      "Epoch 1439/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2748446453.5734 - val_loss: 11862921874.1828\n",
      "Epoch 1440/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 3437936157.0287 - val_loss: 4787286205.4616\n",
      "Epoch 1441/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2676232458.5166 - val_loss: 5208717498.7252\n",
      "Epoch 1442/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2788077879.1761 - val_loss: 6350124104.3353\n",
      "Epoch 1443/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 3834374922.8768 - val_loss: 4573051449.7890\n",
      "Epoch 1444/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 2332298350.6764 - val_loss: 4459103825.4447\n",
      "Epoch 1445/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2533732386.8272 - val_loss: 4808980629.7114\n",
      "Epoch 1446/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2615206514.9623 - val_loss: 8163778150.4000\n",
      "Epoch 1447/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2803111101.2988 - val_loss: 5955064505.4290\n",
      "Epoch 1448/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 2882002948.6640 - val_loss: 5677518834.2459\n",
      "Epoch 1449/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 3076382375.7614 - val_loss: 7424406249.4605\n",
      "Epoch 1450/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 2923015902.3613 - val_loss: 5384027530.7657\n",
      "Epoch 1451/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2675520799.5498 - val_loss: 4586434528.8911\n",
      "Epoch 1452/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 2840698339.6196 - val_loss: 9233521542.8051\n",
      "Epoch 1453/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2871593264.4052 - val_loss: 4514489762.4934\n",
      "Epoch 1454/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2593499729.6837 - val_loss: 5350964909.9792\n",
      "Epoch 1455/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2891659004.3984 - val_loss: 6436945587.0200\n",
      "Epoch 1456/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 3280802024.3016 - val_loss: 4552316225.1702\n",
      "Epoch 1457/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2483404625.1075 - val_loss: 4812316336.4996\n",
      "Epoch 1458/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 3375009420.5335 - val_loss: 7851174681.7080\n",
      "Epoch 1459/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 83us/step - loss: 3234356015.6398 - val_loss: 4998113467.5173\n",
      "Epoch 1460/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2326360442.8858 - val_loss: 4385952782.9783\n",
      "Epoch 1461/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2538922006.7620 - val_loss: 5179915029.0993\n",
      "Epoch 1462/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2770115251.6466 - val_loss: 8508676208.6256\n",
      "Epoch 1463/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 3186306551.4283 - val_loss: 8302880755.5421\n",
      "Epoch 1464/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2757795875.4395 - val_loss: 13023327644.7685\n",
      "Epoch 1465/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 3545338725.1322 - val_loss: 4478611364.3657\n",
      "Epoch 1466/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2808535929.4451 - val_loss: 5643139703.9707\n",
      "Epoch 1467/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2588893904.0990 - val_loss: 5192358437.8059\n",
      "Epoch 1468/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2554884251.1559 - val_loss: 6344423031.3947\n",
      "Epoch 1469/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 3504881141.4654 - val_loss: 5547823855.1494\n",
      "Epoch 1470/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2672429857.9989 - val_loss: 6907086778.0051\n",
      "Epoch 1471/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2759416912.0990 - val_loss: 5106268109.3401\n",
      "Epoch 1472/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2370815481.3011 - val_loss: 4383059346.7589\n",
      "Epoch 1473/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2692362785.4947 - val_loss: 4659835653.6169\n",
      "Epoch 1474/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2399331918.2262 - val_loss: 4588467077.6529\n",
      "Epoch 1475/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2330093082.6877 - val_loss: 4630144098.0793\n",
      "Epoch 1476/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 2594687903.1176 - val_loss: 5222179499.0267\n",
      "Epoch 1477/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2855343037.3709 - val_loss: 4614327962.7522\n",
      "Epoch 1478/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 2927100912.6213 - val_loss: 7588816623.7615\n",
      "Epoch 1479/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 3010057228.2093 - val_loss: 5864200361.5865\n",
      "Epoch 1480/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2985525095.2212 - val_loss: 8465445482.8647\n",
      "Epoch 1481/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2816371788.9297 - val_loss: 5288573128.1913\n",
      "Epoch 1482/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2465493398.3545 - val_loss: 4453453680.2295\n",
      "Epoch 1483/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2842742942.0011 - val_loss: 5133360607.9550\n",
      "Epoch 1484/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 2474164503.9145 - val_loss: 4786679795.1460\n",
      "Epoch 1485/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 2518601300.8531 - val_loss: 4512597537.3772\n",
      "Epoch 1486/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 3015658268.8846 - val_loss: 5245140056.2858\n",
      "Epoch 1487/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2564919116.9297 - val_loss: 4804143222.4585\n",
      "Epoch 1488/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2534059692.8756 - val_loss: 4651732740.2847\n",
      "Epoch 1489/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2502466851.5836 - val_loss: 9718485529.7800\n",
      "Epoch 1490/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 4120847269.5284 - val_loss: 11759548841.7305\n",
      "Epoch 1491/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2912613899.2369 - val_loss: 11647182428.0304\n",
      "Epoch 1492/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3190380124.6325 - val_loss: 5313211371.7648\n",
      "Epoch 1493/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 2341277796.3039 - val_loss: 4701870886.0219\n",
      "Epoch 1494/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2348723288.6708 - val_loss: 7399134778.4011\n",
      "Epoch 1495/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2617917038.5684 - val_loss: 5478710933.0993\n",
      "Epoch 1496/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 3204771200.7923 - val_loss: 7468714529.5572\n",
      "Epoch 1497/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 2347674471.6173 - val_loss: 4227804804.3567\n",
      "Epoch 1498/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2291804561.0715 - val_loss: 5038593175.6557\n",
      "Epoch 1499/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2596889205.8165 - val_loss: 4525456510.2357\n",
      "Epoch 1500/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2402385746.9803 - val_loss: 8825422502.4180\n",
      "Epoch 1501/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2441279087.2167 - val_loss: 6361164126.4788\n",
      "Epoch 1502/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2875949283.7456 - val_loss: 4082626832.5266\n",
      "Epoch 1503/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2266292558.6584 - val_loss: 5159872806.7961\n",
      "Epoch 1504/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2512950023.3472 - val_loss: 5865966067.3260\n",
      "Epoch 1505/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2717379104.8464 - val_loss: 6154702716.9395\n",
      "Epoch 1506/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2724541855.6939 - val_loss: 4136534879.1989\n",
      "Epoch 1507/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2314577538.3410 - val_loss: 4580401753.1859\n",
      "Epoch 1508/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2270709033.9223 - val_loss: 12652743793.0577\n",
      "Epoch 1509/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2826311637.3213 - val_loss: 4423518163.4250\n",
      "Epoch 1510/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2419775516.9387 - val_loss: 5052729003.2068\n",
      "Epoch 1511/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 3150161452.6595 - val_loss: 4695925591.7817\n",
      "Epoch 1512/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2807702193.9178 - val_loss: 4596239343.0774\n",
      "Epoch 1513/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 2236969635.1514 - val_loss: 4173295134.3887\n",
      "Epoch 1514/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2724255052.8576 - val_loss: 5039827362.8895\n",
      "Epoch 1515/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2710319177.1840 - val_loss: 7903847327.5049\n",
      "Epoch 1516/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 3519648977.3236 - val_loss: 4665569794.3764\n",
      "Epoch 1517/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2375949012.6370 - val_loss: 6069492202.1086\n",
      "Epoch 1518/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2394121494.3298 - val_loss: 4349999487.6399\n",
      "Epoch 1519/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2969070753.3506 - val_loss: 4592056584.3533\n",
      "Epoch 1520/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 3479960741.3844 - val_loss: 4258243541.6574\n",
      "Epoch 1521/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2777850576.7833 - val_loss: 4895302577.6518\n",
      "Epoch 1522/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2310296244.1868 - val_loss: 4251555327.2079\n",
      "Epoch 1523/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2045160043.6151 - val_loss: 5014696495.8155\n",
      "Epoch 1524/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2218183823.4508 - val_loss: 4351597428.7302\n",
      "Epoch 1525/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2061912716.3894 - val_loss: 5332367479.3226\n",
      "Epoch 1526/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 2548155719.8875 - val_loss: 5726445434.3111\n",
      "Epoch 1527/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2824166924.5335 - val_loss: 4710382715.7153\n",
      "Epoch 1528/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 2444909886.6674 - val_loss: 12145420079.2394\n",
      "Epoch 1529/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 3561247884.2454 - val_loss: 5080599482.6172\n",
      "Epoch 1530/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2369483789.0242 - val_loss: 11733730797.4211\n",
      "Epoch 1531/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2813072759.6443 - val_loss: 5305076301.9162\n",
      "Epoch 1532/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 2611282723.2594 - val_loss: 5039526937.8880\n",
      "Epoch 1533/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2313313875.2684 - val_loss: 6717084673.4402\n",
      "Epoch 1534/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2392697443.9797 - val_loss: 26702301974.9716\n",
      "Epoch 1535/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 4915292651.7591 - val_loss: 5174964553.9376\n",
      "Epoch 1536/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2330983947.3089 - val_loss: 4408617684.6852\n",
      "Epoch 1537/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2555806055.6533 - val_loss: 5298952292.7437\n",
      "Epoch 1538/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2436199577.1390 - val_loss: 5995397944.9249\n",
      "Epoch 1539/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2577049289.9764 - val_loss: 4202195937.3952\n",
      "Epoch 1540/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2427000179.6826 - val_loss: 6440329534.1457\n",
      "Epoch 1541/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2561656473.4271 - val_loss: 4100088900.3027\n",
      "Epoch 1542/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2058402482.2780 - val_loss: 9789992181.7024\n",
      "Epoch 1543/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 2180715679.8379 - val_loss: 4223207069.2366\n",
      "Epoch 1544/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 2376267725.5059 - val_loss: 3916895878.3730\n",
      "Epoch 1545/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2051922939.3900 - val_loss: 4173914380.0619\n",
      "Epoch 1546/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2331487975.5093 - val_loss: 4184679939.5286\n",
      "Epoch 1547/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2436357530.6517 - val_loss: 7841170595.8256\n",
      "Epoch 1548/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 2806126651.9302 - val_loss: 5581488913.1387\n",
      "Epoch 1549/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 3084371085.1818 - val_loss: 5463849368.7359\n",
      "Epoch 1550/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2217611506.8903 - val_loss: 4380825882.3561\n",
      "Epoch 1551/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2342811251.8267 - val_loss: 4958786047.8920\n",
      "Epoch 1552/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2491006946.8272 - val_loss: 5830399600.2655\n",
      "Epoch 1553/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2651288368.8374 - val_loss: 15762755264.5581\n",
      "Epoch 1554/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2617179438.0642 - val_loss: 3932706736.2475\n",
      "Epoch 1555/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2083576166.4288 - val_loss: 11735003082.9997\n",
      "Epoch 1556/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2726501468.5605 - val_loss: 4434952161.1792\n",
      "Epoch 1557/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2688607647.4778 - val_loss: 4105498188.1159\n",
      "Epoch 1558/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2280969830.1047 - val_loss: 6482428918.3505\n",
      "Epoch 1559/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2167777977.8413 - val_loss: 4544993333.5044\n",
      "Epoch 1560/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2584461828.4660 - val_loss: 4212469232.1575\n",
      "Epoch 1561/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2362517458.5481 - val_loss: 7105036360.9474\n",
      "Epoch 1562/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2644009463.2212 - val_loss: 6378705294.5103\n",
      "Epoch 1563/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 2134172208.9814 - val_loss: 8542220273.4537\n",
      "Epoch 1564/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2639830781.1548 - val_loss: 4538249844.9103\n",
      "Epoch 1565/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2044835918.1542 - val_loss: 4993390748.1204\n",
      "Epoch 1566/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 3338666465.2425 - val_loss: 9017241153.1702\n",
      "Epoch 1567/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2365883619.8357 - val_loss: 4072936224.1530\n",
      "Epoch 1568/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 2071087034.7057 - val_loss: 5119907950.9693\n",
      "Epoch 1569/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 3197961612.4615 - val_loss: 5779318127.6174\n",
      "Epoch 1570/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 3424508780.3354 - val_loss: 4136639681.1342\n",
      "Epoch 1571/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2188680393.1120 - val_loss: 8528598395.0672\n",
      "Epoch 1572/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 3597671082.4266 - val_loss: 3848468567.9257\n",
      "Epoch 1573/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2191873166.6224 - val_loss: 4398985375.3969\n",
      "Epoch 1574/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2157999361.7828 - val_loss: 4331344932.5097\n",
      "Epoch 1575/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2237239842.2870 - val_loss: 6404716076.6470\n",
      "Epoch 1576/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2658341172.1508 - val_loss: 7216287993.3030\n",
      "Epoch 1577/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 2681859391.0636 - val_loss: 3668515315.3620\n",
      "Epoch 1578/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1934058692.0698 - val_loss: 5405113571.2675\n",
      "Epoch 1579/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2765082221.1998 - val_loss: 4047628015.8335\n",
      "Epoch 1580/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2113817478.5549 - val_loss: 6999657571.3755\n",
      "Epoch 1581/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 2233983765.2673 - val_loss: 3813384128.0540\n",
      "Epoch 1582/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2317077682.9083 - val_loss: 4437766536.7134\n",
      "Epoch 1583/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 2372057779.0703 - val_loss: 4491791756.0619\n",
      "Epoch 1584/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 2002454880.7383 - val_loss: 5272733495.4487\n",
      "Epoch 1585/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 2037276589.4519 - val_loss: 4965548811.8819\n",
      "Epoch 1586/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 2662010173.6590 - val_loss: 7175400046.4653\n",
      "Epoch 1587/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 82us/step - loss: 2417901763.3495 - val_loss: 4084178652.1744\n",
      "Epoch 1588/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1982854989.0017 - val_loss: 4987341235.5241\n",
      "Epoch 1589/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2073525821.3528 - val_loss: 7527180320.8371\n",
      "Epoch 1590/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 3110192241.4136 - val_loss: 5177728629.5224\n",
      "Epoch 1591/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2323304816.6573 - val_loss: 4803607050.1896\n",
      "Epoch 1592/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2583821690.2015 - val_loss: 5495178431.5499\n",
      "Epoch 1593/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1866072411.3360 - val_loss: 5469634278.2920\n",
      "Epoch 1594/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2381297574.8070 - val_loss: 4021784628.6042\n",
      "Epoch 1595/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1959201878.4378 - val_loss: 7928139492.3477\n",
      "Epoch 1596/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 2569234103.7614 - val_loss: 4362955403.3058\n",
      "Epoch 1597/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2205071331.8897 - val_loss: 6832287477.2703\n",
      "Epoch 1598/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2107964222.6674 - val_loss: 7064238346.4416\n",
      "Epoch 1599/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2428067749.3844 - val_loss: 4691582533.5809\n",
      "Epoch 1600/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2945733140.4570 - val_loss: 5580619209.1274\n",
      "Epoch 1601/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2393304539.4080 - val_loss: 8670610399.1629\n",
      "Epoch 1602/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2061307343.2707 - val_loss: 4705003524.1406\n",
      "Epoch 1603/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2538674575.9190 - val_loss: 6252836660.2082\n",
      "Epoch 1604/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 2807977176.5988 - val_loss: 3908147062.3325\n",
      "Epoch 1605/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2153794344.4592 - val_loss: 4791455148.1069\n",
      "Epoch 1606/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2122178315.2369 - val_loss: 6985159323.2563\n",
      "Epoch 1607/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1993573398.7259 - val_loss: 3632415608.0428\n",
      "Epoch 1608/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 2096064769.5847 - val_loss: 3925588106.5677\n",
      "Epoch 1609/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2663327365.5959 - val_loss: 7610404783.2034\n",
      "Epoch 1610/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2675444222.1992 - val_loss: 4346725816.9969\n",
      "Epoch 1611/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2599519617.0805 - val_loss: 5450815827.3530\n",
      "Epoch 1612/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1790577242.8497 - val_loss: 5162580116.6312\n",
      "Epoch 1613/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1887739842.9173 - val_loss: 4921404331.3148\n",
      "Epoch 1614/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1935580462.7485 - val_loss: 3906977904.3736\n",
      "Epoch 1615/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1862767700.9972 - val_loss: 4114412493.5201\n",
      "Epoch 1616/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2173177725.5509 - val_loss: 4102244710.9401\n",
      "Epoch 1617/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2142730021.6005 - val_loss: 6175305435.7783\n",
      "Epoch 1618/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2371508526.1002 - val_loss: 4771001881.4200\n",
      "Epoch 1619/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2260160725.5014 - val_loss: 7392633332.5502\n",
      "Epoch 1620/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 2807961766.3208 - val_loss: 3910273288.2453\n",
      "Epoch 1621/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2479320338.7282 - val_loss: 3838097453.0070\n",
      "Epoch 1622/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2608871008.7923 - val_loss: 3923614112.4051\n",
      "Epoch 1623/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1898120890.7237 - val_loss: 3688121415.6512\n",
      "Epoch 1624/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2211416325.8706 - val_loss: 4073237328.2205\n",
      "Epoch 1625/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2293942578.7102 - val_loss: 4070423559.0571\n",
      "Epoch 1626/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2006366780.1823 - val_loss: 4423236942.8523\n",
      "Epoch 1627/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1917056522.3095 - val_loss: 4095398874.1581\n",
      "Epoch 1628/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2007819970.3410 - val_loss: 3646119501.9882\n",
      "Epoch 1629/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2317419712.5402 - val_loss: 4063756842.0546\n",
      "Epoch 1630/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1851477929.8863 - val_loss: 4053196413.7136\n",
      "Epoch 1631/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2076435399.4192 - val_loss: 3679352682.2166\n",
      "Epoch 1632/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1708233049.7513 - val_loss: 6380045166.9693\n",
      "Epoch 1633/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2981427825.3596 - val_loss: 4223665321.2985\n",
      "Epoch 1634/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1946765596.5245 - val_loss: 5003496407.2416\n",
      "Epoch 1635/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2183592339.1604 - val_loss: 4032516176.2025\n",
      "Epoch 1636/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1700772751.6308 - val_loss: 5971235226.7522\n",
      "Epoch 1637/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2088206432.2521 - val_loss: 4098410387.6231\n",
      "Epoch 1638/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1763193284.9342 - val_loss: 4492147709.9837\n",
      "Epoch 1639/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2971770885.4744 - val_loss: 10668351082.2886\n",
      "Epoch 1640/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2380189262.3883 - val_loss: 5034286815.3789\n",
      "Epoch 1641/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2244215443.1289 - val_loss: 4526575599.2574\n",
      "Epoch 1642/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1867021003.7051 - val_loss: 4075922359.0526\n",
      "Epoch 1643/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2228354579.0163 - val_loss: 3675189082.4101\n",
      "Epoch 1644/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1735454539.5971 - val_loss: 3751986765.0880\n",
      "Epoch 1645/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1777132580.3759 - val_loss: 3515143805.9117\n",
      "Epoch 1646/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1869059324.2904 - val_loss: 3802621044.3702\n",
      "Epoch 1647/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1654859184.5853 - val_loss: 6618180419.9066\n",
      "Epoch 1648/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2020414680.1666 - val_loss: 6975216204.0079\n",
      "Epoch 1649/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2013757969.7198 - val_loss: 4227027344.6706\n",
      "Epoch 1650/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2138868220.8216 - val_loss: 4198242106.7612\n",
      "Epoch 1651/10000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1887478667.1649 - val_loss: 4565081650.8399\n",
      "Epoch 1652/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2612891667.5926 - val_loss: 6070993366.3775\n",
      "Epoch 1653/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2793577389.3799 - val_loss: 4447161275.0852\n",
      "Epoch 1654/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2109587622.3928 - val_loss: 3509655060.8473\n",
      "Epoch 1655/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2114651006.7755 - val_loss: 3481459258.0771\n",
      "Epoch 1656/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1846729529.6972 - val_loss: 5919864549.4999\n",
      "Epoch 1657/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1955943565.9021 - val_loss: 3812578603.5308\n",
      "Epoch 1658/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2158140143.7209 - val_loss: 4242557208.2318\n",
      "Epoch 1659/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1734698336.9544 - val_loss: 3449840019.7311\n",
      "Epoch 1660/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2378129424.2791 - val_loss: 4171549545.3525\n",
      "Epoch 1661/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 2159844643.6916 - val_loss: 3549540864.8641\n",
      "Epoch 1662/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1909477090.9713 - val_loss: 5642243642.1131\n",
      "Epoch 1663/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2040102396.5425 - val_loss: 9342938600.2363\n",
      "Epoch 1664/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 3282452081.9539 - val_loss: 4466145476.6987\n",
      "Epoch 1665/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1935955582.8295 - val_loss: 3674334893.5651\n",
      "Epoch 1666/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1556352172.5515 - val_loss: 5740143233.7283\n",
      "Epoch 1667/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2526335196.9927 - val_loss: 4481449098.3696\n",
      "Epoch 1668/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2039852781.8841 - val_loss: 5838923489.0352\n",
      "Epoch 1669/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2545512144.6033 - val_loss: 3884852245.3693\n",
      "Epoch 1670/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1922634656.2701 - val_loss: 3419283540.3252\n",
      "Epoch 1671/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1899433085.6230 - val_loss: 5828011683.8976\n",
      "Epoch 1672/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2018762618.9938 - val_loss: 4220898087.8222\n",
      "Epoch 1673/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1810550517.4834 - val_loss: 5430759746.0343\n",
      "Epoch 1674/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2845553142.7800 - val_loss: 3555989476.7077\n",
      "Epoch 1675/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1975895912.3016 - val_loss: 6478986444.0079\n",
      "Epoch 1676/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 2591460342.8160 - val_loss: 7092541498.1131\n",
      "Epoch 1677/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1912083764.0068 - val_loss: 4097181589.1353\n",
      "Epoch 1678/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1880261303.3922 - val_loss: 4205295426.3944\n",
      "Epoch 1679/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1790552059.3900 - val_loss: 4210849470.5418\n",
      "Epoch 1680/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1667787757.9561 - val_loss: 5444507142.1210\n",
      "Epoch 1681/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2076569758.2060 - val_loss: 3403861559.2686\n",
      "Epoch 1682/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1849995142.4108 - val_loss: 3685825118.3347\n",
      "Epoch 1683/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1710106803.7186 - val_loss: 4436335500.8540\n",
      "Epoch 1684/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 2277819741.7850 - val_loss: 4042041666.5024\n",
      "Epoch 1685/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1887435366.8880 - val_loss: 3952979151.2124\n",
      "Epoch 1686/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1605359917.9561 - val_loss: 6175577472.3241\n",
      "Epoch 1687/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1871041182.4873 - val_loss: 4179965622.0805\n",
      "Epoch 1688/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2625778043.3990 - val_loss: 3990718648.0428\n",
      "Epoch 1689/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1602828635.0478 - val_loss: 4298401941.5674\n",
      "Epoch 1690/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1909996063.9820 - val_loss: 4303619930.5181\n",
      "Epoch 1691/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2969601296.0630 - val_loss: 4583300756.3432\n",
      "Epoch 1692/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1786231399.9415 - val_loss: 3510600416.3691\n",
      "Epoch 1693/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1951742855.4913 - val_loss: 4626674849.9533\n",
      "Epoch 1694/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1968501165.0197 - val_loss: 5029960705.6563\n",
      "Epoch 1695/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1825337082.3815 - val_loss: 4600655485.0835\n",
      "Epoch 1696/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1711352829.5284 - val_loss: 3630504151.7457\n",
      "Epoch 1697/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2149049499.8987 - val_loss: 4301791212.0529\n",
      "Epoch 1698/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 2126830720.0720 - val_loss: 5513356195.3575\n",
      "Epoch 1699/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1866224786.5841 - val_loss: 4011873415.7412\n",
      "Epoch 1700/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1919083177.5982 - val_loss: 4695364254.7128\n",
      "Epoch 1701/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2330915924.4209 - val_loss: 4767357488.6796\n",
      "Epoch 1702/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 2286764074.0124 - val_loss: 3873321125.4098\n",
      "Epoch 1703/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1721057892.4479 - val_loss: 5186964525.3311\n",
      "Epoch 1704/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1755210219.0028 - val_loss: 4574496255.5679\n",
      "Epoch 1705/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1816721818.8678 - val_loss: 4250288207.9325\n",
      "Epoch 1706/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1996020404.0788 - val_loss: 8951219740.2284\n",
      "Epoch 1707/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2845044867.3855 - val_loss: 5780752362.3246\n",
      "Epoch 1708/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1845861534.7575 - val_loss: 4220131675.5263\n",
      "Epoch 1709/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1956798998.4254 - val_loss: 3365824909.7181\n",
      "Epoch 1710/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1606510527.4237 - val_loss: 3620599588.5817\n",
      "Epoch 1711/10000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2338503498.7507 - val_loss: 8339899410.8669\n",
      "Epoch 1712/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1732844472.8329 - val_loss: 3527108470.4585\n",
      "Epoch 1713/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1710458282.7147 - val_loss: 3317986973.7046\n",
      "Epoch 1714/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1429406636.1013 - val_loss: 3789013202.9930\n",
      "Epoch 1715/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 90us/step - loss: 1716909704.9679 - val_loss: 3515833860.3927\n",
      "Epoch 1716/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1582842647.7344 - val_loss: 5188984035.2675\n",
      "Epoch 1717/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1892421954.1249 - val_loss: 3473968172.2689\n",
      "Epoch 1718/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1909715171.1064 - val_loss: 3553487754.5316\n",
      "Epoch 1719/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1656330639.6308 - val_loss: 3906419686.4000\n",
      "Epoch 1720/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1627139373.0017 - val_loss: 3457783321.0059\n",
      "Epoch 1721/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1973224963.0974 - val_loss: 15296760253.4616\n",
      "Epoch 1722/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2356537389.0917 - val_loss: 3659840880.7606\n",
      "Epoch 1723/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1614573772.0653 - val_loss: 6203120333.9342\n",
      "Epoch 1724/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1892193537.8728 - val_loss: 3480540876.9440\n",
      "Epoch 1725/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1743673920.6033 - val_loss: 3576321032.7494\n",
      "Epoch 1726/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1704759382.8700 - val_loss: 5403336472.2678\n",
      "Epoch 1727/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1726221688.2926 - val_loss: 3246930585.5460\n",
      "Epoch 1728/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1726706290.6382 - val_loss: 4142237741.5471\n",
      "Epoch 1729/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1829412694.5098 - val_loss: 4350100595.6861\n",
      "Epoch 1730/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2370398707.7546 - val_loss: 4169800463.3384\n",
      "Epoch 1731/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1516543077.7085 - val_loss: 3552734949.3918\n",
      "Epoch 1732/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1674485842.4041 - val_loss: 6542355726.3302\n",
      "Epoch 1733/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1815081556.3759 - val_loss: 7347538541.9252\n",
      "Epoch 1734/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1950075173.6365 - val_loss: 3673477571.5105\n",
      "Epoch 1735/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1773573834.8407 - val_loss: 7893799574.5035\n",
      "Epoch 1736/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1972863731.4665 - val_loss: 7093331674.1941\n",
      "Epoch 1737/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2264814398.1632 - val_loss: 3494763861.7114\n",
      "Epoch 1738/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1839297303.6263 - val_loss: 3840227155.3350\n",
      "Epoch 1739/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1623566203.4980 - val_loss: 4292949793.7913\n",
      "Epoch 1740/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1646289377.9629 - val_loss: 11143829122.0523\n",
      "Epoch 1741/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 2173046248.0855 - val_loss: 6060479989.2703\n",
      "Epoch 1742/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2524553671.0231 - val_loss: 8806971034.3921\n",
      "Epoch 1743/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2206524092.8666 - val_loss: 5037847743.5859\n",
      "Epoch 1744/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1711259119.3607 - val_loss: 3759556072.2183\n",
      "Epoch 1745/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1499326916.8621 - val_loss: 3812147887.0233\n",
      "Epoch 1746/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1428961214.9916 - val_loss: 3976572508.0844\n",
      "Epoch 1747/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1608907180.4434 - val_loss: 6648980830.1907\n",
      "Epoch 1748/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1900349148.9966 - val_loss: 4730011091.4250\n",
      "Epoch 1749/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1746731544.6888 - val_loss: 3799527272.7404\n",
      "Epoch 1750/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1804473970.5301 - val_loss: 3318623257.7800\n",
      "Epoch 1751/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1545109093.5644 - val_loss: 3591010758.9131\n",
      "Epoch 1752/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2044494004.9432 - val_loss: 5083545768.0743\n",
      "Epoch 1753/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2146636378.6156 - val_loss: 5607496350.0107\n",
      "Epoch 1754/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1800039295.4958 - val_loss: 5010840842.5857\n",
      "Epoch 1755/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1609631937.4766 - val_loss: 3874988972.3049\n",
      "Epoch 1756/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1833650548.2589 - val_loss: 4681651461.6169\n",
      "Epoch 1757/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2596376657.8818 - val_loss: 4255417540.4287\n",
      "Epoch 1758/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1786534542.8385 - val_loss: 6883765513.3615\n",
      "Epoch 1759/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 2492703163.9302 - val_loss: 3948232476.0844\n",
      "Epoch 1760/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1455321599.4958 - val_loss: 3174075535.0323\n",
      "Epoch 1761/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1303145754.7597 - val_loss: 4806184300.5210\n",
      "Epoch 1762/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1419644631.4102 - val_loss: 3738379929.0599\n",
      "Epoch 1763/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1564070630.5008 - val_loss: 3483713027.4565\n",
      "Epoch 1764/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1520598118.0867 - val_loss: 4216259152.5806\n",
      "Epoch 1765/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1620930953.5802 - val_loss: 4413985357.1961\n",
      "Epoch 1766/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1564594658.1790 - val_loss: 3551031606.9806\n",
      "Epoch 1767/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1500563557.6005 - val_loss: 3417327374.2942\n",
      "Epoch 1768/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1441143402.3185 - val_loss: 3480046211.6006\n",
      "Epoch 1769/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2104851976.9319 - val_loss: 15414114849.8453\n",
      "Epoch 1770/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2311445882.0304 - val_loss: 3336128991.4509\n",
      "Epoch 1771/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1428168297.1660 - val_loss: 17336939632.0495\n",
      "Epoch 1772/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 3383365706.3365 - val_loss: 3675256148.7932\n",
      "Epoch 1773/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1890053850.1114 - val_loss: 5970442587.5263\n",
      "Epoch 1774/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1860609818.6877 - val_loss: 3483893498.7072\n",
      "Epoch 1775/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1420759382.3298 - val_loss: 3399311048.9474\n",
      "Epoch 1776/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1533801717.4564 - val_loss: 6726364078.5193\n",
      "Epoch 1777/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1609244200.9499 - val_loss: 3555174579.8841\n",
      "Epoch 1778/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1678064510.6314 - val_loss: 3658068870.5530\n",
      "Epoch 1779/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 2226908494.2262 - val_loss: 3352122595.8796\n",
      "Epoch 1780/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1726261426.0619 - val_loss: 3422529453.3311\n",
      "Epoch 1781/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1754902758.5008 - val_loss: 3726766696.5333\n",
      "Epoch 1782/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1700490674.7822 - val_loss: 3212547866.3201\n",
      "Epoch 1783/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1804177985.5487 - val_loss: 3735825166.8793\n",
      "Epoch 1784/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2093374138.3455 - val_loss: 4691464750.9333\n",
      "Epoch 1785/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1508506897.8998 - val_loss: 3802983397.0318\n",
      "Epoch 1786/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1460666387.3225 - val_loss: 3554759675.4273\n",
      "Epoch 1787/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1510074930.6382 - val_loss: 6448603418.5722\n",
      "Epoch 1788/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1743672773.5104 - val_loss: 8105161534.2897\n",
      "Epoch 1789/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1872747362.7552 - val_loss: 3648091877.1038\n",
      "Epoch 1790/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1869505215.9280 - val_loss: 4211893137.0667\n",
      "Epoch 1791/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1381029408.5582 - val_loss: 3905242421.7024\n",
      "Epoch 1792/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1568997561.1930 - val_loss: 3967648935.4982\n",
      "Epoch 1793/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1430241572.8801 - val_loss: 5014236852.7302\n",
      "Epoch 1794/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2068012715.2887 - val_loss: 3439891435.6298\n",
      "Epoch 1795/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1364617335.7164 - val_loss: 3686021227.3148\n",
      "Epoch 1796/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1364777421.0017 - val_loss: 7748952081.1387\n",
      "Epoch 1797/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2849920032.0540 - val_loss: 5748752772.1406\n",
      "Epoch 1798/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1648920458.4086 - val_loss: 3675275763.1820\n",
      "Epoch 1799/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1460045452.3894 - val_loss: 4130324560.4006\n",
      "Epoch 1800/10000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 1617431315.2774 - val_loss: 3297561869.6821\n",
      "Epoch 1801/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1641111430.1947 - val_loss: 3661770600.4523\n",
      "Epoch 1802/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1669408245.9876 - val_loss: 3304344713.5775\n",
      "Epoch 1803/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1917980914.8182 - val_loss: 3405317315.6366\n",
      "Epoch 1804/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1373161146.6337 - val_loss: 5231600910.5463\n",
      "Epoch 1805/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1750497031.9595 - val_loss: 5459220535.3046\n",
      "Epoch 1806/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1756316875.0568 - val_loss: 3733554008.2498\n",
      "Epoch 1807/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1546018762.4626 - val_loss: 3730764063.6759\n",
      "Epoch 1808/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1386204330.3185 - val_loss: 3425763007.2619\n",
      "Epoch 1809/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1527153312.6303 - val_loss: 3575921364.7392\n",
      "Epoch 1810/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1712571673.4992 - val_loss: 4057689192.4163\n",
      "Epoch 1811/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1490423763.7727 - val_loss: 4064465577.4065\n",
      "Epoch 1812/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1613936071.3832 - val_loss: 4329113037.8622\n",
      "Epoch 1813/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1341582012.9927 - val_loss: 3241883932.2824\n",
      "Epoch 1814/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1692001294.8835 - val_loss: 4340830353.2107\n",
      "Epoch 1815/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1412082390.6539 - val_loss: 4077546340.9418\n",
      "Epoch 1816/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2042733916.2904 - val_loss: 9244202480.8776\n",
      "Epoch 1817/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1895960517.2223 - val_loss: 3913952657.9128\n",
      "Epoch 1818/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1918723147.4890 - val_loss: 4077799235.0425\n",
      "Epoch 1819/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1559407329.1705 - val_loss: 4723174315.6028\n",
      "Epoch 1820/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1667637302.4558 - val_loss: 4027327956.8653\n",
      "Epoch 1821/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1519049765.8165 - val_loss: 4710984211.2180\n",
      "Epoch 1822/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1924202361.2966 - val_loss: 3836341211.5443\n",
      "Epoch 1823/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1380916445.8931 - val_loss: 3835272270.6363\n",
      "Epoch 1824/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1526327657.8863 - val_loss: 6035829281.4852\n",
      "Epoch 1825/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2103373125.8706 - val_loss: 3631953633.9803\n",
      "Epoch 1826/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2059348379.2999 - val_loss: 5406384499.3260\n",
      "Epoch 1827/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1812292897.7828 - val_loss: 3240308884.7662\n",
      "Epoch 1828/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1308973202.7462 - val_loss: 5844624091.8504\n",
      "Epoch 1829/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1420025098.6967 - val_loss: 4511123439.4734\n",
      "Epoch 1830/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1318217922.1069 - val_loss: 7269019150.6183\n",
      "Epoch 1831/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2197804904.1576 - val_loss: 4719608178.1018\n",
      "Epoch 1832/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2282456496.6213 - val_loss: 7204858102.9266\n",
      "Epoch 1833/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2106433041.2876 - val_loss: 3453083848.1913\n",
      "Epoch 1834/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1449822717.4069 - val_loss: 4312045527.3857\n",
      "Epoch 1835/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1807065110.1024 - val_loss: 3253111963.8323\n",
      "Epoch 1836/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1430051055.4328 - val_loss: 5214971798.5035\n",
      "Epoch 1837/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1593707190.4558 - val_loss: 4431522298.8152\n",
      "Epoch 1838/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1494201066.6427 - val_loss: 5215505963.6388\n",
      "Epoch 1839/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1425465885.1007 - val_loss: 7133243212.4039\n",
      "Epoch 1840/10000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1890910511.8289 - val_loss: 3685511834.3381\n",
      "Epoch 1841/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1660572685.1097 - val_loss: 7606645004.0259\n",
      "Epoch 1842/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1875509867.3630 - val_loss: 3519693365.5224\n",
      "Epoch 1843/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 75us/step - loss: 1769557776.7113 - val_loss: 4359681848.9609\n",
      "Epoch 1844/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1432557543.6533 - val_loss: 3390011756.8450\n",
      "Epoch 1845/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1479882548.3669 - val_loss: 4247817485.0340\n",
      "Epoch 1846/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1626603769.0490 - val_loss: 3427400216.9879\n",
      "Epoch 1847/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1371868254.9387 - val_loss: 5139738490.3471\n",
      "Epoch 1848/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1367072847.6669 - val_loss: 3770413955.9606\n",
      "Epoch 1849/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1421319135.0771 - val_loss: 3916009551.5364\n",
      "Epoch 1850/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1622356937.6387 - val_loss: 5417273836.1249\n",
      "Epoch 1851/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1417790876.7406 - val_loss: 3741178408.9204\n",
      "Epoch 1852/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1477545690.0034 - val_loss: 11312014042.4821\n",
      "Epoch 1853/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2608727657.5982 - val_loss: 3412821220.6897\n",
      "Epoch 1854/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1915959474.2780 - val_loss: 4193992624.4636\n",
      "Epoch 1855/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1925266890.8407 - val_loss: 3249401004.3949\n",
      "Epoch 1856/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1669575337.4181 - val_loss: 4559795448.1508\n",
      "Epoch 1857/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1294335517.4249 - val_loss: 3619459237.9319\n",
      "Epoch 1858/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1424075747.0433 - val_loss: 3210146300.2554\n",
      "Epoch 1859/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1652623260.6325 - val_loss: 3375362344.0023\n",
      "Epoch 1860/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1425216167.9865 - val_loss: 4322404393.9105\n",
      "Epoch 1861/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1610182333.0827 - val_loss: 4284622095.6985\n",
      "Epoch 1862/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1344737550.4063 - val_loss: 3564617996.3139\n",
      "Epoch 1863/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1409835936.0540 - val_loss: 4392161483.8639\n",
      "Epoch 1864/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1901795258.6697 - val_loss: 3700538325.4053\n",
      "Epoch 1865/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 2003521595.2099 - val_loss: 4613412851.4700\n",
      "Epoch 1866/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1384259187.3675 - val_loss: 3728981215.7210\n",
      "Epoch 1867/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1109100056.2026 - val_loss: 4644030419.3530\n",
      "Epoch 1868/10000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2162239798.5999 - val_loss: 12051300019.8841\n",
      "Epoch 1869/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 3172393599.3517 - val_loss: 4083959740.5795\n",
      "Epoch 1870/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1213985078.7417 - val_loss: 3648288809.7845\n",
      "Epoch 1871/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1342749835.0929 - val_loss: 3330495482.2931\n",
      "Epoch 1872/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1709495884.0473 - val_loss: 4497265474.7004\n",
      "Epoch 1873/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1923053332.0248 - val_loss: 5110900545.8183\n",
      "Epoch 1874/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1523947100.4164 - val_loss: 3178140583.5522\n",
      "Epoch 1875/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1351973814.8070 - val_loss: 3627662917.5269\n",
      "Epoch 1876/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1487438979.7727 - val_loss: 3331984630.4585\n",
      "Epoch 1877/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1204495234.9893 - val_loss: 4560149801.7485\n",
      "Epoch 1878/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1496445235.7186 - val_loss: 3968545964.4129\n",
      "Epoch 1879/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1681001335.2909 - val_loss: 4750069075.9651\n",
      "Epoch 1880/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1284799851.6511 - val_loss: 4833474762.7477\n",
      "Epoch 1881/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1738275008.9916 - val_loss: 5752902430.0287\n",
      "Epoch 1882/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1358413888.9814 - val_loss: 3253364329.3525\n",
      "Epoch 1883/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1267690196.2048 - val_loss: 4312848100.9598\n",
      "Epoch 1884/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1867214774.5391 - val_loss: 3309353681.1747\n",
      "Epoch 1885/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1176024414.0822 - val_loss: 3674564438.4855\n",
      "Epoch 1886/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1332231639.8064 - val_loss: 3714104006.5890\n",
      "Epoch 1887/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1816636405.4834 - val_loss: 11944257804.8900\n",
      "Epoch 1888/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1905952895.0636 - val_loss: 3296812620.9800\n",
      "Epoch 1889/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1247616927.5498 - val_loss: 4026726420.9193\n",
      "Epoch 1890/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1329255615.3157 - val_loss: 5428276847.5454\n",
      "Epoch 1891/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1540574795.0929 - val_loss: 3559630827.0987\n",
      "Epoch 1892/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1617836607.5318 - val_loss: 3228519155.9921\n",
      "Epoch 1893/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1417313191.6173 - val_loss: 3560559773.4166\n",
      "Epoch 1894/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1586284756.1508 - val_loss: 3218592620.2419\n",
      "Epoch 1895/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1433663932.0023 - val_loss: 8903095072.0450\n",
      "Epoch 1896/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1934947252.6550 - val_loss: 4374884975.4014\n",
      "Epoch 1897/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1453885483.2909 - val_loss: 3246518090.2076\n",
      "Epoch 1898/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1347377007.7209 - val_loss: 4155605631.2979\n",
      "Epoch 1899/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1696908498.3320 - val_loss: 4495986018.0793\n",
      "Epoch 1900/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1514641664.2161 - val_loss: 3528607755.8278\n",
      "Epoch 1901/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2136512440.4007 - val_loss: 3348729252.1857\n",
      "Epoch 1902/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1205920985.9313 - val_loss: 4323212632.4298\n",
      "Epoch 1903/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1551863052.2454 - val_loss: 3923780588.2689\n",
      "Epoch 1904/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1343703943.2752 - val_loss: 4759815772.0844\n",
      "Epoch 1905/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1803999152.1711 - val_loss: 3462607083.8008\n",
      "Epoch 1906/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1334379915.7411 - val_loss: 5576816619.3328\n",
      "Epoch 1907/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1431952080.0990 - val_loss: 3420520634.4371\n",
      "Epoch 1908/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1427339200.0360 - val_loss: 4003470383.3114\n",
      "Epoch 1909/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2832708325.3123 - val_loss: 3392456116.2082\n",
      "Epoch 1910/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1363868977.8458 - val_loss: 3772946388.0191\n",
      "Epoch 1911/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1477816071.7479 - val_loss: 3686351121.1387\n",
      "Epoch 1912/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1296624795.8042 - val_loss: 4475036549.4368\n",
      "Epoch 1913/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1220759840.9904 - val_loss: 4914362607.0053\n",
      "Epoch 1914/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2117741625.7895 - val_loss: 3416838308.9238\n",
      "Epoch 1915/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1335619066.8858 - val_loss: 3221209225.1814\n",
      "Epoch 1916/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1092255593.9223 - val_loss: 3540561637.8959\n",
      "Epoch 1917/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1453757179.7051 - val_loss: 3340798218.5136\n",
      "Epoch 1918/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1270465118.7935 - val_loss: 4630639118.4743\n",
      "Epoch 1919/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1922234017.2786 - val_loss: 3535727304.6954\n",
      "Epoch 1920/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1291488247.3787 - val_loss: 4507047625.5415\n",
      "Epoch 1921/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1469942104.2386 - val_loss: 4460950314.3066\n",
      "Epoch 1922/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1482751326.5053 - val_loss: 4426357486.4833\n",
      "Epoch 1923/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1365429464.0450 - val_loss: 3202472061.4976\n",
      "Epoch 1924/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1252100689.0355 - val_loss: 4408399517.7046\n",
      "Epoch 1925/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1423237227.6151 - val_loss: 9840045986.5294\n",
      "Epoch 1926/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1458742637.2718 - val_loss: 3290611287.7637\n",
      "Epoch 1927/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1522433734.9600 - val_loss: 5247750100.1451\n",
      "Epoch 1928/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1746648273.8998 - val_loss: 3474449186.4934\n",
      "Epoch 1929/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1573833069.5419 - val_loss: 3753802600.0923\n",
      "Epoch 1930/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1276041143.7524 - val_loss: 3134581668.1226\n",
      "Epoch 1931/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1561106177.8728 - val_loss: 3757762078.7308\n",
      "Epoch 1932/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2464556351.2437 - val_loss: 4711974546.0748\n",
      "Epoch 1933/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1810920347.4440 - val_loss: 4782796271.5094\n",
      "Epoch 1934/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2616251623.3112 - val_loss: 3333434614.7646\n",
      "Epoch 1935/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1212742872.7788 - val_loss: 3602834338.3854\n",
      "Epoch 1936/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1150412203.9505 - val_loss: 3386885835.9359\n",
      "Epoch 1937/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1111579759.2167 - val_loss: 10049805058.6644\n",
      "Epoch 1938/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2932629894.9150 - val_loss: 3228861049.4290\n",
      "Epoch 1939/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1212727084.3782 - val_loss: 5203298963.8391\n",
      "Epoch 1940/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1574877944.4367 - val_loss: 3137491356.0484\n",
      "Epoch 1941/10000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1464501357.1277 - val_loss: 4739197891.5826\n",
      "Epoch 1942/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1180852879.2347 - val_loss: 3335899172.6537\n",
      "Epoch 1943/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1292935739.3540 - val_loss: 4167019816.3983\n",
      "Epoch 1944/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1368790145.1525 - val_loss: 3746447684.1226\n",
      "Epoch 1945/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1577691387.4980 - val_loss: 3580868190.9828\n",
      "Epoch 1946/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1170061929.4902 - val_loss: 3254719486.1457\n",
      "Epoch 1947/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1141607667.4485 - val_loss: 3210634788.6177\n",
      "Epoch 1948/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1282572825.3731 - val_loss: 8092959414.0444\n",
      "Epoch 1949/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1907992458.1925 - val_loss: 4383237274.3561\n",
      "Epoch 1950/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 1183820530.4581 - val_loss: 3589934740.4692\n",
      "Epoch 1951/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1271449690.0394 - val_loss: 3344090877.2996\n",
      "Epoch 1952/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1382966583.0321 - val_loss: 3885525374.1997\n",
      "Epoch 1953/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1120525665.5127 - val_loss: 3530538283.2788\n",
      "Epoch 1954/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1664703737.0850 - val_loss: 3477801103.2034\n",
      "Epoch 1955/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1244265746.0079 - val_loss: 4368294459.8414\n",
      "Epoch 1956/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1530157768.8239 - val_loss: 5409544941.4931\n",
      "Epoch 1957/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1634405114.0934 - val_loss: 6113392325.5269\n",
      "Epoch 1958/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1862140397.6680 - val_loss: 3267754268.8585\n",
      "Epoch 1959/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1683239811.7456 - val_loss: 4035144639.0729\n",
      "Epoch 1960/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1245862321.6297 - val_loss: 9694784786.1468\n",
      "Epoch 1961/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1702497596.2904 - val_loss: 3213417462.5125\n",
      "Epoch 1962/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1065071315.7727 - val_loss: 5230852644.9418\n",
      "Epoch 1963/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1196434952.3241 - val_loss: 3132795925.0633\n",
      "Epoch 1964/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1078146096.9094 - val_loss: 3156362689.0622\n",
      "Epoch 1965/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1400037965.8165 - val_loss: 3181369545.6315\n",
      "Epoch 1966/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1242505567.7299 - val_loss: 3832937526.7286\n",
      "Epoch 1967/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1257833027.4215 - val_loss: 3339320557.4931\n",
      "Epoch 1968/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1251318344.9139 - val_loss: 3901560954.5451\n",
      "Epoch 1969/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1484905945.9313 - val_loss: 4258799739.1932\n",
      "Epoch 1970/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1606077452.5695 - val_loss: 3953534525.4616\n",
      "Epoch 1971/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 85us/step - loss: 1151511774.4333 - val_loss: 3400038755.5556\n",
      "Epoch 1972/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1415886401.9629 - val_loss: 4547261400.8979\n",
      "Epoch 1973/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1268482311.0591 - val_loss: 6282430749.2366\n",
      "Epoch 1974/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2007700439.3382 - val_loss: 3137891102.9108\n",
      "Epoch 1975/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1133073121.2425 - val_loss: 3972584426.3966\n",
      "Epoch 1976/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1567183268.6325 - val_loss: 4554919387.5983\n",
      "Epoch 1977/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1293076288.9004 - val_loss: 5253945480.1733\n",
      "Epoch 1978/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1368531795.1604 - val_loss: 3250182355.8571\n",
      "Epoch 1979/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1252328212.3849 - val_loss: 5402460096.1980\n",
      "Epoch 1980/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1180764290.3770 - val_loss: 3830622480.9226\n",
      "Epoch 1981/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1409307101.4069 - val_loss: 3495367620.6627\n",
      "Epoch 1982/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1205536387.7456 - val_loss: 3189237939.6141\n",
      "Epoch 1983/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1445141515.8132 - val_loss: 3337272753.1117\n",
      "Epoch 1984/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1952301227.4350 - val_loss: 6755933748.0641\n",
      "Epoch 1985/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2446934806.1857 - val_loss: 4102297438.8028\n",
      "Epoch 1986/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1047061681.4856 - val_loss: 3602267415.3677\n",
      "Epoch 1987/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1211116232.1756 - val_loss: 3553109073.0127\n",
      "Epoch 1988/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1125538831.9910 - val_loss: 6526392141.5561\n",
      "Epoch 1989/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1713640373.6635 - val_loss: 4445022377.0824\n",
      "Epoch 1990/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1473022328.3872 - val_loss: 3235122970.5001\n",
      "Epoch 1991/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1055991995.8942 - val_loss: 5123376487.5522\n",
      "Epoch 1992/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1074688877.0557 - val_loss: 3651488420.7617\n",
      "Epoch 1993/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1361084799.0996 - val_loss: 4746782160.0405\n",
      "Epoch 1994/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1238922867.8267 - val_loss: 12468064741.1398\n",
      "Epoch 1995/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 3950494338.4851 - val_loss: 3550012400.3015\n",
      "Epoch 1996/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1193142505.2741 - val_loss: 3069164928.1800\n",
      "Epoch 1997/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1182790597.6545 - val_loss: 3258186635.7558\n",
      "Epoch 1998/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1303062973.9831 - val_loss: 3598495498.5136\n",
      "Epoch 1999/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1243126496.5943 - val_loss: 3224806493.8847\n",
      "Epoch 2000/10000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1379280355.7636 - val_loss: 3865198811.8504\n",
      "Epoch 2001/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1209060341.1232 - val_loss: 4213695441.0307\n",
      "Epoch 2002/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1838564092.2183 - val_loss: 4666687783.3541\n",
      "Epoch 2003/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1339666555.5701 - val_loss: 3424059829.4684\n",
      "Epoch 2004/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1426534439.6353 - val_loss: 5333316168.5873\n",
      "Epoch 2005/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1233739809.2786 - val_loss: 4196009320.0203\n",
      "Epoch 2006/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1053874350.8509 - val_loss: 3119061866.0006\n",
      "Epoch 2007/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1034955301.1322 - val_loss: 3919974236.5255\n",
      "Epoch 2008/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1810752522.6607 - val_loss: 6476111511.2236\n",
      "Epoch 2009/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1457864960.1441 - val_loss: 5062273124.5997\n",
      "Epoch 2010/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1716662446.8925 - val_loss: 3382553570.2414\n",
      "Epoch 2011/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1233498629.9966 - val_loss: 3104810211.9786\n",
      "Epoch 2012/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1439625346.5931 - val_loss: 3067357325.5921\n",
      "Epoch 2013/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1304669163.6691 - val_loss: 3382551072.9632\n",
      "Epoch 2014/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1107107741.3168 - val_loss: 3568015565.9342\n",
      "Epoch 2015/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1324462355.7366 - val_loss: 4437850497.2962\n",
      "Epoch 2016/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1387612367.1806 - val_loss: 3112259280.4546\n",
      "Epoch 2017/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1487076467.2324 - val_loss: 3591862266.5632\n",
      "Epoch 2018/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1278279489.9449 - val_loss: 3438497037.3401\n",
      "Epoch 2019/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1504847440.2791 - val_loss: 3439050147.1955\n",
      "Epoch 2020/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1116936712.9319 - val_loss: 3496111754.1716\n",
      "Epoch 2021/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1063448696.5627 - val_loss: 2992571525.5629\n",
      "Epoch 2022/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1170284389.6005 - val_loss: 3896022890.7567\n",
      "Epoch 2023/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1248071087.4688 - val_loss: 4064791568.4546\n",
      "Epoch 2024/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1692672495.1446 - val_loss: 4842906126.0962\n",
      "Epoch 2025/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1370258563.4215 - val_loss: 4628106070.0895\n",
      "Epoch 2026/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1422938831.3922 - val_loss: 3273139046.3640\n",
      "Epoch 2027/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1081851285.9719 - val_loss: 3039081916.6515\n",
      "Epoch 2028/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1398363104.5222 - val_loss: 3157536554.3966\n",
      "Epoch 2029/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1055770743.8965 - val_loss: 3807682802.7139\n",
      "Epoch 2030/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1566381722.8272 - val_loss: 3507718381.4751\n",
      "Epoch 2031/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1272044025.5172 - val_loss: 3522934562.4214\n",
      "Epoch 2032/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1208584197.4024 - val_loss: 3774188994.7184\n",
      "Epoch 2033/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1413430632.8059 - val_loss: 5175138335.9730\n",
      "Epoch 2034/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2194110032.5324 - val_loss: 3669080966.9851\n",
      "Epoch 2035/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1111288494.8385 - val_loss: 3095668755.2990\n",
      "Epoch 2036/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1011729970.8903 - val_loss: 3386342372.7257\n",
      "Epoch 2037/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1122702418.9083 - val_loss: 3376402928.5896\n",
      "Epoch 2038/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1633845367.4282 - val_loss: 12614908080.5716\n",
      "Epoch 2039/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2168426382.6944 - val_loss: 3388103730.5879\n",
      "Epoch 2040/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 928395459.2594 - val_loss: 2961906067.3350\n",
      "Epoch 2041/10000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 1027094044.5335 - val_loss: 3578485559.7367\n",
      "Epoch 2042/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1390854533.2628 - val_loss: 4273005623.7007\n",
      "Epoch 2043/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1084455136.1981 - val_loss: 3735718173.1646\n",
      "Epoch 2044/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1277904757.4834 - val_loss: 4815817691.7783\n",
      "Epoch 2045/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1355022843.3180 - val_loss: 4142586843.0492\n",
      "Epoch 2046/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1370265890.8633 - val_loss: 4373501497.6810\n",
      "Epoch 2047/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1381431423.6398 - val_loss: 3233110776.6729\n",
      "Epoch 2048/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1409465385.5622 - val_loss: 3926096565.5764\n",
      "Epoch 2049/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1395893288.9139 - val_loss: 3492466843.8323\n",
      "Epoch 2050/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1854324779.6151 - val_loss: 3385096473.8520\n",
      "Epoch 2051/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1017555927.3562 - val_loss: 3932960281.9241\n",
      "Epoch 2052/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1267067358.7575 - val_loss: 3336415701.4413\n",
      "Epoch 2053/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1045694696.4727 - val_loss: 4123115395.5376\n",
      "Epoch 2054/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1204525659.9482 - val_loss: 3285870112.4771\n",
      "Epoch 2055/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1029237610.6292 - val_loss: 3245559566.0422\n",
      "Epoch 2056/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1099312241.2335 - val_loss: 6640206712.0428\n",
      "Epoch 2057/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1431369204.8531 - val_loss: 3379062965.9724\n",
      "Epoch 2058/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1025392295.5453 - val_loss: 4080542569.3165\n",
      "Epoch 2059/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1278306690.8813 - val_loss: 4456209350.4090\n",
      "Epoch 2060/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1284718347.9932 - val_loss: 3235873176.0158\n",
      "Epoch 2061/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1092173299.9527 - val_loss: 3328812784.1935\n",
      "Epoch 2062/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 967596472.2431 - val_loss: 3097205437.6776\n",
      "Epoch 2063/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1321614412.0653 - val_loss: 3592298111.8200\n",
      "Epoch 2064/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1487704810.9668 - val_loss: 3353746211.2675\n",
      "Epoch 2065/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1106612639.4418 - val_loss: 3369903773.7406\n",
      "Epoch 2066/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1274835403.8852 - val_loss: 4478738493.9477\n",
      "Epoch 2067/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1288647715.9077 - val_loss: 5403518616.9519\n",
      "Epoch 2068/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1582920510.4153 - val_loss: 3989528869.4999\n",
      "Epoch 2069/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1036598545.6117 - val_loss: 3558967505.9848\n",
      "Epoch 2070/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1596620494.0822 - val_loss: 5847495715.4295\n",
      "Epoch 2071/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1606479254.0416 - val_loss: 5026918997.8374\n",
      "Epoch 2072/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2104468652.3714 - val_loss: 4160179807.3429\n",
      "Epoch 2073/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1240320040.3737 - val_loss: 3136846459.2788\n",
      "Epoch 2074/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1209472541.3889 - val_loss: 3452268586.3786\n",
      "Epoch 2075/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1217190731.9572 - val_loss: 4829536299.7828\n",
      "Epoch 2076/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1065209606.1947 - val_loss: 3697750437.6259\n",
      "Epoch 2077/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 954071701.3528 - val_loss: 3260804648.9744\n",
      "Epoch 2078/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 957658726.9330 - val_loss: 3202008910.9873\n",
      "Epoch 2079/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1210146965.9696 - val_loss: 4640637872.5716\n",
      "Epoch 2080/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1898190706.3860 - val_loss: 3864531422.5148\n",
      "Epoch 2081/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1439193231.6308 - val_loss: 3478720132.7977\n",
      "Epoch 2082/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1216765255.3112 - val_loss: 4103194727.3722\n",
      "Epoch 2083/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1390092041.7243 - val_loss: 3674777822.4608\n",
      "Epoch 2084/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 997704628.3129 - val_loss: 3351582072.9339\n",
      "Epoch 2085/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 990521859.0974 - val_loss: 3617071304.6594\n",
      "Epoch 2086/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1218254808.2386 - val_loss: 7999304100.4017\n",
      "Epoch 2087/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 2049533565.8391 - val_loss: 3980422044.2644\n",
      "Epoch 2088/10000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 1157930131.41 - 0s 85us/step - loss: 1111011770.7057 - val_loss: 2920949669.1398\n",
      "Epoch 2089/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1000361860.3219 - val_loss: 3849344359.8762\n",
      "Epoch 2090/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1269183451.6961 - val_loss: 3065129749.9094\n",
      "Epoch 2091/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1200371558.5729 - val_loss: 3862190776.4928\n",
      "Epoch 2092/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1210208025.2831 - val_loss: 4082170850.3314\n",
      "Epoch 2093/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1119109755.6061 - val_loss: 9985570726.9941\n",
      "Epoch 2094/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1903996301.5419 - val_loss: 5343234745.9331\n",
      "Epoch 2095/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1184947034.8317 - val_loss: 4866133971.1910\n",
      "Epoch 2096/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1021126297.4271 - val_loss: 5730307141.4188\n",
      "Epoch 2097/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2336135146.1204 - val_loss: 3258757005.8802\n",
      "Epoch 2098/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 913175692.6055 - val_loss: 4252641027.0245\n",
      "Epoch 2099/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 81us/step - loss: 1338027406.7248 - val_loss: 3110298404.1406\n",
      "Epoch 2100/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1066684104.3557 - val_loss: 4714960798.2087\n",
      "Epoch 2101/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 978937998.9465 - val_loss: 4750216200.6774\n",
      "Epoch 2102/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1055991763.9167 - val_loss: 5142949107.3980\n",
      "Epoch 2103/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1105981215.1536 - val_loss: 3847603388.5255\n",
      "Epoch 2104/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1061744274.0799 - val_loss: 3438052864.1800\n",
      "Epoch 2105/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1196379171.6106 - val_loss: 3267112841.8295\n",
      "Epoch 2106/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 966112120.4367 - val_loss: 3642895554.2143\n",
      "Epoch 2107/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1452903850.7147 - val_loss: 7101654511.4374\n",
      "Epoch 2108/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1938809155.4215 - val_loss: 3392291003.1032\n",
      "Epoch 2109/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1033470143.6939 - val_loss: 3274695900.3544\n",
      "Epoch 2110/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 963453042.6922 - val_loss: 3074758965.0093\n",
      "Epoch 2111/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 966669837.0557 - val_loss: 7108350825.7845\n",
      "Epoch 2112/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1025186983.9775 - val_loss: 3996508180.6132\n",
      "Epoch 2113/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1308981905.0264 - val_loss: 3307845086.2807\n",
      "Epoch 2114/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 930885103.7209 - val_loss: 5216477041.2017\n",
      "Epoch 2115/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1727523758.7485 - val_loss: 4435672357.1578\n",
      "Epoch 2116/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1259330494.5954 - val_loss: 3405284584.4883\n",
      "Epoch 2117/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 998805534.1812 - val_loss: 3520913536.2520\n",
      "Epoch 2118/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 876767542.3838 - val_loss: 2884655385.4515\n",
      "Epoch 2119/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 862688108.2634 - val_loss: 3425691559.5702\n",
      "Epoch 2120/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1224685246.3973 - val_loss: 3583045478.4720\n",
      "Epoch 2121/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1136852838.3568 - val_loss: 4039932387.6096\n",
      "Epoch 2122/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1346749408.3061 - val_loss: 3258694765.7992\n",
      "Epoch 2123/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 954163085.8481 - val_loss: 4049178300.0934\n",
      "Epoch 2124/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1129138184.0225 - val_loss: 3068252572.7145\n",
      "Epoch 2125/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1015290560.9004 - val_loss: 6167076351.9280\n",
      "Epoch 2126/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1880683728.4232 - val_loss: 3540131493.5539\n",
      "Epoch 2127/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 939748205.7760 - val_loss: 3268507414.1615\n",
      "Epoch 2128/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1258144446.5234 - val_loss: 12611768892.6335\n",
      "Epoch 2129/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3896993177.2831 - val_loss: 3716604835.2855\n",
      "Epoch 2130/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 894467715.3855 - val_loss: 2935949306.5541\n",
      "Epoch 2131/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 890854292.0608 - val_loss: 4109457886.8388\n",
      "Epoch 2132/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1089859404.1553 - val_loss: 3755827981.9342\n",
      "Epoch 2133/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 886774962.1024 - val_loss: 3420400348.7505\n",
      "Epoch 2134/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 986721403.9032 - val_loss: 2992681127.3451\n",
      "Epoch 2135/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 924571346.9083 - val_loss: 3016866899.0380\n",
      "Epoch 2136/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 978133437.8931 - val_loss: 3272849490.3809\n",
      "Epoch 2137/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1157149090.6472 - val_loss: 11918611547.1662\n",
      "Epoch 2138/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1578553211.4620 - val_loss: 6841315237.5179\n",
      "Epoch 2139/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1405976892.2904 - val_loss: 4033740297.0014\n",
      "Epoch 2140/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1058774927.9190 - val_loss: 11676504466.2549\n",
      "Epoch 2141/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1724737618.8362 - val_loss: 3785555526.9806\n",
      "Epoch 2142/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 982653261.8661 - val_loss: 3511868831.2889\n",
      "Epoch 2143/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1497490314.1564 - val_loss: 3146886537.4087\n",
      "Epoch 2144/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 871469117.2268 - val_loss: 4036346484.0461\n",
      "Epoch 2145/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 982121912.0101 - val_loss: 3484579634.0478\n",
      "Epoch 2146/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1087789830.4108 - val_loss: 3195391788.7190\n",
      "Epoch 2147/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1173784165.7085 - val_loss: 4781630012.6335\n",
      "Epoch 2148/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1385372552.2116 - val_loss: 3895760002.1963\n",
      "Epoch 2149/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1001670822.0326 - val_loss: 3430825030.6430\n",
      "Epoch 2150/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2091284280.9049 - val_loss: 4388005149.7046\n",
      "Epoch 2151/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1160102733.7220 - val_loss: 3039182780.0169\n",
      "Epoch 2152/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 825194695.8875 - val_loss: 3068249342.1097\n",
      "Epoch 2153/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1232133381.6185 - val_loss: 4311944566.2965\n",
      "Epoch 2154/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 962856689.3056 - val_loss: 3436191938.2143\n",
      "Epoch 2155/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 947142433.4406 - val_loss: 3505792137.9736\n",
      "Epoch 2156/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1076023700.1688 - val_loss: 3209741100.3499\n",
      "Epoch 2157/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 795474891.4170 - val_loss: 3069510281.8655\n",
      "Epoch 2158/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 856596434.8362 - val_loss: 3457375534.1007\n",
      "Epoch 2159/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 870082637.2898 - val_loss: 2984144602.9862\n",
      "Epoch 2160/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1183227485.7130 - val_loss: 3211622898.3359\n",
      "Epoch 2161/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1034193051.3180 - val_loss: 3162112971.0695\n",
      "Epoch 2162/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1000435989.5014 - val_loss: 3240821512.3488\n",
      "Epoch 2163/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 1445355387.9347 - val_loss: 3712934281.3255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2164/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1296664836.4660 - val_loss: 3133280086.3235\n",
      "Epoch 2165/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1005779640.2566 - val_loss: 3038221968.9586\n",
      "Epoch 2166/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1059310478.2802 - val_loss: 3041319507.2900\n",
      "Epoch 2167/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 892789812.1508 - val_loss: 3759029127.3091\n",
      "Epoch 2168/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1036032717.8841 - val_loss: 3785323287.1156\n",
      "Epoch 2169/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1011912929.6027 - val_loss: 5087060234.2976\n",
      "Epoch 2170/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1759415353.1210 - val_loss: 4321052492.2419\n",
      "Epoch 2171/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1237292136.3106 - val_loss: 3573963510.4675\n",
      "Epoch 2172/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 835297721.4069 - val_loss: 3275218304.6256\n",
      "Epoch 2173/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1027867112.4817 - val_loss: 3014296784.4456\n",
      "Epoch 2174/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 852963911.9235 - val_loss: 3339558841.5370\n",
      "Epoch 2175/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 961328514.9533 - val_loss: 4413832578.5564\n",
      "Epoch 2176/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1366927810.6292 - val_loss: 3122735027.9561\n",
      "Epoch 2177/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 941038516.4389 - val_loss: 7113776671.5049\n",
      "Epoch 2178/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1164430186.8948 - val_loss: 3415433301.5674\n",
      "Epoch 2179/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1053335921.5037 - val_loss: 4040694236.2824\n",
      "Epoch 2180/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 898961317.5194 - val_loss: 3031235594.7612\n",
      "Epoch 2181/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 873954838.4558 - val_loss: 3388374227.2810\n",
      "Epoch 2182/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 991203463.9235 - val_loss: 2938796741.4504\n",
      "Epoch 2183/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1256222679.6984 - val_loss: 4008418738.0478\n",
      "Epoch 2184/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1246738804.5650 - val_loss: 3582650076.3364\n",
      "Epoch 2185/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 870476844.6235 - val_loss: 4670844094.0017\n",
      "Epoch 2186/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 955709244.1463 - val_loss: 3742703876.7527\n",
      "Epoch 2187/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 836240733.5689 - val_loss: 3224999213.9972\n",
      "Epoch 2188/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1256747100.2364 - val_loss: 3479606217.0464\n",
      "Epoch 2189/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 789040326.5999 - val_loss: 3902587153.1747\n",
      "Epoch 2190/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 864619456.0360 - val_loss: 4740570925.6551\n",
      "Epoch 2191/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1041268155.6421 - val_loss: 5174024055.9707\n",
      "Epoch 2192/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 942449094.6269 - val_loss: 5479985874.4889\n",
      "Epoch 2193/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1614719513.6207 - val_loss: 4086539935.0008\n",
      "Epoch 2194/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1282744357.4564 - val_loss: 3540916563.2990\n",
      "Epoch 2195/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1007826801.5937 - val_loss: 3341088085.6934\n",
      "Epoch 2196/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 966491036.1643 - val_loss: 3013681079.9527\n",
      "Epoch 2197/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 961501441.0805 - val_loss: 5212796881.0487\n",
      "Epoch 2198/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 965312375.2842 - val_loss: 5702398675.2450\n",
      "Epoch 2199/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1460419235.3225 - val_loss: 4247283225.2039\n",
      "Epoch 2200/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 869114890.8768 - val_loss: 4179414137.7710\n",
      "Epoch 2201/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1664353209.7693 - val_loss: 4430649237.3153\n",
      "Epoch 2202/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 996867613.6050 - val_loss: 3869397375.0999\n",
      "Epoch 2203/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 983456004.9342 - val_loss: 5366732679.1831\n",
      "Epoch 2204/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1280632713.2200 - val_loss: 3045354199.1246\n",
      "Epoch 2205/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1117385859.4575 - val_loss: 7783664808.2183\n",
      "Epoch 2206/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1552778608.5132 - val_loss: 3765467105.3952\n",
      "Epoch 2207/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1074221782.3658 - val_loss: 3880800337.8048\n",
      "Epoch 2208/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1517139668.6370 - val_loss: 3378681282.0613\n",
      "Epoch 2209/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 722748169.0523 - val_loss: 2884909636.6807\n",
      "Epoch 2210/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 815499927.1581 - val_loss: 4922813107.2360\n",
      "Epoch 2211/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1029685953.6207 - val_loss: 2952737155.1595\n",
      "Epoch 2212/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 908606734.0642 - val_loss: 2860463272.6414\n",
      "Epoch 2213/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 965596549.4744 - val_loss: 4377110183.3181\n",
      "Epoch 2214/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 953681094.2307 - val_loss: 3286638661.2028\n",
      "Epoch 2215/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 926736286.1812 - val_loss: 4209169947.1302\n",
      "Epoch 2216/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1186347487.2977 - val_loss: 4262080035.1415\n",
      "Epoch 2217/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1060231462.6089 - val_loss: 2976983318.9356\n",
      "Epoch 2218/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 845256310.2757 - val_loss: 3452941498.8152\n",
      "Epoch 2219/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1249245258.1204 - val_loss: 2963140763.3733\n",
      "Epoch 2220/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1052410751.9280 - val_loss: 6015692703.7930\n",
      "Epoch 2221/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1112515980.0473 - val_loss: 7275798799.6264\n",
      "Epoch 2222/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1169088083.7727 - val_loss: 3834509534.9198\n",
      "Epoch 2223/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1444871418.0574 - val_loss: 5318005988.0596\n",
      "Epoch 2224/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1040197990.4108 - val_loss: 3102897939.4835\n",
      "Epoch 2225/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 902832028.3804 - val_loss: 3433869487.4284\n",
      "Epoch 2226/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 992096139.8852 - val_loss: 3201051411.6951\n",
      "Epoch 2227/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 986658906.5436 - val_loss: 5017435149.0340\n",
      "Epoch 2228/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1055705235.1559 - val_loss: 3147333084.0079\n",
      "Epoch 2229/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1113698569.8503 - val_loss: 3074361738.4776\n",
      "Epoch 2230/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 808086648.4727 - val_loss: 2930588251.7333\n",
      "Epoch 2231/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 715752028.1463 - val_loss: 2881550773.7294\n",
      "Epoch 2232/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 720297921.8920 - val_loss: 3214455587.1235\n",
      "Epoch 2233/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1161068999.8875 - val_loss: 3565279813.1308\n",
      "Epoch 2234/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1068229921.9629 - val_loss: 4214748034.4484\n",
      "Epoch 2235/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 841990233.6072 - val_loss: 3227119309.4301\n",
      "Epoch 2236/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1168275067.9662 - val_loss: 2923781999.7525\n",
      "Epoch 2237/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1154451886.7485 - val_loss: 4234449048.8799\n",
      "Epoch 2238/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 906078542.2352 - val_loss: 2997927222.0354\n",
      "Epoch 2239/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 830373817.1210 - val_loss: 3546491687.9842\n",
      "Epoch 2240/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 975504548.1328 - val_loss: 3034241113.5820\n",
      "Epoch 2241/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 776811327.4688 - val_loss: 3013355377.3547\n",
      "Epoch 2242/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 878202653.3889 - val_loss: 5104139845.7789\n",
      "Epoch 2243/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1140490547.9347 - val_loss: 3398003341.1150\n",
      "Epoch 2244/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1110977705.7423 - val_loss: 3765375573.1173\n",
      "Epoch 2245/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2234918392.3827 - val_loss: 10277578685.5336\n",
      "Epoch 2246/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1473882593.3146 - val_loss: 3282049191.9662\n",
      "Epoch 2247/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 868655936.1801 - val_loss: 4928999165.4076\n",
      "Epoch 2248/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 950790269.4339 - val_loss: 3035976622.0062\n",
      "Epoch 2249/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 984882421.4969 - val_loss: 3018033160.8934\n",
      "Epoch 2250/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 968295732.2949 - val_loss: 5200901198.2762\n",
      "Epoch 2251/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 953363394.7912 - val_loss: 3477700655.1404\n",
      "Epoch 2252/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 982802584.5267 - val_loss: 3314469669.5179\n",
      "Epoch 2253/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 812569339.9527 - val_loss: 3254755422.4788\n",
      "Epoch 2254/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 674871044.9071 - val_loss: 3979219630.0962\n",
      "Epoch 2255/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 828831442.6201 - val_loss: 3004742009.4380\n",
      "Epoch 2256/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 939011469.1818 - val_loss: 12703844991.5319\n",
      "Epoch 2257/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1935494576.9094 - val_loss: 3037977219.8976\n",
      "Epoch 2258/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 912107990.6989 - val_loss: 3182217739.5218\n",
      "Epoch 2259/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 842992975.5228 - val_loss: 3226824716.7730\n",
      "Epoch 2260/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1884595993.0129 - val_loss: 8230671775.0729\n",
      "Epoch 2261/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1601003289.2110 - val_loss: 3851305481.2895\n",
      "Epoch 2262/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 936175076.5560 - val_loss: 3689770395.8819\n",
      "Epoch 2263/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1185943409.8008 - val_loss: 2884821635.3215\n",
      "Epoch 2264/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 681296895.2617 - val_loss: 3149661123.8166\n",
      "Epoch 2265/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 665971895.7974 - val_loss: 2911773923.8976\n",
      "Epoch 2266/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 796342240.7023 - val_loss: 3585464555.4768\n",
      "Epoch 2267/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1056483874.7912 - val_loss: 3987316093.6596\n",
      "Epoch 2268/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1387556563.9167 - val_loss: 3863384489.2264\n",
      "Epoch 2269/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1197127129.1570 - val_loss: 2946752700.8180\n",
      "Epoch 2270/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 731127606.4918 - val_loss: 4071111568.2745\n",
      "Epoch 2271/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 784590979.0253 - val_loss: 3040079720.3443\n",
      "Epoch 2272/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 892496905.8863 - val_loss: 3382045146.5496\n",
      "Epoch 2273/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1011458800.1171 - val_loss: 3463103409.8138\n",
      "Epoch 2274/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1463491371.0388 - val_loss: 3070235548.1654\n",
      "Epoch 2275/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1091698059.5971 - val_loss: 2923410888.2273\n",
      "Epoch 2276/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 796034521.7153 - val_loss: 3531797470.5868\n",
      "Epoch 2277/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 777301740.1553 - val_loss: 3938824279.8897\n",
      "Epoch 2278/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1053914362.5256 - val_loss: 6847381291.7108\n",
      "Epoch 2279/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2136393074.5166 - val_loss: 5768984846.1862\n",
      "Epoch 2280/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 795137462.9240 - val_loss: 5186684232.8754\n",
      "Epoch 2281/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 972778021.8165 - val_loss: 3895536098.4934\n",
      "Epoch 2282/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1045672184.5087 - val_loss: 4537847048.4973\n",
      "Epoch 2283/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1072686030.2172 - val_loss: 2937799161.7485\n",
      "Epoch 2284/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 776962888.4975 - val_loss: 3079879834.4641\n",
      "Epoch 2285/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 715383733.9336 - val_loss: 4818255432.7674\n",
      "Epoch 2286/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1005072593.9719 - val_loss: 4366855764.3612\n",
      "Epoch 2287/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1378081788.9026 - val_loss: 10471816488.3983\n",
      "Epoch 2288/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 895232701.1367 - val_loss: 3434006304.1890\n",
      "Epoch 2289/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 842463725.9201 - val_loss: 3414262813.2096\n",
      "Epoch 2290/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 942268745.3281 - val_loss: 8896797453.1421\n",
      "Epoch 2291/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1180039054.0912 - val_loss: 3798637136.4726\n",
      "Epoch 2292/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 968164473.9494 - val_loss: 3094983639.2799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2293/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 920760120.2026 - val_loss: 3416092198.2560\n",
      "Epoch 2294/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1298382644.3669 - val_loss: 6281376923.5443\n",
      "Epoch 2295/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 941985668.3759 - val_loss: 2882655895.9077\n",
      "Epoch 2296/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 578975849.3821 - val_loss: 2864601898.4236\n",
      "Epoch 2297/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 809380603.5701 - val_loss: 3785041088.6841\n",
      "Epoch 2298/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1237328613.9246 - val_loss: 3401584980.5367\n",
      "Epoch 2299/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1255088799.8019 - val_loss: 3187537123.9111\n",
      "Epoch 2300/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 958422080.6843 - val_loss: 4941423349.8644\n",
      "Epoch 2301/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1837499123.1604 - val_loss: 3435728921.6900\n",
      "Epoch 2302/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 828413497.2651 - val_loss: 7583802440.0833\n",
      "Epoch 2303/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1982221257.9764 - val_loss: 3798091955.4340\n",
      "Epoch 2304/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 818576545.8548 - val_loss: 3233999119.1831\n",
      "Epoch 2305/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 953808369.8638 - val_loss: 3043800361.4650\n",
      "Epoch 2306/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1027437205.5734 - val_loss: 2983675456.4771\n",
      "Epoch 2307/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 910847205.6365 - val_loss: 4689921090.6824\n",
      "Epoch 2308/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1036421506.8542 - val_loss: 2854469997.1601\n",
      "Epoch 2309/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 741757222.9871 - val_loss: 3198370232.2048\n",
      "Epoch 2310/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1584358076.6866 - val_loss: 6990689690.1761\n",
      "Epoch 2311/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 972051126.4018 - val_loss: 2842860452.9868\n",
      "Epoch 2312/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 723900905.2380 - val_loss: 3693720534.6655\n",
      "Epoch 2313/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 846385476.6100 - val_loss: 3297049238.5035\n",
      "Epoch 2314/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 787605842.6922 - val_loss: 3415803771.4093\n",
      "Epoch 2315/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1066929834.8047 - val_loss: 2821121154.7904\n",
      "Epoch 2316/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 694063132.7496 - val_loss: 3227112520.2993\n",
      "Epoch 2317/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 802824504.1125 - val_loss: 3126408164.4377\n",
      "Epoch 2318/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 782343879.0231 - val_loss: 3128830142.2627\n",
      "Epoch 2319/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 938057700.5380 - val_loss: 2966673820.1564\n",
      "Epoch 2320/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1258935433.0039 - val_loss: 4657895222.5035\n",
      "Epoch 2321/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1008035679.2077 - val_loss: 2960705026.9435\n",
      "Epoch 2322/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 786737719.8965 - val_loss: 5483709169.5977\n",
      "Epoch 2323/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 943119349.0287 - val_loss: 3460249660.8315\n",
      "Epoch 2324/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 893396148.5290 - val_loss: 3229724335.0504\n",
      "Epoch 2325/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 788678825.1300 - val_loss: 3261553901.4526\n",
      "Epoch 2326/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 808770807.9325 - val_loss: 4330225895.5162\n",
      "Epoch 2327/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1599863138.6697 - val_loss: 3909608682.1086\n",
      "Epoch 2328/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 868083836.5065 - val_loss: 2982439423.9820\n",
      "Epoch 2329/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1486800757.6275 - val_loss: 5679115699.2000\n",
      "Epoch 2330/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1144204296.0675 - val_loss: 3682257755.9584\n",
      "Epoch 2331/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2046971811.4215 - val_loss: 2954019237.4008\n",
      "Epoch 2332/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 760455383.1581 - val_loss: 4107860947.2810\n",
      "Epoch 2333/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 744747605.2403 - val_loss: 2996750804.7302\n",
      "Epoch 2334/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1142181009.6117 - val_loss: 3552161988.0326\n",
      "Epoch 2335/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 812813076.5290 - val_loss: 3122324597.7429\n",
      "Epoch 2336/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 681433245.3528 - val_loss: 3323061831.3271\n",
      "Epoch 2337/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 885373862.6449 - val_loss: 2965445825.0847\n",
      "Epoch 2338/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 834708320.4502 - val_loss: 3075733170.4844\n",
      "Epoch 2339/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 653916276.5470 - val_loss: 3365647772.4805\n",
      "Epoch 2340/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 825108030.7394 - val_loss: 3250290055.5432\n",
      "Epoch 2341/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 941603370.4986 - val_loss: 3013462768.3015\n",
      "Epoch 2342/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1291304576.8284 - val_loss: 3974135647.7750\n",
      "Epoch 2343/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 837466883.2414 - val_loss: 4236185391.4194\n",
      "Epoch 2344/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1056460437.9696 - val_loss: 3578132325.6259\n",
      "Epoch 2345/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1072982847.3427 - val_loss: 3520595034.7972\n",
      "Epoch 2346/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 849153647.2887 - val_loss: 4395962927.9820\n",
      "Epoch 2347/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 994917169.4136 - val_loss: 2855287757.8892\n",
      "Epoch 2348/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 913733148.1733 - val_loss: 4001426125.9702\n",
      "Epoch 2349/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 859263448.0585 - val_loss: 3542484868.6447\n",
      "Epoch 2350/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 816637570.7417 - val_loss: 3130666151.8897\n",
      "Epoch 2351/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1119457676.4615 - val_loss: 6732542304.6391\n",
      "Epoch 2352/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 978303948.8576 - val_loss: 7272519710.8928\n",
      "Epoch 2353/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1293148928.5763 - val_loss: 3013334501.7632\n",
      "Epoch 2354/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 810531569.2425 - val_loss: 3159868190.3302\n",
      "Epoch 2355/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 957292682.1564 - val_loss: 4123690619.5533\n",
      "Epoch 2356/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1084995189.9156 - val_loss: 3024624315.6073\n",
      "Epoch 2357/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1055697525.3934 - val_loss: 3196354812.8315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2358/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 775655484.5785 - val_loss: 2813141510.4990\n",
      "Epoch 2359/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 939851004.6145 - val_loss: 5763002287.1314\n",
      "Epoch 2360/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1214081256.4637 - val_loss: 3266265692.8405\n",
      "Epoch 2361/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1161815120.0270 - val_loss: 3288043733.0408\n",
      "Epoch 2362/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1304602928.9094 - val_loss: 4197683475.3710\n",
      "Epoch 2363/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 892694170.4356 - val_loss: 3599912458.2796\n",
      "Epoch 2364/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 909641992.9319 - val_loss: 4005708748.1879\n",
      "Epoch 2365/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1288319007.6939 - val_loss: 5435643120.8056\n",
      "Epoch 2366/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 962774881.4947 - val_loss: 3684695157.5404\n",
      "Epoch 2367/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 758169053.6522 - val_loss: 3164313301.6124\n",
      "Epoch 2368/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 910456907.0523 - val_loss: 3692986805.9904\n",
      "Epoch 2369/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 858537335.8604 - val_loss: 2726124186.6959\n",
      "Epoch 2370/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 792273939.9167 - val_loss: 3219961035.6298\n",
      "Epoch 2371/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 707607519.2257 - val_loss: 3609393137.3277\n",
      "Epoch 2372/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 741289205.3393 - val_loss: 3127134592.5761\n",
      "Epoch 2373/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1134102391.2842 - val_loss: 4287759821.0880\n",
      "Epoch 2374/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1725849581.8481 - val_loss: 3750394869.4143\n",
      "Epoch 2375/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 687675659.6151 - val_loss: 2953459750.7331\n",
      "Epoch 2376/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1029925492.6911 - val_loss: 3349212233.4335\n",
      "Epoch 2377/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1000363965.9111 - val_loss: 4258262960.4996\n",
      "Epoch 2378/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1141361461.5194 - val_loss: 2853247051.8368\n",
      "Epoch 2379/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 697137393.6657 - val_loss: 3739814321.4717\n",
      "Epoch 2380/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1041085454.9826 - val_loss: 7286375177.2534\n",
      "Epoch 2381/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2086084588.0113 - val_loss: 2764075561.6495\n",
      "Epoch 2382/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 715162071.1401 - val_loss: 3057848268.2239\n",
      "Epoch 2383/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 740381978.7597 - val_loss: 6603274831.5724\n",
      "Epoch 2384/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 949762852.0698 - val_loss: 3632787191.2326\n",
      "Epoch 2385/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 867392654.7755 - val_loss: 5568109072.1935\n",
      "Epoch 2386/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 829947175.4012 - val_loss: 3666545439.8740\n",
      "Epoch 2387/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 803336635.3461 - val_loss: 2905274928.8821\n",
      "Epoch 2388/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 703916376.3827 - val_loss: 3444417470.0377\n",
      "Epoch 2389/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1213315226.0394 - val_loss: 8001749564.8495\n",
      "Epoch 2390/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2442750487.9415 - val_loss: 3336535939.9651\n",
      "Epoch 2391/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 677936248.1486 - val_loss: 4535093451.5758\n",
      "Epoch 2392/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 981420858.8678 - val_loss: 3989553087.4059\n",
      "Epoch 2393/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1168395083.3450 - val_loss: 2923275227.2698\n",
      "Epoch 2394/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 638337507.6196 - val_loss: 2829919704.4838\n",
      "Epoch 2395/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 724999308.2814 - val_loss: 3079286986.9997\n",
      "Epoch 2396/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 743251001.0310 - val_loss: 3569789290.7927\n",
      "Epoch 2397/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 817237564.9747 - val_loss: 3019280798.4158\n",
      "Epoch 2398/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 648859415.3382 - val_loss: 2998621910.0084\n",
      "Epoch 2399/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 888232798.9443 - val_loss: 2884198656.9091\n",
      "Epoch 2400/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1468164615.6353 - val_loss: 2871609803.7738\n",
      "Epoch 2401/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 947119444.5830 - val_loss: 3585152379.6433\n",
      "Epoch 2402/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 687257054.6854 - val_loss: 3569464796.5705\n",
      "Epoch 2403/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 710285602.0709 - val_loss: 3099900866.9255\n",
      "Epoch 2404/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 682675298.8689 - val_loss: 2963535341.0430\n",
      "Epoch 2405/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 952199623.4553 - val_loss: 2977862825.5910\n",
      "Epoch 2406/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 984827205.5194 - val_loss: 3179557967.3924\n",
      "Epoch 2407/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1240466204.1823 - val_loss: 3037512112.0045\n",
      "Epoch 2408/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1013284765.6770 - val_loss: 3051715326.0017\n",
      "Epoch 2409/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 753945434.8407 - val_loss: 3388634268.8945\n",
      "Epoch 2410/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 753369369.3911 - val_loss: 3079279820.0439\n",
      "Epoch 2411/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1117581097.8278 - val_loss: 6149850060.1879\n",
      "Epoch 2412/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1469952528.2791 - val_loss: 3065999454.7848\n",
      "Epoch 2413/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 786943050.0844 - val_loss: 3372772944.5446\n",
      "Epoch 2414/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 708614145.3326 - val_loss: 2773931084.2239\n",
      "Epoch 2415/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 698250340.3084 - val_loss: 3038839658.0478\n",
      "Epoch 2416/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 735366408.8171 - val_loss: 2983749197.4211\n",
      "Epoch 2417/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1029287908.4840 - val_loss: 4542814580.9103\n",
      "Epoch 2418/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 775480849.8998 - val_loss: 3460721676.4489\n",
      "Epoch 2419/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1197925928.4322 - val_loss: 3124178036.2847\n",
      "Epoch 2420/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 699696825.8773 - val_loss: 3328916268.5120\n",
      "Epoch 2421/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 730420977.4856 - val_loss: 2855436104.4253\n",
      "Epoch 2422/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 802429172.4209 - val_loss: 3139996008.7854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2423/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 772493479.4012 - val_loss: 5919131820.1429\n",
      "Epoch 2424/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1851653630.9690 - val_loss: 3076718090.7477\n",
      "Epoch 2425/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 641778517.9111 - val_loss: 3225965940.8383\n",
      "Epoch 2426/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 717883997.9291 - val_loss: 4362657695.3249\n",
      "Epoch 2427/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1222470548.7811 - val_loss: 3230235514.1401\n",
      "Epoch 2428/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 704926209.0264 - val_loss: 2936868689.1657\n",
      "Epoch 2429/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 794946997.2583 - val_loss: 2894725117.2726\n",
      "Epoch 2430/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 715703937.1255 - val_loss: 2986302355.7221\n",
      "Epoch 2431/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 941021556.4750 - val_loss: 7464400142.1862\n",
      "Epoch 2432/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1048754505.4721 - val_loss: 10690866044.4354\n",
      "Epoch 2433/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1253982495.1896 - val_loss: 2908542553.6270\n",
      "Epoch 2434/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 807584936.4817 - val_loss: 5793422210.5564\n",
      "Epoch 2435/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 864406641.1705 - val_loss: 2929631998.7218\n",
      "Epoch 2436/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 617470349.2898 - val_loss: 2911200915.1775\n",
      "Epoch 2437/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1174344761.4451 - val_loss: 4377303200.6031\n",
      "Epoch 2438/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 736714488.6168 - val_loss: 4072314102.8546\n",
      "Epoch 2439/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 963818809.9133 - val_loss: 2901889202.7741\n",
      "Epoch 2440/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 706257326.9645 - val_loss: 4617723940.6537\n",
      "Epoch 2441/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1680500142.7124 - val_loss: 3124761758.4248\n",
      "Epoch 2442/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 799404691.1244 - val_loss: 3868868016.0675\n",
      "Epoch 2443/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 788181690.7777 - val_loss: 2893731832.1508\n",
      "Epoch 2444/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 655821517.4339 - val_loss: 5242244506.7162\n",
      "Epoch 2445/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1313111954.4761 - val_loss: 3306275230.5013\n",
      "Epoch 2446/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 980397591.9145 - val_loss: 3228860346.4371\n",
      "Epoch 2447/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 953575964.6325 - val_loss: 7078410641.6788\n",
      "Epoch 2448/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1227625129.9944 - val_loss: 6799517168.8056\n",
      "Epoch 2449/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2112872609.6207 - val_loss: 2912151232.9181\n",
      "Epoch 2450/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 585699054.2802 - val_loss: 3281471986.4979\n",
      "Epoch 2451/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 902486909.0737 - val_loss: 2794471767.7367\n",
      "Epoch 2452/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 634191742.1272 - val_loss: 2931982689.7463\n",
      "Epoch 2453/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 669226739.4170 - val_loss: 2927672176.4861\n",
      "Epoch 2454/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 798679110.3388 - val_loss: 4404132800.3421\n",
      "Epoch 2455/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 809834356.4524 - val_loss: 4066888599.4397\n",
      "Epoch 2456/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 872403725.6320 - val_loss: 5457643240.5243\n",
      "Epoch 2457/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 902772706.8092 - val_loss: 3715223236.0146\n",
      "Epoch 2458/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 895129136.8959 - val_loss: 3032842199.0976\n",
      "Epoch 2459/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 733480209.5037 - val_loss: 3704038600.3713\n",
      "Epoch 2460/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 731879026.8903 - val_loss: 3934261459.2090\n",
      "Epoch 2461/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 867653421.8841 - val_loss: 3090386997.0363\n",
      "Epoch 2462/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 747634540.7316 - val_loss: 3080317803.5128\n",
      "Epoch 2463/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 721511119.8075 - val_loss: 2716863052.9969\n",
      "Epoch 2464/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 686498175.8559 - val_loss: 3600969288.2048\n",
      "Epoch 2465/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 862725789.0287 - val_loss: 3713764078.5373\n",
      "Epoch 2466/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 988861266.4457 - val_loss: 4279681626.8422\n",
      "Epoch 2467/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 1408665811.7727 - val_loss: 5247339242.5046\n",
      "Epoch 2468/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1299113796.5875 - val_loss: 2749123889.2377\n",
      "Epoch 2469/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 589442424.7788 - val_loss: 4040672638.0917\n",
      "Epoch 2470/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1004716987.6151 - val_loss: 2907757585.2602\n",
      "Epoch 2471/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 577155292.4524 - val_loss: 2895737613.0430\n",
      "Epoch 2472/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 612752730.6156 - val_loss: 4809841118.8748\n",
      "Epoch 2473/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1159115371.7591 - val_loss: 3263508155.6703\n",
      "Epoch 2474/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1087354780.6685 - val_loss: 3665109740.6290\n",
      "Epoch 2475/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1029579201.1525 - val_loss: 2896410946.0163\n",
      "Epoch 2476/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 875625614.0461 - val_loss: 3854633817.7980\n",
      "Epoch 2477/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 848706047.1896 - val_loss: 3202061164.0709\n",
      "Epoch 2478/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 748963386.9218 - val_loss: 5158819469.2951\n",
      "Epoch 2479/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1020330686.7394 - val_loss: 4464998744.5378\n",
      "Epoch 2480/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1041054456.0383 - val_loss: 3130295348.3837\n",
      "Epoch 2481/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1338306776.9769 - val_loss: 2935253032.2453\n",
      "Epoch 2482/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1086104643.1334 - val_loss: 3381695707.9764\n",
      "Epoch 2483/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 973801931.9212 - val_loss: 3762063893.8149\n",
      "Epoch 2484/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1228199076.6640 - val_loss: 4346043960.4208\n",
      "Epoch 2485/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 792671794.7192 - val_loss: 2754071666.1131\n",
      "Epoch 2486/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 680280113.5577 - val_loss: 3804881349.9949\n",
      "Epoch 2487/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1208446522.9578 - val_loss: 4838756074.1806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2488/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 732276451.3450 - val_loss: 3549015223.3767\n",
      "Epoch 2489/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 675037259.2999 - val_loss: 2824999655.7592\n",
      "Epoch 2490/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 737835124.3489 - val_loss: 3580657479.9392\n",
      "Epoch 2491/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 631611862.1002 - val_loss: 3633184126.0017\n",
      "Epoch 2492/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 824100595.5025 - val_loss: 2867982209.8633\n",
      "Epoch 2493/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 933311571.7006 - val_loss: 2983477499.9032\n",
      "Epoch 2494/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1114020636.8531 - val_loss: 4616094939.5803\n",
      "Epoch 2495/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 777591571.7006 - val_loss: 2921323613.8037\n",
      "Epoch 2496/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 900977201.8278 - val_loss: 3011755736.2768\n",
      "Epoch 2497/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 913822086.7620 - val_loss: 2917660360.8866\n",
      "Epoch 2498/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 738897771.8672 - val_loss: 3676156558.4383\n",
      "Epoch 2499/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 929713360.6933 - val_loss: 3822546940.8315\n",
      "Epoch 2500/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 814579653.3483 - val_loss: 4129603097.6000\n",
      "Epoch 2501/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1029182666.9848 - val_loss: 3317014559.5679\n",
      "Epoch 2502/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 939808459.7051 - val_loss: 3454828775.1381\n",
      "Epoch 2503/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 983452821.6095 - val_loss: 3283899018.9817\n",
      "Epoch 2504/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 763152536.3827 - val_loss: 2896154148.1361\n",
      "Epoch 2505/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 852952876.8036 - val_loss: 3630662656.8574\n",
      "Epoch 2506/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1317830087.1311 - val_loss: 3160810362.1311\n",
      "Epoch 2507/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1026806591.8064 - val_loss: 3021888099.0695\n",
      "Epoch 2508/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 666161835.7952 - val_loss: 3180934436.1496\n",
      "Epoch 2509/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1040891363.8942 - val_loss: 2916316842.5406\n",
      "Epoch 2510/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 806395205.2943 - val_loss: 3000462837.7024\n",
      "Epoch 2511/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 624219508.3309 - val_loss: 5387104437.8284\n",
      "Epoch 2512/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 993300162.3770 - val_loss: 2834770060.9260\n",
      "Epoch 2513/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1131479487.8199 - val_loss: 5822743476.2442\n",
      "Epoch 2514/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 1079740836.7721 - val_loss: 3695275236.9958\n",
      "Epoch 2515/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1249902953.3101 - val_loss: 3265620599.8717\n",
      "Epoch 2516/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1005560772.3579 - val_loss: 2878381400.7179\n",
      "Epoch 2517/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 673834452.7811 - val_loss: 3011102546.7949\n",
      "Epoch 2518/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 691443095.4102 - val_loss: 6156951105.0262\n",
      "Epoch 2519/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1074009014.4558 - val_loss: 5226291756.5030\n",
      "Epoch 2520/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 886829951.4237 - val_loss: 3194046145.3952\n",
      "Epoch 2521/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 748584468.4209 - val_loss: 2920518744.1778\n",
      "Epoch 2522/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 795167322.1835 - val_loss: 4037918289.3907\n",
      "Epoch 2523/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 1058032338.3320 - val_loss: 6971962189.7722\n",
      "Epoch 2524/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1144204202.4423 - val_loss: 2652066536.0293\n",
      "Epoch 2525/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 669489165.3258 - val_loss: 3138093002.8557\n",
      "Epoch 2526/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 643556352.0540 - val_loss: 2676806197.6911\n",
      "Epoch 2527/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 571600377.0129 - val_loss: 3739800445.2996\n",
      "Epoch 2528/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1221434854.8610 - val_loss: 3343335678.2357\n",
      "Epoch 2529/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 741128218.5616 - val_loss: 3149706090.3966\n",
      "Epoch 2530/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 656072551.6533 - val_loss: 2955477396.7032\n",
      "Epoch 2531/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 701219093.1412 - val_loss: 3057503303.4127\n",
      "Epoch 2532/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 695633256.1508 - val_loss: 2850218771.7131\n",
      "Epoch 2533/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1685082048.4682 - val_loss: 4327099242.1356\n",
      "Epoch 2534/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1381688296.4097 - val_loss: 3134262678.0354\n",
      "Epoch 2535/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 647293281.7468 - val_loss: 2771413097.7845\n",
      "Epoch 2536/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 828012625.2515 - val_loss: 2897869963.3328\n",
      "Epoch 2537/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 833451654.5549 - val_loss: 3290152729.5280\n",
      "Epoch 2538/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 709188756.7271 - val_loss: 2941127143.3677\n",
      "Epoch 2539/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 765208669.0107 - val_loss: 2726036113.5437\n",
      "Epoch 2540/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1224667778.5031 - val_loss: 3308231790.3572\n",
      "Epoch 2541/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 920961837.0917 - val_loss: 4890825623.3316\n",
      "Epoch 2542/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 784691366.6494 - val_loss: 3083014501.5359\n",
      "Epoch 2543/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 737271984.9004 - val_loss: 3406646490.3741\n",
      "Epoch 2544/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 662286998.6472 - val_loss: 2834274108.9125\n",
      "Epoch 2545/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 848246546.6742 - val_loss: 3463721285.9049\n",
      "Epoch 2546/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 637085421.7040 - val_loss: 3147419900.3094\n",
      "Epoch 2547/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 769215852.2634 - val_loss: 4066099004.4174\n",
      "Epoch 2548/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 826965450.6066 - val_loss: 2916506865.3727\n",
      "Epoch 2549/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 916877927.3652 - val_loss: 2674582696.3983\n",
      "Epoch 2550/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1050140842.0304 - val_loss: 5230204968.5423\n",
      "Epoch 2551/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1139676622.7665 - val_loss: 4117461907.4205\n",
      "Epoch 2552/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1288258062.4063 - val_loss: 3745503124.5412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2553/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 700462090.2645 - val_loss: 3007482069.5224\n",
      "Epoch 2554/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 749684244.9882 - val_loss: 3255468890.2774\n",
      "Epoch 2555/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 588948836.5560 - val_loss: 2843847816.5288\n",
      "Epoch 2556/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 823665269.0512 - val_loss: 3317172653.9072\n",
      "Epoch 2557/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 631290601.9629 - val_loss: 2894309734.1255\n",
      "Epoch 2558/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 636148456.8779 - val_loss: 3554241492.8293\n",
      "Epoch 2559/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 1397745087.3157 - val_loss: 13000596632.6639\n",
      "Epoch 2560/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 2038532736.5549 - val_loss: 2758870564.9350\n",
      "Epoch 2561/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 642587033.4271 - val_loss: 2704926332.6875\n",
      "Epoch 2562/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 649706807.4643 - val_loss: 3155732868.2127\n",
      "Epoch 2563/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 632503343.6849 - val_loss: 2857723198.5058\n",
      "Epoch 2564/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 654436691.2234 - val_loss: 2681828524.8315\n",
      "Epoch 2565/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 817560159.0816 - val_loss: 3448349255.7952\n",
      "Epoch 2566/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 724700714.8182 - val_loss: 2805289393.0757\n",
      "Epoch 2567/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 763216244.8711 - val_loss: 3372632475.5803\n",
      "Epoch 2568/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 994294993.6837 - val_loss: 2998197565.7789\n",
      "Epoch 2569/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 729893653.7535 - val_loss: 2859967648.1440\n",
      "Epoch 2570/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 796854602.1925 - val_loss: 3608634292.8203\n",
      "Epoch 2571/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1840795369.3101 - val_loss: 3020097807.9595\n",
      "Epoch 2572/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 552946083.2054 - val_loss: 4228286025.4875\n",
      "Epoch 2573/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 742746327.9617 - val_loss: 2990085320.0990\n",
      "Epoch 2574/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 635076774.5369 - val_loss: 2848312761.6495\n",
      "Epoch 2575/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 776288916.4052 - val_loss: 3525842629.6799\n",
      "Epoch 2576/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 733769030.2667 - val_loss: 3543730081.1252\n",
      "Epoch 2577/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 659326846.6854 - val_loss: 3219176056.0428\n",
      "Epoch 2578/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 945670918.3208 - val_loss: 3122653981.0655\n",
      "Epoch 2579/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 926212086.8745 - val_loss: 2691950509.9027\n",
      "Epoch 2580/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 633602573.7760 - val_loss: 3171885382.5530\n",
      "Epoch 2581/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 980883977.3281 - val_loss: 3006629486.8613\n",
      "Epoch 2582/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1097977702.4828 - val_loss: 2775588137.9083\n",
      "Epoch 2583/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 699566491.2999 - val_loss: 5974876471.0886\n",
      "Epoch 2584/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 856892574.8655 - val_loss: 2922885589.6956\n",
      "Epoch 2585/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 912610975.4418 - val_loss: 4236512834.8264\n",
      "Epoch 2586/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 682297610.2825 - val_loss: 2818823030.1277\n",
      "Epoch 2587/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 835755019.4012 - val_loss: 2919717469.6821\n",
      "Epoch 2588/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 725542121.1086 - val_loss: 2637672215.6062\n",
      "Epoch 2589/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 770410321.8728 - val_loss: 4503233631.0188\n",
      "Epoch 2590/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 925706402.4671 - val_loss: 3646660622.9423\n",
      "Epoch 2591/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 1014152192.0720 - val_loss: 6993411050.4326\n",
      "Epoch 2592/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 763367672.6888 - val_loss: 4252952520.7539\n",
      "Epoch 2593/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 965349546.3545 - val_loss: 3444042395.1842\n",
      "Epoch 2594/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1107909978.5076 - val_loss: 2749542185.8025\n",
      "Epoch 2595/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 656371253.4114 - val_loss: 2817557940.5322\n",
      "Epoch 2596/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 792560776.9589 - val_loss: 2944307483.9764\n",
      "Epoch 2597/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 820865734.0236 - val_loss: 3071633235.1820\n",
      "Epoch 2598/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 758199103.1919 - val_loss: 2761528074.0591\n",
      "Epoch 2599/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 615428770.2150 - val_loss: 3737654766.1547\n",
      "Epoch 2600/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 914239440.5943 - val_loss: 2935576714.7072\n",
      "Epoch 2601/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 873354273.4947 - val_loss: 3549384480.0945\n",
      "Epoch 2602/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 795977947.9842 - val_loss: 3338235008.0270\n",
      "Epoch 2603/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 871106708.0248 - val_loss: 3201125853.6866\n",
      "Epoch 2604/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1564612974.1362 - val_loss: 3584589934.1772\n",
      "Epoch 2605/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1220494437.5577 - val_loss: 3106939053.9117\n",
      "Epoch 2606/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 583747159.4823 - val_loss: 2675813541.3165\n",
      "Epoch 2607/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 719693335.2662 - val_loss: 3216008033.4132\n",
      "Epoch 2608/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 705020264.4153 - val_loss: 3283777219.5736\n",
      "Epoch 2609/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 670866271.5138 - val_loss: 3041754077.0025\n",
      "Epoch 2610/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 865946128.0810 - val_loss: 3165462395.5488\n",
      "Epoch 2611/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 717421138.5841 - val_loss: 3195312575.7120\n",
      "Epoch 2612/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 709638492.6325 - val_loss: 6620462298.1941\n",
      "Epoch 2613/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1237361690.4356 - val_loss: 3409956068.3837\n",
      "Epoch 2614/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 719517767.8154 - val_loss: 2921595568.3105\n",
      "Epoch 2615/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1059124483.8402 - val_loss: 2900851400.1738\n",
      "Epoch 2616/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 623029582.9465 - val_loss: 2789837311.3429\n",
      "Epoch 2617/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 821285203.2729 - val_loss: 2787947223.9167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2618/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1397510244.3399 - val_loss: 3983048841.2534\n",
      "Epoch 2619/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 750431499.5611 - val_loss: 4018928483.4835\n",
      "Epoch 2620/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 716925709.9741 - val_loss: 5100474556.3994\n",
      "Epoch 2621/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 949318181.9809 - val_loss: 3412067465.9736\n",
      "Epoch 2622/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 592904397.3258 - val_loss: 2871910517.5674\n",
      "Epoch 2623/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 775345413.0422 - val_loss: 3786990495.3339\n",
      "Epoch 2624/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 680823848.4097 - val_loss: 3711783053.2051\n",
      "Epoch 2625/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 727044784.9814 - val_loss: 3191818101.8464\n",
      "Epoch 2626/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1192113702.3208 - val_loss: 10738009796.8428\n",
      "Epoch 2627/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2424264236.1373 - val_loss: 3718035633.7238\n",
      "Epoch 2628/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 996743965.5149 - val_loss: 3120419910.0669\n",
      "Epoch 2629/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 666787816.6978 - val_loss: 2823825224.1013\n",
      "Epoch 2630/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 620038989.1638 - val_loss: 2743320935.3063\n",
      "Epoch 2631/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 759315492.0878 - val_loss: 2711771591.0031\n",
      "Epoch 2632/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 651471327.3787 - val_loss: 3237612808.7269\n",
      "Epoch 2633/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 752441390.6944 - val_loss: 5067159638.4855\n",
      "Epoch 2634/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 728964943.3787 - val_loss: 2718700646.0264\n",
      "Epoch 2635/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 654566289.0715 - val_loss: 3067024876.6560\n",
      "Epoch 2636/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 891565824.7653 - val_loss: 5023579005.3716\n",
      "Epoch 2637/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1159418953.1840 - val_loss: 7502034885.3108\n",
      "Epoch 2638/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1167128875.9392 - val_loss: 3170615264.7291\n",
      "Epoch 2639/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 885872133.8571 - val_loss: 3129817152.9541\n",
      "Epoch 2640/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 591309189.4024 - val_loss: 4883417561.4380\n",
      "Epoch 2641/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 917812761.9133 - val_loss: 2864595837.9477\n",
      "Epoch 2642/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 828180805.2763 - val_loss: 4186994992.8596\n",
      "Epoch 2643/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 663373559.3562 - val_loss: 3775006627.9156\n",
      "Epoch 2644/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1026422309.5827 - val_loss: 2954858170.9682\n",
      "Epoch 2645/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 603999982.9645 - val_loss: 4457249976.7809\n",
      "Epoch 2646/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 765394466.3815 - val_loss: 2861186254.7466\n",
      "Epoch 2647/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 682960927.9820 - val_loss: 2898144365.2051\n",
      "Epoch 2648/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 826234157.0917 - val_loss: 3563371861.6034\n",
      "Epoch 2649/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 691874890.3365 - val_loss: 2819483222.9986\n",
      "Epoch 2650/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 865429537.2786 - val_loss: 4620637099.5308\n",
      "Epoch 2651/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1289596756.2769 - val_loss: 2804598035.8457\n",
      "Epoch 2652/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 671920907.2369 - val_loss: 3938217278.5418\n",
      "Epoch 2653/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 830821854.2893 - val_loss: 5185153830.9311\n",
      "Epoch 2654/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1469482917.8165 - val_loss: 18286760329.1814\n",
      "Epoch 2655/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2183236415.9280 - val_loss: 2783032273.3907\n",
      "Epoch 2656/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 648235829.4834 - val_loss: 4437343668.9643\n",
      "Epoch 2657/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1249121532.2544 - val_loss: 3708800634.4911\n",
      "Epoch 2658/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 758169136.8374 - val_loss: 3119332339.6411\n",
      "Epoch 2659/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 476919830.2150 - val_loss: 3262001478.3910\n",
      "Epoch 2660/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 708107718.1767 - val_loss: 2654276089.0689\n",
      "Epoch 2661/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 653408108.8396 - val_loss: 2875320904.1204\n",
      "Epoch 2662/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 488678285.9021 - val_loss: 3649985815.7637\n",
      "Epoch 2663/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 607947936.7743 - val_loss: 3060270413.6821\n",
      "Epoch 2664/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 642607256.0585 - val_loss: 3374860402.9840\n",
      "Epoch 2665/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1161035943.7074 - val_loss: 3351501860.6537\n",
      "Epoch 2666/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 886382005.8075 - val_loss: 2683722564.1581\n",
      "Epoch 2667/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 844748680.1035 - val_loss: 4137213219.9336\n",
      "Epoch 2668/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 762167541.1953 - val_loss: 2631426458.4484\n",
      "Epoch 2669/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 780676961.7468 - val_loss: 3930884391.6242\n",
      "Epoch 2670/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 946470592.9004 - val_loss: 16748913558.8636\n",
      "Epoch 2671/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2115738577.7288 - val_loss: 2996531740.9305\n",
      "Epoch 2672/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 570490568.6798 - val_loss: 2827441439.7390\n",
      "Epoch 2673/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 721205634.0439 - val_loss: 2954565319.2371\n",
      "Epoch 2674/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 666154526.2893 - val_loss: 3578379173.9139\n",
      "Epoch 2675/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 638937730.2330 - val_loss: 2809019466.4416\n",
      "Epoch 2676/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 628159156.7271 - val_loss: 3411165611.9449\n",
      "Epoch 2677/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 637283994.7777 - val_loss: 3386871361.1027\n",
      "Epoch 2678/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 825793194.4266 - val_loss: 12028909695.6039\n",
      "Epoch 2679/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1180637347.9437 - val_loss: 5860476796.6515\n",
      "Epoch 2680/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 876283640.1486 - val_loss: 2684054766.0515\n",
      "Epoch 2681/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 662948938.0034 - val_loss: 3407695524.5457\n",
      "Epoch 2682/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 767682249.6522 - val_loss: 2665093446.6790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2683/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1002278137.2290 - val_loss: 3070080610.6149\n",
      "Epoch 2684/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 812702603.9932 - val_loss: 4095974569.0104\n",
      "Epoch 2685/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 817971555.2954 - val_loss: 2978114018.7634\n",
      "Epoch 2686/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 855987647.4598 - val_loss: 4260249278.4698\n",
      "Epoch 2687/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1105572868.6460 - val_loss: 2834484803.1685\n",
      "Epoch 2688/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 648385715.0884 - val_loss: 3603260423.2011\n",
      "Epoch 2689/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 882509990.9690 - val_loss: 3576910841.6990\n",
      "Epoch 2690/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 705016840.5718 - val_loss: 2714973123.1797\n",
      "Epoch 2691/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 581500453.7850 - val_loss: 3580156522.9727\n",
      "Epoch 2692/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 803582619.6601 - val_loss: 4407636936.3713\n",
      "Epoch 2693/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 859130704.3151 - val_loss: 3479198949.1398\n",
      "Epoch 2694/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 586709760.9364 - val_loss: 4084614711.5927\n",
      "Epoch 2695/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 749775869.1187 - val_loss: 2713823380.0911\n",
      "Epoch 2696/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 714266104.2206 - val_loss: 3200103734.6385\n",
      "Epoch 2697/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1236823399.4733 - val_loss: 2898657811.0689\n",
      "Epoch 2698/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 535907454.4153 - val_loss: 4039904737.8993\n",
      "Epoch 2699/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 743710157.0017 - val_loss: 4473806936.5738\n",
      "Epoch 2700/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1085555100.0203 - val_loss: 2660535578.7972\n",
      "Epoch 2701/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 640539450.9826 - val_loss: 2683228696.5198\n",
      "Epoch 2702/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 591536887.2662 - val_loss: 2860371460.7347\n",
      "Epoch 2703/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 910602098.9623 - val_loss: 9940288003.0245\n",
      "Epoch 2704/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1202196246.0236 - val_loss: 2787503651.0627\n",
      "Epoch 2705/10000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 886268531.636 - 0s 102us/step - loss: 852036705.0985 - val_loss: 2775564593.4740\n",
      "Epoch 2706/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 778519348.9071 - val_loss: 3301596686.7533\n",
      "Epoch 2707/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 734485727.9820 - val_loss: 3613011306.4416\n",
      "Epoch 2708/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1008341592.1306 - val_loss: 2880887687.0211\n",
      "Epoch 2709/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1097636757.7985 - val_loss: 4780269619.9741\n",
      "Epoch 2710/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1203018915.4935 - val_loss: 2965002071.2776\n",
      "Epoch 2711/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 542669960.7518 - val_loss: 2808673128.9114\n",
      "Epoch 2712/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 626321383.9415 - val_loss: 3101698033.7778\n",
      "Epoch 2713/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 625414116.6280 - val_loss: 6031494994.0208\n",
      "Epoch 2714/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2098799012.1688 - val_loss: 2849701226.4236\n",
      "Epoch 2715/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 526902949.8075 - val_loss: 2752864274.5570\n",
      "Epoch 2716/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 593509817.1750 - val_loss: 2607809387.7446\n",
      "Epoch 2717/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 797160445.9831 - val_loss: 6579847939.8166\n",
      "Epoch 2718/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1317308100.2138 - val_loss: 3038365674.4326\n",
      "Epoch 2719/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1168033859.5881 - val_loss: 3048871746.4214\n",
      "Epoch 2720/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 603706274.4851 - val_loss: 2906576831.0729\n",
      "Epoch 2721/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 544792632.7608 - val_loss: 2817910015.2709\n",
      "Epoch 2722/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 718393783.7254 - val_loss: 2630299668.1035\n",
      "Epoch 2723/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 975121232.8914 - val_loss: 4846866801.0577\n",
      "Epoch 2724/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 918675485.8571 - val_loss: 3638389656.9519\n",
      "Epoch 2725/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 631668132.7361 - val_loss: 2815970556.1564\n",
      "Epoch 2726/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 694438008.0045 - val_loss: 3138699003.8774\n",
      "Epoch 2727/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1057005326.0822 - val_loss: 3045445106.8219\n",
      "Epoch 2728/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 723550855.4215 - val_loss: 3290767372.2599\n",
      "Epoch 2729/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 844728788.3939 - val_loss: 2696725214.6014\n",
      "Epoch 2730/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 712284576.0900 - val_loss: 2976777442.3314\n",
      "Epoch 2731/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 622737363.4665 - val_loss: 3319240796.4895\n",
      "Epoch 2732/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 713907669.5734 - val_loss: 4760062861.6641\n",
      "Epoch 2733/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1002986430.0912 - val_loss: 3392973330.4169\n",
      "Epoch 2734/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 633974290.3050 - val_loss: 3097859258.6532\n",
      "Epoch 2735/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 590988271.5048 - val_loss: 3911195616.7831\n",
      "Epoch 2736/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1258985732.9342 - val_loss: 2778709304.8461\n",
      "Epoch 2737/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 632075754.9308 - val_loss: 8067446663.4532\n",
      "Epoch 2738/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1361582896.5492 - val_loss: 2691349017.9241\n",
      "Epoch 2739/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 563908654.0281 - val_loss: 6152811457.4222\n",
      "Epoch 2740/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1192174384.3196 - val_loss: 4049373306.7072\n",
      "Epoch 2741/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 665160474.1384 - val_loss: 4901194613.3063\n",
      "Epoch 2742/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 855156986.6697 - val_loss: 3886811868.5345\n",
      "Epoch 2743/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 607878939.8762 - val_loss: 3564902068.9283\n",
      "Epoch 2744/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 581010852.3759 - val_loss: 2751622189.1241\n",
      "Epoch 2745/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 795156729.6612 - val_loss: 6882194925.1331\n",
      "Epoch 2746/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 881587109.1322 - val_loss: 2819537614.7308\n",
      "Epoch 2747/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 645936495.5048 - val_loss: 5211444647.3541\n",
      "Epoch 2748/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1120051180.0113 - val_loss: 2946180402.9345\n",
      "Epoch 2749/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 612107385.1570 - val_loss: 2861314874.9075\n",
      "Epoch 2750/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 597114975.8177 - val_loss: 2615147070.8737\n",
      "Epoch 2751/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 522529494.5954 - val_loss: 2994567252.4557\n",
      "Epoch 2752/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 610078012.3984 - val_loss: 2925479647.9280\n",
      "Epoch 2753/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 999176908.3309 - val_loss: 2614048210.1997\n",
      "Epoch 2754/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 552057312.8824 - val_loss: 4200371324.3094\n",
      "Epoch 2755/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1489017169.6837 - val_loss: 5082788327.9482\n",
      "Epoch 2756/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1026079566.7665 - val_loss: 2754126593.6383\n",
      "Epoch 2757/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 590537646.9645 - val_loss: 2731284073.9105\n",
      "Epoch 2758/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 639480573.6500 - val_loss: 2977169274.3876\n",
      "Epoch 2759/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 595695579.4260 - val_loss: 3202657860.2667\n",
      "Epoch 2760/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 643327127.2302 - val_loss: 4503475385.3390\n",
      "Epoch 2761/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 645365619.9167 - val_loss: 2986782781.6776\n",
      "Epoch 2762/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 716301973.6815 - val_loss: 2818382500.5637\n",
      "Epoch 2763/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1074996782.8205 - val_loss: 3360380048.9226\n",
      "Epoch 2764/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1064983186.6922 - val_loss: 3071746737.0037\n",
      "Epoch 2765/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 639281027.2189 - val_loss: 2851479976.5603\n",
      "Epoch 2766/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 599743620.0338 - val_loss: 2966784566.0714\n",
      "Epoch 2767/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 650511006.1812 - val_loss: 2836807522.8895\n",
      "Epoch 2768/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 559281483.3450 - val_loss: 3118561505.5392\n",
      "Epoch 2769/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 730402920.3376 - val_loss: 2618282028.1699\n",
      "Epoch 2770/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 451417195.0929 - val_loss: 3082432969.7125\n",
      "Epoch 2771/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1047987661.7940 - val_loss: 3213585932.5030\n",
      "Epoch 2772/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 1134243533.4609 - val_loss: 7486151755.6118\n",
      "Epoch 2773/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 824667942.8970 - val_loss: 2589365340.4039\n",
      "Epoch 2774/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 867060870.1947 - val_loss: 3200054311.6782\n",
      "Epoch 2775/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 527289726.0011 - val_loss: 4494599361.1702\n",
      "Epoch 2776/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 656366937.6072 - val_loss: 3662559979.6568\n",
      "Epoch 2777/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 908721512.5898 - val_loss: 3300952019.0830\n",
      "Epoch 2778/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 730852633.8053 - val_loss: 2826641670.2650\n",
      "Epoch 2779/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 548667482.7507 - val_loss: 2614309444.5952\n",
      "Epoch 2780/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 699722063.6185 - val_loss: 3040718792.2363\n",
      "Epoch 2781/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 735755478.2938 - val_loss: 3130357753.7350\n",
      "Epoch 2782/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 642731400.6438 - val_loss: 2726940061.2591\n",
      "Epoch 2783/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 774351320.7068 - val_loss: 2983967693.0520\n",
      "Epoch 2784/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 551703227.1289 - val_loss: 3521602641.9308\n",
      "Epoch 2785/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 660111567.1626 - val_loss: 5032509808.6976\n",
      "Epoch 2786/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 852652661.1908 - val_loss: 2747293449.9488\n",
      "Epoch 2787/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 678323672.8959 - val_loss: 2683369424.9226\n",
      "Epoch 2788/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 787764816.5650 - val_loss: 3040563523.7986\n",
      "Epoch 2789/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 548831175.6804 - val_loss: 4144706450.9300\n",
      "Epoch 2790/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 677474731.0073 - val_loss: 3092707599.2664\n",
      "Epoch 2791/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 730525387.7051 - val_loss: 3179865004.0191\n",
      "Epoch 2792/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1114905223.5633 - val_loss: 4025797199.9325\n",
      "Epoch 2793/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1144356263.1851 - val_loss: 2976589399.9977\n",
      "Epoch 2794/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 544501422.5684 - val_loss: 3223350504.4343\n",
      "Epoch 2795/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 681229197.3258 - val_loss: 4884228087.3587\n",
      "Epoch 2796/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 804967189.9156 - val_loss: 2613445965.5261\n",
      "Epoch 2797/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 686134387.8807 - val_loss: 3040958696.0788\n",
      "Epoch 2798/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 900248036.9612 - val_loss: 3112632155.3103\n",
      "Epoch 2799/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 671590187.0748 - val_loss: 3082599889.5501\n",
      "Epoch 2800/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 792736610.5391 - val_loss: 7056641031.2911\n",
      "Epoch 2801/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1187971207.1311 - val_loss: 2948625655.5567\n",
      "Epoch 2802/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 522353716.5650 - val_loss: 2649484475.3103\n",
      "Epoch 2803/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 850407564.9657 - val_loss: 6957306199.2236\n",
      "Epoch 2804/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1703970492.0023 - val_loss: 2927469478.9783\n",
      "Epoch 2805/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 565656304.7293 - val_loss: 5107915703.1606\n",
      "Epoch 2806/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1095034120.7878 - val_loss: 4408226927.5094\n",
      "Epoch 2807/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 737946567.6353 - val_loss: 4356516642.1333\n",
      "Epoch 2808/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 586899785.8323 - val_loss: 2956610443.3778\n",
      "Epoch 2809/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 630744413.4969 - val_loss: 2661025637.5404\n",
      "Epoch 2810/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 448381523.4845 - val_loss: 3137349023.9280\n",
      "Epoch 2811/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 577881086.1677 - val_loss: 2877148421.4729\n",
      "Epoch 2812/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 81us/step - loss: 650742297.9313 - val_loss: 3202110704.1755\n",
      "Epoch 2813/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 843217899.4350 - val_loss: 4579084119.5657\n",
      "Epoch 2814/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 917373013.7895 - val_loss: 3496990423.8897\n",
      "Epoch 2815/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 699498711.0861 - val_loss: 9226422615.9257\n",
      "Epoch 2816/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1740052753.8638 - val_loss: 3635998532.3027\n",
      "Epoch 2817/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 650217779.6466 - val_loss: 2987975514.6892\n",
      "Epoch 2818/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 545314573.1322 - val_loss: 2908940491.3508\n",
      "Epoch 2819/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 685767577.6162 - val_loss: 3820775532.3927\n",
      "Epoch 2820/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 715453506.1249 - val_loss: 2803625046.6295\n",
      "Epoch 2821/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 570868410.4896 - val_loss: 3109428045.4121\n",
      "Epoch 2822/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 952837445.7265 - val_loss: 5809926674.5789\n",
      "Epoch 2823/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 923333987.5476 - val_loss: 2766956130.2864\n",
      "Epoch 2824/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 615213136.5582 - val_loss: 4146207174.3370\n",
      "Epoch 2825/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 662226606.4828 - val_loss: 2569801906.1288\n",
      "Epoch 2826/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 708496582.0146 - val_loss: 3059579833.3300\n",
      "Epoch 2827/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 606221916.8486 - val_loss: 2671474077.3671\n",
      "Epoch 2828/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 486615452.1643 - val_loss: 3119846772.0956\n",
      "Epoch 2829/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 592718940.7406 - val_loss: 3369973047.1876\n",
      "Epoch 2830/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 782634006.9060 - val_loss: 4177205311.9820\n",
      "Epoch 2831/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 793805299.1784 - val_loss: 5285932501.5134\n",
      "Epoch 2832/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1507072317.3979 - val_loss: 2645393448.5120\n",
      "Epoch 2833/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 680413718.9465 - val_loss: 2649091639.0976\n",
      "Epoch 2834/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 724177889.9629 - val_loss: 2973028655.8703\n",
      "Epoch 2835/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 565796406.4558 - val_loss: 2914549123.5646\n",
      "Epoch 2836/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1585590332.9387 - val_loss: 4285439750.6250\n",
      "Epoch 2837/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 953882361.9223 - val_loss: 3059329630.8388\n",
      "Epoch 2838/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 510883313.8458 - val_loss: 2613215855.5567\n",
      "Epoch 2839/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 754065942.0416 - val_loss: 2942902152.8214\n",
      "Epoch 2840/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 868176684.0090 - val_loss: 4583729246.5868\n",
      "Epoch 2841/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 772793656.6888 - val_loss: 3050054396.8495\n",
      "Epoch 2842/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 678368367.1086 - val_loss: 2610352371.5224\n",
      "Epoch 2843/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 595843751.3292 - val_loss: 3062883706.0546\n",
      "Epoch 2844/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 509416054.3478 - val_loss: 3013066374.6745\n",
      "Epoch 2845/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1034823298.8813 - val_loss: 6748595818.2886\n",
      "Epoch 2846/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 892679039.8469 - val_loss: 3038192401.4110\n",
      "Epoch 2847/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 729258626.6652 - val_loss: 4423958952.2903\n",
      "Epoch 2848/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1185419581.0827 - val_loss: 3567822360.0158\n",
      "Epoch 2849/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 880901517.5599 - val_loss: 3106049410.1963\n",
      "Epoch 2850/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 955109662.4423 - val_loss: 3051305972.9733\n",
      "Epoch 2851/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 477353377.8548 - val_loss: 2734730122.2796\n",
      "Epoch 2852/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 524365896.9859 - val_loss: 4375394483.0200\n",
      "Epoch 2853/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 614049573.0962 - val_loss: 3449204563.1100\n",
      "Epoch 2854/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 538334814.3410 - val_loss: 2735248335.8965\n",
      "Epoch 2855/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 636088697.7569 - val_loss: 3582467616.8371\n",
      "Epoch 2856/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 757471584.2341 - val_loss: 3111622615.1246\n",
      "Epoch 2857/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 568169084.1103 - val_loss: 2567301962.6644\n",
      "Epoch 2858/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 899586750.8835 - val_loss: 3416842398.4248\n",
      "Epoch 2859/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 640885326.6584 - val_loss: 2818993730.6284\n",
      "Epoch 2860/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 654060552.2836 - val_loss: 2954181590.6475\n",
      "Epoch 2861/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1337035488.2341 - val_loss: 3627975408.6256\n",
      "Epoch 2862/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 709003105.5037 - val_loss: 2636594860.2217\n",
      "Epoch 2863/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 481003287.1401 - val_loss: 2692389403.5758\n",
      "Epoch 2864/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 508393480.6798 - val_loss: 2876054486.5170\n",
      "Epoch 2865/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 646086840.3286 - val_loss: 3332742729.0937\n",
      "Epoch 2866/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 674723232.6483 - val_loss: 2642385685.4368\n",
      "Epoch 2867/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 528860531.8177 - val_loss: 2786435215.7255\n",
      "Epoch 2868/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 714174246.2487 - val_loss: 2926738543.6377\n",
      "Epoch 2869/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 915685049.7062 - val_loss: 3857983742.5598\n",
      "Epoch 2870/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 620623796.5830 - val_loss: 2704061805.7035\n",
      "Epoch 2871/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 714148449.2425 - val_loss: 4141438355.8391\n",
      "Epoch 2872/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1255482340.4479 - val_loss: 2969983556.2847\n",
      "Epoch 2873/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 588583135.1626 - val_loss: 2639761948.7685\n",
      "Epoch 2874/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 669931876.0158 - val_loss: 2823127132.0304\n",
      "Epoch 2875/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 619670912.0000 - val_loss: 3137442239.2799\n",
      "Epoch 2876/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 672231757.7220 - val_loss: 3161114300.1384\n",
      "Epoch 2877/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 83us/step - loss: 753045593.0670 - val_loss: 4359995690.9547\n",
      "Epoch 2878/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 714590749.6410 - val_loss: 2791078024.4118\n",
      "Epoch 2879/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 600605298.9623 - val_loss: 3050893791.3834\n",
      "Epoch 2880/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1491915512.9049 - val_loss: 2805073970.6127\n",
      "Epoch 2881/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 511516025.2347 - val_loss: 2529997877.4323\n",
      "Epoch 2882/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 440501064.4277 - val_loss: 2562383871.8442\n",
      "Epoch 2883/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 925833113.4631 - val_loss: 2968052972.9395\n",
      "Epoch 2884/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 581338470.3391 - val_loss: 2627496037.7468\n",
      "Epoch 2885/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 541889616.4232 - val_loss: 3212394882.4529\n",
      "Epoch 2886/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 834998877.1728 - val_loss: 8117245978.3561\n",
      "Epoch 2887/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1142871452.5245 - val_loss: 4257075989.1713\n",
      "Epoch 2888/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1102458602.9938 - val_loss: 2756525854.6948\n",
      "Epoch 2889/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 468550065.8158 - val_loss: 2724429752.6301\n",
      "Epoch 2890/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 485907002.7597 - val_loss: 3607263381.4413\n",
      "Epoch 2891/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 589703466.7732 - val_loss: 2688516817.2647\n",
      "Epoch 2892/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 746982541.2898 - val_loss: 5089881970.1108\n",
      "Epoch 2893/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 749320627.8492 - val_loss: 3037643252.6582\n",
      "Epoch 2894/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 490889295.5228 - val_loss: 2871804292.6807\n",
      "Epoch 2895/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 735388581.8706 - val_loss: 4951452205.2231\n",
      "Epoch 2896/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 687935788.7316 - val_loss: 3229523331.0504\n",
      "Epoch 2897/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 764909610.6066 - val_loss: 3552812244.5232\n",
      "Epoch 2898/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 807438274.6292 - val_loss: 8127271854.1232\n",
      "Epoch 2899/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1128557866.7867 - val_loss: 9379958714.9412\n",
      "Epoch 2900/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1110494046.9375 - val_loss: 2848576330.4281\n",
      "Epoch 2901/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 660151631.7389 - val_loss: 2639518093.7722\n",
      "Epoch 2902/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 552403066.0934 - val_loss: 2990020273.5797\n",
      "Epoch 2903/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 471373472.3421 - val_loss: 3821699907.6546\n",
      "Epoch 2904/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 822256722.0878 - val_loss: 2889930778.5271\n",
      "Epoch 2905/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 665774912.6843 - val_loss: 5494574614.9716\n",
      "Epoch 2906/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1259244914.0664 - val_loss: 11904759776.3151\n",
      "Epoch 2907/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2109311279.4328 - val_loss: 2603712587.0267\n",
      "Epoch 2908/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 517669448.7338 - val_loss: 2633058344.7741\n",
      "Epoch 2909/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 486157170.9893 - val_loss: 3319445897.1094\n",
      "Epoch 2910/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 518869641.0039 - val_loss: 3857038457.0869\n",
      "Epoch 2911/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 887338462.8115 - val_loss: 5816427947.8909\n",
      "Epoch 2912/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 841973753.9854 - val_loss: 2711728752.5536\n",
      "Epoch 2913/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 444856019.8267 - val_loss: 3057576736.5851\n",
      "Epoch 2914/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 573831326.7575 - val_loss: 3334144196.7077\n",
      "Epoch 2915/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 613557674.7147 - val_loss: 3115440844.3049\n",
      "Epoch 2916/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 453996641.1435 - val_loss: 3862212212.2622\n",
      "Epoch 2917/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1020476935.4192 - val_loss: 2882704541.7491\n",
      "Epoch 2918/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 638290906.7327 - val_loss: 3335047022.1052\n",
      "Epoch 2919/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 459945409.9809 - val_loss: 3874206737.4987\n",
      "Epoch 2920/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1220789932.0113 - val_loss: 2844744670.7128\n",
      "Epoch 2921/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 492895721.9584 - val_loss: 4981084723.4880\n",
      "Epoch 2922/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 780298181.0827 - val_loss: 3853553859.4745\n",
      "Epoch 2923/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 564497865.6882 - val_loss: 3020058081.5572\n",
      "Epoch 2924/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 543753028.9342 - val_loss: 9002526052.3837\n",
      "Epoch 2925/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1718038391.1761 - val_loss: 3926967391.0549\n",
      "Epoch 2926/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 746951255.1581 - val_loss: 3318000361.3975\n",
      "Epoch 2927/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 636376172.6685 - val_loss: 2568333307.1032\n",
      "Epoch 2928/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 387721270.5819 - val_loss: 2698065474.4619\n",
      "Epoch 2929/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 738674221.9201 - val_loss: 7700628841.4245\n",
      "Epoch 2930/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 794227881.0670 - val_loss: 2531928729.5617\n",
      "Epoch 2931/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 479022113.9809 - val_loss: 4412741788.6425\n",
      "Epoch 2932/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 566367836.3444 - val_loss: 2939911091.9291\n",
      "Epoch 2933/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 585148202.6967 - val_loss: 4916247837.2726\n",
      "Epoch 2934/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 737497242.5076 - val_loss: 2835377244.1339\n",
      "Epoch 2935/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 748486007.6624 - val_loss: 3782120296.3803\n",
      "Epoch 2936/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1211810270.5053 - val_loss: 3174601509.8779\n",
      "Epoch 2937/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1016156810.2487 - val_loss: 3488717502.1817\n",
      "Epoch 2938/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 534898879.7794 - val_loss: 2901715872.4771\n",
      "Epoch 2939/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 510027575.2482 - val_loss: 4152658505.3075\n",
      "Epoch 2940/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 632204661.6995 - val_loss: 2945880430.0737\n",
      "Epoch 2941/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 415439811.2774 - val_loss: 2698321230.0197\n",
      "Epoch 2942/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 96us/step - loss: 430178587.1581 - val_loss: 2791809614.4923\n",
      "Epoch 2943/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 601458112.9724 - val_loss: 4887592414.6138\n",
      "Epoch 2944/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 753102005.1052 - val_loss: 2545794200.4771\n",
      "Epoch 2945/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 628922722.8272 - val_loss: 3963943036.1474\n",
      "Epoch 2946/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1209103585.1705 - val_loss: 6245042978.5654\n",
      "Epoch 2947/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 865340218.1654 - val_loss: 2576324382.5238\n",
      "Epoch 2948/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 594954927.5408 - val_loss: 3841130638.9423\n",
      "Epoch 2949/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 607084481.4696 - val_loss: 2857291459.3902\n",
      "Epoch 2950/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 568549063.3607 - val_loss: 2786797926.5080\n",
      "Epoch 2951/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 842774479.3427 - val_loss: 2999732811.0357\n",
      "Epoch 2952/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 782454936.3467 - val_loss: 2760425892.4940\n",
      "Epoch 2953/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 702743860.0270 - val_loss: 3985231310.5733\n",
      "Epoch 2954/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 735103482.0214 - val_loss: 5988350712.5828\n",
      "Epoch 2955/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 997287262.0371 - val_loss: 2693396317.9522\n",
      "Epoch 2956/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 578583311.5588 - val_loss: 4007313968.5986\n",
      "Epoch 2957/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1380352542.3433 - val_loss: 4882381390.1322\n",
      "Epoch 2958/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 673934569.6702 - val_loss: 4158469307.5893\n",
      "Epoch 2959/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 922592382.9871 - val_loss: 2663763369.1904\n",
      "Epoch 2960/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 819020691.2324 - val_loss: 3391218800.9316\n",
      "Epoch 2961/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 574935561.4631 - val_loss: 3234205463.0796\n",
      "Epoch 2962/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 542391371.9932 - val_loss: 3269781103.1314\n",
      "Epoch 2963/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 509986091.9932 - val_loss: 2623054634.6160\n",
      "Epoch 2964/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 436917301.8436 - val_loss: 3134363352.8934\n",
      "Epoch 2965/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 488962951.8694 - val_loss: 2675308001.8273\n",
      "Epoch 2966/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 785951539.5003 - val_loss: 2659547923.4025\n",
      "Epoch 2967/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 406936757.0197 - val_loss: 2613803090.7049\n",
      "Epoch 2968/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1243630434.3545 - val_loss: 3612754579.9291\n",
      "Epoch 2969/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 625210084.1148 - val_loss: 2721053935.9190\n",
      "Epoch 2970/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 524566267.2459 - val_loss: 2737088408.4478\n",
      "Epoch 2971/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 586622595.2999 - val_loss: 2663258329.3120\n",
      "Epoch 2972/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 459005624.6348 - val_loss: 3372211512.9429\n",
      "Epoch 2973/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 568276456.6978 - val_loss: 2922572566.6475\n",
      "Epoch 2974/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 799217107.2864 - val_loss: 2645840326.3640\n",
      "Epoch 2975/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 693837941.0422 - val_loss: 3053335812.1406\n",
      "Epoch 2976/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 495666727.3292 - val_loss: 2808118443.7648\n",
      "Epoch 2977/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 702680326.1418 - val_loss: 4011177932.1519\n",
      "Epoch 2978/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 999600245.0872 - val_loss: 2564964452.5761\n",
      "Epoch 2979/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 624538420.2949 - val_loss: 3357392581.2388\n",
      "Epoch 2980/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 567700157.0107 - val_loss: 2597784378.7792\n",
      "Epoch 2981/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 457249275.9302 - val_loss: 4869535749.1848\n",
      "Epoch 2982/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 1556017922.5211 - val_loss: 4144422371.3395\n",
      "Epoch 2983/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 579204456.1936 - val_loss: 2856407522.6284\n",
      "Epoch 2984/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 413868005.7895 - val_loss: 2776755502.7443\n",
      "Epoch 2985/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 650514683.7625 - val_loss: 4043507749.0138\n",
      "Epoch 2986/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 788481899.7231 - val_loss: 2902268280.5063\n",
      "Epoch 2987/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 548508817.5937 - val_loss: 3787831490.3764\n",
      "Epoch 2988/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 691650803.1064 - val_loss: 3274208050.8489\n",
      "Epoch 2989/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 731995912.1936 - val_loss: 2904107753.6630\n",
      "Epoch 2990/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 617597784.4457 - val_loss: 2703040731.0402\n",
      "Epoch 2991/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 426136520.0135 - val_loss: 2621402499.4565\n",
      "Epoch 2992/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 646805625.4451 - val_loss: 8487643055.4914\n",
      "Epoch 2993/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 1843089359.3742 - val_loss: 2593132213.5224\n",
      "Epoch 2994/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 465070985.8503 - val_loss: 2572389540.3882\n",
      "Epoch 2995/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 500009055.2437 - val_loss: 3635733142.5125\n",
      "Epoch 2996/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 609048897.3326 - val_loss: 2786881640.8574\n",
      "Epoch 2997/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 833823752.3917 - val_loss: 4316769888.8551\n",
      "Epoch 2998/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 458455411.9527 - val_loss: 3118393193.8025\n",
      "Epoch 2999/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 615131615.9460 - val_loss: 3178697267.9111\n",
      "Epoch 3000/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 585416854.6179 - val_loss: 2837314709.2231\n",
      "Epoch 3001/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 634445165.1277 - val_loss: 3572094376.5243\n",
      "Epoch 3002/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 897737368.0225 - val_loss: 2570478539.5837\n",
      "Epoch 3003/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 449719725.4519 - val_loss: 2513806143.7840\n",
      "Epoch 3004/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 463391550.7361 - val_loss: 2589478241.9893\n",
      "Epoch 3005/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 535893824.5402 - val_loss: 2597208222.2672\n",
      "Epoch 3006/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 780904181.2673 - val_loss: 3395872672.7021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3007/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 905846242.6111 - val_loss: 2870402520.4298\n",
      "Epoch 3008/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 705456853.5104 - val_loss: 5584099419.5263\n",
      "Epoch 3009/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 934033090.1970 - val_loss: 2721161270.1525\n",
      "Epoch 3010/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 507005960.2116 - val_loss: 3712622884.0653\n",
      "Epoch 3011/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 735312887.9325 - val_loss: 4634626540.3319\n",
      "Epoch 3012/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 975219561.9313 - val_loss: 2603943345.5167\n",
      "Epoch 3013/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 544813187.7817 - val_loss: 2751873729.9983\n",
      "Epoch 3014/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 664275816.6258 - val_loss: 2829252270.6993\n",
      "Epoch 3015/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 410345703.8154 - val_loss: 4101744193.8093\n",
      "Epoch 3016/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 796464938.0664 - val_loss: 2638141488.7786\n",
      "Epoch 3017/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 488466727.0974 - val_loss: 2535582529.8633\n",
      "Epoch 3018/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 455124294.0146 - val_loss: 3848899648.7831\n",
      "Epoch 3019/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 1285012178.6697 - val_loss: 4247179615.1269\n",
      "Epoch 3020/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 776962368.4232 - val_loss: 2591317504.4681\n",
      "Epoch 3021/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 425994518.2893 - val_loss: 3209520669.8622\n",
      "Epoch 3022/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 613343575.1221 - val_loss: 2967685183.0368\n",
      "Epoch 3023/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 679245201.0535 - val_loss: 2624531313.0577\n",
      "Epoch 3024/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 421060592.2881 - val_loss: 2457476228.8203\n",
      "Epoch 3025/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 729812900.0158 - val_loss: 3298905397.0363\n",
      "Epoch 3026/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 794665513.0219 - val_loss: 2636644652.3741\n",
      "Epoch 3027/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 544227125.6545 - val_loss: 2762344190.0940\n",
      "Epoch 3028/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 490652366.8700 - val_loss: 2720467002.6352\n",
      "Epoch 3029/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 536371923.3405 - val_loss: 3361564839.3271\n",
      "Epoch 3030/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 563778027.2549 - val_loss: 2638792539.1662\n",
      "Epoch 3031/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 882408143.7029 - val_loss: 3359339796.8113\n",
      "Epoch 3032/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1216164420.8621 - val_loss: 3746275213.4301\n",
      "Epoch 3033/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1094640011.8312 - val_loss: 2659851078.8399\n",
      "Epoch 3034/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 465087889.6477 - val_loss: 2662686620.1879\n",
      "Epoch 3035/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 430860789.8436 - val_loss: 3569652803.8706\n",
      "Epoch 3036/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 979100769.9629 - val_loss: 3021630933.8419\n",
      "Epoch 3037/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 539118170.9038 - val_loss: 2772982761.2242\n",
      "Epoch 3038/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 664968257.5847 - val_loss: 2631366235.1145\n",
      "Epoch 3039/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 510190627.5476 - val_loss: 3050902892.4850\n",
      "Epoch 3040/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 779301611.1469 - val_loss: 2600647197.6124\n",
      "Epoch 3041/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 635146409.0940 - val_loss: 2697714063.5364\n",
      "Epoch 3042/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 492683947.5431 - val_loss: 9392613242.8872\n",
      "Epoch 3043/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1514209110.7980 - val_loss: 4771911442.0748\n",
      "Epoch 3044/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1550960316.1823 - val_loss: 2810423907.5195\n",
      "Epoch 3045/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 453990242.9308 - val_loss: 2558096335.5769\n",
      "Epoch 3046/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 409307626.7507 - val_loss: 3134244090.0231\n",
      "Epoch 3047/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 413514311.4012 - val_loss: 2614635303.1314\n",
      "Epoch 3048/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 473226311.3112 - val_loss: 2729303025.8813\n",
      "Epoch 3049/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 677887942.8070 - val_loss: 2684198041.2579\n",
      "Epoch 3050/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 617144692.0923 - val_loss: 2825422504.9249\n",
      "Epoch 3051/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 395092308.5650 - val_loss: 3794661235.6861\n",
      "Epoch 3052/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 501494115.2774 - val_loss: 2604042933.7384\n",
      "Epoch 3053/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 699054437.1052 - val_loss: 2899054933.9229\n",
      "Epoch 3054/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1000293741.1187 - val_loss: 2786957720.7719\n",
      "Epoch 3055/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 498378399.4958 - val_loss: 2567000392.3196\n",
      "Epoch 3056/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 613161779.7907 - val_loss: 3343848083.7131\n",
      "Epoch 3057/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 499692654.6314 - val_loss: 2981039144.3623\n",
      "Epoch 3058/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 676530356.2949 - val_loss: 2890675373.2411\n",
      "Epoch 3059/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 1134505387.9302 - val_loss: 2691636799.3159\n",
      "Epoch 3060/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 488681920.4232 - val_loss: 3472815444.4602\n",
      "Epoch 3061/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 661015703.8965 - val_loss: 4726264806.6520\n",
      "Epoch 3062/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 841366305.2966 - val_loss: 3744325530.5722\n",
      "Epoch 3063/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 821127364.1688 - val_loss: 2638602753.2788\n",
      "Epoch 3064/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 359446180.0428 - val_loss: 2648544381.5876\n",
      "Epoch 3065/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 565321227.0208 - val_loss: 3016422056.1823\n",
      "Epoch 3066/10000\n",
      "3554/3554 [==============================] - 0s 130us/step - loss: 451277899.4890 - val_loss: 2750350150.8591\n",
      "Epoch 3067/10000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 484083212.0698 - val_loss: 2731557091.9617\n",
      "Epoch 3068/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 629001174.8700 - val_loss: 3203851952.4962\n",
      "Epoch 3069/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 540133011.3765 - val_loss: 4686610966.5215\n",
      "Epoch 3070/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 827910410.6967 - val_loss: 3570646540.1699\n",
      "Epoch 3071/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 647702772.3939 - val_loss: 3423689770.2459\n",
      "Epoch 3072/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 836142138.8137 - val_loss: 5232573478.3820\n",
      "Epoch 3073/10000\n",
      "3554/3554 [==============================] - 0s 140us/step - loss: 657954646.7980 - val_loss: 4095672045.5651\n",
      "Epoch 3074/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 694955941.7490 - val_loss: 2836548834.3404\n",
      "Epoch 3075/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 475687383.2380 - val_loss: 3072833212.3634\n",
      "Epoch 3076/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 468918041.3573 - val_loss: 3762707079.3091\n",
      "Epoch 3077/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 733816167.8694 - val_loss: 3007027211.7378\n",
      "Epoch 3078/10000\n",
      "3554/3554 [==============================] - 0s 136us/step - loss: 829159392.1981 - val_loss: 2666963994.4731\n",
      "Epoch 3079/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 724915837.2628 - val_loss: 2557007365.9769\n",
      "Epoch 3080/10000\n",
      "3554/3554 [==============================] - 1s 147us/step - loss: 435570377.3641 - val_loss: 2573188090.5812\n",
      "Epoch 3081/10000\n",
      "3554/3554 [==============================] - 0s 138us/step - loss: 442225763.4800 - val_loss: 2757209244.3859\n",
      "Epoch 3082/10000\n",
      "3554/3554 [==============================] - 1s 148us/step - loss: 404291027.1784 - val_loss: 3273629939.5060\n",
      "Epoch 3083/10000\n",
      "3554/3554 [==============================] - 1s 149us/step - loss: 621514301.8810 - val_loss: 3065514423.2326\n",
      "Epoch 3084/10000\n",
      "3554/3554 [==============================] - 1s 152us/step - loss: 485869839.0546 - val_loss: 5037120286.4608\n",
      "Epoch 3085/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 1556561013.7355 - val_loss: 2921775388.2419\n",
      "Epoch 3086/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 702943852.1193 - val_loss: 5655606201.0509\n",
      "Epoch 3087/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1182478644.0068 - val_loss: 3189796402.4169\n",
      "Epoch 3088/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 531184756.5830 - val_loss: 2413829697.4819\n",
      "Epoch 3089/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 379608585.5262 - val_loss: 2487247698.3730\n",
      "Epoch 3090/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 469047691.6871 - val_loss: 3492059815.5702\n",
      "Epoch 3091/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 650357403.7321 - val_loss: 3707082900.3432\n",
      "Epoch 3092/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 731990377.7558 - val_loss: 2481009454.5598\n",
      "Epoch 3093/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 577988075.1424 - val_loss: 2624814783.7120\n",
      "Epoch 3094/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 349412032.4344 - val_loss: 2791789352.6233\n",
      "Epoch 3095/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 558923892.2634 - val_loss: 4023057465.2129\n",
      "Epoch 3096/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 515037671.0591 - val_loss: 2513510634.6307\n",
      "Epoch 3097/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 630681836.6775 - val_loss: 2879510123.6726\n",
      "Epoch 3098/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 914526957.7400 - val_loss: 3379295568.0765\n",
      "Epoch 3099/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 539577990.6224 - val_loss: 2601707310.6543\n",
      "Epoch 3100/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 592110209.5127 - val_loss: 2673473692.0034\n",
      "Epoch 3101/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 711782711.0141 - val_loss: 2613546222.2492\n",
      "Epoch 3102/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 473604937.2020 - val_loss: 2516739879.1111\n",
      "Epoch 3103/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 820121634.7552 - val_loss: 3373435053.6911\n",
      "Epoch 3104/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 405812899.2639 - val_loss: 2612438541.9162\n",
      "Epoch 3105/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 698263929.0445 - val_loss: 3281907688.8304\n",
      "Epoch 3106/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 625849366.3298 - val_loss: 3204439992.1238\n",
      "Epoch 3107/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 724759590.8250 - val_loss: 2835848223.2349\n",
      "Epoch 3108/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 426142345.9403 - val_loss: 2940166239.6309\n",
      "Epoch 3109/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 793345266.7327 - val_loss: 2824544400.7786\n",
      "Epoch 3110/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 569114587.0118 - val_loss: 3182934467.2045\n",
      "Epoch 3111/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 914218397.6050 - val_loss: 3945070202.8512\n",
      "Epoch 3112/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 1278975258.9398 - val_loss: 2682893269.8014\n",
      "Epoch 3113/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 626925894.8430 - val_loss: 2514983939.2833\n",
      "Epoch 3114/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 487982463.6579 - val_loss: 2698594124.9890\n",
      "Epoch 3115/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 460261061.5419 - val_loss: 2569598121.3885\n",
      "Epoch 3116/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 452926924.2183 - val_loss: 2894780505.9961\n",
      "Epoch 3117/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 570902021.9426 - val_loss: 2967753125.5021\n",
      "Epoch 3118/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 710498711.2842 - val_loss: 2545182197.2478\n",
      "Epoch 3119/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 621960497.2335 - val_loss: 3126153468.3567\n",
      "Epoch 3120/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 600589171.1964 - val_loss: 2806694369.2062\n",
      "Epoch 3121/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 616986957.7670 - val_loss: 2569162055.9167\n",
      "Epoch 3122/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 420340090.2915 - val_loss: 3033610569.6675\n",
      "Epoch 3123/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 751569537.0445 - val_loss: 3621844357.6529\n",
      "Epoch 3124/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 592580834.1519 - val_loss: 7241074112.4861\n",
      "Epoch 3125/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 861882307.8537 - val_loss: 4228070557.8487\n",
      "Epoch 3126/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 768359063.0501 - val_loss: 2836852367.5094\n",
      "Epoch 3127/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 694560196.3579 - val_loss: 3339945721.3030\n",
      "Epoch 3128/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 520163111.0861 - val_loss: 2510161087.6309\n",
      "Epoch 3129/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 398841683.4035 - val_loss: 2385022616.5063\n",
      "Epoch 3130/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 708319143.1131 - val_loss: 2942480869.8689\n",
      "Epoch 3131/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 487684720.2251 - val_loss: 2608306412.4003\n",
      "Epoch 3132/10000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 572053070.439 - 0s 85us/step - loss: 675200606.9015 - val_loss: 4190635432.8124\n",
      "Epoch 3133/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 844431349.4294 - val_loss: 2665889404.8023\n",
      "Epoch 3134/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 479891582.3748 - val_loss: 2369978763.1707\n",
      "Epoch 3135/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 101us/step - loss: 499803531.5971 - val_loss: 6440468219.1752\n",
      "Epoch 3136/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 735804723.9167 - val_loss: 2390508194.0107\n",
      "Epoch 3137/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 464490103.3562 - val_loss: 2431715129.8475\n",
      "Epoch 3138/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 504721977.2651 - val_loss: 2539152340.4692\n",
      "Epoch 3139/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 831159061.5374 - val_loss: 4311559933.3356\n",
      "Epoch 3140/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 579953231.9662 - val_loss: 2456681455.1854\n",
      "Epoch 3141/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 698426850.1069 - val_loss: 4297149237.1803\n",
      "Epoch 3142/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 397343622.1632 - val_loss: 2534107613.5111\n",
      "Epoch 3143/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 418209864.6978 - val_loss: 3843143701.0633\n",
      "Epoch 3144/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 740651289.3731 - val_loss: 2510252249.2489\n",
      "Epoch 3145/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 557428915.6466 - val_loss: 2531839456.2250\n",
      "Epoch 3146/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 843365094.9330 - val_loss: 5887393530.5767\n",
      "Epoch 3147/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 2408915607.7119 - val_loss: 2857166866.4709\n",
      "Epoch 3148/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 490898263.8784 - val_loss: 5382995608.3038\n",
      "Epoch 3149/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 637260653.6815 - val_loss: 2470261576.3893\n",
      "Epoch 3150/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 444489993.9764 - val_loss: 5518204814.7983\n",
      "Epoch 3151/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 754892287.9482 - val_loss: 4496559697.8768\n",
      "Epoch 3152/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 547074921.9584 - val_loss: 2728339058.6959\n",
      "Epoch 3153/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1191365389.3123 - val_loss: 2367766737.0487\n",
      "Epoch 3154/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 418839270.7124 - val_loss: 2609591459.5286\n",
      "Epoch 3155/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 391834814.5954 - val_loss: 2413221469.2366\n",
      "Epoch 3156/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 443947308.2273 - val_loss: 2520809492.8023\n",
      "Epoch 3157/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 620196802.9533 - val_loss: 2527781781.1668\n",
      "Epoch 3158/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 526655984.5132 - val_loss: 5233924407.8807\n",
      "Epoch 3159/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 834460868.4750 - val_loss: 3397927547.6073\n",
      "Epoch 3160/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 580821610.3185 - val_loss: 2723516630.3100\n",
      "Epoch 3161/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 463946666.3005 - val_loss: 2399541824.8163\n",
      "Epoch 3162/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 497051540.8711 - val_loss: 2736590201.6090\n",
      "Epoch 3163/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 539059574.9240 - val_loss: 2821667509.2793\n",
      "Epoch 3164/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 436461316.7001 - val_loss: 3534180332.3724\n",
      "Epoch 3165/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 881114960.2611 - val_loss: 2633776008.6864\n",
      "Epoch 3166/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 621820070.5369 - val_loss: 2748009324.4681\n",
      "Epoch 3167/10000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 534699343.6308 - val_loss: 3105727544.7449\n",
      "Epoch 3168/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 492317146.2915 - val_loss: 2358935618.1378\n",
      "Epoch 3169/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 509335360.0000 - val_loss: 2487608888.9969\n",
      "Epoch 3170/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 511662138.1699 - val_loss: 3035507613.7947\n",
      "Epoch 3171/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 518870800.4952 - val_loss: 2732279252.4467\n",
      "Epoch 3172/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 565644022.9600 - val_loss: 2694257147.5353\n",
      "Epoch 3173/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 897137124.9342 - val_loss: 2668807431.8132\n",
      "Epoch 3174/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 966210265.9674 - val_loss: 7788433158.1210\n",
      "Epoch 3175/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1354897567.4958 - val_loss: 2559393826.8489\n",
      "Epoch 3176/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 536330771.0884 - val_loss: 4234355907.4655\n",
      "Epoch 3177/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1194574676.9972 - val_loss: 2739373404.5525\n",
      "Epoch 3178/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 690416653.2448 - val_loss: 2852520684.4850\n",
      "Epoch 3179/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 487083875.1874 - val_loss: 2416381260.6380\n",
      "Epoch 3180/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 473105024.9724 - val_loss: 2830216253.6236\n",
      "Epoch 3181/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 702795735.6624 - val_loss: 3972759138.7274\n",
      "Epoch 3182/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1231992306.5841 - val_loss: 3081787116.5390\n",
      "Epoch 3183/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 387595911.2797 - val_loss: 2612228075.6208\n",
      "Epoch 3184/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 410631196.3804 - val_loss: 2835470839.9707\n",
      "Epoch 3185/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 516201760.4322 - val_loss: 2908317912.1598\n",
      "Epoch 3186/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 1661249055.9100 - val_loss: 7186924323.0695\n",
      "Epoch 3187/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 705434784.2341 - val_loss: 2753902782.6745\n",
      "Epoch 3188/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 368467464.6095 - val_loss: 2657353117.8132\n",
      "Epoch 3189/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 406486136.8329 - val_loss: 2375001102.9716\n",
      "Epoch 3190/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 761405643.6151 - val_loss: 4370380273.6338\n",
      "Epoch 3191/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 954072362.5886 - val_loss: 2456358944.7629\n",
      "Epoch 3192/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 494767147.6511 - val_loss: 2433004172.6380\n",
      "Epoch 3193/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 601983266.8633 - val_loss: 3128500546.4484\n",
      "Epoch 3194/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 504421323.3891 - val_loss: 2346996858.3990\n",
      "Epoch 3195/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 400790582.4401 - val_loss: 2556272018.5969\n",
      "Epoch 3196/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 467016433.4316 - val_loss: 2457816790.0669\n",
      "Epoch 3197/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 553830634.7687 - val_loss: 2531873453.3941\n",
      "Epoch 3198/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 589696036.0518 - val_loss: 2759034414.7713\n",
      "Epoch 3199/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 570785793.7423 - val_loss: 2337531739.2371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3200/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 386911353.3281 - val_loss: 3578388262.3100\n",
      "Epoch 3201/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 703993484.7046 - val_loss: 3088810977.6113\n",
      "Epoch 3202/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 593942454.2397 - val_loss: 3114470103.8177\n",
      "Epoch 3203/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 785753259.9392 - val_loss: 4991918134.5845\n",
      "Epoch 3204/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1153294772.9432 - val_loss: 3867275615.7030\n",
      "Epoch 3205/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1065839087.1356 - val_loss: 2704844007.2495\n",
      "Epoch 3206/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 350482061.1818 - val_loss: 5091186063.4824\n",
      "Epoch 3207/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 558568056.4007 - val_loss: 2738555320.8529\n",
      "Epoch 3208/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 813833144.9882 - val_loss: 3025652116.1091\n",
      "Epoch 3209/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 585326415.9190 - val_loss: 2506201228.8990\n",
      "Epoch 3210/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 462303326.2893 - val_loss: 3111478350.7826\n",
      "Epoch 3211/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 617867181.2110 - val_loss: 2843065607.0571\n",
      "Epoch 3212/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 403989540.4862 - val_loss: 2443220302.2402\n",
      "Epoch 3213/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 526734144.3286 - val_loss: 2369996887.8481\n",
      "Epoch 3214/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 538662050.3590 - val_loss: 2601143774.0467\n",
      "Epoch 3215/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 454220733.9111 - val_loss: 2566560053.5899\n",
      "Epoch 3216/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 709971000.8227 - val_loss: 2433805404.5435\n",
      "Epoch 3217/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 457013291.5070 - val_loss: 2643586241.4132\n",
      "Epoch 3218/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 534061427.5746 - val_loss: 3185587876.8698\n",
      "Epoch 3219/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 502749173.4474 - val_loss: 2918823588.3747\n",
      "Epoch 3220/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 904628069.9437 - val_loss: 2594657425.6788\n",
      "Epoch 3221/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 779315192.4007 - val_loss: 2391929100.8540\n",
      "Epoch 3222/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 690513661.6612 - val_loss: 3243548895.9910\n",
      "Epoch 3223/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 689177142.1587 - val_loss: 2343131427.1865\n",
      "Epoch 3224/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 446015581.9111 - val_loss: 2653121774.9356\n",
      "Epoch 3225/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 588678591.8379 - val_loss: 2962097936.8439\n",
      "Epoch 3226/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 450783174.6089 - val_loss: 4255686767.0414\n",
      "Epoch 3227/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 489169761.7107 - val_loss: 4127763119.5814\n",
      "Epoch 3228/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 613736258.9893 - val_loss: 2317797883.5572\n",
      "Epoch 3229/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 591188378.2195 - val_loss: 3123348334.1952\n",
      "Epoch 3230/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1097888356.1778 - val_loss: 2663389100.3589\n",
      "Epoch 3231/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 431603857.5397 - val_loss: 2768600401.0307\n",
      "Epoch 3232/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 506219091.6162 - val_loss: 2443024470.5980\n",
      "Epoch 3233/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 545700993.8008 - val_loss: 2640738118.2065\n",
      "Epoch 3234/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 468517530.8678 - val_loss: 2606376563.3013\n",
      "Epoch 3235/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 531074229.8796 - val_loss: 2632989142.7173\n",
      "Epoch 3236/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 550518141.3708 - val_loss: 3355783569.7553\n",
      "Epoch 3237/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 467294318.4963 - val_loss: 3907598574.1592\n",
      "Epoch 3238/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 866233196.9837 - val_loss: 7439631067.5623\n",
      "Epoch 3239/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1691150809.7513 - val_loss: 3084511096.0248\n",
      "Epoch 3240/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 786184546.7124 - val_loss: 2856624734.4788\n",
      "Epoch 3241/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 456585652.3669 - val_loss: 3397532312.0563\n",
      "Epoch 3242/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 655498878.3433 - val_loss: 2716726872.7449\n",
      "Epoch 3243/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 650539272.2836 - val_loss: 2431905373.9837\n",
      "Epoch 3244/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 519413970.6213 - val_loss: 2922671046.6970\n",
      "Epoch 3245/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 559930222.8565 - val_loss: 3895208568.1868\n",
      "Epoch 3246/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 509513348.0394 - val_loss: 2530868374.2605\n",
      "Epoch 3247/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 473706276.9342 - val_loss: 2771016160.0900\n",
      "Epoch 3248/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 399665682.4294 - val_loss: 2516936254.0422\n",
      "Epoch 3249/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 561556344.2566 - val_loss: 2412782945.0982\n",
      "Epoch 3250/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 551117448.0135 - val_loss: 2351207362.7634\n",
      "Epoch 3251/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 949528835.5656 - val_loss: 3737695780.1226\n",
      "Epoch 3252/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 876908351.5318 - val_loss: 2677631084.2554\n",
      "Epoch 3253/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 534723058.9263 - val_loss: 3287684272.8056\n",
      "Epoch 3254/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 941018706.8362 - val_loss: 2576514335.6669\n",
      "Epoch 3255/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 665152936.1193 - val_loss: 2340340199.8307\n",
      "Epoch 3256/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 328703649.1525 - val_loss: 3427523786.8287\n",
      "Epoch 3257/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 647716456.0495 - val_loss: 2632265926.2650\n",
      "Epoch 3258/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 443561253.3844 - val_loss: 2318447684.1429\n",
      "Epoch 3259/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 355962098.1880 - val_loss: 3634228687.3114\n",
      "Epoch 3260/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 689738927.4328 - val_loss: 4350594002.1918\n",
      "Epoch 3261/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 927952804.3309 - val_loss: 3249939405.7001\n",
      "Epoch 3262/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 518254953.4181 - val_loss: 2689916147.5871\n",
      "Epoch 3263/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 894045747.2864 - val_loss: 5878434010.0501\n",
      "Epoch 3264/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1452536056.8689 - val_loss: 2318421293.5111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3265/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 467222380.6775 - val_loss: 2452555330.7769\n",
      "Epoch 3266/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 448583882.6787 - val_loss: 2518527835.1032\n",
      "Epoch 3267/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 496805154.1609 - val_loss: 4122969549.4121\n",
      "Epoch 3268/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 533406791.2932 - val_loss: 2596333348.1136\n",
      "Epoch 3269/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 400008182.9961 - val_loss: 3004662078.5418\n",
      "Epoch 3270/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 462987401.2200 - val_loss: 2491293762.9390\n",
      "Epoch 3271/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 438499988.6730 - val_loss: 2564368090.8422\n",
      "Epoch 3272/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 524890565.1722 - val_loss: 3030556050.7229\n",
      "Epoch 3273/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 505139732.2729 - val_loss: 3285177787.7333\n",
      "Epoch 3274/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 693801413.5824 - val_loss: 3736399308.0439\n",
      "Epoch 3275/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1581174576.6393 - val_loss: 2422084654.5508\n",
      "Epoch 3276/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 453025513.3461 - val_loss: 2686178945.5494\n",
      "Epoch 3277/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 525926636.6595 - val_loss: 2499551320.1778\n",
      "Epoch 3278/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 438220420.9882 - val_loss: 3140133630.7398\n",
      "Epoch 3279/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 471332937.9291 - val_loss: 2263982506.9459\n",
      "Epoch 3280/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 541531979.1379 - val_loss: 2413751496.2700\n",
      "Epoch 3281/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 433838629.5284 - val_loss: 3751126070.0084\n",
      "Epoch 3282/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1851477854.2893 - val_loss: 4264589641.9556\n",
      "Epoch 3283/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 707147468.4795 - val_loss: 2581438583.3046\n",
      "Epoch 3284/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 467535835.9786 - val_loss: 2275855302.7421\n",
      "Epoch 3285/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 385330827.4530 - val_loss: 2548124380.9665\n",
      "Epoch 3286/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 500726412.2454 - val_loss: 2429431318.5035\n",
      "Epoch 3287/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 455423349.2853 - val_loss: 2731157038.4113\n",
      "Epoch 3288/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 555961396.7383 - val_loss: 2857479836.5255\n",
      "Epoch 3289/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 486681288.3196 - val_loss: 2277112315.7873\n",
      "Epoch 3290/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 515318261.9966 - val_loss: 2411997597.1235\n",
      "Epoch 3291/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 437659769.8143 - val_loss: 4653421567.1719\n",
      "Epoch 3292/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 937911150.8925 - val_loss: 2718062429.2366\n",
      "Epoch 3293/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 721648483.9797 - val_loss: 2442797914.2661\n",
      "Epoch 3294/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 821819184.3962 - val_loss: 2419875422.3707\n",
      "Epoch 3295/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 469542266.1835 - val_loss: 2331206097.2669\n",
      "Epoch 3296/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 415529256.7968 - val_loss: 2473033725.8954\n",
      "Epoch 3297/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 498106270.1272 - val_loss: 2408658005.7114\n",
      "Epoch 3298/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 601150996.9612 - val_loss: 2790560718.2402\n",
      "Epoch 3299/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 976622787.2054 - val_loss: 2487546177.7148\n",
      "Epoch 3300/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 696664197.6545 - val_loss: 4073681776.5536\n",
      "Epoch 3301/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 554840152.3467 - val_loss: 3455590405.8689\n",
      "Epoch 3302/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 815301660.8846 - val_loss: 2491255801.6720\n",
      "Epoch 3303/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 753269261.3979 - val_loss: 2746182414.6903\n",
      "Epoch 3304/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 438343962.1474 - val_loss: 2279513102.7623\n",
      "Epoch 3305/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 658205965.3618 - val_loss: 3073660522.6847\n",
      "Epoch 3306/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 371697903.2527 - val_loss: 3515715355.5803\n",
      "Epoch 3307/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 582657540.4660 - val_loss: 2558053164.4309\n",
      "Epoch 3308/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 471284303.9370 - val_loss: 3094503458.8714\n",
      "Epoch 3309/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1005326768.3331 - val_loss: 2598106700.4714\n",
      "Epoch 3310/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1198861051.2549 - val_loss: 2630067693.9741\n",
      "Epoch 3311/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 433898890.9488 - val_loss: 3111921699.6512\n",
      "Epoch 3312/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 774766777.9133 - val_loss: 2545044326.4180\n",
      "Epoch 3313/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1764256170.5706 - val_loss: 3417105166.4743\n",
      "Epoch 3314/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 782044351.5678 - val_loss: 2308730545.9398\n",
      "Epoch 3315/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 569546523.7681 - val_loss: 2426882009.4110\n",
      "Epoch 3316/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 512862715.6061 - val_loss: 3582651799.8537\n",
      "Epoch 3317/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 784767578.4716 - val_loss: 2890707753.0104\n",
      "Epoch 3318/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 519163295.6939 - val_loss: 3150253940.2982\n",
      "Epoch 3319/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 605501381.0782 - val_loss: 6141042595.8256\n",
      "Epoch 3320/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 951917420.7901 - val_loss: 2288070171.2518\n",
      "Epoch 3321/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 408812823.2167 - val_loss: 2787239413.8464\n",
      "Epoch 3322/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 324115073.5487 - val_loss: 2459650470.1637\n",
      "Epoch 3323/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 447640722.1745 - val_loss: 2335701293.4031\n",
      "Epoch 3324/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 396319011.7636 - val_loss: 2230833507.6456\n",
      "Epoch 3325/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 458997828.6820 - val_loss: 2454790857.6000\n",
      "Epoch 3326/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 652755836.5785 - val_loss: 6650542634.9907\n",
      "Epoch 3327/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 780280129.9313 - val_loss: 2257764062.5215\n",
      "Epoch 3328/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 438166549.5059 - val_loss: 2296344873.4605\n",
      "Epoch 3329/10000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 507116425.3641 - val_loss: 2946425874.2188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3330/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 633213567.9820 - val_loss: 2472476632.1193\n",
      "Epoch 3331/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 375855789.8661 - val_loss: 3129507094.5395\n",
      "Epoch 3332/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 548471885.2178 - val_loss: 2448265399.4982\n",
      "Epoch 3333/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 815091341.5329 - val_loss: 3048677555.4745\n",
      "Epoch 3334/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 720751580.7406 - val_loss: 2599419314.0703\n",
      "Epoch 3335/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 486213581.6140 - val_loss: 2868476618.8377\n",
      "Epoch 3336/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 383878836.0068 - val_loss: 4862723172.2397\n",
      "Epoch 3337/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 599579091.5408 - val_loss: 2987490301.4076\n",
      "Epoch 3338/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 543709751.5363 - val_loss: 2295864042.0771\n",
      "Epoch 3339/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 598940701.9651 - val_loss: 8734394984.7044\n",
      "Epoch 3340/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1472245716.4930 - val_loss: 2404579176.2678\n",
      "Epoch 3341/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 446880467.1784 - val_loss: 2420129819.8188\n",
      "Epoch 3342/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 524551212.3534 - val_loss: 2462100975.0774\n",
      "Epoch 3343/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 482846899.6286 - val_loss: 2434780602.4281\n",
      "Epoch 3344/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 749355131.0377 - val_loss: 2313789805.2973\n",
      "Epoch 3345/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 363865761.3506 - val_loss: 2318135476.7482\n",
      "Epoch 3346/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 314792330.7237 - val_loss: 2248424787.8211\n",
      "Epoch 3347/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 644958118.4288 - val_loss: 2532711721.9826\n",
      "Epoch 3348/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 463336872.6618 - val_loss: 2218574018.3944\n",
      "Epoch 3349/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 439276058.3275 - val_loss: 2388071920.2453\n",
      "Epoch 3350/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1146808890.5796 - val_loss: 3462856498.5159\n",
      "Epoch 3351/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 817253896.3737 - val_loss: 4512264865.7013\n",
      "Epoch 3352/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 507247709.2628 - val_loss: 2292493793.1072\n",
      "Epoch 3353/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 495871772.1103 - val_loss: 2286918685.3896\n",
      "Epoch 3354/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 962615361.7828 - val_loss: 2696932178.2053\n",
      "Epoch 3355/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 738296954.4536 - val_loss: 3467091410.6329\n",
      "Epoch 3356/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 655043443.6106 - val_loss: 2358255570.0658\n",
      "Epoch 3357/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 384082901.2043 - val_loss: 2829120241.4537\n",
      "Epoch 3358/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 591061846.5459 - val_loss: 4207581550.2132\n",
      "Epoch 3359/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 846744653.8120 - val_loss: 3261266368.5221\n",
      "Epoch 3360/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 491000089.1075 - val_loss: 2516852682.8557\n",
      "Epoch 3361/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 457285171.8357 - val_loss: 2259762678.6565\n",
      "Epoch 3362/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 409445560.7608 - val_loss: 4141168455.6962\n",
      "Epoch 3363/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1020934735.5723 - val_loss: 3425614790.0129\n",
      "Epoch 3364/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 431061674.6607 - val_loss: 3377778487.9527\n",
      "Epoch 3365/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 532408374.8160 - val_loss: 2413649542.3730\n",
      "Epoch 3366/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 432646727.9235 - val_loss: 3337230436.2757\n",
      "Epoch 3367/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 739530757.5464 - val_loss: 2890605636.5187\n",
      "Epoch 3368/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 670486404.0979 - val_loss: 2809900781.0970\n",
      "Epoch 3369/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 415189290.2105 - val_loss: 2791993245.6506\n",
      "Epoch 3370/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 490678827.6826 - val_loss: 2251428854.8461\n",
      "Epoch 3371/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 434587939.6916 - val_loss: 2398764753.1364\n",
      "Epoch 3372/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 489307491.5115 - val_loss: 2476921955.6006\n",
      "Epoch 3373/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1034339566.7214 - val_loss: 3116556616.2633\n",
      "Epoch 3374/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 434487928.8689 - val_loss: 2269275613.0160\n",
      "Epoch 3375/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 375014716.6055 - val_loss: 3189908014.2942\n",
      "Epoch 3376/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 778930713.0670 - val_loss: 3015447365.8149\n",
      "Epoch 3377/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 555399307.5622 - val_loss: 2550975460.1091\n",
      "Epoch 3378/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 614814758.1182 - val_loss: 2338028801.0689\n",
      "Epoch 3379/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 443325224.8329 - val_loss: 2307988291.0875\n",
      "Epoch 3380/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 514682133.0422 - val_loss: 2271479359.8560\n",
      "Epoch 3381/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 549060264.8621 - val_loss: 2366054013.4436\n",
      "Epoch 3382/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 414730709.0962 - val_loss: 2277225120.0383\n",
      "Epoch 3383/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 482841518.2667 - val_loss: 2325219335.1449\n",
      "Epoch 3384/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 430566554.3905 - val_loss: 2533130424.4748\n",
      "Epoch 3385/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 446606832.9634 - val_loss: 2362619235.6163\n",
      "Epoch 3386/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 830941338.6517 - val_loss: 3412583068.8405\n",
      "Epoch 3387/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1385834185.6882 - val_loss: 4564624768.8641\n",
      "Epoch 3388/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 818856209.2876 - val_loss: 2646841972.8923\n",
      "Epoch 3389/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 456083220.7631 - val_loss: 2663434919.8582\n",
      "Epoch 3390/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 445343330.8272 - val_loss: 4371937651.0020\n",
      "Epoch 3391/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 671582005.7760 - val_loss: 2878731652.6087\n",
      "Epoch 3392/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 433613342.4615 - val_loss: 2760637398.7556\n",
      "Epoch 3393/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 575896228.3039 - val_loss: 4730761190.7601\n",
      "Epoch 3394/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 630373617.8278 - val_loss: 2571884646.2211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3395/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 394946377.9223 - val_loss: 2200407431.4307\n",
      "Epoch 3396/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 370552916.8756 - val_loss: 2312823621.4605\n",
      "Epoch 3397/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 450431481.3011 - val_loss: 2924042455.1696\n",
      "Epoch 3398/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 807874693.7265 - val_loss: 2503088698.1283\n",
      "Epoch 3399/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 697180278.5459 - val_loss: 2495685170.0118\n",
      "Epoch 3400/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 553075152.9634 - val_loss: 2612841301.1173\n",
      "Epoch 3401/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 609859251.2144 - val_loss: 3563961167.7885\n",
      "Epoch 3402/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 974676622.2082 - val_loss: 3580581464.2138\n",
      "Epoch 3403/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 531006485.7535 - val_loss: 2330301303.2956\n",
      "Epoch 3404/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 423330342.5324 - val_loss: 4334826986.8287\n",
      "Epoch 3405/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 938738360.4097 - val_loss: 2580925107.1460\n",
      "Epoch 3406/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 617149105.1255 - val_loss: 6027970828.3139\n",
      "Epoch 3407/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 733609642.7777 - val_loss: 2505456874.9277\n",
      "Epoch 3408/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 398811870.6224 - val_loss: 4189029332.2532\n",
      "Epoch 3409/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 444438772.2769 - val_loss: 2542599532.3769\n",
      "Epoch 3410/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 434320625.9539 - val_loss: 5311161961.6765\n",
      "Epoch 3411/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 758084628.7091 - val_loss: 2297526199.4914\n",
      "Epoch 3412/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 448127051.5250 - val_loss: 2753139592.3173\n",
      "Epoch 3413/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 501101580.8576 - val_loss: 2374927023.3879\n",
      "Epoch 3414/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 470129281.2245 - val_loss: 2248504494.2717\n",
      "Epoch 3415/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 457397919.3630 - val_loss: 2285841277.3176\n",
      "Epoch 3416/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 627724649.1660 - val_loss: 2649217460.1992\n",
      "Epoch 3417/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 656094998.3658 - val_loss: 3371570962.7409\n",
      "Epoch 3418/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 571864169.4001 - val_loss: 3694272853.9049\n",
      "Epoch 3419/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1136990252.0833 - val_loss: 4284492772.7977\n",
      "Epoch 3420/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 853382266.9938 - val_loss: 4096033609.3255\n",
      "Epoch 3421/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 531838159.0456 - val_loss: 2335590989.0250\n",
      "Epoch 3422/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 424377300.4209 - val_loss: 3074334090.5609\n",
      "Epoch 3423/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 962952022.6899 - val_loss: 2767454425.7620\n",
      "Epoch 3424/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 625024916.2409 - val_loss: 2391549923.5150\n",
      "Epoch 3425/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 531615134.3253 - val_loss: 2647141078.0354\n",
      "Epoch 3426/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 388700303.3427 - val_loss: 2364047838.9783\n",
      "Epoch 3427/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 714605560.6528 - val_loss: 4277770136.0518\n",
      "Epoch 3428/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 594211751.4823 - val_loss: 2554463501.7361\n",
      "Epoch 3429/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 559370033.1975 - val_loss: 3823093863.2641\n",
      "Epoch 3430/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 661562185.6882 - val_loss: 2429517827.9989\n",
      "Epoch 3431/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 515215837.7895 - val_loss: 2191585852.0326\n",
      "Epoch 3432/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 354184032.8734 - val_loss: 3435437197.1601\n",
      "Epoch 3433/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 472786246.3748 - val_loss: 2278145219.4745\n",
      "Epoch 3434/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 321760489.0940 - val_loss: 2267076753.3007\n",
      "Epoch 3435/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 474702432.1621 - val_loss: 2870858936.6729\n",
      "Epoch 3436/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 681334346.4086 - val_loss: 3327130562.1063\n",
      "Epoch 3437/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 674648389.2223 - val_loss: 3038525667.4295\n",
      "Epoch 3438/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 474141409.8548 - val_loss: 5065012588.4129\n",
      "Epoch 3439/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 526395261.7670 - val_loss: 3640595890.2639\n",
      "Epoch 3440/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1034963456.2161 - val_loss: 3986804345.1139\n",
      "Epoch 3441/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 742015868.6505 - val_loss: 2834946215.9572\n",
      "Epoch 3442/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 480462374.6809 - val_loss: 2330993619.6501\n",
      "Epoch 3443/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 373933182.6854 - val_loss: 2257544323.1156\n",
      "Epoch 3444/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 336048914.8362 - val_loss: 2759471925.9004\n",
      "Epoch 3445/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 535728712.3196 - val_loss: 20515048260.7707\n",
      "Epoch 3446/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 3121471662.4873 - val_loss: 2217996894.6633\n",
      "Epoch 3447/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 322425121.8188 - val_loss: 2437583779.6276\n",
      "Epoch 3448/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 360593674.7822 - val_loss: 2304151426.2205\n",
      "Epoch 3449/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 334126588.1373 - val_loss: 2212246474.4709\n",
      "Epoch 3450/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 454321954.7282 - val_loss: 2257951346.0169\n",
      "Epoch 3451/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 467380985.3551 - val_loss: 2520477439.3069\n",
      "Epoch 3452/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 422636982.8160 - val_loss: 2444670884.8585\n",
      "Epoch 3453/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 491141487.7209 - val_loss: 4437952317.1195\n",
      "Epoch 3454/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 961014473.3506 - val_loss: 4345353951.7030\n",
      "Epoch 3455/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 444501236.3669 - val_loss: 4466172582.6340\n",
      "Epoch 3456/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 845812115.2729 - val_loss: 2180266346.5136\n",
      "Epoch 3457/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 392538334.4513 - val_loss: 2312175850.3066\n",
      "Epoch 3458/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 379584504.0146 - val_loss: 2303428811.6996\n",
      "Epoch 3459/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 315317992.6438 - val_loss: 2216441173.6236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3460/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 360892345.7513 - val_loss: 2191283215.0470\n",
      "Epoch 3461/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 589706423.8424 - val_loss: 3120495925.0588\n",
      "Epoch 3462/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 659591959.8829 - val_loss: 2295852808.7314\n",
      "Epoch 3463/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 859000832.0540 - val_loss: 2451785099.1077\n",
      "Epoch 3464/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 509526155.2369 - val_loss: 2351656632.3488\n",
      "Epoch 3465/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 551228446.2172 - val_loss: 4425074660.8518\n",
      "Epoch 3466/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 498760669.7040 - val_loss: 3156760012.1541\n",
      "Epoch 3467/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 404557094.9330 - val_loss: 2200616416.2880\n",
      "Epoch 3468/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 896195294.8655 - val_loss: 2799074547.8841\n",
      "Epoch 3469/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1342005312.6230 - val_loss: 2421063024.7381\n",
      "Epoch 3470/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 437435907.1154 - val_loss: 2964968110.5193\n",
      "Epoch 3471/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 680334418.8452 - val_loss: 7353530413.0790\n",
      "Epoch 3472/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 947215200.4502 - val_loss: 3052597539.9156\n",
      "Epoch 3473/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 771949414.5729 - val_loss: 5386616309.2703\n",
      "Epoch 3474/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 965895057.9111 - val_loss: 2339191978.1176\n",
      "Epoch 3475/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 334822237.9381 - val_loss: 2210171610.9255\n",
      "Epoch 3476/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 348879849.1660 - val_loss: 2796467367.2326\n",
      "Epoch 3477/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 966307482.0619 - val_loss: 3314475664.2160\n",
      "Epoch 3478/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 483403237.4204 - val_loss: 2627082795.3373\n",
      "Epoch 3479/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 530047582.5774 - val_loss: 5204723242.5587\n",
      "Epoch 3480/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1124222637.1277 - val_loss: 2264381829.4188\n",
      "Epoch 3481/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 393147451.4350 - val_loss: 2522491180.9170\n",
      "Epoch 3482/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 404880617.9674 - val_loss: 2176765538.9480\n",
      "Epoch 3483/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 350815579.2999 - val_loss: 2202469749.0633\n",
      "Epoch 3484/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 507262475.0568 - val_loss: 2263375798.2042\n",
      "Epoch 3485/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 485569575.7974 - val_loss: 2412079815.2011\n",
      "Epoch 3486/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 633949330.7102 - val_loss: 2241028048.7876\n",
      "Epoch 3487/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 370460391.5093 - val_loss: 2389162843.5533\n",
      "Epoch 3488/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1042835692.0113 - val_loss: 2570679584.3331\n",
      "Epoch 3489/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 565160958.7034 - val_loss: 3376522137.3750\n",
      "Epoch 3490/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1314113575.0501 - val_loss: 2518675873.4222\n",
      "Epoch 3491/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 479688738.2150 - val_loss: 2447033122.9255\n",
      "Epoch 3492/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 479876267.9122 - val_loss: 3812583360.7021\n",
      "Epoch 3493/10000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 441415871.4328 - val_loss: 2174435207.3913\n",
      "Epoch 3494/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 549785947.1289 - val_loss: 3165313606.1030\n",
      "Epoch 3495/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 812434777.5802 - val_loss: 4829302826.8107\n",
      "Epoch 3496/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 599529208.1846 - val_loss: 2402288276.7302\n",
      "Epoch 3497/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 538972389.5284 - val_loss: 2350904005.8419\n",
      "Epoch 3498/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 343142814.6182 - val_loss: 2234553919.5904\n",
      "Epoch 3499/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 382906098.8948 - val_loss: 2205571052.4579\n",
      "Epoch 3500/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 449871969.6387 - val_loss: 4882402024.8124\n",
      "Epoch 3501/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 600463054.4783 - val_loss: 2562321440.7359\n",
      "Epoch 3502/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 555984105.8863 - val_loss: 2663572818.1108\n",
      "Epoch 3503/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 534350701.5959 - val_loss: 2326850215.8020\n",
      "Epoch 3504/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 395116683.9809 - val_loss: 3553766874.2481\n",
      "Epoch 3505/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 447065269.8616 - val_loss: 2331534305.0892\n",
      "Epoch 3506/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 759344093.7850 - val_loss: 2515393224.4073\n",
      "Epoch 3507/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 567020468.1868 - val_loss: 3449803634.8759\n",
      "Epoch 3508/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 566459374.9285 - val_loss: 2302581483.2563\n",
      "Epoch 3509/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 824445333.5374 - val_loss: 13048924238.2762\n",
      "Epoch 3510/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1407622270.2352 - val_loss: 4008791899.6523\n",
      "Epoch 3511/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 798729981.8391 - val_loss: 2222071970.3696\n",
      "Epoch 3512/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 388581009.2515 - val_loss: 2106780872.8776\n",
      "Epoch 3513/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 399292922.9488 - val_loss: 2557259248.8416\n",
      "Epoch 3514/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 457548986.3253 - val_loss: 3700451864.4838\n",
      "Epoch 3515/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 428814619.6916 - val_loss: 2337470870.4945\n",
      "Epoch 3516/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 566533590.5521 - val_loss: 2243230371.8143\n",
      "Epoch 3517/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 336970197.3934 - val_loss: 3078171529.5955\n",
      "Epoch 3518/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 564874882.9533 - val_loss: 14052428873.4515\n",
      "Epoch 3519/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1854258286.2802 - val_loss: 2344085442.1086\n",
      "Epoch 3520/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 413476748.4975 - val_loss: 2103764315.9179\n",
      "Epoch 3521/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 349894948.8621 - val_loss: 2650339757.4391\n",
      "Epoch 3522/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 440626017.9268 - val_loss: 2857099392.4321\n",
      "Epoch 3523/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 480983672.6618 - val_loss: 2228127315.0380\n",
      "Epoch 3524/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 437181334.8025 - val_loss: 2246594499.4633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3525/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 383869029.3483 - val_loss: 3028760779.4048\n",
      "Epoch 3526/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 473035341.3630 - val_loss: 2125658352.8686\n",
      "Epoch 3527/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 488855166.2712 - val_loss: 2454414592.3781\n",
      "Epoch 3528/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 471780627.3022 - val_loss: 3070625597.0475\n",
      "Epoch 3529/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 605868438.5459 - val_loss: 5157551302.4630\n",
      "Epoch 3530/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 995014264.8329 - val_loss: 3357134452.2442\n",
      "Epoch 3531/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 576882279.4733 - val_loss: 2181866245.7018\n",
      "Epoch 3532/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 438314099.9201 - val_loss: 2166999638.1198\n",
      "Epoch 3533/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 329326131.9527 - val_loss: 2419716731.0402\n",
      "Epoch 3534/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 484860280.2026 - val_loss: 2826001670.7150\n",
      "Epoch 3535/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 414687672.1306 - val_loss: 2125887477.1195\n",
      "Epoch 3536/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 617942065.5127 - val_loss: 3401364507.1482\n",
      "Epoch 3537/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 552662472.4997 - val_loss: 2946748505.8700\n",
      "Epoch 3538/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 851644820.5290 - val_loss: 4296468179.4610\n",
      "Epoch 3539/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1137355953.6297 - val_loss: 6072216846.9783\n",
      "Epoch 3540/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 605561583.0816 - val_loss: 2290778988.7730\n",
      "Epoch 3541/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 640638373.7445 - val_loss: 4308644494.2222\n",
      "Epoch 3542/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 970776834.8407 - val_loss: 2262664760.9136\n",
      "Epoch 3543/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 398585525.6635 - val_loss: 3380824581.6889\n",
      "Epoch 3544/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1025977210.1204 - val_loss: 2236989832.8169\n",
      "Epoch 3545/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 393478422.0777 - val_loss: 2194027394.4000\n",
      "Epoch 3546/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 495715261.0287 - val_loss: 2173382076.2352\n",
      "Epoch 3547/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 337165391.0906 - val_loss: 2877939500.0529\n",
      "Epoch 3548/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 964607805.6590 - val_loss: 3935873539.9606\n",
      "Epoch 3549/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 578977503.1176 - val_loss: 2968839103.1179\n",
      "Epoch 3550/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 869287641.0490 - val_loss: 3048507090.3449\n",
      "Epoch 3551/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 448744167.7254 - val_loss: 2518089814.6250\n",
      "Epoch 3552/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 591136913.9539 - val_loss: 2206609555.4880\n",
      "Epoch 3553/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 402734704.6933 - val_loss: 2341388224.5851\n",
      "Epoch 3554/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 546064095.0096 - val_loss: 4052177072.8236\n",
      "Epoch 3555/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 455017813.6815 - val_loss: 4640200989.2366\n",
      "Epoch 3556/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 843219025.9268 - val_loss: 2251966591.1111\n",
      "Epoch 3557/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 324069260.8756 - val_loss: 3108432620.5255\n",
      "Epoch 3558/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 408441814.5234 - val_loss: 2144341986.6149\n",
      "Epoch 3559/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 367008107.3101 - val_loss: 2178405625.1589\n",
      "Epoch 3560/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 416698234.6697 - val_loss: 2862826524.2644\n",
      "Epoch 3561/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 460960561.2425 - val_loss: 2325442081.6158\n",
      "Epoch 3562/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 331653567.3157 - val_loss: 2880625713.0847\n",
      "Epoch 3563/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 649422697.0219 - val_loss: 2619005924.3027\n",
      "Epoch 3564/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 632592112.4412 - val_loss: 2537990084.3567\n",
      "Epoch 3565/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 480920617.2741 - val_loss: 3080274708.0911\n",
      "Epoch 3566/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1252353500.1283 - val_loss: 2357646251.6118\n",
      "Epoch 3567/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 474198603.7231 - val_loss: 2233209930.4934\n",
      "Epoch 3568/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 495816384.3872 - val_loss: 3430128668.4805\n",
      "Epoch 3569/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 619173435.0658 - val_loss: 2192922700.4940\n",
      "Epoch 3570/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 410606477.8301 - val_loss: 2227695141.5674\n",
      "Epoch 3571/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 780222511.3967 - val_loss: 2496216631.1066\n",
      "Epoch 3572/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 504520161.5307 - val_loss: 2522531314.0388\n",
      "Epoch 3573/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 423382207.4688 - val_loss: 2254396673.2602\n",
      "Epoch 3574/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 422951416.7428 - val_loss: 2124399405.3086\n",
      "Epoch 3575/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 385291262.4952 - val_loss: 2282196248.3938\n",
      "Epoch 3576/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 352689462.5098 - val_loss: 2786307074.9345\n",
      "Epoch 3577/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 533790486.5459 - val_loss: 2966969575.9482\n",
      "Epoch 3578/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 606636603.4080 - val_loss: 2236808816.4478\n",
      "Epoch 3579/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 518149784.3298 - val_loss: 2591685819.6073\n",
      "Epoch 3580/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 605831709.6770 - val_loss: 2280354272.8529\n",
      "Epoch 3581/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 480377473.8548 - val_loss: 2794251399.3632\n",
      "Epoch 3582/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 574437160.4997 - val_loss: 5797631917.4751\n",
      "Epoch 3583/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 835465218.8452 - val_loss: 2382114616.2025\n",
      "Epoch 3584/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 544337452.2273 - val_loss: 5157458699.1347\n",
      "Epoch 3585/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1063983636.5110 - val_loss: 2607036653.4571\n",
      "Epoch 3586/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 437783458.8092 - val_loss: 2431879555.8526\n",
      "Epoch 3587/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 431785538.2870 - val_loss: 2250722866.5339\n",
      "Epoch 3588/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 422448929.5824 - val_loss: 2511084783.4914\n",
      "Epoch 3589/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 340081820.1823 - val_loss: 2345567313.5820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3590/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 535479666.4581 - val_loss: 2163619341.1421\n",
      "Epoch 3591/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 679832903.2752 - val_loss: 2853670060.7347\n",
      "Epoch 3592/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1068187863.7344 - val_loss: 2928652756.5592\n",
      "Epoch 3593/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 374650431.0008 - val_loss: 2237207250.4709\n",
      "Epoch 3594/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 412225746.9443 - val_loss: 4623812774.0579\n",
      "Epoch 3595/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 822742842.9668 - val_loss: 2192469227.9854\n",
      "Epoch 3596/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 477626988.1193 - val_loss: 2093341315.1122\n",
      "Epoch 3597/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 421052455.4913 - val_loss: 4232635548.6965\n",
      "Epoch 3598/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 688040883.5025 - val_loss: 2730722166.4945\n",
      "Epoch 3599/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 502600048.9139 - val_loss: 2186023028.2734\n",
      "Epoch 3600/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 590380470.0597 - val_loss: 2302598665.8655\n",
      "Epoch 3601/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 443553760.0180 - val_loss: 2334356678.6430\n",
      "Epoch 3602/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 392980454.6629 - val_loss: 2278889622.2065\n",
      "Epoch 3603/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 523972089.8593 - val_loss: 2790366037.2613\n",
      "Epoch 3604/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 588456961.3686 - val_loss: 2388807208.2633\n",
      "Epoch 3605/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 509623662.5053 - val_loss: 2742108400.1935\n",
      "Epoch 3606/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 680093517.2898 - val_loss: 3276191958.5035\n",
      "Epoch 3607/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 879398648.4367 - val_loss: 2305495811.5893\n",
      "Epoch 3608/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 930047200.3061 - val_loss: 2297109011.5331\n",
      "Epoch 3609/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 639840545.0985 - val_loss: 2674787340.8360\n",
      "Epoch 3610/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 404080663.9145 - val_loss: 2506603631.1494\n",
      "Epoch 3611/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 551229376.6843 - val_loss: 2508683571.6681\n",
      "Epoch 3612/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 941212420.5740 - val_loss: 3761577075.0020\n",
      "Epoch 3613/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 400384793.3551 - val_loss: 2398071586.9435\n",
      "Epoch 3614/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 396528561.7017 - val_loss: 2132660594.2188\n",
      "Epoch 3615/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 460964499.7817 - val_loss: 2273523087.3024\n",
      "Epoch 3616/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 421130989.8908 - val_loss: 2169262295.2821\n",
      "Epoch 3617/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 571580453.0782 - val_loss: 2298737291.7378\n",
      "Epoch 3618/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 562302177.5757 - val_loss: 2731634497.5032\n",
      "Epoch 3619/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 566368235.5971 - val_loss: 2508259618.3494\n",
      "Epoch 3620/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 487624865.0546 - val_loss: 2402205407.5826\n",
      "Epoch 3621/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 448674320.2431 - val_loss: 2453201398.6340\n",
      "Epoch 3622/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 488556472.7248 - val_loss: 2089492643.9021\n",
      "Epoch 3623/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 443775423.7839 - val_loss: 3032860251.3103\n",
      "Epoch 3624/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 550558481.8728 - val_loss: 2127773628.3589\n",
      "Epoch 3625/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 419151236.0383 - val_loss: 2293615783.7502\n",
      "Epoch 3626/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 643148194.8993 - val_loss: 4682044954.6082\n",
      "Epoch 3627/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 664207419.6421 - val_loss: 2915845181.8307\n",
      "Epoch 3628/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 446001580.8959 - val_loss: 2235594516.1722\n",
      "Epoch 3629/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 395631695.6308 - val_loss: 2579595411.6771\n",
      "Epoch 3630/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 554105605.8391 - val_loss: 2252631197.5696\n",
      "Epoch 3631/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 385961187.8627 - val_loss: 2377614812.9058\n",
      "Epoch 3632/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 959911475.2864 - val_loss: 2488859420.1947\n",
      "Epoch 3633/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 401939313.5937 - val_loss: 2737712914.5159\n",
      "Epoch 3634/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 387970002.0259 - val_loss: 2206017388.7179\n",
      "Epoch 3635/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 473500144.4412 - val_loss: 2443656788.3927\n",
      "Epoch 3636/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 427412770.7237 - val_loss: 2546384030.0647\n",
      "Epoch 3637/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 404294777.4091 - val_loss: 2555302385.5977\n",
      "Epoch 3638/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 482519775.1851 - val_loss: 2565389404.6425\n",
      "Epoch 3639/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 709668971.1829 - val_loss: 2346606551.3406\n",
      "Epoch 3640/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 412879572.2769 - val_loss: 2305530526.3077\n",
      "Epoch 3641/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 431049898.4986 - val_loss: 4733362578.7589\n",
      "Epoch 3642/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 680701409.3146 - val_loss: 2709074909.7812\n",
      "Epoch 3643/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 695889630.3433 - val_loss: 2456610725.9679\n",
      "Epoch 3644/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 754310399.0366 - val_loss: 2142811747.5376\n",
      "Epoch 3645/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 361974149.0062 - val_loss: 4121682859.7108\n",
      "Epoch 3646/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 676015074.6472 - val_loss: 2185599240.8979\n",
      "Epoch 3647/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 517853138.1272 - val_loss: 3528986462.6588\n",
      "Epoch 3648/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 387715930.6156 - val_loss: 3289624881.0757\n",
      "Epoch 3649/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 590349609.2741 - val_loss: 2676784969.7598\n",
      "Epoch 3650/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 781067314.6787 - val_loss: 2092105858.9840\n",
      "Epoch 3651/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 522834767.7389 - val_loss: 3257086342.1570\n",
      "Epoch 3652/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 534497379.8267 - val_loss: 2224144196.2869\n",
      "Epoch 3653/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 744238970.5256 - val_loss: 3501859112.8304\n",
      "Epoch 3654/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 856839054.1902 - val_loss: 18047029000.5693\n",
      "Epoch 3655/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 80us/step - loss: 2645538847.8199 - val_loss: 3225087374.3662\n",
      "Epoch 3656/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 367315795.0253 - val_loss: 2096949935.7165\n",
      "Epoch 3657/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 255421180.0023 - val_loss: 2204901758.3167\n",
      "Epoch 3658/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 335933620.2409 - val_loss: 2115792101.1736\n",
      "Epoch 3659/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 276704317.5746 - val_loss: 2156172001.1713\n",
      "Epoch 3660/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 511961214.6567 - val_loss: 2310832792.6639\n",
      "Epoch 3661/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 401911783.7164 - val_loss: 2131773422.5677\n",
      "Epoch 3662/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 451073843.4665 - val_loss: 2158020193.7103\n",
      "Epoch 3663/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 397665274.4536 - val_loss: 3552433062.0219\n",
      "Epoch 3664/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 439369571.3281 - val_loss: 2305123887.7435\n",
      "Epoch 3665/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 517415754.6246 - val_loss: 6190765040.6256\n",
      "Epoch 3666/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 647479334.0056 - val_loss: 4896735414.0264\n",
      "Epoch 3667/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 747889447.0782 - val_loss: 2338580840.6233\n",
      "Epoch 3668/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 485207789.1007 - val_loss: 2242907319.4127\n",
      "Epoch 3669/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 425036987.8267 - val_loss: 3592653113.8250\n",
      "Epoch 3670/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 715206573.3889 - val_loss: 2258565856.1288\n",
      "Epoch 3671/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 442812489.2921 - val_loss: 2581263791.2034\n",
      "Epoch 3672/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 874944348.3354 - val_loss: 2751351840.5851\n",
      "Epoch 3673/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 372211153.2515 - val_loss: 2140519262.0377\n",
      "Epoch 3674/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 426175076.3579 - val_loss: 2300332404.2982\n",
      "Epoch 3675/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 424902611.6466 - val_loss: 2049956940.1564\n",
      "Epoch 3676/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 347900170.8092 - val_loss: 2232344720.0158\n",
      "Epoch 3677/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 713719087.6398 - val_loss: 3350621417.9646\n",
      "Epoch 3678/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1410780315.0118 - val_loss: 2419988428.0079\n",
      "Epoch 3679/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 510962978.2510 - val_loss: 2939613031.8222\n",
      "Epoch 3680/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 666757712.7113 - val_loss: 2197359562.3336\n",
      "Epoch 3681/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 341601972.8779 - val_loss: 1995967879.0819\n",
      "Epoch 3682/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 607537033.5217 - val_loss: 2210490807.4464\n",
      "Epoch 3683/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 408482531.4305 - val_loss: 2033499667.4014\n",
      "Epoch 3684/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 380338088.7698 - val_loss: 2731649572.7527\n",
      "Epoch 3685/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 723497551.3247 - val_loss: 2642919396.5097\n",
      "Epoch 3686/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 849052890.3920 - val_loss: 2318959803.8233\n",
      "Epoch 3687/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 451601306.0754 - val_loss: 2821132540.4714\n",
      "Epoch 3688/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 554540227.9617 - val_loss: 3192943381.8194\n",
      "Epoch 3689/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 420900736.4322 - val_loss: 3491749688.4568\n",
      "Epoch 3690/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 423928123.2819 - val_loss: 2722615055.0504\n",
      "Epoch 3691/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 520825819.9842 - val_loss: 3045354927.5252\n",
      "Epoch 3692/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1035347350.5098 - val_loss: 2322817571.2855\n",
      "Epoch 3693/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 424872456.4277 - val_loss: 2101066206.9378\n",
      "Epoch 3694/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 449884748.4885 - val_loss: 2926921055.1899\n",
      "Epoch 3695/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 502428094.7394 - val_loss: 2804055452.0574\n",
      "Epoch 3696/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 644726835.1424 - val_loss: 2413519308.8540\n",
      "Epoch 3697/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 463972489.3641 - val_loss: 2145135011.4543\n",
      "Epoch 3698/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 663832879.2707 - val_loss: 5778292673.7823\n",
      "Epoch 3699/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1144572878.7710 - val_loss: 2440864243.0380\n",
      "Epoch 3700/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 299902914.3410 - val_loss: 2568556376.5558\n",
      "Epoch 3701/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 426430924.6967 - val_loss: 2084080491.4813\n",
      "Epoch 3702/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 373744207.3067 - val_loss: 2353807311.5342\n",
      "Epoch 3703/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 308507968.7563 - val_loss: 2283046632.0023\n",
      "Epoch 3704/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 667104308.6505 - val_loss: 2450715851.0357\n",
      "Epoch 3705/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 513665473.2606 - val_loss: 2080733553.7733\n",
      "Epoch 3706/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 343497551.7299 - val_loss: 2400556283.1032\n",
      "Epoch 3707/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 985122274.5391 - val_loss: 2403809831.8357\n",
      "Epoch 3708/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 585661857.2425 - val_loss: 3597226077.1286\n",
      "Epoch 3709/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 521184723.7636 - val_loss: 2105856831.7705\n",
      "Epoch 3710/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 427770152.6168 - val_loss: 3447469417.3165\n",
      "Epoch 3711/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 492603061.0872 - val_loss: 2289714261.7609\n",
      "Epoch 3712/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 632667290.0934 - val_loss: 2867076048.4726\n",
      "Epoch 3713/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 959450670.5864 - val_loss: 2152002617.7255\n",
      "Epoch 3714/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 335593401.8008 - val_loss: 2208465492.5502\n",
      "Epoch 3715/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 377090305.0805 - val_loss: 2877528515.6726\n",
      "Epoch 3716/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 637405814.1038 - val_loss: 2156227720.3083\n",
      "Epoch 3717/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 306590760.9679 - val_loss: 3444589930.6127\n",
      "Epoch 3718/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 552950049.3866 - val_loss: 3740634794.2526\n",
      "Epoch 3719/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 745162132.6235 - val_loss: 2135312363.9809\n",
      "Epoch 3720/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 81us/step - loss: 506911942.1722 - val_loss: 2602678022.1030\n",
      "Epoch 3721/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 692348868.0788 - val_loss: 2182269248.6301\n",
      "Epoch 3722/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 493947832.2026 - val_loss: 2402404905.9961\n",
      "Epoch 3723/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 612652843.8132 - val_loss: 3503853153.0892\n",
      "Epoch 3724/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 490832158.7417 - val_loss: 2132596595.5916\n",
      "Epoch 3725/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 311454840.5447 - val_loss: 2138289780.3274\n",
      "Epoch 3726/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 840423294.0551 - val_loss: 8552169644.4669\n",
      "Epoch 3727/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1156640148.6550 - val_loss: 2178490069.7699\n",
      "Epoch 3728/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 396539160.0135 - val_loss: 2014370527.3316\n",
      "Epoch 3729/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 278872665.6972 - val_loss: 2357178542.0287\n",
      "Epoch 3730/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 408061811.7546 - val_loss: 2132211799.7817\n",
      "Epoch 3731/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 381130005.6095 - val_loss: 4092905305.4380\n",
      "Epoch 3732/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 639467723.9932 - val_loss: 3770388150.9806\n",
      "Epoch 3733/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 588289946.7237 - val_loss: 3812728558.1772\n",
      "Epoch 3734/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1115378757.2943 - val_loss: 2338828065.3772\n",
      "Epoch 3735/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 359867692.9162 - val_loss: 2104820693.0402\n",
      "Epoch 3736/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 367623227.8762 - val_loss: 2227224223.3249\n",
      "Epoch 3737/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 508729698.3230 - val_loss: 2272879209.4965\n",
      "Epoch 3738/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 365174049.5037 - val_loss: 3627133083.9044\n",
      "Epoch 3739/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 597406069.2493 - val_loss: 2515725889.2062\n",
      "Epoch 3740/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 523899936.6303 - val_loss: 2313583570.7769\n",
      "Epoch 3741/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 912093191.0411 - val_loss: 2151602606.0017\n",
      "Epoch 3742/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 453540639.1536 - val_loss: 2783635239.8402\n",
      "Epoch 3743/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 538829290.2645 - val_loss: 2754930959.7165\n",
      "Epoch 3744/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 606763813.2583 - val_loss: 2280740451.6129\n",
      "Epoch 3745/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 410811520.6303 - val_loss: 2047334334.0917\n",
      "Epoch 3746/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 446596636.0338 - val_loss: 2211832533.1983\n",
      "Epoch 3747/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 461436766.9826 - val_loss: 5061645795.5916\n",
      "Epoch 3748/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 880528156.5065 - val_loss: 2561153482.4776\n",
      "Epoch 3749/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 330865566.1452 - val_loss: 2181778760.7674\n",
      "Epoch 3750/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 943417141.3393 - val_loss: 2821660958.4608\n",
      "Epoch 3751/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 369353296.4232 - val_loss: 2113594397.3693\n",
      "Epoch 3752/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 395756712.6258 - val_loss: 3282678478.6678\n",
      "Epoch 3753/10000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 596177718.7800 - val_loss: 2217704031.4667\n",
      "Epoch 3754/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 341002544.2611 - val_loss: 2026367878.9266\n",
      "Epoch 3755/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1540646391.6443 - val_loss: 11638841150.7218\n",
      "Epoch 3756/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1767020074.9848 - val_loss: 2017015157.6619\n",
      "Epoch 3757/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 455043219.8177 - val_loss: 2163601809.2737\n",
      "Epoch 3758/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 306013465.2470 - val_loss: 2147648145.0217\n",
      "Epoch 3759/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 292014657.1131 - val_loss: 2021757424.4793\n",
      "Epoch 3760/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 287728535.7704 - val_loss: 2371968581.7609\n",
      "Epoch 3761/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 469258157.8120 - val_loss: 2996575436.2419\n",
      "Epoch 3762/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 485110805.3799 - val_loss: 2079470908.3857\n",
      "Epoch 3763/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 441140818.1880 - val_loss: 2126243244.1699\n",
      "Epoch 3764/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 492785940.0608 - val_loss: 2217249445.3468\n",
      "Epoch 3765/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 527201811.9257 - val_loss: 2904014248.8664\n",
      "Epoch 3766/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 607794977.2425 - val_loss: 2624574927.1944\n",
      "Epoch 3767/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 435454371.4755 - val_loss: 2082632734.5868\n",
      "Epoch 3768/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 429994901.1052 - val_loss: 1982895215.5370\n",
      "Epoch 3769/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 545223970.1609 - val_loss: 2665499357.0745\n",
      "Epoch 3770/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 457540906.9308 - val_loss: 3593655866.2211\n",
      "Epoch 3771/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 509535669.9516 - val_loss: 2250783881.2714\n",
      "Epoch 3772/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 555740724.0068 - val_loss: 2124361669.8239\n",
      "Epoch 3773/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 490035991.7704 - val_loss: 1980886520.7134\n",
      "Epoch 3774/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 332454773.4114 - val_loss: 2017413504.5063\n",
      "Epoch 3775/10000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1231431365.9786 - val_loss: 13158071010.8354\n",
      "Epoch 3776/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1103823232.0720 - val_loss: 2682352188.3634\n",
      "Epoch 3777/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 367269896.3917 - val_loss: 2107669768.8619\n",
      "Epoch 3778/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 350176341.3708 - val_loss: 2057229115.7063\n",
      "Epoch 3779/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 409008922.6427 - val_loss: 3363288809.4920\n",
      "Epoch 3780/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 478449361.2335 - val_loss: 1983665147.1077\n",
      "Epoch 3781/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 314738053.7715 - val_loss: 1998004404.6042\n",
      "Epoch 3782/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 387654157.0467 - val_loss: 2219046910.6790\n",
      "Epoch 3783/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 423879917.0017 - val_loss: 2289585629.2539\n",
      "Epoch 3784/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 339907559.4192 - val_loss: 2123328388.4467\n",
      "Epoch 3785/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 91us/step - loss: 462334775.1041 - val_loss: 2114724072.4883\n",
      "Epoch 3786/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 490749390.3163 - val_loss: 2163277155.3170\n",
      "Epoch 3787/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 799072544.8599 - val_loss: 3042334005.4323\n",
      "Epoch 3788/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 525180388.3939 - val_loss: 2700477451.9719\n",
      "Epoch 3789/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 590419648.0495 - val_loss: 2707593855.8920\n",
      "Epoch 3790/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 383558334.8340 - val_loss: 2467894961.0194\n",
      "Epoch 3791/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1246312979.9527 - val_loss: 2059561590.0624\n",
      "Epoch 3792/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 667744567.2302 - val_loss: 2224944758.4546\n",
      "Epoch 3793/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 343537981.5689 - val_loss: 2141748711.8335\n",
      "Epoch 3794/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 383274186.2015 - val_loss: 3360710597.0948\n",
      "Epoch 3795/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 506415179.1199 - val_loss: 2046354660.0416\n",
      "Epoch 3796/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 707263315.8807 - val_loss: 2796063975.6557\n",
      "Epoch 3797/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 430620135.3438 - val_loss: 2101420240.3218\n",
      "Epoch 3798/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 316219180.6235 - val_loss: 2459662436.3927\n",
      "Epoch 3799/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 323262381.1638 - val_loss: 2308153505.5392\n",
      "Epoch 3800/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 416967657.6837 - val_loss: 3910128186.0411\n",
      "Epoch 3801/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 911198270.7451 - val_loss: 2180016235.6208\n",
      "Epoch 3802/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 274434014.2893 - val_loss: 11539925908.7032\n",
      "Epoch 3803/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 2770727111.9955 - val_loss: 2301620230.8771\n",
      "Epoch 3804/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 370034223.3607 - val_loss: 2259473430.0940\n",
      "Epoch 3805/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 289266492.6505 - val_loss: 2270944496.3556\n",
      "Epoch 3806/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 513166396.7586 - val_loss: 2631271635.2135\n",
      "Epoch 3807/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 496327349.0692 - val_loss: 2305063150.7893\n",
      "Epoch 3808/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 639328690.1699 - val_loss: 2085968314.8332\n",
      "Epoch 3809/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 373308653.4519 - val_loss: 2095476462.6633\n",
      "Epoch 3810/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 332258524.4885 - val_loss: 2996052881.6608\n",
      "Epoch 3811/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 700711737.3371 - val_loss: 2738547438.6295\n",
      "Epoch 3812/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 840479016.8396 - val_loss: 2074348705.0824\n",
      "Epoch 3813/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 294949059.0602 - val_loss: 2266671835.9584\n",
      "Epoch 3814/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 542218385.3956 - val_loss: 5533420447.1809\n",
      "Epoch 3815/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 585958706.8903 - val_loss: 2244251620.2397\n",
      "Epoch 3816/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 470766377.7029 - val_loss: 2734528979.0830\n",
      "Epoch 3817/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 392623964.8486 - val_loss: 2505090297.3210\n",
      "Epoch 3818/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 773907261.4069 - val_loss: 2091974976.0056\n",
      "Epoch 3819/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 527802755.8402 - val_loss: 2098530514.6194\n",
      "Epoch 3820/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 651023191.8120 - val_loss: 2399516023.5387\n",
      "Epoch 3821/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 558239446.5594 - val_loss: 2979915586.4844\n",
      "Epoch 3822/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 388239718.7890 - val_loss: 1992351506.7229\n",
      "Epoch 3823/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 807495315.7693 - val_loss: 6337035139.3485\n",
      "Epoch 3824/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 687925840.8554 - val_loss: 3444467858.7679\n",
      "Epoch 3825/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 863756569.0422 - val_loss: 2497602319.6804\n",
      "Epoch 3826/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 428299754.4986 - val_loss: 3001646754.8354\n",
      "Epoch 3827/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 397900211.5256 - val_loss: 2041246225.0118\n",
      "Epoch 3828/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 405912582.8227 - val_loss: 1970670104.6639\n",
      "Epoch 3829/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 414353231.2347 - val_loss: 2901275953.7778\n",
      "Epoch 3830/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 418981593.3551 - val_loss: 2091983645.9162\n",
      "Epoch 3831/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 420074552.0405 - val_loss: 2586597499.3553\n",
      "Epoch 3832/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 506056579.8897 - val_loss: 2078974556.4444\n",
      "Epoch 3833/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 428129850.6337 - val_loss: 2353359913.9601\n",
      "Epoch 3834/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 331597173.1052 - val_loss: 1975624732.7910\n",
      "Epoch 3835/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 372883100.2003 - val_loss: 3604306612.2082\n",
      "Epoch 3836/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 767263318.8700 - val_loss: 2922541831.1471\n",
      "Epoch 3837/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 816873204.9252 - val_loss: 2038388196.5862\n",
      "Epoch 3838/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 557317176.8104 - val_loss: 2090544825.9241\n",
      "Epoch 3839/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 523513846.5549 - val_loss: 2244636618.3516\n",
      "Epoch 3840/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 728781060.8171 - val_loss: 2019702115.0605\n",
      "Epoch 3841/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 432461048.2206 - val_loss: 2088215053.9027\n",
      "Epoch 3842/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 412442541.4834 - val_loss: 2059714333.4706\n",
      "Epoch 3843/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 316041985.3326 - val_loss: 2234581662.7758\n",
      "Epoch 3844/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 517714437.0602 - val_loss: 3027217083.7513\n",
      "Epoch 3845/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 900288470.9060 - val_loss: 4082455691.3778\n",
      "Epoch 3846/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 492451335.3044 - val_loss: 2243930958.6048\n",
      "Epoch 3847/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 314771937.1390 - val_loss: 2144234348.5930\n",
      "Epoch 3848/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 329054013.6050 - val_loss: 2259668445.2366\n",
      "Epoch 3849/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 561724550.6629 - val_loss: 2112386616.9812\n",
      "Epoch 3850/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 90us/step - loss: 625637147.5160 - val_loss: 2282500063.2101\n",
      "Epoch 3851/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 890902263.5363 - val_loss: 2292785789.3243\n",
      "Epoch 3852/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 353832357.4159 - val_loss: 2156252990.8298\n",
      "Epoch 3853/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 312423912.4007 - val_loss: 2182359396.4422\n",
      "Epoch 3854/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 335833026.9173 - val_loss: 4777659117.5651\n",
      "Epoch 3855/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 605515629.8841 - val_loss: 3278726876.2104\n",
      "Epoch 3856/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 356434215.1773 - val_loss: 2059566367.9437\n",
      "Epoch 3857/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 422473302.4378 - val_loss: 2359718285.7902\n",
      "Epoch 3858/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 568537793.2966 - val_loss: 2146273013.1421\n",
      "Epoch 3859/10000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 505579229.5869 - val_loss: 2106065259.1977\n",
      "Epoch 3860/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 491012506.0754 - val_loss: 3215022146.3224\n",
      "Epoch 3861/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 993213279.9460 - val_loss: 3728050454.7196\n",
      "Epoch 3862/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 412696116.7991 - val_loss: 2977470718.5598\n",
      "Epoch 3863/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 578722442.4963 - val_loss: 2067268924.7145\n",
      "Epoch 3864/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 430825812.5290 - val_loss: 3962654280.5153\n",
      "Epoch 3865/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 512736634.3815 - val_loss: 2770626150.3280\n",
      "Epoch 3866/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 805522679.9505 - val_loss: 2184643583.5274\n",
      "Epoch 3867/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 438266429.6230 - val_loss: 4365050878.0917\n",
      "Epoch 3868/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 729673588.0090 - val_loss: 2278890087.7952\n",
      "Epoch 3869/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 311117138.6972 - val_loss: 2068838389.5089\n",
      "Epoch 3870/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 383853287.6894 - val_loss: 2286300190.5350\n",
      "Epoch 3871/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 338033486.3163 - val_loss: 2083150289.0892\n",
      "Epoch 3872/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 337990594.8813 - val_loss: 2533903370.5947\n",
      "Epoch 3873/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 555916312.3196 - val_loss: 2829374670.5103\n",
      "Epoch 3874/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 443538529.6747 - val_loss: 4168789983.1629\n",
      "Epoch 3875/10000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 822456423.9617 - val_loss: 2044541783.2416\n",
      "Epoch 3876/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 415709670.2847 - val_loss: 5061392685.0070\n",
      "Epoch 3877/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 934296071.2392 - val_loss: 2072755792.6616\n",
      "Epoch 3878/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 396634341.8886 - val_loss: 2621103755.8819\n",
      "Epoch 3879/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 676844193.2696 - val_loss: 2031808228.1136\n",
      "Epoch 3880/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 449508626.8362 - val_loss: 2298365445.6079\n",
      "Epoch 3881/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 479930273.7648 - val_loss: 3101478234.0771\n",
      "Epoch 3882/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 724431687.3742 - val_loss: 3442622813.1105\n",
      "Epoch 3883/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 639663811.2504 - val_loss: 2152430398.1367\n",
      "Epoch 3884/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 355562395.6759 - val_loss: 2143142398.2380\n",
      "Epoch 3885/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 595857785.8593 - val_loss: 2264124415.4059\n",
      "Epoch 3886/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 442317285.6162 - val_loss: 2257577144.1013\n",
      "Epoch 3887/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 285935633.1795 - val_loss: 1977699159.0976\n",
      "Epoch 3888/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 342172338.5661 - val_loss: 2149117501.6551\n",
      "Epoch 3889/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 323664816.6753 - val_loss: 3037460004.1316\n",
      "Epoch 3890/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 761245541.1322 - val_loss: 3348965657.9916\n",
      "Epoch 3891/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 720823179.4395 - val_loss: 2942220143.8695\n",
      "Epoch 3892/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 340889872.7293 - val_loss: 2281871020.1249\n",
      "Epoch 3893/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 420539868.2003 - val_loss: 2113108796.3634\n",
      "Epoch 3894/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 350917446.1047 - val_loss: 2189713718.2605\n",
      "Epoch 3895/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 573549710.5324 - val_loss: 1983011169.4582\n",
      "Epoch 3896/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 341794488.0405 - val_loss: 2187328165.9139\n",
      "Epoch 3897/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 518348193.8188 - val_loss: 2419941023.3609\n",
      "Epoch 3898/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 541215730.6742 - val_loss: 2486050505.5775\n",
      "Epoch 3899/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 873225569.6792 - val_loss: 2328525775.3744\n",
      "Epoch 3900/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 398168759.2437 - val_loss: 2079746711.5091\n",
      "Epoch 3901/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 336029267.8267 - val_loss: 2026471789.7902\n",
      "Epoch 3902/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 359484358.3028 - val_loss: 5517779542.9896\n",
      "Epoch 3903/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 657912398.5504 - val_loss: 3896793505.3052\n",
      "Epoch 3904/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 688612653.9854 - val_loss: 3022142904.6549\n",
      "Epoch 3905/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1216988912.2251 - val_loss: 2374140514.0917\n",
      "Epoch 3906/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 793874627.8177 - val_loss: 5392655370.6577\n",
      "Epoch 3907/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1050189873.7603 - val_loss: 2238054153.0779\n",
      "Epoch 3908/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 357345735.2752 - val_loss: 2061406069.3063\n",
      "Epoch 3909/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 351291914.2825 - val_loss: 2229640061.3671\n",
      "Epoch 3910/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 463555509.0152 - val_loss: 2737675535.6264\n",
      "Epoch 3911/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 417029318.9961 - val_loss: 2126371312.0045\n",
      "Epoch 3912/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 560046321.4541 - val_loss: 2746260845.4571\n",
      "Epoch 3913/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 407565795.5476 - val_loss: 2820024659.7671\n",
      "Epoch 3914/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 1085268418.4311 - val_loss: 1974130951.9887\n",
      "Epoch 3915/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 85us/step - loss: 369324825.5892 - val_loss: 2114566173.1331\n",
      "Epoch 3916/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 453139401.4181 - val_loss: 2380869792.0135\n",
      "Epoch 3917/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 345315434.9848 - val_loss: 2051200268.1024\n",
      "Epoch 3918/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 350163241.6702 - val_loss: 2402525565.2186\n",
      "Epoch 3919/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 582316891.2639 - val_loss: 13261159995.1932\n",
      "Epoch 3920/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 1177661735.3711 - val_loss: 2320721514.1693\n",
      "Epoch 3921/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 525840129.0861 - val_loss: 3152418636.0439\n",
      "Epoch 3922/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 467890767.8109 - val_loss: 3814663825.0307\n",
      "Epoch 3923/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 666597757.2853 - val_loss: 2879299646.4338\n",
      "Epoch 3924/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 656917979.1919 - val_loss: 2480870179.8504\n",
      "Epoch 3925/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 666702603.7862 - val_loss: 1889936443.2585\n",
      "Epoch 3926/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 335241697.7017 - val_loss: 2000557394.9570\n",
      "Epoch 3927/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 306668411.2639 - val_loss: 2472959755.1617\n",
      "Epoch 3928/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 404486037.0332 - val_loss: 2292832493.5246\n",
      "Epoch 3929/10000\n",
      "3554/3554 [==============================] - 0s 140us/step - loss: 530476659.0703 - val_loss: 2164644632.2858\n",
      "Epoch 3930/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 499884426.7878 - val_loss: 2106012218.1536\n",
      "Epoch 3931/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 415341580.5965 - val_loss: 2183342640.5266\n",
      "Epoch 3932/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 368153572.6505 - val_loss: 2643459195.5218\n",
      "Epoch 3933/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 684287533.6680 - val_loss: 5610612204.9890\n",
      "Epoch 3934/10000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 509186710.1092 - val_loss: 2051521615.0233\n",
      "Epoch 3935/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 412655646.8655 - val_loss: 2728594429.0565\n",
      "Epoch 3936/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 435963352.7428 - val_loss: 2476842320.7876\n",
      "Epoch 3937/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 558505368.5447 - val_loss: 2485029470.1007\n",
      "Epoch 3938/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 658104763.9662 - val_loss: 2026430630.0399\n",
      "Epoch 3939/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 451250302.8655 - val_loss: 2106586494.7128\n",
      "Epoch 3940/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 429720057.8120 - val_loss: 1967790332.2239\n",
      "Epoch 3941/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 492953669.8165 - val_loss: 1961824525.9927\n",
      "Epoch 3942/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 417221032.4097 - val_loss: 1931944176.2295\n",
      "Epoch 3943/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 382687600.7563 - val_loss: 2367290413.0520\n",
      "Epoch 3944/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 698235621.3303 - val_loss: 2097136165.5179\n",
      "Epoch 3945/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 305418223.4147 - val_loss: 2378646106.9142\n",
      "Epoch 3946/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 385937177.4046 - val_loss: 2603413086.5328\n",
      "Epoch 3947/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 572819495.7974 - val_loss: 2055036320.7921\n",
      "Epoch 3948/10000\n",
      "3554/3554 [==============================] - 0s 138us/step - loss: 437007988.4389 - val_loss: 2240881379.1595\n",
      "Epoch 3949/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 517649970.8182 - val_loss: 2550142566.6790\n",
      "Epoch 3950/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 701752972.3174 - val_loss: 3890113623.0616\n",
      "Epoch 3951/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 660939983.1626 - val_loss: 3007225380.1496\n",
      "Epoch 3952/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 555391488.7923 - val_loss: 2278344868.7617\n",
      "Epoch 3953/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 365479482.7507 - val_loss: 2178537118.0017\n",
      "Epoch 3954/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 657981157.7828 - val_loss: 2213013823.0706\n",
      "Epoch 3955/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 397118169.2110 - val_loss: 2030941879.3789\n",
      "Epoch 3956/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 552132434.8362 - val_loss: 2510809583.6534\n",
      "Epoch 3957/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 773725363.5385 - val_loss: 2677243592.3353\n",
      "Epoch 3958/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 533556987.1154 - val_loss: 3131407901.5966\n",
      "Epoch 3959/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 450561275.5667 - val_loss: 2009742621.3918\n",
      "Epoch 3960/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 544615606.6809 - val_loss: 5179262415.3564\n",
      "Epoch 3961/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1455330099.4395 - val_loss: 2067738235.3058\n",
      "Epoch 3962/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 300841459.4485 - val_loss: 1972825584.4816\n",
      "Epoch 3963/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 418732856.1576 - val_loss: 2581515848.6594\n",
      "Epoch 3964/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 391478482.4131 - val_loss: 2750678899.1460\n",
      "Epoch 3965/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 424836454.2127 - val_loss: 3099593090.4844\n",
      "Epoch 3966/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 607807833.7670 - val_loss: 3960663162.8512\n",
      "Epoch 3967/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 563744075.1289 - val_loss: 2140293295.7795\n",
      "Epoch 3968/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 340186373.6095 - val_loss: 2400937574.0759\n",
      "Epoch 3969/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 308537858.5931 - val_loss: 4021874799.2214\n",
      "Epoch 3970/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 611346419.4406 - val_loss: 2019020824.6639\n",
      "Epoch 3971/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 419966449.5577 - val_loss: 2039252997.3468\n",
      "Epoch 3972/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 702393799.9775 - val_loss: 2128169259.0267\n",
      "Epoch 3973/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 323669911.5194 - val_loss: 2081201493.9454\n",
      "Epoch 3974/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 511750082.0169 - val_loss: 2096406072.0956\n",
      "Epoch 3975/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 503426518.3928 - val_loss: 1907286926.6183\n",
      "Epoch 3976/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 404506152.8779 - val_loss: 4263297088.9902\n",
      "Epoch 3977/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1269019230.7575 - val_loss: 2493341872.8236\n",
      "Epoch 3978/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 462444630.0416 - val_loss: 2024497141.0048\n",
      "Epoch 3979/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 734486329.0490 - val_loss: 2992127188.5952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3980/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 491168375.8064 - val_loss: 2129275116.4850\n",
      "Epoch 3981/10000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 411418517.272 - 0s 85us/step - loss: 396782841.9831 - val_loss: 1940424299.4408\n",
      "Epoch 3982/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 304038005.4980 - val_loss: 1929520448.0630\n",
      "Epoch 3983/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 515269283.0073 - val_loss: 3238994735.8515\n",
      "Epoch 3984/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 646581331.4350 - val_loss: 2164070418.2034\n",
      "Epoch 3985/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 385203015.2752 - val_loss: 1920868652.4332\n",
      "Epoch 3986/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 664139056.5492 - val_loss: 5563102427.7063\n",
      "Epoch 3987/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 750593130.9848 - val_loss: 2041353780.9688\n",
      "Epoch 3988/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 471835965.6050 - val_loss: 1907596020.6582\n",
      "Epoch 3989/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 339033196.3759 - val_loss: 2222252625.8048\n",
      "Epoch 3990/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 305360510.4513 - val_loss: 2028139826.8174\n",
      "Epoch 3991/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 402900031.0726 - val_loss: 2204697406.1637\n",
      "Epoch 3992/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 427617629.4249 - val_loss: 1941828679.4442\n",
      "Epoch 3993/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 325013875.8807 - val_loss: 2046620138.7837\n",
      "Epoch 3994/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 378614134.4198 - val_loss: 1985878084.9868\n",
      "Epoch 3995/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 569506971.2999 - val_loss: 2029246118.0006\n",
      "Epoch 3996/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 490902761.0850 - val_loss: 2731756483.3305\n",
      "Epoch 3997/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 459646714.4086 - val_loss: 1955800992.3150\n",
      "Epoch 3998/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 434678811.0118 - val_loss: 1952232692.2442\n",
      "Epoch 3999/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 732990328.4142 - val_loss: 2400352916.4512\n",
      "Epoch 4000/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 989551258.4716 - val_loss: 2554670120.1643\n",
      "Epoch 4001/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 488251303.9055 - val_loss: 2436169936.2565\n",
      "Epoch 4002/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 407760988.6145 - val_loss: 1876972308.0439\n",
      "Epoch 4003/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 305447895.9730 - val_loss: 2043439529.3367\n",
      "Epoch 4004/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 427627719.1806 - val_loss: 1944480687.5904\n",
      "Epoch 4005/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 544189904.1351 - val_loss: 2250682173.2816\n",
      "Epoch 4006/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 512626385.6477 - val_loss: 1926670789.7519\n",
      "Epoch 4007/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 321176760.5087 - val_loss: 2118723833.4515\n",
      "Epoch 4008/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 315002959.5228 - val_loss: 2000497513.3626\n",
      "Epoch 4009/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 444758420.4209 - val_loss: 2952109008.3646\n",
      "Epoch 4010/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 732688251.8402 - val_loss: 2213891548.6425\n",
      "Epoch 4011/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 427581753.5532 - val_loss: 2020318304.7876\n",
      "Epoch 4012/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 366210392.8149 - val_loss: 6366465093.7069\n",
      "Epoch 4013/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 760980355.2774 - val_loss: 2006162687.6444\n",
      "Epoch 4014/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 366601006.8565 - val_loss: 3103476202.0006\n",
      "Epoch 4015/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 596773028.6370 - val_loss: 2586367088.4456\n",
      "Epoch 4016/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 533248097.2425 - val_loss: 3408845653.8374\n",
      "Epoch 4017/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1880172867.1694 - val_loss: 3053233875.7491\n",
      "Epoch 4018/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 751432369.0580 - val_loss: 2271987395.0695\n",
      "Epoch 4019/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 513525375.8559 - val_loss: 2430402842.0501\n",
      "Epoch 4020/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 333050290.9263 - val_loss: 2203679863.6197\n",
      "Epoch 4021/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 336807400.8329 - val_loss: 1926374846.5418\n",
      "Epoch 4022/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 725595486.3613 - val_loss: 2417230199.7277\n",
      "Epoch 4023/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 366568834.2566 - val_loss: 1964613526.7286\n",
      "Epoch 4024/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 448471245.3618 - val_loss: 1914420181.8487\n",
      "Epoch 4025/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 553982551.4710 - val_loss: 2003524008.8889\n",
      "Epoch 4026/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 306414740.3264 - val_loss: 1987668980.8698\n",
      "Epoch 4027/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 505735498.7355 - val_loss: 1935048362.5992\n",
      "Epoch 4028/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 413829346.9781 - val_loss: 2384687353.9421\n",
      "Epoch 4029/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 417957469.3528 - val_loss: 4064632693.5584\n",
      "Epoch 4030/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 623870151.8469 - val_loss: 2664912340.0191\n",
      "Epoch 4031/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 421168067.7636 - val_loss: 1892285552.8281\n",
      "Epoch 4032/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 550926769.4856 - val_loss: 2282842563.0110\n",
      "Epoch 4033/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 468696243.5566 - val_loss: 2483117594.1041\n",
      "Epoch 4034/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 552370225.6477 - val_loss: 2025666944.3173\n",
      "Epoch 4035/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 359486260.2003 - val_loss: 1948641894.8129\n",
      "Epoch 4036/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 283320138.8407 - val_loss: 2644522152.9744\n",
      "Epoch 4037/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 591146466.3770 - val_loss: 2125898545.7226\n",
      "Epoch 4038/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 405475477.7895 - val_loss: 2680629056.7381\n",
      "Epoch 4039/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 764429986.4311 - val_loss: 2490970572.8630\n",
      "Epoch 4040/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 508623285.8075 - val_loss: 2082869193.1184\n",
      "Epoch 4041/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 452891493.0962 - val_loss: 1960712317.2051\n",
      "Epoch 4042/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 898233778.1429 - val_loss: 2299217939.6321\n",
      "Epoch 4043/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 367979822.6404 - val_loss: 2100372649.0284\n",
      "Epoch 4044/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 347776554.4648 - val_loss: 2274677584.6076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4045/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 449473727.8739 - val_loss: 1994510745.8723\n",
      "Epoch 4046/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 451656881.9719 - val_loss: 2534696172.7010\n",
      "Epoch 4047/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 776872016.4772 - val_loss: 2181620255.4149\n",
      "Epoch 4048/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 356358867.5205 - val_loss: 2386641067.2428\n",
      "Epoch 4049/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 461667892.6460 - val_loss: 2129492455.0931\n",
      "Epoch 4050/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 294618972.1823 - val_loss: 2140131805.4301\n",
      "Epoch 4051/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 539708845.0557 - val_loss: 2368955249.1387\n",
      "Epoch 4052/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 514819292.7124 - val_loss: 2712976712.2633\n",
      "Epoch 4053/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 600670251.3270 - val_loss: 2058457328.2115\n",
      "Epoch 4054/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 564827966.9195 - val_loss: 1946247583.0188\n",
      "Epoch 4055/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 300689617.8998 - val_loss: 1969412884.7707\n",
      "Epoch 4056/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 339718376.9499 - val_loss: 2222752664.5198\n",
      "Epoch 4057/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 398421078.5639 - val_loss: 2042856313.6653\n",
      "Epoch 4058/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 535625503.0636 - val_loss: 2077464481.3772\n",
      "Epoch 4059/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 400915109.1683 - val_loss: 9409514187.5038\n",
      "Epoch 4060/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1948518462.1272 - val_loss: 2375654675.9111\n",
      "Epoch 4061/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 395576632.2836 - val_loss: 2478611311.6534\n",
      "Epoch 4062/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 291410226.6111 - val_loss: 2319079304.5333\n",
      "Epoch 4063/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 409579773.3922 - val_loss: 1884089417.2805\n",
      "Epoch 4064/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 280010964.2138 - val_loss: 1952131739.0357\n",
      "Epoch 4065/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 453040267.9572 - val_loss: 1991981094.1367\n",
      "Epoch 4066/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 664985330.5706 - val_loss: 2241484181.8824\n",
      "Epoch 4067/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 312527357.4069 - val_loss: 1977594170.4934\n",
      "Epoch 4068/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 359937729.7828 - val_loss: 2002320270.3662\n",
      "Epoch 4069/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 451903477.3934 - val_loss: 3730951896.5378\n",
      "Epoch 4070/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 663917746.7102 - val_loss: 1998136100.2442\n",
      "Epoch 4071/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 628520863.2617 - val_loss: 4125534603.4858\n",
      "Epoch 4072/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 790715151.7513 - val_loss: 1901112966.5350\n",
      "Epoch 4073/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 288318134.8520 - val_loss: 1967982965.0115\n",
      "Epoch 4074/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 344681842.4041 - val_loss: 1925979943.2731\n",
      "Epoch 4075/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 652672411.3675 - val_loss: 2613763647.0459\n",
      "Epoch 4076/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 327239936.2881 - val_loss: 2239149695.9640\n",
      "Epoch 4077/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 505585189.3393 - val_loss: 2373841203.2540\n",
      "Epoch 4078/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 370919332.0518 - val_loss: 1901198349.7181\n",
      "Epoch 4079/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 471760619.0253 - val_loss: 2223043332.1226\n",
      "Epoch 4080/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 971347918.0101 - val_loss: 2876291242.8467\n",
      "Epoch 4081/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 826263038.4873 - val_loss: 1992894137.1286\n",
      "Epoch 4082/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 348171357.0467 - val_loss: 2204823952.0225\n",
      "Epoch 4083/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 360068841.3911 - val_loss: 2084904273.9713\n",
      "Epoch 4084/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1020878942.5774 - val_loss: 8579119309.5921\n",
      "Epoch 4085/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1482817564.3264 - val_loss: 2100189151.1269\n",
      "Epoch 4086/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 322380479.6218 - val_loss: 1899627499.0965\n",
      "Epoch 4087/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 278228180.4930 - val_loss: 2185846357.9814\n",
      "Epoch 4088/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 427229806.0822 - val_loss: 2180277336.6999\n",
      "Epoch 4089/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 306823301.8706 - val_loss: 3346662543.4464\n",
      "Epoch 4090/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 500533139.1176 - val_loss: 1975277912.7280\n",
      "Epoch 4091/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 344967140.9162 - val_loss: 12392383814.2110\n",
      "Epoch 4092/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1848830142.6314 - val_loss: 2117801935.8245\n",
      "Epoch 4093/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 339171714.5931 - val_loss: 2615247797.0633\n",
      "Epoch 4094/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 384291622.6314 - val_loss: 2145544715.1595\n",
      "Epoch 4095/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 310451828.7271 - val_loss: 2352978696.6188\n",
      "Epoch 4096/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 526332640.9544 - val_loss: 3454605081.5820\n",
      "Epoch 4097/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 437327165.6320 - val_loss: 2255347481.5460\n",
      "Epoch 4098/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 511806634.5706 - val_loss: 3048420470.1705\n",
      "Epoch 4099/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 634682308.9882 - val_loss: 2311062551.9257\n",
      "Epoch 4100/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 603353003.7366 - val_loss: 2337354505.3885\n",
      "Epoch 4101/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 405696846.7304 - val_loss: 2368870122.2391\n",
      "Epoch 4102/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 369807955.2054 - val_loss: 2107419598.1435\n",
      "Epoch 4103/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 410009266.9263 - val_loss: 2943022499.5376\n",
      "Epoch 4104/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 447785007.6714 - val_loss: 2996298788.8698\n",
      "Epoch 4105/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 368026280.3016 - val_loss: 2684822504.3623\n",
      "Epoch 4106/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 718529690.2195 - val_loss: 2800697505.0284\n",
      "Epoch 4107/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 428768374.6674 - val_loss: 1895693100.3769\n",
      "Epoch 4108/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 403932826.4896 - val_loss: 1941972043.1662\n",
      "Epoch 4109/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 491507927.6624 - val_loss: 8916771630.6633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4110/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1248047405.6320 - val_loss: 2114516022.5845\n",
      "Epoch 4111/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 396897175.9145 - val_loss: 2082150422.4585\n",
      "Epoch 4112/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 527141880.6888 - val_loss: 2792070487.7997\n",
      "Epoch 4113/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 762784875.0028 - val_loss: 1951595472.9586\n",
      "Epoch 4114/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 297052857.3731 - val_loss: 1891342812.9660\n",
      "Epoch 4115/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 317515328.7203 - val_loss: 2369405589.5944\n",
      "Epoch 4116/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 638216969.7963 - val_loss: 2750745207.1314\n",
      "Epoch 4117/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 811750482.4041 - val_loss: 3927094326.4405\n",
      "Epoch 4118/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 799372611.0816 - val_loss: 1931514444.9080\n",
      "Epoch 4119/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 319527632.6213 - val_loss: 1985255859.9651\n",
      "Epoch 4120/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 432375251.0974 - val_loss: 1829692645.4864\n",
      "Epoch 4121/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 352675598.5504 - val_loss: 2037481430.8996\n",
      "Epoch 4122/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 644137078.2757 - val_loss: 5277585976.0248\n",
      "Epoch 4123/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 842620699.1919 - val_loss: 2116814478.5733\n",
      "Epoch 4124/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 425656672.7383 - val_loss: 1844790340.5176\n",
      "Epoch 4125/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 301732899.9797 - val_loss: 2687276780.6830\n",
      "Epoch 4126/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 452427709.0287 - val_loss: 3175821951.2799\n",
      "Epoch 4127/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 394881621.9876 - val_loss: 1990435729.6788\n",
      "Epoch 4128/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 737107751.6533 - val_loss: 1902111088.3015\n",
      "Epoch 4129/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 298453936.0450 - val_loss: 3813320810.9367\n",
      "Epoch 4130/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 790854006.6719 - val_loss: 1976789164.4174\n",
      "Epoch 4131/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 328868286.5234 - val_loss: 2439647775.5049\n",
      "Epoch 4132/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 423820155.3990 - val_loss: 1960825351.4419\n",
      "Epoch 4133/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 338697815.2549 - val_loss: 1851465471.7108\n",
      "Epoch 4134/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 331247419.8222 - val_loss: 2187437064.3353\n",
      "Epoch 4135/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 408779926.1137 - val_loss: 2344948026.2031\n",
      "Epoch 4136/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 529893788.2003 - val_loss: 1997354071.4532\n",
      "Epoch 4137/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 497805304.3286 - val_loss: 2170787191.4667\n",
      "Epoch 4138/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 401331207.8514 - val_loss: 4591815974.6700\n",
      "Epoch 4139/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1397570330.8678 - val_loss: 1988393049.4875\n",
      "Epoch 4140/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 343564535.0411 - val_loss: 1964219333.4987\n",
      "Epoch 4141/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 396266454.8340 - val_loss: 2089739759.5567\n",
      "Epoch 4142/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 488152768.9364 - val_loss: 3210608079.3384\n",
      "Epoch 4143/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 698663992.5087 - val_loss: 2063702762.0456\n",
      "Epoch 4144/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 516348028.8936 - val_loss: 2210255416.8169\n",
      "Epoch 4145/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 280118903.2662 - val_loss: 2039594107.9674\n",
      "Epoch 4146/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 456717845.0332 - val_loss: 1955061018.0501\n",
      "Epoch 4147/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 442507457.7468 - val_loss: 3937835256.7629\n",
      "Epoch 4148/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 647251468.8036 - val_loss: 2458232110.0782\n",
      "Epoch 4149/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 897848483.5205 - val_loss: 2461898255.6354\n",
      "Epoch 4150/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 394559778.5937 - val_loss: 4084152188.3634\n",
      "Epoch 4151/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 454664400.1711 - val_loss: 5814358017.5662\n",
      "Epoch 4152/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1356259871.1986 - val_loss: 1940236476.7977\n",
      "Epoch 4153/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 313198125.7760 - val_loss: 2453302043.1122\n",
      "Epoch 4154/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 440925996.8261 - val_loss: 2279583882.1896\n",
      "Epoch 4155/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 272683938.3995 - val_loss: 1820413662.4743\n",
      "Epoch 4156/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 319001120.2611 - val_loss: 2421754476.1249\n",
      "Epoch 4157/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 339748999.2032 - val_loss: 1886779340.0709\n",
      "Epoch 4158/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 315505809.1795 - val_loss: 2280155226.8962\n",
      "Epoch 4159/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 424366203.1199 - val_loss: 1968616051.2180\n",
      "Epoch 4160/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 546877399.5183 - val_loss: 3492663919.7615\n",
      "Epoch 4161/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 698224126.6764 - val_loss: 1957633094.1390\n",
      "Epoch 4162/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 367372555.3630 - val_loss: 2609196463.1134\n",
      "Epoch 4163/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 568630720.1531 - val_loss: 2197239802.2661\n",
      "Epoch 4164/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 529558864.3151 - val_loss: 2125594429.2816\n",
      "Epoch 4165/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 513795452.7856 - val_loss: 1951319754.6892\n",
      "Epoch 4166/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 650427245.5779 - val_loss: 2030323828.2667\n",
      "Epoch 4167/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 315002170.3185 - val_loss: 1998058526.3482\n",
      "Epoch 4168/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 340394761.7456 - val_loss: 1811510260.8248\n",
      "Epoch 4169/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 309618547.4620 - val_loss: 2035511925.3603\n",
      "Epoch 4170/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 873757410.8993 - val_loss: 2406643912.2453\n",
      "Epoch 4171/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 544509264.1846 - val_loss: 1826989606.4315\n",
      "Epoch 4172/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 291139584.8824 - val_loss: 1910383107.9550\n",
      "Epoch 4173/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 464460248.5267 - val_loss: 2073735399.5342\n",
      "Epoch 4174/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 747392597.7895 - val_loss: 2460290449.6158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4175/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 500823928.5267 - val_loss: 1990420541.4256\n",
      "Epoch 4176/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 585845181.6590 - val_loss: 2209211640.9789\n",
      "Epoch 4177/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 520839216.6213 - val_loss: 2194370176.6211\n",
      "Epoch 4178/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 425174343.0231 - val_loss: 2313487571.0155\n",
      "Epoch 4179/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 939785580.3354 - val_loss: 3177980663.9842\n",
      "Epoch 4180/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 735571109.7715 - val_loss: 2287405889.1612\n",
      "Epoch 4181/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 274409402.1294 - val_loss: 5772964577.8993\n",
      "Epoch 4182/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 657246536.5718 - val_loss: 2341804146.7859\n",
      "Epoch 4183/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 398269586.5481 - val_loss: 2898038550.8996\n",
      "Epoch 4184/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 465508412.5425 - val_loss: 2359054389.8914\n",
      "Epoch 4185/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 775469186.4131 - val_loss: 2148062104.5918\n",
      "Epoch 4186/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 751938025.2380 - val_loss: 2264655344.5176\n",
      "Epoch 4187/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 356675378.9443 - val_loss: 2206732526.1682\n",
      "Epoch 4188/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 302389586.8362 - val_loss: 2593989712.5626\n",
      "Epoch 4189/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 398261049.5667 - val_loss: 2044585219.6636\n",
      "Epoch 4190/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 292047823.9910 - val_loss: 1950531124.7122\n",
      "Epoch 4191/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 579654229.0512 - val_loss: 2389060383.2855\n",
      "Epoch 4192/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 373497805.4879 - val_loss: 2131892776.1643\n",
      "Epoch 4193/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 581382328.8509 - val_loss: 2145033259.8594\n",
      "Epoch 4194/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 532224084.0248 - val_loss: 1903143757.2861\n",
      "Epoch 4195/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 313772369.2020 - val_loss: 1856545293.4391\n",
      "Epoch 4196/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 297813151.3877 - val_loss: 2125160079.8740\n",
      "Epoch 4197/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 428902026.4142 - val_loss: 2075631400.0338\n",
      "Epoch 4198/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 353312203.4890 - val_loss: 1910091301.8014\n",
      "Epoch 4199/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 648748573.0647 - val_loss: 2483515667.9831\n",
      "Epoch 4200/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 894004512.9544 - val_loss: 2474754144.9091\n",
      "Epoch 4201/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 446169483.5537 - val_loss: 1806969879.8729\n",
      "Epoch 4202/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 341508850.8717 - val_loss: 1791898376.3035\n",
      "Epoch 4203/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 343731705.9133 - val_loss: 2066159824.6796\n",
      "Epoch 4204/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 427147474.4761 - val_loss: 3253595419.0762\n",
      "Epoch 4205/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 606611989.2133 - val_loss: 1991458796.6256\n",
      "Epoch 4206/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 805920656.7614 - val_loss: 2290481416.7404\n",
      "Epoch 4207/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 518897672.0135 - val_loss: 2762978139.3913\n",
      "Epoch 4208/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 589753920.6843 - val_loss: 6848345577.0284\n",
      "Epoch 4209/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 933336067.3315 - val_loss: 2507188773.8779\n",
      "Epoch 4210/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 440011200.1261 - val_loss: 2223523356.7325\n",
      "Epoch 4211/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 309934500.0338 - val_loss: 2022432967.4892\n",
      "Epoch 4212/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 382741021.4429 - val_loss: 1986337622.0805\n",
      "Epoch 4213/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 417317626.6156 - val_loss: 2139612349.1837\n",
      "Epoch 4214/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 354084983.0141 - val_loss: 2894025050.3561\n",
      "Epoch 4215/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 469240253.7062 - val_loss: 1851492831.6872\n",
      "Epoch 4216/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 709458591.6579 - val_loss: 2338839479.7187\n",
      "Epoch 4217/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 968875005.8391 - val_loss: 2157341200.8506\n",
      "Epoch 4218/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 627949170.9353 - val_loss: 1855962778.7623\n",
      "Epoch 4219/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 350803605.1412 - val_loss: 1970821613.7496\n",
      "Epoch 4220/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 350856706.6292 - val_loss: 1846001516.7280\n",
      "Epoch 4221/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 372826873.0129 - val_loss: 1793211107.4633\n",
      "Epoch 4222/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 306508651.0388 - val_loss: 1853219931.9314\n",
      "Epoch 4223/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 437351183.0186 - val_loss: 2092944348.3634\n",
      "Epoch 4224/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 416961919.7929 - val_loss: 2941425088.5221\n",
      "Epoch 4225/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 719077780.9162 - val_loss: 2176135454.8343\n",
      "Epoch 4226/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 445098697.1120 - val_loss: 2662646123.3868\n",
      "Epoch 4227/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 570768161.5667 - val_loss: 1856507360.2160\n",
      "Epoch 4228/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 357492947.8627 - val_loss: 2008468594.2098\n",
      "Epoch 4229/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 366957694.9285 - val_loss: 2122448123.7063\n",
      "Epoch 4230/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 438263526.9510 - val_loss: 2183441031.3586\n",
      "Epoch 4231/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 440776015.8649 - val_loss: 1935317750.4135\n",
      "Epoch 4232/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 373612427.2369 - val_loss: 2619597526.5755\n",
      "Epoch 4233/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 812630456.0045 - val_loss: 2191358760.2543\n",
      "Epoch 4234/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 353966317.1660 - val_loss: 2030454738.5789\n",
      "Epoch 4235/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 605475384.1171 - val_loss: 2115452965.1938\n",
      "Epoch 4236/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 354751701.0872 - val_loss: 1957785492.9913\n",
      "Epoch 4237/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 519031097.4631 - val_loss: 5108364439.3677\n",
      "Epoch 4238/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 799507113.9223 - val_loss: 2285888558.2143\n",
      "Epoch 4239/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 404686008.3647 - val_loss: 2052643840.5761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4240/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 371323407.6488 - val_loss: 1925830437.4819\n",
      "Epoch 4241/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 304481837.5284 - val_loss: 2061707442.6644\n",
      "Epoch 4242/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 654872588.3894 - val_loss: 5254716740.7707\n",
      "Epoch 4243/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 801075565.3663 - val_loss: 3025326909.9297\n",
      "Epoch 4244/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 396359092.4029 - val_loss: 2655323773.1556\n",
      "Epoch 4245/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 414705498.4716 - val_loss: 5270062633.7665\n",
      "Epoch 4246/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 778207331.9077 - val_loss: 3520307623.7142\n",
      "Epoch 4247/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 589090970.7237 - val_loss: 2813516674.2143\n",
      "Epoch 4248/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1024609343.2617 - val_loss: 1832522582.2875\n",
      "Epoch 4249/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 379368399.3292 - val_loss: 2079736239.3384\n",
      "Epoch 4250/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 314026583.3247 - val_loss: 3332735788.9620\n",
      "Epoch 4251/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 393800746.8948 - val_loss: 2228438023.5567\n",
      "Epoch 4252/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 385610029.0827 - val_loss: 1836788500.9013\n",
      "Epoch 4253/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 310923821.2088 - val_loss: 1954638077.0115\n",
      "Epoch 4254/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 392912778.6517 - val_loss: 2059467643.5713\n",
      "Epoch 4255/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 405222317.4519 - val_loss: 2323078988.2149\n",
      "Epoch 4256/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 269104154.5436 - val_loss: 1938172159.3204\n",
      "Epoch 4257/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 451975564.2296 - val_loss: 2136647334.7331\n",
      "Epoch 4258/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 497728182.5279 - val_loss: 2713186605.1871\n",
      "Epoch 4259/10000\n",
      "3554/3554 [==============================] - 0s 134us/step - loss: 733486965.6995 - val_loss: 3414412855.5027\n",
      "Epoch 4260/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 482784488.7158 - val_loss: 1852382271.3069\n",
      "Epoch 4261/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 566080108.0439 - val_loss: 2052761049.5055\n",
      "Epoch 4262/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 397862894.3343 - val_loss: 1798093792.7764\n",
      "Epoch 4263/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 557138975.5498 - val_loss: 7250019587.0965\n",
      "Epoch 4264/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1178006615.9178 - val_loss: 2049423909.3918\n",
      "Epoch 4265/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 286282936.2926 - val_loss: 2248976307.6141\n",
      "Epoch 4266/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 349536389.3483 - val_loss: 1962037725.0385\n",
      "Epoch 4267/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 798245861.7175 - val_loss: 3548499223.0976\n",
      "Epoch 4268/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 456472387.9977 - val_loss: 2511922583.5747\n",
      "Epoch 4269/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 432193341.3708 - val_loss: 2552939814.1660\n",
      "Epoch 4270/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 374957250.2150 - val_loss: 1864053141.0138\n",
      "Epoch 4271/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 698755176.9094 - val_loss: 2292467938.4754\n",
      "Epoch 4272/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 482340007.7074 - val_loss: 2142227870.7488\n",
      "Epoch 4273/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 350916536.0765 - val_loss: 3024964321.6113\n",
      "Epoch 4274/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 492115042.1069 - val_loss: 2280590176.2970\n",
      "Epoch 4275/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 735600828.8486 - val_loss: 2051399621.3468\n",
      "Epoch 4276/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 462379892.1418 - val_loss: 1948448938.7004\n",
      "Epoch 4277/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 515361797.0062 - val_loss: 2495455545.3660\n",
      "Epoch 4278/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 681782224.8194 - val_loss: 2070211549.4166\n",
      "Epoch 4279/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 460351235.3044 - val_loss: 2377504451.9966\n",
      "Epoch 4280/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 397218459.1078 - val_loss: 3207375336.8124\n",
      "Epoch 4281/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 317569046.2577 - val_loss: 3889997904.9046\n",
      "Epoch 4282/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 653585629.4249 - val_loss: 2476507076.1879\n",
      "Epoch 4283/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 556185161.8188 - val_loss: 2229343755.0087\n",
      "Epoch 4284/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1282455034.7777 - val_loss: 2653113121.4132\n",
      "Epoch 4285/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 876555683.8627 - val_loss: 1879951860.7055\n",
      "Epoch 4286/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 280027476.3354 - val_loss: 1871429181.7451\n",
      "Epoch 4287/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 285677726.8194 - val_loss: 2161529475.8526\n",
      "Epoch 4288/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 246528037.4868 - val_loss: 1855295462.7533\n",
      "Epoch 4289/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 569190581.9291 - val_loss: 3114431709.5606\n",
      "Epoch 4290/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 405305375.1716 - val_loss: 1957359120.5581\n",
      "Epoch 4291/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 402841575.5363 - val_loss: 1989988139.8774\n",
      "Epoch 4292/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 681833229.6860 - val_loss: 1995854012.7370\n",
      "Epoch 4293/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 425535755.4395 - val_loss: 1893712273.1927\n",
      "Epoch 4294/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 360974045.5689 - val_loss: 1798767501.8779\n",
      "Epoch 4295/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 581845153.1885 - val_loss: 1810328701.7013\n",
      "Epoch 4296/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 508529724.5065 - val_loss: 2395592869.8430\n",
      "Epoch 4297/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 388780174.9105 - val_loss: 3682139362.6914\n",
      "Epoch 4298/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 1169902342.5909 - val_loss: 1781370693.0318\n",
      "Epoch 4299/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 346630857.9223 - val_loss: 1887809635.2023\n",
      "Epoch 4300/10000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 305281939.3044 - val_loss: 1844093033.4425\n",
      "Epoch 4301/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 375500182.9196 - val_loss: 1792211047.6242\n",
      "Epoch 4302/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 257902557.8030 - val_loss: 2492910309.1308\n",
      "Epoch 4303/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 425809795.4125 - val_loss: 1966584775.4262\n",
      "Epoch 4304/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 382627679.3112 - val_loss: 1754496106.0118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4305/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 338000301.5149 - val_loss: 2878085021.6326\n",
      "Epoch 4306/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 788235176.1261 - val_loss: 1997790108.0169\n",
      "Epoch 4307/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 663525753.6612 - val_loss: 4052212924.0214\n",
      "Epoch 4308/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 347643561.8143 - val_loss: 2179657031.7457\n",
      "Epoch 4309/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 413694084.3219 - val_loss: 1926589843.4610\n",
      "Epoch 4310/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 473488333.6961 - val_loss: 1868549694.7983\n",
      "Epoch 4311/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 359687643.7141 - val_loss: 1991203566.6453\n",
      "Epoch 4312/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 671470720.6483 - val_loss: 1937965347.9561\n",
      "Epoch 4313/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 451693085.3528 - val_loss: 2731386459.7243\n",
      "Epoch 4314/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 444663177.6185 - val_loss: 2564159825.3547\n",
      "Epoch 4315/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 579634720.7968 - val_loss: 2128880005.1128\n",
      "Epoch 4316/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 341080446.8475 - val_loss: 4907997841.3187\n",
      "Epoch 4317/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 752370529.2786 - val_loss: 1862548998.4450\n",
      "Epoch 4318/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 325525397.7895 - val_loss: 1922026015.1629\n",
      "Epoch 4319/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 527069497.8953 - val_loss: 2650218740.6672\n",
      "Epoch 4320/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 354989367.9685 - val_loss: 2691446898.6059\n",
      "Epoch 4321/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 747142709.0152 - val_loss: 1869386217.1387\n",
      "Epoch 4322/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 613655030.3399 - val_loss: 2070940684.4759\n",
      "Epoch 4323/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 302730963.7727 - val_loss: 2381829541.4729\n",
      "Epoch 4324/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 346418539.5521 - val_loss: 1857815915.2270\n",
      "Epoch 4325/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 576176572.0203 - val_loss: 1812210941.8757\n",
      "Epoch 4326/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 283261360.6213 - val_loss: 1991763869.0588\n",
      "Epoch 4327/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 516051783.5273 - val_loss: 1891860690.5969\n",
      "Epoch 4328/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 490753812.4389 - val_loss: 2585382235.0582\n",
      "Epoch 4329/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 692809645.7310 - val_loss: 2341051044.4377\n",
      "Epoch 4330/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 290851670.9060 - val_loss: 1980528976.3331\n",
      "Epoch 4331/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 322469161.2380 - val_loss: 1854173726.7331\n",
      "Epoch 4332/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 366434941.2808 - val_loss: 1924650979.3215\n",
      "Epoch 4333/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 443997211.4800 - val_loss: 3568886742.5215\n",
      "Epoch 4334/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 802552007.4553 - val_loss: 2362395241.9646\n",
      "Epoch 4335/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 579482430.0191 - val_loss: 2349108435.8391\n",
      "Epoch 4336/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1185103645.1728 - val_loss: 2002034189.0340\n",
      "Epoch 4337/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 439298869.5194 - val_loss: 1948887499.3778\n",
      "Epoch 4338/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 368230504.0135 - val_loss: 3778311907.2315\n",
      "Epoch 4339/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 617693416.1846 - val_loss: 1809726018.4529\n",
      "Epoch 4340/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 264972228.9792 - val_loss: 4130047146.5226\n",
      "Epoch 4341/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 488250281.6117 - val_loss: 1722489014.4529\n",
      "Epoch 4342/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 370038301.2088 - val_loss: 5178863538.8759\n",
      "Epoch 4343/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 859274359.1581 - val_loss: 1991088187.0942\n",
      "Epoch 4344/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 373649111.4733 - val_loss: 1770895068.5682\n",
      "Epoch 4345/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 351725520.4277 - val_loss: 1822113423.5004\n",
      "Epoch 4346/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 397182633.6882 - val_loss: 2004939943.7547\n",
      "Epoch 4347/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 375127606.2667 - val_loss: 2092337280.4422\n",
      "Epoch 4348/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 339083231.4237 - val_loss: 1868128599.5814\n",
      "Epoch 4349/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 502700101.2583 - val_loss: 3128713760.6931\n",
      "Epoch 4350/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 644375877.0422 - val_loss: 1763655794.1176\n",
      "Epoch 4351/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 398627508.5110 - val_loss: 2087918068.2442\n",
      "Epoch 4352/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 532800461.1953 - val_loss: 2688734347.1257\n",
      "Epoch 4353/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 488707380.8711 - val_loss: 4452668537.7710\n",
      "Epoch 4354/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 609142019.4688 - val_loss: 1825334678.9356\n",
      "Epoch 4355/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 257303256.0450 - val_loss: 1899582820.6627\n",
      "Epoch 4356/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 334846893.3979 - val_loss: 1757122912.2475\n",
      "Epoch 4357/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 889290905.4271 - val_loss: 2668968286.5148\n",
      "Epoch 4358/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 595114753.3686 - val_loss: 3014234494.8118\n",
      "Epoch 4359/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 446701041.1750 - val_loss: 1825767360.3083\n",
      "Epoch 4360/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 238469386.5931 - val_loss: 1840185823.1089\n",
      "Epoch 4361/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 373424773.4902 - val_loss: 2198217566.4473\n",
      "Epoch 4362/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 513161166.3883 - val_loss: 1909171852.0439\n",
      "Epoch 4363/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 426351614.6674 - val_loss: 1886491712.7426\n",
      "Epoch 4364/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 461715598.7665 - val_loss: 1783684799.7480\n",
      "Epoch 4365/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 283336967.8424 - val_loss: 1772790092.0855\n",
      "Epoch 4366/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 496870292.9972 - val_loss: 1983341919.0909\n",
      "Epoch 4367/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 650107153.4316 - val_loss: 2585886618.0681\n",
      "Epoch 4368/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 466263569.6297 - val_loss: 1765948944.2993\n",
      "Epoch 4369/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 419115711.3877 - val_loss: 1953881491.5331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4370/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 597894335.7164 - val_loss: 1788314668.7190\n",
      "Epoch 4371/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 270613507.7636 - val_loss: 1752835912.7437\n",
      "Epoch 4372/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 351052441.3731 - val_loss: 1890153245.4076\n",
      "Epoch 4373/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 292891506.4738 - val_loss: 1976866675.3710\n",
      "Epoch 4374/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 485774448.1171 - val_loss: 2915278225.9488\n",
      "Epoch 4375/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 792707131.4440 - val_loss: 2078816834.0523\n",
      "Epoch 4376/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 795524904.0056 - val_loss: 1856432595.3665\n",
      "Epoch 4377/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 455980722.4581 - val_loss: 1875246512.4096\n",
      "Epoch 4378/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 394051959.9730 - val_loss: 2377418769.8453\n",
      "Epoch 4379/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 646747143.5273 - val_loss: 3097200268.8540\n",
      "Epoch 4380/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 580523278.5684 - val_loss: 2002315353.3660\n",
      "Epoch 4381/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 747745987.8717 - val_loss: 3749665508.2082\n",
      "Epoch 4382/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 877131212.5582 - val_loss: 1938744062.3842\n",
      "Epoch 4383/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 457478810.9038 - val_loss: 1781949563.1572\n",
      "Epoch 4384/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 327483164.3804 - val_loss: 1923878902.8231\n",
      "Epoch 4385/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 347692042.8768 - val_loss: 1891291602.0377\n",
      "Epoch 4386/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 483382537.1120 - val_loss: 1956068162.5114\n",
      "Epoch 4387/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 378458581.0242 - val_loss: 1783912351.0233\n",
      "Epoch 4388/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 355792899.3945 - val_loss: 1845787464.0833\n",
      "Epoch 4389/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 287955085.1818 - val_loss: 3045384155.8684\n",
      "Epoch 4390/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1036817935.1266 - val_loss: 2479998724.6087\n",
      "Epoch 4391/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 728502611.9572 - val_loss: 2051584164.1553\n",
      "Epoch 4392/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 252320193.1345 - val_loss: 1803562995.1820\n",
      "Epoch 4393/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 410107136.1767 - val_loss: 1718355071.4284\n",
      "Epoch 4394/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 482572307.8087 - val_loss: 3390671095.0706\n",
      "Epoch 4395/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 442335900.0203 - val_loss: 2191594305.4402\n",
      "Epoch 4396/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 354758674.2420 - val_loss: 1921729288.0653\n",
      "Epoch 4397/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 475720343.9865 - val_loss: 1977127389.5966\n",
      "Epoch 4398/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 466428025.1570 - val_loss: 3090237990.8501\n",
      "Epoch 4399/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 382574887.6443 - val_loss: 2165071838.9986\n",
      "Epoch 4400/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 327136594.1159 - val_loss: 2939947631.9055\n",
      "Epoch 4401/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 480212285.7175 - val_loss: 2155207081.1904\n",
      "Epoch 4402/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 338864140.9387 - val_loss: 2149303580.6515\n",
      "Epoch 4403/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 545013739.2493 - val_loss: 1830471994.1007\n",
      "Epoch 4404/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 290435675.7321 - val_loss: 2086949887.6129\n",
      "Epoch 4405/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 639215805.4789 - val_loss: 1771952775.5927\n",
      "Epoch 4406/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 484248605.5554 - val_loss: 2279447676.1654\n",
      "Epoch 4407/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 587551176.3962 - val_loss: 2097126584.3949\n",
      "Epoch 4408/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 428583082.5706 - val_loss: 1970389411.2023\n",
      "Epoch 4409/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 729640231.9235 - val_loss: 2145370030.5373\n",
      "Epoch 4410/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 418862075.6061 - val_loss: 2046591091.9651\n",
      "Epoch 4411/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 283055823.5228 - val_loss: 1700632726.6217\n",
      "Epoch 4412/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 493996933.0422 - val_loss: 2749337218.0163\n",
      "Epoch 4413/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 598506502.6269 - val_loss: 2788293621.9004\n",
      "Epoch 4414/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 617766857.5442 - val_loss: 1964564869.0183\n",
      "Epoch 4415/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1422650702.8565 - val_loss: 2101015466.6037\n",
      "Epoch 4416/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 269909072.2611 - val_loss: 2576259644.6515\n",
      "Epoch 4417/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 283038443.0208 - val_loss: 1811569901.3153\n",
      "Epoch 4418/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 437366387.7546 - val_loss: 1956323037.1060\n",
      "Epoch 4419/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 362905841.0805 - val_loss: 2766897343.0459\n",
      "Epoch 4420/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 460664643.1424 - val_loss: 1790256724.1564\n",
      "Epoch 4421/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 472370559.8559 - val_loss: 1980124193.0892\n",
      "Epoch 4422/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 467469564.3534 - val_loss: 2328696195.0245\n",
      "Epoch 4423/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 465763565.0197 - val_loss: 2989251307.4768\n",
      "Epoch 4424/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 397702360.5267 - val_loss: 3860433701.9859\n",
      "Epoch 4425/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 763971093.7310 - val_loss: 2023941769.6810\n",
      "Epoch 4426/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 360095417.4091 - val_loss: 6923250003.8931\n",
      "Epoch 4427/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 833530999.5003 - val_loss: 2201688041.6045\n",
      "Epoch 4428/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 506989953.3686 - val_loss: 1867379281.1027\n",
      "Epoch 4429/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 333816882.5121 - val_loss: 2127600325.9567\n",
      "Epoch 4430/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 681283573.9156 - val_loss: 2343057133.6731\n",
      "Epoch 4431/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 796424237.6725 - val_loss: 1851574271.0098\n",
      "Epoch 4432/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 329862450.7620 - val_loss: 2912240062.7578\n",
      "Epoch 4433/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 812085188.6539 - val_loss: 2070330051.7243\n",
      "Epoch 4434/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 328879252.4479 - val_loss: 1745592693.2973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4435/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 464534158.3703 - val_loss: 1950883241.0284\n",
      "Epoch 4436/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 414736040.8509 - val_loss: 2439084816.7246\n",
      "Epoch 4437/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 556457810.6201 - val_loss: 1911335120.0000\n",
      "Epoch 4438/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 404355929.0670 - val_loss: 2265159291.1572\n",
      "Epoch 4439/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 545779495.5273 - val_loss: 3694124660.9823\n",
      "Epoch 4440/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 616571232.4817 - val_loss: 1861286104.0068\n",
      "Epoch 4441/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 341878897.9358 - val_loss: 1987980045.4661\n",
      "Epoch 4442/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 497536425.2786 - val_loss: 2831496204.3859\n",
      "Epoch 4443/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 412211360.5402 - val_loss: 1728507552.8866\n",
      "Epoch 4444/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 374209142.4198 - val_loss: 3264124415.2079\n",
      "Epoch 4445/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 392006894.5414 - val_loss: 1713431261.2546\n",
      "Epoch 4446/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 308306357.7265 - val_loss: 1767788116.5907\n",
      "Epoch 4447/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 448182976.7586 - val_loss: 3046244105.7755\n",
      "Epoch 4448/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 543570375.0951 - val_loss: 1803303501.8217\n",
      "Epoch 4449/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 252246522.3455 - val_loss: 1722126365.9927\n",
      "Epoch 4450/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 325579957.3754 - val_loss: 2171078996.0596\n",
      "Epoch 4451/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 366123525.7625 - val_loss: 1865554543.7255\n",
      "Epoch 4452/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 987752906.2645 - val_loss: 3229404427.9089\n",
      "Epoch 4453/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 3716880550.2273 - val_loss: 1790307063.0616\n",
      "Epoch 4454/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 241795364.6460 - val_loss: 2423044631.4937\n",
      "Epoch 4455/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 324001565.8976 - val_loss: 1696686896.6053\n",
      "Epoch 4456/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 224813911.9910 - val_loss: 1794373418.1288\n",
      "Epoch 4457/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 215584953.8965 - val_loss: 1838451970.3404\n",
      "Epoch 4458/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 313451694.2983 - val_loss: 1879446469.8329\n",
      "Epoch 4459/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 405083814.7349 - val_loss: 1833642005.1826\n",
      "Epoch 4460/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 412369208.1576 - val_loss: 2304509536.2970\n",
      "Epoch 4461/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 400840309.9921 - val_loss: 2016763978.3674\n",
      "Epoch 4462/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 342110609.9358 - val_loss: 1788941722.0681\n",
      "Epoch 4463/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 318775629.5149 - val_loss: 1807588709.7384\n",
      "Epoch 4464/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 357938578.9443 - val_loss: 1773392588.2554\n",
      "Epoch 4465/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 478407855.5768 - val_loss: 1909065686.4900\n",
      "Epoch 4466/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 359741730.8542 - val_loss: 2722724322.4754\n",
      "Epoch 4467/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 415363502.5144 - val_loss: 4426825679.8965\n",
      "Epoch 4468/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 867784348.8503 - val_loss: 1693034047.5904\n",
      "Epoch 4469/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 447164201.8143 - val_loss: 2984927121.6923\n",
      "Epoch 4470/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 661188728.7428 - val_loss: 1758879852.9305\n",
      "Epoch 4471/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 232354039.2662 - val_loss: 1702809160.9485\n",
      "Epoch 4472/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 327900570.5256 - val_loss: 2420879941.9049\n",
      "Epoch 4473/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 328170293.3754 - val_loss: 2960822941.7046\n",
      "Epoch 4474/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 713153108.0338 - val_loss: 1791184222.9648\n",
      "Epoch 4475/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 356053016.2116 - val_loss: 1847728331.4048\n",
      "Epoch 4476/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 337989891.0523 - val_loss: 2126405478.6700\n",
      "Epoch 4477/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1000493562.5256 - val_loss: 1905368503.6602\n",
      "Epoch 4478/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 563184499.6646 - val_loss: 1734023977.1364\n",
      "Epoch 4479/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 527076891.5250 - val_loss: 2712486728.2273\n",
      "Epoch 4480/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 339927151.6308 - val_loss: 2172185796.7437\n",
      "Epoch 4481/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 644872578.5898 - val_loss: 1766184852.2352\n",
      "Epoch 4482/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 374955792.2971 - val_loss: 1727106797.0610\n",
      "Epoch 4483/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 392327244.2454 - val_loss: 1834752611.5826\n",
      "Epoch 4484/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 458001631.7659 - val_loss: 4241397704.9114\n",
      "Epoch 4485/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 466856116.0968 - val_loss: 1925688888.1013\n",
      "Epoch 4486/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 318659109.1683 - val_loss: 2746163427.6816\n",
      "Epoch 4487/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 620604913.9989 - val_loss: 2902940781.9612\n",
      "Epoch 4488/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 319057723.4980 - val_loss: 1743052404.5952\n",
      "Epoch 4489/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 278630948.1238 - val_loss: 2471525058.3764\n",
      "Epoch 4490/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 611704858.6517 - val_loss: 4728764077.7632\n",
      "Epoch 4491/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 777571777.8008 - val_loss: 1957714537.6225\n",
      "Epoch 4492/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 296757793.2425 - val_loss: 2288387344.9406\n",
      "Epoch 4493/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 418492538.1294 - val_loss: 1784655739.6973\n",
      "Epoch 4494/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 383508791.6804 - val_loss: 2570770818.0343\n",
      "Epoch 4495/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1082331788.6685 - val_loss: 2789507778.4799\n",
      "Epoch 4496/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 368948242.8565 - val_loss: 1818059953.6158\n",
      "Epoch 4497/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 245223217.6657 - val_loss: 1844494895.2214\n",
      "Epoch 4498/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 690602063.7732 - val_loss: 5155117467.0042\n",
      "Epoch 4499/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 467315173.3844 - val_loss: 1760636670.5778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4500/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 364668917.9645 - val_loss: 1758951900.5401\n",
      "Epoch 4501/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 423007196.9207 - val_loss: 7684120329.8655\n",
      "Epoch 4502/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1013822390.2397 - val_loss: 4655438096.8506\n",
      "Epoch 4503/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 2004182590.9105 - val_loss: 2010571731.8841\n",
      "Epoch 4504/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 452693931.1829 - val_loss: 1942031016.2408\n",
      "Epoch 4505/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 352877397.8514 - val_loss: 1744601364.0844\n",
      "Epoch 4506/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 265775671.5543 - val_loss: 1734890054.9648\n",
      "Epoch 4507/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 276718611.4845 - val_loss: 1720126286.2695\n",
      "Epoch 4508/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 249235632.8171 - val_loss: 2104964895.8110\n",
      "Epoch 4509/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 591439930.7777 - val_loss: 1694878916.3657\n",
      "Epoch 4510/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 249967959.1030 - val_loss: 1778598355.4025\n",
      "Epoch 4511/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 399423971.2954 - val_loss: 1806559090.2819\n",
      "Epoch 4512/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 421228370.9263 - val_loss: 1864069301.1353\n",
      "Epoch 4513/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 355266823.6353 - val_loss: 2077685296.2655\n",
      "Epoch 4514/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 365532490.8678 - val_loss: 1939777768.1620\n",
      "Epoch 4515/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 426419508.6550 - val_loss: 2810728064.7561\n",
      "Epoch 4516/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 1414888315.4620 - val_loss: 1960999703.1336\n",
      "Epoch 4517/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 401534925.3258 - val_loss: 1943112647.1291\n",
      "Epoch 4518/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 341372613.0242 - val_loss: 1838685924.7077\n",
      "Epoch 4519/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 494330597.1503 - val_loss: 1969604829.6326\n",
      "Epoch 4520/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 465585391.8109 - val_loss: 2124586646.3955\n",
      "Epoch 4521/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 514850000.9274 - val_loss: 2121666219.2788\n",
      "Epoch 4522/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 335495596.9071 - val_loss: 1741969854.8467\n",
      "Epoch 4523/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 427208497.3776 - val_loss: 2271760553.4425\n",
      "Epoch 4524/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 486148477.7310 - val_loss: 1921361240.5738\n",
      "Epoch 4525/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 331924513.4947 - val_loss: 5808041572.1316\n",
      "Epoch 4526/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1400232196.1238 - val_loss: 2619283195.8954\n",
      "Epoch 4527/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 483790100.6010 - val_loss: 1876809083.9876\n",
      "Epoch 4528/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 419378099.9347 - val_loss: 1963461129.9376\n",
      "Epoch 4529/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 635438847.5678 - val_loss: 2338126152.2453\n",
      "Epoch 4530/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 485861324.5920 - val_loss: 1686018967.2776\n",
      "Epoch 4531/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 310088225.0625 - val_loss: 2022868585.7080\n",
      "Epoch 4532/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 416869215.4778 - val_loss: 2035740662.9266\n",
      "Epoch 4533/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 357146694.5549 - val_loss: 1776790827.0267\n",
      "Epoch 4534/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 472227926.5053 - val_loss: 2138796652.8158\n",
      "Epoch 4535/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 706688612.9162 - val_loss: 1706884785.2962\n",
      "Epoch 4536/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 378244437.4294 - val_loss: 2119130309.9027\n",
      "Epoch 4537/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 526660176.4052 - val_loss: 2026833704.2633\n",
      "Epoch 4538/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 446602147.5014 - val_loss: 1944355291.8954\n",
      "Epoch 4539/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 455041363.7907 - val_loss: 3845049441.2332\n",
      "Epoch 4540/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 419221310.4333 - val_loss: 1732884155.5511\n",
      "Epoch 4541/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 330377680.5943 - val_loss: 2269527524.2397\n",
      "Epoch 4542/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 492213996.6595 - val_loss: 1859684864.5761\n",
      "Epoch 4543/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 512263855.5228 - val_loss: 2643668635.7063\n",
      "Epoch 4544/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 514573625.9133 - val_loss: 2108242848.9091\n",
      "Epoch 4545/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 387542731.7772 - val_loss: 2180510672.7786\n",
      "Epoch 4546/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 362765678.9826 - val_loss: 1894066582.2155\n",
      "Epoch 4547/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 533999848.7248 - val_loss: 1829591541.2141\n",
      "Epoch 4548/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 349916885.1818 - val_loss: 1843948210.7814\n",
      "Epoch 4549/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 577989836.2296 - val_loss: 3082672816.1395\n",
      "Epoch 4550/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 488338916.8441 - val_loss: 2737993563.7783\n",
      "Epoch 4551/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 446643543.1356 - val_loss: 1793356250.0636\n",
      "Epoch 4552/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 363729052.5965 - val_loss: 5414311118.3482\n",
      "Epoch 4553/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1756717413.5194 - val_loss: 1716631919.5589\n",
      "Epoch 4554/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 296965493.1232 - val_loss: 2114549586.5969\n",
      "Epoch 4555/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 460665270.0146 - val_loss: 2228199392.4276\n",
      "Epoch 4556/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 352111081.9764 - val_loss: 1929983429.8689\n",
      "Epoch 4557/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 402051001.6252 - val_loss: 5063730662.3280\n",
      "Epoch 4558/10000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 484442959.7952 - val_loss: 2162812660.8383\n",
      "Epoch 4559/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 368822387.3945 - val_loss: 4411975842.8714\n",
      "Epoch 4560/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 755263685.6725 - val_loss: 2290528878.4473\n",
      "Epoch 4561/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 700825412.4299 - val_loss: 2309557596.4444\n",
      "Epoch 4562/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 358710611.8087 - val_loss: 1694360072.2464\n",
      "Epoch 4563/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 501632409.3799 - val_loss: 2418706079.2169\n",
      "Epoch 4564/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 474023486.7485 - val_loss: 2312842159.7975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4565/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 386164339.1196 - val_loss: 1802283939.1010\n",
      "Epoch 4566/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 308037432.9409 - val_loss: 2855828881.2107\n",
      "Epoch 4567/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 420229736.3557 - val_loss: 1706175745.4717\n",
      "Epoch 4568/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 716412323.3855 - val_loss: 1677790201.4380\n",
      "Epoch 4569/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 317073148.3264 - val_loss: 2621819901.3536\n",
      "Epoch 4570/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 423191447.6263 - val_loss: 3979626038.8006\n",
      "Epoch 4571/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 867020176.3692 - val_loss: 1723348768.4816\n",
      "Epoch 4572/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 403652327.4260 - val_loss: 2053499611.6163\n",
      "Epoch 4573/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 295445769.0039 - val_loss: 7964271111.1291\n",
      "Epoch 4574/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 696732260.3399 - val_loss: 1766413986.9277\n",
      "Epoch 4575/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 298098949.8886 - val_loss: 2250618767.4104\n",
      "Epoch 4576/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 442920182.9826 - val_loss: 2575265974.6835\n",
      "Epoch 4577/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 320389151.1716 - val_loss: 1803633448.7471\n",
      "Epoch 4578/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 480136185.2155 - val_loss: 2233668144.1395\n",
      "Epoch 4579/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 555600079.8829 - val_loss: 3404066725.3378\n",
      "Epoch 4580/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 596648273.0174 - val_loss: 1685487785.6945\n",
      "Epoch 4581/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 354288690.8678 - val_loss: 1921329404.0754\n",
      "Epoch 4582/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 390241714.9623 - val_loss: 2308042278.9941\n",
      "Epoch 4583/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 308642111.6443 - val_loss: 1855229030.2920\n",
      "Epoch 4584/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 525807623.7074 - val_loss: 2069783104.3781\n",
      "Epoch 4585/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 566817879.7704 - val_loss: 1690222179.7536\n",
      "Epoch 4586/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 550871484.1193 - val_loss: 1590050729.6675\n",
      "Epoch 4587/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 336655786.3050 - val_loss: 3458338463.3429\n",
      "Epoch 4588/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 672156123.5566 - val_loss: 2529814388.9823\n",
      "Epoch 4589/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 322080841.6882 - val_loss: 1753871604.1632\n",
      "Epoch 4590/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 426438920.3557 - val_loss: 3251816138.1356\n",
      "Epoch 4591/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 597170339.8717 - val_loss: 2870012705.9173\n",
      "Epoch 4592/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 416527983.7749 - val_loss: 2577066057.9916\n",
      "Epoch 4593/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 514677259.1694 - val_loss: 1603684831.0819\n",
      "Epoch 4594/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 585591967.2167 - val_loss: 1970819789.7496\n",
      "Epoch 4595/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 333541553.2200 - val_loss: 1664993864.0833\n",
      "Epoch 4596/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 568101551.1806 - val_loss: 2025573830.8276\n",
      "Epoch 4597/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 505189678.1835 - val_loss: 1731267939.0200\n",
      "Epoch 4598/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 302891962.5706 - val_loss: 1752839529.1724\n",
      "Epoch 4599/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 250360978.8047 - val_loss: 1834455926.8726\n",
      "Epoch 4600/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 430470687.7884 - val_loss: 1696648492.5255\n",
      "Epoch 4601/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 401812153.8413 - val_loss: 2275213401.5820\n",
      "Epoch 4602/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 521665544.7428 - val_loss: 1830038311.8222\n",
      "Epoch 4603/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 260692245.9066 - val_loss: 1605099675.1820\n",
      "Epoch 4604/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 324603660.4615 - val_loss: 4846586174.2897\n",
      "Epoch 4605/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 625486233.7153 - val_loss: 3132120412.8225\n",
      "Epoch 4606/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 883511458.1519 - val_loss: 2700943801.2129\n",
      "Epoch 4607/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 480579849.0554 - val_loss: 2027497258.9345\n",
      "Epoch 4608/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 284104968.8959 - val_loss: 2185763173.6304\n",
      "Epoch 4609/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 424884300.1283 - val_loss: 2416554038.0084\n",
      "Epoch 4610/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 531733647.9505 - val_loss: 1964954829.6146\n",
      "Epoch 4611/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 503227827.7006 - val_loss: 1826492092.5165\n",
      "Epoch 4612/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 285393424.5672 - val_loss: 4132970999.3046\n",
      "Epoch 4613/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 847505109.6590 - val_loss: 1698084409.0419\n",
      "Epoch 4614/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 318388455.1491 - val_loss: 2287540953.4470\n",
      "Epoch 4615/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 329148161.3686 - val_loss: 1605612179.8841\n",
      "Epoch 4616/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 367908957.0107 - val_loss: 2734734566.8681\n",
      "Epoch 4617/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 752709047.5903 - val_loss: 2110171584.0270\n",
      "Epoch 4618/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 447743659.3461 - val_loss: 1558637788.6515\n",
      "Epoch 4619/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 341548183.1221 - val_loss: 2832684323.2495\n",
      "Epoch 4620/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 702284690.2555 - val_loss: 1644450317.3333\n",
      "Epoch 4621/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 277700474.1654 - val_loss: 1744716839.9685\n",
      "Epoch 4622/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 329472321.1075 - val_loss: 1911873700.1316\n",
      "Epoch 4623/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 389008864.9724 - val_loss: 1790355918.6205\n",
      "Epoch 4624/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 344606171.6691 - val_loss: 1958075549.9567\n",
      "Epoch 4625/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 485828607.5453 - val_loss: 1605848573.7541\n",
      "Epoch 4626/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 347860307.9257 - val_loss: 1648005393.2692\n",
      "Epoch 4627/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 386206293.7445 - val_loss: 2180564646.1457\n",
      "Epoch 4628/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 647509244.0203 - val_loss: 2336141863.8222\n",
      "Epoch 4629/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 519440691.7186 - val_loss: 2572399705.2219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4630/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 864449895.8965 - val_loss: 1654496988.1474\n",
      "Epoch 4631/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 257813018.0394 - val_loss: 1629116124.5615\n",
      "Epoch 4632/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 489938216.5537 - val_loss: 2706891155.8751\n",
      "Epoch 4633/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 711926317.8481 - val_loss: 2921473162.5496\n",
      "Epoch 4634/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 285718355.5431 - val_loss: 1734851437.9837\n",
      "Epoch 4635/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 311253204.7811 - val_loss: 1830964464.1350\n",
      "Epoch 4636/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 491805729.4226 - val_loss: 2120900506.9952\n",
      "Epoch 4637/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 711876486.9150 - val_loss: 3774520184.9789\n",
      "Epoch 4638/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1070689103.2347 - val_loss: 1972470195.6321\n",
      "Epoch 4639/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 373722097.6747 - val_loss: 1613871532.7280\n",
      "Epoch 4640/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 349801319.7974 - val_loss: 1766148526.9153\n",
      "Epoch 4641/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 569449479.7794 - val_loss: 4647281361.6968\n",
      "Epoch 4642/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1919214181.7445 - val_loss: 1738332609.1972\n",
      "Epoch 4643/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 452800810.8588 - val_loss: 1679727383.2866\n",
      "Epoch 4644/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 345447868.9567 - val_loss: 1567851909.6259\n",
      "Epoch 4645/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 251849933.5779 - val_loss: 1555627427.2405\n",
      "Epoch 4646/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 308663012.9702 - val_loss: 1673590112.4613\n",
      "Epoch 4647/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 256540905.2020 - val_loss: 1844153343.4194\n",
      "Epoch 4648/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 409855316.3489 - val_loss: 1778839464.9834\n",
      "Epoch 4649/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 295301052.2904 - val_loss: 2473897080.2948\n",
      "Epoch 4650/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 384636926.3973 - val_loss: 1654799470.0917\n",
      "Epoch 4651/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 356754170.9578 - val_loss: 1858802706.7769\n",
      "Epoch 4652/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 504435475.1773 - val_loss: 1764662398.5238\n",
      "Epoch 4653/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 281513592.8194 - val_loss: 2256084436.0911\n",
      "Epoch 4654/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 499491207.5273 - val_loss: 3137224883.2180\n",
      "Epoch 4655/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 785743394.6832 - val_loss: 1685399081.4155\n",
      "Epoch 4656/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 515628892.5605 - val_loss: 1651737990.3010\n",
      "Epoch 4657/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 283016071.8920 - val_loss: 1580445760.3826\n",
      "Epoch 4658/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 346197510.3748 - val_loss: 1706156222.0377\n",
      "Epoch 4659/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 376093298.1519 - val_loss: 3079721822.4248\n",
      "Epoch 4660/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 471742157.0884 - val_loss: 1985973333.9814\n",
      "Epoch 4661/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 290637989.7062 - val_loss: 1887665444.5997\n",
      "Epoch 4662/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 423732445.7850 - val_loss: 2147097668.3792\n",
      "Epoch 4663/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 761745600.8689 - val_loss: 1639190651.9269\n",
      "Epoch 4664/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 258194836.5830 - val_loss: 1542444025.6293\n",
      "Epoch 4665/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 387386695.6443 - val_loss: 1553062958.9648\n",
      "Epoch 4666/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 483272283.3360 - val_loss: 3254236516.0416\n",
      "Epoch 4667/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1114499071.4958 - val_loss: 1882504845.3536\n",
      "Epoch 4668/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 983524850.7462 - val_loss: 5127604006.9941\n",
      "Epoch 4669/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 640232926.2487 - val_loss: 1621244045.1015\n",
      "Epoch 4670/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 220742580.8081 - val_loss: 1728372810.0276\n",
      "Epoch 4671/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 265349279.5138 - val_loss: 1820854106.2323\n",
      "Epoch 4672/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 311169623.3247 - val_loss: 1599088376.0743\n",
      "Epoch 4673/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 406798441.8863 - val_loss: 2471644033.5482\n",
      "Epoch 4674/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 715071401.0580 - val_loss: 2063682117.3243\n",
      "Epoch 4675/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 340745053.9291 - val_loss: 2362882480.6796\n",
      "Epoch 4676/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 359506940.1823 - val_loss: 1602917516.5300\n",
      "Epoch 4677/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 496481031.8514 - val_loss: 2183952799.5589\n",
      "Epoch 4678/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 386311391.9505 - val_loss: 1767881722.0951\n",
      "Epoch 4679/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 380228627.2414 - val_loss: 1631682189.8048\n",
      "Epoch 4680/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 270648043.2369 - val_loss: 1665437816.8079\n",
      "Epoch 4681/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 242130540.1373 - val_loss: 2338534176.8731\n",
      "Epoch 4682/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 623070146.5211 - val_loss: 1911263172.5907\n",
      "Epoch 4683/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 335001420.1733 - val_loss: 2109828320.8641\n",
      "Epoch 4684/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 507293182.7710 - val_loss: 1606343085.3716\n",
      "Epoch 4685/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 369181598.1632 - val_loss: 1619211381.4706\n",
      "Epoch 4686/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 351613685.6635 - val_loss: 3131012543.1989\n",
      "Epoch 4687/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 737623802.7012 - val_loss: 2166612020.0821\n",
      "Epoch 4688/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 339085533.8210 - val_loss: 2381829097.1724\n",
      "Epoch 4689/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 970968603.4710 - val_loss: 3026087623.2866\n",
      "Epoch 4690/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 746722051.2774 - val_loss: 2156400536.2678\n",
      "Epoch 4691/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 347971100.1373 - val_loss: 1898494383.9145\n",
      "Epoch 4692/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 323648947.5464 - val_loss: 1576242261.6416\n",
      "Epoch 4693/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 596385057.3236 - val_loss: 1907941981.5066\n",
      "Epoch 4694/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 312999415.2212 - val_loss: 1667199328.9451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4695/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 374791780.5200 - val_loss: 2303421905.6968\n",
      "Epoch 4696/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 442506448.8014 - val_loss: 1547044299.8278\n",
      "Epoch 4697/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 328497337.3416 - val_loss: 1555143322.9907\n",
      "Epoch 4698/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 387820497.6837 - val_loss: 2197837386.9637\n",
      "Epoch 4699/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 744063588.8981 - val_loss: 1641510762.9637\n",
      "Epoch 4700/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 323258085.5644 - val_loss: 2466047183.8785\n",
      "Epoch 4701/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 578000130.4041 - val_loss: 1560447540.4647\n",
      "Epoch 4702/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 509676403.2504 - val_loss: 1936301814.1930\n",
      "Epoch 4703/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 423496134.5008 - val_loss: 1724269600.9902\n",
      "Epoch 4704/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 305826132.6730 - val_loss: 1604420898.5384\n",
      "Epoch 4705/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 382488654.4423 - val_loss: 1612091119.1134\n",
      "Epoch 4706/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 437347146.4086 - val_loss: 2647049907.2180\n",
      "Epoch 4707/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 547228782.6404 - val_loss: 2437738443.5578\n",
      "Epoch 4708/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 623601119.9820 - val_loss: 1980917365.1347\n",
      "Epoch 4709/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 495425725.0287 - val_loss: 1612890275.3665\n",
      "Epoch 4710/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 329949306.0754 - val_loss: 2098585827.3575\n",
      "Epoch 4711/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 515608766.2352 - val_loss: 1903237334.4675\n",
      "Epoch 4712/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 769706212.6820 - val_loss: 1746641726.2942\n",
      "Epoch 4713/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 281231784.3196 - val_loss: 1893063554.1873\n",
      "Epoch 4714/10000\n",
      "3554/3554 [==============================] - 0s 131us/step - loss: 476567741.3708 - val_loss: 4623386806.3685\n",
      "Epoch 4715/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 615437927.9775 - val_loss: 1560308949.7333\n",
      "Epoch 4716/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 339635654.9871 - val_loss: 1779934435.1674\n",
      "Epoch 4717/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 407588882.7102 - val_loss: 1630300969.5865\n",
      "Epoch 4718/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 333692541.8571 - val_loss: 1613324876.2284\n",
      "Epoch 4719/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 463155802.6156 - val_loss: 2438322468.0596\n",
      "Epoch 4720/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 457900442.6066 - val_loss: 1916867323.3238\n",
      "Epoch 4721/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 492742475.7591 - val_loss: 3590988376.8979\n",
      "Epoch 4722/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 836744456.1756 - val_loss: 4493419975.9032\n",
      "Epoch 4723/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 447736635.6781 - val_loss: 1991858202.3831\n",
      "Epoch 4724/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 303068246.0957 - val_loss: 2389861728.3601\n",
      "Epoch 4725/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 434695430.3185 - val_loss: 2099672559.4374\n",
      "Epoch 4726/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 436836710.2307 - val_loss: 2464756392.5153\n",
      "Epoch 4727/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 444260580.0518 - val_loss: 1529084730.9570\n",
      "Epoch 4728/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 532225480.6438 - val_loss: 1633091632.3511\n",
      "Epoch 4729/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 455596317.9111 - val_loss: 1511605148.8450\n",
      "Epoch 4730/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 253710906.4412 - val_loss: 1553887232.1305\n",
      "Epoch 4731/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 319708756.9972 - val_loss: 1882035785.4425\n",
      "Epoch 4732/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 375322209.6747 - val_loss: 3958864121.1589\n",
      "Epoch 4733/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 485436281.1210 - val_loss: 1574146671.3924\n",
      "Epoch 4734/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 384509395.5566 - val_loss: 3341044801.9623\n",
      "Epoch 4735/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 555569284.3579 - val_loss: 2132444637.1150\n",
      "Epoch 4736/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 417124335.1086 - val_loss: 2410851678.2627\n",
      "Epoch 4737/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 607811136.3151 - val_loss: 1603386809.2129\n",
      "Epoch 4738/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 313118124.5965 - val_loss: 1572831742.4968\n",
      "Epoch 4739/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 262981041.0535 - val_loss: 2739521801.8835\n",
      "Epoch 4740/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 543472210.2420 - val_loss: 1752063551.6804\n",
      "Epoch 4741/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 314732015.7029 - val_loss: 1748603025.3277\n",
      "Epoch 4742/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 332366430.7845 - val_loss: 1518038811.8166\n",
      "Epoch 4743/10000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 291618090.0484 - val_loss: 4229315367.1381\n",
      "Epoch 4744/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 475187565.9381 - val_loss: 1932881864.3353\n",
      "Epoch 4745/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 501876751.3427 - val_loss: 2656063026.3089\n",
      "Epoch 4746/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 780840284.7904 - val_loss: 2630587503.0774\n",
      "Epoch 4747/10000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 501741329.8638 - val_loss: 2956802932.4062\n",
      "Epoch 4748/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 499568370.0979 - val_loss: 2299559153.3637\n",
      "Epoch 4749/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 363886640.6753 - val_loss: 3227802470.0489\n",
      "Epoch 4750/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 321785313.2425 - val_loss: 1571337095.7637\n",
      "Epoch 4751/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 326421778.2712 - val_loss: 2058685653.1893\n",
      "Epoch 4752/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 491575872.6483 - val_loss: 1496185301.9049\n",
      "Epoch 4753/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 336381837.0017 - val_loss: 1514024136.1643\n",
      "Epoch 4754/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 408847034.1835 - val_loss: 1664439273.0419\n",
      "Epoch 4755/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 516978058.0484 - val_loss: 1571691544.7269\n",
      "Epoch 4756/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 387395290.7687 - val_loss: 1572592137.1454\n",
      "Epoch 4757/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 519363449.3461 - val_loss: 1616353299.9651\n",
      "Epoch 4758/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 530342333.1187 - val_loss: 2224070600.4433\n",
      "Epoch 4759/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 527046647.5363 - val_loss: 1691450735.4194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4760/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 299459216.5312 - val_loss: 2207267306.6757\n",
      "Epoch 4761/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 772268514.9533 - val_loss: 1648101939.5623\n",
      "Epoch 4762/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 243999988.3129 - val_loss: 1538867780.4354\n",
      "Epoch 4763/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 558417929.4361 - val_loss: 2745657707.8459\n",
      "Epoch 4764/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 609183886.2622 - val_loss: 3046319826.9930\n",
      "Epoch 4765/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 552596908.4907 - val_loss: 1568587002.8585\n",
      "Epoch 4766/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 284590251.7096 - val_loss: 1501937921.8768\n",
      "Epoch 4767/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 253462915.4800 - val_loss: 1477261444.1406\n",
      "Epoch 4768/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 211168709.3033 - val_loss: 1633205018.5632\n",
      "Epoch 4769/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 278140311.3832 - val_loss: 1686738310.3730\n",
      "Epoch 4770/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 421959344.6213 - val_loss: 1767334697.7845\n",
      "Epoch 4771/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 593227773.6590 - val_loss: 3306922295.3406\n",
      "Epoch 4772/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 536639271.3292 - val_loss: 1460639085.3165\n",
      "Epoch 4773/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 539808850.6201 - val_loss: 1964629275.3283\n",
      "Epoch 4774/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 725004528.7428 - val_loss: 2008440267.4498\n",
      "Epoch 4775/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 285839134.7822 - val_loss: 1760810208.1800\n",
      "Epoch 4776/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 291696647.1311 - val_loss: 2047307423.3834\n",
      "Epoch 4777/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 610784179.2639 - val_loss: 1659743285.5899\n",
      "Epoch 4778/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 319785198.7485 - val_loss: 1775681150.2717\n",
      "Epoch 4779/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 350556591.1626 - val_loss: 1841452411.5893\n",
      "Epoch 4780/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 309027713.9088 - val_loss: 2065576736.9451\n",
      "Epoch 4781/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 594400592.3512 - val_loss: 1564499956.9823\n",
      "Epoch 4782/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 321395630.7034 - val_loss: 1786111616.7111\n",
      "Epoch 4783/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 320454291.9707 - val_loss: 2011390409.6675\n",
      "Epoch 4784/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1013187944.9859 - val_loss: 2619273665.9623\n",
      "Epoch 4785/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 314444272.4322 - val_loss: 1492774773.4346\n",
      "Epoch 4786/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 384591823.6488 - val_loss: 2572993713.2197\n",
      "Epoch 4787/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 410318943.4823 - val_loss: 1915819710.2357\n",
      "Epoch 4788/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 326747774.4873 - val_loss: 1619407944.4748\n",
      "Epoch 4789/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 454245010.6156 - val_loss: 1753110261.5730\n",
      "Epoch 4790/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 306701772.6595 - val_loss: 4034847928.3488\n",
      "Epoch 4791/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 666065665.5307 - val_loss: 1568155189.6619\n",
      "Epoch 4792/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 341139656.9499 - val_loss: 2585407932.9215\n",
      "Epoch 4793/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 311997789.7085 - val_loss: 2728523700.8023\n",
      "Epoch 4794/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 298495689.1300 - val_loss: 1946354848.2700\n",
      "Epoch 4795/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 470800373.3033 - val_loss: 2579063455.8290\n",
      "Epoch 4796/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 657278137.9944 - val_loss: 1927549521.7328\n",
      "Epoch 4797/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 316949946.7057 - val_loss: 3164336509.2636\n",
      "Epoch 4798/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 351084133.0242 - val_loss: 2048111757.6101\n",
      "Epoch 4799/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 299647846.1362 - val_loss: 3656376960.0360\n",
      "Epoch 4800/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 761918345.9764 - val_loss: 2071594808.5828\n",
      "Epoch 4801/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 365285224.7338 - val_loss: 1891422521.4897\n",
      "Epoch 4802/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 651955393.9088 - val_loss: 5326237850.3921\n",
      "Epoch 4803/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 622670076.5875 - val_loss: 1488100966.4810\n",
      "Epoch 4804/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 252115747.0073 - val_loss: 3857865151.9820\n",
      "Epoch 4805/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 784699934.4153 - val_loss: 1960726866.1648\n",
      "Epoch 4806/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 375220334.5549 - val_loss: 1589059550.2357\n",
      "Epoch 4807/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 265649689.7333 - val_loss: 1741975629.5561\n",
      "Epoch 4808/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 409087676.2904 - val_loss: 5944137536.5401\n",
      "Epoch 4809/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 4125995234.7822 - val_loss: 1489858570.9075\n",
      "Epoch 4810/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 220175897.0129 - val_loss: 2300304656.8506\n",
      "Epoch 4811/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 355100477.3258 - val_loss: 1930182351.3924\n",
      "Epoch 4812/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 213088874.7462 - val_loss: 1461834797.2872\n",
      "Epoch 4813/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 282164286.9465 - val_loss: 2000851987.9111\n",
      "Epoch 4814/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 320404515.7051 - val_loss: 1425647390.2807\n",
      "Epoch 4815/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 208692446.5864 - val_loss: 1479242996.0146\n",
      "Epoch 4816/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 239800970.3635 - val_loss: 1714364185.6360\n",
      "Epoch 4817/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 220323738.3275 - val_loss: 2224255827.4610\n",
      "Epoch 4818/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 483799762.1159 - val_loss: 1983590471.9032\n",
      "Epoch 4819/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 531064404.7541 - val_loss: 2561894923.3508\n",
      "Epoch 4820/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 431371028.5650 - val_loss: 1996077383.4937\n",
      "Epoch 4821/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 295701255.9595 - val_loss: 1962458085.8419\n",
      "Epoch 4822/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 327199152.4952 - val_loss: 2701969845.5764\n",
      "Epoch 4823/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 367789748.9071 - val_loss: 1695894593.7013\n",
      "Epoch 4824/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 324061381.3483 - val_loss: 1669951166.8591\n",
      "Epoch 4825/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 93us/step - loss: 410634572.0653 - val_loss: 1788756009.6765\n",
      "Epoch 4826/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 524218876.3984 - val_loss: 1679433601.1882\n",
      "Epoch 4827/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 463991975.6275 - val_loss: 1703071572.5187\n",
      "Epoch 4828/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 352420108.9657 - val_loss: 1436152273.5640\n",
      "Epoch 4829/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 294889959.6083 - val_loss: 1491328457.7148\n",
      "Epoch 4830/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 359120885.8526 - val_loss: 2558624238.2492\n",
      "Epoch 4831/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 311725264.5672 - val_loss: 1725543084.0529\n",
      "Epoch 4832/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 580859363.5476 - val_loss: 2616041799.2371\n",
      "Epoch 4833/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 504740520.2656 - val_loss: 2617088877.6731\n",
      "Epoch 4834/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 382569462.3658 - val_loss: 1784851913.7125\n",
      "Epoch 4835/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 340492659.6826 - val_loss: 1685106124.1159\n",
      "Epoch 4836/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 362503349.8796 - val_loss: 2111069848.3938\n",
      "Epoch 4837/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 595277237.9516 - val_loss: 2618744829.0835\n",
      "Epoch 4838/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 586817494.6719 - val_loss: 1646670046.1322\n",
      "Epoch 4839/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 418003826.3140 - val_loss: 1982079018.6869\n",
      "Epoch 4840/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 534216289.4744 - val_loss: 1594810885.6349\n",
      "Epoch 4841/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 326622165.6455 - val_loss: 2423650739.5241\n",
      "Epoch 4842/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 611685991.4102 - val_loss: 1446899327.9595\n",
      "Epoch 4843/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 218940007.1131 - val_loss: 3229662136.8889\n",
      "Epoch 4844/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 522140760.4727 - val_loss: 1544641156.7595\n",
      "Epoch 4845/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 259013286.2487 - val_loss: 3770924261.8599\n",
      "Epoch 4846/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1077831958.6719 - val_loss: 1698125498.2796\n",
      "Epoch 4847/10000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 304464033.2065 - val_loss: 1834597696.7381\n",
      "Epoch 4848/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 435967658.2285 - val_loss: 1901428327.4802\n",
      "Epoch 4849/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 310430096.7113 - val_loss: 1544390003.6366\n",
      "Epoch 4850/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 448043477.7265 - val_loss: 1576137299.3125\n",
      "Epoch 4851/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 281453050.1925 - val_loss: 1950307893.5224\n",
      "Epoch 4852/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 343158612.8171 - val_loss: 1586666357.2253\n",
      "Epoch 4853/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 553730095.5408 - val_loss: 7915750305.6653\n",
      "Epoch 4854/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1808987891.9887 - val_loss: 1633452312.6841\n",
      "Epoch 4855/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 374066124.4705 - val_loss: 1934809331.4790\n",
      "Epoch 4856/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 478444663.3056 - val_loss: 1562249362.7634\n",
      "Epoch 4857/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 195940543.0276 - val_loss: 1649224339.4993\n",
      "Epoch 4858/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 233638307.7389 - val_loss: 1608024333.0048\n",
      "Epoch 4859/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 253090960.5785 - val_loss: 1469434784.3128\n",
      "Epoch 4860/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 242537940.8261 - val_loss: 1827638815.6219\n",
      "Epoch 4861/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 399440667.5250 - val_loss: 1541818709.2231\n",
      "Epoch 4862/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 325069042.9623 - val_loss: 2493195158.8096\n",
      "Epoch 4863/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 436908632.7710 - val_loss: 1579000873.5235\n",
      "Epoch 4864/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 285815400.8779 - val_loss: 1897479306.7567\n",
      "Epoch 4865/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 654310492.0023 - val_loss: 1701957920.1170\n",
      "Epoch 4866/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 367486834.7102 - val_loss: 1684320133.7249\n",
      "Epoch 4867/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 450746407.2752 - val_loss: 2333198613.2433\n",
      "Epoch 4868/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 439220967.8154 - val_loss: 3443780262.3460\n",
      "Epoch 4869/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 415593435.8132 - val_loss: 1520027668.7392\n",
      "Epoch 4870/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 359854689.9223 - val_loss: 1441552594.5159\n",
      "Epoch 4871/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 377133787.0771 - val_loss: 2363067350.3415\n",
      "Epoch 4872/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 450109612.4795 - val_loss: 2248141355.6388\n",
      "Epoch 4873/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 404415128.0045 - val_loss: 5585410046.3437\n",
      "Epoch 4874/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 809330655.4057 - val_loss: 1846650951.3271\n",
      "Epoch 4875/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 486535282.0979 - val_loss: 1822177190.1480\n",
      "Epoch 4876/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 299946083.2639 - val_loss: 1712203342.7488\n",
      "Epoch 4877/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 357481315.7636 - val_loss: 2429752606.1727\n",
      "Epoch 4878/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 466236497.1255 - val_loss: 1619614647.3609\n",
      "Epoch 4879/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 292272173.6545 - val_loss: 2854038574.7713\n",
      "Epoch 4880/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 321326468.1148 - val_loss: 1831521274.4731\n",
      "Epoch 4881/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 379686935.1311 - val_loss: 2392087744.9902\n",
      "Epoch 4882/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 728775690.8227 - val_loss: 2184745586.2098\n",
      "Epoch 4883/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 348928527.5588 - val_loss: 2042428801.0262\n",
      "Epoch 4884/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 384978723.6781 - val_loss: 2213936684.8450\n",
      "Epoch 4885/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 391241491.3585 - val_loss: 1536729931.4318\n",
      "Epoch 4886/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 291615093.6995 - val_loss: 2713465914.5091\n",
      "Epoch 4887/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 760225075.4305 - val_loss: 1572501326.3932\n",
      "Epoch 4888/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 333331943.8154 - val_loss: 1519885700.4287\n",
      "Epoch 4889/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 339154857.6432 - val_loss: 1756000889.3300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4890/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 353722570.2285 - val_loss: 1875023960.8523\n",
      "Epoch 4891/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 463564806.8700 - val_loss: 1925028790.5845\n",
      "Epoch 4892/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 669226089.3821 - val_loss: 3118929269.3963\n",
      "Epoch 4893/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 899159191.1221 - val_loss: 2601371450.5451\n",
      "Epoch 4894/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 357283939.3180 - val_loss: 1405821931.2585\n",
      "Epoch 4895/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 264029682.8182 - val_loss: 1677775774.0512\n",
      "Epoch 4896/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 209017560.4547 - val_loss: 1978548806.3707\n",
      "Epoch 4897/10000\n",
      "3554/3554 [==============================] - 1s 141us/step - loss: 564502645.6140 - val_loss: 1624023967.7435\n",
      "Epoch 4898/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 314202869.8075 - val_loss: 1448067778.4259\n",
      "Epoch 4899/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 330356895.8739 - val_loss: 2370829184.6481\n",
      "Epoch 4900/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 435028803.4710 - val_loss: 2027433282.3404\n",
      "Epoch 4901/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 636199495.0591 - val_loss: 3873376035.8616\n",
      "Epoch 4902/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 508582467.7425 - val_loss: 1801983088.7201\n",
      "Epoch 4903/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 355577941.8931 - val_loss: 1827707978.6037\n",
      "Epoch 4904/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 358113343.8920 - val_loss: 4583678659.0065\n",
      "Epoch 4905/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 507168276.2842 - val_loss: 1495696646.2020\n",
      "Epoch 4906/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 508006051.7006 - val_loss: 1880062642.5204\n",
      "Epoch 4907/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 310872105.4541 - val_loss: 1806142705.6698\n",
      "Epoch 4908/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 407600087.9865 - val_loss: 1553868056.1418\n",
      "Epoch 4909/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 343702748.3084 - val_loss: 1691321543.7232\n",
      "Epoch 4910/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 903749132.8216 - val_loss: 1571923291.6174\n",
      "Epoch 4911/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 279881565.1728 - val_loss: 2102450043.2743\n",
      "Epoch 4912/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 457731441.5037 - val_loss: 2083772627.2090\n",
      "Epoch 4913/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 247687217.1255 - val_loss: 1685221344.7111\n",
      "Epoch 4914/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 569553747.3855 - val_loss: 2492322021.4278\n",
      "Epoch 4915/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 519374669.8255 - val_loss: 1497089918.5598\n",
      "Epoch 4916/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 450262272.8284 - val_loss: 1659046871.7367\n",
      "Epoch 4917/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 247888028.0743 - val_loss: 1869115890.5541\n",
      "Epoch 4918/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 407207532.8666 - val_loss: 1567796175.3474\n",
      "Epoch 4919/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 332870020.0248 - val_loss: 1649470676.1969\n",
      "Epoch 4920/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 417553978.4626 - val_loss: 2415977706.3111\n",
      "Epoch 4921/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 381491979.9572 - val_loss: 2481502892.4579\n",
      "Epoch 4922/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 980792688.4052 - val_loss: 1800021085.5246\n",
      "Epoch 4923/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 327484691.1244 - val_loss: 1673397784.7426\n",
      "Epoch 4924/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 288087199.5205 - val_loss: 1465940999.4802\n",
      "Epoch 4925/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 347798648.7248 - val_loss: 1534438227.8031\n",
      "Epoch 4926/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 375091284.4997 - val_loss: 4276336646.0129\n",
      "Epoch 4927/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 393078992.6393 - val_loss: 1552628203.9314\n",
      "Epoch 4928/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 358189036.1373 - val_loss: 1675716022.9086\n",
      "Epoch 4929/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 301495338.7867 - val_loss: 1658237216.6841\n",
      "Epoch 4930/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 691713375.1716 - val_loss: 2392643889.1657\n",
      "Epoch 4931/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 442652819.2324 - val_loss: 4239273761.9173\n",
      "Epoch 4932/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 746290090.1654 - val_loss: 2545519773.7046\n",
      "Epoch 4933/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 371980789.0884 - val_loss: 1563879386.7612\n",
      "Epoch 4934/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 330063306.5796 - val_loss: 1679882749.6484\n",
      "Epoch 4935/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 278230267.0838 - val_loss: 1511822157.4256\n",
      "Epoch 4936/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 393951541.8796 - val_loss: 1691698253.3311\n",
      "Epoch 4937/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 356811296.1261 - val_loss: 2058202816.5041\n",
      "Epoch 4938/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 841164785.1255 - val_loss: 1726042572.3319\n",
      "Epoch 4939/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 280319351.5768 - val_loss: 1489583550.0917\n",
      "Epoch 4940/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 264316454.1047 - val_loss: 1992391300.2487\n",
      "Epoch 4941/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 487031035.5701 - val_loss: 1669495197.6146\n",
      "Epoch 4942/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 305257445.5824 - val_loss: 2618532356.5907\n",
      "Epoch 4943/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 382274648.1936 - val_loss: 1506128846.0129\n",
      "Epoch 4944/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 384287185.8458 - val_loss: 2442295365.2748\n",
      "Epoch 4945/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 447428110.1362 - val_loss: 1517005882.7972\n",
      "Epoch 4946/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 223249156.7901 - val_loss: 2126226123.8098\n",
      "Epoch 4947/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 913176875.9595 - val_loss: 1571263235.1055\n",
      "Epoch 4948/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 471316070.7349 - val_loss: 8181581976.6639\n",
      "Epoch 4949/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1560431855.4418 - val_loss: 1463701643.1302\n",
      "Epoch 4950/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 214001500.0563 - val_loss: 1602765473.2928\n",
      "Epoch 4951/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 313002795.0028 - val_loss: 2307383366.2470\n",
      "Epoch 4952/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 427299564.1373 - val_loss: 1564993799.1786\n",
      "Epoch 4953/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 221564891.3405 - val_loss: 1618494311.0233\n",
      "Epoch 4954/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 351883085.5419 - val_loss: 1562879159.0841\n",
      "Epoch 4955/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 551109293.8644 - val_loss: 1675324283.3868\n",
      "Epoch 4956/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 550623161.8413 - val_loss: 1622686071.2776\n",
      "Epoch 4957/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 352121224.4834 - val_loss: 1501294386.8579\n",
      "Epoch 4958/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 423423138.4378 - val_loss: 1423946796.4129\n",
      "Epoch 4959/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 217631898.1120 - val_loss: 1640417971.6411\n",
      "Epoch 4960/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 211487557.2223 - val_loss: 1462892769.6878\n",
      "Epoch 4961/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 371129957.5689 - val_loss: 2168699052.5570\n",
      "Epoch 4962/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 334459736.1306 - val_loss: 1705072869.3378\n",
      "Epoch 4963/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 363840457.9944 - val_loss: 2592072092.1564\n",
      "Epoch 4964/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 549140985.6972 - val_loss: 2160536631.8087\n",
      "Epoch 4965/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 290050593.2200 - val_loss: 1749001969.8678\n",
      "Epoch 4966/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 444143117.6860 - val_loss: 2561219549.5786\n",
      "Epoch 4967/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 918585152.6123 - val_loss: 3273768669.8667\n",
      "Epoch 4968/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 684771268.0698 - val_loss: 1572945534.7713\n",
      "Epoch 4969/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 406695413.4204 - val_loss: 1698689853.3986\n",
      "Epoch 4970/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 291708788.9432 - val_loss: 1723932097.7328\n",
      "Epoch 4971/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 875518948.6820 - val_loss: 2118986784.6391\n",
      "Epoch 4972/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 414992582.8790 - val_loss: 2098696371.7401\n",
      "Epoch 4973/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 248934116.1868 - val_loss: 1945976589.8082\n",
      "Epoch 4974/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 232122063.5993 - val_loss: 2389188112.1305\n",
      "Epoch 4975/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 452131970.5211 - val_loss: 1632808462.5823\n",
      "Epoch 4976/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 277584942.0461 - val_loss: 1945185322.3426\n",
      "Epoch 4977/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 311651109.7445 - val_loss: 1480480134.6160\n",
      "Epoch 4978/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 269831245.0467 - val_loss: 1839907631.8425\n",
      "Epoch 4979/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 403658468.7946 - val_loss: 1544144912.2385\n",
      "Epoch 4980/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 739816223.7299 - val_loss: 6515759909.6619\n",
      "Epoch 4981/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1327059485.0287 - val_loss: 1624443382.2785\n",
      "Epoch 4982/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 311317686.7349 - val_loss: 1429966914.0186\n",
      "Epoch 4983/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 327416085.5554 - val_loss: 1488097437.8982\n",
      "Epoch 4984/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 242964794.4356 - val_loss: 1529166786.6329\n",
      "Epoch 4985/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 299441581.2032 - val_loss: 1582613562.2661\n",
      "Epoch 4986/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 294040236.5515 - val_loss: 1767730547.2900\n",
      "Epoch 4987/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 321233659.4992 - val_loss: 1589394645.0633\n",
      "Epoch 4988/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 317244829.5712 - val_loss: 2109685170.1648\n",
      "Epoch 4989/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 522834439.8875 - val_loss: 3314189697.3412\n",
      "Epoch 4990/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 859182191.9865 - val_loss: 1659577506.9435\n",
      "Epoch 4991/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 409100155.9482 - val_loss: 2196628692.7032\n",
      "Epoch 4992/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 427879500.3129 - val_loss: 1670820347.3823\n",
      "Epoch 4993/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 253147196.2904 - val_loss: 1649035218.4349\n",
      "Epoch 4994/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 254574054.5110 - val_loss: 1400166122.6847\n",
      "Epoch 4995/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 337239892.5830 - val_loss: 1532538982.1536\n",
      "Epoch 4996/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 232240302.3883 - val_loss: 4826742054.6700\n",
      "Epoch 4997/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 900996522.1880 - val_loss: 1577629100.2509\n",
      "Epoch 4998/10000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 314217271.4609 - val_loss: 1787729133.6191\n",
      "Epoch 4999/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 230164239.8514 - val_loss: 1446174561.9060\n",
      "Epoch 5000/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 326675695.8649 - val_loss: 1533481951.4149\n",
      "Epoch 5001/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 511851552.7822 - val_loss: 1804489585.1657\n",
      "Epoch 5002/10000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 289019775.9280 - val_loss: 1463692848.0000\n",
      "Epoch 5003/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 280437028.8171 - val_loss: 1483351428.0686\n",
      "Epoch 5004/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 239828919.3405 - val_loss: 1471219901.4886\n",
      "Epoch 5005/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 320750994.6922 - val_loss: 1704812228.0056\n",
      "Epoch 5006/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 363393660.7946 - val_loss: 2072232363.6028\n",
      "Epoch 5007/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 650072695.8289 - val_loss: 1484728315.5758\n",
      "Epoch 5008/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 723243470.0822 - val_loss: 3270934944.6391\n",
      "Epoch 5009/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 501109396.8711 - val_loss: 1454416738.4394\n",
      "Epoch 5010/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 245024638.9555 - val_loss: 1627811768.5693\n",
      "Epoch 5011/10000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 794466451.2324 - val_loss: 1566442730.1716\n",
      "Epoch 5012/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 318709009.4564 - val_loss: 1713929394.2639\n",
      "Epoch 5013/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 331819778.4086 - val_loss: 1568458427.7873\n",
      "Epoch 5014/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 232962372.7001 - val_loss: 1609036529.3637\n",
      "Epoch 5015/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 334370068.7023 - val_loss: 2151995967.1899\n",
      "Epoch 5016/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 647851137.2583 - val_loss: 1481211726.8343\n",
      "Epoch 5017/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 289181254.4108 - val_loss: 2644307036.0304\n",
      "Epoch 5018/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 345421316.6370 - val_loss: 1571823178.1131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5019/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 456522644.5605 - val_loss: 1775323512.1688\n",
      "Epoch 5020/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 284664338.1699 - val_loss: 1584197608.5333\n",
      "Epoch 5021/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 306732021.0962 - val_loss: 2212287673.1589\n",
      "Epoch 5022/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 320286851.5205 - val_loss: 1655139785.6495\n",
      "Epoch 5023/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 304795193.2200 - val_loss: 1541590336.7539\n",
      "Epoch 5024/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 257181821.7850 - val_loss: 1782258363.5195\n",
      "Epoch 5025/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 483886070.4198 - val_loss: 2889274202.8062\n",
      "Epoch 5026/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1116461529.8233 - val_loss: 1945432243.9741\n",
      "Epoch 5027/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 568247456.6303 - val_loss: 2438323981.7001\n",
      "Epoch 5028/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 571020305.0625 - val_loss: 1793384870.0456\n",
      "Epoch 5029/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 368497425.9358 - val_loss: 1518701219.5601\n",
      "Epoch 5030/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 257700247.2662 - val_loss: 1574775146.9547\n",
      "Epoch 5031/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 376736927.8649 - val_loss: 2195775766.5035\n",
      "Epoch 5032/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 793537916.4885 - val_loss: 1580264561.4425\n",
      "Epoch 5033/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 348867645.9764 - val_loss: 1717253214.1637\n",
      "Epoch 5034/10000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 273604811.0568 - val_loss: 1534120429.9072\n",
      "Epoch 5035/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 294206212.4705 - val_loss: 1431418142.9603\n",
      "Epoch 5036/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 469524759.3742 - val_loss: 1547511137.3592\n",
      "Epoch 5037/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 330720516.1035 - val_loss: 1656539591.5612\n",
      "Epoch 5038/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 441475283.7043 - val_loss: 1676163386.1626\n",
      "Epoch 5039/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 339000855.3382 - val_loss: 2968730398.2807\n",
      "Epoch 5040/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 554618917.8165 - val_loss: 3587832013.0880\n",
      "Epoch 5041/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 704110133.6185 - val_loss: 1426121311.5859\n",
      "Epoch 5042/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 274020994.1249 - val_loss: 1582781910.6138\n",
      "Epoch 5043/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 229517735.2662 - val_loss: 1618063812.9238\n",
      "Epoch 5044/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 338570749.6590 - val_loss: 1818370520.1508\n",
      "Epoch 5045/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 456734445.8661 - val_loss: 1645000755.4340\n",
      "Epoch 5046/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 473196601.5892 - val_loss: 1613328250.3381\n",
      "Epoch 5047/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1217779847.7074 - val_loss: 2152487847.0031\n",
      "Epoch 5048/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 440296425.6894 - val_loss: 1496569882.3336\n",
      "Epoch 5049/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 219452568.8171 - val_loss: 1523265386.3966\n",
      "Epoch 5050/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 219504367.4147 - val_loss: 2106214400.4141\n",
      "Epoch 5051/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 308341489.5127 - val_loss: 1512891190.8906\n",
      "Epoch 5052/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 484867914.0844 - val_loss: 2852077598.8208\n",
      "Epoch 5053/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 299948013.0189 - val_loss: 1438323637.3018\n",
      "Epoch 5054/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 395412692.0608 - val_loss: 1756082112.9496\n",
      "Epoch 5055/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 580190012.3669 - val_loss: 2440311778.7724\n",
      "Epoch 5056/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 309739529.3281 - val_loss: 1551174175.3271\n",
      "Epoch 5057/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 296090308.9702 - val_loss: 1565035823.7255\n",
      "Epoch 5058/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 456526947.9977 - val_loss: 1581800870.2110\n",
      "Epoch 5059/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 525024902.9871 - val_loss: 1513582138.9547\n",
      "Epoch 5060/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 335565248.6663 - val_loss: 1406939999.6850\n",
      "Epoch 5061/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 230551172.0833 - val_loss: 1662945527.4037\n",
      "Epoch 5062/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 413654200.2476 - val_loss: 1415061809.1004\n",
      "Epoch 5063/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 341208510.6314 - val_loss: 1552937184.3376\n",
      "Epoch 5064/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 391809027.7321 - val_loss: 2037660334.6273\n",
      "Epoch 5065/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 681887707.0298 - val_loss: 1494708605.8622\n",
      "Epoch 5066/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 281849120.2701 - val_loss: 1731938398.0647\n",
      "Epoch 5067/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 382725002.0754 - val_loss: 2199615080.4703\n",
      "Epoch 5068/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 409787133.9471 - val_loss: 1783113891.3170\n",
      "Epoch 5069/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 442770171.8222 - val_loss: 3864642555.4273\n",
      "Epoch 5070/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1063896709.9066 - val_loss: 2060254493.0205\n",
      "Epoch 5071/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 506218858.6246 - val_loss: 2307925368.3308\n",
      "Epoch 5072/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 393142321.9358 - val_loss: 1397871521.6878\n",
      "Epoch 5073/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 246826974.1452 - val_loss: 1771678649.5910\n",
      "Epoch 5074/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 278054994.6562 - val_loss: 1845750018.5384\n",
      "Epoch 5075/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 290368412.8936 - val_loss: 2070990790.4090\n",
      "Epoch 5076/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 412503355.3360 - val_loss: 1825985382.9221\n",
      "Epoch 5077/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 846510501.7445 - val_loss: 3560502047.3609\n",
      "Epoch 5078/10000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 1228162036.6911 - val_loss: 1688934446.4383\n",
      "Epoch 5079/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 308186689.6342 - val_loss: 1437945198.3797\n",
      "Epoch 5080/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 235009598.8655 - val_loss: 1785664353.9533\n",
      "Epoch 5081/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 280543463.8875 - val_loss: 1834555835.0942\n",
      "Epoch 5082/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 320563790.1283 - val_loss: 2237772824.7899\n",
      "Epoch 5083/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 208393346.4671 - val_loss: 1467136566.8096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5084/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 285978287.3877 - val_loss: 1601628987.6073\n",
      "Epoch 5085/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 312680448.0360 - val_loss: 1539397488.9496\n",
      "Epoch 5086/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 309832988.7113 - val_loss: 1644742469.3018\n",
      "Epoch 5087/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 523234448.3692 - val_loss: 1463309667.4560\n",
      "Epoch 5088/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 482900601.4181 - val_loss: 1560235001.9691\n",
      "Epoch 5089/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 401956399.2167 - val_loss: 2583640935.1921\n",
      "Epoch 5090/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1102308927.5858 - val_loss: 1573423849.3885\n",
      "Epoch 5091/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 278633695.8559 - val_loss: 1515584040.5603\n",
      "Epoch 5092/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 220772912.7473 - val_loss: 2131623589.2658\n",
      "Epoch 5093/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 358535084.1643 - val_loss: 1803198394.9952\n",
      "Epoch 5094/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 334124599.6714 - val_loss: 1451314113.9173\n",
      "Epoch 5095/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1060155297.2786 - val_loss: 2040350749.1826\n",
      "Epoch 5096/10000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 428410266.8542 - val_loss: 2233106559.8380\n",
      "Epoch 5097/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 310442566.0146 - val_loss: 2150301209.1499\n",
      "Epoch 5098/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 594891051.2549 - val_loss: 1918472008.4433\n",
      "Epoch 5099/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 241620622.8745 - val_loss: 1520206613.2253\n",
      "Epoch 5100/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 260782185.8323 - val_loss: 1696387677.0025\n",
      "Epoch 5101/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 264761771.9122 - val_loss: 1521572886.7060\n",
      "Epoch 5102/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 843381023.6579 - val_loss: 2114657191.1561\n",
      "Epoch 5103/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 269041030.1328 - val_loss: 1410023268.9598\n",
      "Epoch 5104/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 187979965.6770 - val_loss: 1601707396.6897\n",
      "Epoch 5105/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 748204164.3759 - val_loss: 1593432502.8906\n",
      "Epoch 5106/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 320577161.9043 - val_loss: 2127401181.1105\n",
      "Epoch 5107/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 277610775.3742 - val_loss: 3832514199.4397\n",
      "Epoch 5108/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1032069461.5194 - val_loss: 1588645449.0284\n",
      "Epoch 5109/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 280369366.9961 - val_loss: 3007765640.7674\n",
      "Epoch 5110/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 349598835.1064 - val_loss: 2005463475.3620\n",
      "Epoch 5111/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 223429634.6832 - val_loss: 1454387418.9862\n",
      "Epoch 5112/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 223028797.4069 - val_loss: 1911480357.0498\n",
      "Epoch 5113/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 350296788.7901 - val_loss: 1400457186.7184\n",
      "Epoch 5114/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 324626942.4153 - val_loss: 2330653576.0473\n",
      "Epoch 5115/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 606667812.5560 - val_loss: 1591005545.5010\n",
      "Epoch 5116/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 529450968.2566 - val_loss: 1979160829.2996\n",
      "Epoch 5117/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 517006219.4170 - val_loss: 1497654231.9977\n",
      "Epoch 5118/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 222900649.9449 - val_loss: 1432397788.0709\n",
      "Epoch 5119/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 345023195.2324 - val_loss: 1426559197.3266\n",
      "Epoch 5120/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 235202462.7665 - val_loss: 1468353209.3525\n",
      "Epoch 5121/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 195906640.6123 - val_loss: 1494206368.3286\n",
      "Epoch 5122/10000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 338314824.4007 - val_loss: 1539133784.9834\n",
      "Epoch 5123/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 319723930.0934 - val_loss: 1713604295.4532\n",
      "Epoch 5124/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 563647395.6196 - val_loss: 1599691501.9162\n",
      "Epoch 5125/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 748479624.4997 - val_loss: 3228334934.3055\n",
      "Epoch 5126/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 718372119.2392 - val_loss: 1460600518.2065\n",
      "Epoch 5127/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 406232998.8115 - val_loss: 1464547734.9536\n",
      "Epoch 5128/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 250405420.8216 - val_loss: 1446972007.5612\n",
      "Epoch 5129/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 286646239.8604 - val_loss: 1502531181.1691\n",
      "Epoch 5130/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 671155925.4474 - val_loss: 1727242870.4135\n",
      "Epoch 5131/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 393940697.2560 - val_loss: 1498833174.9131\n",
      "Epoch 5132/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 285591197.2538 - val_loss: 1542479335.7682\n",
      "Epoch 5133/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 470938473.9854 - val_loss: 1443783554.8242\n",
      "Epoch 5134/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 420007602.0642 - val_loss: 1910466524.8585\n",
      "Epoch 5135/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 329503663.3967 - val_loss: 1742624883.1460\n",
      "Epoch 5136/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 428338541.1277 - val_loss: 1739624909.5831\n",
      "Epoch 5137/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 388744793.6657 - val_loss: 2621365291.2248\n",
      "Epoch 5138/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 645102046.5053 - val_loss: 1732954583.4892\n",
      "Epoch 5139/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 569091926.3658 - val_loss: 1519817263.3204\n",
      "Epoch 5140/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 549173720.0945 - val_loss: 10605822063.8335\n",
      "Epoch 5141/10000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 2295033845.3393 - val_loss: 2334564845.9567\n",
      "Epoch 5142/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 731816412.1643 - val_loss: 1392907782.9896\n",
      "Epoch 5143/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 182480314.7147 - val_loss: 1580056613.8734\n",
      "Epoch 5144/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 194576486.7693 - val_loss: 1493856882.6419\n",
      "Epoch 5145/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 216227330.4491 - val_loss: 1467127262.0827\n",
      "Epoch 5146/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 198296223.1716 - val_loss: 2718977903.3294\n",
      "Epoch 5147/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 390061019.8582 - val_loss: 1567036213.7564\n",
      "Epoch 5148/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 293272871.2347 - val_loss: 1869869796.5997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5149/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 277750503.1345 - val_loss: 1679410358.1435\n",
      "Epoch 5150/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 285906017.0264 - val_loss: 4046328463.1944\n",
      "Epoch 5151/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 517421219.2954 - val_loss: 4819554183.3812\n",
      "Epoch 5152/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 528292368.3331 - val_loss: 1633850984.2273\n",
      "Epoch 5153/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 324456424.8779 - val_loss: 1432668068.4850\n",
      "Epoch 5154/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 286966827.6601 - val_loss: 1510404781.2411\n",
      "Epoch 5155/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 215861467.2324 - val_loss: 1440395710.5058\n",
      "Epoch 5156/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 193952962.6652 - val_loss: 3355820829.7406\n",
      "Epoch 5157/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 958037350.0326 - val_loss: 1767546730.6487\n",
      "Epoch 5158/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 537675145.1930 - val_loss: 1520945299.8931\n",
      "Epoch 5159/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 246428965.8661 - val_loss: 1557472492.7685\n",
      "Epoch 5160/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 502779070.4153 - val_loss: 1532881417.4605\n",
      "Epoch 5161/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 406827337.5847 - val_loss: 1864335520.5041\n",
      "Epoch 5162/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 223871031.7929 - val_loss: 1432936516.9778\n",
      "Epoch 5163/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 368627235.4575 - val_loss: 5809209919.6219\n",
      "Epoch 5164/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1199942708.5110 - val_loss: 1759217641.0509\n",
      "Epoch 5165/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 273026202.6629 - val_loss: 1375882706.3651\n",
      "Epoch 5166/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 329122023.8683 - val_loss: 1525808823.2506\n",
      "Epoch 5167/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 361002762.5166 - val_loss: 1504515723.0672\n",
      "Epoch 5168/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 433780574.7034 - val_loss: 1457798556.6897\n",
      "Epoch 5169/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 369081507.7355 - val_loss: 1531841870.3032\n",
      "Epoch 5170/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 583139470.8565 - val_loss: 1624608659.7131\n",
      "Epoch 5171/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 293339446.7079 - val_loss: 1835803554.0883\n",
      "Epoch 5172/10000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 375780926.3433 - val_loss: 1522697998.4068\n",
      "Epoch 5173/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 358187187.5656 - val_loss: 1564018201.2940\n",
      "Epoch 5174/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 363192361.2999 - val_loss: 1430864709.3648\n",
      "Epoch 5175/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 804733939.2290 - val_loss: 1713942646.7646\n",
      "Epoch 5176/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 357393028.5380 - val_loss: 1957882160.1845\n",
      "Epoch 5177/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 255838911.4035 - val_loss: 1339729258.9772\n",
      "Epoch 5178/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 293779859.7952 - val_loss: 1386001866.0006\n",
      "Epoch 5179/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 289381355.2189 - val_loss: 2439896553.5145\n",
      "Epoch 5180/10000\n",
      "3554/3554 [==============================] - 0s 137us/step - loss: 585086864.0630 - val_loss: 6159926988.8720\n",
      "Epoch 5181/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 1272193995.4890 - val_loss: 1883380761.5887\n",
      "Epoch 5182/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 391708814.8858 - val_loss: 1377493542.8141\n",
      "Epoch 5183/10000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 224930095.6218 - val_loss: 1514253914.1131\n",
      "Epoch 5184/10000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 232723749.8526 - val_loss: 1418175085.7451\n",
      "Epoch 5185/10000\n",
      "3554/3554 [==============================] - 0s 135us/step - loss: 279453280.0720 - val_loss: 1582973790.7128\n",
      "Epoch 5186/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 388314392.1868 - val_loss: 1758604637.7947\n",
      "Epoch 5187/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 244265711.9955 - val_loss: 1989049371.0222\n",
      "Epoch 5188/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 655613300.6460 - val_loss: 1690578450.8669\n",
      "Epoch 5189/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 300649940.2228 - val_loss: 1560519422.6498\n",
      "Epoch 5190/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 280432433.0895 - val_loss: 2033092731.5308\n",
      "Epoch 5191/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 690347988.3669 - val_loss: 1966909886.5958\n",
      "Epoch 5192/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 378101825.5352 - val_loss: 1447474923.7378\n",
      "Epoch 5193/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 231739032.3106 - val_loss: 4330709170.5159\n",
      "Epoch 5194/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 611508081.8278 - val_loss: 1432894961.0442\n",
      "Epoch 5195/10000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 287928360.9499 - val_loss: 2397149217.4132\n",
      "Epoch 5196/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 787816937.2110 - val_loss: 1834178331.7693\n",
      "Epoch 5197/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 293576475.4080 - val_loss: 1434171475.8616\n",
      "Epoch 5198/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 459209358.0101 - val_loss: 1719483096.5828\n",
      "Epoch 5199/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 216017346.5211 - val_loss: 1478069010.4079\n",
      "Epoch 5200/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 253203965.2628 - val_loss: 1464416541.6146\n",
      "Epoch 5201/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 346309794.4311 - val_loss: 2833655988.8833\n",
      "Epoch 5202/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 669399496.1396 - val_loss: 1588040176.3196\n",
      "Epoch 5203/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 375385813.4654 - val_loss: 1633762186.7747\n",
      "Epoch 5204/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 710205788.5245 - val_loss: 1929293398.2875\n",
      "Epoch 5205/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 527962539.2189 - val_loss: 1431721405.9027\n",
      "Epoch 5206/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 272415364.6145 - val_loss: 2106856574.5778\n",
      "Epoch 5207/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 783159364.1058 - val_loss: 1510274415.1314\n",
      "Epoch 5208/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 249314742.7935 - val_loss: 1644271306.9547\n",
      "Epoch 5209/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 195447488.8104 - val_loss: 2599507491.3935\n",
      "Epoch 5210/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 219761640.0135 - val_loss: 2376678193.6698\n",
      "Epoch 5211/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 287925338.7957 - val_loss: 1597892468.2284\n",
      "Epoch 5212/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 283444451.9977 - val_loss: 2726952487.0301\n",
      "Epoch 5213/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 692455680.8149 - val_loss: 1756806238.7128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5214/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 263329645.9741 - val_loss: 1451116305.2512\n",
      "Epoch 5215/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 332441374.2127 - val_loss: 1453272907.6928\n",
      "Epoch 5216/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 332001348.6190 - val_loss: 1438582290.3269\n",
      "Epoch 5217/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 240594204.7406 - val_loss: 1894947460.3207\n",
      "Epoch 5218/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 377200494.6944 - val_loss: 1517466205.0250\n",
      "Epoch 5219/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 309332092.2183 - val_loss: 3192550091.5758\n",
      "Epoch 5220/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 721107924.4615 - val_loss: 1640188397.8352\n",
      "Epoch 5221/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 348418731.6511 - val_loss: 2123898625.0172\n",
      "Epoch 5222/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 322076312.7068 - val_loss: 2394202240.0720\n",
      "Epoch 5223/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 642173571.0613 - val_loss: 2100420889.0959\n",
      "Epoch 5224/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 303188693.9167 - val_loss: 1382813281.6878\n",
      "Epoch 5225/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 222820196.3579 - val_loss: 1564318281.7575\n",
      "Epoch 5226/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 301953548.0293 - val_loss: 1505697860.3657\n",
      "Epoch 5227/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 501029787.4800 - val_loss: 5373536879.9505\n",
      "Epoch 5228/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 828888090.8452 - val_loss: 1427291208.8394\n",
      "Epoch 5229/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 308593659.7591 - val_loss: 1388671632.4051\n",
      "Epoch 5230/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 264077520.0608 - val_loss: 1469169545.6180\n",
      "Epoch 5231/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 227741165.0647 - val_loss: 1401761378.1648\n",
      "Epoch 5232/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 491558820.2319 - val_loss: 2255184082.3089\n",
      "Epoch 5233/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 516587730.1519 - val_loss: 1592334025.6495\n",
      "Epoch 5234/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 400407552.2161 - val_loss: 2071918017.3862\n",
      "Epoch 5235/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 261127366.4783 - val_loss: 1415098561.8723\n",
      "Epoch 5236/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 432398105.9415 - val_loss: 1573845627.9314\n",
      "Epoch 5237/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 309397549.9876 - val_loss: 1386147268.2082\n",
      "Epoch 5238/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 617801523.6331 - val_loss: 3715652423.9032\n",
      "Epoch 5239/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 548136802.6111 - val_loss: 1801665604.3567\n",
      "Epoch 5240/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 264558959.0906 - val_loss: 2423310376.1823\n",
      "Epoch 5241/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 648245566.8694 - val_loss: 1586114416.0855\n",
      "Epoch 5242/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 214900732.5785 - val_loss: 1860447517.9477\n",
      "Epoch 5243/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 379153372.8126 - val_loss: 1503141443.4543\n",
      "Epoch 5244/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 404344229.6005 - val_loss: 1493293796.9845\n",
      "Epoch 5245/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 352751000.8171 - val_loss: 1802724355.3890\n",
      "Epoch 5246/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 381908290.9173 - val_loss: 1508114419.4070\n",
      "Epoch 5247/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 483418234.8858 - val_loss: 1631861732.7077\n",
      "Epoch 5248/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 292758359.9325 - val_loss: 1415948388.9440\n",
      "Epoch 5249/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 321778907.3855 - val_loss: 1416984194.4034\n",
      "Epoch 5250/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 253369278.2172 - val_loss: 1544121161.7755\n",
      "Epoch 5251/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 217385050.6337 - val_loss: 1842266593.5257\n",
      "Epoch 5252/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 418407108.6325 - val_loss: 1751877272.2768\n",
      "Epoch 5253/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 267992806.8070 - val_loss: 1422064425.9871\n",
      "Epoch 5254/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 351922830.6224 - val_loss: 2526040418.4754\n",
      "Epoch 5255/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 577188506.9758 - val_loss: 1609622519.5027\n",
      "Epoch 5256/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 388011415.9865 - val_loss: 1484792390.1255\n",
      "Epoch 5257/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 332918142.4153 - val_loss: 2381897579.8909\n",
      "Epoch 5258/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 523142231.3337 - val_loss: 2253081897.5595\n",
      "Epoch 5259/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 541889445.4834 - val_loss: 1482525143.9797\n",
      "Epoch 5260/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 382660131.9617 - val_loss: 1514872367.0368\n",
      "Epoch 5261/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 400296725.9876 - val_loss: 1662119650.7634\n",
      "Epoch 5262/10000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 197214923.5205 - val_loss: 1739499559.0031\n",
      "Epoch 5263/10000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 259743840.8104 - val_loss: 1435438786.0186\n",
      "Epoch 5264/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 456901292.5875 - val_loss: 2087814889.4695\n",
      "Epoch 5265/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 730664142.6944 - val_loss: 1834876980.4264\n",
      "Epoch 5266/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 375095946.2105 - val_loss: 2591293004.8405\n",
      "Epoch 5267/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 482642863.5726 - val_loss: 2606802721.2152\n",
      "Epoch 5268/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 785851539.5566 - val_loss: 1403860859.4970\n",
      "Epoch 5269/10000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 187941942.6809 - val_loss: 1557724097.1342\n",
      "Epoch 5270/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 262480008.0045 - val_loss: 2517649525.9769\n",
      "Epoch 5271/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 294181587.3405 - val_loss: 2036597147.3103\n",
      "Epoch 5272/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 360685641.1210 - val_loss: 1531025963.2428\n",
      "Epoch 5273/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 433907235.4035 - val_loss: 2112315683.2135\n",
      "Epoch 5274/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 500454017.5127 - val_loss: 3420082415.3654\n",
      "Epoch 5275/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 668345224.0225 - val_loss: 1547833254.0354\n",
      "Epoch 5276/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 204855223.0861 - val_loss: 1441982846.1840\n",
      "Epoch 5277/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 373019766.1317 - val_loss: 1754475069.9927\n",
      "Epoch 5278/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 609438789.6815 - val_loss: 1580381963.1617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5279/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 241810551.4643 - val_loss: 1399795421.1421\n",
      "Epoch 5280/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 241741472.4502 - val_loss: 1483935092.0686\n",
      "Epoch 5281/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 304956814.7485 - val_loss: 1592059501.4931\n",
      "Epoch 5282/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 287623647.9640 - val_loss: 1459549786.1581\n",
      "Epoch 5283/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 386317781.2673 - val_loss: 1764144683.1572\n",
      "Epoch 5284/10000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 675948445.7130 - val_loss: 2623069666.6014\n",
      "Epoch 5285/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 304386578.0079 - val_loss: 1436214558.7623\n",
      "Epoch 5286/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 216907866.5796 - val_loss: 1582566140.1485\n",
      "Epoch 5287/10000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 418785294.6584 - val_loss: 1774645151.9190\n",
      "Epoch 5288/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 360773660.3804 - val_loss: 9721999829.0813\n",
      "Epoch 5289/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2717844577.1165 - val_loss: 2813186102.0805\n",
      "Epoch 5290/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 502870013.2628 - val_loss: 1445375077.8734\n",
      "Epoch 5291/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 155493277.3934 - val_loss: 1408660838.7578\n",
      "Epoch 5292/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 199876298.1925 - val_loss: 1360256683.6366\n",
      "Epoch 5293/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 205433094.6269 - val_loss: 1589728042.7837\n",
      "Epoch 5294/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 223212298.6427 - val_loss: 1527458860.6965\n",
      "Epoch 5295/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 258353899.0523 - val_loss: 1609257000.3443\n",
      "Epoch 5296/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 321479315.7366 - val_loss: 2119883210.7837\n",
      "Epoch 5297/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 381396464.0990 - val_loss: 2240694583.4307\n",
      "Epoch 5298/10000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 271809528.2386 - val_loss: 1563256320.2160\n",
      "Epoch 5299/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 324575425.8548 - val_loss: 1794371395.4115\n",
      "Epoch 5300/10000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 301811741.5509 - val_loss: 1956056179.2900\n",
      "Epoch 5301/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 374861402.7372 - val_loss: 1617973788.3904\n",
      "Epoch 5302/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 245048409.6972 - val_loss: 1677435046.5305\n",
      "Epoch 5303/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 611380480.6663 - val_loss: 1556568325.8419\n",
      "Epoch 5304/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 320124868.0428 - val_loss: 3460664890.9052\n",
      "Epoch 5305/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 731910134.9781 - val_loss: 1482906996.2487\n",
      "Epoch 5306/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 309763410.0281 - val_loss: 1414898504.6684\n",
      "Epoch 5307/10000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 240491578.9848 - val_loss: 1480118927.4284\n",
      "Epoch 5308/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 298148973.0884 - val_loss: 1474031036.1024\n",
      "Epoch 5309/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 258200441.8773 - val_loss: 1623665968.6256\n",
      "Epoch 5310/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 296282150.2757 - val_loss: 1728973562.2931\n",
      "Epoch 5311/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 327586158.3163 - val_loss: 1446695991.4284\n",
      "Epoch 5312/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 587555768.1125 - val_loss: 5619813802.4506\n",
      "Epoch 5313/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 853361373.6050 - val_loss: 2588823329.7733\n",
      "Epoch 5314/10000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 339939803.7333 - val_loss: 1723990960.6886\n",
      "Epoch 5315/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 238274341.7985 - val_loss: 2199992036.1136\n",
      "Epoch 5316/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 566200245.4249 - val_loss: 1546614832.0900\n",
      "Epoch 5317/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 267486235.8042 - val_loss: 1545013599.3609\n",
      "Epoch 5318/10000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 472314064.1711 - val_loss: 2516601620.0191\n",
      "Epoch 5319/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 331521920.1801 - val_loss: 1487592629.5201\n",
      "Epoch 5320/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 257350763.5611 - val_loss: 4055861481.1364\n",
      "Epoch 5321/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 659367936.3931 - val_loss: 1523456726.0895\n",
      "Epoch 5322/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 206945213.5599 - val_loss: 1740912110.5013\n",
      "Epoch 5323/10000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 502784809.0940 - val_loss: 1407033030.0624\n",
      "Epoch 5324/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 230009011.1244 - val_loss: 1495428526.8523\n",
      "Epoch 5325/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 442796639.3697 - val_loss: 2061198799.1674\n",
      "Epoch 5326/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1108962441.4631 - val_loss: 4113680160.3331\n",
      "Epoch 5327/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 465533383.4935 - val_loss: 1483493949.8577\n",
      "Epoch 5328/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 195722148.3579 - val_loss: 1405519009.9083\n",
      "Epoch 5329/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 398322605.1638 - val_loss: 1427807187.1460\n",
      "Epoch 5330/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 451673802.4468 - val_loss: 1638480242.5755\n",
      "Epoch 5331/10000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 233645118.0732 - val_loss: 1500683631.8065\n",
      "Epoch 5332/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 360932016.4772 - val_loss: 1558543462.5080\n",
      "Epoch 5333/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 326981773.4339 - val_loss: 3743222336.4501\n",
      "Epoch 5334/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 793153100.7496 - val_loss: 2713837002.5316\n",
      "Epoch 5335/10000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 343679126.5459 - val_loss: 1982363644.3994\n",
      "Epoch 5336/10000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 439710287.3247 - val_loss: 1598489361.1387\n",
      "Epoch 5337/10000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 282162632.4322 - val_loss: 2361040630.8546\n",
      "Epoch 5338/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 227977752.8149 - val_loss: 1478397390.0602\n",
      "Epoch 5339/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 476078735.9370 - val_loss: 8390395226.4461\n",
      "Epoch 5340/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2086892106.5886 - val_loss: 2571574169.9060\n",
      "Epoch 5341/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 310939605.5734 - val_loss: 2468301260.7640\n",
      "Epoch 5342/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 348444947.4665 - val_loss: 1408561302.7015\n",
      "Epoch 5343/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 171547535.4778 - val_loss: 1390226164.2082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5344/10000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 315711751.1491 - val_loss: 2023318133.2163\n",
      "Epoch 5345/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 229574024.5808 - val_loss: 1959460851.6501\n",
      "Epoch 5346/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 266869836.8576 - val_loss: 1610374598.3280\n",
      "Epoch 5347/10000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 251765314.6472 - val_loss: 1936349062.5530\n",
      "Epoch 5348/10000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 431474345.6984 - val_loss: 2779744823.9167\n",
      "Epoch 5349/10000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 476810843.5340 - val_loss: 1437426164.5210\n",
      "Epoch 5350/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 251278738.3545 - val_loss: 1494606553.9601\n",
      "Epoch 5351/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 297476496.8194 - val_loss: 1550682959.1809\n",
      "Epoch 5352/10000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 481927039.0276 - val_loss: 2482922095.7975\n",
      "Epoch 5353/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 387518477.1840 - val_loss: 1559592634.6217\n",
      "Epoch 5354/10000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 335642957.1097 - val_loss: 2783194620.6875\n",
      "Epoch 5355/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 393306756.2138 - val_loss: 2419000016.1845\n",
      "Epoch 5356/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 425254412.2904 - val_loss: 1904302975.3519\n",
      "Epoch 5357/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 309175465.6702 - val_loss: 1460036793.2579\n",
      "Epoch 5358/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 268613177.1908 - val_loss: 1391818973.6731\n",
      "Epoch 5359/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 242559957.3438 - val_loss: 1657766281.7035\n",
      "Epoch 5360/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 308398402.1970 - val_loss: 2088291052.1609\n",
      "Epoch 5361/10000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 342247548.2999 - val_loss: 1482222486.2425\n",
      "Epoch 5362/10000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 353934073.6432 - val_loss: 1458161306.4776\n",
      "Epoch 5363/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 578229873.3776 - val_loss: 5821958363.5623\n",
      "Epoch 5364/10000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1060779543.0501 - val_loss: 1735028245.9544\n",
      "Epoch 5365/10000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 411462804.5830 - val_loss: 1415204504.9136\n",
      "Epoch 5366/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 285238574.1002 - val_loss: 1576391879.4712\n",
      "Epoch 5367/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1113856313.5892 - val_loss: 7836298120.8934\n",
      "Epoch 5368/10000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 591747393.6387 - val_loss: 1841909568.1665\n",
      "Epoch 5369/10000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 267779764.1643 - val_loss: 1405044721.1522\n",
      "Epoch 5370/10000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 251697084.3084 - val_loss: 1473740596.7662\n",
      "Epoch 5371/10000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 249361693.9921 - val_loss: 1535177109.8014\n",
      "Epoch 5372/10000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 346420281.8188 - val_loss: 1513416849.6878\n",
      "Epoch 5373/10000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 461666542.9195 - val_loss: 5135949128.6594\n",
      "Epoch 5374/10000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1134127332.8846 - val_loss: 3398295776.9271\n",
      "Epoch 5375/10000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 377067805.3708 - val_loss: 1371250197.0138\n",
      "Epoch 5376/10000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 214568853.7355 - val_loss: 1502538830.6925\n",
      "Epoch 5377/10000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 213173418.4536 - val_loss: 1425526053.2546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe417859128>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile model\n",
    "model22.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(\"model22 loss:\",model22.loss)\n",
    "\n",
    "model_train22 = model22.fit(predictors,target, epochs=10000, validation_split=0.5, callbacks=[early_stopping_monitor], verbose=True)\n",
    "model_train22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe4169f3860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the plot\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(model_train22.history['val_loss'], 'r')\n",
    "plt.title(\"Adam only\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.savefig(\"adam_5_layrs_7000_epochs_only_with_200_callbacks\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model22.save(\"adam_5_layers_7000_epochs_only_with_200_callbacks.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('adam_5_layers_7000_epochs_only_with_200_callbacks.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing output file to neural3.csv\n"
     ]
    }
   ],
   "source": [
    "# Calculate predictions: predictions\n",
    "predictions = model.predict(X_test.values)\n",
    "predictions = pd.DataFrame(predictions)\n",
    "\n",
    "output = pd.DataFrame(data = {\"PRT_ID\":test[\"PRT_ID\"]})\n",
    "\n",
    "result = pd.concat([output, predictions], axis=1)\n",
    "\n",
    "result.columns = ['PRT_ID','SALES_PRICE']\n",
    "print(\"Writing output file to neural3.csv\")\n",
    "result.to_csv(\"../output/neural3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
