{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#importing pandas to visualise the dataset in tabular format\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 150)\n",
    "\n",
    "import numpy as np\n",
    "#introducing stable analysis through random seed\n",
    "np.random.seed(42)\n",
    "#importing time function to create animated behaviour\n",
    "import time\n",
    "#importing regExp for data cleaning\n",
    "import re\n",
    "from numpy import NaN\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(patience=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/encoded_train.csv\")\n",
    "test = pd.read_csv(\"../data/encoded_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PRT_ID  AREA  INT_SQFT  DIST_MAINROAD  N_BEDROOM  N_BATHROOM  N_ROOM  SALE_COND  PARK_FACIL  BUILDTYPE  UTILITY_AVAIL  STREET  MZZONE  QS_ROOMS  \\\n",
      "0  P03210     1      1004            131        1.0         1.0       3         -2           1         -1              1       1      -1       4.0   \n",
      "1  P09411    -3      1986             26        2.0         1.0       5         -2           0         -1              1       0       2       4.9   \n",
      "2  P01812    -2       909             70        1.0         1.0       3         -2           1         -1             -1       0       1       4.1   \n",
      "3  P05346     3      1855             14        3.0         2.0       5         -1           0          1             -2       1      -2       4.7   \n",
      "4  P06210     1      1226             84        1.0         1.0       3         -2           1          1              1       0       0       3.0   \n",
      "\n",
      "   QS_BATHROOM  QS_BEDROOM  QS_OVERALL  REG_FEE  COMMIS  SALES_PRICE  DATE_DIFF  YEAR  \n",
      "0          3.9         4.9       4.330   380000  144400      7600000       44.0  1967  \n",
      "1          4.2         2.5       3.765   760122  304049     21717770       11.0  1995  \n",
      "2          3.8         2.2       3.090   421094   92114     13159200       20.0  1992  \n",
      "3          3.9         3.6       4.010   356321   77042      9630290       22.0  1988  \n",
      "4          2.5         4.1       3.290   237000   74063      7406250       30.0  1979  \n",
      "   PRT_ID  AREA  INT_SQFT  DIST_MAINROAD  N_BEDROOM  N_BATHROOM  N_ROOM  SALE_COND  PARK_FACIL  BUILDTYPE  UTILITY_AVAIL  STREET  MZZONE  QS_ROOMS  \\\n",
      "0  P05996     0       958            185          1           1       3         -2           0          1             -2       1       2       3.1   \n",
      "1  P09294    -3      1807            108          2           1       5          0           1          1              0      -1       3       2.6   \n",
      "2  P03807     1      1658             59          2           2       4          0           0          1              0       1      -2       2.5   \n",
      "3  P00539    -3      1592            102          1           1       4         -2           1          1              1       0       1       4.1   \n",
      "4  P01448     0       857             62          1           1       3         -1           0          0             -1       0       2       3.0   \n",
      "\n",
      "   QS_BATHROOM  QS_BEDROOM  QS_OVERALL  REG_FEE  COMMIS  DATE_DIFF  YEAR  \n",
      "0          4.4         3.9       3.860   203260   93813       27.0  1982  \n",
      "1          4.1         2.1       2.775   370410  222246       17.0  1990  \n",
      "2          2.3         3.2       2.720   387972  113159       16.0  1995  \n",
      "3          4.8         2.5       3.635   408134   84442       19.0  1995  \n",
      "4          4.5         2.9       3.570   181212   34849       34.0  1978  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = df.drop(['PRT_ID','SALES_PRICE'],axis=1)\n",
    "y_train = df['SALES_PRICE']\n",
    "\n",
    "X_test = test.drop(['PRT_ID'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify the model\n",
    "predictors = X_train.values\n",
    "target = y_train.values.reshape((-1,1)).astype('int32')\n",
    "\n",
    "n_cols = predictors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model 1\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(50, activation='relu', input_shape=(n_cols,)))\n",
    "model1.add(Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "model1.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model1.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "#model 2\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(50, activation='relu', input_shape=(n_cols,)))\n",
    "model2.add(Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "model2.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model2.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "#model 3\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(50, activation='relu', input_shape=(n_cols,)))\n",
    "model3.add(Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "model3.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model3.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "#model 4\n",
    "model4 = Sequential()\n",
    "model4.add(Dense(50, activation='relu', input_shape=(n_cols,)))\n",
    "model4.add(Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "model4.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model4.add(Dense(1, kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1 loss: mean_squared_error\n",
      "model2 loss: mean_squared_error\n",
      "model3 loss: mean_squared_error\n",
      "model4 loss: mean_squared_error\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model1.compile(loss='mean_squared_error', optimizer='nadam')\n",
    "print(\"model1 loss:\",model1.loss)\n",
    "\n",
    "# Compile model\n",
    "model2.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(\"model2 loss:\",model2.loss)\n",
    "\n",
    "# Compile model\n",
    "model3.compile(loss='mean_squared_error', optimizer='adadelta')\n",
    "print(\"model3 loss:\",model3.loss)\n",
    "\n",
    "# Compile model\n",
    "model4.compile(loss='mean_squared_error', optimizer='adagrad')\n",
    "print(\"model4 loss:\",model4.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4265 samples, validate on 2844 samples\n",
      "Epoch 1/800\n",
      "4265/4265 [==============================] - 1s 192us/step - loss: 41280402470628.2109 - val_loss: 4543595538123.7920\n",
      "Epoch 2/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 4058122020861.5991 - val_loss: 4092782917951.7300\n",
      "Epoch 3/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3854588345253.9648 - val_loss: 3927149722841.4741\n",
      "Epoch 4/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3772674601583.2837 - val_loss: 4063063708713.7666\n",
      "Epoch 5/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3731956159381.1582 - val_loss: 4015535681207.6284\n",
      "Epoch 6/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3699340000561.6392 - val_loss: 4059546594193.1025\n",
      "Epoch 7/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3672379191465.9863 - val_loss: 3964555943924.4785\n",
      "Epoch 8/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3637800035496.7861 - val_loss: 3754582260354.3403\n",
      "Epoch 9/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3602810504066.9111 - val_loss: 3706213217748.0732\n",
      "Epoch 10/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3581220653059.3613 - val_loss: 3680528903886.6724\n",
      "Epoch 11/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3560571768400.7920 - val_loss: 4067170846331.1387\n",
      "Epoch 12/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3552365579065.4424 - val_loss: 3625564568954.7793\n",
      "Epoch 13/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3502200190780.5640 - val_loss: 3670854813238.0083\n",
      "Epoch 14/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3506107625376.9229 - val_loss: 3682997101362.0479\n",
      "Epoch 15/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3487201425381.5898 - val_loss: 3880141902958.8975\n",
      "Epoch 16/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3453696972103.2480 - val_loss: 3994217745838.6274\n",
      "Epoch 17/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3453660185401.9229 - val_loss: 3555460887835.7241\n",
      "Epoch 18/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3428176352210.6226 - val_loss: 3542990243520.2700\n",
      "Epoch 19/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3402300308724.1753 - val_loss: 3667768883565.8174\n",
      "Epoch 20/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3394722796110.6309 - val_loss: 3685112295579.5444\n",
      "Epoch 21/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3374229360262.5728 - val_loss: 3560606099101.7046\n",
      "Epoch 22/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3369876568364.1177 - val_loss: 3571850624033.1250\n",
      "Epoch 23/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3357416435578.5078 - val_loss: 3647511926078.2896\n",
      "Epoch 24/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3344710592425.0859 - val_loss: 3612219789064.2812\n",
      "Epoch 25/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3328809576303.4639 - val_loss: 3454587351610.3291\n",
      "Epoch 26/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3315969938786.1387 - val_loss: 3581923385931.6118\n",
      "Epoch 27/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3301169029413.8745 - val_loss: 3405663838311.6963\n",
      "Epoch 28/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3280451402485.2559 - val_loss: 3660820589825.8003\n",
      "Epoch 29/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3284390955099.7158 - val_loss: 3423153810205.8848\n",
      "Epoch 30/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3280813623045.8223 - val_loss: 3370186338574.7622\n",
      "Epoch 31/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3262339410578.3374 - val_loss: 3349431532761.4741\n",
      "Epoch 32/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3256334872630.7412 - val_loss: 3411548920600.1235\n",
      "Epoch 33/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3242949673897.3262 - val_loss: 3404466974714.2393\n",
      "Epoch 34/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3221734872679.3604 - val_loss: 3341200140740.2305\n",
      "Epoch 35/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3210866745876.0479 - val_loss: 3475666186948.5908\n",
      "Epoch 36/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3225789870100.1680 - val_loss: 3307385567874.3403\n",
      "Epoch 37/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3208309115044.7041 - val_loss: 3318972677406.6050\n",
      "Epoch 38/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3185502025386.5869 - val_loss: 3694740957889.7104\n",
      "Epoch 39/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3202351192108.6572 - val_loss: 3271513377346.9707\n",
      "Epoch 40/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3186066899547.1157 - val_loss: 3307592087940.8608\n",
      "Epoch 41/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3181549661429.1357 - val_loss: 3487271405063.9214\n",
      "Epoch 42/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3164394465004.8525 - val_loss: 3313452190597.5811\n",
      "Epoch 43/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3171479002611.6348 - val_loss: 3246412072847.6626\n",
      "Epoch 44/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3162375862871.7544 - val_loss: 3436042157204.3433\n",
      "Epoch 45/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3148024739898.1025 - val_loss: 3281209543396.2759\n",
      "Epoch 46/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3145954322775.3340 - val_loss: 3222960770156.0171\n",
      "Epoch 47/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3155534344707.7217 - val_loss: 3216840269651.1729\n",
      "Epoch 48/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3122475089493.5933 - val_loss: 3234578509979.5444\n",
      "Epoch 49/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3126601561336.4971 - val_loss: 3381369404933.0410\n",
      "Epoch 50/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3115609433106.9673 - val_loss: 3329439119495.3813\n",
      "Epoch 51/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3114531335513.0151 - val_loss: 3298460224643.0605\n",
      "Epoch 52/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3121532882969.9302 - val_loss: 3186313401385.7666\n",
      "Epoch 53/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3116783921818.0200 - val_loss: 3245868174559.2349\n",
      "Epoch 54/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3114754132067.3989 - val_loss: 3229392699576.3486\n",
      "Epoch 55/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3119364094206.0190 - val_loss: 3371437397402.4644\n",
      "Epoch 56/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3107936621683.9653 - val_loss: 3215590241333.2881\n",
      "Epoch 57/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3100428480701.1938 - val_loss: 3223238886136.4390\n",
      "Epoch 58/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3096928334074.6577 - val_loss: 3178514975759.8423\n",
      "Epoch 59/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3099622206643.8301 - val_loss: 3188592709545.5864\n",
      "Epoch 60/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3097627431310.5562 - val_loss: 3196339488747.8369\n",
      "Epoch 61/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3089691156562.5923 - val_loss: 3171657074506.5317\n",
      "Epoch 62/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3115790088553.5811 - val_loss: 3214504780087.0884\n",
      "Epoch 63/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3107889641361.0767 - val_loss: 3190407021442.7002\n",
      "Epoch 64/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 63us/step - loss: 3073990321528.2271 - val_loss: 3295013111419.1392\n",
      "Epoch 65/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3088396314045.3740 - val_loss: 3164350041679.9326\n",
      "Epoch 66/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3099500301447.6528 - val_loss: 3155417939115.3867\n",
      "Epoch 67/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3092703584062.0044 - val_loss: 3151965141680.4277\n",
      "Epoch 68/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3117392312681.5811 - val_loss: 3157078611400.5513\n",
      "Epoch 69/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3103104089485.8354 - val_loss: 3264641225193.6763\n",
      "Epoch 70/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3088836118804.1074 - val_loss: 3170838152873.2266\n",
      "Epoch 71/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3089247443084.6948 - val_loss: 3198721378168.6187\n",
      "Epoch 72/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3088367563294.6123 - val_loss: 3177459570374.0308\n",
      "Epoch 73/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3086172338091.9673 - val_loss: 3173041900882.4531\n",
      "Epoch 74/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3091552173181.0889 - val_loss: 3151851658031.1675\n",
      "Epoch 75/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3088253908811.9297 - val_loss: 3158505741034.0366\n",
      "Epoch 76/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3074965077654.8989 - val_loss: 3213376090152.3262\n",
      "Epoch 77/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3076851880760.9619 - val_loss: 3147304360359.4263\n",
      "Epoch 78/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3077953571499.3071 - val_loss: 3247364708568.0337\n",
      "Epoch 79/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3095019984944.4990 - val_loss: 3274901020752.6528\n",
      "Epoch 80/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3086339857327.5684 - val_loss: 3234695278355.8032\n",
      "Epoch 81/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3064721548913.9248 - val_loss: 3341867674029.1870\n",
      "Epoch 82/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3095355026396.7061 - val_loss: 3174062898669.9971\n",
      "Epoch 83/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3080689966744.8198 - val_loss: 3152936715184.7876\n",
      "Epoch 84/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3076524034316.4248 - val_loss: 3246225418208.3149\n",
      "Epoch 85/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3070491924843.5020 - val_loss: 3184469078609.3726\n",
      "Epoch 86/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3087234003959.1167 - val_loss: 3159459981326.4023\n",
      "Epoch 87/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3069752950311.4956 - val_loss: 3314506620040.8213\n",
      "Epoch 88/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3100911242940.3540 - val_loss: 3444830494616.3037\n",
      "Epoch 89/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3089723548218.4629 - val_loss: 3139726223074.8354\n",
      "Epoch 90/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3086904513782.5767 - val_loss: 3144813559508.4331\n",
      "Epoch 91/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3071863922678.3965 - val_loss: 3263386052069.3560\n",
      "Epoch 92/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3090277310177.8081 - val_loss: 3169737378140.5347\n",
      "Epoch 93/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3081024206829.2729 - val_loss: 3330135275885.8174\n",
      "Epoch 94/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3084697722789.7246 - val_loss: 3149110691059.3979\n",
      "Epoch 95/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3070761342740.2280 - val_loss: 3146503926330.3291\n",
      "Epoch 96/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3075426272111.7036 - val_loss: 3147307593100.0620\n",
      "Epoch 97/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3077993209608.2231 - val_loss: 3254195815460.0059\n",
      "Epoch 98/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3083475471856.7539 - val_loss: 3149420736621.4570\n",
      "Epoch 99/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3078914232146.1724 - val_loss: 3148661848913.7329\n",
      "Epoch 100/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3078491773660.2861 - val_loss: 3201481919665.1475\n",
      "Epoch 101/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3082362180770.0630 - val_loss: 3206742321281.6201\n",
      "Epoch 102/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3085588991968.3076 - val_loss: 3282079915674.8242\n",
      "Epoch 103/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3080817962501.8818 - val_loss: 3161097181215.6851\n",
      "Epoch 104/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3069247383511.1841 - val_loss: 3146390417240.9341\n",
      "Epoch 105/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3074015297059.6538 - val_loss: 3146571200370.8579\n",
      "Epoch 106/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3084113355118.8633 - val_loss: 3203454630322.9478\n",
      "Epoch 107/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3091589233704.5762 - val_loss: 3210010729724.0396\n",
      "Epoch 108/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3069957372722.7197 - val_loss: 3134664299861.3335\n",
      "Epoch 109/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3085906899743.9927 - val_loss: 3487764148771.2856\n",
      "Epoch 110/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3076672013651.7329 - val_loss: 3225242252894.3350\n",
      "Epoch 111/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3076929315701.4663 - val_loss: 3189000847475.2178\n",
      "Epoch 112/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3084645125009.7969 - val_loss: 3255426578590.4248\n",
      "Epoch 113/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3084337197944.3472 - val_loss: 3135821872091.9941\n",
      "Epoch 114/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3073163515971.7065 - val_loss: 3316050652993.8901\n",
      "Epoch 115/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3089661688872.5762 - val_loss: 3138353065240.8438\n",
      "Epoch 116/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3074901910600.7480 - val_loss: 3222598833355.0718\n",
      "Epoch 117/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3089455533422.1431 - val_loss: 3161596779011.6006\n",
      "Epoch 118/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3075845031447.6489 - val_loss: 3147879717402.6440\n",
      "Epoch 119/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3086155791243.0742 - val_loss: 3394379646310.6162\n",
      "Epoch 120/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3073534071912.4409 - val_loss: 3136105500470.3687\n",
      "Epoch 121/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3054919017925.0571 - val_loss: 3330993626410.1265\n",
      "Epoch 122/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3087568190047.4370 - val_loss: 3131220083494.5259\n",
      "Epoch 123/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3083973685441.0356 - val_loss: 3134807848219.7241\n",
      "Epoch 124/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3070725768539.4155 - val_loss: 3194106537675.7920\n",
      "Epoch 125/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3076178533656.6694 - val_loss: 3276004486977.8901\n",
      "Epoch 126/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3075891605739.2920 - val_loss: 3147922947565.9971\n",
      "Epoch 127/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 62us/step - loss: 3085332640858.9951 - val_loss: 3133938879572.9731\n",
      "Epoch 128/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3069285547375.1035 - val_loss: 3178778718801.3726\n",
      "Epoch 129/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3065783846631.0903 - val_loss: 3142471638751.9551\n",
      "Epoch 130/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3073993464060.0981 - val_loss: 3422306964521.7666\n",
      "Epoch 131/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3090529948645.8296 - val_loss: 3132721651700.4780\n",
      "Epoch 132/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3073952271188.3325 - val_loss: 3164873027071.2798\n",
      "Epoch 133/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3073597076025.5024 - val_loss: 3191587996754.0928\n",
      "Epoch 134/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3096001240951.6265 - val_loss: 3201195089516.7368\n",
      "Epoch 135/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3082445008962.2656 - val_loss: 3200210418398.5146\n",
      "Epoch 136/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3072815462865.3018 - val_loss: 3166385933097.4062\n",
      "Epoch 137/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3074223218924.2524 - val_loss: 3177187187272.7314\n",
      "Epoch 138/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3081575998344.6733 - val_loss: 3399387054264.3486\n",
      "Epoch 139/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3102831647559.8481 - val_loss: 3284057538122.1714\n",
      "Epoch 140/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3084980347289.1196 - val_loss: 3135836081329.1475\n",
      "Epoch 141/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3084248060686.7056 - val_loss: 3389409180013.8174\n",
      "Epoch 142/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3081920226330.6504 - val_loss: 3136107869352.5063\n",
      "Epoch 143/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3088784199171.9614 - val_loss: 3251170887544.6187\n",
      "Epoch 144/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3083233470165.8032 - val_loss: 3217638391208.8662\n",
      "Epoch 145/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3059439862013.5391 - val_loss: 3273395288844.6021\n",
      "Epoch 146/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3071611306521.8101 - val_loss: 3163747460373.9634\n",
      "Epoch 147/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3062693118347.6748 - val_loss: 3150713530543.7075\n",
      "Epoch 148/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3078915523566.4731 - val_loss: 3156189768846.5825\n",
      "Epoch 149/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3072680051629.1675 - val_loss: 3346546229524.5234\n",
      "Epoch 150/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3081160261716.5127 - val_loss: 3225067681213.0293\n",
      "Epoch 151/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3063580433654.0957 - val_loss: 3171803379248.2476\n",
      "Epoch 152/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3095684182178.3032 - val_loss: 3243075918063.0771\n",
      "Epoch 153/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3090601966824.6509 - val_loss: 3246633786573.9521\n",
      "Epoch 154/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3064698419269.6270 - val_loss: 3273089148158.9199\n",
      "Epoch 155/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3079204627094.6587 - val_loss: 3354248289762.4756\n",
      "Epoch 156/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3079105859901.8838 - val_loss: 3187011892369.4629\n",
      "Epoch 157/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3072941780593.4438 - val_loss: 3141924739264.9902\n",
      "Epoch 158/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3062155332420.9668 - val_loss: 3149450917101.6372\n",
      "Epoch 159/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3084334440300.1021 - val_loss: 3170883457329.3276\n",
      "Epoch 160/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3064805510963.4399 - val_loss: 3293496828122.9141\n",
      "Epoch 161/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3082543484661.9761 - val_loss: 3129172428779.8369\n",
      "Epoch 162/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3071576007802.6880 - val_loss: 3347653978909.8848\n",
      "Epoch 163/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3097210791438.0454 - val_loss: 3309148613843.7129\n",
      "Epoch 164/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3052438018822.5425 - val_loss: 3243815429605.3560\n",
      "Epoch 165/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3066721390479.6357 - val_loss: 3188734185454.7173\n",
      "Epoch 166/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3066035818091.6821 - val_loss: 3179738724049.5527\n",
      "Epoch 167/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3068644221606.0249 - val_loss: 3139131100152.7988\n",
      "Epoch 168/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3061171039169.8154 - val_loss: 3151096256728.0337\n",
      "Epoch 169/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3058591915542.2085 - val_loss: 3435548799615.4600\n",
      "Epoch 170/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3055687136631.2666 - val_loss: 3305402539213.9521\n",
      "Epoch 171/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3069521836908.3428 - val_loss: 3246917044779.9268\n",
      "Epoch 172/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3075833877450.9390 - val_loss: 3210509296272.7427\n",
      "Epoch 173/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3066832975930.1025 - val_loss: 3211546338305.4404\n",
      "Epoch 174/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3062150242893.6704 - val_loss: 3164067926067.8481\n",
      "Epoch 175/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3072378234516.4980 - val_loss: 3182866453338.3740\n",
      "Epoch 176/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3066135300909.9180 - val_loss: 3159208132101.0410\n",
      "Epoch 177/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3071030544590.9604 - val_loss: 3136333658293.4683\n",
      "Epoch 178/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3074937634650.8154 - val_loss: 3296004325076.4331\n",
      "Epoch 179/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3066109266906.7856 - val_loss: 3135012553187.9155\n",
      "Epoch 180/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3054913817086.4395 - val_loss: 3199241279773.1646\n",
      "Epoch 181/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3079052426595.5786 - val_loss: 3184149339249.7778\n",
      "Epoch 182/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3063759051107.8188 - val_loss: 3134285174009.1587\n",
      "Epoch 183/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3065247931607.3643 - val_loss: 3161339260323.1055\n",
      "Epoch 184/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3091464790229.2031 - val_loss: 3137342042567.1113\n",
      "Epoch 185/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3076666970160.9790 - val_loss: 3134285505837.0068\n",
      "Epoch 186/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3060613750344.1484 - val_loss: 3136142615783.8765\n",
      "Epoch 187/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3070541900676.3521 - val_loss: 3208192084892.6245\n",
      "Epoch 188/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3093607732055.6943 - val_loss: 3160342053117.4795\n",
      "Epoch 189/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3048614228906.2866 - val_loss: 3173741246138.5093\n",
      "Epoch 190/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 72us/step - loss: 3075966492443.4307 - val_loss: 3224352133171.8481\n",
      "Epoch 191/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3065165017119.6924 - val_loss: 3138890796693.0635\n",
      "Epoch 192/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3073799225989.3721 - val_loss: 3200366217841.0576\n",
      "Epoch 193/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3065847055911.0156 - val_loss: 3202163382718.4697\n",
      "Epoch 194/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3076230779785.6338 - val_loss: 3152684134094.6724\n",
      "Epoch 195/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3075728517351.9307 - val_loss: 3255956897745.9126\n",
      "Epoch 196/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3055294453247.6396 - val_loss: 3137286260093.6597\n",
      "Epoch 197/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3069671852669.2085 - val_loss: 3128521151368.4614\n",
      "Epoch 198/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3053796898148.0591 - val_loss: 3217349158258.1377\n",
      "Epoch 199/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3075173910293.1880 - val_loss: 3191617192442.9590\n",
      "Epoch 200/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3057879728193.3057 - val_loss: 3119321328252.5796\n",
      "Epoch 201/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3067694278561.4028 - val_loss: 3191281072217.2939\n",
      "Epoch 202/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3069066900993.5605 - val_loss: 3138508985984.8999\n",
      "Epoch 203/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3094852211801.0747 - val_loss: 3143631968103.3359\n",
      "Epoch 204/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3066077873733.7471 - val_loss: 3142039325688.7988\n",
      "Epoch 205/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3045445639367.9980 - val_loss: 3173297056219.2744\n",
      "Epoch 206/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3052120853900.8750 - val_loss: 3822175219521.8901\n",
      "Epoch 207/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3071343178677.8110 - val_loss: 3119164718043.9941\n",
      "Epoch 208/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3078613027706.7476 - val_loss: 3260598073202.8579\n",
      "Epoch 209/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3055208879857.6543 - val_loss: 3138300366554.1943\n",
      "Epoch 210/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3058386378972.8862 - val_loss: 3261363975751.2910\n",
      "Epoch 211/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3047389422806.8838 - val_loss: 3135696046658.9707\n",
      "Epoch 212/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3059093868996.3369 - val_loss: 3176174515783.2910\n",
      "Epoch 213/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3064930744128.4053 - val_loss: 3154930786338.5654\n",
      "Epoch 214/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3055704521326.8032 - val_loss: 3131911817725.8398\n",
      "Epoch 215/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3050714085199.7710 - val_loss: 3128928455304.1011\n",
      "Epoch 216/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3083712789867.2622 - val_loss: 3131442683201.1704\n",
      "Epoch 217/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3055940376432.4238 - val_loss: 3164070986626.7002\n",
      "Epoch 218/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3047837003354.3955 - val_loss: 3208684538434.9707\n",
      "Epoch 219/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3038819073475.6162 - val_loss: 3118475257939.5332\n",
      "Epoch 220/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3076874251386.2080 - val_loss: 3113543256389.4907\n",
      "Epoch 221/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3070484082097.3691 - val_loss: 3120725614119.6060\n",
      "Epoch 222/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3061143313892.2690 - val_loss: 3139620666792.8662\n",
      "Epoch 223/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3062650296187.9487 - val_loss: 3119354294980.5908\n",
      "Epoch 224/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3075108620456.5454 - val_loss: 3126423576472.3037\n",
      "Epoch 225/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3041616755683.4287 - val_loss: 3159711505729.1704\n",
      "Epoch 226/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3058665136879.0137 - val_loss: 3108561938953.3613\n",
      "Epoch 227/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3052006242392.8350 - val_loss: 3292640229649.6426\n",
      "Epoch 228/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3058580660191.3472 - val_loss: 3115746714971.0942\n",
      "Epoch 229/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3059141914183.1875 - val_loss: 3112090410835.1729\n",
      "Epoch 230/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3043706862939.8960 - val_loss: 3161657853401.8340\n",
      "Epoch 231/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3071368299832.8423 - val_loss: 3112537111585.1250\n",
      "Epoch 232/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3050604248676.9595 - val_loss: 3155615966601.1816\n",
      "Epoch 233/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3040136655809.3354 - val_loss: 3109219041786.9590\n",
      "Epoch 234/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3056504371903.4751 - val_loss: 3141271288381.2095\n",
      "Epoch 235/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3067797830235.5957 - val_loss: 3117441140416.2700\n",
      "Epoch 236/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3069264757419.7871 - val_loss: 3287464762689.1704\n",
      "Epoch 237/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3066789605695.8047 - val_loss: 3137234696995.6455\n",
      "Epoch 238/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3061977514767.6660 - val_loss: 3279424462951.6963\n",
      "Epoch 239/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3067147280286.0415 - val_loss: 3197619673211.8594\n",
      "Epoch 240/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3054101833637.2446 - val_loss: 3114703539284.9731\n",
      "Epoch 241/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3062877251120.6191 - val_loss: 3228027434820.7705\n",
      "Epoch 242/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3060051535362.5210 - val_loss: 3118431677882.1489\n",
      "Epoch 243/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3047564286192.5742 - val_loss: 3113826707055.6177\n",
      "Epoch 244/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3060262570686.5142 - val_loss: 3118704723901.7495\n",
      "Epoch 245/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3062012429152.3379 - val_loss: 3111827080734.9648\n",
      "Epoch 246/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3036689717592.2944 - val_loss: 3533200068429.4121\n",
      "Epoch 247/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3063883685405.8921 - val_loss: 3128997354932.3882\n",
      "Epoch 248/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3053838688388.5317 - val_loss: 3142633361690.2842\n",
      "Epoch 249/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3052290869727.7075 - val_loss: 3137301897665.3501\n",
      "Epoch 250/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3055282023135.1670 - val_loss: 3127100611098.6440\n",
      "Epoch 251/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3039867977078.7866 - val_loss: 3308599525399.0435\n",
      "Epoch 252/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3037028630754.6484 - val_loss: 3649942723605.6035\n",
      "Epoch 253/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 96us/step - loss: 3065585036375.6343 - val_loss: 3270922911444.4331\n",
      "Epoch 254/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3060998691690.4214 - val_loss: 3156568742426.6440\n",
      "Epoch 255/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3050670704393.6636 - val_loss: 3133640871619.1504\n",
      "Epoch 256/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3050052535958.4189 - val_loss: 3129079227554.7456\n",
      "Epoch 257/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3047399526998.3135 - val_loss: 3146744628352.1802\n",
      "Epoch 258/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3065632442567.2778 - val_loss: 3180539841644.0171\n",
      "Epoch 259/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3048905218764.9199 - val_loss: 3130753314533.7158\n",
      "Epoch 260/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3045108992752.4541 - val_loss: 3140556301129.0913\n",
      "Epoch 261/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3052818187857.2720 - val_loss: 3129539293961.7217\n",
      "Epoch 262/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3051853372181.9087 - val_loss: 3120585440450.4302\n",
      "Epoch 263/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3045990951255.3340 - val_loss: 3107329838188.0171\n",
      "Epoch 264/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3042692812057.6299 - val_loss: 3139478990680.9341\n",
      "Epoch 265/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3036961761415.8931 - val_loss: 3143233785746.5430\n",
      "Epoch 266/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3043565118498.3330 - val_loss: 3120731949450.6216\n",
      "Epoch 267/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3037789955505.8491 - val_loss: 3210284570655.6851\n",
      "Epoch 268/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3064365353393.6094 - val_loss: 3110431923083.3418\n",
      "Epoch 269/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3043386112100.3594 - val_loss: 3127121064598.5034\n",
      "Epoch 270/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3044925915562.4067 - val_loss: 3113894538935.6289\n",
      "Epoch 271/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3052608305721.0225 - val_loss: 3159332054685.7046\n",
      "Epoch 272/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3062473410820.7417 - val_loss: 3132187376788.3433\n",
      "Epoch 273/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3044436622772.2505 - val_loss: 3139674593979.9492\n",
      "Epoch 274/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3036665222033.3169 - val_loss: 3117107607710.4248\n",
      "Epoch 275/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3054875278353.5269 - val_loss: 3118166860455.7861\n",
      "Epoch 276/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3054416474293.5112 - val_loss: 3192867193477.2207\n",
      "Epoch 277/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3054387201198.5479 - val_loss: 3133229535975.1562\n",
      "Epoch 278/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3054109042566.5122 - val_loss: 3162217237727.2349\n",
      "Epoch 279/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3055275147648.1504 - val_loss: 3103674568617.5864\n",
      "Epoch 280/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3059270122943.7749 - val_loss: 3156728588325.4458\n",
      "Epoch 281/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3043945312548.9146 - val_loss: 3144670962021.1758\n",
      "Epoch 282/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3031414388590.5029 - val_loss: 3109944533602.6553\n",
      "Epoch 283/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3048638721760.8481 - val_loss: 3158421519070.5146\n",
      "Epoch 284/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3039889863613.4941 - val_loss: 3112378667105.9351\n",
      "Epoch 285/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3048355223442.9971 - val_loss: 3102251825379.5557\n",
      "Epoch 286/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3050943501673.8213 - val_loss: 3213634776137.4517\n",
      "Epoch 287/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3063663980360.5684 - val_loss: 3202924854627.7354\n",
      "Epoch 288/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3080774625212.2935 - val_loss: 3123250179928.9341\n",
      "Epoch 289/800\n",
      "4265/4265 [==============================] - 0s 112us/step - loss: 3039353241077.5562 - val_loss: 3135043735788.1968\n",
      "Epoch 290/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3033390445551.4331 - val_loss: 3144728630014.1997\n",
      "Epoch 291/800\n",
      "4265/4265 [==============================] - 0s 111us/step - loss: 3053917955786.2788 - val_loss: 3108421132967.7861\n",
      "Epoch 292/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3043788114349.7681 - val_loss: 3180785287329.3052\n",
      "Epoch 293/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3036109074225.5195 - val_loss: 3419853704461.3223\n",
      "Epoch 294/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3058543114009.9902 - val_loss: 3291317119935.1899\n",
      "Epoch 295/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3043372337923.6611 - val_loss: 3130455485029.5356\n",
      "Epoch 296/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3057482990858.7441 - val_loss: 3120132743939.9604\n",
      "Epoch 297/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3025347485939.9355 - val_loss: 3105814731774.5596\n",
      "Epoch 298/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3032065537353.1685 - val_loss: 3100379554587.0044\n",
      "Epoch 299/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3058796707290.6655 - val_loss: 3123715602406.0762\n",
      "Epoch 300/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3052919452086.8916 - val_loss: 3112865506121.0913\n",
      "Epoch 301/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3028602078132.8506 - val_loss: 3105675403897.6992\n",
      "Epoch 302/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3057185272811.5918 - val_loss: 3480076846023.8311\n",
      "Epoch 303/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3077006791638.4639 - val_loss: 3097848900842.7568\n",
      "Epoch 304/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3046679232362.1816 - val_loss: 3153234775493.6709\n",
      "Epoch 305/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3050385583579.6255 - val_loss: 3113313209359.8423\n",
      "Epoch 306/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3047607846104.8047 - val_loss: 3165843665558.5034\n",
      "Epoch 307/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3038747770000.2964 - val_loss: 3126819432347.1841\n",
      "Epoch 308/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3052011126384.4839 - val_loss: 3105675854077.4795\n",
      "Epoch 309/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3023638026230.8765 - val_loss: 3176625271469.5469\n",
      "Epoch 310/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3033342454391.4468 - val_loss: 3437643950324.8384\n",
      "Epoch 311/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3056351682027.9521 - val_loss: 3107802979718.3008\n",
      "Epoch 312/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3044222672333.2197 - val_loss: 3108341614110.9648\n",
      "Epoch 313/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3029276009852.0684 - val_loss: 3111648062929.1929\n",
      "Epoch 314/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3024685691672.3091 - val_loss: 3145210509309.1196\n",
      "Epoch 315/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3027074345925.6572 - val_loss: 3099986043628.9170\n",
      "Epoch 316/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 63us/step - loss: 3033400881771.4419 - val_loss: 3106229928788.6133\n",
      "Epoch 317/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3052673969566.1621 - val_loss: 3099845982043.8145\n",
      "Epoch 318/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3070472411126.8765 - val_loss: 3365118940939.1616\n",
      "Epoch 319/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3045745941823.0845 - val_loss: 3118975088383.6401\n",
      "Epoch 320/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3025689286128.2739 - val_loss: 3095710799811.5107\n",
      "Epoch 321/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3029622174169.4653 - val_loss: 3165607638622.3350\n",
      "Epoch 322/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3057766470153.4839 - val_loss: 3139985436297.5415\n",
      "Epoch 323/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3038801893547.4268 - val_loss: 3090448107845.4907\n",
      "Epoch 324/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3034803033664.9453 - val_loss: 3097518405836.5117\n",
      "Epoch 325/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3036436176217.9751 - val_loss: 3092876299418.1040\n",
      "Epoch 326/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3065584414820.8394 - val_loss: 3111816039716.3657\n",
      "Epoch 327/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3037421609933.8203 - val_loss: 3165570528839.2910\n",
      "Epoch 328/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3030763168068.6069 - val_loss: 3209694754398.3350\n",
      "Epoch 329/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3038333709403.4761 - val_loss: 3155068002315.5220\n",
      "Epoch 330/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3031113291497.9717 - val_loss: 3112847248952.8887\n",
      "Epoch 331/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3028802416322.1162 - val_loss: 3150424287269.4458\n",
      "Epoch 332/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3034590011947.0967 - val_loss: 3109543176759.4487\n",
      "Epoch 333/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3021635958254.3535 - val_loss: 3115167118274.0703\n",
      "Epoch 334/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3055377656646.8877 - val_loss: 3323319766377.4966\n",
      "Epoch 335/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3040077466275.6235 - val_loss: 3206125580881.3726\n",
      "Epoch 336/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3027297175394.0181 - val_loss: 3149913299298.2954\n",
      "Epoch 337/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3027480210880.7354 - val_loss: 3097306726584.3486\n",
      "Epoch 338/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3026069885441.8008 - val_loss: 3511885927327.5049\n",
      "Epoch 339/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3029541700571.2656 - val_loss: 3110749323056.6074\n",
      "Epoch 340/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3026060263343.3286 - val_loss: 3106752194850.9253\n",
      "Epoch 341/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3041632019348.1978 - val_loss: 3362178792089.3838\n",
      "Epoch 342/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3034881218835.1475 - val_loss: 3103041371399.5610\n",
      "Epoch 343/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3037696302057.1909 - val_loss: 3116627158962.2280\n",
      "Epoch 344/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3057418964476.2783 - val_loss: 3109045865257.4062\n",
      "Epoch 345/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3037273549404.5562 - val_loss: 3093257850194.4531\n",
      "Epoch 346/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3050258218443.2993 - val_loss: 3162132279105.8901\n",
      "Epoch 347/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3033471170230.1113 - val_loss: 3084823285512.2812\n",
      "Epoch 348/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3019458646091.8696 - val_loss: 3088640287238.4810\n",
      "Epoch 349/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3034251033018.2529 - val_loss: 3087457440786.7231\n",
      "Epoch 350/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3043478444226.4761 - val_loss: 3239968313764.5459\n",
      "Epoch 351/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3021974496670.6421 - val_loss: 3093906812922.2393\n",
      "Epoch 352/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3033825752965.5522 - val_loss: 3185387964856.7090\n",
      "Epoch 353/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3041000371302.5200 - val_loss: 3092561754270.4248\n",
      "Epoch 354/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3038554197093.0796 - val_loss: 3276488100626.3628\n",
      "Epoch 355/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3036873903900.3911 - val_loss: 3097402295954.1826\n",
      "Epoch 356/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3034888348291.4517 - val_loss: 3087478086378.0366\n",
      "Epoch 357/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3017487540471.7769 - val_loss: 3184504424174.3574\n",
      "Epoch 358/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3023667931667.5674 - val_loss: 3093257943474.9478\n",
      "Epoch 359/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3032836252237.6704 - val_loss: 3125165444180.9731\n",
      "Epoch 360/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3032174325668.7642 - val_loss: 3105868080106.3965\n",
      "Epoch 361/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3028939341109.4810 - val_loss: 3113076028400.1577\n",
      "Epoch 362/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3026492326625.5679 - val_loss: 3121851641688.9341\n",
      "Epoch 363/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3033148987140.8618 - val_loss: 3091939183286.1885\n",
      "Epoch 364/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3024170514820.4717 - val_loss: 3085627100129.7554\n",
      "Epoch 365/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3042020826534.8052 - val_loss: 3182902806922.6216\n",
      "Epoch 366/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3041799005137.6616 - val_loss: 3130174339829.5586\n",
      "Epoch 367/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3039329104468.3931 - val_loss: 3163247092737.4404\n",
      "Epoch 368/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3032597120178.3896 - val_loss: 3155705929555.1729\n",
      "Epoch 369/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3037832231803.7085 - val_loss: 3087067884847.8877\n",
      "Epoch 370/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3035333402729.6411 - val_loss: 3168055307014.8413\n",
      "Epoch 371/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3070268160108.0420 - val_loss: 3082703360904.4614\n",
      "Epoch 372/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3032538866188.3652 - val_loss: 3191656980076.7368\n",
      "Epoch 373/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3045061057447.8853 - val_loss: 3163068123231.0547\n",
      "Epoch 374/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3035105222204.6235 - val_loss: 3106445152699.5894\n",
      "Epoch 375/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3013587459383.4014 - val_loss: 3090946358051.6455\n",
      "Epoch 376/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3015960002782.8071 - val_loss: 3106243184205.0522\n",
      "Epoch 377/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3015394578335.0024 - val_loss: 3149953744688.6074\n",
      "Epoch 378/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3024463138085.1543 - val_loss: 3096538215500.3320\n",
      "Epoch 379/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 84us/step - loss: 3027914146633.2886 - val_loss: 3093819637690.8691\n",
      "Epoch 380/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3039615997996.6572 - val_loss: 3107474748884.0732\n",
      "Epoch 381/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3041098533689.4424 - val_loss: 3083138601795.3306\n",
      "Epoch 382/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3043417423618.4609 - val_loss: 3080546467724.7822\n",
      "Epoch 383/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3016957817194.0615 - val_loss: 3084832151583.6851\n",
      "Epoch 384/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3025040565178.6128 - val_loss: 3223456101383.2012\n",
      "Epoch 385/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3032890338599.0752 - val_loss: 3086554164090.0591\n",
      "Epoch 386/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3030408472300.8525 - val_loss: 3122702434280.9565\n",
      "Epoch 387/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3028595674873.8174 - val_loss: 3092093620759.7637\n",
      "Epoch 388/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3018187995309.3477 - val_loss: 3262408920079.8423\n",
      "Epoch 389/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3034564772857.9976 - val_loss: 3107806354038.8184\n",
      "Epoch 390/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3020616298243.4214 - val_loss: 3088887376577.7104\n",
      "Epoch 391/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3032074668661.5259 - val_loss: 3134827057733.8511\n",
      "Epoch 392/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3025375418627.7812 - val_loss: 3079430234238.7397\n",
      "Epoch 393/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3019009540898.8735 - val_loss: 3127558048691.6680\n",
      "Epoch 394/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3018297614710.5459 - val_loss: 3083832784547.4653\n",
      "Epoch 395/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3020488973704.0732 - val_loss: 3226222933229.6372\n",
      "Epoch 396/800\n",
      "4265/4265 [==============================] - 0s 58us/step - loss: 3009939700238.7656 - val_loss: 3090717481268.2080\n",
      "Epoch 397/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3015742428056.9995 - val_loss: 3152029676666.4189\n",
      "Epoch 398/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3012436339534.5708 - val_loss: 3116297787746.2954\n",
      "Epoch 399/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3018982857128.9658 - val_loss: 3131444978343.7861\n",
      "Epoch 400/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3038493443669.1133 - val_loss: 3099331284974.7173\n",
      "Epoch 401/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3023533728998.2500 - val_loss: 3170698944823.0884\n",
      "Epoch 402/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3019568510334.9492 - val_loss: 3072274586438.2109\n",
      "Epoch 403/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3013275602370.6562 - val_loss: 3131858912199.8311\n",
      "Epoch 404/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3014452520753.9995 - val_loss: 3081060300197.9858\n",
      "Epoch 405/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3023057606838.9512 - val_loss: 3285928661159.0659\n",
      "Epoch 406/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3018519853448.3130 - val_loss: 3077961507034.9141\n",
      "Epoch 407/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3004121618342.2051 - val_loss: 3073027911605.1084\n",
      "Epoch 408/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3007464710042.2002 - val_loss: 3095603011065.5190\n",
      "Epoch 409/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3018127020492.0195 - val_loss: 3078603504696.1689\n",
      "Epoch 410/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3025167171802.9653 - val_loss: 3101803241690.9141\n",
      "Epoch 411/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3009809564212.7007 - val_loss: 3105929764691.1729\n",
      "Epoch 412/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3026647219063.8667 - val_loss: 3080144461605.0859\n",
      "Epoch 413/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3031023050561.8457 - val_loss: 3142178170571.7920\n",
      "Epoch 414/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3008865655458.6636 - val_loss: 3078459291207.2910\n",
      "Epoch 415/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3034755615779.7739 - val_loss: 3145359582232.4839\n",
      "Epoch 416/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3010020264619.3071 - val_loss: 3246364564685.9521\n",
      "Epoch 417/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3006382989360.0186 - val_loss: 3080371691416.3037\n",
      "Epoch 418/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3006578618084.6895 - val_loss: 3078463224104.6865\n",
      "Epoch 419/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3002424284744.6284 - val_loss: 3090155730272.8550\n",
      "Epoch 420/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3015882506439.7583 - val_loss: 3107903698318.9424\n",
      "Epoch 421/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3029527586959.5762 - val_loss: 3071735545372.0845\n",
      "Epoch 422/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3006378109947.4380 - val_loss: 3145880213120.8999\n",
      "Epoch 423/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3010112920814.4131 - val_loss: 3087793980590.2671\n",
      "Epoch 424/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3005278658281.4912 - val_loss: 3088549741373.5698\n",
      "Epoch 425/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3000913964553.7241 - val_loss: 3085733779095.9438\n",
      "Epoch 426/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3006878585284.3369 - val_loss: 3096033284862.1997\n",
      "Epoch 427/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3013758902419.8979 - val_loss: 3083635498143.8647\n",
      "Epoch 428/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3031151534619.7310 - val_loss: 3215083759215.6177\n",
      "Epoch 429/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3027847120376.9170 - val_loss: 3312609406855.0210\n",
      "Epoch 430/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3029760290805.4355 - val_loss: 3205807039789.0068\n",
      "Epoch 431/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3007738441175.7842 - val_loss: 3144663460130.9253\n",
      "Epoch 432/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3006715578213.8594 - val_loss: 3177272901355.4766\n",
      "Epoch 433/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3012919631900.8115 - val_loss: 3259131265070.0874\n",
      "Epoch 434/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3009158109559.0269 - val_loss: 3251879503702.0532\n",
      "Epoch 435/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3015032112994.0181 - val_loss: 3086132202580.9731\n",
      "Epoch 436/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3019097664799.3921 - val_loss: 3158039865796.2305\n",
      "Epoch 437/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3034857284135.2554 - val_loss: 3077500726460.6694\n",
      "Epoch 438/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3001529943763.8823 - val_loss: 3081216637939.0381\n",
      "Epoch 439/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3014287952405.4888 - val_loss: 3205768431987.5781\n",
      "Epoch 440/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3008960038054.8652 - val_loss: 3108998266027.3867\n",
      "Epoch 441/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3024228881658.4180 - val_loss: 3070534679562.0815\n",
      "Epoch 442/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 64us/step - loss: 3027302468121.3301 - val_loss: 3278048571593.6313\n",
      "Epoch 443/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3030005242830.3003 - val_loss: 3066449027429.1758\n",
      "Epoch 444/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3004188176734.5366 - val_loss: 3088077394017.9351\n",
      "Epoch 445/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3009606688604.7358 - val_loss: 3206803811931.4541\n",
      "Epoch 446/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3013492261067.5996 - val_loss: 3066141553164.2417\n",
      "Epoch 447/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3020320247991.4316 - val_loss: 3145555660414.0195\n",
      "Epoch 448/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3029693898980.5693 - val_loss: 3071012182047.6851\n",
      "Epoch 449/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 2997400041783.6416 - val_loss: 3295777848145.7329\n",
      "Epoch 450/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3002865136581.1768 - val_loss: 3090678311202.9253\n",
      "Epoch 451/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3028131632174.8184 - val_loss: 3073278141510.5708\n",
      "Epoch 452/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3006612207182.3906 - val_loss: 3086699103175.8311\n",
      "Epoch 453/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2995601298317.4756 - val_loss: 3278140836695.4937\n",
      "Epoch 454/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3034549453138.0518 - val_loss: 3064677700142.8071\n",
      "Epoch 455/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3005237572541.4941 - val_loss: 3082907727408.2476\n",
      "Epoch 456/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2998219458167.6870 - val_loss: 3200733580027.3193\n",
      "Epoch 457/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3006519536543.2422 - val_loss: 3133064214548.1631\n",
      "Epoch 458/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3016094773978.8457 - val_loss: 3110081826637.4121\n",
      "Epoch 459/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3026800802072.9097 - val_loss: 3063502105973.0181\n",
      "Epoch 460/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2988390785429.2783 - val_loss: 3054561066547.1279\n",
      "Epoch 461/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3002592969138.0894 - val_loss: 3061733821548.0171\n",
      "Epoch 462/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3004606188975.4487 - val_loss: 3097008492987.5894\n",
      "Epoch 463/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3014526374678.3887 - val_loss: 3064593064131.8706\n",
      "Epoch 464/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3025639210600.8013 - val_loss: 3108643048371.6680\n",
      "Epoch 465/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 2994490063755.0742 - val_loss: 3221995322562.4302\n",
      "Epoch 466/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2995685119122.6973 - val_loss: 3065837950961.5977\n",
      "Epoch 467/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3006820710219.9297 - val_loss: 3061004513343.3701\n",
      "Epoch 468/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3002369359583.8872 - val_loss: 3061142231486.4697\n",
      "Epoch 469/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2990925226504.5229 - val_loss: 3160695253259.8818\n",
      "Epoch 470/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3004855662477.2354 - val_loss: 3095077926678.6836\n",
      "Epoch 471/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3012256437083.5356 - val_loss: 3199769499933.1646\n",
      "Epoch 472/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 2998971905794.9409 - val_loss: 3101655493129.3613\n",
      "Epoch 473/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2997830052506.0200 - val_loss: 3066931083330.2505\n",
      "Epoch 474/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3013081409475.9766 - val_loss: 3058411111321.7441\n",
      "Epoch 475/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3001312103175.5029 - val_loss: 3095108071026.4980\n",
      "Epoch 476/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2990569930110.4692 - val_loss: 3110339092030.6499\n",
      "Epoch 477/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 2998978098570.4741 - val_loss: 3055442618843.2744\n",
      "Epoch 478/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 2993291681033.3037 - val_loss: 3059323411523.6904\n",
      "Epoch 479/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2997250249843.9653 - val_loss: 3225587178356.2983\n",
      "Epoch 480/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3003912460958.8223 - val_loss: 3066033734922.4414\n",
      "Epoch 481/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3028436811983.4409 - val_loss: 3059655497091.4204\n",
      "Epoch 482/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3002125195589.0869 - val_loss: 3155729738940.6694\n",
      "Epoch 483/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2997057855447.6641 - val_loss: 3090392604844.8271\n",
      "Epoch 484/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 2995183118587.1382 - val_loss: 3224979184938.1265\n",
      "Epoch 485/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3007789238782.4395 - val_loss: 3185237424516.8608\n",
      "Epoch 486/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2989804534352.0713 - val_loss: 3066539838387.6680\n",
      "Epoch 487/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 2997158345568.8179 - val_loss: 3106867019084.6919\n",
      "Epoch 488/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2992943823013.6646 - val_loss: 3118712712472.8438\n",
      "Epoch 489/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3015461945716.6255 - val_loss: 3090684910152.7314\n",
      "Epoch 490/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2997342473516.8374 - val_loss: 3094601669284.9058\n",
      "Epoch 491/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2990630131956.4155 - val_loss: 3075892636722.4077\n",
      "Epoch 492/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2999592269109.9609 - val_loss: 3048210140728.8887\n",
      "Epoch 493/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2994743051968.6753 - val_loss: 3055525466670.8071\n",
      "Epoch 494/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3001754018861.8579 - val_loss: 3057419538921.6763\n",
      "Epoch 495/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 2988462797215.8423 - val_loss: 3160930052801.7104\n",
      "Epoch 496/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 2996416363879.4204 - val_loss: 3220435821269.8735\n",
      "Epoch 497/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3007228102985.8887 - val_loss: 3056122519356.1294\n",
      "Epoch 498/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 2985587580803.1514 - val_loss: 3095686325664.2251\n",
      "Epoch 499/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3010718385683.8076 - val_loss: 3045325768453.4009\n",
      "Epoch 500/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3002193962383.2759 - val_loss: 3102450724097.8003\n",
      "Epoch 501/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 2985292621230.0078 - val_loss: 3042466101498.5991\n",
      "Epoch 502/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 2989674597715.2529 - val_loss: 3055264109471.5049\n",
      "Epoch 503/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 2996812094740.8281 - val_loss: 3180991208630.9087\n",
      "Epoch 504/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 2978406881493.6836 - val_loss: 3077452260791.2686\n",
      "Epoch 505/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 66us/step - loss: 2992872786476.5371 - val_loss: 3045577020019.9380\n",
      "Epoch 506/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2977178365088.6230 - val_loss: 3051191994071.3135\n",
      "Epoch 507/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3011007093798.6553 - val_loss: 3076159185921.4404\n",
      "Epoch 508/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2979645340931.5415 - val_loss: 3086012126987.1616\n",
      "Epoch 509/800\n",
      "4265/4265 [==============================] - 0s 112us/step - loss: 3000533462261.1357 - val_loss: 3054925972101.2207\n",
      "Epoch 510/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2988378523267.2109 - val_loss: 3050541489081.4292\n",
      "Epoch 511/800\n",
      "4265/4265 [==============================] - 0s 115us/step - loss: 2983253539012.3970 - val_loss: 3054133834137.0239\n",
      "Epoch 512/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 3002049684656.4688 - val_loss: 3042414710213.6709\n",
      "Epoch 513/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 2995828242862.7280 - val_loss: 3135477866530.5654\n",
      "Epoch 514/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2994320940493.2197 - val_loss: 3461377278666.3516\n",
      "Epoch 515/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2985226281495.8896 - val_loss: 3067384927596.3770\n",
      "Epoch 516/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2986105867088.4912 - val_loss: 3066517743446.0532\n",
      "Epoch 517/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2973019361528.7368 - val_loss: 3255848923913.7217\n",
      "Epoch 518/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2969519222277.8818 - val_loss: 3110363052213.4683\n",
      "Epoch 519/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 2978108958464.0601 - val_loss: 3036492534364.8945\n",
      "Epoch 520/800\n",
      "4265/4265 [==============================] - 0s 112us/step - loss: 2981882897565.2617 - val_loss: 3113348820018.4077\n",
      "Epoch 521/800\n",
      "4265/4265 [==============================] - 1s 123us/step - loss: 2985101846594.7461 - val_loss: 3048852297667.5107\n",
      "Epoch 522/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 2997354737522.8252 - val_loss: 3088475627254.9985\n",
      "Epoch 523/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 2970680336236.1021 - val_loss: 3120175727444.6133\n",
      "Epoch 524/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3006858303236.8618 - val_loss: 3185599129038.3120\n",
      "Epoch 525/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 2976537838812.6460 - val_loss: 3060366546284.3770\n",
      "Epoch 526/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 2972289263260.1812 - val_loss: 3043795934782.6499\n",
      "Epoch 527/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2966357467598.9009 - val_loss: 3104936302715.8594\n",
      "Epoch 528/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 2959449487080.0508 - val_loss: 3102975308899.3755\n",
      "Epoch 529/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2982512642009.1050 - val_loss: 3087894470598.3911\n",
      "Epoch 530/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 2996750740997.8818 - val_loss: 3042688296375.2686\n",
      "Epoch 531/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2970789048674.3784 - val_loss: 3055368063024.9678\n",
      "Epoch 532/800\n",
      "4265/4265 [==============================] - 1s 119us/step - loss: 2978519408910.8257 - val_loss: 3087153448502.0083\n",
      "Epoch 533/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 2969384993916.6089 - val_loss: 3146460728243.6680\n",
      "Epoch 534/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 2973790234037.6909 - val_loss: 3136833309919.2349\n",
      "Epoch 535/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 2989309045866.8418 - val_loss: 3035410715113.6763\n",
      "Epoch 536/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 2975977958725.8071 - val_loss: 3037939307838.2896\n",
      "Epoch 537/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2964361520761.6074 - val_loss: 3078949840426.4868\n",
      "Epoch 538/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 2984374590667.8394 - val_loss: 3034311487436.1519\n",
      "Epoch 539/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 2976140866562.6411 - val_loss: 3142681301965.5923\n",
      "Epoch 540/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 2974706297198.3833 - val_loss: 3104833077708.8721\n",
      "Epoch 541/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2999641326639.7788 - val_loss: 3023696220557.5020\n",
      "Epoch 542/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 2965708366970.6880 - val_loss: 3029880322874.6890\n",
      "Epoch 543/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2984933282286.5933 - val_loss: 3073809317888.0000\n",
      "Epoch 544/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2981941490283.4419 - val_loss: 3031196135694.7622\n",
      "Epoch 545/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 2970478306188.5146 - val_loss: 3063048614919.2012\n",
      "Epoch 546/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 2957791655172.0215 - val_loss: 3042359282427.3193\n",
      "Epoch 547/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 2986446664491.5171 - val_loss: 3034246218004.5234\n",
      "Epoch 548/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2996464556887.2139 - val_loss: 3072640233443.1953\n",
      "Epoch 549/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2979165865910.5312 - val_loss: 3390953775599.4375\n",
      "Epoch 550/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2964122835115.4268 - val_loss: 3086704652812.2417\n",
      "Epoch 551/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2983619932118.7036 - val_loss: 3136611297179.1841\n",
      "Epoch 552/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2995492857365.7285 - val_loss: 3053858971544.3037\n",
      "Epoch 553/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2975417040450.3862 - val_loss: 3176629574908.0396\n",
      "Epoch 554/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 2976468308789.1206 - val_loss: 3029163906550.6387\n",
      "Epoch 555/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2964787722620.7891 - val_loss: 3044780429663.4150\n",
      "Epoch 556/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2964760981351.3003 - val_loss: 3063802906811.2295\n",
      "Epoch 557/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2968791818314.9092 - val_loss: 3015096778360.2588\n",
      "Epoch 558/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 2965560692927.1147 - val_loss: 3080451172297.2715\n",
      "Epoch 559/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2970981255820.5752 - val_loss: 3076035886067.0381\n",
      "Epoch 560/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 2952244819787.9297 - val_loss: 3022724861266.4531\n",
      "Epoch 561/800\n",
      "4265/4265 [==============================] - ETA: 0s - loss: 2965821203438.035 - 0s 83us/step - loss: 2950805969701.2749 - val_loss: 3105298055536.6978\n",
      "Epoch 562/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2966567542947.2642 - val_loss: 3100549466299.2295\n",
      "Epoch 563/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2948090556516.8394 - val_loss: 3027876310895.9775\n",
      "Epoch 564/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 2961700381895.5181 - val_loss: 3031074201865.0015\n",
      "Epoch 565/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2961937722463.3174 - val_loss: 3017324026417.6880\n",
      "Epoch 566/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 2973510695169.8604 - val_loss: 3023495144311.1787\n",
      "Epoch 567/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 2976945713487.1709 - val_loss: 3022176961134.1772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 568/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 2943223938130.8325 - val_loss: 3116525625539.8706\n",
      "Epoch 569/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 2949553256728.9097 - val_loss: 3032763787047.9663\n",
      "Epoch 570/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 2943296844126.5366 - val_loss: 3021474970104.0786\n",
      "Epoch 571/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2962988838033.2568 - val_loss: 3024067895399.6963\n",
      "Epoch 572/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2948770245938.6001 - val_loss: 3281192497768.4165\n",
      "Epoch 573/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2955030413131.4497 - val_loss: 3253075720603.9043\n",
      "Epoch 574/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 2959762568087.0791 - val_loss: 3042375240397.2319\n",
      "Epoch 575/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2947085375398.2051 - val_loss: 3010860566715.2295\n",
      "Epoch 576/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2946140656671.4526 - val_loss: 3019378555499.2969\n",
      "Epoch 577/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2969415789106.2993 - val_loss: 3025925008664.8438\n",
      "Epoch 578/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2943603826305.7705 - val_loss: 3366379045025.3052\n",
      "Epoch 579/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2951064377304.1445 - val_loss: 3106980641364.2529\n",
      "Epoch 580/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2944012505482.7139 - val_loss: 3017871567807.1899\n",
      "Epoch 581/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 2964137403991.0342 - val_loss: 3008593043974.4810\n",
      "Epoch 582/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 2954561481093.4321 - val_loss: 3164796286350.9424\n",
      "Epoch 583/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2958586077247.3848 - val_loss: 3010730370003.3530\n",
      "Epoch 584/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2946747135758.4658 - val_loss: 3015920983798.9985\n",
      "Epoch 585/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 2949433708769.6885 - val_loss: 3160869078328.5288\n",
      "Epoch 586/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2943592273223.2480 - val_loss: 3001064009468.7593\n",
      "Epoch 587/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2951004188550.0322 - val_loss: 3018563590360.0337\n",
      "Epoch 588/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2942484868852.0552 - val_loss: 3128289746056.8213\n",
      "Epoch 589/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2960076484635.8506 - val_loss: 3098991116080.6074\n",
      "Epoch 590/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 2961130963362.7236 - val_loss: 3106257738174.4697\n",
      "Epoch 591/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2975156160488.4707 - val_loss: 3159146137441.5752\n",
      "Epoch 592/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2949544325455.1709 - val_loss: 3008551746892.6919\n",
      "Epoch 593/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2942140753867.6592 - val_loss: 3009133301005.3223\n",
      "Epoch 594/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2970791710557.6968 - val_loss: 3257817238589.9297\n",
      "Epoch 595/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 2942360850092.9873 - val_loss: 3062306665179.6343\n",
      "Epoch 596/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2923285067730.3823 - val_loss: 3153370844452.3657\n",
      "Epoch 597/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2951429245150.3267 - val_loss: 3033224148413.0293\n",
      "Epoch 598/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2938917700947.7329 - val_loss: 3078392700732.1294\n",
      "Epoch 599/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 2947884120083.6880 - val_loss: 3033554212043.0718\n",
      "Epoch 600/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2929973376801.6733 - val_loss: 3001370674442.4414\n",
      "Epoch 601/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 2933176459388.8486 - val_loss: 3052893310474.8018\n",
      "Epoch 602/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 2935208801094.4077 - val_loss: 3087483780543.9102\n",
      "Epoch 603/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 2960495366100.7832 - val_loss: 3005230211705.6992\n",
      "Epoch 604/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2926556790250.0312 - val_loss: 3036373857609.8115\n",
      "Epoch 605/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2937150102985.3784 - val_loss: 2990885052704.0449\n",
      "Epoch 606/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2932610616186.7476 - val_loss: 2994341372675.9604\n",
      "Epoch 607/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2927208416157.8018 - val_loss: 3050874937724.2192\n",
      "Epoch 608/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 2945695690311.1875 - val_loss: 2993635366160.2026\n",
      "Epoch 609/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 2932956963052.2524 - val_loss: 3013341304702.3799\n",
      "Epoch 610/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 2922020934683.6108 - val_loss: 3016718416998.2559\n",
      "Epoch 611/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2934305648387.4214 - val_loss: 3117406831997.6597\n",
      "Epoch 612/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2954945733428.1606 - val_loss: 3004125628695.4038\n",
      "Epoch 613/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2927060249326.5332 - val_loss: 3023050614452.7480\n",
      "Epoch 614/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2923678914658.4385 - val_loss: 2990259122884.5908\n",
      "Epoch 615/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2936998762736.5742 - val_loss: 3102649148670.9199\n",
      "Epoch 616/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2927668518614.2837 - val_loss: 2981001733167.5273\n",
      "Epoch 617/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2935674831662.3984 - val_loss: 2990028749188.8608\n",
      "Epoch 618/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2935421313644.4023 - val_loss: 3059435480848.9229\n",
      "Epoch 619/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2914976974786.0557 - val_loss: 3028007145454.7173\n",
      "Epoch 620/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 2916654067701.4355 - val_loss: 2984917841548.4219\n",
      "Epoch 621/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 2917972297189.7100 - val_loss: 2970790660628.8833\n",
      "Epoch 622/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2939690940312.7593 - val_loss: 3191799820535.7188\n",
      "Epoch 623/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 2926659485607.6455 - val_loss: 3162948257057.4854\n",
      "Epoch 624/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2924296543501.1450 - val_loss: 3022886222143.7300\n",
      "Epoch 625/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2929662561849.7427 - val_loss: 3030223656300.3770\n",
      "Epoch 626/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2928138150542.9756 - val_loss: 2990942746137.2041\n",
      "Epoch 627/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2918270659533.3403 - val_loss: 2997013833788.4893\n",
      "Epoch 628/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 2919482453701.9575 - val_loss: 2989050710203.2295\n",
      "Epoch 629/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 2895234330878.4995 - val_loss: 2981258214709.6484\n",
      "Epoch 630/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 2908175456600.2944 - val_loss: 3014520321492.0732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 631/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 2911765147499.1416 - val_loss: 2986302166864.2925\n",
      "Epoch 632/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 2912736052598.3062 - val_loss: 3258319832422.6162\n",
      "Epoch 633/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 2926276805491.5449 - val_loss: 2998651547642.2393\n",
      "Epoch 634/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 2903640031773.6514 - val_loss: 2973515109579.0718\n",
      "Epoch 635/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 2916062284628.3325 - val_loss: 2986349832828.5796\n",
      "Epoch 636/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2897541401094.1226 - val_loss: 2961023625737.3613\n",
      "Epoch 637/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 2903152451985.4365 - val_loss: 2985715529886.4248\n",
      "Epoch 638/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2898812975434.8491 - val_loss: 3181283360560.6074\n",
      "Epoch 639/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 2901719968279.4092 - val_loss: 3051710010893.6821\n",
      "Epoch 640/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 2905368372212.2354 - val_loss: 3120838686302.3350\n",
      "Epoch 641/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 2922345853535.9175 - val_loss: 3035407599987.5781\n",
      "Epoch 642/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 2896804253579.7944 - val_loss: 3267685532961.4854\n",
      "Epoch 643/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 2906785554729.7163 - val_loss: 3083228694530.8804\n",
      "Epoch 644/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 2892637612870.8877 - val_loss: 3013953435645.1196\n",
      "Epoch 645/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2879705399491.9165 - val_loss: 3155088191090.4980\n",
      "Epoch 646/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2917323874601.7163 - val_loss: 2982948515534.6724\n",
      "Epoch 647/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2914845937175.1689 - val_loss: 2962483259383.3589\n",
      "Epoch 648/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2896687893374.5898 - val_loss: 2963616541446.8413\n",
      "Epoch 649/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 2889915043001.5923 - val_loss: 2998670510128.9678\n",
      "Epoch 650/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2884208031794.4199 - val_loss: 2950056057232.3823\n",
      "Epoch 651/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 2904732911216.0039 - val_loss: 3148089468735.0098\n",
      "Epoch 652/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 2914443296775.6831 - val_loss: 3017629752318.5596\n",
      "Epoch 653/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2902954000249.5474 - val_loss: 2971228470235.9941\n",
      "Epoch 654/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2905084081438.9121 - val_loss: 2955609661198.0420\n",
      "Epoch 655/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2888389315842.5811 - val_loss: 2950572654200.2588\n",
      "Epoch 656/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 2880678176538.9502 - val_loss: 3059236022816.4053\n",
      "Epoch 657/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 2884554042943.5049 - val_loss: 3318374674956.2417\n",
      "Epoch 658/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 2896420153368.4893 - val_loss: 3016170803344.0225\n",
      "Epoch 659/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2888394154750.3794 - val_loss: 2953912725659.5444\n",
      "Epoch 660/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2875994457865.6636 - val_loss: 2930565640877.5469\n",
      "Epoch 661/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 2869085515066.2827 - val_loss: 3138098124854.7285\n",
      "Epoch 662/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 2865822066094.0078 - val_loss: 2939652131141.4907\n",
      "Epoch 663/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 2873736523945.9863 - val_loss: 2934041561551.7524\n",
      "Epoch 664/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2885428133930.2563 - val_loss: 2957677463024.8774\n",
      "Epoch 665/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2877796441929.5288 - val_loss: 2987309340334.9873\n",
      "Epoch 666/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2885507625210.6577 - val_loss: 2992952941174.8184\n",
      "Epoch 667/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2867351187049.7612 - val_loss: 3047761787476.2529\n",
      "Epoch 668/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 2898548389715.6123 - val_loss: 2932416871572.3433\n",
      "Epoch 669/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2871750020807.8779 - val_loss: 2922465764030.8296\n",
      "Epoch 670/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2852461378131.9131 - val_loss: 3004979227076.2305\n",
      "Epoch 671/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2857671493727.5571 - val_loss: 3008977883533.5020\n",
      "Epoch 672/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 2855150456569.8174 - val_loss: 3123870300180.1631\n",
      "Epoch 673/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 2855765666189.1152 - val_loss: 3065640513023.2798\n",
      "Epoch 674/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2867616143304.7788 - val_loss: 2904010614061.0068\n",
      "Epoch 675/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2850766393688.7744 - val_loss: 3153029968396.2417\n",
      "Epoch 676/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 2857557867426.1235 - val_loss: 2912243294680.3940\n",
      "Epoch 677/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2861433530937.9829 - val_loss: 2906649606279.3813\n",
      "Epoch 678/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 2847246100020.4604 - val_loss: 2968762058731.8369\n",
      "Epoch 679/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2851144226753.0957 - val_loss: 2941694649161.0913\n",
      "Epoch 680/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2855496085228.3726 - val_loss: 2905571356758.4136\n",
      "Epoch 681/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2851550035376.4092 - val_loss: 3078837414570.6665\n",
      "Epoch 682/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 2856868730402.2134 - val_loss: 2908841405536.4951\n",
      "Epoch 683/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2845812762056.8984 - val_loss: 2899538164216.0786\n",
      "Epoch 684/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2861993477559.6118 - val_loss: 2896991422351.6626\n",
      "Epoch 685/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 2842546734208.4502 - val_loss: 2888417359085.6372\n",
      "Epoch 686/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2849769694419.0425 - val_loss: 3530376369769.8564\n",
      "Epoch 687/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2841866232048.0938 - val_loss: 3457244235986.2729\n",
      "Epoch 688/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2838933542668.5449 - val_loss: 4250224868523.3872\n",
      "Epoch 689/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2878192660692.2427 - val_loss: 3157165668648.6865\n",
      "Epoch 690/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2817349520600.3242 - val_loss: 2939749785496.3037\n",
      "Epoch 691/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 2825784314255.0361 - val_loss: 3093806667646.3799\n",
      "Epoch 692/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2848993006769.4292 - val_loss: 2876499400597.4233\n",
      "Epoch 693/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2812379298357.1807 - val_loss: 2877745198478.9424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 694/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 2816337706838.9736 - val_loss: 2874279122399.5947\n",
      "Epoch 695/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2816794544972.6499 - val_loss: 2874852817353.9917\n",
      "Epoch 696/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 2801597718687.4219 - val_loss: 2862815946881.6201\n",
      "Epoch 697/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 2811899148737.9360 - val_loss: 2915652471132.5347\n",
      "Epoch 698/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2816294603419.9409 - val_loss: 2926333435132.0396\n",
      "Epoch 699/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2811267703031.7769 - val_loss: 2887333278980.6807\n",
      "Epoch 700/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2797607195660.2446 - val_loss: 3208638404409.2490\n",
      "Epoch 701/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 2805419630079.1597 - val_loss: 2940832717476.9058\n",
      "Epoch 702/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 2792337018264.3994 - val_loss: 2846754491292.6245\n",
      "Epoch 703/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 2783915058048.9902 - val_loss: 3082259887364.6807\n",
      "Epoch 704/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 2826523016778.0688 - val_loss: 2848061526160.0225\n",
      "Epoch 705/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 2771862451436.9722 - val_loss: 3044240485656.8438\n",
      "Epoch 706/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 2790713657431.8740 - val_loss: 2837286722719.8647\n",
      "Epoch 707/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2799877421890.0854 - val_loss: 2840998796056.1235\n",
      "Epoch 708/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2786786045430.5161 - val_loss: 2929018385138.6777\n",
      "Epoch 709/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 2773508429365.4209 - val_loss: 3009648392580.8608\n",
      "Epoch 710/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 2769862968206.4355 - val_loss: 2915661056625.0576\n",
      "Epoch 711/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2784410315122.2246 - val_loss: 2860101438387.6680\n",
      "Epoch 712/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 2751492711784.8608 - val_loss: 2907470302454.2783\n",
      "Epoch 713/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 2775199495785.2812 - val_loss: 2814447860308.2529\n",
      "Epoch 714/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 2765773579828.4604 - val_loss: 2893683465928.9116\n",
      "Epoch 715/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 2767677850637.2051 - val_loss: 2809206527732.1182\n",
      "Epoch 716/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 2731392109937.9844 - val_loss: 2851490151411.0381\n",
      "Epoch 717/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 2748721252028.8340 - val_loss: 2911204301868.6470\n",
      "Epoch 718/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 2744255665498.4551 - val_loss: 2807344794317.2319\n",
      "Epoch 719/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 2730031859534.8110 - val_loss: 2788171284986.9590\n",
      "Epoch 720/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2741919447274.8120 - val_loss: 2788772357951.0098\n",
      "Epoch 721/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 2760124482930.4648 - val_loss: 2784593030447.8877\n",
      "Epoch 722/800\n",
      "4265/4265 [==============================] - 1s 126us/step - loss: 2738686534167.8896 - val_loss: 2817957583916.6470\n",
      "Epoch 723/800\n",
      "4265/4265 [==============================] - 1s 132us/step - loss: 2713026238051.5190 - val_loss: 2883837352221.1646\n",
      "Epoch 724/800\n",
      "4265/4265 [==============================] - 1s 159us/step - loss: 2714754502305.4634 - val_loss: 2832591217826.7456\n",
      "Epoch 725/800\n",
      "4265/4265 [==============================] - 1s 130us/step - loss: 2710889675636.0254 - val_loss: 2840134127898.2842\n",
      "Epoch 726/800\n",
      "4265/4265 [==============================] - 1s 128us/step - loss: 2730181950927.1406 - val_loss: 2914994064399.8423\n",
      "Epoch 727/800\n",
      "4265/4265 [==============================] - 1s 119us/step - loss: 2694099684464.6040 - val_loss: 2791288096955.2295\n",
      "Epoch 728/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 2714995777737.6792 - val_loss: 2739252755373.9072\n",
      "Epoch 729/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 2694198662816.9829 - val_loss: 2792103865302.2334\n",
      "Epoch 730/800\n",
      "4265/4265 [==============================] - 1s 126us/step - loss: 2699065024682.9468 - val_loss: 2729610619747.0156\n",
      "Epoch 731/800\n",
      "4265/4265 [==============================] - 1s 121us/step - loss: 2672971567813.7173 - val_loss: 2853939510097.7329\n",
      "Epoch 732/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 2683022973214.6719 - val_loss: 2777670016090.7344\n",
      "Epoch 733/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 2656631997656.8047 - val_loss: 2857315697700.0059\n",
      "Epoch 734/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 2663326127892.2280 - val_loss: 2881494840626.7681\n",
      "Epoch 735/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 2676573662825.7612 - val_loss: 2709023227350.9536\n",
      "Epoch 736/800\n",
      "4265/4265 [==============================] - 1s 125us/step - loss: 2663004667312.4092 - val_loss: 3328045254866.2729\n",
      "Epoch 737/800\n",
      "4265/4265 [==============================] - 1s 136us/step - loss: 2681841566729.3638 - val_loss: 2788842819013.6709\n",
      "Epoch 738/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 2675395339928.3398 - val_loss: 3146875311191.8535\n",
      "Epoch 739/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 2654797057297.9473 - val_loss: 2876951593835.6567\n",
      "Epoch 740/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 2650785222363.0854 - val_loss: 2986022598952.6865\n",
      "Epoch 741/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2655043838460.9985 - val_loss: 2686146301704.2812\n",
      "Epoch 742/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2619123590113.0283 - val_loss: 2677598134283.5220\n",
      "Epoch 743/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 2632688472055.3564 - val_loss: 2718735473962.1265\n",
      "Epoch 744/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 2618166681567.3472 - val_loss: 2789465943597.3672\n",
      "Epoch 745/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2596148421989.0195 - val_loss: 2639106827288.4839\n",
      "Epoch 746/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 2585234462949.0498 - val_loss: 2721928605782.4136\n",
      "Epoch 747/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 2595958935455.0024 - val_loss: 2619931978111.1001\n",
      "Epoch 748/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 2583445373911.4238 - val_loss: 2762693068295.9214\n",
      "Epoch 749/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 2569101713836.3271 - val_loss: 2595687438183.3359\n",
      "Epoch 750/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 2559647759289.1724 - val_loss: 2784556767378.9028\n",
      "Epoch 751/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2578428980426.8794 - val_loss: 2728703325352.5063\n",
      "Epoch 752/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 2540379086638.6382 - val_loss: 2577754180969.4966\n",
      "Epoch 753/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 2550960091697.8193 - val_loss: 2627118389302.7285\n",
      "Epoch 754/800\n",
      "4265/4265 [==============================] - 0s 116us/step - loss: 2555659734159.3359 - val_loss: 2882055184118.9985\n",
      "Epoch 755/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 2528040427756.2524 - val_loss: 2561315319318.3237\n",
      "Epoch 756/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 2521833670636.3120 - val_loss: 2873640906469.7158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 757/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 2513934096171.2769 - val_loss: 2562911563724.1519\n",
      "Epoch 758/800\n",
      "4265/4265 [==============================] - 1s 126us/step - loss: 2482748412721.2793 - val_loss: 2572944139795.4429\n",
      "Epoch 759/800\n",
      "4265/4265 [==============================] - 1s 139us/step - loss: 2500425349093.5898 - val_loss: 2612664746191.3926\n",
      "Epoch 760/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 2472570220345.2021 - val_loss: 3286731777463.2686\n",
      "Epoch 761/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 2478364869579.8999 - val_loss: 2906860382406.7510\n",
      "Epoch 762/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2469344510090.2939 - val_loss: 2620660575098.0591\n",
      "Epoch 763/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2440447655075.5039 - val_loss: 3168862737634.1152\n",
      "Epoch 764/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2447788328944.1538 - val_loss: 2788511832164.8159\n",
      "Epoch 765/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2408262398667.4795 - val_loss: 2672071261263.2124\n",
      "Epoch 766/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2459024611457.1704 - val_loss: 2795994473081.6992\n",
      "Epoch 767/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 2421589271590.1748 - val_loss: 2628950947491.4653\n",
      "Epoch 768/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 2413422834287.2837 - val_loss: 2540897030264.9790\n",
      "Epoch 769/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 2424115824113.2344 - val_loss: 2516943711674.1489\n",
      "Epoch 770/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 2386613071703.9346 - val_loss: 2442944628969.3164\n",
      "Epoch 771/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2378885001923.7964 - val_loss: 2441555542845.5698\n",
      "Epoch 772/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 2341720042018.9336 - val_loss: 2472893084978.7681\n",
      "Epoch 773/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 2358369255285.7061 - val_loss: 2533736819831.5386\n",
      "Epoch 774/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 2350642460238.3906 - val_loss: 2440835790176.8550\n",
      "Epoch 775/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 2340578707670.6440 - val_loss: 2338475671459.8257\n",
      "Epoch 776/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 2310894234492.6685 - val_loss: 2549771259840.6299\n",
      "Epoch 777/800\n",
      "4265/4265 [==============================] - 0s 113us/step - loss: 2298657383919.3135 - val_loss: 2429704922551.2686\n",
      "Epoch 778/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 2352132247393.5381 - val_loss: 2652108350258.0479\n",
      "Epoch 779/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 2295814296434.5850 - val_loss: 2316257729926.3008\n",
      "Epoch 780/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2307634502679.2891 - val_loss: 2418100653094.8862\n",
      "Epoch 781/800\n",
      "4265/4265 [==============================] - ETA: 0s - loss: 2300721848395.155 - 0s 83us/step - loss: 2281643034116.4419 - val_loss: 2266877197506.4302\n",
      "Epoch 782/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 2273823477586.1724 - val_loss: 2597396483410.4531\n",
      "Epoch 783/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 2264954949903.7861 - val_loss: 2527166270065.0576\n",
      "Epoch 784/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 2273964800553.6562 - val_loss: 3165239297912.6187\n",
      "Epoch 785/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2243254436758.1187 - val_loss: 2253830566780.9395\n",
      "Epoch 786/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 2212687283428.3291 - val_loss: 2226512599163.8594\n",
      "Epoch 787/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2229167115960.5117 - val_loss: 2893995541540.0059\n",
      "Epoch 788/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 2239439569787.2285 - val_loss: 2292143417865.3613\n",
      "Epoch 789/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 2215788147649.3354 - val_loss: 2210446504068.5005\n",
      "Epoch 790/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 2208009968167.7358 - val_loss: 2269409430935.5835\n",
      "Epoch 791/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 2188087466585.6753 - val_loss: 2204582793152.6299\n",
      "Epoch 792/800\n",
      "4265/4265 [==============================] - 1s 119us/step - loss: 2223660134669.8652 - val_loss: 2199091660388.0957\n",
      "Epoch 793/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 2171392509959.2026 - val_loss: 2236826863526.7061\n",
      "Epoch 794/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 2251804967203.9541 - val_loss: 2175300071372.1519\n",
      "Epoch 795/800\n",
      "4265/4265 [==============================] - 0s 117us/step - loss: 2193390298273.1030 - val_loss: 2187319640709.2205\n",
      "Epoch 796/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 2189345067729.2419 - val_loss: 2901569014062.4473\n",
      "Epoch 797/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 2181837811643.8132 - val_loss: 2206521533671.8765\n",
      "Epoch 798/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 2184215910529.1704 - val_loss: 2268146127107.2407\n",
      "Epoch 799/800\n",
      "4265/4265 [==============================] - 0s 113us/step - loss: 2173773322250.0837 - val_loss: 2189147188850.4978\n",
      "Epoch 800/800\n",
      "4265/4265 [==============================] - 0s 116us/step - loss: 2190452848967.0081 - val_loss: 2540078735048.9116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff82d3e9a90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train1 = model1.fit(predictors,target, epochs=800, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=True)\n",
    "model_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4265 samples, validate on 2844 samples\n",
      "Epoch 1/800\n",
      "4265/4265 [==============================] - 1s 167us/step - loss: 111170890919691.1094 - val_loss: 32644138863954.4531\n",
      "Epoch 2/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 6417615432319.1299 - val_loss: 4442964687882.0820\n",
      "Epoch 3/800\n",
      "4265/4265 [==============================] - 1s 122us/step - loss: 4183312259915.6899 - val_loss: 4287860850895.3926\n",
      "Epoch 4/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 4074041946232.0469 - val_loss: 4207460369881.8340\n",
      "Epoch 5/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 3998024245100.1021 - val_loss: 4112852327814.3003\n",
      "Epoch 6/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3899009462080.8853 - val_loss: 4020277310171.6348\n",
      "Epoch 7/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3840092232554.4214 - val_loss: 3953686133378.3403\n",
      "Epoch 8/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3802065415612.8936 - val_loss: 3958730251446.9087\n",
      "Epoch 9/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3752746541011.8228 - val_loss: 3882884803749.6260\n",
      "Epoch 10/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 3736017255752.6885 - val_loss: 3848106207200.3149\n",
      "Epoch 11/800\n",
      "4265/4265 [==============================] - 0s 109us/step - loss: 3711545196770.6484 - val_loss: 3839025266204.0845\n",
      "Epoch 12/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3686438349546.6914 - val_loss: 3859148605465.9238\n",
      "Epoch 13/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3682905054396.4736 - val_loss: 3910091661392.6528\n",
      "Epoch 14/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3690239959130.2754 - val_loss: 3830990836501.2432\n",
      "Epoch 15/800\n",
      "4265/4265 [==============================] - ETA: 0s - loss: 3720240199468.137 - 0s 83us/step - loss: 3703121878846.0044 - val_loss: 3790817921096.0112\n",
      "Epoch 16/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3665312171040.4126 - val_loss: 3897613817518.9873\n",
      "Epoch 17/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3664841820781.8428 - val_loss: 3801082589362.5879\n",
      "Epoch 18/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3671142315863.4546 - val_loss: 3785860746348.0171\n",
      "Epoch 19/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3651021128613.4849 - val_loss: 3849734949535.1450\n",
      "Epoch 20/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3658235456634.2080 - val_loss: 3796578580477.1196\n",
      "Epoch 21/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3700293343610.8682 - val_loss: 3765113161846.0986\n",
      "Epoch 22/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3659378066483.6201 - val_loss: 3752385478149.0410\n",
      "Epoch 23/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3634924678761.7612 - val_loss: 3749021682104.7090\n",
      "Epoch 24/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3638875643552.5024 - val_loss: 3745196545065.7666\n",
      "Epoch 25/800\n",
      "4265/4265 [==============================] - 0s 114us/step - loss: 3629403241535.6245 - val_loss: 3736840064269.3223\n",
      "Epoch 26/800\n",
      "4265/4265 [==============================] - 0s 109us/step - loss: 3619604027452.0234 - val_loss: 3766353811971.6006\n",
      "Epoch 27/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3624918139383.2368 - val_loss: 3768405648085.8735\n",
      "Epoch 28/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3639564122143.2119 - val_loss: 3758191389262.4922\n",
      "Epoch 29/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3603376473270.2310 - val_loss: 3770980196755.2632\n",
      "Epoch 30/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3624809364036.5464 - val_loss: 3720755392160.5850\n",
      "Epoch 31/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3601661517203.5977 - val_loss: 3706684776090.8242\n",
      "Epoch 32/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3585692640758.9961 - val_loss: 3733292083490.9253\n",
      "Epoch 33/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3629987624618.5869 - val_loss: 3692087510512.8774\n",
      "Epoch 34/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3585906511786.5264 - val_loss: 3736494314399.5049\n",
      "Epoch 35/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3581105726363.8809 - val_loss: 3685994544345.4741\n",
      "Epoch 36/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3574399088356.2090 - val_loss: 3689801040033.3052\n",
      "Epoch 37/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3566817995494.8501 - val_loss: 3671564988986.3291\n",
      "Epoch 38/800\n",
      "4265/4265 [==============================] - ETA: 0s - loss: 3531128483907.147 - 0s 71us/step - loss: 3574765668989.2085 - val_loss: 3743633507963.1392\n",
      "Epoch 39/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3568864856044.3120 - val_loss: 3663254058935.9888\n",
      "Epoch 40/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3568237083304.4258 - val_loss: 3755816751017.5864\n",
      "Epoch 41/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3546499960350.8521 - val_loss: 3686662309913.9238\n",
      "Epoch 42/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3541320060431.4863 - val_loss: 3716613492257.8452\n",
      "Epoch 43/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3547655113345.0508 - val_loss: 3639758526173.0747\n",
      "Epoch 44/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3529640069357.6929 - val_loss: 3631807186900.7935\n",
      "Epoch 45/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3528342201482.0537 - val_loss: 3635644143647.6851\n",
      "Epoch 46/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3530537856072.2681 - val_loss: 3643303245821.1196\n",
      "Epoch 47/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3511674393139.7402 - val_loss: 3686667269265.4629\n",
      "Epoch 48/800\n",
      "4265/4265 [==============================] - 0s 109us/step - loss: 3497393852207.5986 - val_loss: 3620574000158.2446\n",
      "Epoch 49/800\n",
      "4265/4265 [==============================] - 0s 117us/step - loss: 3505383351407.1631 - val_loss: 3606099967700.4331\n",
      "Epoch 50/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3512754873017.2324 - val_loss: 3633973998046.1548\n",
      "Epoch 51/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3509399467248.8145 - val_loss: 3674419085288.9565\n",
      "Epoch 52/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3497613175707.4004 - val_loss: 3590974992239.9775\n",
      "Epoch 53/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3472810599454.4917 - val_loss: 3622662176583.6514\n",
      "Epoch 54/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3473993447147.8926 - val_loss: 3576220943902.9648\n",
      "Epoch 55/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3479209081197.4224 - val_loss: 3602664648006.9312\n",
      "Epoch 56/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3463979432347.5210 - val_loss: 3587427076352.3599\n",
      "Epoch 57/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3462649442197.3984 - val_loss: 3589545179962.6890\n",
      "Epoch 58/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3468109452784.2739 - val_loss: 3558995583701.8735\n",
      "Epoch 59/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3474798112692.1304 - val_loss: 3555519883877.5356\n",
      "Epoch 60/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3456819778360.9619 - val_loss: 3557999690165.8286\n",
      "Epoch 61/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3474238390014.6196 - val_loss: 3543953890394.7344\n",
      "Epoch 62/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3443116113881.5850 - val_loss: 3525933834574.1323\n",
      "Epoch 63/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 67us/step - loss: 3427946700114.2920 - val_loss: 3532324210299.1392\n",
      "Epoch 64/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3416581191426.9409 - val_loss: 3564044698360.4390\n",
      "Epoch 65/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3409549328967.9082 - val_loss: 3512852249840.5176\n",
      "Epoch 66/800\n",
      "4265/4265 [==============================] - 0s 115us/step - loss: 3411926474607.9438 - val_loss: 3685928842062.8525\n",
      "Epoch 67/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3405318451792.5513 - val_loss: 3497995794636.5117\n",
      "Epoch 68/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3398579986168.8574 - val_loss: 3506605477041.1475\n",
      "Epoch 69/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3411093625049.5249 - val_loss: 3490288372797.9297\n",
      "Epoch 70/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3396709472592.6118 - val_loss: 3484548386660.4556\n",
      "Epoch 71/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3409579508779.9375 - val_loss: 3521896722587.5444\n",
      "Epoch 72/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3383639278582.1562 - val_loss: 3462752723900.3096\n",
      "Epoch 73/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3365747776147.2979 - val_loss: 3475044490883.7808\n",
      "Epoch 74/800\n",
      "4265/4265 [==============================] - 0s 114us/step - loss: 3373599505183.5122 - val_loss: 3484851772437.6035\n",
      "Epoch 75/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3355534631893.5034 - val_loss: 3442910631230.2896\n",
      "Epoch 76/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3380170881681.3765 - val_loss: 3437220376501.1084\n",
      "Epoch 77/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3344013574332.2334 - val_loss: 3595411434707.7129\n",
      "Epoch 78/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3362978294917.7324 - val_loss: 3437720927380.3433\n",
      "Epoch 79/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3340186974220.0049 - val_loss: 3525483711204.2759\n",
      "Epoch 80/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3333771421125.0571 - val_loss: 3425313725968.5625\n",
      "Epoch 81/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3329237506069.6084 - val_loss: 3410503095821.6821\n",
      "Epoch 82/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3317085980510.1768 - val_loss: 3440447668523.5669\n",
      "Epoch 83/800\n",
      "4265/4265 [==============================] - 1s 143us/step - loss: 3322324048615.8105 - val_loss: 3444864030982.1211\n",
      "Epoch 84/800\n",
      "4265/4265 [==============================] - 0s 113us/step - loss: 3376124794237.0288 - val_loss: 3423693141805.7271\n",
      "Epoch 85/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3301028465680.5669 - val_loss: 3470513320414.1548\n",
      "Epoch 86/800\n",
      "4265/4265 [==============================] - 0s 117us/step - loss: 3290611593036.4102 - val_loss: 3373031444554.8916\n",
      "Epoch 87/800\n",
      "4265/4265 [==============================] - 0s 109us/step - loss: 3291588874227.5151 - val_loss: 3384133874533.8960\n",
      "Epoch 88/800\n",
      "4265/4265 [==============================] - 0s 116us/step - loss: 3283654028825.0898 - val_loss: 3369289353702.7959\n",
      "Epoch 89/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 3278641103017.0264 - val_loss: 3381551788579.2856\n",
      "Epoch 90/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3307648230426.6504 - val_loss: 3355958046760.3262\n",
      "Epoch 91/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3272637178541.7080 - val_loss: 3371182221787.2744\n",
      "Epoch 92/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3266662632510.6646 - val_loss: 3339266713337.8789\n",
      "Epoch 93/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3253134198141.9893 - val_loss: 3343037048270.3120\n",
      "Epoch 94/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3248190980633.8101 - val_loss: 3323451172786.2280\n",
      "Epoch 95/800\n",
      "4265/4265 [==============================] - 0s 117us/step - loss: 3245188872019.6123 - val_loss: 3344659008412.6245\n",
      "Epoch 96/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3252359520549.8745 - val_loss: 3319360277404.6245\n",
      "Epoch 97/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3231973078452.7305 - val_loss: 3326612257779.0381\n",
      "Epoch 98/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3240123610437.3271 - val_loss: 3299432722103.6289\n",
      "Epoch 99/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3222312110632.6958 - val_loss: 3292529431593.7666\n",
      "Epoch 100/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3215423764914.5698 - val_loss: 3320564995735.9438\n",
      "Epoch 101/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3206872971587.1660 - val_loss: 3288576633376.4053\n",
      "Epoch 102/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3205071483968.1050 - val_loss: 3300206757015.2236\n",
      "Epoch 103/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3201339840710.3174 - val_loss: 3313278197771.5220\n",
      "Epoch 104/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3196668094365.5615 - val_loss: 3261129917291.6567\n",
      "Epoch 105/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3189482775390.4170 - val_loss: 3293748320817.6880\n",
      "Epoch 106/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3188315157249.2607 - val_loss: 3364837358832.5176\n",
      "Epoch 107/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3195614435138.3257 - val_loss: 3244259330834.3628\n",
      "Epoch 108/800\n",
      "4265/4265 [==============================] - 1s 123us/step - loss: 3176113261872.6792 - val_loss: 3242728638466.8804\n",
      "Epoch 109/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3168289341121.1553 - val_loss: 3326892371363.1055\n",
      "Epoch 110/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3178695341919.1372 - val_loss: 3244618656518.8413\n",
      "Epoch 111/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3174027435538.3672 - val_loss: 3231487717185.8901\n",
      "Epoch 112/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3156954234130.9072 - val_loss: 3414488987230.3350\n",
      "Epoch 113/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3182187187646.8145 - val_loss: 3217335668350.0195\n",
      "Epoch 114/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3147657308111.5010 - val_loss: 3273415955082.9819\n",
      "Epoch 115/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 3177752907194.9727 - val_loss: 3231543789086.9648\n",
      "Epoch 116/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3147667905981.8540 - val_loss: 3248883279632.9229\n",
      "Epoch 117/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3155451150835.3950 - val_loss: 3198388984369.6880\n",
      "Epoch 118/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3128520404339.9053 - val_loss: 3194464214175.8647\n",
      "Epoch 119/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3110671427831.2969 - val_loss: 3211023272538.0142\n",
      "Epoch 120/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3120269012927.6548 - val_loss: 3191557124597.1982\n",
      "Epoch 121/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3143311820811.0444 - val_loss: 3188664802832.5625\n",
      "Epoch 122/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3104539942587.3931 - val_loss: 3185673953268.4780\n",
      "Epoch 123/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3120805321536.1650 - val_loss: 3187284556049.6426\n",
      "Epoch 124/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3114687915076.9067 - val_loss: 3179726263545.1587\n",
      "Epoch 125/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3089242766349.6855 - val_loss: 3177660437568.8101\n",
      "Epoch 126/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 112us/step - loss: 3111618479893.1880 - val_loss: 3175245829553.5078\n",
      "Epoch 127/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3112786577207.7617 - val_loss: 3177350114008.7539\n",
      "Epoch 128/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3115489201698.6934 - val_loss: 3257378028300.6021\n",
      "Epoch 129/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3118651045930.7363 - val_loss: 3197662223128.1235\n",
      "Epoch 130/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3125553292718.0078 - val_loss: 3186304777179.9941\n",
      "Epoch 131/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3093368648491.5171 - val_loss: 3202813870379.5669\n",
      "Epoch 132/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3115334431020.5977 - val_loss: 3195490333173.1982\n",
      "Epoch 133/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3100679223065.9902 - val_loss: 3175871066958.8525\n",
      "Epoch 134/800\n",
      "4265/4265 [==============================] - 0s 109us/step - loss: 3109613796438.6738 - val_loss: 3188841684404.3882\n",
      "Epoch 135/800\n",
      "4265/4265 [==============================] - 1s 121us/step - loss: 3112125081993.2739 - val_loss: 3170421794461.7046\n",
      "Epoch 136/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3094251217885.1860 - val_loss: 3177724883698.6777\n",
      "Epoch 137/800\n",
      "4265/4265 [==============================] - 0s 109us/step - loss: 3102068109182.3496 - val_loss: 3195705992884.7480\n",
      "Epoch 138/800\n",
      "4265/4265 [==============================] - 1s 132us/step - loss: 3082849598293.2935 - val_loss: 3187349531997.9746\n",
      "Epoch 139/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3088032659813.7397 - val_loss: 3159852317613.9072\n",
      "Epoch 140/800\n",
      "4265/4265 [==============================] - 1s 144us/step - loss: 3075902994774.3740 - val_loss: 3170411096700.5796\n",
      "Epoch 141/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3079691559359.5347 - val_loss: 3162877856092.5347\n",
      "Epoch 142/800\n",
      "4265/4265 [==============================] - 0s 114us/step - loss: 3085231006708.2354 - val_loss: 3160357614737.4629\n",
      "Epoch 143/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3074899373427.9053 - val_loss: 3160092808740.7256\n",
      "Epoch 144/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3076783440678.7148 - val_loss: 3177629317647.1226\n",
      "Epoch 145/800\n",
      "4265/4265 [==============================] - 1s 126us/step - loss: 3079681036659.6650 - val_loss: 3186754187488.6753\n",
      "Epoch 146/800\n",
      "4265/4265 [==============================] - 1s 128us/step - loss: 3079670673213.0439 - val_loss: 3308652086930.1826\n",
      "Epoch 147/800\n",
      "4265/4265 [==============================] - 1s 124us/step - loss: 3069735635408.3418 - val_loss: 3167062850477.9072\n",
      "Epoch 148/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3066760537552.5815 - val_loss: 3174856138671.3472\n",
      "Epoch 149/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3073061412020.7910 - val_loss: 3156113745611.7920\n",
      "Epoch 150/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3093165667964.4888 - val_loss: 3175681959374.3120\n",
      "Epoch 151/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3095246523274.1143 - val_loss: 3196669446561.6650\n",
      "Epoch 152/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3092814691629.7979 - val_loss: 3302410467048.5962\n",
      "Epoch 153/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3080287245028.4492 - val_loss: 3192523987989.6035\n",
      "Epoch 154/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3079881121002.5718 - val_loss: 3156215186491.0493\n",
      "Epoch 155/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3076221112849.1665 - val_loss: 3213097041366.9536\n",
      "Epoch 156/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3067996716921.5474 - val_loss: 3225532055114.1714\n",
      "Epoch 157/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3067949473163.9150 - val_loss: 3154201392227.3755\n",
      "Epoch 158/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3063463522009.1646 - val_loss: 3153781630368.2251\n",
      "Epoch 159/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3074283160439.3867 - val_loss: 3157628371243.5669\n",
      "Epoch 160/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3076919109725.6362 - val_loss: 3152082344013.7720\n",
      "Epoch 161/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3091043535085.6929 - val_loss: 3172482946827.1616\n",
      "Epoch 162/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3073169145521.7896 - val_loss: 3158623331974.6611\n",
      "Epoch 163/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3068475762554.9878 - val_loss: 3165578630600.5513\n",
      "Epoch 164/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3065418711324.2710 - val_loss: 3151224579349.9634\n",
      "Epoch 165/800\n",
      "4265/4265 [==============================] - 0s 114us/step - loss: 3082169787910.3628 - val_loss: 3160181655278.3574\n",
      "Epoch 166/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 3071739565559.9570 - val_loss: 3156077806443.6567\n",
      "Epoch 167/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3068653524798.4844 - val_loss: 3155413824450.0703\n",
      "Epoch 168/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3068084710456.9023 - val_loss: 3163838325162.3066\n",
      "Epoch 169/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3078355619877.4551 - val_loss: 3160465452520.2363\n",
      "Epoch 170/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3081907839980.5522 - val_loss: 3154976323442.8579\n",
      "Epoch 171/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3071811687920.2739 - val_loss: 3157594868060.5347\n",
      "Epoch 172/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3077137445529.5400 - val_loss: 3154753846881.2153\n",
      "Epoch 173/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3064363899431.7358 - val_loss: 3172237526950.7061\n",
      "Epoch 174/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3073999840090.5757 - val_loss: 3160005707617.5752\n",
      "Epoch 175/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3073043539516.1436 - val_loss: 3158112485214.6948\n",
      "Epoch 176/800\n",
      "4265/4265 [==============================] - 0s 112us/step - loss: 3056554201513.4463 - val_loss: 3157560350959.0771\n",
      "Epoch 177/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3062326490510.3154 - val_loss: 3208318167307.8818\n",
      "Epoch 178/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3094585609509.1543 - val_loss: 3154411226516.7031\n",
      "Epoch 179/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3070589376091.8359 - val_loss: 3148246491884.9170\n",
      "Epoch 180/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3083457622032.3262 - val_loss: 3176471616740.9956\n",
      "Epoch 181/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3055661681711.2983 - val_loss: 3165379941302.5483\n",
      "Epoch 182/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3096800663062.6890 - val_loss: 3186118931463.2012\n",
      "Epoch 183/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3067168124544.8105 - val_loss: 3152008084997.0410\n",
      "Epoch 184/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3062475156091.2881 - val_loss: 3151349101436.9395\n",
      "Epoch 185/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3088129352611.5640 - val_loss: 3153289627743.0547\n",
      "Epoch 186/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3059903449387.1567 - val_loss: 3158917475977.5415\n",
      "Epoch 187/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3072658132426.3394 - val_loss: 3234758226098.5879\n",
      "Epoch 188/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3080787149118.8447 - val_loss: 3223996543868.9395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3063023297028.6816 - val_loss: 3171022062927.5723\n",
      "Epoch 190/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3059894485353.1011 - val_loss: 3149759375420.4893\n",
      "Epoch 191/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3069268481554.8477 - val_loss: 3155067900186.2842\n",
      "Epoch 192/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3061825303450.9204 - val_loss: 3163333507714.3403\n",
      "Epoch 193/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3089014611977.6035 - val_loss: 3158802868537.9692\n",
      "Epoch 194/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3064165429195.1792 - val_loss: 3146204377220.5005\n",
      "Epoch 195/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3060473623220.4307 - val_loss: 3149957616013.5020\n",
      "Epoch 196/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3053677594784.8628 - val_loss: 3174526567990.0083\n",
      "Epoch 197/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3067388959198.7471 - val_loss: 3148172636592.0674\n",
      "Epoch 198/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3070865250659.8188 - val_loss: 3154092342535.5610\n",
      "Epoch 199/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3080121207474.9897 - val_loss: 3167098346471.5161\n",
      "Epoch 200/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3075355906761.5586 - val_loss: 3156817256782.1323\n",
      "Epoch 201/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3093577988207.8833 - val_loss: 3148640543722.3965\n",
      "Epoch 202/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3077082982240.0972 - val_loss: 3149543391992.4390\n",
      "Epoch 203/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 3083207734570.4365 - val_loss: 3159712875440.7876\n",
      "Epoch 204/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3060383546977.1182 - val_loss: 3231794090519.7637\n",
      "Epoch 205/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3068640833832.7559 - val_loss: 3145207880863.8647\n",
      "Epoch 206/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3068926081508.5093 - val_loss: 3142700839251.8931\n",
      "Epoch 207/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3066509808863.5273 - val_loss: 3165139431372.1519\n",
      "Epoch 208/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3061278479794.8101 - val_loss: 3159472264118.5483\n",
      "Epoch 209/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3064767404076.6572 - val_loss: 3168306242607.5273\n",
      "Epoch 210/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3073360698352.8740 - val_loss: 3151369264771.7808\n",
      "Epoch 211/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 3063150248742.7148 - val_loss: 3150608905223.2012\n",
      "Epoch 212/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3073383756791.1167 - val_loss: 3145036193872.6528\n",
      "Epoch 213/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3066306156596.3408 - val_loss: 3146935704781.9521\n",
      "Epoch 214/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3074703503795.0503 - val_loss: 3158495778455.9438\n",
      "Epoch 215/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3083057714998.8018 - val_loss: 3150589398170.1040\n",
      "Epoch 216/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3069154111999.8799 - val_loss: 3207689252512.5850\n",
      "Epoch 217/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3093815436091.8433 - val_loss: 3143144191858.8579\n",
      "Epoch 218/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3074066999232.1353 - val_loss: 3178142520753.5078\n",
      "Epoch 219/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3063009606857.9189 - val_loss: 3172568920841.7217\n",
      "Epoch 220/800\n",
      "4265/4265 [==============================] - 1s 128us/step - loss: 3073698790847.7749 - val_loss: 3159734258796.0171\n",
      "Epoch 221/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3060010316860.2637 - val_loss: 3210071853519.7524\n",
      "Epoch 222/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3067117341873.9097 - val_loss: 3142763434519.7637\n",
      "Epoch 223/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3066983386289.9097 - val_loss: 3190252437596.1743\n",
      "Epoch 224/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3086223609032.9585 - val_loss: 3140080463681.8901\n",
      "Epoch 225/800\n",
      "4265/4265 [==============================] - 0s 111us/step - loss: 3067052959768.4893 - val_loss: 3140536959252.5234\n",
      "Epoch 226/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3060752240988.6162 - val_loss: 3245880606673.9126\n",
      "Epoch 227/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3067277640194.7607 - val_loss: 3179668479781.0859\n",
      "Epoch 228/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3052437218253.8203 - val_loss: 3151021390466.3403\n",
      "Epoch 229/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3066302071759.7412 - val_loss: 3240222542195.5781\n",
      "Epoch 230/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3070390413098.3164 - val_loss: 3141970751251.8032\n",
      "Epoch 231/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3084912868196.6592 - val_loss: 3193425893499.8594\n",
      "Epoch 232/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3063890514080.3828 - val_loss: 3206608054148.1406\n",
      "Epoch 233/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3082157851230.9570 - val_loss: 3214454613246.9199\n",
      "Epoch 234/800\n",
      "4265/4265 [==============================] - 0s 111us/step - loss: 3066038577149.5991 - val_loss: 3140610273665.9805\n",
      "Epoch 235/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3067473030961.5195 - val_loss: 3163942760603.5444\n",
      "Epoch 236/800\n",
      "4265/4265 [==============================] - 0s 114us/step - loss: 3056891995354.7251 - val_loss: 3169707359887.3022\n",
      "Epoch 237/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3058612270147.9468 - val_loss: 3253845774687.4150\n",
      "Epoch 238/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3068010445891.4663 - val_loss: 3137301425732.4106\n",
      "Epoch 239/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3072691107959.5669 - val_loss: 3143529749272.1235\n",
      "Epoch 240/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3067594093916.3765 - val_loss: 3139332459558.8862\n",
      "Epoch 241/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3073750522092.7324 - val_loss: 3209510665156.9507\n",
      "Epoch 242/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3074264102386.1948 - val_loss: 3154750167279.0771\n",
      "Epoch 243/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3063826666496.7202 - val_loss: 3140720866725.9858\n",
      "Epoch 244/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3060114640338.0220 - val_loss: 3155115305481.3613\n",
      "Epoch 245/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3060937904983.6943 - val_loss: 3152468779296.0449\n",
      "Epoch 246/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3057596716117.2334 - val_loss: 3166317565131.0718\n",
      "Epoch 247/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3078556150817.8530 - val_loss: 3146287985671.2012\n",
      "Epoch 248/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3073691010333.9517 - val_loss: 3175569896685.6372\n",
      "Epoch 249/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3084131747609.0298 - val_loss: 3161575091849.5415\n",
      "Epoch 250/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3058095467173.5449 - val_loss: 3177089588591.2573\n",
      "Epoch 251/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3052836808378.9131 - val_loss: 3141223867600.8325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 252/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 3064357355727.4409 - val_loss: 3142064941692.5796\n",
      "Epoch 253/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3064076668957.7715 - val_loss: 3143662902570.1265\n",
      "Epoch 254/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3061539735240.3584 - val_loss: 3145149669410.5654\n",
      "Epoch 255/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3059088453955.6460 - val_loss: 3149573089110.0532\n",
      "Epoch 256/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3059581922549.1357 - val_loss: 3145705533411.1953\n",
      "Epoch 257/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3076627006292.8135 - val_loss: 3233205370580.4331\n",
      "Epoch 258/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3055994280368.6489 - val_loss: 3225257397148.6245\n",
      "Epoch 259/800\n",
      "4265/4265 [==============================] - 1s 119us/step - loss: 3067305098841.4346 - val_loss: 3154224636030.7397\n",
      "Epoch 260/800\n",
      "4265/4265 [==============================] - 1s 120us/step - loss: 3060782724586.5112 - val_loss: 3176149144226.0254\n",
      "Epoch 261/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 3056534275127.4619 - val_loss: 3164552227706.0591\n",
      "Epoch 262/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3058827535363.6011 - val_loss: 3142872779538.3628\n",
      "Epoch 263/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3060683155349.8784 - val_loss: 3246524734301.2544\n",
      "Epoch 264/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3087732713834.5415 - val_loss: 3183536075299.2856\n",
      "Epoch 265/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3065543272872.0059 - val_loss: 3278367421654.5938\n",
      "Epoch 266/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3062880039343.2080 - val_loss: 3165865893231.2573\n",
      "Epoch 267/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3055124048584.1182 - val_loss: 3272768014384.9678\n",
      "Epoch 268/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3060523766542.7056 - val_loss: 3283772529339.9492\n",
      "Epoch 269/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3060459262093.1748 - val_loss: 3147431987617.6650\n",
      "Epoch 270/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3056133292412.3086 - val_loss: 3162452630134.8184\n",
      "Epoch 271/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3043885056799.0322 - val_loss: 3135527636652.1069\n",
      "Epoch 272/800\n",
      "4265/4265 [==============================] - 0s 112us/step - loss: 3059147342745.9604 - val_loss: 3147797637572.2305\n",
      "Epoch 273/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3058947573805.6177 - val_loss: 3132776560360.5962\n",
      "Epoch 274/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3040967146256.1465 - val_loss: 3157600879675.0493\n",
      "Epoch 275/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3058127332082.8550 - val_loss: 3144271874880.4502\n",
      "Epoch 276/800\n",
      "4265/4265 [==============================] - 1s 118us/step - loss: 3064334366098.1572 - val_loss: 3202639451707.7695\n",
      "Epoch 277/800\n",
      "4265/4265 [==============================] - 0s 115us/step - loss: 3050051299855.7261 - val_loss: 3148417806122.8467\n",
      "Epoch 278/800\n",
      "4265/4265 [==============================] - 1s 153us/step - loss: 3057242799866.7778 - val_loss: 3141282513379.9155\n",
      "Epoch 279/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3050495603142.2573 - val_loss: 3144511105798.8413\n",
      "Epoch 280/800\n",
      "4265/4265 [==============================] - 0s 112us/step - loss: 3058952556723.5898 - val_loss: 3143512799505.6426\n",
      "Epoch 281/800\n",
      "4265/4265 [==============================] - 0s 114us/step - loss: 3077437285191.3677 - val_loss: 3134328629815.4487\n",
      "Epoch 282/800\n",
      "4265/4265 [==============================] - 1s 124us/step - loss: 3044686064189.8242 - val_loss: 3239169244285.2998\n",
      "Epoch 283/800\n",
      "4265/4265 [==============================] - 1s 122us/step - loss: 3069975111512.4146 - val_loss: 3207041116036.1406\n",
      "Epoch 284/800\n",
      "4265/4265 [==============================] - 1s 120us/step - loss: 3050210305158.2124 - val_loss: 3219938123004.0396\n",
      "Epoch 285/800\n",
      "4265/4265 [==============================] - 1s 120us/step - loss: 3054112340172.0796 - val_loss: 3134105727408.0674\n",
      "Epoch 286/800\n",
      "4265/4265 [==============================] - 1s 121us/step - loss: 3063429607182.9458 - val_loss: 3145543908177.7329\n",
      "Epoch 287/800\n",
      "4265/4265 [==============================] - 1s 126us/step - loss: 3074186758166.5688 - val_loss: 3135516158726.8413\n",
      "Epoch 288/800\n",
      "4265/4265 [==============================] - 1s 124us/step - loss: 3049353482423.4316 - val_loss: 3145532247378.4531\n",
      "Epoch 289/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3045597404578.9634 - val_loss: 3136782854388.8384\n",
      "Epoch 290/800\n",
      "4265/4265 [==============================] - 0s 114us/step - loss: 3063231871410.5698 - val_loss: 3135253006338.8804\n",
      "Epoch 291/800\n",
      "4265/4265 [==============================] - 0s 116us/step - loss: 3062219141743.2837 - val_loss: 3136019260256.1353\n",
      "Epoch 292/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 3051555227236.4790 - val_loss: 3138473252918.7285\n",
      "Epoch 293/800\n",
      "4265/4265 [==============================] - 0s 111us/step - loss: 3067941343257.9302 - val_loss: 3159377356560.9229\n",
      "Epoch 294/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3039504905118.7617 - val_loss: 3217599138924.0171\n",
      "Epoch 295/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3072532789455.9214 - val_loss: 3135208400196.0508\n",
      "Epoch 296/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3055911424609.8379 - val_loss: 3175699342729.1816\n",
      "Epoch 297/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3058347618354.8999 - val_loss: 3148954441437.0747\n",
      "Epoch 298/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3050786987907.1514 - val_loss: 3150791994925.3672\n",
      "Epoch 299/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3060148402149.5898 - val_loss: 3137757617127.5161\n",
      "Epoch 300/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3080012980018.4795 - val_loss: 3182571336342.5034\n",
      "Epoch 301/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3053462515344.1763 - val_loss: 3249719086510.6274\n",
      "Epoch 302/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3046256270977.7705 - val_loss: 3134017464518.7510\n",
      "Epoch 303/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3043417937027.3315 - val_loss: 3133453065537.1704\n",
      "Epoch 304/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3046265316943.3511 - val_loss: 3157037142505.6763\n",
      "Epoch 305/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3050715197513.9492 - val_loss: 3136031623055.6626\n",
      "Epoch 306/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3051105595634.9746 - val_loss: 3187550852690.8130\n",
      "Epoch 307/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3064195293205.1284 - val_loss: 3135699919458.6553\n",
      "Epoch 308/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3062555580026.5679 - val_loss: 3218104299998.1548\n",
      "Epoch 309/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3056570336676.4043 - val_loss: 3153201464402.0928\n",
      "Epoch 310/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3063205325289.3110 - val_loss: 3272009406150.0308\n",
      "Epoch 311/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3077448323697.2041 - val_loss: 3135470119456.4053\n",
      "Epoch 312/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3065153166459.1680 - val_loss: 3181089452901.8960\n",
      "Epoch 313/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3062074190032.8818 - val_loss: 3131934684720.2476\n",
      "Epoch 314/800\n",
      "4265/4265 [==============================] - 1s 130us/step - loss: 3058029087441.7222 - val_loss: 3147851887738.4189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 315/800\n",
      "4265/4265 [==============================] - 0s 112us/step - loss: 3059198566175.2725 - val_loss: 3139037717528.4839\n",
      "Epoch 316/800\n",
      "4265/4265 [==============================] - 0s 112us/step - loss: 3057064155307.4268 - val_loss: 3145789046737.9126\n",
      "Epoch 317/800\n",
      "4265/4265 [==============================] - 0s 117us/step - loss: 3065635381238.3965 - val_loss: 3143983425043.4429\n",
      "Epoch 318/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3054788888813.6929 - val_loss: 3134175171602.7231\n",
      "Epoch 319/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3044063761347.2563 - val_loss: 3169089253831.1113\n",
      "Epoch 320/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3055800030742.6890 - val_loss: 3140093828232.8213\n",
      "Epoch 321/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3044253012812.1699 - val_loss: 3193720931963.1392\n",
      "Epoch 322/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 3056286405713.3916 - val_loss: 3129617370104.7988\n",
      "Epoch 323/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3041720921260.1475 - val_loss: 3151961035863.8535\n",
      "Epoch 324/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3045898416328.7183 - val_loss: 3152109911165.2998\n",
      "Epoch 325/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3078521180623.8608 - val_loss: 3155179376645.7607\n",
      "Epoch 326/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3047047260595.5303 - val_loss: 3262197467576.7090\n",
      "Epoch 327/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3057358278601.2588 - val_loss: 3244896162304.7202\n",
      "Epoch 328/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3044770868603.5884 - val_loss: 3138792241978.6890\n",
      "Epoch 329/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3060030360519.5781 - val_loss: 3131191148843.5669\n",
      "Epoch 330/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3048979918495.5425 - val_loss: 3150040407430.3008\n",
      "Epoch 331/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3066772830354.4570 - val_loss: 3154753575519.7749\n",
      "Epoch 332/800\n",
      "4265/4265 [==============================] - 0s 115us/step - loss: 3071715427414.1938 - val_loss: 3132854138393.2041\n",
      "Epoch 333/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3049285458882.7759 - val_loss: 3177512321415.7412\n",
      "Epoch 334/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3047086744460.5146 - val_loss: 3252877850920.6865\n",
      "Epoch 335/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3059405728713.4990 - val_loss: 3137904398226.5430\n",
      "Epoch 336/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3046642812846.8481 - val_loss: 3133016923549.3447\n",
      "Epoch 337/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3039525552323.9165 - val_loss: 3125595066857.6763\n",
      "Epoch 338/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3077727418180.2466 - val_loss: 3141124446447.0771\n",
      "Epoch 339/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3090077006715.7085 - val_loss: 3184876098647.8535\n",
      "Epoch 340/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3070024711339.1865 - val_loss: 3145403821889.8901\n",
      "Epoch 341/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3050069666408.0806 - val_loss: 3140355703083.5669\n",
      "Epoch 342/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3043348350303.2573 - val_loss: 3291963718942.6050\n",
      "Epoch 343/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3065719006219.2847 - val_loss: 3133086090114.7002\n",
      "Epoch 344/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3059201716881.8569 - val_loss: 3124868035729.4629\n",
      "Epoch 345/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3068646402533.4697 - val_loss: 3132784140414.7397\n",
      "Epoch 346/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3048485680126.7998 - val_loss: 3129583482001.4629\n",
      "Epoch 347/800\n",
      "4265/4265 [==============================] - 0s 111us/step - loss: 3045561016656.1313 - val_loss: 3130272654890.4868\n",
      "Epoch 348/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3055010226642.7422 - val_loss: 3136670397193.7217\n",
      "Epoch 349/800\n",
      "4265/4265 [==============================] - 0s 112us/step - loss: 3049676598905.1274 - val_loss: 3149493982457.1587\n",
      "Epoch 350/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3047811123933.2466 - val_loss: 3125298883219.6230\n",
      "Epoch 351/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3039241319603.3501 - val_loss: 3189296610797.9971\n",
      "Epoch 352/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3055099959425.1704 - val_loss: 3238852630744.0337\n",
      "Epoch 353/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3055660741496.3472 - val_loss: 3137275358811.4541\n",
      "Epoch 354/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3098866486181.0049 - val_loss: 3140816326223.9326\n",
      "Epoch 355/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3051537772133.9199 - val_loss: 3151182663224.8887\n",
      "Epoch 356/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3046498623382.3589 - val_loss: 3229600820527.8877\n",
      "Epoch 357/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3078333459827.9053 - val_loss: 3144502383519.5049\n",
      "Epoch 358/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3057365648474.0352 - val_loss: 3132431718592.9902\n",
      "Epoch 359/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3047487622686.8521 - val_loss: 3138725338479.2573\n",
      "Epoch 360/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3045348197646.5859 - val_loss: 3132671414070.3687\n",
      "Epoch 361/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3051096745739.5845 - val_loss: 3177299428411.0493\n",
      "Epoch 362/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3029576935183.4258 - val_loss: 3128719302367.9551\n",
      "Epoch 363/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3044300776924.1060 - val_loss: 3159014139641.8789\n",
      "Epoch 364/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 3051021173865.4009 - val_loss: 3125080999524.0957\n",
      "Epoch 365/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3046698024890.8530 - val_loss: 3147404328660.4331\n",
      "Epoch 366/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3051476157722.1099 - val_loss: 3148344576878.5371\n",
      "Epoch 367/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3057896865096.6885 - val_loss: 3126227227666.7231\n",
      "Epoch 368/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3066116811183.6890 - val_loss: 3139508428235.4316\n",
      "Epoch 369/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3058438460316.8413 - val_loss: 3129966480284.6245\n",
      "Epoch 370/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3038665736998.7148 - val_loss: 3146812753715.4883\n",
      "Epoch 371/800\n",
      "4265/4265 [==============================] - 0s 109us/step - loss: 3051890031714.1982 - val_loss: 3129387646054.2559\n",
      "Epoch 372/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3051881243313.5493 - val_loss: 3286868180461.9971\n",
      "Epoch 373/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3055601860942.2104 - val_loss: 3141115828140.4668\n",
      "Epoch 374/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3047912226358.8613 - val_loss: 3124751786848.1353\n",
      "Epoch 375/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3061665441340.1436 - val_loss: 3140750372489.5415\n",
      "Epoch 376/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3037592879488.1504 - val_loss: 3283672762716.5347\n",
      "Epoch 377/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3046043441642.2715 - val_loss: 3193240733929.3164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3051761548701.2012 - val_loss: 3135144203674.4644\n",
      "Epoch 379/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3034331785109.8784 - val_loss: 3136019869713.2827\n",
      "Epoch 380/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3055154695030.9062 - val_loss: 3129585099109.1758\n",
      "Epoch 381/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3043392018207.7524 - val_loss: 3136518991520.5850\n",
      "Epoch 382/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3067919120084.8433 - val_loss: 3138032495942.9312\n",
      "Epoch 383/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3056691561465.9976 - val_loss: 3143870288338.6328\n",
      "Epoch 384/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3041461005238.2910 - val_loss: 3137649393687.0435\n",
      "Epoch 385/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3040874136981.0386 - val_loss: 3171553906278.9761\n",
      "Epoch 386/800\n",
      "4265/4265 [==============================] - 1s 122us/step - loss: 3043782448843.2397 - val_loss: 3122434997995.4766\n",
      "Epoch 387/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3057971054215.0527 - val_loss: 3127182141938.3179\n",
      "Epoch 388/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3053149925219.4590 - val_loss: 3179000113604.2305\n",
      "Epoch 389/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3062283321017.4727 - val_loss: 3122662853855.2349\n",
      "Epoch 390/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3030005404296.2529 - val_loss: 3138299658654.7847\n",
      "Epoch 391/800\n",
      "4265/4265 [==============================] - 0s 115us/step - loss: 3059746978983.3452 - val_loss: 3132156828347.9492\n",
      "Epoch 392/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3050523563673.2998 - val_loss: 3314936976794.4644\n",
      "Epoch 393/800\n",
      "4265/4265 [==============================] - 0s 111us/step - loss: 3047787945025.5454 - val_loss: 3172794944274.3628\n",
      "Epoch 394/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3034235902853.3120 - val_loss: 3143582062301.0747\n",
      "Epoch 395/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3046968079063.0044 - val_loss: 3132238921451.4766\n",
      "Epoch 396/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3064670704164.3745 - val_loss: 3135067342390.0083\n",
      "Epoch 397/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3083858655378.4570 - val_loss: 3248326990155.2520\n",
      "Epoch 398/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3040787006062.3228 - val_loss: 3232211262278.2109\n",
      "Epoch 399/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3072750070629.6196 - val_loss: 3153369051844.5908\n",
      "Epoch 400/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3041214394392.0093 - val_loss: 3127552434533.1758\n",
      "Epoch 401/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3048022352623.0137 - val_loss: 3124985342404.2305\n",
      "Epoch 402/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3066666940804.4717 - val_loss: 3331003747896.8887\n",
      "Epoch 403/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3070029778247.7280 - val_loss: 3130042100901.6260\n",
      "Epoch 404/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3044422231035.9185 - val_loss: 3157650504529.7329\n",
      "Epoch 405/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3044908281722.5078 - val_loss: 3118994675444.1182\n",
      "Epoch 406/800\n",
      "4265/4265 [==============================] - 0s 117us/step - loss: 3041255472756.3252 - val_loss: 3130658340610.5205\n",
      "Epoch 407/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3051227993342.2593 - val_loss: 3126699094609.3726\n",
      "Epoch 408/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3042647356410.9580 - val_loss: 3128339217164.6021\n",
      "Epoch 409/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3032505995420.5410 - val_loss: 3135979749145.5640\n",
      "Epoch 410/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3075233585023.7900 - val_loss: 3143100588204.8271\n",
      "Epoch 411/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3035600573194.8643 - val_loss: 3181505966166.4136\n",
      "Epoch 412/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3058487831712.6230 - val_loss: 3121542002800.3374\n",
      "Epoch 413/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3040978354033.8643 - val_loss: 3119900069202.4531\n",
      "Epoch 414/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3033919656880.0488 - val_loss: 3153550454755.1953\n",
      "Epoch 415/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3050871563736.2642 - val_loss: 3156458008892.8496\n",
      "Epoch 416/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3035395084905.5215 - val_loss: 3131892565442.7905\n",
      "Epoch 417/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3047779200940.4473 - val_loss: 3149943983050.7119\n",
      "Epoch 418/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3035617895842.4834 - val_loss: 3123410408535.8535\n",
      "Epoch 419/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3051713635416.1147 - val_loss: 3124738254908.4893\n",
      "Epoch 420/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3052556590333.7793 - val_loss: 3137220095464.2363\n",
      "Epoch 421/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3051595546581.7437 - val_loss: 3120798236118.9536\n",
      "Epoch 422/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3041717033016.1821 - val_loss: 3117138035955.3979\n",
      "Epoch 423/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3037605976515.8564 - val_loss: 3131439123794.4531\n",
      "Epoch 424/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3048200291606.2686 - val_loss: 3196770641150.9199\n",
      "Epoch 425/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3048824824393.8286 - val_loss: 3127705549488.4277\n",
      "Epoch 426/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3058007680403.1177 - val_loss: 3281244753649.2378\n",
      "Epoch 427/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3073281071667.2603 - val_loss: 3140081689232.7427\n",
      "Epoch 428/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3037925577747.9277 - val_loss: 3120921995001.8789\n",
      "Epoch 429/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3014042652187.0107 - val_loss: 3153871089312.5850\n",
      "Epoch 430/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3038062995968.3604 - val_loss: 3178402778496.5400\n",
      "Epoch 431/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3043123705433.9155 - val_loss: 3334657389298.6777\n",
      "Epoch 432/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3066420266404.4043 - val_loss: 3233982325577.0913\n",
      "Epoch 433/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3066977607382.2837 - val_loss: 3148224381826.7002\n",
      "Epoch 434/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3046748651596.8301 - val_loss: 3131756202632.1011\n",
      "Epoch 435/800\n",
      "4265/4265 [==============================] - ETA: 0s - loss: 3102423651249.231 - 0s 83us/step - loss: 3059430297937.0918 - val_loss: 3141894775947.7017\n",
      "Epoch 436/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3048746877611.7871 - val_loss: 3142629452389.5356\n",
      "Epoch 437/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3062213440987.1455 - val_loss: 3122001992886.9087\n",
      "Epoch 438/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3045341798136.8574 - val_loss: 3137826809133.0068\n",
      "Epoch 439/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3034740191263.6924 - val_loss: 3118557653375.1001\n",
      "Epoch 440/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 72us/step - loss: 3034867759938.0854 - val_loss: 3119634551619.3306\n",
      "Epoch 441/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3045523316937.6792 - val_loss: 3126064301668.0957\n",
      "Epoch 442/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3033429265236.3325 - val_loss: 3122725291320.5288\n",
      "Epoch 443/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3045716403080.6733 - val_loss: 3148043738064.4727\n",
      "Epoch 444/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3037918570297.6826 - val_loss: 3119090602819.3306\n",
      "Epoch 445/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3044221579257.2773 - val_loss: 3120814828986.1489\n",
      "Epoch 446/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3059920031885.1748 - val_loss: 3154486745373.1646\n",
      "Epoch 447/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3047777355360.6377 - val_loss: 3116475372424.4614\n",
      "Epoch 448/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3028816844445.1411 - val_loss: 3125703460636.4443\n",
      "Epoch 449/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3071231358327.2666 - val_loss: 3131021048726.8638\n",
      "Epoch 450/800\n",
      "4265/4265 [==============================] - 0s 112us/step - loss: 3030250571260.7583 - val_loss: 3116178848478.5146\n",
      "Epoch 451/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3033354739510.3208 - val_loss: 3142149171030.0532\n",
      "Epoch 452/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3024039474412.9722 - val_loss: 3121886664274.8130\n",
      "Epoch 453/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3063040493198.7358 - val_loss: 3116351434723.1953\n",
      "Epoch 454/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3053881757080.3994 - val_loss: 3126352608081.7329\n",
      "Epoch 455/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3021484298023.9155 - val_loss: 3119944563998.6050\n",
      "Epoch 456/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3062252578871.2212 - val_loss: 3116628774595.1504\n",
      "Epoch 457/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3042992433368.5649 - val_loss: 3116292407710.7847\n",
      "Epoch 458/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3034114788207.2236 - val_loss: 3123420198194.7681\n",
      "Epoch 459/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3046997093271.5591 - val_loss: 3123277788005.8960\n",
      "Epoch 460/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3034527615159.9121 - val_loss: 3132487416634.6890\n",
      "Epoch 461/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3033115217031.6528 - val_loss: 3124343811514.1489\n",
      "Epoch 462/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3047450939982.6309 - val_loss: 3116160329903.7075\n",
      "Epoch 463/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3035800982989.7007 - val_loss: 3212351600798.4248\n",
      "Epoch 464/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3049442978262.1035 - val_loss: 3125623402743.7188\n",
      "Epoch 465/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3047414158720.8706 - val_loss: 3121093915747.3755\n",
      "Epoch 466/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3049550909677.2124 - val_loss: 3160155353497.0239\n",
      "Epoch 467/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 3045501551087.5537 - val_loss: 3127396857415.2910\n",
      "Epoch 468/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3030200320622.3228 - val_loss: 3144544552571.1392\n",
      "Epoch 469/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3023673779169.0283 - val_loss: 3116801198981.5811\n",
      "Epoch 470/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3041248034074.5903 - val_loss: 3192199951090.6777\n",
      "Epoch 471/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3043318085117.7192 - val_loss: 3148631437628.8496\n",
      "Epoch 472/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3039712289956.9443 - val_loss: 3112167627175.4263\n",
      "Epoch 473/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3023680048743.8403 - val_loss: 3120494770703.1226\n",
      "Epoch 474/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3047029437876.7305 - val_loss: 3126163556539.2295\n",
      "Epoch 475/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3031439940685.0703 - val_loss: 3135088845940.6582\n",
      "Epoch 476/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3026678083354.4702 - val_loss: 3139463468142.8975\n",
      "Epoch 477/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3052182800832.9751 - val_loss: 3130728960213.1533\n",
      "Epoch 478/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3033335027541.5337 - val_loss: 3114652013794.1152\n",
      "Epoch 479/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3054060026924.4175 - val_loss: 3134038521945.2939\n",
      "Epoch 480/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3048479817566.6572 - val_loss: 3119225904518.3008\n",
      "Epoch 481/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3030075634609.9697 - val_loss: 3112697674232.0786\n",
      "Epoch 482/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3067749655298.2207 - val_loss: 3245033077793.1250\n",
      "Epoch 483/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3061524518995.0728 - val_loss: 3117531565348.3657\n",
      "Epoch 484/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3028741746735.0586 - val_loss: 3115016867730.5430\n",
      "Epoch 485/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3048834901909.8784 - val_loss: 3112590437426.4077\n",
      "Epoch 486/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3062774047455.6470 - val_loss: 3199478972485.1309\n",
      "Epoch 487/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3037187731633.6694 - val_loss: 3115893536995.5557\n",
      "Epoch 488/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3033505983629.4150 - val_loss: 3194458556879.7524\n",
      "Epoch 489/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3030134095856.6343 - val_loss: 3120767922907.6343\n",
      "Epoch 490/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3036598714010.7402 - val_loss: 3171482340229.5811\n",
      "Epoch 491/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3045964430303.5874 - val_loss: 3112923057236.9731\n",
      "Epoch 492/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 3029623881455.2534 - val_loss: 3116689889542.1211\n",
      "Epoch 493/800\n",
      "4265/4265 [==============================] - 0s 111us/step - loss: 3025177326271.9551 - val_loss: 3120450211384.8887\n",
      "Epoch 494/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3032059778882.3257 - val_loss: 3199830024595.2632\n",
      "Epoch 495/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3042461829757.2085 - val_loss: 3287424896891.4995\n",
      "Epoch 496/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3048209421900.4697 - val_loss: 3117425213785.6538\n",
      "Epoch 497/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3041063291763.0649 - val_loss: 3181764600902.5708\n",
      "Epoch 498/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3029984952454.4526 - val_loss: 3284506630244.8159\n",
      "Epoch 499/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3046438342063.4487 - val_loss: 3161584752464.2925\n",
      "Epoch 500/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3058126341160.0957 - val_loss: 3115389786927.1675\n",
      "Epoch 501/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3019519025599.5347 - val_loss: 3132174008550.4360\n",
      "Epoch 502/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3034578135717.5449 - val_loss: 3132501727263.6851\n",
      "Epoch 503/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 99us/step - loss: 3039814946238.8145 - val_loss: 3152726372461.4570\n",
      "Epoch 504/800\n",
      "4265/4265 [==============================] - 0s 114us/step - loss: 3027079026532.8994 - val_loss: 3152768865966.9873\n",
      "Epoch 505/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3033682775970.8438 - val_loss: 3117031299472.3823\n",
      "Epoch 506/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3035764679579.8809 - val_loss: 3189565350060.8271\n",
      "Epoch 507/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3034356219327.7749 - val_loss: 3119190973000.7314\n",
      "Epoch 508/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3044682307786.1592 - val_loss: 3117781572560.4727\n",
      "Epoch 509/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3035466310966.9214 - val_loss: 3198447804174.0420\n",
      "Epoch 510/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3037188632204.3350 - val_loss: 3132354152358.7061\n",
      "Epoch 511/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3035904302913.8457 - val_loss: 3131253319740.4893\n",
      "Epoch 512/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3022473813749.0161 - val_loss: 3153314112213.8735\n",
      "Epoch 513/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3037934021058.8960 - val_loss: 3109666565838.6724\n",
      "Epoch 514/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3023708472467.6572 - val_loss: 3132339847260.1743\n",
      "Epoch 515/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3039023875980.2749 - val_loss: 3122512253048.9790\n",
      "Epoch 516/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3040287358061.7231 - val_loss: 3122061995473.1929\n",
      "Epoch 517/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3024227692821.5483 - val_loss: 3165824375299.6006\n",
      "Epoch 518/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3028555116433.5566 - val_loss: 3182826263086.8071\n",
      "Epoch 519/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3052514597753.7876 - val_loss: 3121751507842.7002\n",
      "Epoch 520/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3049353563002.7476 - val_loss: 3113788924030.7397\n",
      "Epoch 521/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3028995610365.1787 - val_loss: 3112325557690.1489\n",
      "Epoch 522/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3041311217109.3833 - val_loss: 3137124592828.6694\n",
      "Epoch 523/800\n",
      "4265/4265 [==============================] - 0s 109us/step - loss: 3046022472027.6558 - val_loss: 3192826306018.4756\n",
      "Epoch 524/800\n",
      "4265/4265 [==============================] - 0s 113us/step - loss: 3058420224006.7227 - val_loss: 3110426799292.6694\n",
      "Epoch 525/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3034530692724.3252 - val_loss: 3109765982568.0562\n",
      "Epoch 526/800\n",
      "4265/4265 [==============================] - 1s 126us/step - loss: 3013193736428.2524 - val_loss: 3241760732028.9395\n",
      "Epoch 527/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3021506391692.3350 - val_loss: 3110689865405.3896\n",
      "Epoch 528/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3040219037250.3862 - val_loss: 3110284088246.5483\n",
      "Epoch 529/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3036725880495.3882 - val_loss: 3199639893874.8579\n",
      "Epoch 530/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3046866309076.7832 - val_loss: 3115007204534.9087\n",
      "Epoch 531/800\n",
      "4265/4265 [==============================] - 0s 57us/step - loss: 3036808770428.1885 - val_loss: 3110237857990.7510\n",
      "Epoch 532/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3028365496123.1230 - val_loss: 3133041710352.2026\n",
      "Epoch 533/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3025686597508.1118 - val_loss: 3272246367365.9409\n",
      "Epoch 534/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3033874313651.0503 - val_loss: 3109008988859.9492\n",
      "Epoch 535/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3034902765873.3989 - val_loss: 3110203159121.3726\n",
      "Epoch 536/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3021673284363.8247 - val_loss: 3108207907397.8511\n",
      "Epoch 537/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3034504339968.8403 - val_loss: 3180738642288.6978\n",
      "Epoch 538/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3034689993422.8408 - val_loss: 3110867509443.8706\n",
      "Epoch 539/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3024727612800.3901 - val_loss: 3108955457654.0986\n",
      "Epoch 540/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3028769235161.0449 - val_loss: 3114434043085.9521\n",
      "Epoch 541/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3037286948681.5288 - val_loss: 3120389250922.2168\n",
      "Epoch 542/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3035659922227.6802 - val_loss: 3112468848328.9116\n",
      "Epoch 543/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3033772846159.9512 - val_loss: 3116155799716.1855\n",
      "Epoch 544/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3031256696405.1133 - val_loss: 3122045275036.6245\n",
      "Epoch 545/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3010508463718.8804 - val_loss: 3118192760356.7256\n",
      "Epoch 546/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3045202259469.5654 - val_loss: 3106128974958.8975\n",
      "Epoch 547/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3026995901561.7275 - val_loss: 3110150173587.9829\n",
      "Epoch 548/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3050283366565.6646 - val_loss: 3182224116844.0171\n",
      "Epoch 549/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3030398425639.7358 - val_loss: 3186958978363.4092\n",
      "Epoch 550/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3040452535764.4229 - val_loss: 3113536524708.5459\n",
      "Epoch 551/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3031285543431.5630 - val_loss: 3108916559318.9536\n",
      "Epoch 552/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3027761464871.0156 - val_loss: 3149558727969.4854\n",
      "Epoch 553/800\n",
      "4265/4265 [==============================] - 0s 109us/step - loss: 3043457435520.7500 - val_loss: 3106401323033.9238\n",
      "Epoch 554/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3026895194580.1831 - val_loss: 3114161021769.0913\n",
      "Epoch 555/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3036304176541.6816 - val_loss: 3237027378851.4653\n",
      "Epoch 556/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3026369533643.2397 - val_loss: 3162969199819.0718\n",
      "Epoch 557/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3043631132073.6865 - val_loss: 3119283051172.9058\n",
      "Epoch 558/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3040293437098.1064 - val_loss: 3266862359876.0508\n",
      "Epoch 559/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3065120764784.6641 - val_loss: 3163025861267.6230\n",
      "Epoch 560/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3070247074664.5005 - val_loss: 3140461586400.3149\n",
      "Epoch 561/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3074585948222.4243 - val_loss: 3118179569831.0659\n",
      "Epoch 562/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3052309636241.7368 - val_loss: 3170582293323.9717\n",
      "Epoch 563/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3020650589997.6782 - val_loss: 3114316371031.8535\n",
      "Epoch 564/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3030650695139.3091 - val_loss: 3133962861140.2529\n",
      "Epoch 565/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3032017047504.9414 - val_loss: 3279087645887.5498\n",
      "Epoch 566/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 74us/step - loss: 3030772412255.6172 - val_loss: 3120795710171.6343\n",
      "Epoch 567/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3020827134178.1685 - val_loss: 3121935635797.3335\n",
      "Epoch 568/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3030521441859.3462 - val_loss: 3135151836083.6680\n",
      "Epoch 569/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3010963182942.2969 - val_loss: 3135280061738.1265\n",
      "Epoch 570/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3032206883523.3164 - val_loss: 3114889997039.7974\n",
      "Epoch 571/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3025318506765.8652 - val_loss: 3099486123959.9888\n",
      "Epoch 572/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3024010885043.6499 - val_loss: 3109409683522.2505\n",
      "Epoch 573/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3016827313736.1484 - val_loss: 3168164612582.7959\n",
      "Epoch 574/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3050062991539.5898 - val_loss: 3115245049150.2896\n",
      "Epoch 575/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3021922535488.8257 - val_loss: 3230869472130.7002\n",
      "Epoch 576/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3025679362395.1753 - val_loss: 3166169057421.1421\n",
      "Epoch 577/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3027871365654.4487 - val_loss: 3139031343484.2192\n",
      "Epoch 578/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3047671420665.3374 - val_loss: 3110526841333.1982\n",
      "Epoch 579/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3020580037551.0884 - val_loss: 3112536651819.2065\n",
      "Epoch 580/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3013046867809.0581 - val_loss: 3103207071847.6963\n",
      "Epoch 581/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3033218412460.4473 - val_loss: 3111431294175.2349\n",
      "Epoch 582/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3037905888643.7515 - val_loss: 3121247077158.5259\n",
      "Epoch 583/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3019676319436.6797 - val_loss: 3123939012510.0649\n",
      "Epoch 584/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3023508196848.7539 - val_loss: 3107689872509.2998\n",
      "Epoch 585/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3033738769345.3354 - val_loss: 3214436813263.7524\n",
      "Epoch 586/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3038863026511.6509 - val_loss: 3168127016487.6060\n",
      "Epoch 587/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3013337686121.6411 - val_loss: 3106332016363.4766\n",
      "Epoch 588/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3033733927856.0488 - val_loss: 3118429867945.5864\n",
      "Epoch 589/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3018113822571.1416 - val_loss: 3147138007685.2207\n",
      "Epoch 590/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3019140169251.6538 - val_loss: 3289392510304.8550\n",
      "Epoch 591/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3037222534829.9482 - val_loss: 3141226782524.1294\n",
      "Epoch 592/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3015014458532.9443 - val_loss: 3104683376524.7822\n",
      "Epoch 593/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3029812218489.3672 - val_loss: 3108814763015.2012\n",
      "Epoch 594/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3026572582333.8540 - val_loss: 3106994749946.9590\n",
      "Epoch 595/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3035452782369.6733 - val_loss: 3102199686744.5737\n",
      "Epoch 596/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3016337762489.8325 - val_loss: 3129054748245.6934\n",
      "Epoch 597/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 3041194641641.8511 - val_loss: 3216013182840.6187\n",
      "Epoch 598/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3043176273142.5767 - val_loss: 3099493147280.7427\n",
      "Epoch 599/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3023144818675.0352 - val_loss: 3107012837882.9590\n",
      "Epoch 600/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3017106014665.1387 - val_loss: 3120372950432.2251\n",
      "Epoch 601/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3038141432649.2886 - val_loss: 3104394114078.2446\n",
      "Epoch 602/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3024278535788.6426 - val_loss: 3375332465316.9058\n",
      "Epoch 603/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3033939939572.8955 - val_loss: 3182028061890.4302\n",
      "Epoch 604/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3028020973663.0771 - val_loss: 3100029819464.7314\n",
      "Epoch 605/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3017062560962.7158 - val_loss: 3115460544054.0083\n",
      "Epoch 606/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3016477839704.7744 - val_loss: 3153371549402.1943\n",
      "Epoch 607/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3026704198013.7490 - val_loss: 3115778722347.9268\n",
      "Epoch 608/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3016664663740.8340 - val_loss: 3170550293689.7891\n",
      "Epoch 609/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3033869783569.1665 - val_loss: 3262950451329.6201\n",
      "Epoch 610/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3056198549611.5620 - val_loss: 3127984738747.5894\n",
      "Epoch 611/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3034991841882.1553 - val_loss: 3100318538450.9932\n",
      "Epoch 612/800\n",
      "4265/4265 [==============================] - 1s 128us/step - loss: 3053953455093.1958 - val_loss: 3096467376153.9238\n",
      "Epoch 613/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3025009007696.9116 - val_loss: 3099161485715.2632\n",
      "Epoch 614/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3024167797189.2974 - val_loss: 3104246136186.7793\n",
      "Epoch 615/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3055862014921.9790 - val_loss: 3110008587806.9648\n",
      "Epoch 616/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3035079115981.2803 - val_loss: 3153526939590.3911\n",
      "Epoch 617/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3036385014621.4565 - val_loss: 3114273110266.5991\n",
      "Epoch 618/800\n",
      "4265/4265 [==============================] - 0s 115us/step - loss: 3027364763984.6118 - val_loss: 3112771636815.9326\n",
      "Epoch 619/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3038674760714.3237 - val_loss: 3137971122538.9365\n",
      "Epoch 620/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3037176399206.9399 - val_loss: 3139753779902.8296\n",
      "Epoch 621/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3035375542147.1514 - val_loss: 3107624824664.9341\n",
      "Epoch 622/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3011857352868.7041 - val_loss: 3105456417796.3208\n",
      "Epoch 623/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3024929222587.8135 - val_loss: 3211232311546.5991\n",
      "Epoch 624/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3032087203815.9907 - val_loss: 3112805179080.9116\n",
      "Epoch 625/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3040550022139.4380 - val_loss: 3164075023865.5190\n",
      "Epoch 626/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3014830437747.4248 - val_loss: 3183223058034.4980\n",
      "Epoch 627/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3029892047391.5723 - val_loss: 3101598573223.7861\n",
      "Epoch 628/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3049284017213.7041 - val_loss: 3097892350749.8848\n",
      "Epoch 629/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 66us/step - loss: 3053160870238.5366 - val_loss: 3098263570987.9268\n",
      "Epoch 630/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3014752873978.3579 - val_loss: 3113395235360.4053\n",
      "Epoch 631/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3011795633353.4385 - val_loss: 3127252448885.3784\n",
      "Epoch 632/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3014021023678.2144 - val_loss: 3189773310628.9058\n",
      "Epoch 633/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3007786430706.9746 - val_loss: 3166177119363.0605\n",
      "Epoch 634/800\n",
      "4265/4265 [==============================] - 0s 117us/step - loss: 3016988846377.2363 - val_loss: 3129560545323.2065\n",
      "Epoch 635/800\n",
      "4265/4265 [==============================] - 0s 111us/step - loss: 3050300402053.4321 - val_loss: 3149583910384.8774\n",
      "Epoch 636/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3019542933070.8706 - val_loss: 3108700986251.3418\n",
      "Epoch 637/800\n",
      "4265/4265 [==============================] - 0s 113us/step - loss: 3039098760994.1533 - val_loss: 3098979903248.9229\n",
      "Epoch 638/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3044091411577.2476 - val_loss: 3114758469329.5527\n",
      "Epoch 639/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3022749093960.0283 - val_loss: 3102072614007.5386\n",
      "Epoch 640/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3009427752675.2490 - val_loss: 3097919846005.3784\n",
      "Epoch 641/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3017356747748.8696 - val_loss: 3096889972191.5947\n",
      "Epoch 642/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3028244602593.8081 - val_loss: 3110224751896.8438\n",
      "Epoch 643/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3025791621675.5771 - val_loss: 3104778161674.8018\n",
      "Epoch 644/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3020273054204.0386 - val_loss: 3159459015707.3643\n",
      "Epoch 645/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3023109851131.6787 - val_loss: 3105021967393.1250\n",
      "Epoch 646/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3022398541542.6104 - val_loss: 3126808605541.8960\n",
      "Epoch 647/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3021402482236.1436 - val_loss: 3095709159107.1504\n",
      "Epoch 648/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3039557141167.6284 - val_loss: 3096744106568.7314\n",
      "Epoch 649/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3024715327374.1958 - val_loss: 3108823910402.8804\n",
      "Epoch 650/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3017745876484.4419 - val_loss: 3199502779658.4414\n",
      "Epoch 651/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3009983060976.8740 - val_loss: 3134398196786.4077\n",
      "Epoch 652/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3026626904717.0552 - val_loss: 3116312196817.5527\n",
      "Epoch 653/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3019194200787.1626 - val_loss: 3110841813432.7090\n",
      "Epoch 654/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3003775655042.8511 - val_loss: 3147673233468.4893\n",
      "Epoch 655/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3016075184062.2144 - val_loss: 3163455904628.2983\n",
      "Epoch 656/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3029506251265.3203 - val_loss: 3114930614611.8931\n",
      "Epoch 657/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3004912799235.9614 - val_loss: 3118981389794.4756\n",
      "Epoch 658/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3036287711347.7251 - val_loss: 3109884199557.2207\n",
      "Epoch 659/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3018655805444.8022 - val_loss: 3112704610171.4995\n",
      "Epoch 660/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3006016281035.5396 - val_loss: 3116781412824.3940\n",
      "Epoch 661/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3046783242865.2041 - val_loss: 3115737198148.4106\n",
      "Epoch 662/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3027703302239.5571 - val_loss: 3097602253203.2632\n",
      "Epoch 663/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3038933343305.2290 - val_loss: 3128694066860.1069\n",
      "Epoch 664/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3026789490359.5518 - val_loss: 3093635240955.6792\n",
      "Epoch 665/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3014917059406.0903 - val_loss: 3120678927784.8662\n",
      "Epoch 666/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3035658723310.7134 - val_loss: 3100195479356.1294\n",
      "Epoch 667/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3023880011203.6162 - val_loss: 3165573743882.4414\n",
      "Epoch 668/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3009204405003.8247 - val_loss: 3094728125190.8413\n",
      "Epoch 669/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3011804120180.9258 - val_loss: 3103543863103.0098\n",
      "Epoch 670/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3009974902582.3208 - val_loss: 3088733645160.0562\n",
      "Epoch 671/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3013040195337.6636 - val_loss: 3094245289125.6260\n",
      "Epoch 672/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3022844262619.4458 - val_loss: 3099335140445.6147\n",
      "Epoch 673/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3033846986014.9121 - val_loss: 3135480464373.9185\n",
      "Epoch 674/800\n",
      "4265/4265 [==============================] - 0s 113us/step - loss: 3031031318577.4595 - val_loss: 3136721374799.9326\n",
      "Epoch 675/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3019901442342.3550 - val_loss: 3095396775264.8550\n",
      "Epoch 676/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3010030811167.2119 - val_loss: 3092639285478.4360\n",
      "Epoch 677/800\n",
      "4265/4265 [==============================] - 0s 113us/step - loss: 3015620879352.0767 - val_loss: 3101929182157.5923\n",
      "Epoch 678/800\n",
      "4265/4265 [==============================] - 0s 111us/step - loss: 2998996614357.4434 - val_loss: 3137443886432.8550\n",
      "Epoch 679/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3012361075625.8062 - val_loss: 3090320140279.3589\n",
      "Epoch 680/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3009056658248.3281 - val_loss: 3091713461448.1914\n",
      "Epoch 681/800\n",
      "4265/4265 [==============================] - 0s 112us/step - loss: 3019618021930.1367 - val_loss: 3095003258038.9087\n",
      "Epoch 682/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3013151790683.8359 - val_loss: 3174306832326.3911\n",
      "Epoch 683/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3027866342999.9941 - val_loss: 3174764585155.8706\n",
      "Epoch 684/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3015405016030.1470 - val_loss: 3097178809529.7891\n",
      "Epoch 685/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3005636553496.7900 - val_loss: 3097060662593.1704\n",
      "Epoch 686/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3015050648603.1304 - val_loss: 3106533435498.5767\n",
      "Epoch 687/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3021452043125.4663 - val_loss: 3133386793985.4404\n",
      "Epoch 688/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3001906935693.2354 - val_loss: 3189738807169.2603\n",
      "Epoch 689/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3032889501213.4111 - val_loss: 3102101982615.5835\n",
      "Epoch 690/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3015593297869.5801 - val_loss: 3087929631445.8735\n",
      "Epoch 691/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3038204669588.0176 - val_loss: 3114078420968.9565\n",
      "Epoch 692/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 101us/step - loss: 3005744848840.2979 - val_loss: 3122579923439.4375\n",
      "Epoch 693/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3024640663046.8428 - val_loss: 3186992756594.8579\n",
      "Epoch 694/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3009986404772.6445 - val_loss: 3148258426626.5205\n",
      "Epoch 695/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3012462916633.6904 - val_loss: 3095676632235.3867\n",
      "Epoch 696/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3005761709247.8350 - val_loss: 3091277274110.5596\n",
      "Epoch 697/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3007039834545.6094 - val_loss: 3091643114681.7891\n",
      "Epoch 698/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3012311270109.7266 - val_loss: 3102403527116.8721\n",
      "Epoch 699/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3020183970297.1572 - val_loss: 3103519612017.7778\n",
      "Epoch 700/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3024184732367.8013 - val_loss: 3121443900477.9297\n",
      "Epoch 701/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3003649417340.8486 - val_loss: 3107506523981.4121\n",
      "Epoch 702/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3011836811781.1621 - val_loss: 3159998046081.2603\n",
      "Epoch 703/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3018219243242.9316 - val_loss: 3104320635963.0493\n",
      "Epoch 704/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3012416712478.3115 - val_loss: 3098062627841.4404\n",
      "Epoch 705/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3012897783750.3774 - val_loss: 3133512622368.0449\n",
      "Epoch 706/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3020355670560.5327 - val_loss: 3102840761924.4106\n",
      "Epoch 707/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3011997416269.6104 - val_loss: 3090015601584.7876\n",
      "Epoch 708/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2998090336482.1685 - val_loss: 3128273070232.6641\n",
      "Epoch 709/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3014026669885.0439 - val_loss: 3173838914135.1338\n",
      "Epoch 710/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3022434947781.7173 - val_loss: 3088852531704.0786\n",
      "Epoch 711/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3032784319144.9058 - val_loss: 3090975854597.7607\n",
      "Epoch 712/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3013454738549.8857 - val_loss: 3191924078266.5093\n",
      "Epoch 713/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3026504976902.1226 - val_loss: 3123075546306.4302\n",
      "Epoch 714/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3045085969625.2852 - val_loss: 3143123498336.8550\n",
      "Epoch 715/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3023184173588.5278 - val_loss: 3103094238581.0181\n",
      "Epoch 716/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3000539557063.0381 - val_loss: 3152559301933.0068\n",
      "Epoch 717/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3013966730336.7578 - val_loss: 3087976912489.8564\n",
      "Epoch 718/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3006804050492.3838 - val_loss: 3090863613459.4429\n",
      "Epoch 719/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3008918440319.6699 - val_loss: 3113887632860.7144\n",
      "Epoch 720/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3003905565711.1260 - val_loss: 3094868719912.6865\n",
      "Epoch 721/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3011768487650.7686 - val_loss: 3120243086285.5923\n",
      "Epoch 722/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3012759152937.2363 - val_loss: 3190113752359.2461\n",
      "Epoch 723/800\n",
      "4265/4265 [==============================] - 0s 113us/step - loss: 3038632765184.0601 - val_loss: 3084612709772.0620\n",
      "Epoch 724/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3002805103453.9370 - val_loss: 3101220394187.0718\n",
      "Epoch 725/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2993678458355.6348 - val_loss: 3219997774221.5020\n",
      "Epoch 726/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3024406539197.9741 - val_loss: 3092487422620.2646\n",
      "Epoch 727/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3015945715227.9712 - val_loss: 3105922138181.1309\n",
      "Epoch 728/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3014910087051.7944 - val_loss: 3109074788847.4375\n",
      "Epoch 729/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3005932986915.4136 - val_loss: 3124389496834.8804\n",
      "Epoch 730/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3008836585809.5718 - val_loss: 3114057710118.1660\n",
      "Epoch 731/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3016254810048.1353 - val_loss: 3130984986782.4248\n",
      "Epoch 732/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3020664776751.5386 - val_loss: 3143171878099.7129\n",
      "Epoch 733/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3009002648655.4712 - val_loss: 3111082537576.4165\n",
      "Epoch 734/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3001986449930.4438 - val_loss: 3082575012842.3965\n",
      "Epoch 735/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3007477830241.8379 - val_loss: 3140908628932.9507\n",
      "Epoch 736/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3007814971796.3179 - val_loss: 3121199958710.1885\n",
      "Epoch 737/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3022770035977.3037 - val_loss: 3123884123390.9199\n",
      "Epoch 738/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3003419984732.4961 - val_loss: 3090651986193.6426\n",
      "Epoch 739/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3004890558668.5601 - val_loss: 3102630398554.0142\n",
      "Epoch 740/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3021313530476.8823 - val_loss: 3097123448846.4023\n",
      "Epoch 741/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3016708368646.6626 - val_loss: 3090936141440.8999\n",
      "Epoch 742/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2997243546025.9268 - val_loss: 3121896741517.8623\n",
      "Epoch 743/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 2995955178703.6812 - val_loss: 3108926149512.4614\n",
      "Epoch 744/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3006509047156.8657 - val_loss: 3085367930782.0649\n",
      "Epoch 745/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3000006541358.0977 - val_loss: 3242736372636.6245\n",
      "Epoch 746/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3021987077339.2056 - val_loss: 3080128209045.7832\n",
      "Epoch 747/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3005776776381.4336 - val_loss: 3107038792351.1450\n",
      "Epoch 748/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3019557594695.6685 - val_loss: 3084796324130.9253\n",
      "Epoch 749/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2997419079369.3188 - val_loss: 3163472380987.0493\n",
      "Epoch 750/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3005579457304.3091 - val_loss: 3118758668786.3179\n",
      "Epoch 751/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3013395932305.7368 - val_loss: 3117361933477.6260\n",
      "Epoch 752/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3011489449099.9746 - val_loss: 3100429985783.3589\n",
      "Epoch 753/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3032976010085.6196 - val_loss: 3144824870413.6821\n",
      "Epoch 754/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3002151547484.0757 - val_loss: 3083709377402.0591\n",
      "Epoch 755/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 65us/step - loss: 3012392558351.9062 - val_loss: 3126842067430.7959\n",
      "Epoch 756/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3028826200373.7212 - val_loss: 3138489040181.6484\n",
      "Epoch 757/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3017034049837.0776 - val_loss: 3158778239168.9902\n",
      "Epoch 758/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3021554528767.8799 - val_loss: 3142972392783.5723\n",
      "Epoch 759/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2990902646164.0776 - val_loss: 3088722644698.1943\n",
      "Epoch 760/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 2997431293558.7261 - val_loss: 3106386762796.6470\n",
      "Epoch 761/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 2990362719077.1396 - val_loss: 3093364118431.5049\n",
      "Epoch 762/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 2992931820260.4492 - val_loss: 3091772624141.3223\n",
      "Epoch 763/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3048400461875.8599 - val_loss: 3085690853845.5132\n",
      "Epoch 764/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 2996680772828.1660 - val_loss: 3128896041991.2012\n",
      "Epoch 765/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2997093322701.1001 - val_loss: 3136759898907.0044\n",
      "Epoch 766/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3028164289662.5293 - val_loss: 3141620998432.0449\n",
      "Epoch 767/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 2995934553717.7661 - val_loss: 3181130305703.0659\n",
      "Epoch 768/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3011467806792.5083 - val_loss: 3081242727350.5483\n",
      "Epoch 769/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3001336394704.7017 - val_loss: 3086617013390.5825\n",
      "Epoch 770/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3000152513371.0557 - val_loss: 3164003240653.2319\n",
      "Epoch 771/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3011919631337.6714 - val_loss: 3159228738241.7104\n",
      "Epoch 772/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3017066911308.4697 - val_loss: 3083486241977.7891\n",
      "Epoch 773/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3000644083249.0991 - val_loss: 3116639318240.6753\n",
      "Epoch 774/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3002111547751.6602 - val_loss: 3083458253404.8945\n",
      "Epoch 775/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3006671163460.1865 - val_loss: 3147256123651.2407\n",
      "Epoch 776/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 2991399855518.6421 - val_loss: 3140202596608.3599\n",
      "Epoch 777/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2993198252481.4556 - val_loss: 3119989817943.1338\n",
      "Epoch 778/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3015093893020.6011 - val_loss: 3166865680951.4487\n",
      "Epoch 779/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3000999543106.6860 - val_loss: 3110636844477.0293\n",
      "Epoch 780/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3001894273584.8594 - val_loss: 3205497445512.8213\n",
      "Epoch 781/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 2995784751882.3843 - val_loss: 3179480552028.8945\n",
      "Epoch 782/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3012713399866.2227 - val_loss: 3148579381213.4346\n",
      "Epoch 783/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3027983037154.5283 - val_loss: 3157817352364.8271\n",
      "Epoch 784/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3007382102106.2754 - val_loss: 3082413472778.0815\n",
      "Epoch 785/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3026370330800.7090 - val_loss: 3078828465173.6035\n",
      "Epoch 786/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3002733804588.4175 - val_loss: 3092104641499.9941\n",
      "Epoch 787/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3018867825698.8140 - val_loss: 3121945408496.1577\n",
      "Epoch 788/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3024406249333.7061 - val_loss: 3077065186187.3418\n",
      "Epoch 789/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3005543516224.8257 - val_loss: 3111737668615.2012\n",
      "Epoch 790/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2983427383232.6152 - val_loss: 3088974412072.6865\n",
      "Epoch 791/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3002888940055.4092 - val_loss: 3083244750205.6597\n",
      "Epoch 792/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2990194842858.5718 - val_loss: 3080402866273.9351\n",
      "Epoch 793/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2995028148765.6514 - val_loss: 3075913559574.3237\n",
      "Epoch 794/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 2997006228199.8105 - val_loss: 3128426546511.5723\n",
      "Epoch 795/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3021619053316.1416 - val_loss: 3119864882914.8354\n",
      "Epoch 796/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3010611167804.3838 - val_loss: 3098791559237.1309\n",
      "Epoch 797/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3009060524150.1265 - val_loss: 3075308646624.6753\n",
      "Epoch 798/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2999010249010.8398 - val_loss: 3079075369057.9351\n",
      "Epoch 799/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2989108267103.5571 - val_loss: 3083604529388.1968\n",
      "Epoch 800/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3006390389104.3037 - val_loss: 3131141860609.8003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff82d3e9b70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train2 = model2.fit(predictors,target, epochs=800, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=True)\n",
    "model_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4265 samples, validate on 2844 samples\n",
      "Epoch 1/800\n",
      "4265/4265 [==============================] - 1s 125us/step - loss: 37165413203775.9219 - val_loss: 4051247536574.4697\n",
      "Epoch 2/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 4216371834788.7646 - val_loss: 3789865969678.4023\n",
      "Epoch 3/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3917314468617.4233 - val_loss: 3819316268209.1475\n",
      "Epoch 4/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3758426212781.7681 - val_loss: 4445894443514.9590\n",
      "Epoch 5/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3705473052284.9688 - val_loss: 3695828069795.1055\n",
      "Epoch 6/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3622557952400.9565 - val_loss: 3767652864904.4614\n",
      "Epoch 7/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3607183533174.8467 - val_loss: 3765358582459.9492\n",
      "Epoch 8/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3574607686017.5903 - val_loss: 3884489173697.7104\n",
      "Epoch 9/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3541126238779.4229 - val_loss: 3653006469480.0562\n",
      "Epoch 10/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3504036350124.3877 - val_loss: 3676671717070.6724\n",
      "Epoch 11/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3513457759878.0923 - val_loss: 3631602731540.8833\n",
      "Epoch 12/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3495868703578.5757 - val_loss: 3629536954601.3164\n",
      "Epoch 13/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3497585261335.8291 - val_loss: 3627653089743.7524\n",
      "Epoch 14/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3482634360173.6626 - val_loss: 3624885474414.8975\n",
      "Epoch 15/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3479360002569.0039 - val_loss: 3659533908909.9072\n",
      "Epoch 16/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3479868837533.6216 - val_loss: 3613108320068.7705\n",
      "Epoch 17/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3480220284436.7681 - val_loss: 3611257316491.7017\n",
      "Epoch 18/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3470439819949.2280 - val_loss: 3624793197514.7119\n",
      "Epoch 19/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3471017912989.8613 - val_loss: 3608650889120.9453\n",
      "Epoch 20/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3464714371874.8735 - val_loss: 3616323228275.9380\n",
      "Epoch 21/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3458223451826.7495 - val_loss: 3599570423375.9326\n",
      "Epoch 22/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3455568253457.1665 - val_loss: 3596579024821.1084\n",
      "Epoch 23/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3458532607803.6030 - val_loss: 3619103276456.8662\n",
      "Epoch 24/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3457196877299.1548 - val_loss: 3591257058815.2798\n",
      "Epoch 25/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3454444838264.7070 - val_loss: 3594468368902.4810\n",
      "Epoch 26/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3442495723706.7930 - val_loss: 3629906349048.7988\n",
      "Epoch 27/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3446998324355.3315 - val_loss: 3584644682517.2432\n",
      "Epoch 28/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3439317155486.5820 - val_loss: 3581039313218.6104\n",
      "Epoch 29/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3441653686554.3506 - val_loss: 3600509316999.0210\n",
      "Epoch 30/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3440580153231.6357 - val_loss: 3583416816981.3335\n",
      "Epoch 31/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3431466460797.4492 - val_loss: 3580737185437.7046\n",
      "Epoch 32/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3428923899927.0493 - val_loss: 3569684667897.5190\n",
      "Epoch 33/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3429210610661.3496 - val_loss: 3579835536172.2871\n",
      "Epoch 34/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3417300596279.3418 - val_loss: 3607882506712.3940\n",
      "Epoch 35/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3426359951271.6455 - val_loss: 3588944919608.1689\n",
      "Epoch 36/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3417742140046.9756 - val_loss: 3560115884291.2407\n",
      "Epoch 37/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3415669432283.5059 - val_loss: 3561518152276.2529\n",
      "Epoch 38/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3418622731959.0718 - val_loss: 3586466299788.7822\n",
      "Epoch 39/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3411922494198.6963 - val_loss: 3556028510709.1982\n",
      "Epoch 40/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3404763753244.6313 - val_loss: 3553163130784.9453\n",
      "Epoch 41/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3404263103995.3184 - val_loss: 3614476509333.7832\n",
      "Epoch 42/800\n",
      "4265/4265 [==============================] - 1s 122us/step - loss: 3404482428171.2246 - val_loss: 3567681387783.5610\n",
      "Epoch 43/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3405309423467.1416 - val_loss: 3562543089966.4473\n",
      "Epoch 44/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3402806745824.1279 - val_loss: 3543137724776.0562\n",
      "Epoch 45/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3394335495529.8213 - val_loss: 3548845817832.9565\n",
      "Epoch 46/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3389369744885.5562 - val_loss: 3550501488366.3574\n",
      "Epoch 47/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3390577895406.2329 - val_loss: 3528537198436.4556\n",
      "Epoch 48/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3383571359683.9766 - val_loss: 3534157946292.3882\n",
      "Epoch 49/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3385833619194.7778 - val_loss: 3525257108916.3882\n",
      "Epoch 50/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3379344279386.3354 - val_loss: 3548607449666.9707\n",
      "Epoch 51/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3378304934235.6558 - val_loss: 3518554489822.8750\n",
      "Epoch 52/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3373968413612.2075 - val_loss: 3519641917333.4233\n",
      "Epoch 53/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3369258911125.0386 - val_loss: 3515096415219.0381\n",
      "Epoch 54/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3371781463370.6094 - val_loss: 3507726008803.9155\n",
      "Epoch 55/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3368267433837.5430 - val_loss: 3546755075640.8887\n",
      "Epoch 56/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3367666777789.3140 - val_loss: 3510819070562.6553\n",
      "Epoch 57/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3357092793671.7280 - val_loss: 3564543890957.6821\n",
      "Epoch 58/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3359258286366.6719 - val_loss: 3496681278894.6274\n",
      "Epoch 59/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3358285012628.9780 - val_loss: 3513055861620.2983\n",
      "Epoch 60/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3355867297239.3042 - val_loss: 3490035268894.6050\n",
      "Epoch 61/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3347843284953.5850 - val_loss: 3488147117189.9409\n",
      "Epoch 62/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3346078747468.6499 - val_loss: 3561397974553.2041\n",
      "Epoch 63/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3347264517714.2319 - val_loss: 3487516844850.0479\n",
      "Epoch 64/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 78us/step - loss: 3342838537362.2173 - val_loss: 3487907804051.9829\n",
      "Epoch 65/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3337541790550.2534 - val_loss: 3472149565376.6299\n",
      "Epoch 66/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3330564483269.3569 - val_loss: 3529511242952.1914\n",
      "Epoch 67/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3335265414600.4185 - val_loss: 3469231710933.8735\n",
      "Epoch 68/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3325544855702.2983 - val_loss: 3471046451626.3066\n",
      "Epoch 69/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3324271974237.2163 - val_loss: 3465547324575.8647\n",
      "Epoch 70/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3327509167935.9253 - val_loss: 3464648566637.0972\n",
      "Epoch 71/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3318940085931.0669 - val_loss: 3471683229266.8130\n",
      "Epoch 72/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3311702317688.4072 - val_loss: 3460459377947.7241\n",
      "Epoch 73/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3309145939923.8228 - val_loss: 3465188223796.9282\n",
      "Epoch 74/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3308576578952.0732 - val_loss: 3450185497033.9917\n",
      "Epoch 75/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3308154832526.7358 - val_loss: 3458799423148.1069\n",
      "Epoch 76/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3300628941137.5718 - val_loss: 3442059774484.8833\n",
      "Epoch 77/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3296316187540.1978 - val_loss: 3498157596107.4316\n",
      "Epoch 78/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3296473628030.4692 - val_loss: 3514156547865.5640\n",
      "Epoch 79/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3301997760330.4888 - val_loss: 3441530082852.7256\n",
      "Epoch 80/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3275286520374.6216 - val_loss: 3455490387916.1519\n",
      "Epoch 81/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3296390530041.9976 - val_loss: 3537576897286.8413\n",
      "Epoch 82/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3286251453177.0972 - val_loss: 3426943529783.8086\n",
      "Epoch 83/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3284417094175.5723 - val_loss: 3431374580417.7104\n",
      "Epoch 84/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3275523042902.5537 - val_loss: 3415269889872.2925\n",
      "Epoch 85/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3280285459678.5674 - val_loss: 3472177524453.7158\n",
      "Epoch 86/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3269328557425.5044 - val_loss: 3416436667744.8550\n",
      "Epoch 87/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3274815289244.6011 - val_loss: 3403368339165.0747\n",
      "Epoch 88/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3268502476191.6021 - val_loss: 3414080392115.6680\n",
      "Epoch 89/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3261831494500.6592 - val_loss: 3395206055454.9648\n",
      "Epoch 90/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3263497094537.5137 - val_loss: 3389669583023.7075\n",
      "Epoch 91/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3263594342708.7603 - val_loss: 3399043241163.0718\n",
      "Epoch 92/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3255802231180.1548 - val_loss: 3387272537919.0098\n",
      "Epoch 93/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3249952742957.2578 - val_loss: 3400329571447.5386\n",
      "Epoch 94/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3246023709938.7349 - val_loss: 3377680444512.4951\n",
      "Epoch 95/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3243750419482.1704 - val_loss: 3387279505566.4248\n",
      "Epoch 96/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3243898256897.0806 - val_loss: 3369481274450.0928\n",
      "Epoch 97/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3233848793328.5742 - val_loss: 3367291285129.5415\n",
      "Epoch 98/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3241893614561.9883 - val_loss: 3390719480435.9380\n",
      "Epoch 99/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3231054729322.6016 - val_loss: 3370820654052.6357\n",
      "Epoch 100/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3226384609438.4619 - val_loss: 3355517006993.4629\n",
      "Epoch 101/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3226954067216.0264 - val_loss: 3426197347764.3882\n",
      "Epoch 102/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3221778906110.3193 - val_loss: 3353397897944.7539\n",
      "Epoch 103/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3217258424475.1006 - val_loss: 3353629694075.8594\n",
      "Epoch 104/800\n",
      "4265/4265 [==============================] - 1s 125us/step - loss: 3218150575554.6562 - val_loss: 3363472367650.5654\n",
      "Epoch 105/800\n",
      "4265/4265 [==============================] - 0s 111us/step - loss: 3218549587549.2764 - val_loss: 3346454991982.8975\n",
      "Epoch 106/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3209554701326.6460 - val_loss: 3338377715562.2168\n",
      "Epoch 107/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3206934997807.8384 - val_loss: 3333829973241.1587\n",
      "Epoch 108/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3201749689485.8955 - val_loss: 3328013932898.2954\n",
      "Epoch 109/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3198788351547.1831 - val_loss: 3325458464698.8691\n",
      "Epoch 110/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3193764508747.6294 - val_loss: 3321580185798.7510\n",
      "Epoch 111/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3194440896630.1265 - val_loss: 3333532266881.9805\n",
      "Epoch 112/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3190742057820.4961 - val_loss: 3314657229327.1226\n",
      "Epoch 113/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3192073772020.7153 - val_loss: 3378355504763.1392\n",
      "Epoch 114/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3186117301509.9424 - val_loss: 3337198797952.1802\n",
      "Epoch 115/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3180191805971.0874 - val_loss: 3319679339835.4092\n",
      "Epoch 116/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3171170236746.8491 - val_loss: 3396058749789.2544\n",
      "Epoch 117/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3180852719059.9429 - val_loss: 3300685580175.6626\n",
      "Epoch 118/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3168796317721.4502 - val_loss: 3317201099405.8623\n",
      "Epoch 119/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3170914253530.3652 - val_loss: 3297704043544.4839\n",
      "Epoch 120/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3159836459899.2285 - val_loss: 3302732937351.3813\n",
      "Epoch 121/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3163621949378.5356 - val_loss: 3291947720047.2573\n",
      "Epoch 122/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3160639698679.4165 - val_loss: 3285324422926.0420\n",
      "Epoch 123/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3159134933636.4116 - val_loss: 3291759342483.9829\n",
      "Epoch 124/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3154549845306.2827 - val_loss: 3289719842254.3120\n",
      "Epoch 125/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3153594159955.8525 - val_loss: 3318483462872.7539\n",
      "Epoch 126/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3145456863477.3760 - val_loss: 3272894811704.8887\n",
      "Epoch 127/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 89us/step - loss: 3153766393941.9536 - val_loss: 3271977698155.6567\n",
      "Epoch 128/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3142557045879.8066 - val_loss: 3273316971573.2881\n",
      "Epoch 129/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3149738066430.9194 - val_loss: 3263929353067.6567\n",
      "Epoch 130/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3143229017204.4453 - val_loss: 3273529652576.8550\n",
      "Epoch 131/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3142282043977.8286 - val_loss: 3299731003262.3799\n",
      "Epoch 132/800\n",
      "4265/4265 [==============================] - 1s 132us/step - loss: 3134836310108.1963 - val_loss: 3284054406404.6807\n",
      "Epoch 133/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3129963319717.6045 - val_loss: 3262398601708.5571\n",
      "Epoch 134/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3129119637404.1211 - val_loss: 3258415461890.1602\n",
      "Epoch 135/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3138954269108.9707 - val_loss: 3247815334841.4292\n",
      "Epoch 136/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3127465530184.3281 - val_loss: 3241052861746.7681\n",
      "Epoch 137/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3124264911996.6089 - val_loss: 3273648015938.9707\n",
      "Epoch 138/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3119682243227.9409 - val_loss: 3242139106475.3867\n",
      "Epoch 139/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3129862373979.1157 - val_loss: 3237065980016.3374\n",
      "Epoch 140/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3113216881728.1050 - val_loss: 3431025240539.2744\n",
      "Epoch 141/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3119630623171.3765 - val_loss: 3282817807897.2041\n",
      "Epoch 142/800\n",
      "4265/4265 [==============================] - 0s 114us/step - loss: 3123037734923.0444 - val_loss: 3260065553291.3418\n",
      "Epoch 143/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3108057184383.2500 - val_loss: 3274935842029.6372\n",
      "Epoch 144/800\n",
      "4265/4265 [==============================] - 1s 166us/step - loss: 3113401148461.8579 - val_loss: 3228864208792.3037\n",
      "Epoch 145/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3104727990248.9507 - val_loss: 3319577925133.6821\n",
      "Epoch 146/800\n",
      "4265/4265 [==============================] - 1s 136us/step - loss: 3108552301687.3267 - val_loss: 3293628703515.0044\n",
      "Epoch 147/800\n",
      "4265/4265 [==============================] - 0s 109us/step - loss: 3103499553777.8345 - val_loss: 3217800107879.3359\n",
      "Epoch 148/800\n",
      "4265/4265 [==============================] - 0s 112us/step - loss: 3104065217443.5640 - val_loss: 3249292909313.0801\n",
      "Epoch 149/800\n",
      "4265/4265 [==============================] - 1s 146us/step - loss: 3092069968230.7002 - val_loss: 3219455173748.6582\n",
      "Epoch 150/800\n",
      "4265/4265 [==============================] - 1s 168us/step - loss: 3103217792371.4248 - val_loss: 3209405682568.4614\n",
      "Epoch 151/800\n",
      "4265/4265 [==============================] - 1s 138us/step - loss: 3103095593192.8911 - val_loss: 3209286569275.4092\n",
      "Epoch 152/800\n",
      "4265/4265 [==============================] - 0s 113us/step - loss: 3086811473560.3398 - val_loss: 3232391927056.2026\n",
      "Epoch 153/800\n",
      "4265/4265 [==============================] - 1s 122us/step - loss: 3094390453289.0562 - val_loss: 3269155350772.8384\n",
      "Epoch 154/800\n",
      "4265/4265 [==============================] - 1s 131us/step - loss: 3099753473546.2041 - val_loss: 3233302748412.0396\n",
      "Epoch 155/800\n",
      "4265/4265 [==============================] - 1s 153us/step - loss: 3092417025789.1787 - val_loss: 3204077800440.7988\n",
      "Epoch 156/800\n",
      "4265/4265 [==============================] - 1s 158us/step - loss: 3094529739723.4194 - val_loss: 3211707737895.9663\n",
      "Epoch 157/800\n",
      "4265/4265 [==============================] - 1s 134us/step - loss: 3083963564623.5908 - val_loss: 3211371296165.9858\n",
      "Epoch 158/800\n",
      "4265/4265 [==============================] - 1s 173us/step - loss: 3079797858659.3389 - val_loss: 3395684581445.1309\n",
      "Epoch 159/800\n",
      "4265/4265 [==============================] - 1s 148us/step - loss: 3099535283688.5908 - val_loss: 3237902295696.7427\n",
      "Epoch 160/800\n",
      "4265/4265 [==============================] - 0s 117us/step - loss: 3086531177087.1294 - val_loss: 3196249974498.8354\n",
      "Epoch 161/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3079537010013.3364 - val_loss: 3206224630019.2407\n",
      "Epoch 162/800\n",
      "4265/4265 [==============================] - 1s 130us/step - loss: 3077504282866.9746 - val_loss: 3209383879635.3530\n",
      "Epoch 163/800\n",
      "4265/4265 [==============================] - 1s 125us/step - loss: 3075269557204.0625 - val_loss: 3195553624910.8525\n",
      "Epoch 164/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3081221660512.5781 - val_loss: 3215657307428.3657\n",
      "Epoch 165/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3080191430105.7051 - val_loss: 3209016474311.4712\n",
      "Epoch 166/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3080740094301.5767 - val_loss: 3185308443050.3066\n",
      "Epoch 167/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3080738047611.5283 - val_loss: 3189244447091.5781\n",
      "Epoch 168/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3076800520697.1572 - val_loss: 3184014752086.7734\n",
      "Epoch 169/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3067741982530.8062 - val_loss: 3328249116991.7300\n",
      "Epoch 170/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3078426205330.2173 - val_loss: 3183587544010.7119\n",
      "Epoch 171/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3072307601306.2002 - val_loss: 3179922618618.5991\n",
      "Epoch 172/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3075159400484.4941 - val_loss: 3185323370141.7046\n",
      "Epoch 173/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3070591447475.0503 - val_loss: 3198521255743.0098\n",
      "Epoch 174/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3064040070151.9233 - val_loss: 3192892662001.9580\n",
      "Epoch 175/800\n",
      "4265/4265 [==============================] - 0s 116us/step - loss: 3071578250624.3901 - val_loss: 3260199976752.6074\n",
      "Epoch 176/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3069669498843.5059 - val_loss: 3182918815404.1069\n",
      "Epoch 177/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3069791073977.9526 - val_loss: 3175810152583.3813\n",
      "Epoch 178/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3062124099115.8169 - val_loss: 3176373470174.8750\n",
      "Epoch 179/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3061655003460.6069 - val_loss: 3172483660994.4302\n",
      "Epoch 180/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3062073798752.9976 - val_loss: 3216604101872.5176\n",
      "Epoch 181/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3070422248566.3662 - val_loss: 3255962398345.5415\n",
      "Epoch 182/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3062218545450.1968 - val_loss: 3175814792642.7905\n",
      "Epoch 183/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3059849239974.8052 - val_loss: 3191259361089.8901\n",
      "Epoch 184/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3060166335134.8223 - val_loss: 3214681078379.2969\n",
      "Epoch 185/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3068385383601.4292 - val_loss: 3208749514383.3022\n",
      "Epoch 186/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3065463191567.8462 - val_loss: 3160145144260.2305\n",
      "Epoch 187/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3062107420672.4800 - val_loss: 3171892258968.6641\n",
      "Epoch 188/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3060686539097.2549 - val_loss: 3173214989293.2769\n",
      "Epoch 189/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3062346924220.2334 - val_loss: 3240487877642.0815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3052670352593.6016 - val_loss: 3206041031514.3740\n",
      "Epoch 191/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3055571981289.6714 - val_loss: 3155743264243.7583\n",
      "Epoch 192/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3050682380803.7217 - val_loss: 3155799646219.5220\n",
      "Epoch 193/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3052207645307.7686 - val_loss: 3154355067234.2954\n",
      "Epoch 194/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3050007819693.0479 - val_loss: 3158253809220.4106\n",
      "Epoch 195/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3050303334378.3916 - val_loss: 3156596279344.9678\n",
      "Epoch 196/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3054240760614.7148 - val_loss: 3160071032722.5430\n",
      "Epoch 197/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3052101270975.7749 - val_loss: 3246079399207.2461\n",
      "Epoch 198/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3060276512321.9058 - val_loss: 3181509732412.4893\n",
      "Epoch 199/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3052800341720.6846 - val_loss: 3224938996161.3501\n",
      "Epoch 200/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3054800066996.4902 - val_loss: 3174186425642.1265\n",
      "Epoch 201/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3047667278697.9414 - val_loss: 3148743829564.4893\n",
      "Epoch 202/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3044872070447.2388 - val_loss: 3163692665641.4062\n",
      "Epoch 203/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3044212927275.9971 - val_loss: 3153364962988.1069\n",
      "Epoch 204/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3043635181507.0166 - val_loss: 3163721900043.5220\n",
      "Epoch 205/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3052807216931.1138 - val_loss: 3148823998803.8931\n",
      "Epoch 206/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3047256257311.9927 - val_loss: 3163848847423.3701\n",
      "Epoch 207/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3052504793260.8677 - val_loss: 3155595365253.5811\n",
      "Epoch 208/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3049979894780.3989 - val_loss: 3166118545848.7090\n",
      "Epoch 209/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3044065627978.4888 - val_loss: 3296929689709.4570\n",
      "Epoch 210/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3049185206442.9468 - val_loss: 3153882326109.6147\n",
      "Epoch 211/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3045280442795.8472 - val_loss: 3239714980531.3081\n",
      "Epoch 212/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3046624092937.9043 - val_loss: 3149150850340.3657\n",
      "Epoch 213/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3041226874597.6494 - val_loss: 3213800132222.0195\n",
      "Epoch 214/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3045131751630.4805 - val_loss: 3158126326122.9365\n",
      "Epoch 215/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3052109023738.5981 - val_loss: 3161448634837.5132\n",
      "Epoch 216/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3047067789943.4468 - val_loss: 3143198815515.7241\n",
      "Epoch 217/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3043548192355.0391 - val_loss: 3142006436018.5879\n",
      "Epoch 218/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3045768868021.5112 - val_loss: 3172502561539.9604\n",
      "Epoch 219/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3045641558786.7012 - val_loss: 3143507179816.6865\n",
      "Epoch 220/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3052855929217.5903 - val_loss: 3177082386820.8608\n",
      "Epoch 221/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3047571310176.6377 - val_loss: 3144546137602.1602\n",
      "Epoch 222/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3037830684262.8804 - val_loss: 3147997932548.3208\n",
      "Epoch 223/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3035986614808.3696 - val_loss: 3140598633882.4644\n",
      "Epoch 224/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3052219507999.8721 - val_loss: 3192739281584.4277\n",
      "Epoch 225/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3041869575716.1343 - val_loss: 3187931000941.4570\n",
      "Epoch 226/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3041052280332.1250 - val_loss: 3142278047804.4893\n",
      "Epoch 227/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3040825692370.3218 - val_loss: 3146968420058.1943\n",
      "Epoch 228/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3049619890673.4746 - val_loss: 3153024935305.1816\n",
      "Epoch 229/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3040797248609.2383 - val_loss: 3197353325321.7217\n",
      "Epoch 230/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3045347616074.1294 - val_loss: 3140567492207.6177\n",
      "Epoch 231/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3041954420081.5044 - val_loss: 3183715171637.6484\n",
      "Epoch 232/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3047157005997.9482 - val_loss: 3169718402011.9941\n",
      "Epoch 233/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3041090214720.1650 - val_loss: 3162557538983.7861\n",
      "Epoch 234/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3037488949902.4956 - val_loss: 3141944695023.0771\n",
      "Epoch 235/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3039652419232.9829 - val_loss: 3169528782306.4756\n",
      "Epoch 236/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3040073503383.6191 - val_loss: 3140240706299.3193\n",
      "Epoch 237/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3037240924462.0381 - val_loss: 3138219017482.4414\n",
      "Epoch 238/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3040929382215.6079 - val_loss: 3139146588033.2603\n",
      "Epoch 239/800\n",
      "4265/4265 [==============================] - 0s 114us/step - loss: 3044385811274.7290 - val_loss: 3142491233555.0830\n",
      "Epoch 240/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3045224799643.2808 - val_loss: 3144419757279.2349\n",
      "Epoch 241/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3045692858246.9927 - val_loss: 3134026629235.2178\n",
      "Epoch 242/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3035687507643.8730 - val_loss: 3135638126845.4795\n",
      "Epoch 243/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3043295741782.4937 - val_loss: 3133501513877.7832\n",
      "Epoch 244/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3039390482858.4067 - val_loss: 3148949071725.0972\n",
      "Epoch 245/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3038611277304.9170 - val_loss: 3136535110980.0508\n",
      "Epoch 246/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3040297893976.3545 - val_loss: 3154931314313.5415\n",
      "Epoch 247/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3035778061370.3428 - val_loss: 3131059598274.0703\n",
      "Epoch 248/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3047705780091.4683 - val_loss: 3168593824530.3628\n",
      "Epoch 249/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3044604047599.1333 - val_loss: 3137707141687.4487\n",
      "Epoch 250/800\n",
      "4265/4265 [==============================] - 1s 159us/step - loss: 3042496081744.2515 - val_loss: 3133561936041.9468\n",
      "Epoch 251/800\n",
      "4265/4265 [==============================] - 1s 125us/step - loss: 3036153874081.9434 - val_loss: 3132745724704.7651\n",
      "Epoch 252/800\n",
      "4265/4265 [==============================] - 1s 123us/step - loss: 3045237247733.9761 - val_loss: 3181918348542.9199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253/800\n",
      "4265/4265 [==============================] - 1s 127us/step - loss: 3037507043861.9688 - val_loss: 3175047908252.6245\n",
      "Epoch 254/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3031572630817.3130 - val_loss: 3140941623313.2827\n",
      "Epoch 255/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3031691790662.0474 - val_loss: 3151246821770.6216\n",
      "Epoch 256/800\n",
      "4265/4265 [==============================] - 1s 161us/step - loss: 3029121131980.7397 - val_loss: 3132120535230.1099\n",
      "Epoch 257/800\n",
      "4265/4265 [==============================] - 1s 121us/step - loss: 3036170362755.1514 - val_loss: 3242556478436.6357\n",
      "Epoch 258/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3033012916488.1030 - val_loss: 3219436597288.3262\n",
      "Epoch 259/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3043859711192.8047 - val_loss: 3131736419055.7974\n",
      "Epoch 260/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3042587448055.6567 - val_loss: 3134087730909.0747\n",
      "Epoch 261/800\n",
      "4265/4265 [==============================] - 1s 149us/step - loss: 3039677640313.1274 - val_loss: 3138343816830.0195\n",
      "Epoch 262/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3040609915466.7896 - val_loss: 3133276089578.7568\n",
      "Epoch 263/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3036445156724.3857 - val_loss: 3130772710240.1353\n",
      "Epoch 264/800\n",
      "4265/4265 [==============================] - 1s 136us/step - loss: 3037235598697.8213 - val_loss: 3136773261614.4473\n",
      "Epoch 265/800\n",
      "4265/4265 [==============================] - 1s 124us/step - loss: 3037393543008.5781 - val_loss: 3135870466068.1631\n",
      "Epoch 266/800\n",
      "4265/4265 [==============================] - 1s 144us/step - loss: 3037171577601.2607 - val_loss: 3187496586301.9297\n",
      "Epoch 267/800\n",
      "4265/4265 [==============================] - 0s 114us/step - loss: 3043667913181.7866 - val_loss: 3128895072685.1870\n",
      "Epoch 268/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3035327993374.3721 - val_loss: 3148714526953.3164\n",
      "Epoch 269/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3029204739966.8296 - val_loss: 3171422258742.0083\n",
      "Epoch 270/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3030689721819.6255 - val_loss: 3129709168066.7905\n",
      "Epoch 271/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 3037522403748.6445 - val_loss: 3129518235060.3882\n",
      "Epoch 272/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3026951415694.1958 - val_loss: 3149109329459.1279\n",
      "Epoch 273/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3039005218149.9800 - val_loss: 3135480423079.7861\n",
      "Epoch 274/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3036275094784.1802 - val_loss: 3129618737604.2305\n",
      "Epoch 275/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3037835041323.5771 - val_loss: 3127791205685.6484\n",
      "Epoch 276/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3034727012396.6572 - val_loss: 3299752139958.9087\n",
      "Epoch 277/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3035657333363.6050 - val_loss: 3190766017880.2139\n",
      "Epoch 278/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3028753787964.7437 - val_loss: 3189765865518.0874\n",
      "Epoch 279/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3033108870565.3647 - val_loss: 3134337303795.3979\n",
      "Epoch 280/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3036770848732.4663 - val_loss: 3132200705206.9087\n",
      "Epoch 281/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3036138298702.4507 - val_loss: 3180613314966.1436\n",
      "Epoch 282/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3044475160030.0269 - val_loss: 3143889453977.7441\n",
      "Epoch 283/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3038957079046.1226 - val_loss: 3140632579133.9297\n",
      "Epoch 284/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3022036921854.1992 - val_loss: 3151485615044.9507\n",
      "Epoch 285/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3033451350914.4312 - val_loss: 3133391232367.2573\n",
      "Epoch 286/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3030224475978.0088 - val_loss: 3129501072924.0845\n",
      "Epoch 287/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3038076575150.4883 - val_loss: 3129851250852.1855\n",
      "Epoch 288/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3034875179074.2656 - val_loss: 3188688688169.7666\n",
      "Epoch 289/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3033197765224.5610 - val_loss: 3125792311229.7495\n",
      "Epoch 290/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3038129962235.8584 - val_loss: 3169534799082.7568\n",
      "Epoch 291/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3032060782773.9912 - val_loss: 3127673657145.2490\n",
      "Epoch 292/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3031784273098.3989 - val_loss: 3132748534549.2432\n",
      "Epoch 293/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3031452508138.8716 - val_loss: 3127660115250.7681\n",
      "Epoch 294/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3029381252585.5513 - val_loss: 3131549682934.2783\n",
      "Epoch 295/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3036885918792.7480 - val_loss: 3163138660982.8184\n",
      "Epoch 296/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3034273363630.4282 - val_loss: 3140543696463.9326\n",
      "Epoch 297/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3032996391843.0840 - val_loss: 3125808785376.3149\n",
      "Epoch 298/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3031784693143.4390 - val_loss: 3192648989752.1689\n",
      "Epoch 299/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3034380161464.8125 - val_loss: 3130631432690.3179\n",
      "Epoch 300/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3030237154896.7920 - val_loss: 3144682588900.2759\n",
      "Epoch 301/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3033435103456.7275 - val_loss: 3134435953633.7554\n",
      "Epoch 302/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3027188045092.6743 - val_loss: 3142863739072.9902\n",
      "Epoch 303/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3037390679584.7725 - val_loss: 3128452074765.3223\n",
      "Epoch 304/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3034333218450.5776 - val_loss: 3147139615944.1914\n",
      "Epoch 305/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3032858363116.0122 - val_loss: 3137860171104.8550\n",
      "Epoch 306/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3035729291369.1611 - val_loss: 3126268790948.1855\n",
      "Epoch 307/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3035463938148.8394 - val_loss: 3141558911229.4795\n",
      "Epoch 308/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3031287228805.4321 - val_loss: 3145941001770.4868\n",
      "Epoch 309/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3035926416465.8716 - val_loss: 3198192229259.3418\n",
      "Epoch 310/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3036638900440.0845 - val_loss: 3128883324135.8765\n",
      "Epoch 311/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3033055912929.0283 - val_loss: 3137040060790.4585\n",
      "Epoch 312/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3033452329114.1406 - val_loss: 3122378652520.7764\n",
      "Epoch 313/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3035035379421.4868 - val_loss: 3124400318478.4023\n",
      "Epoch 314/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3027642399312.0713 - val_loss: 3222710873553.1929\n",
      "Epoch 315/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3025460722682.4775 - val_loss: 3221983562952.1914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 316/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3034100772200.3809 - val_loss: 3132185054362.1040\n",
      "Epoch 317/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3031735679037.9443 - val_loss: 3143818932079.9775\n",
      "Epoch 318/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3022353414236.6763 - val_loss: 3253750845376.6299\n",
      "Epoch 319/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3027408578173.4492 - val_loss: 3228846520893.2095\n",
      "Epoch 320/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3031380384119.0269 - val_loss: 3134929032118.5483\n",
      "Epoch 321/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3029022322992.4390 - val_loss: 3175981099598.4922\n",
      "Epoch 322/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3030984492221.9146 - val_loss: 3127776953310.8750\n",
      "Epoch 323/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3030840193105.6318 - val_loss: 3124313579047.6060\n",
      "Epoch 324/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3029454303052.4102 - val_loss: 3121135361782.9985\n",
      "Epoch 325/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3022129002500.3213 - val_loss: 3163094266103.7188\n",
      "Epoch 326/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3029023043903.8047 - val_loss: 3171684363291.3643\n",
      "Epoch 327/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3029253856133.3120 - val_loss: 3177658609934.7622\n",
      "Epoch 328/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3033644310226.4424 - val_loss: 3154991733528.1235\n",
      "Epoch 329/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3020239662037.0234 - val_loss: 3127802145312.4053\n",
      "Epoch 330/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3021581917990.9551 - val_loss: 3135672662381.8174\n",
      "Epoch 331/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3026823509090.6787 - val_loss: 3118847994262.1436\n",
      "Epoch 332/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3029425300276.1606 - val_loss: 3118587284495.8423\n",
      "Epoch 333/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3025566427502.3833 - val_loss: 3129060362772.8833\n",
      "Epoch 334/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3029574279569.4365 - val_loss: 3121764694312.6865\n",
      "Epoch 335/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3035654341049.7725 - val_loss: 3137892508834.7456\n",
      "Epoch 336/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3030938977139.5449 - val_loss: 3129161999430.5708\n",
      "Epoch 337/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3026287939371.7573 - val_loss: 3127636636955.7241\n",
      "Epoch 338/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3023448026195.7925 - val_loss: 3147620924863.9102\n",
      "Epoch 339/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3022080695907.0391 - val_loss: 3133829452334.8071\n",
      "Epoch 340/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3018121732497.4365 - val_loss: 3195289891086.7622\n",
      "Epoch 341/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3028507163319.7920 - val_loss: 3126193606869.1533\n",
      "Epoch 342/800\n",
      "4265/4265 [==============================] - 0s 58us/step - loss: 3029380015007.7227 - val_loss: 3118339335722.4868\n",
      "Epoch 343/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3029284244492.7246 - val_loss: 3290245384563.5781\n",
      "Epoch 344/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3038040756384.3828 - val_loss: 3135582751414.1885\n",
      "Epoch 345/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3022897950847.7300 - val_loss: 3189371555960.9790\n",
      "Epoch 346/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3021548557785.2251 - val_loss: 3201504840120.7090\n",
      "Epoch 347/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3025228414941.4263 - val_loss: 3120529343846.6162\n",
      "Epoch 348/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3026694644939.3594 - val_loss: 3148647208669.0747\n",
      "Epoch 349/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3024101563941.5747 - val_loss: 3145635092258.2056\n",
      "Epoch 350/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3024351400634.1929 - val_loss: 3119737798010.7793\n",
      "Epoch 351/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3019655024001.3506 - val_loss: 3121858695611.5894\n",
      "Epoch 352/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3021227601855.6548 - val_loss: 3127875150388.5684\n",
      "Epoch 353/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3017589492913.9097 - val_loss: 3128087086622.9648\n",
      "Epoch 354/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3020389957274.7402 - val_loss: 3137832651146.6216\n",
      "Epoch 355/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3026694883481.1797 - val_loss: 3132623320785.5527\n",
      "Epoch 356/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3030668103068.2412 - val_loss: 3116286799082.7568\n",
      "Epoch 357/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3024591488458.8193 - val_loss: 3169041850379.5220\n",
      "Epoch 358/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3027762767908.0142 - val_loss: 3117882656909.1421\n",
      "Epoch 359/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3021521727761.7070 - val_loss: 3152721621792.7651\n",
      "Epoch 360/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3018764570311.8779 - val_loss: 3301025200816.4277\n",
      "Epoch 361/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3027847984407.2295 - val_loss: 3116579511801.5190\n",
      "Epoch 362/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3012578369706.9468 - val_loss: 3118114625590.7285\n",
      "Epoch 363/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3032931009088.2251 - val_loss: 3213662317111.4487\n",
      "Epoch 364/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3023644616893.6743 - val_loss: 3144663659965.0293\n",
      "Epoch 365/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3022582709657.3599 - val_loss: 3118716571999.4150\n",
      "Epoch 366/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3022722936783.0210 - val_loss: 3125076563354.4644\n",
      "Epoch 367/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3020472121317.5898 - val_loss: 3133550032639.6401\n",
      "Epoch 368/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3023627526334.1543 - val_loss: 3136941732825.1138\n",
      "Epoch 369/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3023831622771.0054 - val_loss: 3116789867429.2656\n",
      "Epoch 370/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3021307966263.0415 - val_loss: 3189828424653.5923\n",
      "Epoch 371/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3023989388129.2979 - val_loss: 3119349609940.0732\n",
      "Epoch 372/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3023542395177.7163 - val_loss: 3125398569466.9590\n",
      "Epoch 373/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3022375999801.5625 - val_loss: 3155314590226.0029\n",
      "Epoch 374/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3021883943466.6167 - val_loss: 3136878598152.6411\n",
      "Epoch 375/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3016404784935.4351 - val_loss: 3187028942052.9956\n",
      "Epoch 376/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3021259589600.7881 - val_loss: 3140518381317.4009\n",
      "Epoch 377/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3031338918162.6675 - val_loss: 3118943723278.0420\n",
      "Epoch 378/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3027051432020.0327 - val_loss: 3140559258083.9155\n",
      "Epoch 379/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 73us/step - loss: 3017006675703.4165 - val_loss: 3133981752099.6455\n",
      "Epoch 380/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3023654918138.7178 - val_loss: 3219443084891.4541\n",
      "Epoch 381/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3021558970587.4458 - val_loss: 3133969358329.5190\n",
      "Epoch 382/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3023805052294.6328 - val_loss: 3171615720645.3110\n",
      "Epoch 383/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3017589843366.3247 - val_loss: 3132188785950.6050\n",
      "Epoch 384/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3027497900191.9028 - val_loss: 3146189275366.4360\n",
      "Epoch 385/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3019519977308.2559 - val_loss: 3208922204232.0112\n",
      "Epoch 386/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3019470815013.0347 - val_loss: 3118096236060.0845\n",
      "Epoch 387/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3023626742222.4209 - val_loss: 3131328920816.5176\n",
      "Epoch 388/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3019554915110.7148 - val_loss: 3146829210533.2656\n",
      "Epoch 389/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3017916022384.4839 - val_loss: 3112566606287.7524\n",
      "Epoch 390/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3017374811959.7617 - val_loss: 3129741516488.9116\n",
      "Epoch 391/800\n",
      "4265/4265 [==============================] - ETA: 0s - loss: 3004421872789.126 - 0s 83us/step - loss: 3013086078343.5928 - val_loss: 3302144457254.1660\n",
      "Epoch 392/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3019283642844.8262 - val_loss: 3152659289774.9873\n",
      "Epoch 393/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3024913145354.6841 - val_loss: 3142419440756.6582\n",
      "Epoch 394/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3022320371799.8740 - val_loss: 3112269108242.7231\n",
      "Epoch 395/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3012327928577.2607 - val_loss: 3205282567071.5049\n",
      "Epoch 396/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3013848084822.8540 - val_loss: 3125612723786.1714\n",
      "Epoch 397/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3015696959379.9580 - val_loss: 3116919042480.0674\n",
      "Epoch 398/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3019624432073.1387 - val_loss: 3107539614591.8198\n",
      "Epoch 399/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3018707945241.0298 - val_loss: 3147089342919.1113\n",
      "Epoch 400/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3018922083882.8569 - val_loss: 3119896167275.6567\n",
      "Epoch 401/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3016056078558.8071 - val_loss: 3234718569352.4614\n",
      "Epoch 402/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3021201765367.1167 - val_loss: 3119102239653.2656\n",
      "Epoch 403/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3010967886660.0063 - val_loss: 3110709770651.9043\n",
      "Epoch 404/800\n",
      "4265/4265 [==============================] - 0s 114us/step - loss: 3012662150714.2227 - val_loss: 3125677176183.8989\n",
      "Epoch 405/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3013737077533.5913 - val_loss: 3117948200651.7920\n",
      "Epoch 406/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3018179488506.0576 - val_loss: 3245409397119.1001\n",
      "Epoch 407/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3014533110580.6406 - val_loss: 3179507490182.3008\n",
      "Epoch 408/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3021348399992.8271 - val_loss: 3118068857681.7329\n",
      "Epoch 409/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3016211383635.7329 - val_loss: 3159096344460.7822\n",
      "Epoch 410/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3014425439342.6831 - val_loss: 3109677849460.2983\n",
      "Epoch 411/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3011667161711.2837 - val_loss: 3107831547515.1392\n",
      "Epoch 412/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3016514861936.1841 - val_loss: 3116579125775.1226\n",
      "Epoch 413/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3007600764560.6567 - val_loss: 3110199561001.4062\n",
      "Epoch 414/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3014104306673.3540 - val_loss: 3110996548076.5571\n",
      "Epoch 415/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3015683806081.9507 - val_loss: 3192537606573.1870\n",
      "Epoch 416/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3022973775984.3643 - val_loss: 3110644455133.0747\n",
      "Epoch 417/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3015249356582.4751 - val_loss: 3112375521746.6328\n",
      "Epoch 418/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3018534207445.7437 - val_loss: 3161327893744.5176\n",
      "Epoch 419/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3013548760045.0327 - val_loss: 3117294200039.8765\n",
      "Epoch 420/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3012749023637.7583 - val_loss: 3163168702095.3022\n",
      "Epoch 421/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3009414865485.6704 - val_loss: 3170218545849.0688\n",
      "Epoch 422/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3020036464910.8257 - val_loss: 3116559174441.4062\n",
      "Epoch 423/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3021916093999.1782 - val_loss: 3133939984191.0098\n",
      "Epoch 424/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3017354459996.9761 - val_loss: 3114008055030.2783\n",
      "Epoch 425/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3010735034870.2759 - val_loss: 3110329408925.3447\n",
      "Epoch 426/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3014476952820.6558 - val_loss: 3115591503232.5400\n",
      "Epoch 427/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3012259280715.9297 - val_loss: 3108846212552.5513\n",
      "Epoch 428/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3009063980701.6216 - val_loss: 3120995579670.6836\n",
      "Epoch 429/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3020346788703.8574 - val_loss: 3167986485181.7495\n",
      "Epoch 430/800\n",
      "4265/4265 [==============================] - 0s 112us/step - loss: 3021919171133.3438 - val_loss: 3108168620455.4263\n",
      "Epoch 431/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3012887072448.1953 - val_loss: 3106380491987.7129\n",
      "Epoch 432/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3010355216733.5767 - val_loss: 3149006825255.9663\n",
      "Epoch 433/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3017585439101.2690 - val_loss: 3105492376136.7314\n",
      "Epoch 434/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3017740923868.2261 - val_loss: 3169566089711.4375\n",
      "Epoch 435/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3023398039207.2256 - val_loss: 3146562422049.4854\n",
      "Epoch 436/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3013585179345.2417 - val_loss: 3206106420035.3306\n",
      "Epoch 437/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3013110542678.8540 - val_loss: 3107935398939.3643\n",
      "Epoch 438/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3009028687544.9922 - val_loss: 3108337456676.7256\n",
      "Epoch 439/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3019559609608.8237 - val_loss: 3156123720725.6035\n",
      "Epoch 440/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3018093140915.4102 - val_loss: 3114681676991.5498\n",
      "Epoch 441/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3012910387713.8008 - val_loss: 3237281386801.3276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 442/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3011599950939.9561 - val_loss: 3104863886449.7778\n",
      "Epoch 443/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3005560588652.4624 - val_loss: 3201741072052.7480\n",
      "Epoch 444/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3006184137155.3765 - val_loss: 3155051200028.0845\n",
      "Epoch 445/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3018864541430.9365 - val_loss: 3113673123117.0068\n",
      "Epoch 446/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3004031420707.4741 - val_loss: 3184668743481.2490\n",
      "Epoch 447/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3007536475296.6230 - val_loss: 3110629155288.3940\n",
      "Epoch 448/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3014370223334.2500 - val_loss: 3141115302746.3740\n",
      "Epoch 449/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3018496858102.8765 - val_loss: 3148878319022.6274\n",
      "Epoch 450/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3015150537206.7563 - val_loss: 3103881434522.4644\n",
      "Epoch 451/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3017595542555.1304 - val_loss: 3236365834686.4697\n",
      "Epoch 452/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3007427647674.7930 - val_loss: 3104723680703.9102\n",
      "Epoch 453/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3008610807175.1128 - val_loss: 3155724833787.6792\n",
      "Epoch 454/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3010234249662.5747 - val_loss: 3175353471557.8511\n",
      "Epoch 455/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3011929616749.9033 - val_loss: 3133690437850.9141\n",
      "Epoch 456/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3011897836630.1938 - val_loss: 3133848050548.2983\n",
      "Epoch 457/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3009277957324.3198 - val_loss: 3103930176715.0718\n",
      "Epoch 458/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3009378072023.3042 - val_loss: 3126618016530.3628\n",
      "Epoch 459/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3017837064458.0239 - val_loss: 3172393278462.5596\n",
      "Epoch 460/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3003953387906.5508 - val_loss: 3100948954582.9536\n",
      "Epoch 461/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3013179908777.8662 - val_loss: 3134666229255.9214\n",
      "Epoch 462/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3015689897165.2803 - val_loss: 3103429582329.5190\n",
      "Epoch 463/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3003385099604.6929 - val_loss: 3125816535768.7539\n",
      "Epoch 464/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3004511495002.5757 - val_loss: 3321163136447.9102\n",
      "Epoch 465/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3006424994325.0083 - val_loss: 3153077446693.4458\n",
      "Epoch 466/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3012482647809.9810 - val_loss: 3136896190559.0547\n",
      "Epoch 467/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3002477089212.6538 - val_loss: 3157717362679.3589\n",
      "Epoch 468/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3011615270536.9731 - val_loss: 3105922872626.7681\n",
      "Epoch 469/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3010338516962.2285 - val_loss: 3130840835603.4429\n",
      "Epoch 470/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3010021820150.4561 - val_loss: 3106128138384.0225\n",
      "Epoch 471/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3005531200558.3384 - val_loss: 3110018071815.5610\n",
      "Epoch 472/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3008311389555.9053 - val_loss: 3116738281472.0000\n",
      "Epoch 473/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3005021876524.5977 - val_loss: 3102662864590.6724\n",
      "Epoch 474/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3004923073621.2334 - val_loss: 3113102939269.9409\n",
      "Epoch 475/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3006734382144.1050 - val_loss: 3114168559791.7075\n",
      "Epoch 476/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3009328492541.1187 - val_loss: 3296336961109.6934\n",
      "Epoch 477/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3009207895483.4536 - val_loss: 3115488310302.2446\n",
      "Epoch 478/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3012876255643.0405 - val_loss: 3100830103802.5991\n",
      "Epoch 479/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3012580755924.1831 - val_loss: 3099781953648.3374\n",
      "Epoch 480/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3002803670666.4141 - val_loss: 3144641661622.1885\n",
      "Epoch 481/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3001356795961.6226 - val_loss: 3128680045290.0366\n",
      "Epoch 482/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3003786340653.0776 - val_loss: 3118822305256.2363\n",
      "Epoch 483/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3007039100603.8730 - val_loss: 3101561347669.6934\n",
      "Epoch 484/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3007165694827.8618 - val_loss: 3108772582165.2432\n",
      "Epoch 485/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3006076760698.8081 - val_loss: 3159578878193.9580\n",
      "Epoch 486/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3003546550990.3608 - val_loss: 3257998522779.9043\n",
      "Epoch 487/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3018217444928.9453 - val_loss: 3121950120820.2983\n",
      "Epoch 488/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3011908689145.9380 - val_loss: 3105274795141.9409\n",
      "Epoch 489/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3006501589544.2158 - val_loss: 3128501662750.2446\n",
      "Epoch 490/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3001888759464.1855 - val_loss: 3100978107502.8975\n",
      "Epoch 491/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3000806451769.9829 - val_loss: 3133417608256.8101\n",
      "Epoch 492/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3005916067348.7681 - val_loss: 3124943196211.8481\n",
      "Epoch 493/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2997888018844.4810 - val_loss: 3158497200153.9238\n",
      "Epoch 494/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3012514546463.0322 - val_loss: 3124275693156.0957\n",
      "Epoch 495/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3008420824442.1479 - val_loss: 3100015744433.5078\n",
      "Epoch 496/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3006974525716.5884 - val_loss: 3094330057130.3066\n",
      "Epoch 497/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3000457419296.0522 - val_loss: 3155409613923.3755\n",
      "Epoch 498/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3003661134593.7407 - val_loss: 3122780201455.4375\n",
      "Epoch 499/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 2999466851798.8242 - val_loss: 3101322978397.6147\n",
      "Epoch 500/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3006596951385.0151 - val_loss: 3098099771175.9663\n",
      "Epoch 501/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3009214834216.9360 - val_loss: 3148392335754.6216\n",
      "Epoch 502/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2995026076199.2554 - val_loss: 3197325558704.7876\n",
      "Epoch 503/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3006848536359.9155 - val_loss: 3102319316951.6738\n",
      "Epoch 504/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3000078241353.1084 - val_loss: 3165381267876.5459\n",
      "Epoch 505/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 63us/step - loss: 2996720194122.7896 - val_loss: 3099893753824.3149\n",
      "Epoch 506/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 2999512738062.3457 - val_loss: 3140358488225.3052\n",
      "Epoch 507/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2998931685468.1963 - val_loss: 3158659125138.5430\n",
      "Epoch 508/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3002408270051.1289 - val_loss: 3129120236683.7017\n",
      "Epoch 509/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 2997799194623.0396 - val_loss: 3133797046764.5571\n",
      "Epoch 510/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3005018095934.8447 - val_loss: 3094314518369.5752\n",
      "Epoch 511/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2986096940055.7695 - val_loss: 3095537440407.9438\n",
      "Epoch 512/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3005890975558.1675 - val_loss: 3097213164404.2983\n",
      "Epoch 513/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3006628091510.7261 - val_loss: 3178986453726.5146\n",
      "Epoch 514/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3002528856414.0566 - val_loss: 3098654966359.1338\n",
      "Epoch 515/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2999468519133.0063 - val_loss: 3093132389772.0620\n",
      "Epoch 516/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 2994722992620.6724 - val_loss: 3115319407346.6777\n",
      "Epoch 517/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 2998493039697.8716 - val_loss: 3105751972067.5557\n",
      "Epoch 518/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3001461072050.6299 - val_loss: 3211485281612.6919\n",
      "Epoch 519/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2997869298628.2168 - val_loss: 3103953240225.3052\n",
      "Epoch 520/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2987043144552.0205 - val_loss: 3162132463823.3926\n",
      "Epoch 521/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 2997045817844.3555 - val_loss: 3102819864881.3276\n",
      "Epoch 522/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3008111140212.8657 - val_loss: 3108360657342.4697\n",
      "Epoch 523/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3004648750343.3828 - val_loss: 3095703173670.1660\n",
      "Epoch 524/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3001591613493.3008 - val_loss: 3176410062306.4756\n",
      "Epoch 525/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3000095141573.9575 - val_loss: 3097984506717.2544\n",
      "Epoch 526/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3011321778970.2305 - val_loss: 3102406048271.1226\n",
      "Epoch 527/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2998523019874.7988 - val_loss: 3148052217740.7822\n",
      "Epoch 528/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3006299732517.8145 - val_loss: 3158834115660.3320\n",
      "Epoch 529/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3001533630252.2373 - val_loss: 3100118271864.6187\n",
      "Epoch 530/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3001827526252.1626 - val_loss: 3110471317685.4683\n",
      "Epoch 531/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2999985947872.4878 - val_loss: 3092535775099.4995\n",
      "Epoch 532/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 2996779424407.1392 - val_loss: 3209192330166.5483\n",
      "Epoch 533/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3004304717597.8315 - val_loss: 3092798043350.5938\n",
      "Epoch 534/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2996861563126.8164 - val_loss: 3120125088302.8071\n",
      "Epoch 535/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2999989937009.6240 - val_loss: 3091814253050.9590\n",
      "Epoch 536/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3011870860814.0454 - val_loss: 3094170687957.5132\n",
      "Epoch 537/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3003596405001.5439 - val_loss: 3091963054244.1855\n",
      "Epoch 538/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3000063947052.5977 - val_loss: 3110719460025.0688\n",
      "Epoch 539/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2999005307427.4136 - val_loss: 3090605089701.2656\n",
      "Epoch 540/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2997555739738.5151 - val_loss: 3112884425470.1997\n",
      "Epoch 541/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 2996559819863.1538 - val_loss: 3184822227502.8071\n",
      "Epoch 542/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2998101600622.3833 - val_loss: 3090063363041.7554\n",
      "Epoch 543/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3001894901501.1787 - val_loss: 3134796327156.8384\n",
      "Epoch 544/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2991862819524.2764 - val_loss: 3238246455742.4697\n",
      "Epoch 545/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2997039390061.1826 - val_loss: 3147962877517.0522\n",
      "Epoch 546/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3002919983498.2339 - val_loss: 3091618750037.6934\n",
      "Epoch 547/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2989166217953.0879 - val_loss: 3198781243599.3926\n",
      "Epoch 548/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 2992772672914.6372 - val_loss: 3109377855332.4556\n",
      "Epoch 549/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 2997756413767.1279 - val_loss: 3100457051506.1377\n",
      "Epoch 550/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2982020629866.7817 - val_loss: 3335245451292.8047\n",
      "Epoch 551/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2997209796445.6968 - val_loss: 3089220174100.5234\n",
      "Epoch 552/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2993896486947.0537 - val_loss: 3130604772903.6060\n",
      "Epoch 553/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3000273904174.9380 - val_loss: 3099242633109.4233\n",
      "Epoch 554/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2989678474250.3237 - val_loss: 3110785970492.8496\n",
      "Epoch 555/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 2993864393883.3408 - val_loss: 3088193653222.7959\n",
      "Epoch 556/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3001468709875.7554 - val_loss: 3086835959303.9214\n",
      "Epoch 557/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2989696869014.6587 - val_loss: 3094052296574.3799\n",
      "Epoch 558/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2994197240425.0410 - val_loss: 3102392512644.5005\n",
      "Epoch 559/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3000587787102.8970 - val_loss: 3176597310180.2759\n",
      "Epoch 560/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 2998900815907.0537 - val_loss: 3105846057060.8159\n",
      "Epoch 561/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 2991551954694.3022 - val_loss: 3089717846557.5244\n",
      "Epoch 562/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2978171534849.0806 - val_loss: 3239549918298.7344\n",
      "Epoch 563/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2997597106491.9634 - val_loss: 3115993852609.7104\n",
      "Epoch 564/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2993890357448.7183 - val_loss: 3175649324474.1489\n",
      "Epoch 565/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 2990509322786.4536 - val_loss: 3111118322628.9507\n",
      "Epoch 566/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 2995345678353.2866 - val_loss: 3142116866114.2505\n",
      "Epoch 567/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 2995188394534.7749 - val_loss: 3263873061422.8071\n",
      "Epoch 568/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 85us/step - loss: 2993265445366.7563 - val_loss: 3094531663932.4893\n",
      "Epoch 569/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 2999646330086.7300 - val_loss: 3084450079100.2192\n",
      "Epoch 570/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2991265854328.3472 - val_loss: 3236872160107.6567\n",
      "Epoch 571/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 2988301853430.6963 - val_loss: 3099000664242.5879\n",
      "Epoch 572/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3000821866267.4307 - val_loss: 3108488746578.8130\n",
      "Epoch 573/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2993115468082.3599 - val_loss: 3214383112825.6992\n",
      "Epoch 574/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3000916868267.1865 - val_loss: 3101244782427.8145\n",
      "Epoch 575/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2994743734511.1333 - val_loss: 3115087912072.8213\n",
      "Epoch 576/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2989551079764.9331 - val_loss: 3087335990319.5273\n",
      "Epoch 577/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2993371795804.6162 - val_loss: 3098988663504.1123\n",
      "Epoch 578/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2991471197101.6475 - val_loss: 3155857461322.8916\n",
      "Epoch 579/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 2996969176834.4609 - val_loss: 3084939594860.0171\n",
      "Epoch 580/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 2990527794718.8521 - val_loss: 3093028326346.7119\n",
      "Epoch 581/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 2999709949761.8457 - val_loss: 3096625221499.4995\n",
      "Epoch 582/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2996148040902.5576 - val_loss: 3085223802093.6372\n",
      "Epoch 583/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 2997767874899.4927 - val_loss: 3085040655243.3418\n",
      "Epoch 584/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 2991813082479.1035 - val_loss: 3082119890301.6597\n",
      "Epoch 585/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 2989035073118.2368 - val_loss: 3085120572293.5811\n",
      "Epoch 586/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 2981148081995.4497 - val_loss: 3086396715831.8086\n",
      "Epoch 587/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 2989860006173.7119 - val_loss: 3202559696147.0830\n",
      "Epoch 588/800\n",
      "4265/4265 [==============================] - 1s 130us/step - loss: 2995071567064.8047 - val_loss: 3150446720675.4653\n",
      "Epoch 589/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 2990481184255.6396 - val_loss: 3082878140899.9155\n",
      "Epoch 590/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2994301008729.1348 - val_loss: 3084074433753.4741\n",
      "Epoch 591/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2985936884456.2905 - val_loss: 3096390216224.4053\n",
      "Epoch 592/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 2991175937153.8911 - val_loss: 3180129759203.1953\n",
      "Epoch 593/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2985934140088.2720 - val_loss: 3135408502711.9888\n",
      "Epoch 594/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 2981093708812.2446 - val_loss: 3080579019667.9829\n",
      "Epoch 595/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2996537932928.9302 - val_loss: 3080981246637.5469\n",
      "Epoch 596/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2992906365063.8931 - val_loss: 3082856599373.4121\n",
      "Epoch 597/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2987804526772.0703 - val_loss: 3299225427772.1294\n",
      "Epoch 598/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2993977079539.5752 - val_loss: 3083214291358.7847\n",
      "Epoch 599/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 2989310722336.1128 - val_loss: 3082270943868.5796\n",
      "Epoch 600/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 2996977928080.1167 - val_loss: 3085025147821.9072\n",
      "Epoch 601/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2982495746874.4028 - val_loss: 3096931683689.4966\n",
      "Epoch 602/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2986564531502.2778 - val_loss: 3110244338219.9268\n",
      "Epoch 603/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3001205459769.4424 - val_loss: 3079964891858.9932\n",
      "Epoch 604/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2981798912896.9902 - val_loss: 3112975309062.1211\n",
      "Epoch 605/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2989542124489.4990 - val_loss: 3085174121934.3120\n",
      "Epoch 606/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 2976553948667.7983 - val_loss: 3083951695425.5303\n",
      "Epoch 607/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2984793062106.3652 - val_loss: 3086378937233.1025\n",
      "Epoch 608/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 2989718704226.9185 - val_loss: 3081751400269.4121\n",
      "Epoch 609/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2989571702968.3921 - val_loss: 3103756028298.6216\n",
      "Epoch 610/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 2984795528657.0620 - val_loss: 3148574304984.7539\n",
      "Epoch 611/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2988367355902.0791 - val_loss: 3099898637224.1465\n",
      "Epoch 612/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 2984149144569.0376 - val_loss: 3080815253812.2080\n",
      "Epoch 613/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2983545712606.3872 - val_loss: 3114427372240.1123\n",
      "Epoch 614/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 2989751645125.1768 - val_loss: 3151428239429.1309\n",
      "Epoch 615/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 2978276799709.6064 - val_loss: 3081301369811.3530\n",
      "Epoch 616/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 2981296737434.8604 - val_loss: 3081049414032.3823\n",
      "Epoch 617/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 2994598336664.2192 - val_loss: 3082876069556.7480\n",
      "Epoch 618/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 2981918333226.1968 - val_loss: 3079899886414.8525\n",
      "Epoch 619/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 2980535111632.9414 - val_loss: 3193901464009.9917\n",
      "Epoch 620/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 2999381526016.6006 - val_loss: 3122201627894.2783\n",
      "Epoch 621/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 2982990892728.5117 - val_loss: 3193495085874.0479\n",
      "Epoch 622/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 2981372318313.5215 - val_loss: 3078508883616.5850\n",
      "Epoch 623/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 2992164054142.5293 - val_loss: 3081228136880.0674\n",
      "Epoch 624/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 2972763913417.9189 - val_loss: 3117442002799.9775\n",
      "Epoch 625/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 2986537939836.1885 - val_loss: 3074699004390.7959\n",
      "Epoch 626/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 2992789624872.8159 - val_loss: 3098904827566.9873\n",
      "Epoch 627/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 2978914421135.0361 - val_loss: 3308366180369.2827\n",
      "Epoch 628/800\n",
      "4265/4265 [==============================] - 0s 112us/step - loss: 2992187781278.4619 - val_loss: 3117737513933.5923\n",
      "Epoch 629/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 2986025388081.4595 - val_loss: 3096533434598.4360\n",
      "Epoch 630/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 2980048735709.5464 - val_loss: 3107203403666.5430\n",
      "Epoch 631/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 94us/step - loss: 2986067410256.3716 - val_loss: 3081402498403.7354\n",
      "Epoch 632/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 2985741901134.4507 - val_loss: 3077523740934.1211\n",
      "Epoch 633/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 2991056735452.1660 - val_loss: 3095444460770.1152\n",
      "Epoch 634/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 2982569258720.8481 - val_loss: 3189998249353.1816\n",
      "Epoch 635/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 2987675480349.2314 - val_loss: 3074393441085.5698\n",
      "Epoch 636/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 2983381737324.1021 - val_loss: 3083186748909.9971\n",
      "Epoch 637/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2988201989627.7983 - val_loss: 3078276301790.8750\n",
      "Epoch 638/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 2981890424755.1699 - val_loss: 3081055834901.2432\n",
      "Epoch 639/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 2984589015117.3101 - val_loss: 3073509293895.6514\n",
      "Epoch 640/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 2982655155503.7188 - val_loss: 3081701687664.6978\n",
      "Epoch 641/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 2976496992905.2134 - val_loss: 3076504019209.0015\n",
      "Epoch 642/800\n",
      "4265/4265 [==============================] - 0s 113us/step - loss: 2978326693365.0757 - val_loss: 3200008935478.7285\n",
      "Epoch 643/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 2979189167838.4468 - val_loss: 3233960083156.4331\n",
      "Epoch 644/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 2988724720191.2646 - val_loss: 3138022744628.5684\n",
      "Epoch 645/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2973269715748.3140 - val_loss: 3135403429064.1914\n",
      "Epoch 646/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2981733914399.7524 - val_loss: 3079230097802.6216\n",
      "Epoch 647/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2985453685853.3965 - val_loss: 3189584059252.2983\n",
      "Epoch 648/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2979948662498.7686 - val_loss: 3133088899959.1787\n",
      "Epoch 649/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2984003461083.5059 - val_loss: 3140263800780.1519\n",
      "Epoch 650/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 2983220683856.4316 - val_loss: 3074167519782.1660\n",
      "Epoch 651/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 2976140759861.1206 - val_loss: 3118890857940.0732\n",
      "Epoch 652/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 2980113420217.8931 - val_loss: 3191549393008.3374\n",
      "Epoch 653/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2981099139679.9175 - val_loss: 3091422186650.1040\n",
      "Epoch 654/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 2982839499897.2476 - val_loss: 3143108187062.5483\n",
      "Epoch 655/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2978781339569.2495 - val_loss: 3082316136978.0029\n",
      "Epoch 656/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 2980731757863.5557 - val_loss: 3079214491938.9253\n",
      "Epoch 657/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 2976939534356.6479 - val_loss: 3117620647852.4668\n",
      "Epoch 658/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2987740167930.7778 - val_loss: 3074709656802.1152\n",
      "Epoch 659/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2980603775351.9868 - val_loss: 3073278790787.0605\n",
      "Epoch 660/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2974783268684.8901 - val_loss: 3076146239473.5977\n",
      "Epoch 661/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2983940906579.6729 - val_loss: 3111240837894.8413\n",
      "Epoch 662/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2977417957544.0654 - val_loss: 3071651559743.7300\n",
      "Epoch 663/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2989339923602.6973 - val_loss: 3133050656430.9873\n",
      "Epoch 664/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2978541280586.6094 - val_loss: 3072775767421.6597\n",
      "Epoch 665/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 2980241560230.9849 - val_loss: 3082316649098.9819\n",
      "Epoch 666/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2985259272886.8315 - val_loss: 3126918836909.5469\n",
      "Epoch 667/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2982238201396.4604 - val_loss: 3073006294126.8975\n",
      "Epoch 668/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2978415210942.5747 - val_loss: 3150112928406.5034\n",
      "Epoch 669/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2979332859075.6768 - val_loss: 3209165973817.9692\n",
      "Epoch 670/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2977495552091.2358 - val_loss: 3092080991391.8647\n",
      "Epoch 671/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2982389958740.0327 - val_loss: 3070725226173.3896\n",
      "Epoch 672/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2981241669616.1538 - val_loss: 3139225624633.6089\n",
      "Epoch 673/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2984504610895.7114 - val_loss: 3119694961985.1704\n",
      "Epoch 674/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2977956354576.6865 - val_loss: 3076792822995.7129\n",
      "Epoch 675/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2975268823280.0938 - val_loss: 3086160023396.4556\n",
      "Epoch 676/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2971254875274.0537 - val_loss: 3070873326103.7637\n",
      "Epoch 677/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2974810612439.9644 - val_loss: 3093848847390.2446\n",
      "Epoch 678/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2968800378223.1035 - val_loss: 3154367385052.7144\n",
      "Epoch 679/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 2980428455596.0273 - val_loss: 3081020108471.6289\n",
      "Epoch 680/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 2978892510690.8286 - val_loss: 3065831353855.2798\n",
      "Epoch 681/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 2971715066976.2773 - val_loss: 3172904543694.3120\n",
      "Epoch 682/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 2984073095810.9712 - val_loss: 3068282132580.8159\n",
      "Epoch 683/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 2975966682200.5947 - val_loss: 3070528750904.5288\n",
      "Epoch 684/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2980671677562.6880 - val_loss: 3080037620043.2520\n",
      "Epoch 685/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 2975660527542.0508 - val_loss: 3113392949803.9268\n",
      "Epoch 686/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2976298786533.6494 - val_loss: 3067004335065.1138\n",
      "Epoch 687/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 2970693583819.8999 - val_loss: 3088714358588.1294\n",
      "Epoch 688/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2965697215186.6821 - val_loss: 3068104916600.2588\n",
      "Epoch 689/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2978494452371.7778 - val_loss: 3068199780282.8691\n",
      "Epoch 690/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2976985717737.1909 - val_loss: 3067317553270.0986\n",
      "Epoch 691/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 2976562688711.6377 - val_loss: 3069114172843.7471\n",
      "Epoch 692/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2977627463920.0938 - val_loss: 3142947736130.9707\n",
      "Epoch 693/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2976440666272.8628 - val_loss: 3069786977771.1167\n",
      "Epoch 694/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 70us/step - loss: 2973724225563.8506 - val_loss: 3110208805356.5571\n",
      "Epoch 695/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 2972213863946.2041 - val_loss: 3116030504839.0210\n",
      "Epoch 696/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2972101358686.8369 - val_loss: 3073136035128.5288\n",
      "Epoch 697/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2965209165198.7959 - val_loss: 3094248261197.0522\n",
      "Epoch 698/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2970891612130.2285 - val_loss: 3097197487381.9634\n",
      "Epoch 699/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2966528638011.7832 - val_loss: 3069123075784.9116\n",
      "Epoch 700/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2977832027329.7559 - val_loss: 3082800262747.4541\n",
      "Epoch 701/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 2967485067322.5830 - val_loss: 3067716528326.7510\n",
      "Epoch 702/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 2975414432593.9321 - val_loss: 3067902983131.9941\n",
      "Epoch 703/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 2970637987933.1562 - val_loss: 3083577855222.2783\n",
      "Epoch 704/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2979439037106.9897 - val_loss: 3139815707828.0283\n",
      "Epoch 705/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 2979652729458.6450 - val_loss: 3080206058071.1338\n",
      "Epoch 706/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 2975602206126.0078 - val_loss: 3070536113058.3853\n",
      "Epoch 707/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 2976057801703.2705 - val_loss: 3064592608790.3237\n",
      "Epoch 708/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 2975813674955.6592 - val_loss: 3072816711659.8369\n",
      "Epoch 709/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 2982609600377.5474 - val_loss: 3075211241878.1436\n",
      "Epoch 710/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 2975514445016.8047 - val_loss: 3115614196201.6763\n",
      "Epoch 711/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2973517668015.8687 - val_loss: 3147043276733.7495\n",
      "Epoch 712/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 2977129820014.9829 - val_loss: 3078495601285.2207\n",
      "Epoch 713/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2968266123987.6426 - val_loss: 3111102430655.9102\n",
      "Epoch 714/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 2969843879477.9014 - val_loss: 3097398041921.1704\n",
      "Epoch 715/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 2964604435930.6655 - val_loss: 3121179678129.5078\n",
      "Epoch 716/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2970549691902.6797 - val_loss: 3103949327237.5811\n",
      "Epoch 717/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2971395829180.8936 - val_loss: 3106383416497.1475\n",
      "Epoch 718/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 2964718313558.4336 - val_loss: 3061541978964.6133\n",
      "Epoch 719/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 2976994925537.5083 - val_loss: 3073188077902.1323\n",
      "Epoch 720/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 2976931257551.6812 - val_loss: 3064097755763.9380\n",
      "Epoch 721/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 2968779259097.2852 - val_loss: 3166464821850.0142\n",
      "Epoch 722/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 2963359295447.1841 - val_loss: 3067251157835.9717\n",
      "Epoch 723/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 2973263911456.0522 - val_loss: 3063531970479.3472\n",
      "Epoch 724/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 2967947476799.9253 - val_loss: 3073103476180.0732\n",
      "Epoch 725/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2970024511322.3354 - val_loss: 3094564603745.5752\n",
      "Epoch 726/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2970442687057.5117 - val_loss: 3084226684112.8325\n",
      "Epoch 727/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2977761970713.3301 - val_loss: 3107680415046.9312\n",
      "Epoch 728/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2969817984752.2139 - val_loss: 3064919207031.5386\n",
      "Epoch 729/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 2967514553636.1943 - val_loss: 3153922454051.2856\n",
      "Epoch 730/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 2964834293009.4668 - val_loss: 3114093480054.0986\n",
      "Epoch 731/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2966347971225.0601 - val_loss: 3063917297456.6074\n",
      "Epoch 732/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2970944882956.4248 - val_loss: 3063482075000.6187\n",
      "Epoch 733/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 2978017914777.2402 - val_loss: 3061758940547.4204\n",
      "Epoch 734/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2963857428974.5933 - val_loss: 3192886650018.7456\n",
      "Epoch 735/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2976808279777.8081 - val_loss: 3059183783895.6738\n",
      "Epoch 736/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 2965748699039.0024 - val_loss: 3059708468614.3008\n",
      "Epoch 737/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2965007899148.8452 - val_loss: 3144007221893.2207\n",
      "Epoch 738/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 2966306795071.5049 - val_loss: 3145841461158.7061\n",
      "Epoch 739/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 2972521598936.6245 - val_loss: 3066406742606.4922\n",
      "Epoch 740/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 2957412121890.2734 - val_loss: 3063585667599.1226\n",
      "Epoch 741/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 2967223555541.3833 - val_loss: 3075541959946.4414\n",
      "Epoch 742/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2965506497190.5049 - val_loss: 3065290489210.7793\n",
      "Epoch 743/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2969441776581.1768 - val_loss: 3068230004638.0649\n",
      "Epoch 744/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2962460298875.0483 - val_loss: 3083627356563.2632\n",
      "Epoch 745/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 2966357636978.3447 - val_loss: 3078622803066.4189\n",
      "Epoch 746/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 2972913407164.9536 - val_loss: 3248852994442.6216\n",
      "Epoch 747/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2963651662652.8037 - val_loss: 3071116707819.8369\n",
      "Epoch 748/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2967302213615.6738 - val_loss: 3088954075818.6665\n",
      "Epoch 749/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 2960550462623.1821 - val_loss: 3098885338580.0732\n",
      "Epoch 750/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2966103815835.2202 - val_loss: 3095426624654.5825\n",
      "Epoch 751/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 2973200036459.4419 - val_loss: 3156708875907.7808\n",
      "Epoch 752/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 2970214095000.2192 - val_loss: 3070472361923.5107\n",
      "Epoch 753/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 2968767255667.9653 - val_loss: 3095467293106.9478\n",
      "Epoch 754/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 2974806325878.4863 - val_loss: 3066275459711.4600\n",
      "Epoch 755/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2965316883702.5767 - val_loss: 3053824610401.9351\n",
      "Epoch 756/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2968079516550.7524 - val_loss: 3070158678053.4458\n",
      "Epoch 757/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 79us/step - loss: 2960108498103.6719 - val_loss: 3054552697111.4038\n",
      "Epoch 758/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2960318761378.2432 - val_loss: 3073331715485.3447\n",
      "Epoch 759/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2967897245522.6523 - val_loss: 3099316496882.3179\n",
      "Epoch 760/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 2965332314610.9150 - val_loss: 3099787141961.0913\n",
      "Epoch 761/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 2960715249860.3970 - val_loss: 3053423719223.8086\n",
      "Epoch 762/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 2975180041991.2632 - val_loss: 3098752005726.3350\n",
      "Epoch 763/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2963448617650.0293 - val_loss: 3062260011290.2842\n",
      "Epoch 764/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2958633220634.2900 - val_loss: 3059305977657.2490\n",
      "Epoch 765/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2959164906811.2432 - val_loss: 3053604709193.0913\n",
      "Epoch 766/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 2952732568909.4902 - val_loss: 3093378401776.8774\n",
      "Epoch 767/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 2961466798130.8999 - val_loss: 3198352457128.8662\n",
      "Epoch 768/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2961810291960.0171 - val_loss: 3054603321136.6074\n",
      "Epoch 769/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 2951690118658.5210 - val_loss: 3066765757847.5835\n",
      "Epoch 770/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 2964005810100.1304 - val_loss: 3333433740188.6245\n",
      "Epoch 771/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 2961206651096.5649 - val_loss: 3059116034972.6245\n",
      "Epoch 772/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 2960326744139.3892 - val_loss: 3056018130739.4883\n",
      "Epoch 773/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 2954250632705.0806 - val_loss: 3048828476483.6904\n",
      "Epoch 774/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 2953436652781.9331 - val_loss: 3049857148343.2686\n",
      "Epoch 775/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 2966723357069.1152 - val_loss: 3053259987989.6035\n",
      "Epoch 776/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 2954977564839.5854 - val_loss: 3086757484230.0308\n",
      "Epoch 777/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 2960415977465.2773 - val_loss: 3052804353696.5850\n",
      "Epoch 778/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2957104954550.7114 - val_loss: 3112706736081.9126\n",
      "Epoch 779/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 2959318583245.5801 - val_loss: 3066961061764.1406\n",
      "Epoch 780/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 2956639409794.2510 - val_loss: 3063538934071.0884\n",
      "Epoch 781/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 2950567698568.3735 - val_loss: 3168571613080.3037\n",
      "Epoch 782/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2959708032669.6216 - val_loss: 3061355326906.1489\n",
      "Epoch 783/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2947410088038.7598 - val_loss: 3171150385549.5020\n",
      "Epoch 784/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 2958480355647.8047 - val_loss: 3073385523951.7974\n",
      "Epoch 785/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2955820803352.1895 - val_loss: 3075185629561.3389\n",
      "Epoch 786/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2954852336038.5654 - val_loss: 3045726563770.1489\n",
      "Epoch 787/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2947147852518.8501 - val_loss: 3391860301259.4316\n",
      "Epoch 788/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2958484042812.2637 - val_loss: 3056760588175.6626\n",
      "Epoch 789/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2957802883601.6465 - val_loss: 3066603562607.6177\n",
      "Epoch 790/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 2943171153607.8779 - val_loss: 3047627196257.5752\n",
      "Epoch 791/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 2948590979271.2778 - val_loss: 3256632991824.6528\n",
      "Epoch 792/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 2959165126975.3247 - val_loss: 3060972676304.8325\n",
      "Epoch 793/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2944686383666.7803 - val_loss: 3142577361316.5459\n",
      "Epoch 794/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2952699524259.9839 - val_loss: 3088258582715.2295\n",
      "Epoch 795/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2948097550014.7544 - val_loss: 3110933652688.8325\n",
      "Epoch 796/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 2949410820525.2876 - val_loss: 3226870616208.0225\n",
      "Epoch 797/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2959821144640.2251 - val_loss: 3071666997481.3164\n",
      "Epoch 798/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2947803110242.7383 - val_loss: 3052980050642.9932\n",
      "Epoch 799/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2947785545611.3145 - val_loss: 3084296905522.0479\n",
      "Epoch 800/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 2951954084082.9746 - val_loss: 3051170923740.3545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff82d3e9f98>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train3 = model3.fit(predictors,target, epochs=800, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=True)\n",
    "model_train3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4265 samples, validate on 2844 samples\n",
      "Epoch 1/800\n",
      "4265/4265 [==============================] - 0s 112us/step - loss: 25578725049518.5469 - val_loss: 4114141859868.8047\n",
      "Epoch 2/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3886214800360.7109 - val_loss: 4129184985566.1543\n",
      "Epoch 3/800\n",
      "4265/4265 [==============================] - 0s 57us/step - loss: 3847336555872.2178 - val_loss: 3970693170765.0522\n",
      "Epoch 4/800\n",
      "4265/4265 [==============================] - 0s 57us/step - loss: 3813133172970.3315 - val_loss: 3946095860411.9497\n",
      "Epoch 5/800\n",
      "4265/4265 [==============================] - 0s 58us/step - loss: 3777606323416.3242 - val_loss: 3973020095852.3770\n",
      "Epoch 6/800\n",
      "4265/4265 [==============================] - 0s 57us/step - loss: 3763916832383.8496 - val_loss: 3965326470678.3237\n",
      "Epoch 7/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3753152069436.0835 - val_loss: 3890903860236.9619\n",
      "Epoch 8/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3739055864031.2871 - val_loss: 3875988313867.1616\n",
      "Epoch 9/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3726703071745.8008 - val_loss: 3870760373494.2783\n",
      "Epoch 10/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3720132657282.6113 - val_loss: 3859689215709.0747\n",
      "Epoch 11/800\n",
      "4265/4265 [==============================] - 0s 57us/step - loss: 3712688585614.9155 - val_loss: 3860580983878.5708\n",
      "Epoch 12/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3708673601848.1221 - val_loss: 3840881958416.5625\n",
      "Epoch 13/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3702526898814.6494 - val_loss: 3836137106666.7568\n",
      "Epoch 14/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3699531625059.7588 - val_loss: 3834084881945.2041\n",
      "Epoch 15/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3698964316924.4585 - val_loss: 3832804409897.0464\n",
      "Epoch 16/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3687982697165.8804 - val_loss: 3853633435645.1196\n",
      "Epoch 17/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3682489533230.3984 - val_loss: 3833972935764.9731\n",
      "Epoch 18/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3686337504255.7598 - val_loss: 3820535448704.1802\n",
      "Epoch 19/800\n",
      "4265/4265 [==============================] - 0s 109us/step - loss: 3682678415696.1313 - val_loss: 3824961327616.7202\n",
      "Epoch 20/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3683282208191.2949 - val_loss: 3818303685207.1338\n",
      "Epoch 21/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3680094194612.3706 - val_loss: 3821517126735.2124\n",
      "Epoch 22/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3668841843624.8462 - val_loss: 3821430580501.9634\n",
      "Epoch 23/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3676323508616.7935 - val_loss: 3809676881960.3262\n",
      "Epoch 24/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3677404761895.9155 - val_loss: 3813642150268.2192\n",
      "Epoch 25/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3673516537107.3877 - val_loss: 3835640722439.2012\n",
      "Epoch 26/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3674308870144.0000 - val_loss: 3804823188832.8550\n",
      "Epoch 27/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3669542289381.1094 - val_loss: 3812907001156.0508\n",
      "Epoch 28/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3663356104449.5005 - val_loss: 3832790914827.1616\n",
      "Epoch 29/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3668164099477.5186 - val_loss: 3798995571016.3711\n",
      "Epoch 30/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3661871223044.2617 - val_loss: 3801812354383.5723\n",
      "Epoch 31/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 3666954169758.1621 - val_loss: 3796344845365.2881\n",
      "Epoch 32/800\n",
      "4265/4265 [==============================] - 0s 114us/step - loss: 3664062172195.7739 - val_loss: 3800293739074.9707\n",
      "Epoch 33/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3662282397659.9858 - val_loss: 3792242588198.1660\n",
      "Epoch 34/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3660783566997.8184 - val_loss: 3790970521349.4009\n",
      "Epoch 35/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3659174099582.1694 - val_loss: 3793045111267.9155\n",
      "Epoch 36/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3660996463206.1602 - val_loss: 3790261875696.1577\n",
      "Epoch 37/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3657315002177.3652 - val_loss: 3803787640394.1714\n",
      "Epoch 38/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3656361679472.7241 - val_loss: 3796876180282.6890\n",
      "Epoch 39/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3654174796349.8242 - val_loss: 3787208197109.9185\n",
      "Epoch 40/800\n",
      "4265/4265 [==============================] - 1s 118us/step - loss: 3651971274858.1216 - val_loss: 3795001005996.4668\n",
      "Epoch 41/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 3658099085084.3911 - val_loss: 3793477443134.6499\n",
      "Epoch 42/800\n",
      "4265/4265 [==============================] - 1s 130us/step - loss: 3652521722309.2974 - val_loss: 3785045520170.8467\n",
      "Epoch 43/800\n",
      "4265/4265 [==============================] - 1s 155us/step - loss: 3652679725994.2866 - val_loss: 3793580610993.5078\n",
      "Epoch 44/800\n",
      "4265/4265 [==============================] - 1s 181us/step - loss: 3652839596648.5610 - val_loss: 3780147179237.7158\n",
      "Epoch 45/800\n",
      "4265/4265 [==============================] - 1s 166us/step - loss: 3649327305164.0195 - val_loss: 3781580886436.5459\n",
      "Epoch 46/800\n",
      "4265/4265 [==============================] - 1s 121us/step - loss: 3650384856169.4009 - val_loss: 3777781822955.1167\n",
      "Epoch 47/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3648410086848.7354 - val_loss: 3780976057181.2544\n",
      "Epoch 48/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3644116155344.2212 - val_loss: 3780358805028.7256\n",
      "Epoch 49/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3644363605204.9629 - val_loss: 3787432438627.0156\n",
      "Epoch 50/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3642400708979.1851 - val_loss: 3780379636443.6343\n",
      "Epoch 51/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3644031821191.5928 - val_loss: 3774366202774.8638\n",
      "Epoch 52/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3642346643515.5435 - val_loss: 3779062297584.1577\n",
      "Epoch 53/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3635716155159.1089 - val_loss: 3779756811426.7456\n",
      "Epoch 54/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3641106563302.4897 - val_loss: 3775323269503.1001\n",
      "Epoch 55/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3638865708018.3145 - val_loss: 3773232179997.8848\n",
      "Epoch 56/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3635087575166.2891 - val_loss: 3768646808030.1548\n",
      "Epoch 57/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3639881716759.7695 - val_loss: 3768183574142.0195\n",
      "Epoch 58/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3637341333835.8096 - val_loss: 3766497994121.1816\n",
      "Epoch 59/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3638974693787.0405 - val_loss: 3765544755948.9170\n",
      "Epoch 60/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3635556555453.5542 - val_loss: 3765391358939.9941\n",
      "Epoch 61/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3633761475211.6143 - val_loss: 3767284061847.9438\n",
      "Epoch 62/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3634984771632.0186 - val_loss: 3764953292719.3472\n",
      "Epoch 63/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3635587364288.2549 - val_loss: 3766569578974.1548\n",
      "Epoch 64/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 66us/step - loss: 3632548073390.3682 - val_loss: 3764205275691.9268\n",
      "Epoch 65/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3626863729064.9658 - val_loss: 3764367905995.0718\n",
      "Epoch 66/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3630606873099.4043 - val_loss: 3763506709493.9185\n",
      "Epoch 67/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3628327297579.0967 - val_loss: 3759923533579.1616\n",
      "Epoch 68/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3628814836124.9609 - val_loss: 3758002459390.1997\n",
      "Epoch 69/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3626671581477.3945 - val_loss: 3775513681908.4780\n",
      "Epoch 70/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3625949126104.7446 - val_loss: 3758600848235.6567\n",
      "Epoch 71/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3625655942165.3682 - val_loss: 3756652957932.1968\n",
      "Epoch 72/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3627268663731.5303 - val_loss: 3755806516340.6582\n",
      "Epoch 73/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3624423623904.0073 - val_loss: 3772289967358.9199\n",
      "Epoch 74/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3627234046955.5918 - val_loss: 3752962989123.6904\n",
      "Epoch 75/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3626782872976.2363 - val_loss: 3760121300395.7471\n",
      "Epoch 76/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3622021075019.8696 - val_loss: 3770833074610.9478\n",
      "Epoch 77/800\n",
      "4265/4265 [==============================] - 1s 123us/step - loss: 3622044854722.8960 - val_loss: 3755191699067.1392\n",
      "Epoch 78/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3618327646533.5674 - val_loss: 3752743706589.4346\n",
      "Epoch 79/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3622350332324.6445 - val_loss: 3753076466873.7891\n",
      "Epoch 80/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3619941795478.4189 - val_loss: 3751282859190.9087\n",
      "Epoch 81/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3617935598534.1377 - val_loss: 3761717122089.7666\n",
      "Epoch 82/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3620163241699.2490 - val_loss: 3747988497386.3965\n",
      "Epoch 83/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3617020727529.3711 - val_loss: 3749305696878.1772\n",
      "Epoch 84/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 3617808902034.0371 - val_loss: 3745737686602.1714\n",
      "Epoch 85/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3616761230046.6870 - val_loss: 3748327376944.9678\n",
      "Epoch 86/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3616781537816.8496 - val_loss: 3744076792729.7441\n",
      "Epoch 87/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3615714675597.9556 - val_loss: 3744566706314.2617\n",
      "Epoch 88/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3612767617162.2939 - val_loss: 3772689547448.3486\n",
      "Epoch 89/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3607926508829.4717 - val_loss: 3741782150436.3657\n",
      "Epoch 90/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3610374662057.0859 - val_loss: 3749870493315.7808\n",
      "Epoch 91/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3610940857079.1763 - val_loss: 3742097548381.6147\n",
      "Epoch 92/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3612871830865.3315 - val_loss: 3740067462845.3896\n",
      "Epoch 93/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3611663510212.2764 - val_loss: 3744331679286.0083\n",
      "Epoch 94/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3603993489562.6206 - val_loss: 3768385249521.9580\n",
      "Epoch 95/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3607289917479.3755 - val_loss: 3737402243322.5991\n",
      "Epoch 96/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3607681238605.4302 - val_loss: 3741737279199.9551\n",
      "Epoch 97/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3604406334355.2378 - val_loss: 3754206086663.9214\n",
      "Epoch 98/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3609816830319.8237 - val_loss: 3735329647689.4517\n",
      "Epoch 99/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3607279959633.7520 - val_loss: 3734782003802.0142\n",
      "Epoch 100/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3607754344881.6094 - val_loss: 3739037549949.6597\n",
      "Epoch 101/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3605537649808.7764 - val_loss: 3733268637641.2715\n",
      "Epoch 102/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3605105983030.8613 - val_loss: 3735908072296.7764\n",
      "Epoch 103/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3602938334393.5923 - val_loss: 3736440130967.5835\n",
      "Epoch 104/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3605547858734.8784 - val_loss: 3736702416547.4653\n",
      "Epoch 105/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3603089912815.4331 - val_loss: 3731027202837.2432\n",
      "Epoch 106/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3601677004904.6807 - val_loss: 3736446726967.8086\n",
      "Epoch 107/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3598804454124.6123 - val_loss: 3732029319251.5332\n",
      "Epoch 108/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3601945371828.3101 - val_loss: 3728641330376.1914\n",
      "Epoch 109/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3599761734496.8179 - val_loss: 3749956911242.2617\n",
      "Epoch 110/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3602665749133.5352 - val_loss: 3746720965886.9199\n",
      "Epoch 111/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3595472445491.8599 - val_loss: 3726678245675.5669\n",
      "Epoch 112/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3593963941439.5049 - val_loss: 3728628444394.7568\n",
      "Epoch 113/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3595706737444.7944 - val_loss: 3732980509308.5796\n",
      "Epoch 114/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3596871968938.4663 - val_loss: 3725276289608.7314\n",
      "Epoch 115/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3596123229742.2183 - val_loss: 3724668096356.4556\n",
      "Epoch 116/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3596460923427.8940 - val_loss: 3724074902829.0068\n",
      "Epoch 117/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3594137704435.0352 - val_loss: 3737669667809.7554\n",
      "Epoch 118/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3594888690755.4663 - val_loss: 3724916647213.0068\n",
      "Epoch 119/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3592792608659.4775 - val_loss: 3725841130658.7456\n",
      "Epoch 120/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3593506360828.2783 - val_loss: 3721042582526.5596\n",
      "Epoch 121/800\n",
      "4265/4265 [==============================] - 0s 111us/step - loss: 3591394557030.0396 - val_loss: 3729358569264.6074\n",
      "Epoch 122/800\n",
      "4265/4265 [==============================] - 0s 113us/step - loss: 3594100175494.3320 - val_loss: 3724709459066.4189\n",
      "Epoch 123/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3591235389831.3530 - val_loss: 3719229741732.9058\n",
      "Epoch 124/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3591625806637.4375 - val_loss: 3721344193762.1152\n",
      "Epoch 125/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3589297876735.5796 - val_loss: 3723544566713.4292\n",
      "Epoch 126/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3591835963271.9531 - val_loss: 3719144563736.4839\n",
      "Epoch 127/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 74us/step - loss: 3590502757217.2979 - val_loss: 3723666400994.8354\n",
      "Epoch 128/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3589366798757.1245 - val_loss: 3717886360286.5146\n",
      "Epoch 129/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3588790038317.6782 - val_loss: 3717200378475.2969\n",
      "Epoch 130/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3588338236176.1465 - val_loss: 3715074945156.5005\n",
      "Epoch 131/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3587138405854.0269 - val_loss: 3716314700084.2080\n",
      "Epoch 132/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3585873396883.6572 - val_loss: 3724789102911.7300\n",
      "Epoch 133/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3587516971185.1890 - val_loss: 3713815858307.0605\n",
      "Epoch 134/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3586654462215.1426 - val_loss: 3720034890298.3291\n",
      "Epoch 135/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3585313316792.9321 - val_loss: 3711879497915.2295\n",
      "Epoch 136/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3584624448397.4756 - val_loss: 3717503771257.6992\n",
      "Epoch 137/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3582016659062.2461 - val_loss: 3710999087475.5781\n",
      "Epoch 138/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3582814671557.7173 - val_loss: 3717546419984.9229\n",
      "Epoch 139/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3582723051338.4888 - val_loss: 3709997486131.8481\n",
      "Epoch 140/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3580126051641.3223 - val_loss: 3710311422191.0771\n",
      "Epoch 141/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3582664971291.6108 - val_loss: 3709210442831.2124\n",
      "Epoch 142/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3580319859218.1274 - val_loss: 3710796546024.9565\n",
      "Epoch 143/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3580390835889.3091 - val_loss: 3708305620185.4741\n",
      "Epoch 144/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3579481902184.9209 - val_loss: 3708450790444.6470\n",
      "Epoch 145/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3580216168327.9531 - val_loss: 3710737348305.5527\n",
      "Epoch 146/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3576647929720.5874 - val_loss: 3705477115183.8877\n",
      "Epoch 147/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3576179919396.8545 - val_loss: 3714265674920.5063\n",
      "Epoch 148/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3578136305662.0791 - val_loss: 3704388780677.2207\n",
      "Epoch 149/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3578196940214.6514 - val_loss: 3712296931448.9790\n",
      "Epoch 150/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3576911215890.9072 - val_loss: 3704414772752.5625\n",
      "Epoch 151/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3575519953099.5996 - val_loss: 3702595359924.0283\n",
      "Epoch 152/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3574782223766.9590 - val_loss: 3716140862479.8423\n",
      "Epoch 153/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3575425977087.8198 - val_loss: 3701971075233.3052\n",
      "Epoch 154/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3573916546158.2031 - val_loss: 3708094814746.6440\n",
      "Epoch 155/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3573907071788.4775 - val_loss: 3706809439388.9844\n",
      "Epoch 156/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3574324486537.7539 - val_loss: 3699856423001.2939\n",
      "Epoch 157/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3573238600593.3169 - val_loss: 3699697433955.7354\n",
      "Epoch 158/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3574211852142.5029 - val_loss: 3702724223425.3501\n",
      "Epoch 159/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3572208691704.6772 - val_loss: 3702478422315.5669\n",
      "Epoch 160/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3572643792968.5083 - val_loss: 3698368035366.1660\n",
      "Epoch 161/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3571701679332.3291 - val_loss: 3699255906401.9351\n",
      "Epoch 162/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3571304773340.5259 - val_loss: 3696522667332.0508\n",
      "Epoch 163/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3570954849331.1401 - val_loss: 3698745506872.1689\n",
      "Epoch 164/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3570854546705.9473 - val_loss: 3695450525286.9761\n",
      "Epoch 165/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3567822326381.8428 - val_loss: 3695116050558.7397\n",
      "Epoch 166/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3568188464043.7271 - val_loss: 3703842903588.7256\n",
      "Epoch 167/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3566874442197.1431 - val_loss: 3693761674180.9507\n",
      "Epoch 168/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3564161396667.8135 - val_loss: 3700609926617.8340\n",
      "Epoch 169/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3565245588848.5439 - val_loss: 3706460973323.8818\n",
      "Epoch 170/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3567788177347.0166 - val_loss: 3695564197709.4121\n",
      "Epoch 171/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3566382143263.7524 - val_loss: 3693517098990.7173\n",
      "Epoch 172/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3565753004701.3813 - val_loss: 3691172689894.0762\n",
      "Epoch 173/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3565229465179.3555 - val_loss: 3695806787463.0210\n",
      "Epoch 174/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3562136149261.1450 - val_loss: 3692944351957.8735\n",
      "Epoch 175/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3566049489227.3296 - val_loss: 3689642039926.8184\n",
      "Epoch 176/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3563938541446.0322 - val_loss: 3689848687562.7119\n",
      "Epoch 177/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3563259240507.5435 - val_loss: 3690885394080.5850\n",
      "Epoch 178/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3561165137890.7085 - val_loss: 3702810609275.1392\n",
      "Epoch 179/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3559354275535.0811 - val_loss: 3687343037784.2139\n",
      "Epoch 180/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3560132936640.3755 - val_loss: 3689517071715.7354\n",
      "Epoch 181/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3561983434554.1631 - val_loss: 3686569111269.7158\n",
      "Epoch 182/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3560712947419.5659 - val_loss: 3686964867596.2417\n",
      "Epoch 183/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3560389291038.0117 - val_loss: 3688809827482.1040\n",
      "Epoch 184/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3558336035588.6221 - val_loss: 3688599170259.7129\n",
      "Epoch 185/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3559989379824.9341 - val_loss: 3692867535285.8286\n",
      "Epoch 186/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3559360879228.2485 - val_loss: 3684115453384.5513\n",
      "Epoch 187/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3558222224895.1597 - val_loss: 3683277984418.0254\n",
      "Epoch 188/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3556477607588.3442 - val_loss: 3693565193012.9282\n",
      "Epoch 189/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3557171500420.7119 - val_loss: 3691594369349.4907\n",
      "Epoch 190/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 67us/step - loss: 3558098706576.0562 - val_loss: 3690917048245.1084\n",
      "Epoch 191/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3557118832833.0356 - val_loss: 3681877920507.3193\n",
      "Epoch 192/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3555349286031.3359 - val_loss: 3680966025504.0449\n",
      "Epoch 193/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3554526210356.7603 - val_loss: 3680417091912.3711\n",
      "Epoch 194/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3554199322013.2012 - val_loss: 3679669979300.1855\n",
      "Epoch 195/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3553799039864.8271 - val_loss: 3683107227650.8804\n",
      "Epoch 196/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3551541958450.9600 - val_loss: 3680834309758.0195\n",
      "Epoch 197/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3553782444828.1514 - val_loss: 3685882868420.5908\n",
      "Epoch 198/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3554026888914.4424 - val_loss: 3678328488166.4360\n",
      "Epoch 199/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3551171625686.0435 - val_loss: 3685071849451.8369\n",
      "Epoch 200/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3552042741507.4214 - val_loss: 3677656560739.3755\n",
      "Epoch 201/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3548076633459.9053 - val_loss: 3677151755458.4302\n",
      "Epoch 202/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3551885905023.9702 - val_loss: 3676004278537.0015\n",
      "Epoch 203/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3548710593873.8120 - val_loss: 3676328047761.4629\n",
      "Epoch 204/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3550898134938.2002 - val_loss: 3674727491252.7480\n",
      "Epoch 205/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3547539808092.7358 - val_loss: 3687383406485.4233\n",
      "Epoch 206/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3549830535274.1216 - val_loss: 3677035780150.7285\n",
      "Epoch 207/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3547360774742.7939 - val_loss: 3673995856934.8862\n",
      "Epoch 208/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3549262537574.0996 - val_loss: 3675820616984.8438\n",
      "Epoch 209/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3548146417544.9136 - val_loss: 3675131626969.8340\n",
      "Epoch 210/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3547009596068.5845 - val_loss: 3671795714419.5781\n",
      "Epoch 211/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3546307908554.9390 - val_loss: 3672963330710.5034\n",
      "Epoch 212/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3546639391947.8394 - val_loss: 3674473827297.7554\n",
      "Epoch 213/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3546249786466.6787 - val_loss: 3671310365680.1577\n",
      "Epoch 214/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3545339644871.5781 - val_loss: 3671929983027.8481\n",
      "Epoch 215/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3544766589974.3286 - val_loss: 3669428887033.5190\n",
      "Epoch 216/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3543514571237.9497 - val_loss: 3668678307926.4136\n",
      "Epoch 217/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3543986071303.7432 - val_loss: 3669915269601.0352\n",
      "Epoch 218/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3541015420830.0415 - val_loss: 3668025929952.6753\n",
      "Epoch 219/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3542888963721.4541 - val_loss: 3667214656582.5708\n",
      "Epoch 220/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3539614591396.1641 - val_loss: 3670224984810.0366\n",
      "Epoch 221/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3542718252752.0410 - val_loss: 3672057705410.0703\n",
      "Epoch 222/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3542209873174.2686 - val_loss: 3666406625539.2407\n",
      "Epoch 223/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3537736328714.2041 - val_loss: 3666277539344.5625\n",
      "Epoch 224/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3541445990475.3892 - val_loss: 3665639511081.7666\n",
      "Epoch 225/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3539149369878.9287 - val_loss: 3670876674794.0366\n",
      "Epoch 226/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3540716857560.5649 - val_loss: 3667601267733.6035\n",
      "Epoch 227/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3539716600815.4331 - val_loss: 3663557309401.1138\n",
      "Epoch 228/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3538722589797.0796 - val_loss: 3663803078802.9028\n",
      "Epoch 229/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3536534076341.3311 - val_loss: 3668837936293.6260\n",
      "Epoch 230/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3535987210643.8374 - val_loss: 3662029133026.1152\n",
      "Epoch 231/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3537439243992.2046 - val_loss: 3661776178076.6245\n",
      "Epoch 232/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3536961284765.8613 - val_loss: 3661485575782.9761\n",
      "Epoch 233/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3537217766885.7100 - val_loss: 3661953722198.0532\n",
      "Epoch 234/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3536174864090.6055 - val_loss: 3660090098101.8286\n",
      "Epoch 235/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3536046072635.8433 - val_loss: 3659780541432.7988\n",
      "Epoch 236/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3533542498171.4683 - val_loss: 3659301839942.5708\n",
      "Epoch 237/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3535437280166.4448 - val_loss: 3660040986842.9141\n",
      "Epoch 238/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3535013824411.6406 - val_loss: 3658849537938.5430\n",
      "Epoch 239/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3533691779498.8867 - val_loss: 3665933217809.2827\n",
      "Epoch 240/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3532560213963.6592 - val_loss: 3671832069109.9185\n",
      "Epoch 241/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3533870756732.1885 - val_loss: 3657545679032.3486\n",
      "Epoch 242/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3531862896325.9575 - val_loss: 3657132319607.1787\n",
      "Epoch 243/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3533467923888.8892 - val_loss: 3657060652165.9409\n",
      "Epoch 244/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3530122330357.8560 - val_loss: 3665974776666.3740\n",
      "Epoch 245/800\n",
      "4265/4265 [==============================] - 0s 58us/step - loss: 3531358678660.6519 - val_loss: 3655400169391.3472\n",
      "Epoch 246/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3531617300834.3784 - val_loss: 3655757002311.2910\n",
      "Epoch 247/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3530757876143.6890 - val_loss: 3654297470425.8340\n",
      "Epoch 248/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3531099305642.5869 - val_loss: 3658639106359.0884\n",
      "Epoch 249/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3529323648089.0747 - val_loss: 3653134530695.3813\n",
      "Epoch 250/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3529617991147.4722 - val_loss: 3656030737426.7231\n",
      "Epoch 251/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3529208475184.1392 - val_loss: 3655352228009.9468\n",
      "Epoch 252/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3527144001707.9072 - val_loss: 3651984276743.5610\n",
      "Epoch 253/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 82us/step - loss: 3527126816217.2251 - val_loss: 3651320455870.8296\n",
      "Epoch 254/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3529134063581.4263 - val_loss: 3650985132769.3950\n",
      "Epoch 255/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3526596076217.2324 - val_loss: 3654398242487.6289\n",
      "Epoch 256/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3527572139806.3115 - val_loss: 3653407005602.3853\n",
      "Epoch 257/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3526157813183.2949 - val_loss: 3649802766361.9238\n",
      "Epoch 258/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3526521681716.8809 - val_loss: 3650106189008.8325\n",
      "Epoch 259/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3524416027338.9990 - val_loss: 3649789273135.5273\n",
      "Epoch 260/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3525468023442.3374 - val_loss: 3653423675158.6836\n",
      "Epoch 261/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3525393984757.1357 - val_loss: 3647721087494.4810\n",
      "Epoch 262/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3524900486599.4580 - val_loss: 3650010865191.6060\n",
      "Epoch 263/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3524851477441.8154 - val_loss: 3648111001438.6948\n",
      "Epoch 264/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3524096722547.8452 - val_loss: 3646400053547.5669\n",
      "Epoch 265/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3523654296556.5522 - val_loss: 3648569976869.4458\n",
      "Epoch 266/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3522100172763.9858 - val_loss: 3647532676748.4219\n",
      "Epoch 267/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3522657002806.9214 - val_loss: 3648937847121.0127\n",
      "Epoch 268/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3522850427770.2676 - val_loss: 3648440636642.1152\n",
      "Epoch 269/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3521524147049.9414 - val_loss: 3646260321946.8242\n",
      "Epoch 270/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3521278255547.6934 - val_loss: 3652663834736.3374\n",
      "Epoch 271/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3520249344004.8022 - val_loss: 3643247383340.2871\n",
      "Epoch 272/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3520206697724.3389 - val_loss: 3643251438645.2881\n",
      "Epoch 273/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3520839289211.8281 - val_loss: 3643874522119.2012\n",
      "Epoch 274/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3519879233585.9395 - val_loss: 3643767991369.4517\n",
      "Epoch 275/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3519227125646.6758 - val_loss: 3641976808242.0479\n",
      "Epoch 276/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3519170327062.9287 - val_loss: 3643263916847.1675\n",
      "Epoch 277/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3518280742781.8691 - val_loss: 3646625225288.7314\n",
      "Epoch 278/800\n",
      "4265/4265 [==============================] - 0s 115us/step - loss: 3518769832372.0103 - val_loss: 3640346676654.6274\n",
      "Epoch 279/800\n",
      "4265/4265 [==============================] - 1s 117us/step - loss: 3517275815202.2734 - val_loss: 3641690692260.9058\n",
      "Epoch 280/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3517486462442.5112 - val_loss: 3640779266978.3853\n",
      "Epoch 281/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3514396343574.7485 - val_loss: 3638873013695.9102\n",
      "Epoch 282/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3517280575712.7275 - val_loss: 3641834520092.0845\n",
      "Epoch 283/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3516241816375.5220 - val_loss: 3640000824655.5723\n",
      "Epoch 284/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3515615684970.5415 - val_loss: 3644749699264.9902\n",
      "Epoch 285/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3514510828958.6421 - val_loss: 3637088916199.1562\n",
      "Epoch 286/800\n",
      "4265/4265 [==============================] - 1s 124us/step - loss: 3514715910018.1909 - val_loss: 3637986192710.9312\n",
      "Epoch 287/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3513354450249.1685 - val_loss: 3636218214673.6426\n",
      "Epoch 288/800\n",
      "4265/4265 [==============================] - 1s 155us/step - loss: 3509671204612.8618 - val_loss: 3650045105032.4614\n",
      "Epoch 289/800\n",
      "4265/4265 [==============================] - 1s 189us/step - loss: 3513330049406.2295 - val_loss: 3635426286498.3853\n",
      "Epoch 290/800\n",
      "4265/4265 [==============================] - 1s 129us/step - loss: 3513765344650.4741 - val_loss: 3634992764844.4668\n",
      "Epoch 291/800\n",
      "4265/4265 [==============================] - 1s 188us/step - loss: 3510920204667.3481 - val_loss: 3648954062810.5542\n",
      "Epoch 292/800\n",
      "4265/4265 [==============================] - 1s 145us/step - loss: 3513394047207.9307 - val_loss: 3634234536736.7651\n",
      "Epoch 293/800\n",
      "4265/4265 [==============================] - 0s 115us/step - loss: 3511766347969.0356 - val_loss: 3634304228696.2139\n",
      "Epoch 294/800\n",
      "4265/4265 [==============================] - 1s 195us/step - loss: 3508524448739.4287 - val_loss: 3651223027527.6514\n",
      "Epoch 295/800\n",
      "4265/4265 [==============================] - 1s 122us/step - loss: 3509428433146.6577 - val_loss: 3632831482688.4502\n",
      "Epoch 296/800\n",
      "4265/4265 [==============================] - 1s 141us/step - loss: 3510189209331.5752 - val_loss: 3636256656561.1475\n",
      "Epoch 297/800\n",
      "4265/4265 [==============================] - 1s 146us/step - loss: 3510084223671.3115 - val_loss: 3633097962941.0293\n",
      "Epoch 298/800\n",
      "4265/4265 [==============================] - 1s 201us/step - loss: 3509790991697.8120 - val_loss: 3631479044185.2939\n",
      "Epoch 299/800\n",
      "4265/4265 [==============================] - 1s 153us/step - loss: 3508123302253.4224 - val_loss: 3634861408578.6104\n",
      "Epoch 300/800\n",
      "4265/4265 [==============================] - 1s 177us/step - loss: 3507442831009.4634 - val_loss: 3636621092025.7891\n",
      "Epoch 301/800\n",
      "4265/4265 [==============================] - 1s 163us/step - loss: 3507223899895.8970 - val_loss: 3640568283458.6104\n",
      "Epoch 302/800\n",
      "4265/4265 [==============================] - 1s 134us/step - loss: 3510457618296.5874 - val_loss: 3633619976814.1772\n",
      "Epoch 303/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 3506930713866.7441 - val_loss: 3635060308034.2505\n",
      "Epoch 304/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3507165881558.8838 - val_loss: 3629197020936.2812\n",
      "Epoch 305/800\n",
      "4265/4265 [==============================] - 1s 162us/step - loss: 3507481122349.7378 - val_loss: 3629396499984.5625\n",
      "Epoch 306/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3506777684832.8179 - val_loss: 3628941040454.2109\n",
      "Epoch 307/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3507028087486.0342 - val_loss: 3628899793146.5991\n",
      "Epoch 308/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3504838783664.5894 - val_loss: 3633254174218.8018\n",
      "Epoch 309/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3504593448718.9458 - val_loss: 3626885911132.8945\n",
      "Epoch 310/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3505267691138.7310 - val_loss: 3630701004848.9678\n",
      "Epoch 311/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3505905109763.6611 - val_loss: 3630588647939.6006\n",
      "Epoch 312/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3504242870978.3560 - val_loss: 3627238143444.0732\n",
      "Epoch 313/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3504086668803.4814 - val_loss: 3627723551912.5063\n",
      "Epoch 314/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3504119707337.3188 - val_loss: 3627089048030.1548\n",
      "Epoch 315/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3501734131201.5605 - val_loss: 3629087811598.4023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 316/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3503132125177.7578 - val_loss: 3630995451552.5850\n",
      "Epoch 317/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 3501927226164.6406 - val_loss: 3626821613956.8608\n",
      "Epoch 318/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3501071846973.5840 - val_loss: 3629140249247.1450\n",
      "Epoch 319/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3500807471276.8677 - val_loss: 3625889515799.4038\n",
      "Epoch 320/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3499988222597.3721 - val_loss: 3622854494418.2729\n",
      "Epoch 321/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3501565616802.1836 - val_loss: 3624504524984.3486\n",
      "Epoch 322/800\n",
      "4265/4265 [==============================] - 1s 149us/step - loss: 3500205701408.5928 - val_loss: 3622246460074.6665\n",
      "Epoch 323/800\n",
      "4265/4265 [==============================] - 1s 129us/step - loss: 3499394573999.3882 - val_loss: 3621625957484.0171\n",
      "Epoch 324/800\n",
      "4265/4265 [==============================] - 1s 138us/step - loss: 3499859334966.8018 - val_loss: 3625237046757.3560\n",
      "Epoch 325/800\n",
      "4265/4265 [==============================] - 0s 117us/step - loss: 3496964560952.1821 - val_loss: 3625003612134.0762\n",
      "Epoch 326/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3498813234491.2432 - val_loss: 3619695641152.0898\n",
      "Epoch 327/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3498729251605.4282 - val_loss: 3620051176993.8452\n",
      "Epoch 328/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3498310124991.2949 - val_loss: 3620057531497.1362\n",
      "Epoch 329/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3497883707516.3687 - val_loss: 3618865488989.6147\n",
      "Epoch 330/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3498191415892.8730 - val_loss: 3622972135870.4697\n",
      "Epoch 331/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3497034932909.7080 - val_loss: 3620424526829.2769\n",
      "Epoch 332/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3497356357748.2056 - val_loss: 3618943839443.7129\n",
      "Epoch 333/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3496900120794.0054 - val_loss: 3617816883125.1084\n",
      "Epoch 334/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3494118795757.1523 - val_loss: 3616392236670.0195\n",
      "Epoch 335/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3495151238376.6509 - val_loss: 3620494584168.0562\n",
      "Epoch 336/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3495501410270.3872 - val_loss: 3615683925794.2056\n",
      "Epoch 337/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3494168896116.0850 - val_loss: 3615360536696.9790\n",
      "Epoch 338/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3493220831350.1265 - val_loss: 3615119989528.1235\n",
      "Epoch 339/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3493744726502.9102 - val_loss: 3616218498982.7061\n",
      "Epoch 340/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3492844593307.5806 - val_loss: 3614066255079.8765\n",
      "Epoch 341/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3493782464206.1206 - val_loss: 3614123006121.9468\n",
      "Epoch 342/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3492393972258.4536 - val_loss: 3615130843985.7329\n",
      "Epoch 343/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3493139766345.2290 - val_loss: 3612886001309.7046\n",
      "Epoch 344/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3491769690797.2280 - val_loss: 3613005141148.9844\n",
      "Epoch 345/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3488521631613.8691 - val_loss: 3612393434945.8901\n",
      "Epoch 346/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3491236203663.3359 - val_loss: 3611643077057.3501\n",
      "Epoch 347/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3491601331717.4019 - val_loss: 3613194993502.6948\n",
      "Epoch 348/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3490145734347.7197 - val_loss: 3615973881023.5498\n",
      "Epoch 349/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3488609020158.9795 - val_loss: 3612158205502.6499\n",
      "Epoch 350/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3491074675816.4409 - val_loss: 3609877824801.4854\n",
      "Epoch 351/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3491039194733.6025 - val_loss: 3610186855339.0269\n",
      "Epoch 352/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3487518985086.5898 - val_loss: 3613493714886.3911\n",
      "Epoch 353/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3488728218787.5039 - val_loss: 3609002984645.3110\n",
      "Epoch 354/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3488832938523.7310 - val_loss: 3610029239323.3643\n",
      "Epoch 355/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3488533085186.1611 - val_loss: 3609919437119.7300\n",
      "Epoch 356/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3487490886261.5259 - val_loss: 3608057009815.9438\n",
      "Epoch 357/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3485625590703.0884 - val_loss: 3607350077500.4893\n",
      "Epoch 358/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3486085857422.1357 - val_loss: 3612218729427.3530\n",
      "Epoch 359/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3485648428270.4131 - val_loss: 3606603741734.1660\n",
      "Epoch 360/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3485772192199.6982 - val_loss: 3607013814220.1519\n",
      "Epoch 361/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3485973694087.0527 - val_loss: 3606412949570.2505\n",
      "Epoch 362/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3484845778622.7544 - val_loss: 3605179315760.2476\n",
      "Epoch 363/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3483602126797.5801 - val_loss: 3612685231082.3965\n",
      "Epoch 364/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3484011240709.4624 - val_loss: 3604643607720.5063\n",
      "Epoch 365/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3483873239933.1489 - val_loss: 3607368264616.1465\n",
      "Epoch 366/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3483444521522.2993 - val_loss: 3608387868358.0308\n",
      "Epoch 367/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3484102314298.5225 - val_loss: 3603818263374.8525\n",
      "Epoch 368/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3483028663318.3286 - val_loss: 3604583145368.3037\n",
      "Epoch 369/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3482967026564.3521 - val_loss: 3603579098453.3335\n",
      "Epoch 370/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3481962236633.4048 - val_loss: 3601851019027.8032\n",
      "Epoch 371/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3481066543290.7930 - val_loss: 3613031720928.3149\n",
      "Epoch 372/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3483096306458.2305 - val_loss: 3601958757999.6177\n",
      "Epoch 373/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3479861168669.1714 - val_loss: 3609325270967.9888\n",
      "Epoch 374/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3481499669838.9307 - val_loss: 3602120947340.4219\n",
      "Epoch 375/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3480280991854.9233 - val_loss: 3601269511371.0718\n",
      "Epoch 376/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3479943354593.2080 - val_loss: 3599943520653.5020\n",
      "Epoch 377/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3479320448143.3359 - val_loss: 3599204061466.2842\n",
      "Epoch 378/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3478079447260.8862 - val_loss: 3598714867579.4995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3479379191386.8755 - val_loss: 3598673170829.5020\n",
      "Epoch 380/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3479295029210.5449 - val_loss: 3599667381260.9619\n",
      "Epoch 381/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3476514466634.7290 - val_loss: 3599401588260.7256\n",
      "Epoch 382/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3478026078799.1108 - val_loss: 3598842061618.0479\n",
      "Epoch 383/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3477702816156.0010 - val_loss: 3597763916807.2012\n",
      "Epoch 384/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3476918210497.5757 - val_loss: 3596684530222.8071\n",
      "Epoch 385/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3476691397915.5508 - val_loss: 3600989259525.4009\n",
      "Epoch 386/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3475798436648.1558 - val_loss: 3598085800512.0898\n",
      "Epoch 387/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3475494305016.0171 - val_loss: 3597387521160.8213\n",
      "Epoch 388/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3476259811286.7036 - val_loss: 3598816078022.7510\n",
      "Epoch 389/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3475634944565.1807 - val_loss: 3596838548487.2012\n",
      "Epoch 390/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3475292399125.7285 - val_loss: 3594647126039.0435\n",
      "Epoch 391/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3474776344414.1768 - val_loss: 3598332160936.1465\n",
      "Epoch 392/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3473925794942.0493 - val_loss: 3596761292696.3037\n",
      "Epoch 393/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3474059316835.9990 - val_loss: 3595206929942.3237\n",
      "Epoch 394/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3473635211237.5898 - val_loss: 3594061461685.4683\n",
      "Epoch 395/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3473000872297.5811 - val_loss: 3595283729654.2783\n",
      "Epoch 396/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3472755682652.8564 - val_loss: 3592910498359.4487\n",
      "Epoch 397/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3471825697955.5039 - val_loss: 3591746004199.8765\n",
      "Epoch 398/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3471328625727.1445 - val_loss: 3600174997492.4780\n",
      "Epoch 399/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3471738366326.0659 - val_loss: 3592240230071.6289\n",
      "Epoch 400/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3471150404316.7661 - val_loss: 3590083023498.9819\n",
      "Epoch 401/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3470374764290.4609 - val_loss: 3594361650854.3462\n",
      "Epoch 402/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3469783049718.9961 - val_loss: 3597443810593.4854\n",
      "Epoch 403/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3470696067614.6123 - val_loss: 3591856216395.2520\n",
      "Epoch 404/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3470637512174.3535 - val_loss: 3588724256670.0649\n",
      "Epoch 405/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3469404328284.6162 - val_loss: 3592659559448.4839\n",
      "Epoch 406/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3469687280248.8872 - val_loss: 3589847739488.4951\n",
      "Epoch 407/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3468298226289.6846 - val_loss: 3587416585430.5938\n",
      "Epoch 408/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3468737618955.2847 - val_loss: 3591497449287.6514\n",
      "Epoch 409/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3468480904870.2646 - val_loss: 3586575390774.7285\n",
      "Epoch 410/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3467512325323.3594 - val_loss: 3587729689708.0171\n",
      "Epoch 411/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3467544938311.1279 - val_loss: 3585878932789.6484\n",
      "Epoch 412/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3466772380704.8931 - val_loss: 3589173775007.1450\n",
      "Epoch 413/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3463973134299.5059 - val_loss: 3585320812728.3486\n",
      "Epoch 414/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3466771249029.5522 - val_loss: 3585783430154.0815\n",
      "Epoch 415/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3466963290253.6553 - val_loss: 3585052476083.3081\n",
      "Epoch 416/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3465684177874.6226 - val_loss: 3584212706812.3994\n",
      "Epoch 417/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3465042209284.2017 - val_loss: 3586330153403.5894\n",
      "Epoch 418/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3464870181479.1201 - val_loss: 3585329706820.7705\n",
      "Epoch 419/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3464500060519.1802 - val_loss: 3584883247936.4502\n",
      "Epoch 420/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3463030164715.5322 - val_loss: 3586829378814.9199\n",
      "Epoch 421/800\n",
      "4265/4265 [==============================] - 0s 57us/step - loss: 3461872191814.0474 - val_loss: 3591987156032.8101\n",
      "Epoch 422/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3463754808606.4321 - val_loss: 3585741261102.4473\n",
      "Epoch 423/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3463872306894.6011 - val_loss: 3585760805394.0029\n",
      "Epoch 424/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3462155117164.4023 - val_loss: 3581265014409.5415\n",
      "Epoch 425/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3463432081622.1636 - val_loss: 3581683639573.9634\n",
      "Epoch 426/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3461737765046.9512 - val_loss: 3584738764929.6201\n",
      "Epoch 427/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3462053141058.6260 - val_loss: 3582298063078.4360\n",
      "Epoch 428/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3461770738121.6187 - val_loss: 3583262990439.6963\n",
      "Epoch 429/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3460251029272.5493 - val_loss: 3578930993736.7314\n",
      "Epoch 430/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3461114360369.8193 - val_loss: 3578930633519.1675\n",
      "Epoch 431/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3460782430502.3550 - val_loss: 3578739025796.1406\n",
      "Epoch 432/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3460057099443.8301 - val_loss: 3578680927901.7046\n",
      "Epoch 433/800\n",
      "4265/4265 [==============================] - 0s 113us/step - loss: 3459088765138.3218 - val_loss: 3580840268864.8101\n",
      "Epoch 434/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3458739039903.5425 - val_loss: 3577127243551.3247\n",
      "Epoch 435/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3459430729435.5659 - val_loss: 3578534518449.8677\n",
      "Epoch 436/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3457907934079.0698 - val_loss: 3582931480408.9341\n",
      "Epoch 437/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3457780254585.0674 - val_loss: 3577072305395.3979\n",
      "Epoch 438/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3458103678755.5938 - val_loss: 3575997259119.2573\n",
      "Epoch 439/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3457927240508.3232 - val_loss: 3575128246597.4907\n",
      "Epoch 440/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3457437750019.1812 - val_loss: 3575083923245.7271\n",
      "Epoch 441/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3457363846554.8008 - val_loss: 3575752004419.3306\n",
      "Epoch 442/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 72us/step - loss: 3456224651461.3569 - val_loss: 3575639713506.8354\n",
      "Epoch 443/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3455850662079.5947 - val_loss: 3573653378366.2896\n",
      "Epoch 444/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3457254985558.0137 - val_loss: 3574261118857.9014\n",
      "Epoch 445/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3455672653918.5972 - val_loss: 3573797706520.1235\n",
      "Epoch 446/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3455095336277.1733 - val_loss: 3573435530803.1279\n",
      "Epoch 447/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3455464115293.3965 - val_loss: 3573462100258.9253\n",
      "Epoch 448/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3453574649382.0547 - val_loss: 3574497807237.5811\n",
      "Epoch 449/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3454502938348.8525 - val_loss: 3576068959005.8848\n",
      "Epoch 450/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3454078163161.5249 - val_loss: 3571006112204.8721\n",
      "Epoch 451/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3453773549313.5005 - val_loss: 3572871343822.6724\n",
      "Epoch 452/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3453086240690.2095 - val_loss: 3574142297204.6582\n",
      "Epoch 453/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3453124732587.5469 - val_loss: 3572872028862.8296\n",
      "Epoch 454/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3452077800503.9419 - val_loss: 3570482222766.9873\n",
      "Epoch 455/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3452139132857.4121 - val_loss: 3572770921654.9087\n",
      "Epoch 456/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3452338584305.4141 - val_loss: 3573530597638.1211\n",
      "Epoch 457/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3451200020385.8828 - val_loss: 3568451906057.3613\n",
      "Epoch 458/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3450186601983.6396 - val_loss: 3568448899328.3599\n",
      "Epoch 459/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3449462812012.2222 - val_loss: 3567765618964.5234\n",
      "Epoch 460/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3451770139239.6006 - val_loss: 3567247936919.5835\n",
      "Epoch 461/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3449325833935.5610 - val_loss: 3569942811528.4614\n",
      "Epoch 462/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3449567280545.0430 - val_loss: 3567377250600.6865\n",
      "Epoch 463/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3448761048529.0620 - val_loss: 3571231331139.3306\n",
      "Epoch 464/800\n",
      "4265/4265 [==============================] - 0s 57us/step - loss: 3448400613375.0396 - val_loss: 3572912558316.1968\n",
      "Epoch 465/800\n",
      "4265/4265 [==============================] - 0s 57us/step - loss: 3448553442220.6875 - val_loss: 3570357892771.4653\n",
      "Epoch 466/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3448763698365.4336 - val_loss: 3567089196007.5161\n",
      "Epoch 467/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3447686826363.8281 - val_loss: 3564986684619.0718\n",
      "Epoch 468/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3448138801526.5459 - val_loss: 3566993678992.7427\n",
      "Epoch 469/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3446109999656.2158 - val_loss: 3566212947795.1729\n",
      "Epoch 470/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3447039816925.6064 - val_loss: 3565107849714.3179\n",
      "Epoch 471/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3446053506978.8438 - val_loss: 3566986175996.3994\n",
      "Epoch 472/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3446087421036.7622 - val_loss: 3563590565772.7822\n",
      "Epoch 473/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3446084379920.5063 - val_loss: 3563039853583.8423\n",
      "Epoch 474/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3445096876342.6812 - val_loss: 3562138479735.5386\n",
      "Epoch 475/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3445528206912.4653 - val_loss: 3562349047733.1084\n",
      "Epoch 476/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3444346959496.0132 - val_loss: 3563593652877.8623\n",
      "Epoch 477/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3444877936193.9058 - val_loss: 3562716721837.5469\n",
      "Epoch 478/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3444006250170.9131 - val_loss: 3564845388634.3740\n",
      "Epoch 479/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3443634908720.1392 - val_loss: 3560386461880.3486\n",
      "Epoch 480/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3443896020616.4932 - val_loss: 3561499893264.5625\n",
      "Epoch 481/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3443983170558.3193 - val_loss: 3562011959307.5220\n",
      "Epoch 482/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3441918040569.6372 - val_loss: 3560135995639.7188\n",
      "Epoch 483/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3443028432890.7178 - val_loss: 3559982111949.9521\n",
      "Epoch 484/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3442060335651.8940 - val_loss: 3559714070262.9985\n",
      "Epoch 485/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3441864175355.7383 - val_loss: 3557981980882.2729\n",
      "Epoch 486/800\n",
      "4265/4265 [==============================] - 0s 57us/step - loss: 3440334513608.8984 - val_loss: 3558422138355.7583\n",
      "Epoch 487/800\n",
      "4265/4265 [==============================] - 0s 57us/step - loss: 3441682520627.2603 - val_loss: 3560479089780.6582\n",
      "Epoch 488/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3440491594043.0034 - val_loss: 3556854230020.3208\n",
      "Epoch 489/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3440384666703.9512 - val_loss: 3562607920647.9214\n",
      "Epoch 490/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3437088692207.1934 - val_loss: 3556243484643.1953\n",
      "Epoch 491/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3440555133323.1943 - val_loss: 3555928386449.1025\n",
      "Epoch 492/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3439454022682.1704 - val_loss: 3556584354431.4600\n",
      "Epoch 493/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3437444877831.8032 - val_loss: 3555175922191.1226\n",
      "Epoch 494/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3439577382885.1094 - val_loss: 3554694473535.0098\n",
      "Epoch 495/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3438783102330.6279 - val_loss: 3558888596504.4839\n",
      "Epoch 496/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3436421171860.2578 - val_loss: 3554085709170.1377\n",
      "Epoch 497/800\n",
      "4265/4265 [==============================] - 0s 57us/step - loss: 3437717948258.0181 - val_loss: 3554599796044.6919\n",
      "Epoch 498/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3438385679149.9180 - val_loss: 3555067494492.1743\n",
      "Epoch 499/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3436868070403.1211 - val_loss: 3553887270217.8115\n",
      "Epoch 500/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3436722463916.6274 - val_loss: 3554572835769.4292\n",
      "Epoch 501/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3434627461159.3755 - val_loss: 3555239623920.5176\n",
      "Epoch 502/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3435243052162.8511 - val_loss: 3557421744865.3950\n",
      "Epoch 503/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3436944060693.5483 - val_loss: 3555905816256.2700\n",
      "Epoch 504/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3434341314480.2886 - val_loss: 3551032279086.0874\n",
      "Epoch 505/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 76us/step - loss: 3434972304338.6226 - val_loss: 3553587493252.8608\n",
      "Epoch 506/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3435053934044.1060 - val_loss: 3551084383800.8887\n",
      "Epoch 507/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3432668415561.5889 - val_loss: 3556680964265.9468\n",
      "Epoch 508/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3433486432963.3164 - val_loss: 3549946592196.9507\n",
      "Epoch 509/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3433631208487.1353 - val_loss: 3549668602311.1113\n",
      "Epoch 510/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3431446660443.4155 - val_loss: 3554046771015.6514\n",
      "Epoch 511/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3433479218317.8955 - val_loss: 3551014214746.7344\n",
      "Epoch 512/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3432633013521.4668 - val_loss: 3550727946862.1772\n",
      "Epoch 513/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3431313847475.3501 - val_loss: 3547778802159.4375\n",
      "Epoch 514/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3431801206730.6992 - val_loss: 3548079899430.5259\n",
      "Epoch 515/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3432193271202.4834 - val_loss: 3549668122266.8242\n",
      "Epoch 516/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3431844753612.5601 - val_loss: 3549304942217.5415\n",
      "Epoch 517/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3430889368483.0840 - val_loss: 3546441158385.2378\n",
      "Epoch 518/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3429947814722.5664 - val_loss: 3550235829940.7480\n",
      "Epoch 519/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3429604728768.6152 - val_loss: 3545609571251.6680\n",
      "Epoch 520/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3429245513091.2715 - val_loss: 3552719954784.1353\n",
      "Epoch 521/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3430499708452.6143 - val_loss: 3547450956245.5132\n",
      "Epoch 522/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3429020009600.4502 - val_loss: 3546214487150.8975\n",
      "Epoch 523/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3429547324702.9121 - val_loss: 3544318892916.2983\n",
      "Epoch 524/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3429405786611.3950 - val_loss: 3544445208348.4443\n",
      "Epoch 525/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3428692666792.0059 - val_loss: 3544549604339.0381\n",
      "Epoch 526/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3428048270619.0708 - val_loss: 3545868844572.0845\n",
      "Epoch 527/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3426866035783.3081 - val_loss: 3542713420931.0605\n",
      "Epoch 528/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3428402313393.1890 - val_loss: 3542757879226.1489\n",
      "Epoch 529/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3427796190613.0386 - val_loss: 3542463221258.8018\n",
      "Epoch 530/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3426801865759.4526 - val_loss: 3541798431080.0562\n",
      "Epoch 531/800\n",
      "4265/4265 [==============================] - 0s 58us/step - loss: 3426140494640.7993 - val_loss: 3547086287395.2856\n",
      "Epoch 532/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3426538966305.3130 - val_loss: 3543028943127.4038\n",
      "Epoch 533/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3426068862156.3198 - val_loss: 3542455705726.7397\n",
      "Epoch 534/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3425214624036.9146 - val_loss: 3540403002804.3882\n",
      "Epoch 535/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3425455290975.4370 - val_loss: 3540051626977.7554\n",
      "Epoch 536/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3424445159914.2715 - val_loss: 3542822390984.1914\n",
      "Epoch 537/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3423760077509.7173 - val_loss: 3539309679819.0718\n",
      "Epoch 538/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3423271002125.4453 - val_loss: 3542699047992.1689\n",
      "Epoch 539/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3423951015093.7510 - val_loss: 3539709779403.4316\n",
      "Epoch 540/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3423049016373.5410 - val_loss: 3538806311721.4062\n",
      "Epoch 541/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3422656523866.3955 - val_loss: 3538511691361.2153\n",
      "Epoch 542/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3421791015713.9136 - val_loss: 3537325651250.7681\n",
      "Epoch 543/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3420030624959.8350 - val_loss: 3541654727868.6694\n",
      "Epoch 544/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3422083219532.8301 - val_loss: 3543022976125.2998\n",
      "Epoch 545/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3422396037673.6562 - val_loss: 3541429875788.3320\n",
      "Epoch 546/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3420880324446.1768 - val_loss: 3542411991094.7285\n",
      "Epoch 547/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3421615584154.9204 - val_loss: 3536357726009.2490\n",
      "Epoch 548/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3420632095544.4819 - val_loss: 3537794278447.5273\n",
      "Epoch 549/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3418992681065.6411 - val_loss: 3534823372105.8115\n",
      "Epoch 550/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3420257425802.2339 - val_loss: 3534677946339.1953\n",
      "Epoch 551/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3420137530847.9478 - val_loss: 3536792554327.4937\n",
      "Epoch 552/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3420065798353.8418 - val_loss: 3534784208308.3882\n",
      "Epoch 553/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3418720067101.8921 - val_loss: 3538354314998.9985\n",
      "Epoch 554/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3419373472177.6094 - val_loss: 3537150169623.7637\n",
      "Epoch 555/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3418158365529.1348 - val_loss: 3535120823326.2446\n",
      "Epoch 556/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3416616448227.6089 - val_loss: 3532398053424.9678\n",
      "Epoch 557/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3418694820698.5757 - val_loss: 3532699739137.4404\n",
      "Epoch 558/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3418443794062.7358 - val_loss: 3535581760965.6709\n",
      "Epoch 559/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3416258191050.7588 - val_loss: 3540397849517.9072\n",
      "Epoch 560/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3414269532062.5220 - val_loss: 3546182262979.8706\n",
      "Epoch 561/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3413032292838.9102 - val_loss: 3530813017979.4995\n",
      "Epoch 562/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3416345327040.2549 - val_loss: 3532318070746.5542\n",
      "Epoch 563/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3417585573390.5254 - val_loss: 3531232484880.5625\n",
      "Epoch 564/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3414979181378.0854 - val_loss: 3538380937547.2520\n",
      "Epoch 565/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3415984045280.9678 - val_loss: 3534132572522.9365\n",
      "Epoch 566/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3415214683434.4365 - val_loss: 3530209611896.9790\n",
      "Epoch 567/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3414756468322.5586 - val_loss: 3530696210521.2939\n",
      "Epoch 568/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 80us/step - loss: 3415102147135.7451 - val_loss: 3530062180046.6724\n",
      "Epoch 569/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3413587619118.7583 - val_loss: 3532959697498.0142\n",
      "Epoch 570/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3414366375739.1230 - val_loss: 3529518614323.4883\n",
      "Epoch 571/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3413573891746.9038 - val_loss: 3528690411096.5737\n",
      "Epoch 572/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3412999969346.6260 - val_loss: 3528608547691.6567\n",
      "Epoch 573/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3413046318065.3540 - val_loss: 3526839314976.4053\n",
      "Epoch 574/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3411792642996.8506 - val_loss: 3528504068744.1011\n",
      "Epoch 575/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3411877962294.6216 - val_loss: 3526272867879.6060\n",
      "Epoch 576/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3411135097643.9971 - val_loss: 3527753499223.1338\n",
      "Epoch 577/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3410989677792.9678 - val_loss: 3530478016382.3799\n",
      "Epoch 578/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3411092050771.8525 - val_loss: 3530777131903.8198\n",
      "Epoch 579/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3410407536179.5000 - val_loss: 3527462970669.0068\n",
      "Epoch 580/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3411103638765.9331 - val_loss: 3524907470024.1914\n",
      "Epoch 581/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3409468996368.1465 - val_loss: 3524307418352.5176\n",
      "Epoch 582/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3409626091676.5410 - val_loss: 3523330770462.9648\n",
      "Epoch 583/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3410035444099.5112 - val_loss: 3524021072672.7651\n",
      "Epoch 584/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3409241893430.1411 - val_loss: 3525126636787.3979\n",
      "Epoch 585/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3408839568033.7031 - val_loss: 3524713802018.9253\n",
      "Epoch 586/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3408004522673.5493 - val_loss: 3523502611938.4756\n",
      "Epoch 587/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3407684635326.5142 - val_loss: 3521566579318.8184\n",
      "Epoch 588/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3407636150057.3560 - val_loss: 3526300400004.8608\n",
      "Epoch 589/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3408319330204.6011 - val_loss: 3522991896066.1602\n",
      "Epoch 590/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3407447076991.7300 - val_loss: 3523475950308.2759\n",
      "Epoch 591/800\n",
      "4265/4265 [==============================] - 0s 56us/step - loss: 3406331570066.0371 - val_loss: 3520133297965.7271\n",
      "Epoch 592/800\n",
      "4265/4265 [==============================] - 0s 58us/step - loss: 3406892475003.7686 - val_loss: 3520460742367.9551\n",
      "Epoch 593/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3406189798964.4604 - val_loss: 3522881784893.9297\n",
      "Epoch 594/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3406440222054.4600 - val_loss: 3519510998711.6289\n",
      "Epoch 595/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3404164355241.7466 - val_loss: 3522286094177.5752\n",
      "Epoch 596/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3405280903920.9341 - val_loss: 3518384529442.5654\n",
      "Epoch 597/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3403734857467.2583 - val_loss: 3522028947504.9678\n",
      "Epoch 598/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3404231478611.2529 - val_loss: 3525560419110.5259\n",
      "Epoch 599/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3404908549481.8213 - val_loss: 3520065608402.9932\n",
      "Epoch 600/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3402687637424.7690 - val_loss: 3524284004210.8579\n",
      "Epoch 601/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3404260880657.7070 - val_loss: 3520569029593.1138\n",
      "Epoch 602/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3404148557516.1997 - val_loss: 3517662532880.2026\n",
      "Epoch 603/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3402131324002.1982 - val_loss: 3519224054266.9590\n",
      "Epoch 604/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3402620663658.6616 - val_loss: 3517284990584.2588\n",
      "Epoch 605/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3402246354725.5146 - val_loss: 3517646479786.3066\n",
      "Epoch 606/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3402196182945.4028 - val_loss: 3516581084170.0815\n",
      "Epoch 607/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3401870297264.2290 - val_loss: 3516940475851.4316\n",
      "Epoch 608/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3401444557890.9858 - val_loss: 3517190678104.5737\n",
      "Epoch 609/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3401272311704.2793 - val_loss: 3517447766891.6567\n",
      "Epoch 610/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3400880283557.7246 - val_loss: 3518130223216.3374\n",
      "Epoch 611/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3400478594129.3916 - val_loss: 3514569149985.8452\n",
      "Epoch 612/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3400436117581.7905 - val_loss: 3516065405996.6470\n",
      "Epoch 613/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3399809065507.4136 - val_loss: 3513811637151.5049\n",
      "Epoch 614/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3398511510422.1187 - val_loss: 3512117998138.3291\n",
      "Epoch 615/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3399104285923.8486 - val_loss: 3513555638603.2520\n",
      "Epoch 616/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3398917303679.4297 - val_loss: 3512973705100.7822\n",
      "Epoch 617/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3399160546144.3379 - val_loss: 3511408142788.2305\n",
      "Epoch 618/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3397593898183.9980 - val_loss: 3511438149611.8369\n",
      "Epoch 619/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3397961023818.3691 - val_loss: 3510898690811.3193\n",
      "Epoch 620/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3397139430778.6279 - val_loss: 3510132807435.1616\n",
      "Epoch 621/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3397312157183.6396 - val_loss: 3511328064617.1362\n",
      "Epoch 622/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3396923028294.4077 - val_loss: 3511384411935.3247\n",
      "Epoch 623/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3396077268159.3545 - val_loss: 3508970454671.3022\n",
      "Epoch 624/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3394035148328.9360 - val_loss: 3513448254318.5371\n",
      "Epoch 625/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3395144186060.0796 - val_loss: 3515981506274.8354\n",
      "Epoch 626/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3396665864046.9829 - val_loss: 3509220279378.0928\n",
      "Epoch 627/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3395728894825.4614 - val_loss: 3510748572261.5356\n",
      "Epoch 628/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3395192344909.2505 - val_loss: 3508166842100.1182\n",
      "Epoch 629/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3394648859763.0054 - val_loss: 3507424302813.0747\n",
      "Epoch 630/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3394496475179.2168 - val_loss: 3509180849380.9956\n",
      "Epoch 631/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 57us/step - loss: 3394265598074.4478 - val_loss: 3507372305389.2769\n",
      "Epoch 632/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3393817355651.7515 - val_loss: 3506243112182.2783\n",
      "Epoch 633/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3393650980261.3647 - val_loss: 3508683268361.0015\n",
      "Epoch 634/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3393280321184.0225 - val_loss: 3505124892522.2168\n",
      "Epoch 635/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3392767428181.1133 - val_loss: 3505674135082.4868\n",
      "Epoch 636/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3392704034509.1602 - val_loss: 3507037044229.0410\n",
      "Epoch 637/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3392205858387.1924 - val_loss: 3505156705226.7119\n",
      "Epoch 638/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3391843729592.3921 - val_loss: 3505307511028.8384\n",
      "Epoch 639/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3391343991669.9463 - val_loss: 3508560512704.2700\n",
      "Epoch 640/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3391534483632.2290 - val_loss: 3505062959803.9492\n",
      "Epoch 641/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3391172800758.8164 - val_loss: 3504017331910.0308\n",
      "Epoch 642/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3388962895369.2437 - val_loss: 3505281023055.2124\n",
      "Epoch 643/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3390440791082.4966 - val_loss: 3503030383715.3755\n",
      "Epoch 644/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3390404149559.1616 - val_loss: 3503929715347.6230\n",
      "Epoch 645/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3389165555115.6069 - val_loss: 3501390738254.8525\n",
      "Epoch 646/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3390162445292.5522 - val_loss: 3506250078354.9028\n",
      "Epoch 647/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3389246565294.6084 - val_loss: 3501222569744.9229\n",
      "Epoch 648/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3388719235932.4961 - val_loss: 3506431709120.6299\n",
      "Epoch 649/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3386761002673.7896 - val_loss: 3510429483653.2207\n",
      "Epoch 650/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3389701993751.2295 - val_loss: 3502527509672.5063\n",
      "Epoch 651/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3387793866936.3921 - val_loss: 3499590431336.4165\n",
      "Epoch 652/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3387966918670.4058 - val_loss: 3498897020637.0747\n",
      "Epoch 653/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3387943797139.3574 - val_loss: 3499204456926.1548\n",
      "Epoch 654/800\n",
      "4265/4265 [==============================] - 0s 56us/step - loss: 3386676127453.4868 - val_loss: 3503744576792.8438\n",
      "Epoch 655/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3386260565167.9888 - val_loss: 3502583608857.2041\n",
      "Epoch 656/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3387166414239.6021 - val_loss: 3500626095546.1489\n",
      "Epoch 657/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3386423208893.9741 - val_loss: 3497269878449.8677\n",
      "Epoch 658/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3385428513904.1240 - val_loss: 3496987632687.5273\n",
      "Epoch 659/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3385139002869.5562 - val_loss: 3497629898391.9438\n",
      "Epoch 660/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3385457800029.4565 - val_loss: 3499566506548.5684\n",
      "Epoch 661/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3385124045234.0894 - val_loss: 3497101538495.5498\n",
      "Epoch 662/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3384712254994.8477 - val_loss: 3498505221173.2881\n",
      "Epoch 663/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3384435683240.6060 - val_loss: 3496231100957.5244\n",
      "Epoch 664/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3383131165389.3999 - val_loss: 3494825833986.1602\n",
      "Epoch 665/800\n",
      "4265/4265 [==============================] - 0s 55us/step - loss: 3383166304670.8818 - val_loss: 3494544053520.2026\n",
      "Epoch 666/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3383435049905.4893 - val_loss: 3494306228077.0972\n",
      "Epoch 667/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3381615082332.9761 - val_loss: 3502787404617.0913\n",
      "Epoch 668/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3383185608979.6274 - val_loss: 3497465096828.5796\n",
      "Epoch 669/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3382243654350.8408 - val_loss: 3494054789212.1743\n",
      "Epoch 670/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3381138188923.2881 - val_loss: 3492815521334.0083\n",
      "Epoch 671/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3381993781763.2417 - val_loss: 3493051211649.2603\n",
      "Epoch 672/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3381961476402.8398 - val_loss: 3492261715034.7344\n",
      "Epoch 673/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3381444610919.5405 - val_loss: 3493045063985.3276\n",
      "Epoch 674/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3380713273413.6270 - val_loss: 3492621263412.5684\n",
      "Epoch 675/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3380838735993.0073 - val_loss: 3492306563411.8931\n",
      "Epoch 676/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3380215797551.1182 - val_loss: 3494558361199.6177\n",
      "Epoch 677/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3380160235192.9922 - val_loss: 3491912437834.8916\n",
      "Epoch 678/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3379826135861.1206 - val_loss: 3491103321714.4980\n",
      "Epoch 679/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3378653838157.6104 - val_loss: 3494454240626.1377\n",
      "Epoch 680/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3379180850703.4863 - val_loss: 3489650102300.8047\n",
      "Epoch 681/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3379176901149.1714 - val_loss: 3489598718389.8286\n",
      "Epoch 682/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3378600722220.7173 - val_loss: 3488792656929.1250\n",
      "Epoch 683/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3379276847897.7500 - val_loss: 3489782351552.2700\n",
      "Epoch 684/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3377155482642.9673 - val_loss: 3489568353192.1465\n",
      "Epoch 685/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3377639707049.4463 - val_loss: 3491060729029.3110\n",
      "Epoch 686/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3377013598754.9336 - val_loss: 3490212728952.9790\n",
      "Epoch 687/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3377582085892.8618 - val_loss: 3488048445598.4248\n",
      "Epoch 688/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3376346056465.3467 - val_loss: 3487651131893.1982\n",
      "Epoch 689/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 3376521947805.8613 - val_loss: 3487785514797.7271\n",
      "Epoch 690/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3374225904387.1812 - val_loss: 3486084682125.5020\n",
      "Epoch 691/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3376513138323.0576 - val_loss: 3485796079278.9873\n",
      "Epoch 692/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3375527948004.6895 - val_loss: 3486544853979.9941\n",
      "Epoch 693/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3375330673427.5078 - val_loss: 3486560607691.4316\n",
      "Epoch 694/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 68us/step - loss: 3374452851145.1387 - val_loss: 3484787786442.3516\n",
      "Epoch 695/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3373908151777.3877 - val_loss: 3488950120672.6753\n",
      "Epoch 696/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3374086229515.6445 - val_loss: 3487330773859.0156\n",
      "Epoch 697/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3372422253234.9897 - val_loss: 3483846391943.3813\n",
      "Epoch 698/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3373607660289.7407 - val_loss: 3485233433454.5371\n",
      "Epoch 699/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3373185164433.7368 - val_loss: 3484990827846.9312\n",
      "Epoch 700/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3371317651622.6250 - val_loss: 3482675164259.3755\n",
      "Epoch 701/800\n",
      "4265/4265 [==============================] - 0s 54us/step - loss: 3372441546541.6782 - val_loss: 3485086147977.1816\n",
      "Epoch 702/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3371665941857.1777 - val_loss: 3483022983997.5698\n",
      "Epoch 703/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3371293570853.5146 - val_loss: 3486034175714.8354\n",
      "Epoch 704/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3372063371645.2690 - val_loss: 3481780363552.0449\n",
      "Epoch 705/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3370964698605.3926 - val_loss: 3480996957822.0195\n",
      "Epoch 706/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3371074012284.6089 - val_loss: 3480769270088.3711\n",
      "Epoch 707/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3370868997298.8701 - val_loss: 3480895928409.2939\n",
      "Epoch 708/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3370363887299.0762 - val_loss: 3480887905918.0195\n",
      "Epoch 709/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3367177634909.8765 - val_loss: 3479795150358.3237\n",
      "Epoch 710/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3369427550972.4585 - val_loss: 3479332855174.3008\n",
      "Epoch 711/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3370049913219.9917 - val_loss: 3479565069408.4951\n",
      "Epoch 712/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3368310405662.1318 - val_loss: 3478929449109.7832\n",
      "Epoch 713/800\n",
      "4265/4265 [==============================] - 0s 56us/step - loss: 3367521940862.9492 - val_loss: 3482653955666.8130\n",
      "Epoch 714/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3368629367760.7017 - val_loss: 3478374594971.9043\n",
      "Epoch 715/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3368431371749.7100 - val_loss: 3477756876785.5977\n",
      "Epoch 716/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3368604976598.3438 - val_loss: 3478514945247.2349\n",
      "Epoch 717/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3367439216022.4785 - val_loss: 3481876630497.7554\n",
      "Epoch 718/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3367168527633.9473 - val_loss: 3479318176585.0913\n",
      "Epoch 719/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3367004401918.4995 - val_loss: 3477157425353.6313\n",
      "Epoch 720/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3367490919547.1680 - val_loss: 3477355479754.3516\n",
      "Epoch 721/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3366571909678.9380 - val_loss: 3476579087390.2446\n",
      "Epoch 722/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3365330718380.9873 - val_loss: 3475465108490.0815\n",
      "Epoch 723/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3366277223067.4609 - val_loss: 3476904286055.3359\n",
      "Epoch 724/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3363390696539.4761 - val_loss: 3474602419869.7046\n",
      "Epoch 725/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3365638933220.9292 - val_loss: 3474264518834.5879\n",
      "Epoch 726/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3365257306352.0938 - val_loss: 3475002588769.2153\n",
      "Epoch 727/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3364625288077.9556 - val_loss: 3475954661488.3374\n",
      "Epoch 728/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3364598703971.9390 - val_loss: 3473941227073.5303\n",
      "Epoch 729/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3363908835925.8335 - val_loss: 3475368100830.8750\n",
      "Epoch 730/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3363922685856.9229 - val_loss: 3475159175012.4556\n",
      "Epoch 731/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3363631633458.6597 - val_loss: 3473864754765.0522\n",
      "Epoch 732/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3363176332509.1265 - val_loss: 3472649439327.0547\n",
      "Epoch 733/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3362514991446.3740 - val_loss: 3472034082648.9341\n",
      "Epoch 734/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3362250307446.1860 - val_loss: 3472135131971.3306\n",
      "Epoch 735/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3361791985202.5396 - val_loss: 3471085913331.3979\n",
      "Epoch 736/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3362162128228.0591 - val_loss: 3472220714429.0293\n",
      "Epoch 737/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3361576257162.8940 - val_loss: 3475551642925.0068\n",
      "Epoch 738/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3361827619392.2251 - val_loss: 3475471799614.2896\n",
      "Epoch 739/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3360026615126.1338 - val_loss: 3477506737211.0493\n",
      "Epoch 740/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3361030623880.2529 - val_loss: 3470276499672.0337\n",
      "Epoch 741/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3359893673575.3604 - val_loss: 3469090820147.8481\n",
      "Epoch 742/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3358371603924.4229 - val_loss: 3474431730574.2222\n",
      "Epoch 743/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3358743648154.6802 - val_loss: 3468337422347.5220\n",
      "Epoch 744/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3359469974131.1250 - val_loss: 3468059166262.0083\n",
      "Epoch 745/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3359473242418.3599 - val_loss: 3468133090870.0083\n",
      "Epoch 746/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3358894317585.2866 - val_loss: 3467459574724.9507\n",
      "Epoch 747/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3358436383179.5396 - val_loss: 3467504621830.1211\n",
      "Epoch 748/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3358238595808.1279 - val_loss: 3467145798680.4839\n",
      "Epoch 749/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3357850925275.4458 - val_loss: 3468029793229.5923\n",
      "Epoch 750/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3357371794575.8159 - val_loss: 3467260058806.9087\n",
      "Epoch 751/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3357204595444.7754 - val_loss: 3470192960536.4839\n",
      "Epoch 752/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3357386456938.1816 - val_loss: 3467918322300.5796\n",
      "Epoch 753/800\n",
      "4265/4265 [==============================] - 0s 56us/step - loss: 3356840473218.4907 - val_loss: 3468359520976.1123\n",
      "Epoch 754/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3356860230732.1094 - val_loss: 3466635889518.5371\n",
      "Epoch 755/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3355415090603.1270 - val_loss: 3466257722280.1465\n",
      "Epoch 756/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3355326510762.5869 - val_loss: 3470768876525.2769\n",
      "Epoch 757/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 60us/step - loss: 3355552052760.6099 - val_loss: 3464699347727.4824\n",
      "Epoch 758/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3354493696438.4111 - val_loss: 3464293350824.8662\n",
      "Epoch 759/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3355240550825.4463 - val_loss: 3464841273447.6963\n",
      "Epoch 760/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3354308916157.4941 - val_loss: 3462849494855.6514\n",
      "Epoch 761/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3353796767514.4702 - val_loss: 3464943326364.9844\n",
      "Epoch 762/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3352504922927.3584 - val_loss: 3462108203610.0142\n",
      "Epoch 763/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3353587357298.8848 - val_loss: 3462294176158.7847\n",
      "Epoch 764/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3353798605902.9907 - val_loss: 3462300754092.8271\n",
      "Epoch 765/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3352938592325.6270 - val_loss: 3463852665376.4053\n",
      "Epoch 766/800\n",
      "4265/4265 [==============================] - ETA: 0s - loss: 3351408004723.612 - 0s 71us/step - loss: 3353375816279.7544 - val_loss: 3461776307921.5527\n",
      "Epoch 767/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3352507911491.8862 - val_loss: 3460680151863.8086\n",
      "Epoch 768/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3351828148927.9551 - val_loss: 3465007720139.7920\n",
      "Epoch 769/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3352086724696.3545 - val_loss: 3460672666196.2529\n",
      "Epoch 770/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3351531911794.6450 - val_loss: 3459746839216.4277\n",
      "Epoch 771/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3350592321102.3906 - val_loss: 3461907925225.3164\n",
      "Epoch 772/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3351125613702.6924 - val_loss: 3462369829589.8735\n",
      "Epoch 773/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3349826928724.5127 - val_loss: 3464308014297.4741\n",
      "Epoch 774/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3350740490914.6636 - val_loss: 3462295708834.7456\n",
      "Epoch 775/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3350480180939.2397 - val_loss: 3460959442146.1152\n",
      "Epoch 776/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3348733318567.2856 - val_loss: 3466813313075.8481\n",
      "Epoch 777/800\n",
      "4265/4265 [==============================] - 0s 57us/step - loss: 3350349599667.8906 - val_loss: 3459618981890.8804\n",
      "Epoch 778/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3348755315522.0854 - val_loss: 3457692977108.7935\n",
      "Epoch 779/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3349146626660.2393 - val_loss: 3456882735723.2969\n",
      "Epoch 780/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3348981571731.8979 - val_loss: 3458137182882.0254\n",
      "Epoch 781/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3348734381249.2754 - val_loss: 3456874972795.1392\n",
      "Epoch 782/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3347077518198.4263 - val_loss: 3460496564788.5684\n",
      "Epoch 783/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3347264444618.1592 - val_loss: 3455597889815.4038\n",
      "Epoch 784/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3347555273026.2061 - val_loss: 3456656329582.5371\n",
      "Epoch 785/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3347020824103.4956 - val_loss: 3460014762920.1465\n",
      "Epoch 786/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3347862480010.0537 - val_loss: 3456090551671.8989\n",
      "Epoch 787/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3346665358499.0239 - val_loss: 3454690344706.5205\n",
      "Epoch 788/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3345746212549.4775 - val_loss: 3453669439830.7734\n",
      "Epoch 789/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3346668118048.6528 - val_loss: 3454752140637.9746\n",
      "Epoch 790/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3345703116690.5171 - val_loss: 3455211782305.3052\n",
      "Epoch 791/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3345579429283.9243 - val_loss: 3454247464769.8901\n",
      "Epoch 792/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3345121180243.9131 - val_loss: 3453816601794.4302\n",
      "Epoch 793/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3344389421279.2871 - val_loss: 3458335853745.1475\n",
      "Epoch 794/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3344848130684.7285 - val_loss: 3455789288118.1885\n",
      "Epoch 795/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3343942355431.3901 - val_loss: 3452204831347.9380\n",
      "Epoch 796/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3344541381884.3389 - val_loss: 3452221479151.0771\n",
      "Epoch 797/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3342987719087.2080 - val_loss: 3451006300131.1953\n",
      "Epoch 798/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3343184560988.4961 - val_loss: 3451245694382.6274\n",
      "Epoch 799/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3343694034195.3877 - val_loss: 3452058528818.4077\n",
      "Epoch 800/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3342851351255.9644 - val_loss: 3452968771318.9985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff82c2b8dd8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train4 = model4.fit(predictors,target, epochs=800, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=True)\n",
    "model_train4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff82af37978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the plot\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(model_train1.history['val_loss'], 'r',\n",
    "         model_train2.history['val_loss'], 'y',\n",
    "         model_train3.history['val_loss'], 'g',\n",
    "         model_train4.history['val_loss'], 'b')\n",
    "plt.title(\"red:nadam , yellow:adam , green:adadelta , blue:adagrad\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.savefig(\"NeuralNetwith4HiddenLayer2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training now with more hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model 1\n",
    "model11 = Sequential()\n",
    "model11.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "model11.add(Dense(70, kernel_initializer='normal', activation='relu'))\n",
    "model11.add(Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "model11.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model11.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "#model 2\n",
    "model22 = Sequential()\n",
    "model22.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "model22.add(Dense(70, kernel_initializer='normal', activation='relu'))\n",
    "model22.add(Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "model22.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model22.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "#model 3\n",
    "model33 = Sequential()\n",
    "model33.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "model33.add(Dense(70, kernel_initializer='normal', activation='relu'))\n",
    "model33.add(Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "model33.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model33.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "#model 4\n",
    "model44 = Sequential()\n",
    "model44.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "model44.add(Dense(70, kernel_initializer='normal', activation='relu'))\n",
    "model44.add(Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "model44.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model44.add(Dense(1, kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model11 loss: mean_squared_error\n",
      "model22 loss: mean_squared_error\n",
      "model33 loss: mean_squared_error\n",
      "model44 loss: mean_squared_error\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model11.compile(loss='mean_squared_error', optimizer='nadam')\n",
    "print(\"model11 loss:\",model11.loss)\n",
    "\n",
    "# Compile model\n",
    "model22.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(\"model22 loss:\",model22.loss)\n",
    "\n",
    "# Compile model\n",
    "model33.compile(loss='mean_squared_error', optimizer='adadelta')\n",
    "print(\"model33 loss:\",model33.loss)\n",
    "\n",
    "# Compile model\n",
    "model44.compile(loss='mean_squared_error', optimizer='adagrad')\n",
    "print(\"model44 loss:\",model44.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4265 samples, validate on 2844 samples\n",
      "Epoch 1/800\n",
      "4265/4265 [==============================] - 1s 172us/step - loss: 30426485919727.6758 - val_loss: 5843251912462.0420\n",
      "Epoch 2/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 3893461385246.7319 - val_loss: 4031032817085.0293\n",
      "Epoch 3/800\n",
      "4265/4265 [==============================] - 1s 136us/step - loss: 3756702743396.6592 - val_loss: 3852033476057.8340\n",
      "Epoch 4/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3762662503491.9468 - val_loss: 3823368817195.9268\n",
      "Epoch 5/800\n",
      "4265/4265 [==============================] - 0s 117us/step - loss: 3766816094254.5786 - val_loss: 3871137846843.7695\n",
      "Epoch 6/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3728525458050.0107 - val_loss: 3866804317096.1465\n",
      "Epoch 7/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3687919301373.4189 - val_loss: 3967858688437.8291\n",
      "Epoch 8/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3705016450203.8208 - val_loss: 3947741871436.6919\n",
      "Epoch 9/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3701875645532.4360 - val_loss: 3699317818473.1362\n",
      "Epoch 10/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3682826929891.2490 - val_loss: 3839453045761.4404\n",
      "Epoch 11/800\n",
      "4265/4265 [==============================] - 0s 112us/step - loss: 3659603940202.9019 - val_loss: 3821001485800.2363\n",
      "Epoch 12/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3603863025257.2812 - val_loss: 3935112220378.1943\n",
      "Epoch 13/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3607039927987.2305 - val_loss: 3687138384064.9902\n",
      "Epoch 14/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3584341873330.5098 - val_loss: 3796679830371.0156\n",
      "Epoch 15/800\n",
      "4265/4265 [==============================] - 1s 117us/step - loss: 3580968550834.0894 - val_loss: 3602666951998.2896\n",
      "Epoch 16/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3521752842581.8936 - val_loss: 5044817534388.3887\n",
      "Epoch 17/800\n",
      "4265/4265 [==============================] - 0s 111us/step - loss: 3512675565145.4346 - val_loss: 4620998221466.8242\n",
      "Epoch 18/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3437038237938.4946 - val_loss: 3462274102786.1602\n",
      "Epoch 19/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3394365213255.4277 - val_loss: 3478273182482.3628\n",
      "Epoch 20/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3394168289207.4917 - val_loss: 3798258532328.9565\n",
      "Epoch 21/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3376005308387.1885 - val_loss: 3529846134308.7256\n",
      "Epoch 22/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3317349142415.6357 - val_loss: 3374638894234.1040\n",
      "Epoch 23/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3299042861883.8433 - val_loss: 3517088120808.9565\n",
      "Epoch 24/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3265381642098.8252 - val_loss: 3502645146331.6343\n",
      "Epoch 25/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3246598241631.7373 - val_loss: 3401115059212.9619\n",
      "Epoch 26/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3229697787342.6606 - val_loss: 3259612097632.4951\n",
      "Epoch 27/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3202835116355.6460 - val_loss: 3697390851021.5923\n",
      "Epoch 28/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3198816432793.5400 - val_loss: 3279922654166.2334\n",
      "Epoch 29/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3187524906244.5015 - val_loss: 3285881045337.6538\n",
      "Epoch 30/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3152231010756.3369 - val_loss: 3871858512776.4614\n",
      "Epoch 31/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3183464301339.1904 - val_loss: 4010683852952.6641\n",
      "Epoch 32/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 3147060231051.0742 - val_loss: 3233597472376.2588\n",
      "Epoch 33/800\n",
      "4265/4265 [==============================] - 0s 115us/step - loss: 3139655089672.7632 - val_loss: 3617580612111.1226\n",
      "Epoch 34/800\n",
      "4265/4265 [==============================] - 1s 124us/step - loss: 3138014879742.0791 - val_loss: 3209145436255.0547\n",
      "Epoch 35/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3145166737464.6621 - val_loss: 3191429708233.9917\n",
      "Epoch 36/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 3125149847723.9072 - val_loss: 3267245326819.9155\n",
      "Epoch 37/800\n",
      "4265/4265 [==============================] - 0s 116us/step - loss: 3126766376217.1499 - val_loss: 3478457712686.0874\n",
      "Epoch 38/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3133118376233.2363 - val_loss: 3373010813342.7847\n",
      "Epoch 39/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3129326060007.8706 - val_loss: 3178598461065.5415\n",
      "Epoch 40/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3105274439466.3164 - val_loss: 3205077380215.5386\n",
      "Epoch 41/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3127220463375.4258 - val_loss: 3222467223056.5625\n",
      "Epoch 42/800\n",
      "4265/4265 [==============================] - 0s 113us/step - loss: 3127731017211.7983 - val_loss: 3291439972559.3926\n",
      "Epoch 43/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3121120784565.5112 - val_loss: 3268221879216.7876\n",
      "Epoch 44/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3126444268482.7759 - val_loss: 3280285233238.4136\n",
      "Epoch 45/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3144517693383.3379 - val_loss: 3399462865498.0142\n",
      "Epoch 46/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3141398835450.6577 - val_loss: 3149079732995.9604\n",
      "Epoch 47/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3109303663061.1431 - val_loss: 3205710608035.4653\n",
      "Epoch 48/800\n",
      "4265/4265 [==============================] - 0s 116us/step - loss: 3111380201937.7817 - val_loss: 3683824849984.8101\n",
      "Epoch 49/800\n",
      "4265/4265 [==============================] - 1s 119us/step - loss: 3131500412893.4263 - val_loss: 3320269062812.2646\n",
      "Epoch 50/800\n",
      "4265/4265 [==============================] - 1s 127us/step - loss: 3112082645335.8145 - val_loss: 3215934938940.1294\n",
      "Epoch 51/800\n",
      "4265/4265 [==============================] - 1s 163us/step - loss: 3109751814301.9819 - val_loss: 3201422621659.9941\n",
      "Epoch 52/800\n",
      "4265/4265 [==============================] - 1s 144us/step - loss: 3114609255373.8203 - val_loss: 3148885803584.0898\n",
      "Epoch 53/800\n",
      "4265/4265 [==============================] - 1s 136us/step - loss: 3116004306176.6602 - val_loss: 3168735246978.3403\n",
      "Epoch 54/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3116613284390.2949 - val_loss: 3756095109969.7329\n",
      "Epoch 55/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3102212271848.5308 - val_loss: 3159634593933.1421\n",
      "Epoch 56/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3088950892515.6689 - val_loss: 3186348894429.7944\n",
      "Epoch 57/800\n",
      "4265/4265 [==============================] - 1s 120us/step - loss: 3104706605690.8081 - val_loss: 3180469230152.7314\n",
      "Epoch 58/800\n",
      "4265/4265 [==============================] - 1s 139us/step - loss: 3102036351158.9512 - val_loss: 3179706199758.6724\n",
      "Epoch 59/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3111599779468.3350 - val_loss: 3141047055712.8550\n",
      "Epoch 60/800\n",
      "4265/4265 [==============================] - 1s 125us/step - loss: 3091023653384.0430 - val_loss: 3388121793042.0029\n",
      "Epoch 61/800\n",
      "4265/4265 [==============================] - 1s 153us/step - loss: 3129929492462.2329 - val_loss: 3185407656258.6104\n",
      "Epoch 62/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3115747869908.9629 - val_loss: 3134044195095.4038\n",
      "Epoch 63/800\n",
      "4265/4265 [==============================] - 1s 156us/step - loss: 3091604045363.0200 - val_loss: 3142605014374.6162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/800\n",
      "4265/4265 [==============================] - 1s 147us/step - loss: 3083337656087.1089 - val_loss: 3146510186815.7300\n",
      "Epoch 65/800\n",
      "4265/4265 [==============================] - 1s 220us/step - loss: 3091540736572.8638 - val_loss: 3978415084631.8535\n",
      "Epoch 66/800\n",
      "4265/4265 [==============================] - 1s 218us/step - loss: 3101266377929.9189 - val_loss: 3142509789368.3486\n",
      "Epoch 67/800\n",
      "4265/4265 [==============================] - 1s 148us/step - loss: 3102513404743.8481 - val_loss: 3809415026281.8564\n",
      "Epoch 68/800\n",
      "4265/4265 [==============================] - 1s 206us/step - loss: 3089791022178.6787 - val_loss: 3454772607779.6455\n",
      "Epoch 69/800\n",
      "4265/4265 [==============================] - 1s 198us/step - loss: 3104591751461.3945 - val_loss: 3279285994877.6597\n",
      "Epoch 70/800\n",
      "4265/4265 [==============================] - 1s 170us/step - loss: 3129090441907.4702 - val_loss: 3165558911915.0269\n",
      "Epoch 71/800\n",
      "4265/4265 [==============================] - 1s 206us/step - loss: 3084847560596.9180 - val_loss: 3229451006522.3291\n",
      "Epoch 72/800\n",
      "4265/4265 [==============================] - 1s 171us/step - loss: 3090685238326.0210 - val_loss: 3319699957405.7046\n",
      "Epoch 73/800\n",
      "4265/4265 [==============================] - 1s 162us/step - loss: 3099561558077.4644 - val_loss: 3228289537526.6387\n",
      "Epoch 74/800\n",
      "4265/4265 [==============================] - 1s 157us/step - loss: 3084532826822.6777 - val_loss: 3132866533269.4233\n",
      "Epoch 75/800\n",
      "4265/4265 [==============================] - 1s 135us/step - loss: 3070783453680.0337 - val_loss: 3140126984471.4038\n",
      "Epoch 76/800\n",
      "4265/4265 [==============================] - 1s 157us/step - loss: 3073618209503.1670 - val_loss: 3214265327212.7368\n",
      "Epoch 77/800\n",
      "4265/4265 [==============================] - 1s 122us/step - loss: 3080781944285.0664 - val_loss: 3444435967158.9087\n",
      "Epoch 78/800\n",
      "4265/4265 [==============================] - 1s 120us/step - loss: 3098538309367.4165 - val_loss: 3357000007219.1279\n",
      "Epoch 79/800\n",
      "4265/4265 [==============================] - 0s 109us/step - loss: 3086107374936.5342 - val_loss: 3290193258833.0127\n",
      "Epoch 80/800\n",
      "4265/4265 [==============================] - 0s 115us/step - loss: 3097666076007.4204 - val_loss: 3159609385708.9170\n",
      "Epoch 81/800\n",
      "4265/4265 [==============================] - 0s 112us/step - loss: 3086192100246.1187 - val_loss: 3297984211695.7974\n",
      "Epoch 82/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3091475259270.9927 - val_loss: 3324206226407.5161\n",
      "Epoch 83/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3120250023652.6895 - val_loss: 3569177641213.4795\n",
      "Epoch 84/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3105102447003.0405 - val_loss: 3280946792520.0112\n",
      "Epoch 85/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3083897502583.8667 - val_loss: 3444786233574.4360\n",
      "Epoch 86/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3087096389729.9585 - val_loss: 3158242917893.0410\n",
      "Epoch 87/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3110336506241.5903 - val_loss: 3158757754329.8340\n",
      "Epoch 88/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3100496277869.9033 - val_loss: 3161913889557.2432\n",
      "Epoch 89/800\n",
      "4265/4265 [==============================] - 0s 116us/step - loss: 3100110631285.5859 - val_loss: 3512342619413.9634\n",
      "Epoch 90/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3067831799949.1748 - val_loss: 3242675452730.6890\n",
      "Epoch 91/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3084463906737.2495 - val_loss: 3134614533426.7681\n",
      "Epoch 92/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3095833604750.0156 - val_loss: 3148430188094.6499\n",
      "Epoch 93/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3091834479957.6533 - val_loss: 3565979941229.8174\n",
      "Epoch 94/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3082946625378.4985 - val_loss: 3392810358677.4233\n",
      "Epoch 95/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3068207580945.3467 - val_loss: 3368605788335.7075\n",
      "Epoch 96/800\n",
      "4265/4265 [==============================] - 1s 117us/step - loss: 3089078966424.2192 - val_loss: 3224438254665.4517\n",
      "Epoch 97/800\n",
      "4265/4265 [==============================] - 1s 120us/step - loss: 3083927894293.0684 - val_loss: 3591398715386.2393\n",
      "Epoch 98/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3091907002371.8413 - val_loss: 3144596607880.4614\n",
      "Epoch 99/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3084055439488.2100 - val_loss: 3258770690238.1099\n",
      "Epoch 100/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3089237150198.7563 - val_loss: 3167644848133.7607\n",
      "Epoch 101/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3090671543714.4834 - val_loss: 3298529513984.7202\n",
      "Epoch 102/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3083617378056.2231 - val_loss: 3287878199540.8384\n",
      "Epoch 103/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3078640948900.8247 - val_loss: 3194938205922.8354\n",
      "Epoch 104/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3082284232113.3691 - val_loss: 3161554751539.8481\n",
      "Epoch 105/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3109809595203.5264 - val_loss: 3465062922651.9043\n",
      "Epoch 106/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3099466448239.1035 - val_loss: 3175868638347.7017\n",
      "Epoch 107/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3109614433758.9868 - val_loss: 3142411371809.4854\n",
      "Epoch 108/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3060246925145.8550 - val_loss: 3161351205388.2417\n",
      "Epoch 109/800\n",
      "4265/4265 [==============================] - 0s 116us/step - loss: 3075653223141.4097 - val_loss: 3119952212261.8057\n",
      "Epoch 110/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3083466876115.0425 - val_loss: 3123665114061.5923\n",
      "Epoch 111/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3098634661024.6230 - val_loss: 3163721649329.1475\n",
      "Epoch 112/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3086683686319.9287 - val_loss: 3310498633321.8564\n",
      "Epoch 113/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3086896283567.3286 - val_loss: 3618123523396.0508\n",
      "Epoch 114/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3086629366272.3604 - val_loss: 3159308167873.7104\n",
      "Epoch 115/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 3057883537978.4629 - val_loss: 3120128678680.1235\n",
      "Epoch 116/800\n",
      "4265/4265 [==============================] - 0s 109us/step - loss: 3056590571734.6440 - val_loss: 3395772136066.3403\n",
      "Epoch 117/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3110479738895.8462 - val_loss: 3342939721318.9761\n",
      "Epoch 118/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3082197478430.0117 - val_loss: 3257788887587.2856\n",
      "Epoch 119/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3085451733677.2280 - val_loss: 3232597204611.7808\n",
      "Epoch 120/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3101010412415.0698 - val_loss: 3125212033548.2417\n",
      "Epoch 121/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3067475305928.8984 - val_loss: 3144154029907.1729\n",
      "Epoch 122/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3062945875072.4502 - val_loss: 3213418097345.7104\n",
      "Epoch 123/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3085525946059.7197 - val_loss: 3261094575782.3462\n",
      "Epoch 124/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3105924382274.3862 - val_loss: 3451584955543.2236\n",
      "Epoch 125/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3077094082455.7993 - val_loss: 3282215726913.8901\n",
      "Epoch 126/800\n",
      "4265/4265 [==============================] - 1s 129us/step - loss: 3081448652077.7979 - val_loss: 3252213962576.2925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/800\n",
      "4265/4265 [==============================] - 0s 111us/step - loss: 3076758136775.8179 - val_loss: 3163959601604.2305\n",
      "Epoch 128/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3088013317443.4062 - val_loss: 3121727015997.9297\n",
      "Epoch 129/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 3081792385001.9116 - val_loss: 3250595915421.7046\n",
      "Epoch 130/800\n",
      "4265/4265 [==============================] - 1s 128us/step - loss: 3084253203318.9062 - val_loss: 3560570028677.2207\n",
      "Epoch 131/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 3093712695220.1304 - val_loss: 3270836972456.1465\n",
      "Epoch 132/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3061121205533.9517 - val_loss: 3171120479380.3433\n",
      "Epoch 133/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 3073336894264.0020 - val_loss: 3131084079426.6104\n",
      "Epoch 134/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3079467619482.3804 - val_loss: 3273360816355.5557\n",
      "Epoch 135/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3086143844237.7153 - val_loss: 3130964008257.1704\n",
      "Epoch 136/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3072802588921.2173 - val_loss: 3893792940412.2192\n",
      "Epoch 137/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3094085330703.4258 - val_loss: 3416066369250.8354\n",
      "Epoch 138/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3108846207460.0288 - val_loss: 3512004043293.5244\n",
      "Epoch 139/800\n",
      "4265/4265 [==============================] - 0s 111us/step - loss: 3063391809367.9346 - val_loss: 3287792765299.5781\n",
      "Epoch 140/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3062092837967.4712 - val_loss: 3115616488394.7119\n",
      "Epoch 141/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3043970764733.7344 - val_loss: 3190012738800.5176\n",
      "Epoch 142/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3100371735652.5996 - val_loss: 3474680427803.7241\n",
      "Epoch 143/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3067925402935.8818 - val_loss: 3141848234511.1226\n",
      "Epoch 144/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3082104416257.4404 - val_loss: 3125257221864.5962\n",
      "Epoch 145/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3088092291289.0449 - val_loss: 3114480288827.0493\n",
      "Epoch 146/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3061919135391.0620 - val_loss: 3147606368682.3066\n",
      "Epoch 147/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3083453732589.8130 - val_loss: 3555140406287.8423\n",
      "Epoch 148/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3083558254411.9297 - val_loss: 3127510263638.0532\n",
      "Epoch 149/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3089018981607.6909 - val_loss: 3467453050252.0620\n",
      "Epoch 150/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3057342403246.6685 - val_loss: 3169209897219.2407\n",
      "Epoch 151/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3061865713455.5986 - val_loss: 3150297488106.0366\n",
      "Epoch 152/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3068491140542.8145 - val_loss: 3214709915325.3896\n",
      "Epoch 153/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3081456263780.7192 - val_loss: 3121175584848.6528\n",
      "Epoch 154/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3075274958353.8867 - val_loss: 3252311924424.9116\n",
      "Epoch 155/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3082825683876.5239 - val_loss: 3286624087528.2363\n",
      "Epoch 156/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3079115975464.1558 - val_loss: 3179540598858.8916\n",
      "Epoch 157/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3097362730592.1577 - val_loss: 3126219493128.2812\n",
      "Epoch 158/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3051518146921.5811 - val_loss: 3163988811303.6060\n",
      "Epoch 159/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 3061197453143.4546 - val_loss: 3109167720185.8789\n",
      "Epoch 160/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3083891141827.1963 - val_loss: 3129284467503.1675\n",
      "Epoch 161/800\n",
      "4265/4265 [==============================] - 1s 125us/step - loss: 3058967929548.4399 - val_loss: 3567025663510.3237\n",
      "Epoch 162/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3063795632089.1050 - val_loss: 3165518260054.0532\n",
      "Epoch 163/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3081316933046.1714 - val_loss: 3117484840300.3770\n",
      "Epoch 164/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3073899652341.6157 - val_loss: 3110040528080.8325\n",
      "Epoch 165/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3059570422540.7852 - val_loss: 3239899690659.4653\n",
      "Epoch 166/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3074607120360.9507 - val_loss: 3193863834732.0171\n",
      "Epoch 167/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3055133990172.5112 - val_loss: 3150776034743.2686\n",
      "Epoch 168/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 3059165519743.3096 - val_loss: 3435888312596.5234\n",
      "Epoch 169/800\n",
      "4265/4265 [==============================] - 0s 109us/step - loss: 3067334860636.7358 - val_loss: 3594877967612.0396\n",
      "Epoch 170/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3067276846018.2959 - val_loss: 3116598996732.7593\n",
      "Epoch 171/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3070808823318.6890 - val_loss: 3118012356247.9438\n",
      "Epoch 172/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3074589344354.7988 - val_loss: 3433325343981.6372\n",
      "Epoch 173/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3063920450740.7910 - val_loss: 3202687741508.4106\n",
      "Epoch 174/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3077849921790.0190 - val_loss: 3129409620063.0547\n",
      "Epoch 175/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3073033212087.4316 - val_loss: 3110952236154.4189\n",
      "Epoch 176/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3075531607409.9844 - val_loss: 3139315486933.1533\n",
      "Epoch 177/800\n",
      "4265/4265 [==============================] - 0s 112us/step - loss: 3066400522228.4756 - val_loss: 3284334552065.4404\n",
      "Epoch 178/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3061670917353.1309 - val_loss: 3652741391384.4839\n",
      "Epoch 179/800\n",
      "4265/4265 [==============================] - 0s 117us/step - loss: 3112546943171.9165 - val_loss: 3109461700487.0210\n",
      "Epoch 180/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3044041406487.5293 - val_loss: 3140986785083.4092\n",
      "Epoch 181/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3054955896576.5400 - val_loss: 3276228374545.2827\n",
      "Epoch 182/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3068062915595.7646 - val_loss: 3123126723378.0479\n",
      "Epoch 183/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3065576191335.9009 - val_loss: 3134461737763.6455\n",
      "Epoch 184/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3087002145458.5098 - val_loss: 3419239240400.1123\n",
      "Epoch 185/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3078765637863.4507 - val_loss: 3129375676286.3799\n",
      "Epoch 186/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3061808883340.8149 - val_loss: 3394129504155.1841\n",
      "Epoch 187/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3051080950964.3101 - val_loss: 3152961585313.3052\n",
      "Epoch 188/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3087190296840.5835 - val_loss: 3183783478400.1802\n",
      "Epoch 189/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3055721210987.3218 - val_loss: 3105088539802.1040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3055905512356.0439 - val_loss: 3113180055324.4443\n",
      "Epoch 191/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3038532563605.6987 - val_loss: 3190660972613.1309\n",
      "Epoch 192/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3070417868886.9141 - val_loss: 3099526431457.3950\n",
      "Epoch 193/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3058496526841.6372 - val_loss: 3127465681460.5684\n",
      "Epoch 194/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3064140484365.0254 - val_loss: 3131671581000.3711\n",
      "Epoch 195/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3045064359279.1035 - val_loss: 3107918130249.4517\n",
      "Epoch 196/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3069160709976.8945 - val_loss: 3149437370414.0874\n",
      "Epoch 197/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3050510229794.0332 - val_loss: 3131152636903.5161\n",
      "Epoch 198/800\n",
      "4265/4265 [==============================] - 1s 122us/step - loss: 3046761425600.4351 - val_loss: 3207139905979.5894\n",
      "Epoch 199/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3056672961411.8711 - val_loss: 3188415159524.9956\n",
      "Epoch 200/800\n",
      "4265/4265 [==============================] - 0s 109us/step - loss: 3035046763293.5913 - val_loss: 3147847116791.3589\n",
      "Epoch 201/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 3049855423338.9019 - val_loss: 3386842917085.7944\n",
      "Epoch 202/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3039731347871.8423 - val_loss: 3540189942410.9819\n",
      "Epoch 203/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3062184955553.4634 - val_loss: 3204038183882.7119\n",
      "Epoch 204/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3069624309243.7983 - val_loss: 3101407637267.8032\n",
      "Epoch 205/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3044239707114.1519 - val_loss: 3143722887458.9253\n",
      "Epoch 206/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3071792203337.5889 - val_loss: 3099356453010.9028\n",
      "Epoch 207/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3061778661487.4033 - val_loss: 3240508747770.2393\n",
      "Epoch 208/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3098710764040.0430 - val_loss: 3140870542101.2432\n",
      "Epoch 209/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 3037830065658.3579 - val_loss: 3493185022335.1001\n",
      "Epoch 210/800\n",
      "4265/4265 [==============================] - 0s 111us/step - loss: 3058125929535.6245 - val_loss: 3144497149119.5498\n",
      "Epoch 211/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 3057439724683.0146 - val_loss: 3276975356269.8174\n",
      "Epoch 212/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3046728744387.6162 - val_loss: 3131050853872.8774\n",
      "Epoch 213/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3061195389335.6797 - val_loss: 3213238684296.1011\n",
      "Epoch 214/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3051911723715.3164 - val_loss: 3148415732198.7959\n",
      "Epoch 215/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3048107500866.4458 - val_loss: 3120313300689.5527\n",
      "Epoch 216/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3047198999438.4355 - val_loss: 3101212881235.8931\n",
      "Epoch 217/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3042661334986.2192 - val_loss: 3246896360844.0620\n",
      "Epoch 218/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 3053196555689.2061 - val_loss: 3177547909952.4502\n",
      "Epoch 219/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3057968665447.0605 - val_loss: 3232764528435.4883\n",
      "Epoch 220/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3062021483599.9512 - val_loss: 3221651663576.7539\n",
      "Epoch 221/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3067511453158.6699 - val_loss: 3102518560033.4854\n",
      "Epoch 222/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3057410039502.6011 - val_loss: 3155560539183.5273\n",
      "Epoch 223/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3041041616142.1055 - val_loss: 3097629609828.4556\n",
      "Epoch 224/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3028083156739.9019 - val_loss: 3250476985740.0620\n",
      "Epoch 225/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3061773893048.0918 - val_loss: 3202746926692.0957\n",
      "Epoch 226/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3045619736789.2031 - val_loss: 3357509111882.8916\n",
      "Epoch 227/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3040755222746.4854 - val_loss: 3160352053671.4263\n",
      "Epoch 228/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3047899869480.7559 - val_loss: 3198195651141.8511\n",
      "Epoch 229/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3054748966003.4854 - val_loss: 3430582373875.7583\n",
      "Epoch 230/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3068043738240.9302 - val_loss: 3161030313111.2236\n",
      "Epoch 231/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3051957415814.0322 - val_loss: 3158369606815.8647\n",
      "Epoch 232/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3056637459677.1265 - val_loss: 3125400529832.1465\n",
      "Epoch 233/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3025554751184.5215 - val_loss: 4183040432574.4697\n",
      "Epoch 234/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3038773607748.8472 - val_loss: 3209959945315.3755\n",
      "Epoch 235/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3067283299677.8164 - val_loss: 3085161432468.7031\n",
      "Epoch 236/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3037383333959.5479 - val_loss: 3094425342234.2842\n",
      "Epoch 237/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3040547883837.2842 - val_loss: 3126911325433.1587\n",
      "Epoch 238/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3040704257865.5288 - val_loss: 3548449776134.4810\n",
      "Epoch 239/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3049301023321.6753 - val_loss: 3158724384984.0337\n",
      "Epoch 240/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3062854988979.3501 - val_loss: 3236713105433.9238\n",
      "Epoch 241/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3058299895669.7061 - val_loss: 3099111558897.2378\n",
      "Epoch 242/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3056467988959.2275 - val_loss: 3209927609428.9731\n",
      "Epoch 243/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3049128281550.6606 - val_loss: 3339015035188.2080\n",
      "Epoch 244/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3038317975431.4731 - val_loss: 3087076280829.8398\n",
      "Epoch 245/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3053457854190.2930 - val_loss: 3360790345471.6401\n",
      "Epoch 246/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3098289322844.9761 - val_loss: 3149504992505.1587\n",
      "Epoch 247/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3030284874201.4653 - val_loss: 3104252143745.6201\n",
      "Epoch 248/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3033955798823.9155 - val_loss: 3103166506261.9634\n",
      "Epoch 249/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3041113031758.5107 - val_loss: 3141467512935.6963\n",
      "Epoch 250/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3030077890584.9697 - val_loss: 3135886832186.3291\n",
      "Epoch 251/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3019257035505.4141 - val_loss: 3117816289496.0337\n",
      "Epoch 252/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3057825211153.5869 - val_loss: 3108281757897.6313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3018985830296.7593 - val_loss: 3091643259948.6470\n",
      "Epoch 254/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 3048433654899.4854 - val_loss: 3983238979618.5649\n",
      "Epoch 255/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3056837827307.6519 - val_loss: 3234321395383.6289\n",
      "Epoch 256/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3033010428425.0039 - val_loss: 3094621877969.5527\n",
      "Epoch 257/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3030769899499.3521 - val_loss: 3075038005988.2759\n",
      "Epoch 258/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3031437077660.7812 - val_loss: 3099422734148.7705\n",
      "Epoch 259/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3021891369947.7461 - val_loss: 3314029642211.9155\n",
      "Epoch 260/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3026964941218.2432 - val_loss: 3783707251822.8975\n",
      "Epoch 261/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3059675847422.8594 - val_loss: 3092029437511.2910\n",
      "Epoch 262/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3046027626829.7305 - val_loss: 3077098613418.6665\n",
      "Epoch 263/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3037259743973.4097 - val_loss: 3399255206155.8818\n",
      "Epoch 264/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3051560055971.9839 - val_loss: 3718691814133.5586\n",
      "Epoch 265/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3057449423826.6226 - val_loss: 3146972499328.5400\n",
      "Epoch 266/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3084071320497.4893 - val_loss: 3324424574662.0308\n",
      "Epoch 267/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3055931742091.3145 - val_loss: 3070628284511.0547\n",
      "Epoch 268/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3034102647897.5552 - val_loss: 3114517888609.2153\n",
      "Epoch 269/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3023079014999.2744 - val_loss: 3096190974248.6865\n",
      "Epoch 270/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3041432339315.5449 - val_loss: 3129821915426.9253\n",
      "Epoch 271/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3037753837532.9463 - val_loss: 3072822443801.5640\n",
      "Epoch 272/800\n",
      "4265/4265 [==============================] - 0s 113us/step - loss: 3024984378453.7134 - val_loss: 3113104981117.2998\n",
      "Epoch 273/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3002693919301.9873 - val_loss: 3131954536874.3066\n",
      "Epoch 274/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3028298538614.2461 - val_loss: 3077207987564.3770\n",
      "Epoch 275/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3020614897785.9678 - val_loss: 3287245674827.2520\n",
      "Epoch 276/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3052188059601.4214 - val_loss: 3076164526875.0044\n",
      "Epoch 277/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3012016411629.5127 - val_loss: 3213850043554.7456\n",
      "Epoch 278/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3027057817147.1831 - val_loss: 3204491490587.7241\n",
      "Epoch 279/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3046511244463.5088 - val_loss: 3176334498837.6035\n",
      "Epoch 280/800\n",
      "4265/4265 [==============================] - 1s 119us/step - loss: 3023474144927.0620 - val_loss: 3098328267463.4712\n",
      "Epoch 281/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3023819597614.1582 - val_loss: 3775684863415.2686\n",
      "Epoch 282/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3047207484130.0483 - val_loss: 3132174537631.5049\n",
      "Epoch 283/800\n",
      "4265/4265 [==============================] - 0s 109us/step - loss: 3029290441417.0786 - val_loss: 3073785001543.2910\n",
      "Epoch 284/800\n",
      "4265/4265 [==============================] - 0s 111us/step - loss: 3022037948241.6919 - val_loss: 3076903159810.8804\n",
      "Epoch 285/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3031573009281.9507 - val_loss: 3118068524010.3965\n",
      "Epoch 286/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3033979581154.5283 - val_loss: 3149163791626.4414\n",
      "Epoch 287/800\n",
      "4265/4265 [==============================] - 0s 115us/step - loss: 3013982811104.0674 - val_loss: 3067096735478.9985\n",
      "Epoch 288/800\n",
      "4265/4265 [==============================] - 1s 128us/step - loss: 3017675083375.5234 - val_loss: 3204524573086.7847\n",
      "Epoch 289/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3020686909126.9175 - val_loss: 3260445542633.3164\n",
      "Epoch 290/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3028949322127.0361 - val_loss: 3123721718730.7119\n",
      "Epoch 291/800\n",
      "4265/4265 [==============================] - 0s 112us/step - loss: 3018910578803.7251 - val_loss: 3078548408737.6650\n",
      "Epoch 292/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3011404964729.3076 - val_loss: 3535063474625.3501\n",
      "Epoch 293/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3026546795661.8955 - val_loss: 3097314467759.3472\n",
      "Epoch 294/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3033958464395.0742 - val_loss: 3125763315743.6851\n",
      "Epoch 295/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3019479139298.9487 - val_loss: 3370484976264.1011\n",
      "Epoch 296/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3009041360471.0342 - val_loss: 3307981020412.0396\n",
      "Epoch 297/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3051391098847.3472 - val_loss: 3123977536248.4390\n",
      "Epoch 298/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3036352481905.6846 - val_loss: 3185878080118.8184\n",
      "Epoch 299/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2996622714862.2329 - val_loss: 3143352730176.0898\n",
      "Epoch 300/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3022391697064.1855 - val_loss: 3159331934121.5864\n",
      "Epoch 301/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3023264109253.7173 - val_loss: 3131836830900.0283\n",
      "Epoch 302/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3007021855954.0820 - val_loss: 3374367372779.1167\n",
      "Epoch 303/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3046628557314.7607 - val_loss: 3220476662641.4175\n",
      "Epoch 304/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3019157761265.2944 - val_loss: 3094012819383.9888\n",
      "Epoch 305/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3017358849695.0620 - val_loss: 3064593235576.2588\n",
      "Epoch 306/800\n",
      "4265/4265 [==============================] - 0s 113us/step - loss: 3023327358300.8564 - val_loss: 3120599034331.2744\n",
      "Epoch 307/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3021558294053.0947 - val_loss: 3084364627161.4741\n",
      "Epoch 308/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3024898426599.0903 - val_loss: 3112496656239.9775\n",
      "Epoch 309/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3016097236242.4272 - val_loss: 3320846627985.4629\n",
      "Epoch 310/800\n",
      "4265/4265 [==============================] - 0s 112us/step - loss: 3033306374464.7651 - val_loss: 3479948618525.8848\n",
      "Epoch 311/800\n",
      "4265/4265 [==============================] - 0s 112us/step - loss: 3025471264528.3867 - val_loss: 3273220570421.6484\n",
      "Epoch 312/800\n",
      "4265/4265 [==============================] - 0s 112us/step - loss: 3029711259889.5342 - val_loss: 3073196541724.4443\n",
      "Epoch 313/800\n",
      "4265/4265 [==============================] - 1s 143us/step - loss: 3021732593199.1782 - val_loss: 3066202838449.5078\n",
      "Epoch 314/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 2992546718554.5757 - val_loss: 3126409968949.6484\n",
      "Epoch 315/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3027478532575.2275 - val_loss: 3214298244535.2686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 316/800\n",
      "4265/4265 [==============================] - 0s 114us/step - loss: 3049410208495.0137 - val_loss: 3070735435041.4854\n",
      "Epoch 317/800\n",
      "4265/4265 [==============================] - 0s 109us/step - loss: 3021567097481.6938 - val_loss: 3068172474906.6440\n",
      "Epoch 318/800\n",
      "4265/4265 [==============================] - 0s 109us/step - loss: 3024025612803.7217 - val_loss: 3146947739071.9102\n",
      "Epoch 319/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3001887092406.5913 - val_loss: 3534347960135.6514\n",
      "Epoch 320/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3016841967063.3042 - val_loss: 3110438846487.0435\n",
      "Epoch 321/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3016726369549.6250 - val_loss: 3172987689429.5132\n",
      "Epoch 322/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3014669237503.7002 - val_loss: 3097437482241.8003\n",
      "Epoch 323/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3012556336365.4531 - val_loss: 3081928230592.2700\n",
      "Epoch 324/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3002936140050.6675 - val_loss: 3064503033706.2168\n",
      "Epoch 325/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3006922721267.9951 - val_loss: 3218796180971.1167\n",
      "Epoch 326/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3002890227173.2300 - val_loss: 3100032244388.9058\n",
      "Epoch 327/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2999879491839.4600 - val_loss: 3055401183499.8818\n",
      "Epoch 328/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3001946081229.5801 - val_loss: 3265253638927.4824\n",
      "Epoch 329/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3013581189193.9492 - val_loss: 3054825941121.6201\n",
      "Epoch 330/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3018252262384.8740 - val_loss: 3056878942320.3374\n",
      "Epoch 331/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3004419679512.1895 - val_loss: 3046283709363.6680\n",
      "Epoch 332/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2994441285486.9829 - val_loss: 3051228032787.8032\n",
      "Epoch 333/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2995037559704.5195 - val_loss: 3065917907462.4810\n",
      "Epoch 334/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3047001002397.9219 - val_loss: 3085088019981.6821\n",
      "Epoch 335/800\n",
      "4265/4265 [==============================] - ETA: 0s - loss: 2972681641437.866 - 0s 72us/step - loss: 2991420213013.1880 - val_loss: 3058989903889.2827\n",
      "Epoch 336/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2987652145814.6587 - val_loss: 3063593959239.6514\n",
      "Epoch 337/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2995039527167.4600 - val_loss: 3109406737997.0522\n",
      "Epoch 338/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3007464116176.9414 - val_loss: 3107185402005.7832\n",
      "Epoch 339/800\n",
      "4265/4265 [==============================] - 0s 112us/step - loss: 3000722124316.9312 - val_loss: 3060357769437.7944\n",
      "Epoch 340/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3002429352943.9141 - val_loss: 3726462107025.8228\n",
      "Epoch 341/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2982127752661.3833 - val_loss: 3254650021049.7891\n",
      "Epoch 342/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3023985937386.1519 - val_loss: 3053896416104.7764\n",
      "Epoch 343/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3001789492999.2632 - val_loss: 3220394556633.4741\n",
      "Epoch 344/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3034579926563.6538 - val_loss: 3117342403196.5796\n",
      "Epoch 345/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3019733171125.3311 - val_loss: 3376374373051.9492\n",
      "Epoch 346/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2980182229606.6401 - val_loss: 3339752799841.2153\n",
      "Epoch 347/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3004532679019.0220 - val_loss: 3045777009714.4077\n",
      "Epoch 348/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2988624864901.1318 - val_loss: 3464769857458.2280\n",
      "Epoch 349/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2994025549565.6587 - val_loss: 3037217620244.5234\n",
      "Epoch 350/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 2992211158561.2529 - val_loss: 3208085876384.5850\n",
      "Epoch 351/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2992794659543.4844 - val_loss: 3060345923921.0127\n",
      "Epoch 352/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2949407790964.2651 - val_loss: 4205282663722.1270\n",
      "Epoch 353/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2993633356541.8994 - val_loss: 3538836445745.6880\n",
      "Epoch 354/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2995530061038.8931 - val_loss: 3709755959333.4458\n",
      "Epoch 355/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3018402970230.4863 - val_loss: 3033076765230.8071\n",
      "Epoch 356/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3015656013808.6343 - val_loss: 3054374121742.7622\n",
      "Epoch 357/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2976739473892.5093 - val_loss: 3051510705870.6724\n",
      "Epoch 358/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2994410736829.4336 - val_loss: 3107128531136.9902\n",
      "Epoch 359/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2984185236588.7622 - val_loss: 3050686097445.4458\n",
      "Epoch 360/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2995911852416.1504 - val_loss: 3099941895408.5176\n",
      "Epoch 361/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2974860632465.4365 - val_loss: 3078035227015.7412\n",
      "Epoch 362/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2988640246330.9429 - val_loss: 3250544575385.7441\n",
      "Epoch 363/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 2987145935486.1694 - val_loss: 3265630272383.8198\n",
      "Epoch 364/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2972138503354.5527 - val_loss: 3115445452154.7793\n",
      "Epoch 365/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3005773230676.3931 - val_loss: 3043475901939.7583\n",
      "Epoch 366/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2974400660835.0986 - val_loss: 3029138729297.0127\n",
      "Epoch 367/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2997624484759.0791 - val_loss: 3034142872433.4175\n",
      "Epoch 368/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2985969211697.8794 - val_loss: 3025737285908.5234\n",
      "Epoch 369/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2968111314095.5088 - val_loss: 3027945179184.9678\n",
      "Epoch 370/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 2967762225812.2578 - val_loss: 3077154244726.0986\n",
      "Epoch 371/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2986781752932.9595 - val_loss: 3036460088237.9072\n",
      "Epoch 372/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 2976623010658.2583 - val_loss: 3052879694840.7988\n",
      "Epoch 373/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2967702670321.8345 - val_loss: 3035712257402.7793\n",
      "Epoch 374/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3000510392636.4438 - val_loss: 3020805518112.7651\n",
      "Epoch 375/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2970504319293.8838 - val_loss: 3158748228658.4077\n",
      "Epoch 376/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 2972414110677.0234 - val_loss: 3125679422658.4302\n",
      "Epoch 377/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2986913738303.5049 - val_loss: 3031060616464.2026\n",
      "Epoch 378/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 64us/step - loss: 2974784666760.6133 - val_loss: 3083166559766.3237\n",
      "Epoch 379/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2964000169179.2056 - val_loss: 3806562367162.5093\n",
      "Epoch 380/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2977344836793.1123 - val_loss: 3415473902057.6763\n",
      "Epoch 381/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3001897440517.9424 - val_loss: 3426160115573.7383\n",
      "Epoch 382/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2991640462130.2397 - val_loss: 3253244238270.4697\n",
      "Epoch 383/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2991976470288.3867 - val_loss: 3238515326261.6484\n",
      "Epoch 384/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 2986221196987.8730 - val_loss: 3005109499739.8145\n",
      "Epoch 385/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 2953780534940.6611 - val_loss: 3189700530826.9819\n",
      "Epoch 386/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 2999949827809.8081 - val_loss: 3019529652572.5347\n",
      "Epoch 387/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2968996807639.4238 - val_loss: 3106871473689.2041\n",
      "Epoch 388/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2975777104146.6675 - val_loss: 3092579672605.5244\n",
      "Epoch 389/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2977637975310.5859 - val_loss: 3007368637928.2363\n",
      "Epoch 390/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2957376110034.9824 - val_loss: 3041502008500.0283\n",
      "Epoch 391/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2962116356481.5903 - val_loss: 3031796853971.7129\n",
      "Epoch 392/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2960891791382.5688 - val_loss: 3018966753084.1294\n",
      "Epoch 393/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2945931971977.0337 - val_loss: 3005666965731.5557\n",
      "Epoch 394/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2968942718512.1392 - val_loss: 3011518395883.1167\n",
      "Epoch 395/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 2947322645405.3213 - val_loss: 3002153118977.8003\n",
      "Epoch 396/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2987123071919.5684 - val_loss: 3010578089779.4883\n",
      "Epoch 397/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2967700895763.6880 - val_loss: 3202988753979.0493\n",
      "Epoch 398/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2966131754300.6836 - val_loss: 2997265339756.3770\n",
      "Epoch 399/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2949067774522.9429 - val_loss: 3033503300065.0352\n",
      "Epoch 400/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2931531055749.3721 - val_loss: 3245198893274.9141\n",
      "Epoch 401/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2964247727093.6763 - val_loss: 3105509724834.0254\n",
      "Epoch 402/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2963188301343.8125 - val_loss: 3092563051717.3110\n",
      "Epoch 403/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2947379826663.9907 - val_loss: 3009106342573.5469\n",
      "Epoch 404/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2944872514265.8848 - val_loss: 3172455965167.4375\n",
      "Epoch 405/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2959923881486.0454 - val_loss: 3066477148364.5117\n",
      "Epoch 406/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2964732250737.6846 - val_loss: 3040593636402.4077\n",
      "Epoch 407/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2945535217555.4775 - val_loss: 3062375898110.5596\n",
      "Epoch 408/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2931141925999.6436 - val_loss: 2984661936280.6641\n",
      "Epoch 409/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2949314402548.4155 - val_loss: 3123675825095.8311\n",
      "Epoch 410/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2926521312424.7861 - val_loss: 3000292851135.9102\n",
      "Epoch 411/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2929550133604.7798 - val_loss: 3045329512946.3179\n",
      "Epoch 412/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2934917607728.4390 - val_loss: 3528099399890.2729\n",
      "Epoch 413/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2970512830860.6348 - val_loss: 3021375781229.8174\n",
      "Epoch 414/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2960611628224.7954 - val_loss: 2991965655990.5483\n",
      "Epoch 415/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2926050352320.3149 - val_loss: 3009354009661.9297\n",
      "Epoch 416/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2930576298536.2158 - val_loss: 3955294599188.1631\n",
      "Epoch 417/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2980150930535.0005 - val_loss: 3016318107624.9565\n",
      "Epoch 418/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2924020515979.9746 - val_loss: 3065632206266.1489\n",
      "Epoch 419/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2929354331459.4062 - val_loss: 3335008637555.9380\n",
      "Epoch 420/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2942567721476.2017 - val_loss: 2978374229566.6499\n",
      "Epoch 421/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2924910637610.1367 - val_loss: 2973434933334.4136\n",
      "Epoch 422/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2923663423761.2271 - val_loss: 3051312565194.7119\n",
      "Epoch 423/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2906125873809.8569 - val_loss: 3813405221866.3965\n",
      "Epoch 424/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 2916816002993.2495 - val_loss: 2980920256895.1001\n",
      "Epoch 425/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2936896736015.1855 - val_loss: 2997456463748.1406\n",
      "Epoch 426/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2935136423781.3794 - val_loss: 2980680551462.8862\n",
      "Epoch 427/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2924745122254.9009 - val_loss: 2975745545764.7256\n",
      "Epoch 428/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2921982410425.4727 - val_loss: 3184115764908.1069\n",
      "Epoch 429/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2936679946276.9741 - val_loss: 3240220812266.3965\n",
      "Epoch 430/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2918743209097.0938 - val_loss: 3144758752240.1577\n",
      "Epoch 431/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2899625690582.3438 - val_loss: 2958318767534.6274\n",
      "Epoch 432/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 2902049875120.4688 - val_loss: 3070544242471.9663\n",
      "Epoch 433/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2925385643644.4888 - val_loss: 2982387354455.4937\n",
      "Epoch 434/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2934292724165.7773 - val_loss: 3100221047429.2207\n",
      "Epoch 435/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 2909851189962.5190 - val_loss: 3253482399228.3994\n",
      "Epoch 436/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 2916564380033.5903 - val_loss: 2945053628539.8594\n",
      "Epoch 437/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2909993339836.0532 - val_loss: 2951774010746.7793\n",
      "Epoch 438/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2915000658835.7178 - val_loss: 3004233335590.5259\n",
      "Epoch 439/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 2891217009666.1611 - val_loss: 3331229988492.4219\n",
      "Epoch 440/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2900511680816.9189 - val_loss: 3014110371413.6934\n",
      "Epoch 441/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 82us/step - loss: 2895044416800.8330 - val_loss: 2940411404506.9141\n",
      "Epoch 442/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2919995226850.0483 - val_loss: 2939813597834.9819\n",
      "Epoch 443/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2882224074495.5796 - val_loss: 3001611665154.5205\n",
      "Epoch 444/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2892046413859.5337 - val_loss: 3105314422760.9565\n",
      "Epoch 445/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 2906515387033.5400 - val_loss: 3014447298718.4248\n",
      "Epoch 446/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2910142603554.0332 - val_loss: 2951714156008.2363\n",
      "Epoch 447/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2884295815921.8945 - val_loss: 3388105792671.8647\n",
      "Epoch 448/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 2887470146936.2271 - val_loss: 3344247340940.7822\n",
      "Epoch 449/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 2897724285164.2524 - val_loss: 2958115307658.2617\n",
      "Epoch 450/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 2881429507580.2783 - val_loss: 2952861225887.5049\n",
      "Epoch 451/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 2880507077885.2988 - val_loss: 3012333065326.8975\n",
      "Epoch 452/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 2875879657109.9385 - val_loss: 2959774155996.3545\n",
      "Epoch 453/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 2938846273253.6494 - val_loss: 2926341274380.6021\n",
      "Epoch 454/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 2864528606785.9058 - val_loss: 3109132233409.7104\n",
      "Epoch 455/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 2873999320878.1582 - val_loss: 3092978218129.4629\n",
      "Epoch 456/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 2898946351382.5088 - val_loss: 3023257957083.6343\n",
      "Epoch 457/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 2869363744381.9292 - val_loss: 3013759248882.3179\n",
      "Epoch 458/800\n",
      "4265/4265 [==============================] - 0s 109us/step - loss: 2876905636358.6025 - val_loss: 2937208670326.0986\n",
      "Epoch 459/800\n",
      "4265/4265 [==============================] - 0s 111us/step - loss: 2876207698641.2417 - val_loss: 2930047481737.9014\n",
      "Epoch 460/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 2852377199974.9399 - val_loss: 3775489850401.1250\n",
      "Epoch 461/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 2910050646143.2500 - val_loss: 2914182517640.4614\n",
      "Epoch 462/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 2877342344414.5674 - val_loss: 2960123237786.4644\n",
      "Epoch 463/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 2851327568023.2593 - val_loss: 2895864696837.7607\n",
      "Epoch 464/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 2877438975272.0356 - val_loss: 2894772619312.9678\n",
      "Epoch 465/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 2850065407878.9927 - val_loss: 2897548448855.8535\n",
      "Epoch 466/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 2849636003376.1392 - val_loss: 3600898995345.4629\n",
      "Epoch 467/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2862906775946.2339 - val_loss: 2893153400437.3784\n",
      "Epoch 468/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2847379511217.7295 - val_loss: 3140406312360.8662\n",
      "Epoch 469/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2852807094284.4849 - val_loss: 3032936831583.7749\n",
      "Epoch 470/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2857851174324.2505 - val_loss: 3084404692424.5513\n",
      "Epoch 471/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2812065388108.4697 - val_loss: 3019134938554.1489\n",
      "Epoch 472/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2844582351699.8525 - val_loss: 3039004560399.8423\n",
      "Epoch 473/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2850962331854.0005 - val_loss: 2993359300138.4868\n",
      "Epoch 474/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2826680782259.2900 - val_loss: 2975922870142.3799\n",
      "Epoch 475/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 2829019202930.4648 - val_loss: 2879451934368.5850\n",
      "Epoch 476/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2816058264531.1025 - val_loss: 2861736011306.4868\n",
      "Epoch 477/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2833981530121.6035 - val_loss: 3010180333452.7822\n",
      "Epoch 478/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2795149398299.3105 - val_loss: 3618480931484.2646\n",
      "Epoch 479/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2813453926707.3203 - val_loss: 2912931481303.3135\n",
      "Epoch 480/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2787931251519.6851 - val_loss: 3682884295378.9932\n",
      "Epoch 481/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2798684747822.5786 - val_loss: 3023791834539.7471\n",
      "Epoch 482/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2815309714459.6108 - val_loss: 2859424181067.9717\n",
      "Epoch 483/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2785321646906.4028 - val_loss: 2856170179115.9268\n",
      "Epoch 484/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 2802877713812.5581 - val_loss: 2949636562678.9985\n",
      "Epoch 485/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 2790931936842.5488 - val_loss: 2925083421193.3613\n",
      "Epoch 486/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 2777836911787.1865 - val_loss: 2863583119224.6187\n",
      "Epoch 487/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2778153282655.3174 - val_loss: 3031768936926.1548\n",
      "Epoch 488/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2761736744899.4966 - val_loss: 2973960426053.8511\n",
      "Epoch 489/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 2785086963366.2646 - val_loss: 2946483732825.6538\n",
      "Epoch 490/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 2745856231665.5342 - val_loss: 2954315406864.5625\n",
      "Epoch 491/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 2715293623353.3823 - val_loss: 2944313340336.0674\n",
      "Epoch 492/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 2734696407537.4746 - val_loss: 2774724540666.5991\n",
      "Epoch 493/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2749352477878.2310 - val_loss: 2832299671667.2178\n",
      "Epoch 494/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 2726324923010.9712 - val_loss: 2789017530062.6724\n",
      "Epoch 495/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 2725569644735.5947 - val_loss: 3666882856018.0928\n",
      "Epoch 496/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 2783133255272.3203 - val_loss: 2828425789486.0874\n",
      "Epoch 497/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2746795738736.0039 - val_loss: 2759224790723.1504\n",
      "Epoch 498/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2713586140388.3291 - val_loss: 3083819361373.6147\n",
      "Epoch 499/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2719264590438.1602 - val_loss: 3297704658900.7935\n",
      "Epoch 500/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2707273848949.6460 - val_loss: 2915411935762.0029\n",
      "Epoch 501/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2675331592223.6924 - val_loss: 2745781226419.6680\n",
      "Epoch 502/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 2682468699628.9126 - val_loss: 2704942640017.1025\n",
      "Epoch 503/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 2673038561309.7715 - val_loss: 2778015694064.5176\n",
      "Epoch 504/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 82us/step - loss: 2672697509261.3550 - val_loss: 2699759291776.5400\n",
      "Epoch 505/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 2663038529371.7759 - val_loss: 2675604202866.1377\n",
      "Epoch 506/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 2653482550500.3291 - val_loss: 2760939881116.2646\n",
      "Epoch 507/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2644360346991.1035 - val_loss: 2668942543864.7988\n",
      "Epoch 508/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 2614403227672.9697 - val_loss: 2744575557032.8662\n",
      "Epoch 509/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 2667953178224.0039 - val_loss: 3317685605302.5483\n",
      "Epoch 510/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 2639711300780.1475 - val_loss: 2717420473935.9326\n",
      "Epoch 511/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2627432196466.2246 - val_loss: 2797668662927.3022\n",
      "Epoch 512/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2604017744483.2788 - val_loss: 2923891700190.1548\n",
      "Epoch 513/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 2631137367467.1270 - val_loss: 2599730348124.1743\n",
      "Epoch 514/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 2586137632558.6382 - val_loss: 2633232747674.1040\n",
      "Epoch 515/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2549556340848.8442 - val_loss: 2684685993710.3574\n",
      "Epoch 516/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2600076418724.3442 - val_loss: 2557496840589.5020\n",
      "Epoch 517/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 2573751133348.9443 - val_loss: 2554997649471.3701\n",
      "Epoch 518/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2551288041463.3564 - val_loss: 2531632049064.1465\n",
      "Epoch 519/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2510666935326.0117 - val_loss: 2736185201774.8975\n",
      "Epoch 520/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2527999443769.9229 - val_loss: 2591104422377.6763\n",
      "Epoch 521/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 2564495437940.2056 - val_loss: 2586138840955.4995\n",
      "Epoch 522/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 2526916175301.0571 - val_loss: 2570041914813.0293\n",
      "Epoch 523/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2460826761105.0767 - val_loss: 2470961004981.8286\n",
      "Epoch 524/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2473724265281.6055 - val_loss: 2440111495890.9932\n",
      "Epoch 525/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2452490047690.6392 - val_loss: 2538538701358.8071\n",
      "Epoch 526/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2438123006460.5186 - val_loss: 2697764037103.4375\n",
      "Epoch 527/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2463796820356.4717 - val_loss: 2749113128646.0308\n",
      "Epoch 528/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2420684200960.2402 - val_loss: 3809262615539.0381\n",
      "Epoch 529/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 2384938841628.4512 - val_loss: 2511665926149.7607\n",
      "Epoch 530/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2404825611846.2275 - val_loss: 2357563993207.5386\n",
      "Epoch 531/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 2384435353448.7407 - val_loss: 2382039202157.8174\n",
      "Epoch 532/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 2412438315463.2178 - val_loss: 3094301436425.3613\n",
      "Epoch 533/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2346958589328.7163 - val_loss: 2341085057075.8481\n",
      "Epoch 534/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2373337782758.4302 - val_loss: 2371621060930.6104\n",
      "Epoch 535/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2318305030068.1304 - val_loss: 2332580693511.9214\n",
      "Epoch 536/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2324348952370.4795 - val_loss: 2693559303385.4741\n",
      "Epoch 537/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2332741191295.3696 - val_loss: 3912549279090.1382\n",
      "Epoch 538/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2364786850337.9731 - val_loss: 2541854896145.2827\n",
      "Epoch 539/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2321512091773.8091 - val_loss: 2789241064970.8018\n",
      "Epoch 540/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2323342847755.1045 - val_loss: 2305703159522.8354\n",
      "Epoch 541/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 2309877526721.0356 - val_loss: 3807797295469.8174\n",
      "Epoch 542/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2358641775839.5273 - val_loss: 2443204029674.7568\n",
      "Epoch 543/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2308981159456.2925 - val_loss: 2574895067061.1084\n",
      "Epoch 544/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2307541139709.5391 - val_loss: 2561019383629.4121\n",
      "Epoch 545/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2330555982452.0850 - val_loss: 2248907375260.2646\n",
      "Epoch 546/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2305194630082.7759 - val_loss: 2549042865821.7046\n",
      "Epoch 547/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2303442455883.5693 - val_loss: 2280939638444.1069\n",
      "Epoch 548/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2290017098195.2227 - val_loss: 3944264843932.2646\n",
      "Epoch 549/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2328192783963.8359 - val_loss: 2292193903444.6133\n",
      "Epoch 550/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2278729685939.4102 - val_loss: 2223752891845.6709\n",
      "Epoch 551/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 2273416913401.1572 - val_loss: 2238161264236.7368\n",
      "Epoch 552/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2237226608191.9849 - val_loss: 2211120844621.4121\n",
      "Epoch 553/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2319352604450.6338 - val_loss: 5687952788518.8857\n",
      "Epoch 554/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 2268080547518.7544 - val_loss: 2384853932801.0801\n",
      "Epoch 555/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 2271107579727.2910 - val_loss: 4438897456987.8145\n",
      "Epoch 556/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 2313140726948.4644 - val_loss: 2789409218179.7808\n",
      "Epoch 557/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2241206873736.4932 - val_loss: 2402906953690.5542\n",
      "Epoch 558/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2263443479106.6260 - val_loss: 3739914119666.3179\n",
      "Epoch 559/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2262672473405.1636 - val_loss: 3000822871093.2881\n",
      "Epoch 560/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2206766640073.4990 - val_loss: 2317624880938.8467\n",
      "Epoch 561/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2273672736027.5508 - val_loss: 2191918851373.0068\n",
      "Epoch 562/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2240463763752.2754 - val_loss: 2329618488618.1265\n",
      "Epoch 563/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2217961044821.2935 - val_loss: 3772021909449.2715\n",
      "Epoch 564/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2262495872662.4189 - val_loss: 2341277519071.2349\n",
      "Epoch 565/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2274662630954.8569 - val_loss: 2347016334040.7539\n",
      "Epoch 566/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2256056314076.4062 - val_loss: 2840240033152.5400\n",
      "Epoch 567/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 79us/step - loss: 2218989455155.9204 - val_loss: 3307035601947.3643\n",
      "Epoch 568/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 2231401341398.5840 - val_loss: 2168738904222.4248\n",
      "Epoch 569/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2239516902589.9146 - val_loss: 2720494126346.4414\n",
      "Epoch 570/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2231115672233.3862 - val_loss: 2447076735710.5146\n",
      "Epoch 571/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2270591218064.4766 - val_loss: 4481689275016.1016\n",
      "Epoch 572/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2260708778623.6099 - val_loss: 2230110638754.0254\n",
      "Epoch 573/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 2205031654176.9526 - val_loss: 2686416668029.6597\n",
      "Epoch 574/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 2213280822466.7158 - val_loss: 4013076453776.3818\n",
      "Epoch 575/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 2259940663835.7310 - val_loss: 2346430865649.9580\n",
      "Epoch 576/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 2275881367514.0649 - val_loss: 2553905869485.5469\n",
      "Epoch 577/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 2195607703439.6360 - val_loss: 2196244543346.8582\n",
      "Epoch 578/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2201047442643.0425 - val_loss: 3723359918895.1675\n",
      "Epoch 579/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2253587729259.3818 - val_loss: 2218846217977.8789\n",
      "Epoch 580/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2285466872773.6572 - val_loss: 3316476825767.0659\n",
      "Epoch 581/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2216399117419.8022 - val_loss: 2925573691677.1646\n",
      "Epoch 582/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2223052982951.4658 - val_loss: 2704314613229.9971\n",
      "Epoch 583/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2185923461227.5620 - val_loss: 4034763971259.9497\n",
      "Epoch 584/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2210467192530.4424 - val_loss: 2309731694681.2939\n",
      "Epoch 585/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2238261946719.0171 - val_loss: 2203624425106.1826\n",
      "Epoch 586/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2211009960145.8418 - val_loss: 2178053404461.7271\n",
      "Epoch 587/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2238407457260.1924 - val_loss: 2421973013845.3335\n",
      "Epoch 588/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2198559463626.1592 - val_loss: 2574689039574.5938\n",
      "Epoch 589/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2241341305728.0298 - val_loss: 2174737664832.4502\n",
      "Epoch 590/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 2244872436791.9419 - val_loss: 3601619621090.1152\n",
      "Epoch 591/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 2225177071215.5234 - val_loss: 2242744612976.3374\n",
      "Epoch 592/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 2222686871534.7134 - val_loss: 2977384029274.7344\n",
      "Epoch 593/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 2222120132279.5518 - val_loss: 2157888793189.5361\n",
      "Epoch 594/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2197825281688.8198 - val_loss: 2548297373635.5107\n",
      "Epoch 595/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2200257595579.7534 - val_loss: 2553856447783.2461\n",
      "Epoch 596/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 2225302572409.6680 - val_loss: 2262848099162.3740\n",
      "Epoch 597/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2187764688809.0862 - val_loss: 2168739094470.3911\n",
      "Epoch 598/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2186684945815.9194 - val_loss: 2213480976274.5430\n",
      "Epoch 599/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2214449502091.3145 - val_loss: 2223397804893.2544\n",
      "Epoch 600/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 2221809692872.7183 - val_loss: 3036726798742.1436\n",
      "Epoch 601/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2200217675781.2822 - val_loss: 2237179572195.1953\n",
      "Epoch 602/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 2154379054795.7197 - val_loss: 2548594058149.2656\n",
      "Epoch 603/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 2160709577289.3486 - val_loss: 2130722899878.7061\n",
      "Epoch 604/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2195585447875.0164 - val_loss: 3431980904004.4106\n",
      "Epoch 605/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2189700176780.9949 - val_loss: 2216230704423.2461\n",
      "Epoch 606/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 2211180624310.4111 - val_loss: 2555207795863.2236\n",
      "Epoch 607/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2254907691909.7920 - val_loss: 3698916790139.4995\n",
      "Epoch 608/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2196330288716.4697 - val_loss: 3226197475397.1309\n",
      "Epoch 609/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2178124560538.1404 - val_loss: 2130298178668.0168\n",
      "Epoch 610/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2170740447103.7898 - val_loss: 2136318985551.5725\n",
      "Epoch 611/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2212044949219.2490 - val_loss: 2722008180128.2251\n",
      "Epoch 612/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 2179385337926.5876 - val_loss: 2181930866880.9905\n",
      "Epoch 613/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2186434865387.7722 - val_loss: 2224135906720.2251\n",
      "Epoch 614/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2193961972811.6294 - val_loss: 2317944172883.8931\n",
      "Epoch 615/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2196991802493.0889 - val_loss: 2955518596022.5483\n",
      "Epoch 616/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 2222766705876.4829 - val_loss: 4362913599839.4150\n",
      "Epoch 617/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2255491131704.6021 - val_loss: 2158900495372.9619\n",
      "Epoch 618/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2178543116581.8745 - val_loss: 3403278894599.9214\n",
      "Epoch 619/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 2191851024046.9082 - val_loss: 2277259895648.1353\n",
      "Epoch 620/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 2136162439435.9448 - val_loss: 2205355521952.9453\n",
      "Epoch 621/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2139773358159.7112 - val_loss: 2882498668904.0562\n",
      "Epoch 622/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2225798251371.8618 - val_loss: 2202904175064.3940\n",
      "Epoch 623/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2210788902316.0869 - val_loss: 2449476434147.5557\n",
      "Epoch 624/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2197446055481.2625 - val_loss: 2174673258706.2729\n",
      "Epoch 625/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2221572416319.6851 - val_loss: 3756951121476.4106\n",
      "Epoch 626/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 2195446027341.5503 - val_loss: 2369338117043.6680\n",
      "Epoch 627/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2168894215867.8733 - val_loss: 2784413323914.9819\n",
      "Epoch 628/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 2199740557720.6396 - val_loss: 3573384395025.6426\n",
      "Epoch 629/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 2211902041986.1909 - val_loss: 2370860447718.0762\n",
      "Epoch 630/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 99us/step - loss: 2181129755813.4243 - val_loss: 2171541626015.8650\n",
      "Epoch 631/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2157817052519.4202 - val_loss: 2374098029169.0576\n",
      "Epoch 632/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2221535173217.3579 - val_loss: 2754717713167.4824\n",
      "Epoch 633/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 2184078474914.4236 - val_loss: 2541218501581.5923\n",
      "Epoch 634/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2219343407470.3833 - val_loss: 2153746934212.2310\n",
      "Epoch 635/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 2201953289870.7358 - val_loss: 2801140945293.5020\n",
      "Epoch 636/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 2165195002988.2822 - val_loss: 2269694570605.4570\n",
      "Epoch 637/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 2158227098932.5203 - val_loss: 2135357187879.9661\n",
      "Epoch 638/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 2236909609776.3188 - val_loss: 2137567267164.5342\n",
      "Epoch 639/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 2230371869180.9985 - val_loss: 2427137081966.1772\n",
      "Epoch 640/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 2156719722130.0969 - val_loss: 2953112575343.2573\n",
      "Epoch 641/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 2235329339178.7969 - val_loss: 3209116374034.7231\n",
      "Epoch 642/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 2192569198051.7891 - val_loss: 2824213129506.9253\n",
      "Epoch 643/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 2191627354642.1272 - val_loss: 2222920680507.0493\n",
      "Epoch 644/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 2170218531553.0879 - val_loss: 3126255007925.4683\n",
      "Epoch 645/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2153267804682.9241 - val_loss: 3537743255122.8130\n",
      "Epoch 646/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 2209334356042.4292 - val_loss: 2450602186852.8159\n",
      "Epoch 647/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2182112821904.8965 - val_loss: 2492659342449.7778\n",
      "Epoch 648/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2158280842155.7273 - val_loss: 2214835967824.2925\n",
      "Epoch 649/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2155243859999.6926 - val_loss: 2417269490332.2646\n",
      "Epoch 650/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2171512096179.7703 - val_loss: 2385881483819.9268\n",
      "Epoch 651/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2165193151077.6799 - val_loss: 2306840309592.9341\n",
      "Epoch 652/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2170158147742.9419 - val_loss: 2255413302475.0718\n",
      "Epoch 653/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 2166275926973.9744 - val_loss: 3126564583582.4248\n",
      "Epoch 654/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2188614799282.2097 - val_loss: 2099616477685.1982\n",
      "Epoch 655/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2172361947205.6270 - val_loss: 2114254016471.6736\n",
      "Epoch 656/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2156891778823.2629 - val_loss: 2107750745538.7903\n",
      "Epoch 657/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2113833249906.5247 - val_loss: 2423652497266.8579\n",
      "Epoch 658/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2177302927884.8452 - val_loss: 2927046551981.1870\n",
      "Epoch 659/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 2142478059657.8137 - val_loss: 2090958341593.8342\n",
      "Epoch 660/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2125955554123.6897 - val_loss: 2387354139128.0786\n",
      "Epoch 661/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 2173138880649.8137 - val_loss: 2382154368174.2671\n",
      "Epoch 662/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 2096528857712.7241 - val_loss: 2873991960423.3359\n",
      "Epoch 663/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 2136599282835.6575 - val_loss: 2253792935290.7793\n",
      "Epoch 664/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2126889973172.7305 - val_loss: 2089681072790.5034\n",
      "Epoch 665/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2094879203744.8027 - val_loss: 2090736708796.6692\n",
      "Epoch 666/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2160457950027.2092 - val_loss: 2472745781435.2295\n",
      "Epoch 667/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2124070842637.8652 - val_loss: 2548712854546.7231\n",
      "Epoch 668/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2196411144666.9055 - val_loss: 2092157318565.9856\n",
      "Epoch 669/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 2147438680623.4185 - val_loss: 2507372501484.5571\n",
      "Epoch 670/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 2132491572651.1267 - val_loss: 2707908550506.2168\n",
      "Epoch 671/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2096712809351.2329 - val_loss: 2103918156015.0771\n",
      "Epoch 672/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2145080526010.0725 - val_loss: 2191332472299.1167\n",
      "Epoch 673/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 2132087028127.3623 - val_loss: 2089366542759.4263\n",
      "Epoch 674/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2167174865554.8174 - val_loss: 2739563865365.9634\n",
      "Epoch 675/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 2168631740361.7388 - val_loss: 2647098518670.5825\n",
      "Epoch 676/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2139772008056.6472 - val_loss: 2084108661006.7622\n",
      "Epoch 677/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2128811902867.9578 - val_loss: 2197701121964.4670\n",
      "Epoch 678/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2117563053546.5115 - val_loss: 2525111486213.4009\n",
      "Epoch 679/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 2178981529833.8511 - val_loss: 2074143488573.2097\n",
      "Epoch 680/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2130790565995.0818 - val_loss: 2150583931070.1099\n",
      "Epoch 681/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2147937006256.5891 - val_loss: 2096203603011.6904\n",
      "Epoch 682/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 2098439158386.6448 - val_loss: 2059574648474.8242\n",
      "Epoch 683/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2137876013976.0393 - val_loss: 4632684450558.2002\n",
      "Epoch 684/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 2179980767505.7070 - val_loss: 3325517274179.6904\n",
      "Epoch 685/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2162279448237.9480 - val_loss: 4672257605931.5664\n",
      "Epoch 686/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2131450372685.6707 - val_loss: 3214380155133.4795\n",
      "Epoch 687/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 2133387085012.9631 - val_loss: 2518680540478.2896\n",
      "Epoch 688/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 2153839981720.4595 - val_loss: 2796542004516.3657\n",
      "Epoch 689/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2133912147951.1934 - val_loss: 2488740496120.4390\n",
      "Epoch 690/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2081922202883.5415 - val_loss: 3195417166976.1802\n",
      "Epoch 691/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2150212665874.1272 - val_loss: 2263532167064.3037\n",
      "Epoch 692/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2181869589458.6223 - val_loss: 2109525799436.2417\n",
      "Epoch 693/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 75us/step - loss: 2119027517161.0112 - val_loss: 2566325281056.0449\n",
      "Epoch 694/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2158273816681.1609 - val_loss: 2745154887345.8677\n",
      "Epoch 695/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2132148411127.1765 - val_loss: 2050201367513.1143\n",
      "Epoch 696/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2169509735019.9224 - val_loss: 2146332158726.8411\n",
      "Epoch 697/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 2140204021107.4248 - val_loss: 2055259864419.7356\n",
      "Epoch 698/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2129528349549.7830 - val_loss: 2079902358111.7747\n",
      "Epoch 699/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 2062328409379.2336 - val_loss: 2228315950234.1040\n",
      "Epoch 700/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2143979485868.2671 - val_loss: 2096192864693.8286\n",
      "Epoch 701/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2132812256817.5793 - val_loss: 2105303221307.0496\n",
      "Epoch 702/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2133198891989.0234 - val_loss: 2611113186645.3335\n",
      "Epoch 703/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 2088519869259.2095 - val_loss: 2974436853232.8774\n",
      "Epoch 704/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 2143731941352.9509 - val_loss: 3509715023269.9858\n",
      "Epoch 705/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 2121209198892.1174 - val_loss: 2452079269113.1587\n",
      "Epoch 706/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 2183379750396.2783 - val_loss: 3128602855127.3135\n",
      "Epoch 707/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2115944899084.3650 - val_loss: 2106587984811.0264\n",
      "Epoch 708/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 2106337943254.2837 - val_loss: 2597567917659.4541\n",
      "Epoch 709/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 2166406531079.2026 - val_loss: 2106140882733.7271\n",
      "Epoch 710/800\n",
      "4265/4265 [==============================] - 0s 117us/step - loss: 2132844279382.0735 - val_loss: 4984785095027.5781\n",
      "Epoch 711/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 2116865516682.0537 - val_loss: 2270693488936.6865\n",
      "Epoch 712/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 2194242390860.6499 - val_loss: 2455127861515.8818\n",
      "Epoch 713/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 2126938813580.9351 - val_loss: 2610314701551.7974\n",
      "Epoch 714/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2205741862015.9702 - val_loss: 2718185799656.9565\n",
      "Epoch 715/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 2130188272391.9832 - val_loss: 2496765044911.7075\n",
      "Epoch 716/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2098057670088.4185 - val_loss: 2309252022225.9126\n",
      "Epoch 717/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 2164647686360.0842 - val_loss: 2339639128288.6753\n",
      "Epoch 718/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2151384945568.6826 - val_loss: 2437631309106.7681\n",
      "Epoch 719/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2145355989199.4409 - val_loss: 2543541846799.4824\n",
      "Epoch 720/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2140240600214.0586 - val_loss: 2621038588773.8960\n",
      "Epoch 721/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2105553719594.6768 - val_loss: 2143482586896.9229\n",
      "Epoch 722/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 2138916820679.3977 - val_loss: 2187121930672.0676\n",
      "Epoch 723/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2156009527186.9971 - val_loss: 2663891697617.9126\n",
      "Epoch 724/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2106157996702.8220 - val_loss: 2062983426549.1982\n",
      "Epoch 725/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2138429026627.6462 - val_loss: 2711471355878.0762\n",
      "Epoch 726/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2189421869836.3047 - val_loss: 2114628608818.0479\n",
      "Epoch 727/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 2155336321799.5029 - val_loss: 2658043386279.4263\n",
      "Epoch 728/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 2133886991930.7029 - val_loss: 3204823661324.6021\n",
      "Epoch 729/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 2142367638566.1750 - val_loss: 2174748014911.7300\n",
      "Epoch 730/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2132052232153.1047 - val_loss: 2543931146862.1772\n",
      "Epoch 731/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2160794553740.8750 - val_loss: 2129328967777.9353\n",
      "Epoch 732/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2143121263106.2808 - val_loss: 3974498712263.4712\n",
      "Epoch 733/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 2105182890477.1526 - val_loss: 2104147966709.5581\n",
      "Epoch 734/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 2097091081913.9526 - val_loss: 2152333189039.3472\n",
      "Epoch 735/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 2146143359263.1521 - val_loss: 3463016385828.3657\n",
      "Epoch 736/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 2164699113942.1035 - val_loss: 2575172604554.9819\n",
      "Epoch 737/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 2115516011309.4375 - val_loss: 2151913661487.5273\n",
      "Epoch 738/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2119355016764.1436 - val_loss: 3086665490120.9116\n",
      "Epoch 739/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 2091504879753.8137 - val_loss: 2839651208507.4092\n",
      "Epoch 740/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 2170299272089.4802 - val_loss: 3055930130731.5669\n",
      "Epoch 741/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 2123408892589.7080 - val_loss: 3285041065171.7129\n",
      "Epoch 742/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 2142959438511.1484 - val_loss: 2267684129646.5371\n",
      "Epoch 743/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2109148063027.0801 - val_loss: 2171677565561.6987\n",
      "Epoch 744/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 2111308460801.2607 - val_loss: 2631363910931.0830\n",
      "Epoch 745/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 2138439172430.2107 - val_loss: 2920091598456.2588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff82ab9fa20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train11 = model11.fit(predictors,target, epochs=800, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=True)\n",
    "model_train11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4265 samples, validate on 2844 samples\n",
      "Epoch 1/800\n",
      "4265/4265 [==============================] - 1s 171us/step - loss: 71253601099497.5000 - val_loss: 4478633373920.6748\n",
      "Epoch 2/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 4105850932052.3330 - val_loss: 4595374837834.8916\n",
      "Epoch 3/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3926173188641.4932 - val_loss: 3914313831557.9409\n",
      "Epoch 4/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3737392044975.5684 - val_loss: 3837329121890.6553\n",
      "Epoch 5/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3681549379865.8701 - val_loss: 3776998914598.1660\n",
      "Epoch 6/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3650255325533.0962 - val_loss: 3884645956088.0786\n",
      "Epoch 7/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3662406554098.4346 - val_loss: 3738401824940.8271\n",
      "Epoch 8/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3679175348484.2617 - val_loss: 3752994220023.3589\n",
      "Epoch 9/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3599078468115.5674 - val_loss: 4074534741915.1841\n",
      "Epoch 10/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3589424401535.9702 - val_loss: 3843880354852.0059\n",
      "Epoch 11/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3621779133824.8706 - val_loss: 3707757643364.0957\n",
      "Epoch 12/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3608438022088.2979 - val_loss: 3856998619098.5542\n",
      "Epoch 13/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3590283021263.2612 - val_loss: 3747139665159.5610\n",
      "Epoch 14/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3564206323478.1489 - val_loss: 3731626471026.4980\n",
      "Epoch 15/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3519185612916.2056 - val_loss: 3623123787833.6089\n",
      "Epoch 16/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3494455752950.3364 - val_loss: 3610559170608.9678\n",
      "Epoch 17/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3493620751598.4131 - val_loss: 3642175441866.7119\n",
      "Epoch 18/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3494455227064.2720 - val_loss: 3621619264516.3208\n",
      "Epoch 19/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3442641527400.5610 - val_loss: 3615511092890.8242\n",
      "Epoch 20/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3460239495489.7256 - val_loss: 3544483742410.3516\n",
      "Epoch 21/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3464757593181.8765 - val_loss: 3562444777486.4023\n",
      "Epoch 22/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3431784009654.0508 - val_loss: 3746360716983.6289\n",
      "Epoch 23/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3413223680024.4893 - val_loss: 3772334167196.9844\n",
      "Epoch 24/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3401752512861.0962 - val_loss: 3516664867752.1465\n",
      "Epoch 25/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3428869629112.1519 - val_loss: 3483030808129.5303\n",
      "Epoch 26/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3376283475654.9175 - val_loss: 3499509266244.7705\n",
      "Epoch 27/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3356799621441.2456 - val_loss: 3637266446310.0762\n",
      "Epoch 28/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3347225255304.0732 - val_loss: 3831764740525.1870\n",
      "Epoch 29/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3317700645927.1353 - val_loss: 3427546853278.0649\n",
      "Epoch 30/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3352269494812.2109 - val_loss: 3487461576709.7607\n",
      "Epoch 31/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3288324898262.8242 - val_loss: 3397283092050.8130\n",
      "Epoch 32/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3291618513586.5098 - val_loss: 3486400248934.2559\n",
      "Epoch 33/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3273184151432.4331 - val_loss: 3446421683993.5640\n",
      "Epoch 34/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3286298989564.8789 - val_loss: 3352091015718.1660\n",
      "Epoch 35/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3231701744292.5845 - val_loss: 3347647690772.1631\n",
      "Epoch 36/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3207037767321.7803 - val_loss: 3513657460347.1392\n",
      "Epoch 37/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3232622017430.5991 - val_loss: 3602754582571.2065\n",
      "Epoch 38/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3243611076147.5000 - val_loss: 3296758036269.7271\n",
      "Epoch 39/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3210130426773.6382 - val_loss: 3352217081910.7285\n",
      "Epoch 40/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3236084994773.0835 - val_loss: 3276271606920.8213\n",
      "Epoch 41/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3207239516509.5767 - val_loss: 3319456978307.4204\n",
      "Epoch 42/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3177719341515.0596 - val_loss: 3356089331498.8467\n",
      "Epoch 43/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3172926114014.3267 - val_loss: 3271522847713.7554\n",
      "Epoch 44/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3192578335605.4663 - val_loss: 3602449942853.4907\n",
      "Epoch 45/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3197571041260.3120 - val_loss: 3244152821469.0747\n",
      "Epoch 46/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3124499593692.8262 - val_loss: 3219566997152.5850\n",
      "Epoch 47/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3136640498148.5093 - val_loss: 3229726568903.1113\n",
      "Epoch 48/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3162554954397.3813 - val_loss: 3226374535787.2969\n",
      "Epoch 49/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3112486809689.3149 - val_loss: 3299377342985.3613\n",
      "Epoch 50/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3151149942668.2749 - val_loss: 3228386526013.5698\n",
      "Epoch 51/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3108599551161.1123 - val_loss: 3200243806179.1953\n",
      "Epoch 52/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3147511014672.5063 - val_loss: 3331117616835.1504\n",
      "Epoch 53/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3121563485408.4878 - val_loss: 3347899455934.4697\n",
      "Epoch 54/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3125888986334.0864 - val_loss: 3238928197531.1841\n",
      "Epoch 55/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3124971128670.1768 - val_loss: 3239899098531.1055\n",
      "Epoch 56/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3089754264549.8296 - val_loss: 3180965556863.4600\n",
      "Epoch 57/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3137869193290.9092 - val_loss: 3336592378135.4038\n",
      "Epoch 58/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3178251003905.4404 - val_loss: 3432442374043.1841\n",
      "Epoch 59/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3108872435658.6992 - val_loss: 3175211690367.1001\n",
      "Epoch 60/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3132397603222.7188 - val_loss: 3528404692940.1519\n",
      "Epoch 61/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3101593654049.9136 - val_loss: 3158914705952.4053\n",
      "Epoch 62/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3117142715637.1357 - val_loss: 3163572839287.1787\n",
      "Epoch 63/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3151162351575.6641 - val_loss: 3297413427240.3262\n",
      "Epoch 64/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 69us/step - loss: 3120458543500.6348 - val_loss: 3348238720782.0420\n",
      "Epoch 65/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3094031767646.5972 - val_loss: 3151364251221.6934\n",
      "Epoch 66/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3087359519612.6685 - val_loss: 3161080082126.6724\n",
      "Epoch 67/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3106982673029.8521 - val_loss: 3159709700954.3740\n",
      "Epoch 68/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3136575188766.3115 - val_loss: 3200629774690.2954\n",
      "Epoch 69/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3073354431113.6938 - val_loss: 3164072577925.5811\n",
      "Epoch 70/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3100816471123.3125 - val_loss: 3228673791962.5542\n",
      "Epoch 71/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 3075917628187.1904 - val_loss: 3293680088900.7705\n",
      "Epoch 72/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3114212534849.6655 - val_loss: 3752226954031.1675\n",
      "Epoch 73/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3149440637725.5913 - val_loss: 3166846788885.9634\n",
      "Epoch 74/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3085205535500.3047 - val_loss: 3393081612457.9468\n",
      "Epoch 75/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3095831273051.3555 - val_loss: 3151788455518.3350\n",
      "Epoch 76/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3104639541203.8228 - val_loss: 3145819504109.9971\n",
      "Epoch 77/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3103557464491.3667 - val_loss: 3155765663729.5977\n",
      "Epoch 78/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3091705075599.1558 - val_loss: 3592339424845.0522\n",
      "Epoch 79/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3064733394688.0601 - val_loss: 3192590303047.6514\n",
      "Epoch 80/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3113127515486.2969 - val_loss: 3158487518523.4092\n",
      "Epoch 81/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3108757109170.5698 - val_loss: 3189109053955.6006\n",
      "Epoch 82/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3070938602822.7676 - val_loss: 3441150596045.5923\n",
      "Epoch 83/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3116637046898.7646 - val_loss: 3559066511535.7075\n",
      "Epoch 84/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3110155648486.1899 - val_loss: 3203352154140.8047\n",
      "Epoch 85/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3105922485064.8086 - val_loss: 3328935770569.9917\n",
      "Epoch 86/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3077798025575.6602 - val_loss: 3237216994132.6133\n",
      "Epoch 87/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3059390818497.5156 - val_loss: 3167644739367.9663\n",
      "Epoch 88/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3058950327362.5059 - val_loss: 3160540452987.8594\n",
      "Epoch 89/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3084039360687.7485 - val_loss: 3172842329659.7695\n",
      "Epoch 90/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3107078142186.8120 - val_loss: 3214906135455.5049\n",
      "Epoch 91/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3072000452559.5010 - val_loss: 3149564444257.2153\n",
      "Epoch 92/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3082344744844.2749 - val_loss: 3163744549137.6426\n",
      "Epoch 93/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3094884599830.5688 - val_loss: 3278686022107.2744\n",
      "Epoch 94/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3113049614433.4780 - val_loss: 3162381871533.1870\n",
      "Epoch 95/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3067976313820.7061 - val_loss: 3147247641394.0479\n",
      "Epoch 96/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3080058321987.4663 - val_loss: 3142460026989.4570\n",
      "Epoch 97/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3124052320035.1138 - val_loss: 3338769015072.0449\n",
      "Epoch 98/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3073909575275.6821 - val_loss: 3141538530363.0493\n",
      "Epoch 99/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3102829836461.3477 - val_loss: 3171959815431.5610\n",
      "Epoch 100/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3067069840274.7573 - val_loss: 3234952510566.2559\n",
      "Epoch 101/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3079276987566.5479 - val_loss: 3174360957135.3926\n",
      "Epoch 102/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3080568694597.2070 - val_loss: 3152802107006.0195\n",
      "Epoch 103/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3060885324521.2515 - val_loss: 3147749848462.9424\n",
      "Epoch 104/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3074442225884.4062 - val_loss: 3199667539190.2783\n",
      "Epoch 105/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3082531870960.5742 - val_loss: 3321992202795.9268\n",
      "Epoch 106/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3101215018603.6821 - val_loss: 3188631059258.6890\n",
      "Epoch 107/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3065580622768.0488 - val_loss: 3198173312122.4189\n",
      "Epoch 108/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3078009879292.9385 - val_loss: 3374741068452.9058\n",
      "Epoch 109/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3130726575237.7324 - val_loss: 3164813314281.3164\n",
      "Epoch 110/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3086754765144.2944 - val_loss: 3231175101064.1011\n",
      "Epoch 111/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3092820485565.3740 - val_loss: 3235435647857.4175\n",
      "Epoch 112/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3073470661891.0615 - val_loss: 3236323589314.4302\n",
      "Epoch 113/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3111465151652.4644 - val_loss: 3301604624594.2729\n",
      "Epoch 114/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3110381243558.3853 - val_loss: 3140646671125.2432\n",
      "Epoch 115/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3092651215066.4854 - val_loss: 3247203843220.3433\n",
      "Epoch 116/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3108726389812.1001 - val_loss: 3151437720856.8438\n",
      "Epoch 117/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3071970654500.4341 - val_loss: 3315804374052.0059\n",
      "Epoch 118/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3123793416417.6885 - val_loss: 3146680796472.5288\n",
      "Epoch 119/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3079192502519.7769 - val_loss: 3143247519363.7808\n",
      "Epoch 120/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3077699476580.1191 - val_loss: 3267686310544.7427\n",
      "Epoch 121/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3082879612828.6011 - val_loss: 3168432271930.3291\n",
      "Epoch 122/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3087150401965.7681 - val_loss: 3337762647205.6260\n",
      "Epoch 123/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3129015012291.7363 - val_loss: 3228401337333.9185\n",
      "Epoch 124/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3108874368671.0620 - val_loss: 3157598995630.2671\n",
      "Epoch 125/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3088233753687.6343 - val_loss: 3195388447644.6245\n",
      "Epoch 126/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3101098557397.7437 - val_loss: 3183247376222.6948\n",
      "Epoch 127/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 77us/step - loss: 3070992585709.5127 - val_loss: 3144475591370.3516\n",
      "Epoch 128/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3085962024109.5879 - val_loss: 3362240329195.1167\n",
      "Epoch 129/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3074782170228.4453 - val_loss: 3138967465148.6694\n",
      "Epoch 130/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3116230771364.1040 - val_loss: 3182790522646.6836\n",
      "Epoch 131/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3093729813776.5063 - val_loss: 3150620057588.4780\n",
      "Epoch 132/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3043632404793.5625 - val_loss: 3214091407757.5020\n",
      "Epoch 133/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3055643686340.0962 - val_loss: 3180601028487.0210\n",
      "Epoch 134/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3058285479900.9463 - val_loss: 3261666182433.4854\n",
      "Epoch 135/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3066631218598.3247 - val_loss: 3239314528472.0337\n",
      "Epoch 136/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3084539618534.2500 - val_loss: 3236875064338.7231\n",
      "Epoch 137/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3103828547816.8911 - val_loss: 3218459058256.6528\n",
      "Epoch 138/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3114279930750.5898 - val_loss: 3319358637806.3574\n",
      "Epoch 139/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3124876919955.6572 - val_loss: 3137556502536.6411\n",
      "Epoch 140/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3057044220316.4810 - val_loss: 3166319674450.0928\n",
      "Epoch 141/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3050686292711.3306 - val_loss: 3205960982839.0884\n",
      "Epoch 142/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3066538301857.2832 - val_loss: 3338560856144.6528\n",
      "Epoch 143/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3065144231743.4448 - val_loss: 3205097592587.1616\n",
      "Epoch 144/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3113814469831.0381 - val_loss: 3207788557157.8960\n",
      "Epoch 145/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3115319396432.1914 - val_loss: 3132755802316.5117\n",
      "Epoch 146/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3070310633551.7114 - val_loss: 3190027026938.9590\n",
      "Epoch 147/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3048218423765.6235 - val_loss: 3163571504233.1362\n",
      "Epoch 148/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3059909254586.0127 - val_loss: 3186030107416.1235\n",
      "Epoch 149/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3054261031936.7202 - val_loss: 3133771767012.9956\n",
      "Epoch 150/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3060882953024.6455 - val_loss: 3152071694552.0337\n",
      "Epoch 151/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3075107980431.8159 - val_loss: 3147092337112.3940\n",
      "Epoch 152/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3071306063097.9380 - val_loss: 3145913574355.3530\n",
      "Epoch 153/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3044380933306.5527 - val_loss: 3150316668124.3545\n",
      "Epoch 154/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3110657105341.8540 - val_loss: 3205083749835.4316\n",
      "Epoch 155/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3111171024609.3281 - val_loss: 3165899594036.2080\n",
      "Epoch 156/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3079467895578.7104 - val_loss: 3203291191097.2490\n",
      "Epoch 157/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3077353464078.8257 - val_loss: 3132726582662.3008\n",
      "Epoch 158/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3064377148859.4536 - val_loss: 3255493638417.6426\n",
      "Epoch 159/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3059767447174.5728 - val_loss: 3293431594454.9536\n",
      "Epoch 160/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3055723521388.7021 - val_loss: 3168246188403.5781\n",
      "Epoch 161/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3047019391277.0776 - val_loss: 3136576560333.9521\n",
      "Epoch 162/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3081935688216.8496 - val_loss: 3133109039328.6753\n",
      "Epoch 163/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3063158727764.2729 - val_loss: 3172600100123.7241\n",
      "Epoch 164/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3104675140113.1665 - val_loss: 3122606206417.1929\n",
      "Epoch 165/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3056416937137.4292 - val_loss: 3252703495296.1802\n",
      "Epoch 166/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3073449924364.5449 - val_loss: 3201410428461.3672\n",
      "Epoch 167/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3058103015138.2881 - val_loss: 3179409556723.3979\n",
      "Epoch 168/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3096468532515.2339 - val_loss: 3213727969988.5908\n",
      "Epoch 169/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3086245231794.8701 - val_loss: 3189624325455.5723\n",
      "Epoch 170/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3162575532916.5054 - val_loss: 3178887139495.0659\n",
      "Epoch 171/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3047548013964.8750 - val_loss: 3135769070170.0142\n",
      "Epoch 172/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3054514467531.4795 - val_loss: 3125920094078.3799\n",
      "Epoch 173/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3049860490339.6387 - val_loss: 3130903868884.0732\n",
      "Epoch 174/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3117269786944.7651 - val_loss: 3177003837638.7510\n",
      "Epoch 175/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3063865168228.2988 - val_loss: 3164963569986.6104\n",
      "Epoch 176/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3068503651080.9434 - val_loss: 3131543982131.8481\n",
      "Epoch 177/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3094952302191.0435 - val_loss: 3145653368598.6836\n",
      "Epoch 178/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3088416056554.0913 - val_loss: 3225187015355.9492\n",
      "Epoch 179/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3097249190063.7485 - val_loss: 3170383479774.8750\n",
      "Epoch 180/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3105663977091.2109 - val_loss: 3155442989537.0352\n",
      "Epoch 181/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3047468216224.9229 - val_loss: 3174806713282.0703\n",
      "Epoch 182/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3056246204624.8818 - val_loss: 3132105983472.8774\n",
      "Epoch 183/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3064761332108.6348 - val_loss: 3643628100122.6440\n",
      "Epoch 184/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3080339116810.8643 - val_loss: 3133102073156.0508\n",
      "Epoch 185/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3100790956030.0791 - val_loss: 3146998012834.3853\n",
      "Epoch 186/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3110120003325.1787 - val_loss: 3443361457706.4868\n",
      "Epoch 187/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3066067575131.6558 - val_loss: 3134899909063.1113\n",
      "Epoch 188/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3091566711078.8354 - val_loss: 3174838519350.0083\n",
      "Epoch 189/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3086622474866.1646 - val_loss: 3140931313790.7397\n",
      "Epoch 190/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 76us/step - loss: 3057425309928.4106 - val_loss: 3393005333715.7129\n",
      "Epoch 191/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3045354492867.2563 - val_loss: 3212025556341.0181\n",
      "Epoch 192/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3071412002095.7188 - val_loss: 3166362482823.3813\n",
      "Epoch 193/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3056001371102.6270 - val_loss: 3146675549168.1577\n",
      "Epoch 194/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3064776771253.1509 - val_loss: 3327445464601.2041\n",
      "Epoch 195/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3075537117535.4976 - val_loss: 3226859561547.6118\n",
      "Epoch 196/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3069911548845.1675 - val_loss: 3287132557663.4150\n",
      "Epoch 197/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3038467051146.4141 - val_loss: 3267476809558.0532\n",
      "Epoch 198/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3088219413273.7500 - val_loss: 3149953427977.3613\n",
      "Epoch 199/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3045189317730.6787 - val_loss: 3164457216175.7075\n",
      "Epoch 200/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3102310736638.3794 - val_loss: 3208393627541.4233\n",
      "Epoch 201/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3045878080469.5034 - val_loss: 3140608535256.7539\n",
      "Epoch 202/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3075525531815.5854 - val_loss: 3255117285171.4883\n",
      "Epoch 203/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3083484946841.1196 - val_loss: 3138212932128.4053\n",
      "Epoch 204/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3072836653688.8872 - val_loss: 3284381401364.5234\n",
      "Epoch 205/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3088933091923.9131 - val_loss: 3213012834888.7314\n",
      "Epoch 206/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3041848332709.6045 - val_loss: 3173207852782.3574\n",
      "Epoch 207/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3074270192547.5640 - val_loss: 3177159712664.3037\n",
      "Epoch 208/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3114743541849.3149 - val_loss: 3151943353495.2236\n",
      "Epoch 209/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3102146617038.6011 - val_loss: 3245368150917.5811\n",
      "Epoch 210/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3065628874043.7236 - val_loss: 3149546700684.7822\n",
      "Epoch 211/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3128257152881.3843 - val_loss: 3161293841570.7456\n",
      "Epoch 212/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3080435310689.9585 - val_loss: 3146906315526.8413\n",
      "Epoch 213/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3063125140356.8320 - val_loss: 3354839596295.5610\n",
      "Epoch 214/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3090378453446.2573 - val_loss: 3168769237579.6118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff82ab47ba8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train22 = model22.fit(predictors,target, epochs=800, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=True)\n",
    "model_train22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4265 samples, validate on 2844 samples\n",
      "Epoch 1/800\n",
      "4265/4265 [==============================] - 1s 168us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: nan - val_loss: nan\n",
      "Epoch 25/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: nan - val_loss: nan\n",
      "Epoch 26/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: nan - val_loss: nan\n",
      "Epoch 27/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: nan - val_loss: nan\n",
      "Epoch 28/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: nan - val_loss: nan\n",
      "Epoch 29/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: nan - val_loss: nan\n",
      "Epoch 30/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: nan - val_loss: nan\n",
      "Epoch 31/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: nan - val_loss: nan\n",
      "Epoch 32/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: nan - val_loss: nan\n",
      "Epoch 33/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: nan - val_loss: nan\n",
      "Epoch 34/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: nan - val_loss: nan\n",
      "Epoch 35/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: nan - val_loss: nan\n",
      "Epoch 36/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: nan - val_loss: nan\n",
      "Epoch 37/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: nan - val_loss: nan\n",
      "Epoch 38/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: nan - val_loss: nan\n",
      "Epoch 39/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: nan - val_loss: nan\n",
      "Epoch 40/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: nan - val_loss: nan\n",
      "Epoch 41/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: nan - val_loss: nan\n",
      "Epoch 42/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: nan - val_loss: nan\n",
      "Epoch 43/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: nan - val_loss: nan\n",
      "Epoch 44/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: nan - val_loss: nan\n",
      "Epoch 45/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: nan - val_loss: nan\n",
      "Epoch 46/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: nan - val_loss: nan\n",
      "Epoch 47/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: nan - val_loss: nan\n",
      "Epoch 48/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: nan - val_loss: nan\n",
      "Epoch 49/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: nan - val_loss: nan\n",
      "Epoch 50/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff8293e5fd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train33 = model33.fit(predictors,target, epochs=800, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=True)\n",
    "model_train33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4265 samples, validate on 2844 samples\n",
      "Epoch 1/800\n",
      "4265/4265 [==============================] - 1s 154us/step - loss: 14983372578161.0234 - val_loss: 4153379028853.7378\n",
      "Epoch 2/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3958061385988.7417 - val_loss: 4096674111591.6963\n",
      "Epoch 3/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3849609045944.4521 - val_loss: 3972916615706.6440\n",
      "Epoch 4/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3759207314377.0186 - val_loss: 3964999481986.3403\n",
      "Epoch 5/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3746431584555.1567 - val_loss: 3874910362622.5596\n",
      "Epoch 6/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3707431450482.3447 - val_loss: 3828450762533.0859\n",
      "Epoch 7/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3711890095820.6797 - val_loss: 3816797160230.5259\n",
      "Epoch 8/800\n",
      "4265/4265 [==============================] - 0s 57us/step - loss: 3697407926631.1802 - val_loss: 3830495370330.7344\n",
      "Epoch 9/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3665386350724.0513 - val_loss: 3799299580261.1758\n",
      "Epoch 10/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3653339979820.1772 - val_loss: 3959680943024.7871\n",
      "Epoch 11/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3675570564974.9829 - val_loss: 3795451420637.4346\n",
      "Epoch 12/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3665466528803.2939 - val_loss: 3815971641122.2056\n",
      "Epoch 13/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3648726111182.7808 - val_loss: 3781093487001.0239\n",
      "Epoch 14/800\n",
      "4265/4265 [==============================] - 0s 58us/step - loss: 3655069076788.5205 - val_loss: 3826148662224.4727\n",
      "Epoch 15/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3647755563250.9746 - val_loss: 3771978251227.9941\n",
      "Epoch 16/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3648462478370.8140 - val_loss: 3775777418682.1489\n",
      "Epoch 17/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3640680166295.0791 - val_loss: 3803539880025.2939\n",
      "Epoch 18/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3630686789188.3066 - val_loss: 3762292165371.3193\n",
      "Epoch 19/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3643751524472.5269 - val_loss: 3797269181700.6807\n",
      "Epoch 20/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3635870241911.8066 - val_loss: 3774456121853.8398\n",
      "Epoch 21/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3631685869635.2266 - val_loss: 3855873383122.9932\n",
      "Epoch 22/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3621851745131.3818 - val_loss: 3887988865044.1631\n",
      "Epoch 23/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3634711610945.9058 - val_loss: 3761252175601.2378\n",
      "Epoch 24/800\n",
      "4265/4265 [==============================] - 0s 58us/step - loss: 3622493471123.3574 - val_loss: 3748639901998.4473\n",
      "Epoch 25/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3612714162312.8535 - val_loss: 3766185341498.3291\n",
      "Epoch 26/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3608065799612.4136 - val_loss: 3759454408640.6299\n",
      "Epoch 27/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3612127226906.1704 - val_loss: 3772314760060.9395\n",
      "Epoch 28/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3607835693450.7139 - val_loss: 3744302868148.7480\n",
      "Epoch 29/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3605247231749.8223 - val_loss: 3733135046330.5093\n",
      "Epoch 30/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3606450996982.4561 - val_loss: 3736550861920.4951\n",
      "Epoch 31/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3607166369534.6196 - val_loss: 3735354136953.3389\n",
      "Epoch 32/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3599533687041.3804 - val_loss: 3727777816979.2632\n",
      "Epoch 33/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3590561294863.7261 - val_loss: 3741729622088.0112\n",
      "Epoch 34/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3602293820332.6875 - val_loss: 3737737969410.5205\n",
      "Epoch 35/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3593587723434.2266 - val_loss: 3744716497091.8706\n",
      "Epoch 36/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3590664062871.7993 - val_loss: 3746454415213.0972\n",
      "Epoch 37/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3586793250529.8081 - val_loss: 3719048797850.8242\n",
      "Epoch 38/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3583804019977.7837 - val_loss: 3713428476578.0254\n",
      "Epoch 39/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3580956866802.4946 - val_loss: 3711713717828.4106\n",
      "Epoch 40/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3579070090863.5234 - val_loss: 3713944695262.1548\n",
      "Epoch 41/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3570822567473.5791 - val_loss: 3782163418703.9326\n",
      "Epoch 42/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3578954156834.3936 - val_loss: 3705090425868.9619\n",
      "Epoch 43/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3566793365022.3721 - val_loss: 3711370010912.0449\n",
      "Epoch 44/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3571538732834.6338 - val_loss: 3700848718786.0703\n",
      "Epoch 45/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3570075441092.9370 - val_loss: 3710054530288.5176\n",
      "Epoch 46/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3568005958346.0391 - val_loss: 3697234538351.9775\n",
      "Epoch 47/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3566982545342.6943 - val_loss: 3697203299709.6597\n",
      "Epoch 48/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3562720242971.5508 - val_loss: 3710708515783.8311\n",
      "Epoch 49/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3559526583616.0449 - val_loss: 3694027578159.1675\n",
      "Epoch 50/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3560133910107.3555 - val_loss: 3707513511348.3882\n",
      "Epoch 51/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3560431535558.9775 - val_loss: 3687537301973.5132\n",
      "Epoch 52/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3556124428629.4131 - val_loss: 3702082316832.4053\n",
      "Epoch 53/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3560548514537.7314 - val_loss: 3689992572542.0195\n",
      "Epoch 54/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3542738847605.2261 - val_loss: 3697274046881.6650\n",
      "Epoch 55/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3544002542121.6562 - val_loss: 3686939357039.9775\n",
      "Epoch 56/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3544912205526.7637 - val_loss: 3687150415405.3672\n",
      "Epoch 57/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3549163471481.8477 - val_loss: 3693639804135.8765\n",
      "Epoch 58/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3546007790860.6650 - val_loss: 3700291347180.9170\n",
      "Epoch 59/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3536467991836.5112 - val_loss: 3678773540838.0762\n",
      "Epoch 60/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3543699801819.5659 - val_loss: 3676796435673.4741\n",
      "Epoch 61/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3538278986462.6870 - val_loss: 3669789476982.0986\n",
      "Epoch 62/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3530102869807.5986 - val_loss: 3722282412299.8818\n",
      "Epoch 63/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3538091078078.5747 - val_loss: 3667415092769.8452\n",
      "Epoch 64/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 65us/step - loss: 3527571943981.9780 - val_loss: 3685443463458.9253\n",
      "Epoch 65/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3534457742600.8237 - val_loss: 3678361978445.0522\n",
      "Epoch 66/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3533268805514.3540 - val_loss: 3661637697098.1714\n",
      "Epoch 67/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3531159430412.6650 - val_loss: 3660383481850.2393\n",
      "Epoch 68/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3527824987497.8213 - val_loss: 3659482641876.0732\n",
      "Epoch 69/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3522342207568.6714 - val_loss: 3713607046416.2026\n",
      "Epoch 70/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3518877305818.7856 - val_loss: 3663261223836.6245\n",
      "Epoch 71/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3524860194912.9976 - val_loss: 3702768166281.1816\n",
      "Epoch 72/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3519845235998.4321 - val_loss: 3686508665140.2080\n",
      "Epoch 73/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3518153513757.5913 - val_loss: 3653364919139.0156\n",
      "Epoch 74/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3516275949122.3862 - val_loss: 3671303309176.6187\n",
      "Epoch 75/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3517714553414.4673 - val_loss: 3670183519970.8354\n",
      "Epoch 76/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3514913348028.1738 - val_loss: 3665696917299.4883\n",
      "Epoch 77/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3512350640976.4912 - val_loss: 3650220894890.6665\n",
      "Epoch 78/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3503769049109.6084 - val_loss: 3674173328054.1885\n",
      "Epoch 79/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3504372922675.8003 - val_loss: 3651068073140.0283\n",
      "Epoch 80/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3507841858554.4775 - val_loss: 3647093794231.2686\n",
      "Epoch 81/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3501080252607.1147 - val_loss: 3638584448456.5513\n",
      "Epoch 82/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3504715480285.1265 - val_loss: 3637975529976.0786\n",
      "Epoch 83/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3502394501778.3374 - val_loss: 3645470216981.2432\n",
      "Epoch 84/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3501294245333.3833 - val_loss: 3634540542110.4248\n",
      "Epoch 85/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3500584828536.1670 - val_loss: 3633206234680.8887\n",
      "Epoch 86/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3496852290423.8667 - val_loss: 3638849477884.0396\n",
      "Epoch 87/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3495371739342.4805 - val_loss: 3631439145204.8384\n",
      "Epoch 88/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3493240275612.4214 - val_loss: 3630198565869.2769\n",
      "Epoch 89/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3491388260275.1699 - val_loss: 3646849710883.6455\n",
      "Epoch 90/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3491867634679.5967 - val_loss: 3629531673008.0674\n",
      "Epoch 91/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3492719309158.2197 - val_loss: 3623911204624.9229\n",
      "Epoch 92/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3481364222154.6392 - val_loss: 3639694194339.4653\n",
      "Epoch 93/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3487397535123.5977 - val_loss: 3621303475014.2109\n",
      "Epoch 94/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3478504757799.7358 - val_loss: 3629948314948.0508\n",
      "Epoch 95/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3480653937055.3623 - val_loss: 3618326971105.3950\n",
      "Epoch 96/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3475151354958.9907 - val_loss: 3698796982220.1519\n",
      "Epoch 97/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3486583212016.1538 - val_loss: 3617566456335.1226\n",
      "Epoch 98/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3478292107385.9678 - val_loss: 3614241172230.8413\n",
      "Epoch 99/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3476901609191.5703 - val_loss: 3627163465955.5557\n",
      "Epoch 100/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3479197803965.3740 - val_loss: 3619503267275.4316\n",
      "Epoch 101/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3476860096030.8521 - val_loss: 3613637172176.4727\n",
      "Epoch 102/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3473860173537.8081 - val_loss: 3609072126876.6245\n",
      "Epoch 103/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3468648008486.2349 - val_loss: 3611471303422.1997\n",
      "Epoch 104/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3472177704672.8481 - val_loss: 3620639265902.8975\n",
      "Epoch 105/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3471573035239.9307 - val_loss: 3606095017935.0322\n",
      "Epoch 106/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3470353518579.5151 - val_loss: 3606256634688.4502\n",
      "Epoch 107/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3468127915650.7310 - val_loss: 3605638692702.6948\n",
      "Epoch 108/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3458111185723.8433 - val_loss: 3602209574871.6738\n",
      "Epoch 109/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3466566800557.5879 - val_loss: 3621620651925.4233\n",
      "Epoch 110/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3464014872541.4263 - val_loss: 3598971409588.0283\n",
      "Epoch 111/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3458349548929.8306 - val_loss: 3598310682456.9341\n",
      "Epoch 112/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3459384836472.4668 - val_loss: 3606621181499.7695\n",
      "Epoch 113/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3460598137308.3462 - val_loss: 3616648815179.6118\n",
      "Epoch 114/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3458021862045.8613 - val_loss: 3598137907439.0771\n",
      "Epoch 115/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3455440732417.3804 - val_loss: 3607584826530.7456\n",
      "Epoch 116/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3454079038163.1626 - val_loss: 3590850435864.1235\n",
      "Epoch 117/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3454178358163.2378 - val_loss: 3601995602689.0801\n",
      "Epoch 118/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3448114773770.1440 - val_loss: 3590382583669.7383\n",
      "Epoch 119/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3441124971931.7607 - val_loss: 3587222874287.7075\n",
      "Epoch 120/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3449323786262.0884 - val_loss: 3585977540227.7808\n",
      "Epoch 121/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3451016790088.9883 - val_loss: 3588584566363.4541\n",
      "Epoch 122/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3447867293914.9653 - val_loss: 3589801193627.5444\n",
      "Epoch 123/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3444166253648.9116 - val_loss: 3585862563353.2041\n",
      "Epoch 124/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3443372951140.4790 - val_loss: 3582590966782.5596\n",
      "Epoch 125/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3442856799346.5244 - val_loss: 3579856832514.8804\n",
      "Epoch 126/800\n",
      "4265/4265 [==============================] - 0s 58us/step - loss: 3442222164918.2910 - val_loss: 3594688837536.9453\n",
      "Epoch 127/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 62us/step - loss: 3439264139275.0444 - val_loss: 3582838371726.9424\n",
      "Epoch 128/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3439687936754.3750 - val_loss: 3592949124227.0605\n",
      "Epoch 129/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3438582825912.6919 - val_loss: 3577739058520.2139\n",
      "Epoch 130/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3436851327361.1104 - val_loss: 3597533254421.2432\n",
      "Epoch 131/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3434602448257.8306 - val_loss: 3573041983343.9775\n",
      "Epoch 132/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3437832406228.9629 - val_loss: 3574991817789.9297\n",
      "Epoch 133/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3432497804133.1396 - val_loss: 3570595990313.4062\n",
      "Epoch 134/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3429092252491.6899 - val_loss: 3568810347973.6709\n",
      "Epoch 135/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3431565000665.5850 - val_loss: 3569815102788.0508\n",
      "Epoch 136/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3429317626508.5752 - val_loss: 3572826679056.9229\n",
      "Epoch 137/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3425869126859.8394 - val_loss: 3570229738644.3433\n",
      "Epoch 138/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3425469693283.5786 - val_loss: 3566623180664.6187\n",
      "Epoch 139/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3427186092402.2246 - val_loss: 3566003063362.9707\n",
      "Epoch 140/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3425972394385.9170 - val_loss: 3562315944586.9819\n",
      "Epoch 141/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3423075835425.7334 - val_loss: 3580307902331.4995\n",
      "Epoch 142/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3418858923149.8955 - val_loss: 3561342015104.8999\n",
      "Epoch 143/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3423617857544.1631 - val_loss: 3595553028600.0786\n",
      "Epoch 144/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3419246578869.7510 - val_loss: 3569112169366.8638\n",
      "Epoch 145/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3413941387148.7549 - val_loss: 3555717957450.5317\n",
      "Epoch 146/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3414917441825.5532 - val_loss: 3556849161902.9873\n",
      "Epoch 147/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3417938929181.4111 - val_loss: 3554453049234.5430\n",
      "Epoch 148/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3412783907373.0176 - val_loss: 3564041126049.3052\n",
      "Epoch 149/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3414198595204.6519 - val_loss: 3558627447619.3306\n",
      "Epoch 150/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3412921764446.4771 - val_loss: 3549636871088.7876\n",
      "Epoch 151/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3412182136552.0508 - val_loss: 3553343320680.4165\n",
      "Epoch 152/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3408148150541.3853 - val_loss: 3552277900730.1489\n",
      "Epoch 153/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3409244710510.0830 - val_loss: 3548240794642.7231\n",
      "Epoch 154/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3408292293231.7637 - val_loss: 3547284780546.1602\n",
      "Epoch 155/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3407239211243.7720 - val_loss: 3544107743851.2969\n",
      "Epoch 156/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3403102521792.9751 - val_loss: 3562003810721.6650\n",
      "Epoch 157/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3404642915862.6890 - val_loss: 3546629785556.7935\n",
      "Epoch 158/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3405033102670.4507 - val_loss: 3548833635326.5596\n",
      "Epoch 159/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3401815815689.2437 - val_loss: 3540155827927.3135\n",
      "Epoch 160/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3402700642563.7812 - val_loss: 3544900650550.0083\n",
      "Epoch 161/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3395698440146.3823 - val_loss: 3537898337817.2041\n",
      "Epoch 162/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3392356187737.4346 - val_loss: 3543465782322.4077\n",
      "Epoch 163/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3398863378722.5132 - val_loss: 3535635780327.1562\n",
      "Epoch 164/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3391957807777.2231 - val_loss: 3534387223112.7314\n",
      "Epoch 165/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3395230872486.4448 - val_loss: 3534094748203.9268\n",
      "Epoch 166/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3393442635370.7217 - val_loss: 3531858334692.6357\n",
      "Epoch 167/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3389050379982.6011 - val_loss: 3541670562693.5811\n",
      "Epoch 168/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3391945428188.1660 - val_loss: 3530451884201.9468\n",
      "Epoch 169/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3389577716044.2896 - val_loss: 3528239019775.6401\n",
      "Epoch 170/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3389090531285.2637 - val_loss: 3532701332648.5063\n",
      "Epoch 171/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3382101888535.1689 - val_loss: 3526711422255.8877\n",
      "Epoch 172/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3387374308691.2529 - val_loss: 3530798345658.1489\n",
      "Epoch 173/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3383498009764.4644 - val_loss: 3522812275439.7974\n",
      "Epoch 174/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3376526087130.3052 - val_loss: 3558057050296.3486\n",
      "Epoch 175/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3382089609470.4995 - val_loss: 3519958718173.0747\n",
      "Epoch 176/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3381231263319.5142 - val_loss: 3520056468757.9634\n",
      "Epoch 177/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3377665821877.7510 - val_loss: 3548298903966.7847\n",
      "Epoch 178/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3376885433941.1133 - val_loss: 3518099719388.3545\n",
      "Epoch 179/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3376826979394.0259 - val_loss: 3515738239223.7188\n",
      "Epoch 180/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3374462487718.3853 - val_loss: 3513619242996.4780\n",
      "Epoch 181/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3373139225802.8794 - val_loss: 3517985076553.8115\n",
      "Epoch 182/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3364862469699.8262 - val_loss: 3520118447932.1294\n",
      "Epoch 183/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3369397169865.7988 - val_loss: 3511042320283.1841\n",
      "Epoch 184/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3370318564844.9126 - val_loss: 3510822765281.3950\n",
      "Epoch 185/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3365912294033.8569 - val_loss: 3512647485880.7090\n",
      "Epoch 186/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3362025353597.2690 - val_loss: 3520039242099.5781\n",
      "Epoch 187/800\n",
      "4265/4265 [==============================] - 0s 58us/step - loss: 3368604279227.6934 - val_loss: 3506940699119.4375\n",
      "Epoch 188/800\n",
      "4265/4265 [==============================] - 0s 58us/step - loss: 3364159229236.5205 - val_loss: 3518231103306.5317\n",
      "Epoch 189/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3363176912975.2310 - val_loss: 3510720642311.5610\n",
      "Epoch 190/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 66us/step - loss: 3363530171099.8057 - val_loss: 3503711290035.3081\n",
      "Epoch 191/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3361030795672.1597 - val_loss: 3506107260386.4756\n",
      "Epoch 192/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3361860349653.3232 - val_loss: 3501799312722.4531\n",
      "Epoch 193/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3361858796857.3223 - val_loss: 3500677088637.6597\n",
      "Epoch 194/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3360217491914.5791 - val_loss: 3501521255733.6484\n",
      "Epoch 195/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3358152018403.5488 - val_loss: 3503553328549.9858\n",
      "Epoch 196/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3359126318590.1992 - val_loss: 3503936718390.0083\n",
      "Epoch 197/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3352263550812.2559 - val_loss: 3511294868927.9102\n",
      "Epoch 198/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3353406085614.1133 - val_loss: 3520219235479.2236\n",
      "Epoch 199/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3354124398312.5308 - val_loss: 3506264021392.3823\n",
      "Epoch 200/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3351597454832.2739 - val_loss: 3497317519342.7173\n",
      "Epoch 201/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3351506367260.1514 - val_loss: 3516636550300.9844\n",
      "Epoch 202/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3349153093749.6460 - val_loss: 3491185586999.8086\n",
      "Epoch 203/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3351763340508.1660 - val_loss: 3490164326330.8691\n",
      "Epoch 204/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3347386232126.1245 - val_loss: 3489314485716.0732\n",
      "Epoch 205/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3346569559403.2622 - val_loss: 3489488021725.7944\n",
      "Epoch 206/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3346097126129.4141 - val_loss: 3489238319057.9126\n",
      "Epoch 207/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3344255936509.5991 - val_loss: 3499134597946.6890\n",
      "Epoch 208/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3341829909649.2568 - val_loss: 3486351868802.7002\n",
      "Epoch 209/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3344213944667.1753 - val_loss: 3489213224023.8535\n",
      "Epoch 210/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3342242591178.0986 - val_loss: 3494813496258.0703\n",
      "Epoch 211/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3342397301406.3423 - val_loss: 3483998075983.2124\n",
      "Epoch 212/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3337550554857.0112 - val_loss: 3482756199200.7651\n",
      "Epoch 213/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3339183286492.4062 - val_loss: 3480586265555.3530\n",
      "Epoch 214/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3338376523796.1680 - val_loss: 3488820204170.9819\n",
      "Epoch 215/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3338721321307.6558 - val_loss: 3482868101137.2827\n",
      "Epoch 216/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3334327698990.6982 - val_loss: 3481722721367.8535\n",
      "Epoch 217/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3337428802982.8052 - val_loss: 3477806457027.8706\n",
      "Epoch 218/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3334135171709.2085 - val_loss: 3476497937783.8989\n",
      "Epoch 219/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3330473208201.2739 - val_loss: 3478361741067.1616\n",
      "Epoch 220/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3331409241756.1812 - val_loss: 3487306176198.0308\n",
      "Epoch 221/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3333413235307.9224 - val_loss: 3472932680204.2417\n",
      "Epoch 222/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3328777445070.6011 - val_loss: 3472634849962.6665\n",
      "Epoch 223/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3329065276170.8643 - val_loss: 3508378411480.3940\n",
      "Epoch 224/800\n",
      "4265/4265 [==============================] - 0s 58us/step - loss: 3328224801387.4419 - val_loss: 3485745895110.0308\n",
      "Epoch 225/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3324515744432.1084 - val_loss: 3490203722039.0884\n",
      "Epoch 226/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3327715869617.0093 - val_loss: 3468581275627.8369\n",
      "Epoch 227/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3324270517908.9780 - val_loss: 3467148026351.4375\n",
      "Epoch 228/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3324621725163.9521 - val_loss: 3465945498083.9155\n",
      "Epoch 229/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3324572563606.2983 - val_loss: 3467400067668.2529\n",
      "Epoch 230/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3320519072422.5049 - val_loss: 3464785469589.7832\n",
      "Epoch 231/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3319350812904.4106 - val_loss: 3464847471254.5034\n",
      "Epoch 232/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3322580885260.0645 - val_loss: 3467572441911.8086\n",
      "Epoch 233/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3321375797613.9033 - val_loss: 3461867784747.9268\n",
      "Epoch 234/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3319075230229.0083 - val_loss: 3462568379520.1802\n",
      "Epoch 235/800\n",
      "4265/4265 [==============================] - 0s 58us/step - loss: 3314791769733.1318 - val_loss: 3471699076258.7456\n",
      "Epoch 236/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3313154584876.5977 - val_loss: 3459235948581.4458\n",
      "Epoch 237/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3315782013806.7432 - val_loss: 3465706622958.7173\n",
      "Epoch 238/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3314554431009.2529 - val_loss: 3457628509225.7666\n",
      "Epoch 239/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3313022209593.7427 - val_loss: 3455861303978.6665\n",
      "Epoch 240/800\n",
      "4265/4265 [==============================] - 0s 58us/step - loss: 3314588162764.9199 - val_loss: 3458925102945.5752\n",
      "Epoch 241/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3309587246102.3286 - val_loss: 3455325201063.7861\n",
      "Epoch 242/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3311807563187.7700 - val_loss: 3453010723576.4390\n",
      "Epoch 243/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3304778289101.1001 - val_loss: 3453399047696.5625\n",
      "Epoch 244/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3307227535343.1934 - val_loss: 3464811066052.5908\n",
      "Epoch 245/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3308260594323.7778 - val_loss: 3453178912364.7368\n",
      "Epoch 246/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3307448345411.5264 - val_loss: 3450700661611.6567\n",
      "Epoch 247/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3308830178655.7373 - val_loss: 3449628251892.1182\n",
      "Epoch 248/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3307084373618.4048 - val_loss: 3452147738523.1841\n",
      "Epoch 249/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3303714763087.1709 - val_loss: 3447299147064.5288\n",
      "Epoch 250/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3301324421400.9097 - val_loss: 3454731953706.4868\n",
      "Epoch 251/800\n",
      "4265/4265 [==============================] - 0s 66us/step - loss: 3300167357767.2480 - val_loss: 3446677717199.3926\n",
      "Epoch 252/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3300182109805.6025 - val_loss: 3444433081362.7231\n",
      "Epoch 253/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265/4265 [==============================] - 0s 60us/step - loss: 3299244700686.1655 - val_loss: 3444284267265.0801\n",
      "Epoch 254/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3299192104027.9561 - val_loss: 3449226777434.3740\n",
      "Epoch 255/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3302278208251.0181 - val_loss: 3445727891692.1968\n",
      "Epoch 256/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3294328392920.3242 - val_loss: 3453103802025.2266\n",
      "Epoch 257/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3292175168226.5283 - val_loss: 3439325014168.6641\n",
      "Epoch 258/800\n",
      "4265/4265 [==============================] - 0s 64us/step - loss: 3295616621579.7646 - val_loss: 3438240236856.5288\n",
      "Epoch 259/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3292547951346.3750 - val_loss: 3437532941373.9297\n",
      "Epoch 260/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3291861489236.1528 - val_loss: 3441888989696.7202\n",
      "Epoch 261/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3291771101247.3848 - val_loss: 3441660367314.6328\n",
      "Epoch 262/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3288849847123.8525 - val_loss: 3434717681096.5513\n",
      "Epoch 263/800\n",
      "4265/4265 [==============================] - 0s 62us/step - loss: 3293320709601.8682 - val_loss: 3433827181984.2251\n",
      "Epoch 264/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3290148423157.0757 - val_loss: 3432970641396.4780\n",
      "Epoch 265/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3288156267143.2930 - val_loss: 3431770468000.5850\n",
      "Epoch 266/800\n",
      "4265/4265 [==============================] - 0s 59us/step - loss: 3286532319329.4780 - val_loss: 3430963060056.2139\n",
      "Epoch 267/800\n",
      "4265/4265 [==============================] - 0s 60us/step - loss: 3289346541225.6260 - val_loss: 3432961412895.3247\n",
      "Epoch 268/800\n",
      "4265/4265 [==============================] - 0s 61us/step - loss: 3286485655085.2578 - val_loss: 3433577234132.4331\n",
      "Epoch 269/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3284069801747.7476 - val_loss: 3428463100387.9155\n",
      "Epoch 270/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3286510726838.5913 - val_loss: 3427361540329.3164\n",
      "Epoch 271/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3284653450950.4375 - val_loss: 3426652079116.9619\n",
      "Epoch 272/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3284076245142.7793 - val_loss: 3433447816109.9072\n",
      "Epoch 273/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3280766947400.0283 - val_loss: 3433761910709.1084\n",
      "Epoch 274/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3282417426921.7915 - val_loss: 3428658657599.7300\n",
      "Epoch 275/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3278200471590.4150 - val_loss: 3448990586796.4668\n",
      "Epoch 276/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3276794981248.5103 - val_loss: 3424134062851.9604\n",
      "Epoch 277/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3276738872444.6089 - val_loss: 3421553712725.6934\n",
      "Epoch 278/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3276145722811.4536 - val_loss: 3420338073939.8931\n",
      "Epoch 279/800\n",
      "4265/4265 [==============================] - 0s 63us/step - loss: 3274872148923.5732 - val_loss: 3427498490843.9941\n",
      "Epoch 280/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3273963912927.8872 - val_loss: 3421645587745.4854\n",
      "Epoch 281/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3272991800982.8989 - val_loss: 3417806280182.6387\n",
      "Epoch 282/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3272619099456.5249 - val_loss: 3431563393781.5586\n",
      "Epoch 283/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3274114714506.1143 - val_loss: 3426901015631.2124\n",
      "Epoch 284/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3273462195741.4111 - val_loss: 3416211221692.6694\n",
      "Epoch 285/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3269054392571.1382 - val_loss: 3414317221337.8340\n",
      "Epoch 286/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3271369698902.5537 - val_loss: 3413575806947.1953\n",
      "Epoch 287/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3270697368873.9565 - val_loss: 3422649364773.8057\n",
      "Epoch 288/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3270234502657.5605 - val_loss: 3413482445338.6440\n",
      "Epoch 289/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 3267323925447.0977 - val_loss: 3413433315644.8496\n",
      "Epoch 290/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3264316732345.6523 - val_loss: 3410642429597.7046\n",
      "Epoch 291/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3268146651452.9238 - val_loss: 3409483959957.0635\n",
      "Epoch 292/800\n",
      "4265/4265 [==============================] - 0s 114us/step - loss: 3264701089107.7329 - val_loss: 3408276089998.5825\n",
      "Epoch 293/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 3265354775504.2212 - val_loss: 3415535653008.0225\n",
      "Epoch 294/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3265216392852.0176 - val_loss: 3407885262421.6934\n",
      "Epoch 295/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3262819266061.5654 - val_loss: 3410714486014.9199\n",
      "Epoch 296/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3261087866835.8228 - val_loss: 3421638013590.5034\n",
      "Epoch 297/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3261061101779.7627 - val_loss: 3407650180826.1943\n",
      "Epoch 298/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3262064018379.8999 - val_loss: 3404873792337.7329\n",
      "Epoch 299/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3257160640060.1436 - val_loss: 3407565360466.4531\n",
      "Epoch 300/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3259727376169.8364 - val_loss: 3403598771852.4219\n",
      "Epoch 301/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3257480655928.4219 - val_loss: 3402768822104.9341\n",
      "Epoch 302/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3256811302048.6230 - val_loss: 3399389956651.9268\n",
      "Epoch 303/800\n",
      "4265/4265 [==============================] - 0s 113us/step - loss: 3256448424253.4038 - val_loss: 3400789873452.2871\n",
      "Epoch 304/800\n",
      "4265/4265 [==============================] - 1s 126us/step - loss: 3255264472482.0034 - val_loss: 3399655498937.7891\n",
      "Epoch 305/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3253093492341.7661 - val_loss: 3397820113391.4375\n",
      "Epoch 306/800\n",
      "4265/4265 [==============================] - 0s 113us/step - loss: 3252005251557.4697 - val_loss: 3403229370030.9873\n",
      "Epoch 307/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3253146809573.2896 - val_loss: 3395310737554.9028\n",
      "Epoch 308/800\n",
      "4265/4265 [==============================] - 0s 114us/step - loss: 3250157672723.1475 - val_loss: 3394457286653.1196\n",
      "Epoch 309/800\n",
      "4265/4265 [==============================] - 1s 134us/step - loss: 3248643910394.0576 - val_loss: 3395307887891.0830\n",
      "Epoch 310/800\n",
      "4265/4265 [==============================] - 0s 113us/step - loss: 3250213071433.3486 - val_loss: 3408139891995.7241\n",
      "Epoch 311/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3251104392810.2417 - val_loss: 3396475089028.5005\n",
      "Epoch 312/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3250485239844.4941 - val_loss: 3397530421043.4883\n",
      "Epoch 313/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3246587518743.5894 - val_loss: 3393560050698.0815\n",
      "Epoch 314/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 3247327390158.4209 - val_loss: 3391905085114.5093\n",
      "Epoch 315/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3247492304487.8403 - val_loss: 3388694145199.7075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 316/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3245663024933.5146 - val_loss: 3388457692786.4980\n",
      "Epoch 317/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3241928138558.0044 - val_loss: 3390400634061.9521\n",
      "Epoch 318/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3243387119060.4229 - val_loss: 3397496268215.2686\n",
      "Epoch 319/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3233828940392.0806 - val_loss: 3388120492645.5356\n",
      "Epoch 320/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3242581394306.9111 - val_loss: 3384420945810.5430\n",
      "Epoch 321/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3239878317317.9424 - val_loss: 3397883265761.3950\n",
      "Epoch 322/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3243431691530.7441 - val_loss: 3383701810710.3237\n",
      "Epoch 323/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3237838014302.1768 - val_loss: 3386256920166.9761\n",
      "Epoch 324/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3241142877846.8989 - val_loss: 3385591493247.4600\n",
      "Epoch 325/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3238881961509.0947 - val_loss: 3387523417838.3574\n",
      "Epoch 326/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3237938332354.8364 - val_loss: 3379108442797.5469\n",
      "Epoch 327/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3232108136946.9150 - val_loss: 3378175012166.9312\n",
      "Epoch 328/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3237694558656.4951 - val_loss: 3378770679286.6387\n",
      "Epoch 329/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3233407997239.8818 - val_loss: 3383128273927.2012\n",
      "Epoch 330/800\n",
      "4265/4265 [==============================] - 0s 113us/step - loss: 3230945169172.7080 - val_loss: 3377644584614.3462\n",
      "Epoch 331/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3234445440509.7192 - val_loss: 3382918942910.1099\n",
      "Epoch 332/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3232902561480.8384 - val_loss: 3390924845741.5469\n",
      "Epoch 333/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3232532836779.3667 - val_loss: 3374012366755.8257\n",
      "Epoch 334/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3232236730963.9131 - val_loss: 3374970190788.9507\n",
      "Epoch 335/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3231978253660.8564 - val_loss: 3379460996244.3433\n",
      "Epoch 336/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3229144615745.1255 - val_loss: 3373044545855.7300\n",
      "Epoch 337/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3226227624703.8198 - val_loss: 3382109788813.8623\n",
      "Epoch 338/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3228348558481.2568 - val_loss: 3370945073641.6763\n",
      "Epoch 339/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3228052893362.7495 - val_loss: 3370334340800.2700\n",
      "Epoch 340/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3225284891326.0342 - val_loss: 3375082932987.3193\n",
      "Epoch 341/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3223871051190.6514 - val_loss: 3367042496094.3350\n",
      "Epoch 342/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3220192080714.2490 - val_loss: 3366111276174.5825\n",
      "Epoch 343/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3225280649879.1392 - val_loss: 3365892547792.8325\n",
      "Epoch 344/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3224258674211.6538 - val_loss: 3368264128059.7695\n",
      "Epoch 345/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3223002213840.1011 - val_loss: 3370633197127.2910\n",
      "Epoch 346/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3222547133331.2378 - val_loss: 3363991063982.6274\n",
      "Epoch 347/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3220888266553.6826 - val_loss: 3363719529623.2236\n",
      "Epoch 348/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3220171074559.2798 - val_loss: 3365980069599.9551\n",
      "Epoch 349/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3218293634311.8628 - val_loss: 3364932340129.6650\n",
      "Epoch 350/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3214733944195.7515 - val_loss: 3362297403953.6880\n",
      "Epoch 351/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3220617073269.0459 - val_loss: 3359163571244.6470\n",
      "Epoch 352/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3216778959534.1880 - val_loss: 3374986097509.8960\n",
      "Epoch 353/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3214168979683.1289 - val_loss: 3374960024321.0801\n",
      "Epoch 354/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3215822862313.4312 - val_loss: 3358036653639.2910\n",
      "Epoch 355/800\n",
      "4265/4265 [==============================] - 0s 68us/step - loss: 3213581274962.1724 - val_loss: 3356548088291.9155\n",
      "Epoch 356/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3215721681828.5239 - val_loss: 3355264345895.9663\n",
      "Epoch 357/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3212291332932.0063 - val_loss: 3355067467640.6187\n",
      "Epoch 358/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3213432486883.4287 - val_loss: 3357839602464.7651\n",
      "Epoch 359/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3211458832673.5532 - val_loss: 3363949641912.3486\n",
      "Epoch 360/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3209992186963.7925 - val_loss: 3370073261230.2671\n",
      "Epoch 361/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3211930171273.3936 - val_loss: 3352710978166.8184\n",
      "Epoch 362/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3210994121184.6680 - val_loss: 3351579281871.7524\n",
      "Epoch 363/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3209026325109.5259 - val_loss: 3350194644637.7046\n",
      "Epoch 364/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3206099238420.2876 - val_loss: 3362128265400.3486\n",
      "Epoch 365/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3207919830282.7441 - val_loss: 3360641316054.5938\n",
      "Epoch 366/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3208126177685.2783 - val_loss: 3349434575254.1436\n",
      "Epoch 367/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3204148198417.5269 - val_loss: 3349762163817.1362\n",
      "Epoch 368/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3203701510481.0918 - val_loss: 3347934848324.0508\n",
      "Epoch 369/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 3203215783125.9238 - val_loss: 3349435403717.6709\n",
      "Epoch 370/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3203509615203.2788 - val_loss: 3344435136699.2295\n",
      "Epoch 371/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3197417752126.0640 - val_loss: 3361049712072.5513\n",
      "Epoch 372/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3203730801308.4214 - val_loss: 3343066368578.9707\n",
      "Epoch 373/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3202765473207.6118 - val_loss: 3342392483367.6060\n",
      "Epoch 374/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3200345723451.4229 - val_loss: 3342781956349.4795\n",
      "Epoch 375/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3193792190539.3892 - val_loss: 3344160738665.4966\n",
      "Epoch 376/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3196065624852.4678 - val_loss: 3346146879133.7046\n",
      "Epoch 377/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3198677925922.5737 - val_loss: 3338991774793.4517\n",
      "Epoch 378/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3197140812709.4849 - val_loss: 3340455836129.0352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3196175093697.5757 - val_loss: 3340986184042.9365\n",
      "Epoch 380/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3196032765547.6821 - val_loss: 3336845225793.8901\n",
      "Epoch 381/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3193588475210.1294 - val_loss: 3352334969652.9282\n",
      "Epoch 382/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3195785761239.5444 - val_loss: 3335875293731.2856\n",
      "Epoch 383/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3189157916526.9829 - val_loss: 3366463108448.8550\n",
      "Epoch 384/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3193115394351.4785 - val_loss: 3338895602603.0269\n",
      "Epoch 385/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3192545337053.9668 - val_loss: 3333882786224.0674\n",
      "Epoch 386/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3190733920907.6143 - val_loss: 3335366092100.0508\n",
      "Epoch 387/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3189583552579.2266 - val_loss: 3331620196657.3276\n",
      "Epoch 388/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3188990984702.9194 - val_loss: 3331624524798.5596\n",
      "Epoch 389/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3188503133366.7114 - val_loss: 3348989236473.1587\n",
      "Epoch 390/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3188214094437.1992 - val_loss: 3329718451071.8198\n",
      "Epoch 391/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3187584389606.9102 - val_loss: 3332225536558.8071\n",
      "Epoch 392/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3185950184925.0664 - val_loss: 3327739544450.7002\n",
      "Epoch 393/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3188254727694.5254 - val_loss: 3326976570836.0732\n",
      "Epoch 394/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3186982405813.1509 - val_loss: 3326837390806.9536\n",
      "Epoch 395/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3185413938733.2578 - val_loss: 3325603161550.3120\n",
      "Epoch 396/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3184067886762.1064 - val_loss: 3337591610965.6934\n",
      "Epoch 397/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3182560753864.2383 - val_loss: 3325851006350.9424\n",
      "Epoch 398/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3180895592204.0645 - val_loss: 3324908188310.5034\n",
      "Epoch 399/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3184545558490.5449 - val_loss: 3323871597563.6792\n",
      "Epoch 400/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3182038323168.3076 - val_loss: 3321897410640.6528\n",
      "Epoch 401/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3182168852441.1050 - val_loss: 3321879224631.0884\n",
      "Epoch 402/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3180617617011.3652 - val_loss: 3320327713015.7188\n",
      "Epoch 403/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3178070862113.5532 - val_loss: 3321926809113.2041\n",
      "Epoch 404/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3179073650253.9106 - val_loss: 3318579687049.5415\n",
      "Epoch 405/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3176678224141.8652 - val_loss: 3325377776333.2319\n",
      "Epoch 406/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3174587337260.5371 - val_loss: 3318852466132.0732\n",
      "Epoch 407/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3177583464750.5181 - val_loss: 3317359654125.6372\n",
      "Epoch 408/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3177159665488.7314 - val_loss: 3315254139326.4697\n",
      "Epoch 409/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3174385782852.1865 - val_loss: 3319978706808.6187\n",
      "Epoch 410/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3177360045657.9155 - val_loss: 3318042868123.9043\n",
      "Epoch 411/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3172317058786.2881 - val_loss: 3322932889026.7905\n",
      "Epoch 412/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3175917456346.7856 - val_loss: 3317515227556.5459\n",
      "Epoch 413/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3174140582113.2080 - val_loss: 3314481393013.0181\n",
      "Epoch 414/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3173221275742.5972 - val_loss: 3311301873877.1533\n",
      "Epoch 415/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3171796710076.1138 - val_loss: 3313212065956.1855\n",
      "Epoch 416/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3169733764026.6128 - val_loss: 3316440583898.1943\n",
      "Epoch 417/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3171112003654.5879 - val_loss: 3311017181068.7822\n",
      "Epoch 418/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3169041099613.9370 - val_loss: 3307923223374.8525\n",
      "Epoch 419/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3168344845395.7925 - val_loss: 3314115249003.6567\n",
      "Epoch 420/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3169411235663.2910 - val_loss: 3306281584366.3574\n",
      "Epoch 421/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3166307278266.0127 - val_loss: 3305436378649.2041\n",
      "Epoch 422/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3168094014215.5029 - val_loss: 3305607778793.6763\n",
      "Epoch 423/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3164787549471.8721 - val_loss: 3306623040752.5176\n",
      "Epoch 424/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3164975846124.1323 - val_loss: 3304050236760.2139\n",
      "Epoch 425/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3163254649217.1104 - val_loss: 3303030408481.4854\n",
      "Epoch 426/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3164352260742.8130 - val_loss: 3301506308058.5542\n",
      "Epoch 427/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3161630719012.7344 - val_loss: 3312916898817.4404\n",
      "Epoch 428/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3162326054313.2061 - val_loss: 3300440201593.3389\n",
      "Epoch 429/800\n",
      "4265/4265 [==============================] - 0s 109us/step - loss: 3159818199372.2896 - val_loss: 3299387028671.5498\n",
      "Epoch 430/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3161398144364.2222 - val_loss: 3298560237187.7808\n",
      "Epoch 431/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3160506899233.4326 - val_loss: 3298500592238.1772\n",
      "Epoch 432/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3159741876807.4277 - val_loss: 3300902535859.3081\n",
      "Epoch 433/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3159174482376.6582 - val_loss: 3296476235156.7031\n",
      "Epoch 434/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3157890355133.7344 - val_loss: 3295695504696.5288\n",
      "Epoch 435/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3154467459071.0396 - val_loss: 3300435617207.2686\n",
      "Epoch 436/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3157193072761.0073 - val_loss: 3294629916620.1519\n",
      "Epoch 437/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3156569226895.2158 - val_loss: 3294116632031.5947\n",
      "Epoch 438/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3156654379656.2529 - val_loss: 3293994406930.7231\n",
      "Epoch 439/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3156799325174.1562 - val_loss: 3297024738109.5698\n",
      "Epoch 440/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3152767076920.0620 - val_loss: 3302340708723.5781\n",
      "Epoch 441/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3154571229157.5898 - val_loss: 3294117243332.2305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 442/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3152771618618.6431 - val_loss: 3295011664649.7217\n",
      "Epoch 443/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3153499842849.5532 - val_loss: 3289841786407.6060\n",
      "Epoch 444/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3153253267314.3447 - val_loss: 3295713034793.0464\n",
      "Epoch 445/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3151809616704.1650 - val_loss: 3294325401522.2280\n",
      "Epoch 446/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3151486521581.2124 - val_loss: 3290897171883.7471\n",
      "Epoch 447/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3148074371348.1074 - val_loss: 3292841190862.3120\n",
      "Epoch 448/800\n",
      "4265/4265 [==============================] - 0s 117us/step - loss: 3149297706767.4258 - val_loss: 3297152943116.9619\n",
      "Epoch 449/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3150668177559.7393 - val_loss: 3285879191157.3784\n",
      "Epoch 450/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3149703331705.5474 - val_loss: 3284703545738.6216\n",
      "Epoch 451/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 3146916971352.6548 - val_loss: 3285649571079.5610\n",
      "Epoch 452/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3148756658146.7085 - val_loss: 3283374754025.3164\n",
      "Epoch 453/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3144943021377.9658 - val_loss: 3289921696821.2881\n",
      "Epoch 454/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3148131827719.6831 - val_loss: 3282169349916.4443\n",
      "Epoch 455/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3145260322811.1978 - val_loss: 3282679942643.7583\n",
      "Epoch 456/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3145080404425.6187 - val_loss: 3285096317826.7002\n",
      "Epoch 457/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3143199024611.7891 - val_loss: 3282380165678.8071\n",
      "Epoch 458/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3144928593746.6523 - val_loss: 3280663687692.2417\n",
      "Epoch 459/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3141992862697.6714 - val_loss: 3281358952203.1616\n",
      "Epoch 460/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3143490432149.0981 - val_loss: 3280976224912.7427\n",
      "Epoch 461/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3143641731063.3564 - val_loss: 3278978327046.4810\n",
      "Epoch 462/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3141873575315.1177 - val_loss: 3277707562806.3687\n",
      "Epoch 463/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3141268880405.3682 - val_loss: 3278944193390.5371\n",
      "Epoch 464/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3142020492798.1992 - val_loss: 3277614213733.5356\n",
      "Epoch 465/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3136680339611.1006 - val_loss: 3285935389153.0352\n",
      "Epoch 466/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3138637088083.7329 - val_loss: 3281124130539.4766\n",
      "Epoch 467/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3135847676964.7344 - val_loss: 3284549646194.8579\n",
      "Epoch 468/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3139825321315.0986 - val_loss: 3276430506004.1631\n",
      "Epoch 469/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3137426563577.1572 - val_loss: 3273427622887.5161\n",
      "Epoch 470/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3135446242396.9160 - val_loss: 3273147135075.3755\n",
      "Epoch 471/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3136057693000.3281 - val_loss: 3278167804713.4062\n",
      "Epoch 472/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3135665104762.9878 - val_loss: 3271475903290.6890\n",
      "Epoch 473/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3135834380578.5132 - val_loss: 3272424154827.7920\n",
      "Epoch 474/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3130878656004.9219 - val_loss: 3270319251329.2603\n",
      "Epoch 475/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3134290263326.4321 - val_loss: 3272786180853.5586\n",
      "Epoch 476/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3135327256802.6484 - val_loss: 3270939259865.1138\n",
      "Epoch 477/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3132535330053.9424 - val_loss: 3269903151006.0649\n",
      "Epoch 478/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3131919574634.2417 - val_loss: 3276109570589.5244\n",
      "Epoch 479/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3132294948492.8149 - val_loss: 3294919773775.9326\n",
      "Epoch 480/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3134400006423.9492 - val_loss: 3265857451314.7681\n",
      "Epoch 481/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3130970970644.5278 - val_loss: 3269524689178.2842\n",
      "Epoch 482/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3131098105628.8711 - val_loss: 3268310912684.1069\n",
      "Epoch 483/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3129749975313.7070 - val_loss: 3265082464425.9468\n",
      "Epoch 484/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3127252871780.2393 - val_loss: 3280162844067.1055\n",
      "Epoch 485/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3122999381842.1724 - val_loss: 3264695233125.5356\n",
      "Epoch 486/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3127347728386.8813 - val_loss: 3266163234363.7695\n",
      "Epoch 487/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3125402112521.4839 - val_loss: 3261507033373.1646\n",
      "Epoch 488/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3126634337879.9941 - val_loss: 3260668063069.9746\n",
      "Epoch 489/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3127215916851.9204 - val_loss: 3262597845896.4614\n",
      "Epoch 490/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3126208491006.1992 - val_loss: 3259321931508.1182\n",
      "Epoch 491/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3124117008815.2080 - val_loss: 3268343260000.1353\n",
      "Epoch 492/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3123387451061.1509 - val_loss: 3258392305099.4316\n",
      "Epoch 493/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3125159323553.4028 - val_loss: 3261238300378.1943\n",
      "Epoch 494/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3122754560643.4517 - val_loss: 3260604102883.5557\n",
      "Epoch 495/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3124466066735.2388 - val_loss: 3258535456739.1953\n",
      "Epoch 496/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3122940540963.0537 - val_loss: 3258044208838.0308\n",
      "Epoch 497/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3121343310478.4956 - val_loss: 3256586527814.5708\n",
      "Epoch 498/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3121777763850.2041 - val_loss: 3262335602348.1069\n",
      "Epoch 499/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3119816376688.7842 - val_loss: 3271024215168.1802\n",
      "Epoch 500/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3122471861542.1152 - val_loss: 3255467889314.0254\n",
      "Epoch 501/800\n",
      "4265/4265 [==============================] - 1s 118us/step - loss: 3120754994190.6460 - val_loss: 3254992935266.2954\n",
      "Epoch 502/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3118641211289.7202 - val_loss: 3257474878157.2319\n",
      "Epoch 503/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3119407872131.0913 - val_loss: 3259287575527.5161\n",
      "Epoch 504/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3118979779669.7134 - val_loss: 3253224547237.2656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3117988633703.9604 - val_loss: 3253006321021.6597\n",
      "Epoch 506/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3116969569986.1162 - val_loss: 3252516756962.4756\n",
      "Epoch 507/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3119024091163.8506 - val_loss: 3251251315609.7441\n",
      "Epoch 508/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3117633986892.2896 - val_loss: 3250458008136.7314\n",
      "Epoch 509/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3117710735587.1289 - val_loss: 3253817265513.4966\n",
      "Epoch 510/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3116532456021.8335 - val_loss: 3248762516786.7681\n",
      "Epoch 511/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3115539040897.0508 - val_loss: 3249002785957.6260\n",
      "Epoch 512/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3113392755766.5010 - val_loss: 3247801859312.5176\n",
      "Epoch 513/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3113974209198.1880 - val_loss: 3251159691673.0239\n",
      "Epoch 514/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3114253043872.8628 - val_loss: 3247351647455.2349\n",
      "Epoch 515/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3113710918640.8740 - val_loss: 3246530811543.9438\n",
      "Epoch 516/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3113592655194.9355 - val_loss: 3246190447608.7988\n",
      "Epoch 517/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3112588038746.1553 - val_loss: 3246593243110.0762\n",
      "Epoch 518/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3110301976252.8340 - val_loss: 3248785832117.4683\n",
      "Epoch 519/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3112466247319.8594 - val_loss: 3247899694697.8564\n",
      "Epoch 520/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3111919927914.4814 - val_loss: 3244201700448.4951\n",
      "Epoch 521/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3110916035511.7319 - val_loss: 3246899240741.0859\n",
      "Epoch 522/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3110549224142.8408 - val_loss: 3243975144247.8086\n",
      "Epoch 523/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3106172111734.9062 - val_loss: 3248997108383.1450\n",
      "Epoch 524/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3109195330101.6606 - val_loss: 3242938549076.6133\n",
      "Epoch 525/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3106368547512.7520 - val_loss: 3255612472237.9072\n",
      "Epoch 526/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3105722690094.4580 - val_loss: 3241405137195.5669\n",
      "Epoch 527/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3109569079527.9307 - val_loss: 3243390861035.4766\n",
      "Epoch 528/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3108179200276.1074 - val_loss: 3242255694927.2124\n",
      "Epoch 529/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3106409879354.6431 - val_loss: 3240249412139.9268\n",
      "Epoch 530/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3107738733204.2578 - val_loss: 3239496117943.6289\n",
      "Epoch 531/800\n",
      "4265/4265 [==============================] - 0s 115us/step - loss: 3106352281492.9180 - val_loss: 3240718171699.1279\n",
      "Epoch 532/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3104835597994.5869 - val_loss: 3238135608649.8115\n",
      "Epoch 533/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3105619465839.0435 - val_loss: 3238010139378.6777\n",
      "Epoch 534/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3106052989874.9297 - val_loss: 3237155076162.2505\n",
      "Epoch 535/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3104002694778.0874 - val_loss: 3240769972975.7974\n",
      "Epoch 536/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3104638898904.9248 - val_loss: 3235851876856.0786\n",
      "Epoch 537/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3105580852427.3594 - val_loss: 3235257612262.0762\n",
      "Epoch 538/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3104619064100.3140 - val_loss: 3236891108952.5737\n",
      "Epoch 539/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3103180780527.4331 - val_loss: 3235688265079.8989\n",
      "Epoch 540/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3103335865901.2578 - val_loss: 3233472294376.2363\n",
      "Epoch 541/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3101026375355.8730 - val_loss: 3234978939179.5669\n",
      "Epoch 542/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3103068193582.3984 - val_loss: 3232929211646.9199\n",
      "Epoch 543/800\n",
      "4265/4265 [==============================] - 0s 103us/step - loss: 3100091408877.6328 - val_loss: 3233033714191.1226\n",
      "Epoch 544/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3099850515751.5557 - val_loss: 3232570221845.9634\n",
      "Epoch 545/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3101428854473.7988 - val_loss: 3242240592704.4502\n",
      "Epoch 546/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3100430898787.5190 - val_loss: 3234438647491.1504\n",
      "Epoch 547/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3100863991376.7920 - val_loss: 3230339673207.5386\n",
      "Epoch 548/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3098085349305.4121 - val_loss: 3231216620839.2461\n",
      "Epoch 549/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3099123097928.4482 - val_loss: 3232036704238.7173\n",
      "Epoch 550/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3099196260259.8037 - val_loss: 3228815460700.5347\n",
      "Epoch 551/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3097682178532.9893 - val_loss: 3230099129356.9619\n",
      "Epoch 552/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3096754874895.7261 - val_loss: 3228331632101.3560\n",
      "Epoch 553/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3097385521323.9072 - val_loss: 3227826866271.0547\n",
      "Epoch 554/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3097693973599.3174 - val_loss: 3229581880531.7129\n",
      "Epoch 555/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3095281471586.9185 - val_loss: 3228996191844.0957\n",
      "Epoch 556/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3096137339355.3857 - val_loss: 3226427614969.8789\n",
      "Epoch 557/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3094088069109.4355 - val_loss: 3235327298322.3628\n",
      "Epoch 558/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3094906392663.3940 - val_loss: 3224629114669.7271\n",
      "Epoch 559/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3094583962458.0952 - val_loss: 3223737672060.2192\n",
      "Epoch 560/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3096378866544.1841 - val_loss: 3223250334565.8960\n",
      "Epoch 561/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3092649071724.2822 - val_loss: 3225905939192.4390\n",
      "Epoch 562/800\n",
      "4265/4265 [==============================] - 0s 65us/step - loss: 3090041354762.9243 - val_loss: 3224764278475.7920\n",
      "Epoch 563/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3092670697620.8584 - val_loss: 3227759288792.3940\n",
      "Epoch 564/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3092647262684.8262 - val_loss: 3224605992167.8765\n",
      "Epoch 565/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3092667936596.0928 - val_loss: 3228820064258.8804\n",
      "Epoch 566/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3093921563661.2051 - val_loss: 3219766514914.1152\n",
      "Epoch 567/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3091678626806.1562 - val_loss: 3220591743488.7202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 568/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3091289943684.6519 - val_loss: 3222482524376.0337\n",
      "Epoch 569/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3091081666926.8633 - val_loss: 3218821574650.2393\n",
      "Epoch 570/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3090336732045.4756 - val_loss: 3218203614598.3008\n",
      "Epoch 571/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3088266201583.0732 - val_loss: 3218985262009.4292\n",
      "Epoch 572/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3089605925281.2832 - val_loss: 3223069903542.1885\n",
      "Epoch 573/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3089304460418.8511 - val_loss: 3216805278035.8931\n",
      "Epoch 574/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3090367318564.8545 - val_loss: 3216994568494.4473\n",
      "Epoch 575/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3089651933612.3271 - val_loss: 3222079356858.8691\n",
      "Epoch 576/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3087373856815.0586 - val_loss: 3220337455697.3726\n",
      "Epoch 577/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3088370841416.0879 - val_loss: 3224066427919.8423\n",
      "Epoch 578/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3087792926006.4414 - val_loss: 3215564905908.3882\n",
      "Epoch 579/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3087470132395.1865 - val_loss: 3215946312155.2744\n",
      "Epoch 580/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3085651898046.2744 - val_loss: 3215216923205.8511\n",
      "Epoch 581/800\n",
      "4265/4265 [==============================] - 0s 110us/step - loss: 3085135682790.7300 - val_loss: 3223820664048.5176\n",
      "Epoch 582/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3088109554470.2349 - val_loss: 3219793046762.7568\n",
      "Epoch 583/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3082994149473.4780 - val_loss: 3213725544327.0210\n",
      "Epoch 584/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3087126182134.3364 - val_loss: 3213273216882.8579\n",
      "Epoch 585/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3083564007996.3838 - val_loss: 3212305560421.8960\n",
      "Epoch 586/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3084276668864.0151 - val_loss: 3211800252974.8071\n",
      "Epoch 587/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3083396788889.5400 - val_loss: 3220808237562.9590\n",
      "Epoch 588/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3085188165433.2021 - val_loss: 3216232240469.3335\n",
      "Epoch 589/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3084655765167.3882 - val_loss: 3217826656688.0674\n",
      "Epoch 590/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3083929486272.3755 - val_loss: 3210576224843.6118\n",
      "Epoch 591/800\n",
      "4265/4265 [==============================] - 0s 84us/step - loss: 3083660524561.5269 - val_loss: 3211115401221.7607\n",
      "Epoch 592/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3076409058818.5210 - val_loss: 3216440238275.8706\n",
      "Epoch 593/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3082372268058.8906 - val_loss: 3217654370194.5430\n",
      "Epoch 594/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3082323791702.0137 - val_loss: 3212379591583.5049\n",
      "Epoch 595/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3080449012246.9287 - val_loss: 3208001057499.6343\n",
      "Epoch 596/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3082353339356.7061 - val_loss: 3207862943744.0000\n",
      "Epoch 597/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3081378414111.8125 - val_loss: 3207694194904.0337\n",
      "Epoch 598/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3080373415817.8735 - val_loss: 3207557367534.3574\n",
      "Epoch 599/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3080577804085.8408 - val_loss: 3206847341477.2656\n",
      "Epoch 600/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3080715205895.3828 - val_loss: 3208543175347.3081\n",
      "Epoch 601/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3076298228883.6572 - val_loss: 3224096922530.3853\n",
      "Epoch 602/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3078288424287.7373 - val_loss: 3220486987649.2603\n",
      "Epoch 603/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3078976466606.9082 - val_loss: 3206054658946.7002\n",
      "Epoch 604/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3079734997158.1450 - val_loss: 3205739030565.4458\n",
      "Epoch 605/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3077000359860.1304 - val_loss: 3218801862232.5737\n",
      "Epoch 606/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3079300545000.3511 - val_loss: 3211582035239.2461\n",
      "Epoch 607/800\n",
      "4265/4265 [==============================] - 0s 116us/step - loss: 3077941690629.2222 - val_loss: 3205364152109.7271\n",
      "Epoch 608/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3077946145540.6221 - val_loss: 3203922214842.8691\n",
      "Epoch 609/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3077616711849.5063 - val_loss: 3204742109100.4668\n",
      "Epoch 610/800\n",
      "4265/4265 [==============================] - 1s 119us/step - loss: 3076288569322.8716 - val_loss: 3204784233908.3882\n",
      "Epoch 611/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3075730712969.2739 - val_loss: 3202645245790.6948\n",
      "Epoch 612/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3077584451111.9756 - val_loss: 3202923486390.9087\n",
      "Epoch 613/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3077015090140.2261 - val_loss: 3205011435329.8901\n",
      "Epoch 614/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3073587384872.2158 - val_loss: 3219416464924.0845\n",
      "Epoch 615/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3074298187006.7393 - val_loss: 3202086710575.8877\n",
      "Epoch 616/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3077167686406.0620 - val_loss: 3202223132746.8916\n",
      "Epoch 617/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3075597583738.1479 - val_loss: 3207115896022.5938\n",
      "Epoch 618/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3076094422710.5913 - val_loss: 3202772597263.1226\n",
      "Epoch 619/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3074853182241.4326 - val_loss: 3202784366459.4995\n",
      "Epoch 620/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3074713841918.4995 - val_loss: 3199709760228.2759\n",
      "Epoch 621/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3072772642180.7119 - val_loss: 3203245721464.6187\n",
      "Epoch 622/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3074331232885.5259 - val_loss: 3199794615245.5923\n",
      "Epoch 623/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3074154742793.3638 - val_loss: 3199698402498.4302\n",
      "Epoch 624/800\n",
      "4265/4265 [==============================] - 0s 112us/step - loss: 3073088769651.3652 - val_loss: 3207566313613.1421\n",
      "Epoch 625/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3074572041621.5186 - val_loss: 3209149666691.4204\n",
      "Epoch 626/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3072006879758.7656 - val_loss: 3197885396159.5498\n",
      "Epoch 627/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3073160115844.1719 - val_loss: 3205444979105.6650\n",
      "Epoch 628/800\n",
      "4265/4265 [==============================] - 1s 119us/step - loss: 3071270601437.7266 - val_loss: 3200076769202.2280\n",
      "Epoch 629/800\n",
      "4265/4265 [==============================] - 0s 107us/step - loss: 3072052114964.7681 - val_loss: 3198124539696.6074\n",
      "Epoch 630/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3065940583788.7021 - val_loss: 3218661614823.8765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 631/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3071940498966.6890 - val_loss: 3199877110966.9087\n",
      "Epoch 632/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3070350946381.7905 - val_loss: 3198001108217.1587\n",
      "Epoch 633/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3069735678679.0044 - val_loss: 3202030338923.6567\n",
      "Epoch 634/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3070315071406.8481 - val_loss: 3205395800743.7861\n",
      "Epoch 635/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3071062713439.7974 - val_loss: 3196518241091.3306\n",
      "Epoch 636/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3069144337747.2529 - val_loss: 3207626597147.0044\n",
      "Epoch 637/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3070312932244.1978 - val_loss: 3194487540198.7959\n",
      "Epoch 638/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3069392983789.8130 - val_loss: 3194829533777.3726\n",
      "Epoch 639/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3069603673348.0215 - val_loss: 3197747336233.7666\n",
      "Epoch 640/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3068359514444.7695 - val_loss: 3194865182043.0942\n",
      "Epoch 641/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3069539342780.1738 - val_loss: 3195898173932.5571\n",
      "Epoch 642/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3069929926829.8276 - val_loss: 3196110961489.7329\n",
      "Epoch 643/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3066615266044.9385 - val_loss: 3193051979925.7832\n",
      "Epoch 644/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3068461102343.8628 - val_loss: 3197741931126.8184\n",
      "Epoch 645/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3066893997214.2217 - val_loss: 3192597793876.9731\n",
      "Epoch 646/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3063362373516.2749 - val_loss: 3207689667297.3950\n",
      "Epoch 647/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3066584441045.2031 - val_loss: 3191717560780.8721\n",
      "Epoch 648/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3068053137378.7085 - val_loss: 3193826960178.0479\n",
      "Epoch 649/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3068374960411.7910 - val_loss: 3192771552580.0508\n",
      "Epoch 650/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3068510401212.1138 - val_loss: 3191842031250.1826\n",
      "Epoch 651/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3065482587181.3774 - val_loss: 3197571715976.4614\n",
      "Epoch 652/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3067753418339.9990 - val_loss: 3191149064462.7622\n",
      "Epoch 653/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3065400197135.3657 - val_loss: 3190070323099.1841\n",
      "Epoch 654/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3064160783007.7822 - val_loss: 3203148077433.3389\n",
      "Epoch 655/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3068002275357.7715 - val_loss: 3189310396770.2954\n",
      "Epoch 656/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3065364443213.7905 - val_loss: 3192406787868.4443\n",
      "Epoch 657/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3066066738483.5601 - val_loss: 3196535221828.4106\n",
      "Epoch 658/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3065705021743.4785 - val_loss: 3193851488155.1841\n",
      "Epoch 659/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3065174961166.6460 - val_loss: 3194844652960.2251\n",
      "Epoch 660/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3062191449533.3740 - val_loss: 3191735555805.0747\n",
      "Epoch 661/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3066440070016.0298 - val_loss: 3189435961534.1099\n",
      "Epoch 662/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3064398381324.9048 - val_loss: 3188497776916.5234\n",
      "Epoch 663/800\n",
      "4265/4265 [==============================] - 1s 118us/step - loss: 3063765983018.7969 - val_loss: 3191782139641.8789\n",
      "Epoch 664/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3063655485850.0801 - val_loss: 3187299603336.4614\n",
      "Epoch 665/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3065321874654.5674 - val_loss: 3188110027227.2744\n",
      "Epoch 666/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3062765020513.1777 - val_loss: 3187290752381.6597\n",
      "Epoch 667/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3064484380691.2075 - val_loss: 3188479024218.7344\n",
      "Epoch 668/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3063707523984.8369 - val_loss: 3188549694701.6372\n",
      "Epoch 669/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3062461691355.1455 - val_loss: 3185919125011.4429\n",
      "Epoch 670/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3063261223425.3203 - val_loss: 3186273451525.0410\n",
      "Epoch 671/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3062269479414.7563 - val_loss: 3185292112327.1113\n",
      "Epoch 672/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3062365061020.1211 - val_loss: 3185919412964.2759\n",
      "Epoch 673/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3062337689314.2881 - val_loss: 3190274674486.3687\n",
      "Epoch 674/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3062180733713.5869 - val_loss: 3192971308151.5386\n",
      "Epoch 675/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3061829179002.5679 - val_loss: 3187005988783.3472\n",
      "Epoch 676/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3061626808290.7085 - val_loss: 3184353956099.2407\n",
      "Epoch 677/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 3060658861546.5112 - val_loss: 3184260180443.2744\n",
      "Epoch 678/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3061423333623.7769 - val_loss: 3186637438284.6919\n",
      "Epoch 679/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3063178697420.9199 - val_loss: 3184994952746.4868\n",
      "Epoch 680/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3058556342570.6768 - val_loss: 3190726847446.2334\n",
      "Epoch 681/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3061987681160.6733 - val_loss: 3201490751447.6738\n",
      "Epoch 682/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3062452496892.5186 - val_loss: 3187493913612.9619\n",
      "Epoch 683/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3059801961490.0068 - val_loss: 3184078743612.4893\n",
      "Epoch 684/800\n",
      "4265/4265 [==============================] - 0s 109us/step - loss: 3058394090739.2148 - val_loss: 3182795523292.3545\n",
      "Epoch 685/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3059667635831.2065 - val_loss: 3186944053484.1968\n",
      "Epoch 686/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3060795580306.5171 - val_loss: 3183351125886.3799\n",
      "Epoch 687/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3059814644096.6304 - val_loss: 3185220513094.9312\n",
      "Epoch 688/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3059505142814.9717 - val_loss: 3182229825389.0972\n",
      "Epoch 689/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3059694321598.6943 - val_loss: 3183554630375.1562\n",
      "Epoch 690/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3059376423810.9111 - val_loss: 3181316278251.8369\n",
      "Epoch 691/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3059265413386.9839 - val_loss: 3181039426166.8184\n",
      "Epoch 692/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3057183970481.4292 - val_loss: 3181596503551.2798\n",
      "Epoch 693/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3059974287334.0698 - val_loss: 3180594114300.7593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 694/800\n",
      "4265/4265 [==============================] - 0s 106us/step - loss: 3058500896010.7441 - val_loss: 3180672447426.0703\n",
      "Epoch 695/800\n",
      "4265/4265 [==============================] - 1s 137us/step - loss: 3057835603611.2202 - val_loss: 3179603907556.6357\n",
      "Epoch 696/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3057117240112.7993 - val_loss: 3179324281022.1099\n",
      "Epoch 697/800\n",
      "4265/4265 [==============================] - 0s 109us/step - loss: 3057737675770.9580 - val_loss: 3181417379929.2939\n",
      "Epoch 698/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3059557254983.1279 - val_loss: 3178748039842.0254\n",
      "Epoch 699/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3056963126607.8916 - val_loss: 3178408788636.2646\n",
      "Epoch 700/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3058451529101.8354 - val_loss: 3180454202775.5835\n",
      "Epoch 701/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3058127772902.7300 - val_loss: 3178210230963.3081\n",
      "Epoch 702/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3058282856985.8101 - val_loss: 3179284832958.8296\n",
      "Epoch 703/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3056326066994.2397 - val_loss: 3179822768300.8271\n",
      "Epoch 704/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3055662818180.8320 - val_loss: 3192758131987.0830\n",
      "Epoch 705/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3057854217924.9966 - val_loss: 3177874552437.3784\n",
      "Epoch 706/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3055964060482.0854 - val_loss: 3183500803473.8228\n",
      "Epoch 707/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3055977295281.3691 - val_loss: 3177583212379.8145\n",
      "Epoch 708/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3054860420781.4678 - val_loss: 3178484572955.0044\n",
      "Epoch 709/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3055767197867.4268 - val_loss: 3176205678105.2041\n",
      "Epoch 710/800\n",
      "4265/4265 [==============================] - 0s 87us/step - loss: 3052591596176.8965 - val_loss: 3176424160196.9507\n",
      "Epoch 711/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3056161743794.9297 - val_loss: 3175804788770.5654\n",
      "Epoch 712/800\n",
      "4265/4265 [==============================] - 0s 71us/step - loss: 3056217268721.4746 - val_loss: 3175512125457.2827\n",
      "Epoch 713/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3056305993125.3647 - val_loss: 3179076767680.6299\n",
      "Epoch 714/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3056017887649.7632 - val_loss: 3175079045134.4023\n",
      "Epoch 715/800\n",
      "4265/4265 [==============================] - 0s 73us/step - loss: 3053733324448.0225 - val_loss: 3177519328513.8003\n",
      "Epoch 716/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3056071363735.0190 - val_loss: 3174998014986.0815\n",
      "Epoch 717/800\n",
      "4265/4265 [==============================] - 0s 67us/step - loss: 3055074685916.2261 - val_loss: 3175381178077.0747\n",
      "Epoch 718/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3054284597668.1641 - val_loss: 3175262867070.0195\n",
      "Epoch 719/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3053420925353.4463 - val_loss: 3182248978123.7920\n",
      "Epoch 720/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3053393710042.7856 - val_loss: 3174030561308.8047\n",
      "Epoch 721/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3052133548247.1240 - val_loss: 3174851804262.2559\n",
      "Epoch 722/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3054539404555.7046 - val_loss: 3173095145978.9590\n",
      "Epoch 723/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3052562365615.0283 - val_loss: 3173005936642.8804\n",
      "Epoch 724/800\n",
      "4265/4265 [==============================] - 0s 96us/step - loss: 3053299062813.2915 - val_loss: 3172842752924.6245\n",
      "Epoch 725/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3055439875311.3735 - val_loss: 3173699926197.4683\n",
      "Epoch 726/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3051041653888.4502 - val_loss: 3172427063330.5654\n",
      "Epoch 727/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3052453921467.1528 - val_loss: 3178884803795.7129\n",
      "Epoch 728/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3053390097741.4902 - val_loss: 3172314051245.5469\n",
      "Epoch 729/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3052293430456.6323 - val_loss: 3171574960755.9380\n",
      "Epoch 730/800\n",
      "4265/4265 [==============================] - 0s 115us/step - loss: 3052867104849.6318 - val_loss: 3172232528517.2207\n",
      "Epoch 731/800\n",
      "4265/4265 [==============================] - 0s 97us/step - loss: 3053750424565.1958 - val_loss: 3171635419789.8623\n",
      "Epoch 732/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3052753065817.3750 - val_loss: 3180176412723.8481\n",
      "Epoch 733/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3051561315799.7842 - val_loss: 3170815372891.4541\n",
      "Epoch 734/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3050582199201.1631 - val_loss: 3171670498049.0801\n",
      "Epoch 735/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3052157843556.3594 - val_loss: 3172399225554.9932\n",
      "Epoch 736/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3050315121392.9341 - val_loss: 3174810642861.1870\n",
      "Epoch 737/800\n",
      "4265/4265 [==============================] - 0s 70us/step - loss: 3052610981925.4551 - val_loss: 3170665226689.3501\n",
      "Epoch 738/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3052125502055.1201 - val_loss: 3174566271192.0337\n",
      "Epoch 739/800\n",
      "4265/4265 [==============================] - 0s 80us/step - loss: 3051561613623.6416 - val_loss: 3170078698477.2769\n",
      "Epoch 740/800\n",
      "4265/4265 [==============================] - 0s 105us/step - loss: 3050871623018.3013 - val_loss: 3171062387016.3711\n",
      "Epoch 741/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3050192684594.5396 - val_loss: 3169696628205.9971\n",
      "Epoch 742/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3053047919918.2778 - val_loss: 3169855850637.1421\n",
      "Epoch 743/800\n",
      "4265/4265 [==============================] - 0s 108us/step - loss: 3051590013530.1553 - val_loss: 3170346883956.2983\n",
      "Epoch 744/800\n",
      "4265/4265 [==============================] - 1s 120us/step - loss: 3050370502370.7686 - val_loss: 3172741510773.3784\n",
      "Epoch 745/800\n",
      "4265/4265 [==============================] - 0s 104us/step - loss: 3050780381386.6392 - val_loss: 3170770493912.3940\n",
      "Epoch 746/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3051100721047.3193 - val_loss: 3172069061639.2012\n",
      "Epoch 747/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3050123235119.5986 - val_loss: 3169437762296.4390\n",
      "Epoch 748/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3052241939720.3433 - val_loss: 3176905925933.0068\n",
      "Epoch 749/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3049836840371.7700 - val_loss: 3170732546817.0801\n",
      "Epoch 750/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3050906145108.9331 - val_loss: 3169579515466.1714\n",
      "Epoch 751/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3050565478501.3198 - val_loss: 3169559071183.7524\n",
      "Epoch 752/800\n",
      "4265/4265 [==============================] - 0s 95us/step - loss: 3049749803646.6494 - val_loss: 3169174166365.2544\n",
      "Epoch 753/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3048550050892.1094 - val_loss: 3174529800730.6440\n",
      "Epoch 754/800\n",
      "4265/4265 [==============================] - 0s 78us/step - loss: 3048641157702.4673 - val_loss: 3169215345463.8086\n",
      "Epoch 755/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3049649425789.5093 - val_loss: 3171020041358.5825\n",
      "Epoch 756/800\n",
      "4265/4265 [==============================] - 0s 76us/step - loss: 3049537745438.6123 - val_loss: 3173094436236.0620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 757/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3048045958982.1675 - val_loss: 3168163708167.5610\n",
      "Epoch 758/800\n",
      "4265/4265 [==============================] - 0s 102us/step - loss: 3046791777849.7427 - val_loss: 3169304508712.6865\n",
      "Epoch 759/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3049698870542.5859 - val_loss: 3170304044612.4106\n",
      "Epoch 760/800\n",
      "4265/4265 [==============================] - 0s 72us/step - loss: 3046779707731.9727 - val_loss: 3179381713786.0591\n",
      "Epoch 761/800\n",
      "4265/4265 [==============================] - 0s 93us/step - loss: 3048340282095.4937 - val_loss: 3168584525239.2686\n",
      "Epoch 762/800\n",
      "4265/4265 [==============================] - 1s 121us/step - loss: 3048359072380.7285 - val_loss: 3166370755660.3320\n",
      "Epoch 763/800\n",
      "4265/4265 [==============================] - 0s 98us/step - loss: 3047570433761.3281 - val_loss: 3175485030607.3926\n",
      "Epoch 764/800\n",
      "4265/4265 [==============================] - 0s 89us/step - loss: 3049461901094.4751 - val_loss: 3170925318518.4585\n",
      "Epoch 765/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3048506896273.5566 - val_loss: 3166273568445.3896\n",
      "Epoch 766/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3047615514354.6147 - val_loss: 3172115790005.4683\n",
      "Epoch 767/800\n",
      "4265/4265 [==============================] - 0s 92us/step - loss: 3047899053238.7114 - val_loss: 3174885030922.0815\n",
      "Epoch 768/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3048231767356.2036 - val_loss: 3166129176506.8691\n",
      "Epoch 769/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3046709881083.1382 - val_loss: 3165986652759.1338\n",
      "Epoch 770/800\n",
      "4265/4265 [==============================] - 0s 100us/step - loss: 3046708366917.2671 - val_loss: 3172093673679.3926\n",
      "Epoch 771/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3045052510769.8193 - val_loss: 3165383807465.6763\n",
      "Epoch 772/800\n",
      "4265/4265 [==============================] - 0s 101us/step - loss: 3047835391153.4292 - val_loss: 3168670921412.5908\n",
      "Epoch 773/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3048950710183.6455 - val_loss: 3165474514820.1406\n",
      "Epoch 774/800\n",
      "4265/4265 [==============================] - 0s 116us/step - loss: 3046720896355.5786 - val_loss: 3165278144630.0986\n",
      "Epoch 775/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3048437297533.2690 - val_loss: 3165121777393.2378\n",
      "Epoch 776/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3047149338485.7061 - val_loss: 3165040126358.1436\n",
      "Epoch 777/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3046228170001.4668 - val_loss: 3165135564840.3262\n",
      "Epoch 778/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3044051787543.5894 - val_loss: 3164188963225.0239\n",
      "Epoch 779/800\n",
      "4265/4265 [==============================] - 0s 75us/step - loss: 3046792171618.9185 - val_loss: 3164364956235.6118\n",
      "Epoch 780/800\n",
      "4265/4265 [==============================] - 0s 83us/step - loss: 3045372616252.6235 - val_loss: 3177010693939.4883\n",
      "Epoch 781/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3047502470424.6694 - val_loss: 3165432318484.8833\n",
      "Epoch 782/800\n",
      "4265/4265 [==============================] - 0s 94us/step - loss: 3047532034367.3247 - val_loss: 3165766987516.7593\n",
      "Epoch 783/800\n",
      "4265/4265 [==============================] - 0s 109us/step - loss: 3045953261770.6392 - val_loss: 3164590046863.3022\n",
      "Epoch 784/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3045681454276.1567 - val_loss: 3167451130354.3179\n",
      "Epoch 785/800\n",
      "4265/4265 [==============================] - 0s 86us/step - loss: 3046199110770.5244 - val_loss: 3163456240143.1226\n",
      "Epoch 786/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3047609419491.2490 - val_loss: 3163141705687.6738\n",
      "Epoch 787/800\n",
      "4265/4265 [==============================] - 0s 69us/step - loss: 3043659367348.8506 - val_loss: 3163549742962.8579\n",
      "Epoch 788/800\n",
      "4265/4265 [==============================] - 0s 79us/step - loss: 3047214669195.9150 - val_loss: 3163178364922.2393\n",
      "Epoch 789/800\n",
      "4265/4265 [==============================] - 0s 88us/step - loss: 3046184076427.9746 - val_loss: 3163960712121.4292\n",
      "Epoch 790/800\n",
      "4265/4265 [==============================] - 0s 77us/step - loss: 3044995687416.0767 - val_loss: 3166552510308.4556\n",
      "Epoch 791/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3045342836110.3154 - val_loss: 3162877299727.8423\n",
      "Epoch 792/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3045530903532.5522 - val_loss: 3163790057483.5220\n",
      "Epoch 793/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3044485481127.9458 - val_loss: 3163157093651.0830\n",
      "Epoch 794/800\n",
      "4265/4265 [==============================] - 0s 74us/step - loss: 3046264998805.6382 - val_loss: 3162476714200.0337\n",
      "Epoch 795/800\n",
      "4265/4265 [==============================] - 0s 82us/step - loss: 3046332033605.5073 - val_loss: 3162173740626.8130\n",
      "Epoch 796/800\n",
      "4265/4265 [==============================] - 0s 91us/step - loss: 3042996495186.8926 - val_loss: 3162347976424.5962\n",
      "Epoch 797/800\n",
      "4265/4265 [==============================] - 0s 99us/step - loss: 3044254365819.4082 - val_loss: 3161926866238.2896\n",
      "Epoch 798/800\n",
      "4265/4265 [==============================] - 0s 85us/step - loss: 3043974233670.2275 - val_loss: 3165149927455.6851\n",
      "Epoch 799/800\n",
      "4265/4265 [==============================] - 0s 90us/step - loss: 3044747531994.6055 - val_loss: 3162406065101.5923\n",
      "Epoch 800/800\n",
      "4265/4265 [==============================] - 0s 81us/step - loss: 3046485044446.0864 - val_loss: 3161901385546.5317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff828fc74a8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train44 = model44.fit(predictors,target, epochs=800, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=True)\n",
    "model_train44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/matplotlib/scale.py:111: RuntimeWarning: invalid value encountered in less_equal\n",
      "  out[a <= 0] = -1000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff80ffc4400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the plot\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(model_train11.history['val_loss'], 'r',\n",
    "         model_train22.history['val_loss'], 'y',\n",
    "         model_train33.history['val_loss'], 'g',\n",
    "         model_train44.history['val_loss'], 'b')\n",
    "plt.title(\"red:nadam , yellow:adam , green:adadelta , blue:adagrad\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.savefig(\"NeuralNetwith5HiddenLayer2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
