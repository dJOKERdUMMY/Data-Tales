{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the less hidden layes didn't work out as per the graph above so using more hidden layers\n",
    "#as per above diagram using only adam and nadam\n",
    "#importing pandas to visualise the dataset in tabular format\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#introducing stable analysis through random seed\n",
    "np.random.seed(42)\n",
    "#importing time function to create animated behaviour\n",
    "import time\n",
    "#importing regExp for data cleaning\n",
    "import re\n",
    "from numpy import NaN\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(patience=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/scaled_train.csv\")\n",
    "test = pd.read_csv(\"../data/scaled_test.csv\")\n",
    "\n",
    "X_train = df.drop(['PRT_ID','SALES_PRICE'],axis=1)\n",
    "y_train = df['SALES_PRICE']\n",
    "\n",
    "X_test = test.drop(['PRT_ID'],axis=1)\n",
    "\n",
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Specify the model\n",
    "predictors = X_train.values\n",
    "target = y_train.values.reshape((-1,1)).astype('int32')\n",
    "\n",
    "n_cols = predictors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model 1\n",
    "model11 = Sequential()\n",
    "model11.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "model11.add(Dense(70, kernel_initializer='normal', activation='relu'))\n",
    "model11.add(Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "model11.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model11.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "#model 2\n",
    "model22 = Sequential()\n",
    "model22.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "model22.add(Dense(70, kernel_initializer='normal', activation='relu'))\n",
    "model22.add(Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "model22.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model22.add(Dense(1, kernel_initializer='normal'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model11 loss: mean_squared_error\n",
      "Train on 3554 samples, validate on 3555 samples\n",
      "Epoch 1/5000\n",
      "3554/3554 [==============================] - 1s 247us/step - loss: 130055774919307.1562 - val_loss: 108183513290585.5156\n",
      "Epoch 2/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 37271765426890.5547 - val_loss: 7535852328217.4199\n",
      "Epoch 3/5000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 6936981707320.1846 - val_loss: 6125685364117.8555\n",
      "Epoch 4/5000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 5732263346719.9824 - val_loss: 5348106016919.5117\n",
      "Epoch 5/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 5006001979115.3984 - val_loss: 4835772549952.4502\n",
      "Epoch 6/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 4538527939261.8750 - val_loss: 4490682345343.5322\n",
      "Epoch 7/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 4220162011912.7881 - val_loss: 4261298545066.3066\n",
      "Epoch 8/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 3983320620793.2290 - val_loss: 4078034094428.5347\n",
      "Epoch 9/5000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 3807000251021.4697 - val_loss: 3943397824368.5537\n",
      "Epoch 10/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3667606659685.1323 - val_loss: 3808226216220.0122\n",
      "Epoch 11/5000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 3531911859382.6719 - val_loss: 3697994518953.1543\n",
      "Epoch 12/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 3412373334443.5791 - val_loss: 3616347297593.2490\n",
      "Epoch 13/5000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 3316491575024.0088 - val_loss: 3597746740217.9512\n",
      "Epoch 14/5000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 3219723109172.5830 - val_loss: 3380367109036.7549\n",
      "Epoch 15/5000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 3116558876727.3198 - val_loss: 3289183332665.9692\n",
      "Epoch 16/5000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 3019453475363.4395 - val_loss: 3305215391589.0317\n",
      "Epoch 17/5000\n",
      "3554/3554 [==============================] - 0s 130us/step - loss: 2949483818696.8237 - val_loss: 3106630522464.6392\n",
      "Epoch 18/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 2858417405242.0571 - val_loss: 3028193476045.7363\n",
      "Epoch 19/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 2784125832337.7920 - val_loss: 2946889567906.8896\n",
      "Epoch 20/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 2702491267323.2456 - val_loss: 2918215550983.4893\n",
      "Epoch 21/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 2629926656199.3828 - val_loss: 2861753531485.0386\n",
      "Epoch 22/5000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 2574563330996.5112 - val_loss: 2740902004890.9683\n",
      "Epoch 23/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 2499179013299.2144 - val_loss: 2922334397699.5283\n",
      "Epoch 24/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 2446123792698.6338 - val_loss: 2582204340721.1655\n",
      "Epoch 25/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 2380670657115.9121 - val_loss: 2541479305365.7832\n",
      "Epoch 26/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 2336980139183.7568 - val_loss: 2471270099820.2329\n",
      "Epoch 27/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 2285867646007.8965 - val_loss: 2441820151257.2578\n",
      "Epoch 28/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 2242611260990.5234 - val_loss: 2368407347672.3940\n",
      "Epoch 29/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 2203225302490.2559 - val_loss: 2357126375433.7935\n",
      "Epoch 30/5000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 2169960485590.0776 - val_loss: 2364675754120.5332\n",
      "Epoch 31/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 2141359407343.7207 - val_loss: 2255438884706.1514\n",
      "Epoch 32/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 2110653543351.9685 - val_loss: 2271200682382.6543\n",
      "Epoch 33/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 2084143531551.4058 - val_loss: 2198018105973.0903\n",
      "Epoch 34/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 2063243396851.4666 - val_loss: 2226068636546.7002\n",
      "Epoch 35/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 2044856607397.6724 - val_loss: 2137894383020.3230\n",
      "Epoch 36/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 2013819457635.1152 - val_loss: 2113231737312.4590\n",
      "Epoch 37/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1988046172374.3660 - val_loss: 2111767555486.4968\n",
      "Epoch 38/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1965175098694.7349 - val_loss: 2241763192038.1479\n",
      "Epoch 39/5000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1948304644830.1450 - val_loss: 2025490634308.9868\n",
      "Epoch 40/5000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 1907272921744.9275 - val_loss: 1995973586025.7124\n",
      "Epoch 41/5000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 1886347288082.7280 - val_loss: 2135358467555.6277\n",
      "Epoch 42/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1862600720107.3989 - val_loss: 1940449747089.1748\n",
      "Epoch 43/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1829840860419.8896 - val_loss: 1919827855104.7922\n",
      "Epoch 44/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1799262298780.4524 - val_loss: 1875974050622.7217\n",
      "Epoch 45/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1771422836850.0979 - val_loss: 1854791266302.8479\n",
      "Epoch 46/5000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 1737386252994.4851 - val_loss: 2033943032157.1106\n",
      "Epoch 47/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1712582434000.0271 - val_loss: 1816288877290.0366\n",
      "Epoch 48/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1668134662399.8560 - val_loss: 1759296073376.5852\n",
      "Epoch 49/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1639089514988.1191 - val_loss: 1772502595203.2046\n",
      "Epoch 50/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1612091011304.8059 - val_loss: 1757964792327.6333\n",
      "Epoch 51/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1575639953161.3643 - val_loss: 1641478984515.3306\n",
      "Epoch 52/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1539597865529.3372 - val_loss: 1616489556364.9260\n",
      "Epoch 53/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1503321282897.6836 - val_loss: 1567768481097.2354\n",
      "Epoch 54/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1470394046986.0845 - val_loss: 1528506746601.7485\n",
      "Epoch 55/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1436979435276.8218 - val_loss: 1511765633508.4917\n",
      "Epoch 56/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1402284771363.7275 - val_loss: 1624785437579.9180\n",
      "Epoch 57/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1389811600963.1333 - val_loss: 1461312013850.3562\n",
      "Epoch 58/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 1347439396383.4058 - val_loss: 1434888503203.8257\n",
      "Epoch 59/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1318717078676.0967 - val_loss: 1383339163362.2593\n",
      "Epoch 60/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 1293520124043.4531 - val_loss: 1390709886562.3674\n",
      "Epoch 61/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1273178672799.3337 - val_loss: 1343591516130.6194\n",
      "Epoch 62/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1244290663552.5042 - val_loss: 1341073908751.2664\n",
      "Epoch 63/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 92us/step - loss: 1226340777421.5779 - val_loss: 1292975905749.0813\n",
      "Epoch 64/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1207688274339.5115 - val_loss: 1369250963919.1763\n",
      "Epoch 65/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1192755173870.4243 - val_loss: 1257819927508.5051\n",
      "Epoch 66/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1171493522070.6899 - val_loss: 1230887199487.3518\n",
      "Epoch 67/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1152990920141.5779 - val_loss: 1356666994015.1270\n",
      "Epoch 68/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1141449960543.0815 - val_loss: 1206447437899.4678\n",
      "Epoch 69/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1125859593352.5718 - val_loss: 1184408102078.3977\n",
      "Epoch 70/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1110538866307.6736 - val_loss: 1177798444667.1392\n",
      "Epoch 71/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1101098227118.4604 - val_loss: 1169564996124.3723\n",
      "Epoch 72/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1088798004368.6393 - val_loss: 1155152557883.5532\n",
      "Epoch 73/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1081529361329.0535 - val_loss: 1157270436883.2991\n",
      "Epoch 74/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1072609660796.6145 - val_loss: 1172945532920.5107\n",
      "Epoch 75/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1059500182120.5897 - val_loss: 1156442462433.2512\n",
      "Epoch 76/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1057290043627.1108 - val_loss: 1135947746605.5830\n",
      "Epoch 77/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1047505769164.8575 - val_loss: 1111926126340.2488\n",
      "Epoch 78/5000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 1040451966880.3420 - val_loss: 1109560831224.5828\n",
      "Epoch 79/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1035566342019.5295 - val_loss: 1120395683596.3140\n",
      "Epoch 80/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1029344886295.3381 - val_loss: 1096572677045.9724\n",
      "Epoch 81/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1020753267120.1891 - val_loss: 1129638499581.7676\n",
      "Epoch 82/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1023894616046.7124 - val_loss: 1492905750863.2844\n",
      "Epoch 83/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1032724017006.7844 - val_loss: 1078768099500.8270\n",
      "Epoch 84/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1008617487222.2758 - val_loss: 1076534709604.8878\n",
      "Epoch 85/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1005382333598.4694 - val_loss: 1112081934594.6643\n",
      "Epoch 86/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1002147487665.6298 - val_loss: 1083655895645.4706\n",
      "Epoch 87/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 999642080794.7957 - val_loss: 1194070488495.2034\n",
      "Epoch 88/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1004251334627.1874 - val_loss: 1128775053029.7158\n",
      "Epoch 89/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 993796508854.6720 - val_loss: 1062587888034.2413\n",
      "Epoch 90/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 986757745238.1498 - val_loss: 1054094984329.3975\n",
      "Epoch 91/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 985583430151.7794 - val_loss: 1051426808552.3083\n",
      "Epoch 92/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 981869723648.0000 - val_loss: 1063557664285.2366\n",
      "Epoch 93/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 978523512762.8497 - val_loss: 1055202480050.8040\n",
      "Epoch 94/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 977117547970.0529 - val_loss: 1061902402821.8329\n",
      "Epoch 95/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 974163976095.1897 - val_loss: 1038968200001.6023\n",
      "Epoch 96/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 971690401026.7372 - val_loss: 1036578365073.6068\n",
      "Epoch 97/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 970200809342.9196 - val_loss: 1040448827768.7628\n",
      "Epoch 98/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 966672245109.4114 - val_loss: 1140674665014.2964\n",
      "Epoch 99/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 972122933763.1694 - val_loss: 1043967171047.9482\n",
      "Epoch 100/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 963283354061.0017 - val_loss: 1031138980161.4583\n",
      "Epoch 101/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 957635468366.9465 - val_loss: 1039131935512.6998\n",
      "Epoch 102/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 957369293736.9860 - val_loss: 1024239558321.8678\n",
      "Epoch 103/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 956733018616.7969 - val_loss: 1018665147496.5603\n",
      "Epoch 104/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 952461040184.1846 - val_loss: 1021402994586.0321\n",
      "Epoch 105/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 955376331806.5414 - val_loss: 1020987880381.4615\n",
      "Epoch 106/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 950992555513.3730 - val_loss: 1024031477152.8011\n",
      "Epoch 107/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 944592422837.0872 - val_loss: 1016306371913.2355\n",
      "Epoch 108/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 947837910643.5386 - val_loss: 1026476477686.2784\n",
      "Epoch 109/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 945493153392.0809 - val_loss: 1008724557017.4740\n",
      "Epoch 110/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 943273172756.8892 - val_loss: 1031747733539.1415\n",
      "Epoch 111/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 944546889940.0608 - val_loss: 1040616318022.5710\n",
      "Epoch 112/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 941064753334.0956 - val_loss: 1006715568948.3522\n",
      "Epoch 113/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 937742618999.7164 - val_loss: 1010804640677.8419\n",
      "Epoch 114/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 940772185449.3101 - val_loss: 1003729987483.1842\n",
      "Epoch 115/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 939348034439.5632 - val_loss: 1018666277923.4296\n",
      "Epoch 116/5000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 938282878237.2448 - val_loss: 1012707227926.2515\n",
      "Epoch 117/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 932863478699.2909 - val_loss: 1007357903156.7843\n",
      "Epoch 118/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 931183724979.6466 - val_loss: 999669990583.4846\n",
      "Epoch 119/5000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 932909965962.0123 - val_loss: 995572632743.9303\n",
      "Epoch 120/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 926058140429.3979 - val_loss: 1006165701113.8070\n",
      "Epoch 121/5000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 932164074745.5172 - val_loss: 1057892266337.7192\n",
      "Epoch 122/5000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 928115268262.8250 - val_loss: 1018841445751.8987\n",
      "Epoch 123/5000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 924816571493.9966 - val_loss: 988918788583.3722\n",
      "Epoch 124/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 920379987134.7395 - val_loss: 1004596118522.5271\n",
      "Epoch 125/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 928358530076.2363 - val_loss: 1004686188140.7369\n",
      "Epoch 126/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 140us/step - loss: 921951082759.9235 - val_loss: 986128049204.1361\n",
      "Epoch 127/5000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 921893196446.7574 - val_loss: 982420804884.8113\n",
      "Epoch 128/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 918128916776.1936 - val_loss: 985622574368.3330\n",
      "Epoch 129/5000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 919040620697.2831 - val_loss: 981553656940.5930\n",
      "Epoch 130/5000\n",
      "3554/3554 [==============================] - 0s 138us/step - loss: 916913994157.8842 - val_loss: 981245176020.5773\n",
      "Epoch 131/5000\n",
      "3554/3554 [==============================] - 0s 139us/step - loss: 915599570041.5891 - val_loss: 980979915309.0791\n",
      "Epoch 132/5000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 918208903962.0753 - val_loss: 1016153580969.4425\n",
      "Epoch 133/5000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 917411093555.2864 - val_loss: 987242213706.6757\n",
      "Epoch 134/5000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 915946994753.1165 - val_loss: 996284970166.3325\n",
      "Epoch 135/5000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 915336189791.8019 - val_loss: 974347629856.3330\n",
      "Epoch 136/5000\n",
      "3554/3554 [==============================] - 1s 151us/step - loss: 908955364705.2426 - val_loss: 976580813097.2625\n",
      "Epoch 137/5000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 909411726983.1312 - val_loss: 988060924813.6461\n",
      "Epoch 138/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 913669282111.2437 - val_loss: 969718921208.5109\n",
      "Epoch 139/5000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 913125241922.2690 - val_loss: 980031912753.4717\n",
      "Epoch 140/5000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 912286721304.6349 - val_loss: 969679609858.3043\n",
      "Epoch 141/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 908090360868.3038 - val_loss: 991910019823.2214\n",
      "Epoch 142/5000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 901722891277.2538 - val_loss: 991856742502.5441\n",
      "Epoch 143/5000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 905962762399.0455 - val_loss: 978498908946.9390\n",
      "Epoch 144/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 906142109315.6737 - val_loss: 985189382551.2957\n",
      "Epoch 145/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 910611643770.5975 - val_loss: 967519123351.7277\n",
      "Epoch 146/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 900768560341.7896 - val_loss: 981036226163.0740\n",
      "Epoch 147/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 901173359433.3280 - val_loss: 973407529817.7980\n",
      "Epoch 148/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 901448970915.3674 - val_loss: 1054911376697.1050\n",
      "Epoch 149/5000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 905821599404.0112 - val_loss: 991364874488.8708\n",
      "Epoch 150/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 902646595740.7406 - val_loss: 962902854229.4054\n",
      "Epoch 151/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 897227981426.9623 - val_loss: 990582934829.5831\n",
      "Epoch 152/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 897224233612.3174 - val_loss: 959123844137.1904\n",
      "Epoch 153/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 897964993548.1012 - val_loss: 958216663780.8518\n",
      "Epoch 154/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 894203483280.6393 - val_loss: 961057782554.4281\n",
      "Epoch 155/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 894926726738.1158 - val_loss: 979526217510.2379\n",
      "Epoch 156/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 899062612014.1001 - val_loss: 1002529854902.1165\n",
      "Epoch 157/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 899684809101.6139 - val_loss: 974138087981.0791\n",
      "Epoch 158/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 897635920198.1587 - val_loss: 980868158602.5497\n",
      "Epoch 159/5000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 893452190166.2217 - val_loss: 974847639671.8268\n",
      "Epoch 160/5000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 892929397120.9364 - val_loss: 952174246682.4281\n",
      "Epoch 161/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 890908029013.2853 - val_loss: 953017622110.9109\n",
      "Epoch 162/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 889046654187.6871 - val_loss: 1016708131153.0127\n",
      "Epoch 163/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 892254291468.9657 - val_loss: 954557959829.0632\n",
      "Epoch 164/5000\n",
      "3554/3554 [==============================] - 0s 132us/step - loss: 889683319130.9038 - val_loss: 969895880059.3552\n",
      "Epoch 165/5000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 888651884759.5183 - val_loss: 948853045351.1201\n",
      "Epoch 166/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 890914368192.1802 - val_loss: 950149671147.6208\n",
      "Epoch 167/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 891427796209.4497 - val_loss: 948592684262.1479\n",
      "Epoch 168/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 888810074169.6252 - val_loss: 963060341164.0349\n",
      "Epoch 169/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 888638666052.4299 - val_loss: 959520998122.6127\n",
      "Epoch 170/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 882442673562.8677 - val_loss: 952146758358.4495\n",
      "Epoch 171/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 885840055912.0135 - val_loss: 946933999404.5750\n",
      "Epoch 172/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 888548164072.6619 - val_loss: 943747155279.5724\n",
      "Epoch 173/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 883699754946.9174 - val_loss: 960006307872.2610\n",
      "Epoch 174/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 883698653152.8824 - val_loss: 952538366468.1766\n",
      "Epoch 175/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 881639952349.4249 - val_loss: 965658034936.4388\n",
      "Epoch 176/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 880921261149.9291 - val_loss: 989952306678.0625\n",
      "Epoch 177/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 884137652041.9044 - val_loss: 946296799457.8273\n",
      "Epoch 178/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 879856499970.7372 - val_loss: 949791448200.8214\n",
      "Epoch 179/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 883455780553.9763 - val_loss: 950405525498.2391\n",
      "Epoch 180/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 878764177639.6534 - val_loss: 986759396039.4712\n",
      "Epoch 181/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 893221005905.5397 - val_loss: 975923499110.5441\n",
      "Epoch 182/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 878920745319.5813 - val_loss: 943510256668.5165\n",
      "Epoch 183/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 875803897152.9724 - val_loss: 945012239548.6694\n",
      "Epoch 184/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 879214598122.1024 - val_loss: 937086192416.1891\n",
      "Epoch 185/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 877982425138.7102 - val_loss: 941110521693.5426\n",
      "Epoch 186/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 881389731581.8390 - val_loss: 934843288389.0588\n",
      "Epoch 187/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 876744061271.4463 - val_loss: 991986346496.1440\n",
      "Epoch 188/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 881937864027.4800 - val_loss: 974952757609.2085\n",
      "Epoch 189/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 92us/step - loss: 878281734357.2133 - val_loss: 935254128061.0295\n",
      "Epoch 190/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 876226470574.8926 - val_loss: 933584500848.3375\n",
      "Epoch 191/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 872359316957.7130 - val_loss: 974292994364.2734\n",
      "Epoch 192/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 873740730460.2003 - val_loss: 940446083768.4928\n",
      "Epoch 193/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 874351433613.9021 - val_loss: 952083363311.7255\n",
      "Epoch 194/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 877706341849.1029 - val_loss: 929862207435.5758\n",
      "Epoch 195/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 873887501743.6128 - val_loss: 952998772924.9575\n",
      "Epoch 196/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 871750480945.5576 - val_loss: 933206042891.8818\n",
      "Epoch 197/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 873494905200.8013 - val_loss: 933747337585.2737\n",
      "Epoch 198/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 871064557039.0006 - val_loss: 944679460350.1277\n",
      "Epoch 199/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 870906537074.6742 - val_loss: 954825731076.3207\n",
      "Epoch 200/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 875229523619.9437 - val_loss: 932616364177.1747\n",
      "Epoch 201/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 869468485015.4103 - val_loss: 939363389192.2812\n",
      "Epoch 202/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 868072917470.2892 - val_loss: 929323104612.5997\n",
      "Epoch 203/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 870662256926.9735 - val_loss: 928011971855.6265\n",
      "Epoch 204/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 874395677181.4069 - val_loss: 940930477876.0641\n",
      "Epoch 205/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 868267978201.1029 - val_loss: 926297731716.0686\n",
      "Epoch 206/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 868643520060.2184 - val_loss: 967191234779.4902\n",
      "Epoch 207/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 873895076242.2240 - val_loss: 937135818192.6166\n",
      "Epoch 208/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 867561751496.1035 - val_loss: 931689247069.1106\n",
      "Epoch 209/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 870493029285.5284 - val_loss: 928071734309.1578\n",
      "Epoch 210/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 864145965738.2825 - val_loss: 931342082248.4794\n",
      "Epoch 211/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 865960764143.4327 - val_loss: 926807956188.2104\n",
      "Epoch 212/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 864648104949.0511 - val_loss: 933760113805.4301\n",
      "Epoch 213/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 869707862281.0759 - val_loss: 927445994405.8419\n",
      "Epoch 214/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 868280742415.8469 - val_loss: 937238635807.1809\n",
      "Epoch 215/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 865823073154.9534 - val_loss: 928550350888.3263\n",
      "Epoch 216/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 863239317793.2786 - val_loss: 939962391587.4296\n",
      "Epoch 217/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 863706924480.9004 - val_loss: 940714296438.9626\n",
      "Epoch 218/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 861252616782.0822 - val_loss: 928746639301.2388\n",
      "Epoch 219/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 868607063032.5087 - val_loss: 928696733240.8889\n",
      "Epoch 220/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 863464803861.0332 - val_loss: 930235578397.3806\n",
      "Epoch 221/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 862265987012.0697 - val_loss: 925848960876.5210\n",
      "Epoch 222/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 864891815741.2268 - val_loss: 944079463614.3977\n",
      "Epoch 223/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 866832315780.9702 - val_loss: 924002198133.0903\n",
      "Epoch 224/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 863340577809.8638 - val_loss: 966392521462.1344\n",
      "Epoch 225/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 867531777332.2948 - val_loss: 951837469179.5353\n",
      "Epoch 226/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 863379904536.2026 - val_loss: 954503862635.5128\n",
      "Epoch 227/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 862305986314.5166 - val_loss: 920670243957.2344\n",
      "Epoch 228/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 857069053134.8744 - val_loss: 915310996871.4531\n",
      "Epoch 229/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 857419989416.1215 - val_loss: 923107765091.0155\n",
      "Epoch 230/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 860042782004.2948 - val_loss: 916160745348.7168\n",
      "Epoch 231/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 860104218721.9629 - val_loss: 916420276720.5896\n",
      "Epoch 232/5000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 861511895564.3895 - val_loss: 918671665899.1887\n",
      "Epoch 233/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 858349624020.9252 - val_loss: 989922075944.3983\n",
      "Epoch 234/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 861079349076.2769 - val_loss: 941444621419.4408\n",
      "Epoch 235/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 861192868602.9578 - val_loss: 918961803357.3265\n",
      "Epoch 236/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 857526794351.7928 - val_loss: 964923501328.0585\n",
      "Epoch 237/5000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 858117447306.5886 - val_loss: 914699280676.6537\n",
      "Epoch 238/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 857568590018.7732 - val_loss: 909977867255.0706\n",
      "Epoch 239/5000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 856684369308.0203 - val_loss: 996998375300.1406\n",
      "Epoch 240/5000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 871240292357.7626 - val_loss: 911372769104.2926\n",
      "Epoch 241/5000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 850402203008.3601 - val_loss: 930341091855.1223\n",
      "Epoch 242/5000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 853597590940.0203 - val_loss: 919125270161.6068\n",
      "Epoch 243/5000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 853488635256.2926 - val_loss: 921751083173.3379\n",
      "Epoch 244/5000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 857927237088.0179 - val_loss: 909988392576.3241\n",
      "Epoch 245/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 853703361318.7529 - val_loss: 910668494324.3342\n",
      "Epoch 246/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 857261876596.8351 - val_loss: 913945512556.4490\n",
      "Epoch 247/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 855094404358.1947 - val_loss: 910707454637.5471\n",
      "Epoch 248/5000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 857487173617.0175 - val_loss: 931056673245.0026\n",
      "Epoch 249/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 857382526270.6675 - val_loss: 907058681518.9873\n",
      "Epoch 250/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 854651338991.7209 - val_loss: 916212201229.4661\n",
      "Epoch 251/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 856974868083.5386 - val_loss: 922743475888.7156\n",
      "Epoch 252/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 134us/step - loss: 857621835024.5673 - val_loss: 921523808528.4906\n",
      "Epoch 253/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 854681873198.8204 - val_loss: 944364110741.1353\n",
      "Epoch 254/5000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 854704937917.7310 - val_loss: 912699151765.8555\n",
      "Epoch 255/5000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 849458180291.9258 - val_loss: 915069217588.9282\n",
      "Epoch 256/5000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 852681103965.0647 - val_loss: 938143186851.8256\n",
      "Epoch 257/5000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 854473831103.0276 - val_loss: 905865902925.1240\n",
      "Epoch 258/5000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 855110438144.4323 - val_loss: 905321324850.4799\n",
      "Epoch 259/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 852583193051.9843 - val_loss: 905262555225.8700\n",
      "Epoch 260/5000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 847567844362.9489 - val_loss: 906688143924.5682\n",
      "Epoch 261/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 852623063373.0737 - val_loss: 903803601900.7009\n",
      "Epoch 262/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 854088877378.1249 - val_loss: 903705633968.5715\n",
      "Epoch 263/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 849741844164.2139 - val_loss: 949609413471.5590\n",
      "Epoch 264/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 850398129449.9224 - val_loss: 939338869510.8411\n",
      "Epoch 265/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 852930044692.3129 - val_loss: 906327103943.6873\n",
      "Epoch 266/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 848897197705.4362 - val_loss: 903613313193.3705\n",
      "Epoch 267/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 850409558518.4918 - val_loss: 906747292238.4923\n",
      "Epoch 268/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 850082192343.0861 - val_loss: 904371636683.1438\n",
      "Epoch 269/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 851054730134.5459 - val_loss: 935061425564.1924\n",
      "Epoch 270/5000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 853224233214.7035 - val_loss: 907265439985.3817\n",
      "Epoch 271/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 847988794667.0748 - val_loss: 901695359919.0593\n",
      "Epoch 272/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 851791255419.4620 - val_loss: 912200424077.8622\n",
      "Epoch 273/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 848542852653.2358 - val_loss: 900891765745.8857\n",
      "Epoch 274/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 846796181971.9167 - val_loss: 928821117250.6104\n",
      "Epoch 275/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 847134533607.7974 - val_loss: 906513182953.8926\n",
      "Epoch 276/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 851129784565.4834 - val_loss: 903564900763.9044\n",
      "Epoch 277/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 846173743098.2374 - val_loss: 901642612822.4135\n",
      "Epoch 278/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 852559050596.4120 - val_loss: 900093514738.4619\n",
      "Epoch 279/5000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 848276638294.1498 - val_loss: 909554495477.6304\n",
      "Epoch 280/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 843060883154.0438 - val_loss: 903342876741.7069\n",
      "Epoch 281/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 848424343677.6229 - val_loss: 906828855081.1184\n",
      "Epoch 282/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 844104182321.8457 - val_loss: 917455569633.3953\n",
      "Epoch 283/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 843577633343.0996 - val_loss: 900491829125.8689\n",
      "Epoch 284/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 846131506160.4413 - val_loss: 946381607871.7660\n",
      "Epoch 285/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 849060558347.8131 - val_loss: 914063935205.1398\n",
      "Epoch 286/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 849614194537.5981 - val_loss: 898400143952.7966\n",
      "Epoch 287/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 845990621499.7861 - val_loss: 903980426969.6180\n",
      "Epoch 288/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 844724188051.0883 - val_loss: 946171555940.2396\n",
      "Epoch 289/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 848841246091.8853 - val_loss: 905826080578.4664\n",
      "Epoch 290/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 845223764117.8256 - val_loss: 917867742571.2247\n",
      "Epoch 291/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 842976509850.5796 - val_loss: 895907865103.6985\n",
      "Epoch 292/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 839338551686.6990 - val_loss: 971482717846.2155\n",
      "Epoch 293/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 844702002215.7614 - val_loss: 899783302008.9069\n",
      "Epoch 294/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 844869864395.2729 - val_loss: 897178403369.0464\n",
      "Epoch 295/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 844893963982.5863 - val_loss: 897198080428.6110\n",
      "Epoch 296/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 842347932425.9404 - val_loss: 899589723597.1600\n",
      "Epoch 297/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 847489015323.9482 - val_loss: 914401628774.1119\n",
      "Epoch 298/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 849373842577.7917 - val_loss: 935883396640.1171\n",
      "Epoch 299/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 845405596416.7203 - val_loss: 911058339358.9648\n",
      "Epoch 300/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 841937760120.0045 - val_loss: 897903329897.5685\n",
      "Epoch 301/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 840798407798.1317 - val_loss: 896317027865.2040\n",
      "Epoch 302/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 841790225048.9950 - val_loss: 903216592980.6852\n",
      "Epoch 303/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 843358404755.5205 - val_loss: 905162387422.5868\n",
      "Epoch 304/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 846102176385.3685 - val_loss: 902113107693.7811\n",
      "Epoch 305/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 844347831555.8898 - val_loss: 898929636119.5477\n",
      "Epoch 306/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 843244241781.1232 - val_loss: 891857713315.0334\n",
      "Epoch 307/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 841434163055.9370 - val_loss: 913208600590.4022\n",
      "Epoch 308/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 846076890628.8982 - val_loss: 912371405086.8928\n",
      "Epoch 309/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 839678975543.6083 - val_loss: 891252838820.5457\n",
      "Epoch 310/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 843430695292.3263 - val_loss: 889079211046.3099\n",
      "Epoch 311/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 846616730080.5942 - val_loss: 894354567996.4175\n",
      "Epoch 312/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 837508855975.1130 - val_loss: 894662971674.2841\n",
      "Epoch 313/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 844132312556.6956 - val_loss: 889373707155.4070\n",
      "Epoch 314/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 839288698890.3724 - val_loss: 895309119100.8676\n",
      "Epoch 315/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 108us/step - loss: 838666295790.4243 - val_loss: 892518111420.3815\n",
      "Epoch 316/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 841707983601.7378 - val_loss: 904879970400.2070\n",
      "Epoch 317/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 847569102528.7563 - val_loss: 895220847141.5898\n",
      "Epoch 318/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 837635298485.5194 - val_loss: 901351707754.2886\n",
      "Epoch 319/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 841749033165.1458 - val_loss: 892785767707.7244\n",
      "Epoch 320/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 841082192471.3021 - val_loss: 893101599646.9288\n",
      "Epoch 321/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 837301004844.6595 - val_loss: 890527819417.0959\n",
      "Epoch 322/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 842035049326.2083 - val_loss: 887931895171.9966\n",
      "Epoch 323/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 842476362038.0237 - val_loss: 888522788063.2349\n",
      "Epoch 324/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 836916202383.6309 - val_loss: 899884001695.3608\n",
      "Epoch 325/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 840160768537.0669 - val_loss: 887639835306.0906\n",
      "Epoch 326/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 836833193903.3247 - val_loss: 958973863425.0082\n",
      "Epoch 327/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 842342551798.6360 - val_loss: 888010265351.4171\n",
      "Epoch 328/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 839480563478.0416 - val_loss: 887682735005.7766\n",
      "Epoch 329/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 837798585135.9730 - val_loss: 898645801454.8613\n",
      "Epoch 330/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 838088981827.2775 - val_loss: 930243467751.9482\n",
      "Epoch 331/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 841619696246.4198 - val_loss: 890282331073.4943\n",
      "Epoch 332/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 836984408136.6077 - val_loss: 904921380229.7249\n",
      "Epoch 333/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 838092621970.3679 - val_loss: 890375965739.4948\n",
      "Epoch 334/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 839352734237.6770 - val_loss: 961254259003.1212\n",
      "Epoch 335/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 840607406825.6703 - val_loss: 897460116842.6487\n",
      "Epoch 336/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 835736963494.9691 - val_loss: 891460897204.1001\n",
      "Epoch 337/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 837801787825.3416 - val_loss: 885723100098.0703\n",
      "Epoch 338/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 837923661384.8960 - val_loss: 918407338176.9901\n",
      "Epoch 339/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 837749909174.3839 - val_loss: 889991911838.2087\n",
      "Epoch 340/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 837250169487.7749 - val_loss: 890173051388.1115\n",
      "Epoch 341/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 838247714149.8525 - val_loss: 917406700700.9845\n",
      "Epoch 342/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 834389188511.1897 - val_loss: 885907333832.0472\n",
      "Epoch 343/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 838582118652.3984 - val_loss: 890368448105.8566\n",
      "Epoch 344/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 837777482986.5345 - val_loss: 886740044608.4501\n",
      "Epoch 345/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 838726519280.7294 - val_loss: 894588482000.3285\n",
      "Epoch 346/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 838336975988.9792 - val_loss: 887839030309.7339\n",
      "Epoch 347/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 840170599587.0793 - val_loss: 885020942601.0015\n",
      "Epoch 348/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 836080990061.6321 - val_loss: 944424124369.9128\n",
      "Epoch 349/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 839463928877.5239 - val_loss: 917082530886.5710\n",
      "Epoch 350/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 837207771494.4288 - val_loss: 886450785848.8889\n",
      "Epoch 351/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 835097923397.2943 - val_loss: 886282635110.1840\n",
      "Epoch 352/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 836502275864.3466 - val_loss: 886230699406.3662\n",
      "Epoch 353/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 835865665946.2915 - val_loss: 923664866145.8633\n",
      "Epoch 354/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 838532997327.4508 - val_loss: 883637271723.3867\n",
      "Epoch 355/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 837802667471.8831 - val_loss: 890240868888.9159\n",
      "Epoch 356/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 835245254963.7186 - val_loss: 940893709470.1367\n",
      "Epoch 357/5000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 841605368037.3483 - val_loss: 900189962899.0470\n",
      "Epoch 358/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 839341698848.4142 - val_loss: 895513019570.8760\n",
      "Epoch 359/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 831720789035.2189 - val_loss: 910612175119.3384\n",
      "Epoch 360/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 835284259357.6770 - val_loss: 889228888043.8368\n",
      "Epoch 361/5000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 835459749349.7805 - val_loss: 926238380286.6318\n",
      "Epoch 362/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 840707157511.2031 - val_loss: 882134466647.5657\n",
      "Epoch 363/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 834682750071.2842 - val_loss: 885420032728.1777\n",
      "Epoch 364/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 831657434273.9269 - val_loss: 884240262947.3575\n",
      "Epoch 365/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 834108989601.3506 - val_loss: 886048953570.1154\n",
      "Epoch 366/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 835368372693.0692 - val_loss: 902026786292.3342\n",
      "Epoch 367/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 834219515917.8300 - val_loss: 881689727184.5446\n",
      "Epoch 368/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 837429549614.9646 - val_loss: 899399584396.7100\n",
      "Epoch 369/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 835345118163.6287 - val_loss: 945210189165.5292\n",
      "Epoch 370/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 839197752551.0770 - val_loss: 884508090789.6979\n",
      "Epoch 371/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 832920016477.6410 - val_loss: 962855131891.2540\n",
      "Epoch 372/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 845057035695.6128 - val_loss: 903190828576.1171\n",
      "Epoch 373/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 835137277599.3336 - val_loss: 886382731238.6521\n",
      "Epoch 374/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 835189778905.6793 - val_loss: 891807073140.8743\n",
      "Epoch 375/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 830156836308.4929 - val_loss: 886854241503.2349\n",
      "Epoch 376/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 832959830644.1147 - val_loss: 901837942400.3241\n",
      "Epoch 377/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 833994398245.7445 - val_loss: 918033811200.7921\n",
      "Epoch 378/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 102us/step - loss: 835722485478.7889 - val_loss: 881817323638.0985\n",
      "Epoch 379/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 835273229511.9595 - val_loss: 883168719224.7628\n",
      "Epoch 380/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 837109196941.7581 - val_loss: 905445881300.0731\n",
      "Epoch 381/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 839333498997.5554 - val_loss: 886781254087.6873\n",
      "Epoch 382/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 836271112173.5599 - val_loss: 914552346936.8169\n",
      "Epoch 383/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 835187107769.6973 - val_loss: 884885612438.5756\n",
      "Epoch 384/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 831491413772.8215 - val_loss: 891024840108.8990\n",
      "Epoch 385/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 833903876115.5925 - val_loss: 879783975183.3384\n",
      "Epoch 386/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 835211690532.5919 - val_loss: 883359640137.8835\n",
      "Epoch 387/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 834324399186.4041 - val_loss: 894055377186.9254\n",
      "Epoch 388/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 836188987859.9167 - val_loss: 879484535023.6534\n",
      "Epoch 389/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 830826446497.6388 - val_loss: 879734005928.2183\n",
      "Epoch 390/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 831549767292.7585 - val_loss: 881010839631.5004\n",
      "Epoch 391/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 832619565708.3174 - val_loss: 927197799324.0483\n",
      "Epoch 392/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 834382333010.4041 - val_loss: 884876763548.4805\n",
      "Epoch 393/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 834083938271.7299 - val_loss: 912857560352.3330\n",
      "Epoch 394/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 833366718336.0720 - val_loss: 881473202139.7063\n",
      "Epoch 395/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 832740934839.8243 - val_loss: 880954782847.0278\n",
      "Epoch 396/5000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 833315644493.7941 - val_loss: 894495427922.4529\n",
      "Epoch 397/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 832516846135.0321 - val_loss: 880323161110.7556\n",
      "Epoch 398/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 832871130549.3754 - val_loss: 907191644237.1960\n",
      "Epoch 399/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 830108654919.8876 - val_loss: 944336401530.4191\n",
      "Epoch 400/5000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 829291101073.9359 - val_loss: 885596458921.5865\n",
      "Epoch 401/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 832796096384.0720 - val_loss: 879553845049.2489\n",
      "Epoch 402/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 830923705314.6111 - val_loss: 881631944821.5223\n",
      "Epoch 403/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 830325194641.3595 - val_loss: 916934068950.4495\n",
      "Epoch 404/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 836395865615.2706 - val_loss: 896202152788.0371\n",
      "Epoch 405/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 831476287901.7490 - val_loss: 881431662676.1091\n",
      "Epoch 406/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 831136058476.9117 - val_loss: 886815752459.3058\n",
      "Epoch 407/5000\n",
      "3554/3554 [==============================] - 0s 69us/step - loss: 832033956120.0585 - val_loss: 896395303952.9946\n",
      "Epoch 408/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 830183243296.5582 - val_loss: 881195909055.4779\n",
      "Epoch 409/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 831348472675.8356 - val_loss: 893066320889.9510\n",
      "Epoch 410/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 833693410391.0140 - val_loss: 903043989812.7843\n",
      "Epoch 411/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 835100480310.8881 - val_loss: 878176427135.6039\n",
      "Epoch 412/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 829449889666.3771 - val_loss: 993377194883.8527\n",
      "Epoch 413/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 834168865902.0641 - val_loss: 882636233897.0824\n",
      "Epoch 414/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 829137056981.7896 - val_loss: 885240525365.7203\n",
      "Epoch 415/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 831262317084.5244 - val_loss: 877600542117.4098\n",
      "Epoch 416/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 834341472402.3679 - val_loss: 881424275450.8152\n",
      "Epoch 417/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 834041620160.7563 - val_loss: 894501063059.8391\n",
      "Epoch 418/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 830511225658.3455 - val_loss: 876037792082.7410\n",
      "Epoch 419/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 831189503423.7479 - val_loss: 895124074010.9323\n",
      "Epoch 420/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 830218702735.0546 - val_loss: 910445160356.4017\n",
      "Epoch 421/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 835776566010.9578 - val_loss: 878097523635.0920\n",
      "Epoch 422/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 834404240419.1515 - val_loss: 894207528458.8016\n",
      "Epoch 423/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 828099635599.9191 - val_loss: 876311328912.5986\n",
      "Epoch 424/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 828355870111.4778 - val_loss: 884494669090.6375\n",
      "Epoch 425/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 829313121013.1953 - val_loss: 939213645257.7035\n",
      "Epoch 426/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 835904528374.7799 - val_loss: 892303857220.9868\n",
      "Epoch 427/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 832247745276.1102 - val_loss: 878202769031.2372\n",
      "Epoch 428/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 829028727633.3956 - val_loss: 1035614597635.0244\n",
      "Epoch 429/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 842899702930.9443 - val_loss: 888582235280.3105\n",
      "Epoch 430/5000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 829455328518.1947 - val_loss: 876022221319.0571\n",
      "Epoch 431/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 827636496744.7339 - val_loss: 900398921162.8557\n",
      "Epoch 432/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 831497323722.2645 - val_loss: 879511534933.9094\n",
      "Epoch 433/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 830327248311.6804 - val_loss: 880168187808.9452\n",
      "Epoch 434/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 829874779985.9719 - val_loss: 886577697391.3293\n",
      "Epoch 435/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 830539830960.6212 - val_loss: 885806097432.4838\n",
      "Epoch 436/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 828568464506.7417 - val_loss: 918679848976.7067\n",
      "Epoch 437/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 835772959228.5425 - val_loss: 887811336658.0568\n",
      "Epoch 438/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 830063804840.1215 - val_loss: 892211300000.0090\n",
      "Epoch 439/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 830352419944.3016 - val_loss: 874459386852.6357\n",
      "Epoch 440/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 828722195500.3713 - val_loss: 914836351534.2312\n",
      "Epoch 441/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 80us/step - loss: 833086564259.7277 - val_loss: 881319212006.9401\n",
      "Epoch 442/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 830928462778.2734 - val_loss: 875408403769.1050\n",
      "Epoch 443/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 830285024540.0923 - val_loss: 878727867834.1490\n",
      "Epoch 444/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 829846405737.7423 - val_loss: 879705680402.5789\n",
      "Epoch 445/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 832672881143.6444 - val_loss: 885906362756.2847\n",
      "Epoch 446/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 829381385350.2667 - val_loss: 888636249461.5944\n",
      "Epoch 447/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 830216364792.6528 - val_loss: 929043617040.2025\n",
      "Epoch 448/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 830713531367.2212 - val_loss: 882245965302.6385\n",
      "Epoch 449/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 831980957099.0028 - val_loss: 880102084420.1947\n",
      "Epoch 450/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 828165102560.3062 - val_loss: 884287302199.4486\n",
      "Epoch 451/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 829973007939.1334 - val_loss: 875883363937.2152\n",
      "Epoch 452/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 827681155996.3083 - val_loss: 875363510373.9679\n",
      "Epoch 453/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 827662374078.7395 - val_loss: 878022097985.3862\n",
      "Epoch 454/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 828424583611.7141 - val_loss: 894204913378.8354\n",
      "Epoch 455/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 825960190604.3174 - val_loss: 879994693904.4906\n",
      "Epoch 456/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 828172071983.8289 - val_loss: 879626012886.8816\n",
      "Epoch 457/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 827728208042.5706 - val_loss: 889531829577.2355\n",
      "Epoch 458/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 830809065627.5880 - val_loss: 876099724211.0920\n",
      "Epoch 459/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 830969331269.4384 - val_loss: 883867396603.5353\n",
      "Epoch 460/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 831079560912.8915 - val_loss: 884192665210.5631\n",
      "Epoch 461/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 832384951899.3359 - val_loss: 882965143356.1294\n",
      "Epoch 462/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 830232616632.6888 - val_loss: 880662484986.8152\n",
      "Epoch 463/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 828022562272.0179 - val_loss: 928695993486.0062\n",
      "Epoch 464/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 833565112111.3969 - val_loss: 878749909056.5221\n",
      "Epoch 465/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 832701531937.5667 - val_loss: 876850926232.8079\n",
      "Epoch 466/5000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 830531885227.7231 - val_loss: 875186893305.8070\n",
      "Epoch 467/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 827494078405.2223 - val_loss: 876479119249.3907\n",
      "Epoch 468/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 827840581638.9150 - val_loss: 875518237127.6873\n",
      "Epoch 469/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 828173637840.6031 - val_loss: 876895350202.1490\n",
      "Epoch 470/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 829266073430.5818 - val_loss: 887660753069.9791\n",
      "Epoch 471/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 832300080511.2076 - val_loss: 880391928819.0380\n",
      "Epoch 472/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 833561643440.1891 - val_loss: 876536189841.6787\n",
      "Epoch 473/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 825750871810.4491 - val_loss: 922072025003.3148\n",
      "Epoch 474/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 829102822516.9792 - val_loss: 877575570597.0498\n",
      "Epoch 475/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 825994990736.6393 - val_loss: 903223084344.5288\n",
      "Epoch 476/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 829958727157.9156 - val_loss: 896561763770.7252\n",
      "Epoch 477/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 830193938498.8452 - val_loss: 944330240390.5890\n",
      "Epoch 478/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 834880899919.0906 - val_loss: 873460681591.7548\n",
      "Epoch 479/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 825872389366.0596 - val_loss: 896188114110.3977\n",
      "Epoch 480/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 829654964939.7052 - val_loss: 935505181176.0787\n",
      "Epoch 481/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 840773491947.6871 - val_loss: 902076768120.0427\n",
      "Epoch 482/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 832219385079.2122 - val_loss: 874943584444.3815\n",
      "Epoch 483/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 829375643721.7603 - val_loss: 879121423847.0841\n",
      "Epoch 484/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 825832671894.6899 - val_loss: 874660586760.1373\n",
      "Epoch 485/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 828951336523.2009 - val_loss: 878755388068.9058\n",
      "Epoch 486/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 832535377012.9792 - val_loss: 875113247728.1575\n",
      "Epoch 487/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 826631634363.1379 - val_loss: 873741657448.9204\n",
      "Epoch 488/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 829107982647.1761 - val_loss: 878927879982.3032\n",
      "Epoch 489/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 824931212754.1880 - val_loss: 897107359727.2933\n",
      "Epoch 490/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 830919769189.9966 - val_loss: 895871956869.2928\n",
      "Epoch 491/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 828037247734.3478 - val_loss: 881266279307.9178\n",
      "Epoch 492/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 828438359872.6843 - val_loss: 890383753517.8712\n",
      "Epoch 493/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 829232240111.0006 - val_loss: 995308117446.8231\n",
      "Epoch 494/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 834989581620.2948 - val_loss: 873150541790.5868\n",
      "Epoch 495/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 828384790204.1464 - val_loss: 932329525825.2422\n",
      "Epoch 496/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 827660852275.2864 - val_loss: 876197732331.2607\n",
      "Epoch 497/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 829233560244.6550 - val_loss: 873665600441.4290\n",
      "Epoch 498/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 833524808723.0164 - val_loss: 877225932626.5969\n",
      "Epoch 499/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 827435900047.4868 - val_loss: 884154803302.8320\n",
      "Epoch 500/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 824476485474.1068 - val_loss: 940502693617.8138\n",
      "Epoch 501/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 831559824616.2296 - val_loss: 873270367075.5916\n",
      "Epoch 502/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 825862509500.5785 - val_loss: 881682175298.8984\n",
      "Epoch 503/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 830075282085.6725 - val_loss: 880327056732.8225\n",
      "Epoch 504/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 75us/step - loss: 829728896642.5211 - val_loss: 884956978174.5598\n",
      "Epoch 505/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 829713422977.9448 - val_loss: 874295688616.8663\n",
      "Epoch 506/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 827927037545.1660 - val_loss: 879752848256.3961\n",
      "Epoch 507/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 823982810125.2538 - val_loss: 881494290315.6298\n",
      "Epoch 508/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 826390210489.6973 - val_loss: 899294291917.8801\n",
      "Epoch 509/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 827410940401.8818 - val_loss: 874350393940.2532\n",
      "Epoch 510/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 827502590580.1147 - val_loss: 883859348543.0819\n",
      "Epoch 511/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 834579154103.8243 - val_loss: 956124552319.6039\n",
      "Epoch 512/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 832609655499.7052 - val_loss: 880881387596.6200\n",
      "Epoch 513/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 827954328494.7484 - val_loss: 876268707653.3468\n",
      "Epoch 514/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 832527038059.4711 - val_loss: 876107798098.8130\n",
      "Epoch 515/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 831768885138.5121 - val_loss: 886095859132.4535\n",
      "Epoch 516/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 825683279139.0073 - val_loss: 872828250932.9282\n",
      "Epoch 517/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 828388618233.0850 - val_loss: 893610982787.9966\n",
      "Epoch 518/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 825140063806.5233 - val_loss: 875691433861.8689\n",
      "Epoch 519/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 825850602352.5132 - val_loss: 879433269759.5680\n",
      "Epoch 520/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 824928796045.0377 - val_loss: 946281838372.5098\n",
      "Epoch 521/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 832111952434.4221 - val_loss: 921713026501.0948\n",
      "Epoch 522/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 827929204566.5818 - val_loss: 880099474778.5182\n",
      "Epoch 523/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 827409475061.9156 - val_loss: 887199161029.1667\n",
      "Epoch 524/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 831651929271.2482 - val_loss: 873818111580.6064\n",
      "Epoch 525/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 823466957985.9269 - val_loss: 887916918527.6399\n",
      "Epoch 526/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 826870218373.9786 - val_loss: 892523506074.7522\n",
      "Epoch 527/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 832347158003.6105 - val_loss: 871344353463.1967\n",
      "Epoch 528/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 831376577330.2780 - val_loss: 881421185138.0658\n",
      "Epoch 529/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 829750038553.3550 - val_loss: 883343246551.7457\n",
      "Epoch 530/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 824793138110.8835 - val_loss: 880539232325.7069\n",
      "Epoch 531/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 825538380439.8424 - val_loss: 879656165567.2618\n",
      "Epoch 532/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 833136785501.3528 - val_loss: 880854259692.9890\n",
      "Epoch 533/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 825204045493.2313 - val_loss: 913270085451.6838\n",
      "Epoch 534/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 829679115518.1272 - val_loss: 873636035944.3444\n",
      "Epoch 535/5000\n",
      "3554/3554 [==============================] - 0s 135us/step - loss: 828782288670.1091 - val_loss: 903860838480.6526\n",
      "Epoch 536/5000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 825191669478.7889 - val_loss: 883555039104.6841\n",
      "Epoch 537/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 827971316665.1210 - val_loss: 870354946000.1846\n",
      "Epoch 538/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 828504490085.4204 - val_loss: 897070615950.3662\n",
      "Epoch 539/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 828105581489.0535 - val_loss: 895244963652.1947\n",
      "Epoch 540/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 825239836189.1007 - val_loss: 875927402211.9877\n",
      "Epoch 541/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 828041270794.6608 - val_loss: 875218517495.2146\n",
      "Epoch 542/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 827550348400.3691 - val_loss: 870880135945.1454\n",
      "Epoch 543/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 831089147977.7603 - val_loss: 948841655139.0155\n",
      "Epoch 544/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 831081759190.2217 - val_loss: 872560042225.9578\n",
      "Epoch 545/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 828998547069.9111 - val_loss: 871663505247.8469\n",
      "Epoch 546/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 828792676550.2307 - val_loss: 874483508783.0953\n",
      "Epoch 547/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 826861366551.4823 - val_loss: 872607053014.5935\n",
      "Epoch 548/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 825131463690.9489 - val_loss: 907873479232.6661\n",
      "Epoch 549/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 825441013047.7524 - val_loss: 871723808433.2917\n",
      "Epoch 550/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 827184273376.8824 - val_loss: 980754777875.2271\n",
      "Epoch 551/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 839808901345.8909 - val_loss: 873485575206.3099\n",
      "Epoch 552/5000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 826062802388.4929 - val_loss: 872499386381.2501\n",
      "Epoch 553/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 826524337953.5667 - val_loss: 897025800313.5551\n",
      "Epoch 554/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 826257950894.0281 - val_loss: 914107232582.0669\n",
      "Epoch 555/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 834003657317.1323 - val_loss: 871958718731.8818\n",
      "Epoch 556/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 823136025554.4761 - val_loss: 873192049066.8827\n",
      "Epoch 557/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 824791912934.3567 - val_loss: 885302097866.4236\n",
      "Epoch 558/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 828577437213.1007 - val_loss: 871759411533.5562\n",
      "Epoch 559/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 829446986425.2650 - val_loss: 871236210011.6703\n",
      "Epoch 560/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 827751783641.2471 - val_loss: 871516709511.5251\n",
      "Epoch 561/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 827094555441.1256 - val_loss: 924160184044.6290\n",
      "Epoch 562/5000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 830764437688.50 - 0s 85us/step - loss: 830964679808.5043 - val_loss: 873794409412.3746\n",
      "Epoch 563/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 826599970277.7805 - val_loss: 878634576222.8389\n",
      "Epoch 564/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 828240982712.1124 - val_loss: 873906499845.5449\n",
      "Epoch 565/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 828286279177.5082 - val_loss: 872486575429.7789\n",
      "Epoch 566/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 830568779008.4323 - val_loss: 889295457540.1046\n",
      "Epoch 567/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 140us/step - loss: 829997231143.7614 - val_loss: 876502961780.8022\n",
      "Epoch 568/5000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 828923050381.6139 - val_loss: 872289260157.1555\n",
      "Epoch 569/5000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 823455288917.5734 - val_loss: 887923400084.1272\n",
      "Epoch 570/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 827191851359.5138 - val_loss: 871206612147.4520\n",
      "Epoch 571/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 828384427027.0164 - val_loss: 869487408821.9004\n",
      "Epoch 572/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 827498699338.6246 - val_loss: 877957459247.8875\n",
      "Epoch 573/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 825263591421.6951 - val_loss: 877409502778.6172\n",
      "Epoch 574/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 825891252891.2999 - val_loss: 887236560461.0520\n",
      "Epoch 575/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 825889882978.6832 - val_loss: 874505774616.0518\n",
      "Epoch 576/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 825845215898.1475 - val_loss: 875933210416.0315\n",
      "Epoch 577/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 827355406884.5919 - val_loss: 869600035101.7406\n",
      "Epoch 578/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 825766768236.6234 - val_loss: 870879193775.2754\n",
      "Epoch 579/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 823424424743.9055 - val_loss: 892575183229.3716\n",
      "Epoch 580/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 831534277285.6725 - val_loss: 872953342067.7941\n",
      "Epoch 581/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 828131235311.0006 - val_loss: 872899679900.5525\n",
      "Epoch 582/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 827445654511.2887 - val_loss: 877730901129.9735\n",
      "Epoch 583/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 825969169110.0776 - val_loss: 875282721058.9254\n",
      "Epoch 584/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 826815774019.2775 - val_loss: 880160344947.1460\n",
      "Epoch 585/5000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 824108701296.0809 - val_loss: 872419513906.5519\n",
      "Epoch 586/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 826769805051.5341 - val_loss: 893670864828.5974\n",
      "Epoch 587/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 826132230791.7074 - val_loss: 892879466305.8903\n",
      "Epoch 588/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 833777736321.9448 - val_loss: 894112015149.4391\n",
      "Epoch 589/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 827021104964.1418 - val_loss: 904027843122.8400\n",
      "Epoch 590/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 835156431039.3157 - val_loss: 875158731887.4734\n",
      "Epoch 591/5000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 829483148946.6562 - val_loss: 920481525551.4554\n",
      "Epoch 592/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 831525710786.3409 - val_loss: 887013495458.0253\n",
      "Epoch 593/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 834585652844.6234 - val_loss: 875925484394.5046\n",
      "Epoch 594/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 824713786793.8502 - val_loss: 881353911503.1044\n",
      "Epoch 595/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 825256308329.1660 - val_loss: 874187555064.8708\n",
      "Epoch 596/5000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 828092916555.6332 - val_loss: 883614868292.4827\n",
      "Epoch 597/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 825157804276.3308 - val_loss: 897100707721.9015\n",
      "Epoch 598/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 823801302549.0332 - val_loss: 888571891413.5853\n",
      "Epoch 599/5000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 827830054278.1226 - val_loss: 946767989619.1460\n",
      "Epoch 600/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 839889872825.6973 - val_loss: 871333350696.9744\n",
      "Epoch 601/5000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 823795592471.4823 - val_loss: 881488579152.7966\n",
      "Epoch 602/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 824004699444.2948 - val_loss: 882081186266.6981\n",
      "Epoch 603/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 826403085289.5261 - val_loss: 878764172197.2659\n",
      "Epoch 604/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 831961205915.0118 - val_loss: 898705710023.2551\n",
      "Epoch 605/5000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 826385812994.5931 - val_loss: 923572389374.7039\n",
      "Epoch 606/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 830075498203.2639 - val_loss: 889456387667.9651\n",
      "Epoch 607/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 831380789041.7018 - val_loss: 879827399207.8943\n",
      "Epoch 608/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 826845092786.2059 - val_loss: 875262853677.6552\n",
      "Epoch 609/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 823252930640.6753 - val_loss: 871613066603.8009\n",
      "Epoch 610/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 825206152333.1818 - val_loss: 878282690229.3243\n",
      "Epoch 611/5000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 825071662911.5317 - val_loss: 886448407491.2225\n",
      "Epoch 612/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 827693964957.0287 - val_loss: 918259084149.4503\n",
      "Epoch 613/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 826307817778.5660 - val_loss: 873837012384.2250\n",
      "Epoch 614/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 824546085664.9905 - val_loss: 876952421660.8765\n",
      "Epoch 615/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 826435379103.1897 - val_loss: 895188374173.4166\n",
      "Epoch 616/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 827172984810.1024 - val_loss: 902621452914.2098\n",
      "Epoch 617/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 824825430845.8030 - val_loss: 938528431978.2166\n",
      "Epoch 618/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 827184924615.5272 - val_loss: 877560177656.2228\n",
      "Epoch 619/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 830182331877.7805 - val_loss: 907654690790.0759\n",
      "Epoch 620/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 825751314906.8317 - val_loss: 870070840527.1044\n",
      "Epoch 621/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 822621396996.6100 - val_loss: 876395203231.1449\n",
      "Epoch 622/5000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 830559376725.33 - 0s 86us/step - loss: 827032293604.1959 - val_loss: 881937314228.6763\n",
      "Epoch 623/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 823861847117.7941 - val_loss: 881356623863.9347\n",
      "Epoch 624/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 828292866744.1124 - val_loss: 878728884444.0664\n",
      "Epoch 625/5000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 828386605315.3134 - val_loss: 876532716949.8555\n",
      "Epoch 626/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 829162556571.0118 - val_loss: 871720354953.3975\n",
      "Epoch 627/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 824143289091.0253 - val_loss: 872239654843.4453\n",
      "Epoch 628/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 829107383557.0422 - val_loss: 872588834080.3330\n",
      "Epoch 629/5000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 825055205787.4441 - val_loss: 869572657976.9609\n",
      "Epoch 630/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 94us/step - loss: 822936406466.6293 - val_loss: 871795001987.4926\n",
      "Epoch 631/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 826817047176.8599 - val_loss: 871542242300.2554\n",
      "Epoch 632/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 825548151813.1863 - val_loss: 874336810346.0726\n",
      "Epoch 633/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 826402408571.3179 - val_loss: 883896421548.5389\n",
      "Epoch 634/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 827145884401.7378 - val_loss: 868696598169.0959\n",
      "Epoch 635/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 825273302920.1396 - val_loss: 870266998273.5842\n",
      "Epoch 636/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 824493344158.3252 - val_loss: 892751961012.8203\n",
      "Epoch 637/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 826743003814.8250 - val_loss: 884028143654.5980\n",
      "Epoch 638/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 826405095035.6060 - val_loss: 906949493528.6998\n",
      "Epoch 639/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 832482624566.7439 - val_loss: 878201670238.6228\n",
      "Epoch 640/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 823876264853.3934 - val_loss: 897226511512.3759\n",
      "Epoch 641/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 827287107953.9539 - val_loss: 871162244257.0172\n",
      "Epoch 642/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 823460445617.9178 - val_loss: 874847800676.8878\n",
      "Epoch 643/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 823950226230.8881 - val_loss: 981004802545.1656\n",
      "Epoch 644/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 833228206050.0349 - val_loss: 877679687999.7300\n",
      "Epoch 645/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 827744767933.1548 - val_loss: 874548084104.6053\n",
      "Epoch 646/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 829459066882.3049 - val_loss: 875535944991.7570\n",
      "Epoch 647/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 828615188834.9713 - val_loss: 871818000164.5098\n",
      "Epoch 648/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 828675745426.6562 - val_loss: 928205016835.6726\n",
      "Epoch 649/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 830309148315.8762 - val_loss: 876717883986.5249\n",
      "Epoch 650/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 830091673978.0214 - val_loss: 871715311465.0645\n",
      "Epoch 651/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 828236388210.2419 - val_loss: 870425852375.8177\n",
      "Epoch 652/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 826964705943.8424 - val_loss: 869996899954.4979\n",
      "Epoch 653/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 829259920570.1295 - val_loss: 893176178895.9685\n",
      "Epoch 654/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 827739139139.4215 - val_loss: 902328897979.5894\n",
      "Epoch 655/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 828953129036.0652 - val_loss: 867940358816.2970\n",
      "Epoch 656/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 826863841217.7648 - val_loss: 886851385866.5137\n",
      "Epoch 657/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 829832866782.0011 - val_loss: 898018130055.3811\n",
      "Epoch 658/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 824000613641.6522 - val_loss: 874301098443.1438\n",
      "Epoch 659/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 828571762478.2443 - val_loss: 871205147975.5072\n",
      "Epoch 660/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 823153644375.1582 - val_loss: 874638259059.7220\n",
      "Epoch 661/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 828582984616.9860 - val_loss: 876393590381.8892\n",
      "Epoch 662/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 829404006574.0281 - val_loss: 869997556826.1581\n",
      "Epoch 663/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 824177407042.2690 - val_loss: 872990598998.0535\n",
      "Epoch 664/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 830145911601.1256 - val_loss: 876688577504.0270\n",
      "Epoch 665/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 825131971862.3297 - val_loss: 872166296997.4098\n",
      "Epoch 666/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 825234795633.5216 - val_loss: 881209490253.1240\n",
      "Epoch 667/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 824266922911.7659 - val_loss: 872957896183.7908\n",
      "Epoch 668/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 823078669333.3213 - val_loss: 892098201160.4434\n",
      "Epoch 669/5000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 825483199072.5222 - val_loss: 881101411084.0259\n",
      "Epoch 670/5000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 828306302878.0371 - val_loss: 869307498288.6075\n",
      "Epoch 671/5000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 827906225918.9916 - val_loss: 961175373771.5758\n",
      "Epoch 672/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 833173225084.7585 - val_loss: 885188944422.7421\n",
      "Epoch 673/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 828540586711.2302 - val_loss: 924199951658.1266\n",
      "Epoch 674/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 824919909057.3325 - val_loss: 918457779328.1801\n",
      "Epoch 675/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 826594239307.6332 - val_loss: 868801980020.2262\n",
      "Epoch 676/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 824521838488.2747 - val_loss: 877227080566.6025\n",
      "Epoch 677/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 824582015583.3696 - val_loss: 953273103892.5952\n",
      "Epoch 678/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 831080756419.3494 - val_loss: 875645240033.3953\n",
      "Epoch 679/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 822117275036.0203 - val_loss: 867748340401.0037\n",
      "Epoch 680/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 829823360014.4064 - val_loss: 958922164406.6205\n",
      "Epoch 681/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 831840494485.3934 - val_loss: 873045119603.9381\n",
      "Epoch 682/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 822130807058.2960 - val_loss: 871795520818.7679\n",
      "Epoch 683/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 824676553453.1278 - val_loss: 887780182041.9241\n",
      "Epoch 684/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 827391722661.3844 - val_loss: 873798251241.4604\n",
      "Epoch 685/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 825257948075.0748 - val_loss: 871816801417.9735\n",
      "Epoch 686/5000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 826490829013.2133 - val_loss: 867468609525.0543\n",
      "Epoch 687/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 827574599896.6709 - val_loss: 881428933502.6678\n",
      "Epoch 688/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 823964019207.7794 - val_loss: 868410274979.8976\n",
      "Epoch 689/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 826141161629.8932 - val_loss: 870976546093.0071\n",
      "Epoch 690/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 828667488296.3376 - val_loss: 878907862577.9758\n",
      "Epoch 691/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 824227448305.3055 - val_loss: 875396298726.0759\n",
      "Epoch 692/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 825554073379.8716 - val_loss: 907502171834.5092\n",
      "Epoch 693/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 99us/step - loss: 828171168899.9618 - val_loss: 879591259358.0826\n",
      "Epoch 694/5000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 828521584175.5408 - val_loss: 880022341284.6177\n",
      "Epoch 695/5000\n",
      "3554/3554 [==============================] - 1s 143us/step - loss: 828205467480.8870 - val_loss: 878166463746.3763\n",
      "Epoch 696/5000\n",
      "3554/3554 [==============================] - 1s 170us/step - loss: 823050974283.4890 - val_loss: 912481137016.7628\n",
      "Epoch 697/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 830865950764.9478 - val_loss: 869420184518.6791\n",
      "Epoch 698/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 828670034390.2217 - val_loss: 878180213881.2670\n",
      "Epoch 699/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 826558123255.2122 - val_loss: 877739929096.4973\n",
      "Epoch 700/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 827112713394.0619 - val_loss: 872386072849.0667\n",
      "Epoch 701/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 827809853257.9044 - val_loss: 887147258176.3060\n",
      "Epoch 702/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 827978285756.7225 - val_loss: 893055573483.6929\n",
      "Epoch 703/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 827683226789.3844 - val_loss: 870855278204.8676\n",
      "Epoch 704/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 820895883789.5419 - val_loss: 870913728500.4781\n",
      "Epoch 705/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 823996404954.3997 - val_loss: 881121280824.9609\n",
      "Epoch 706/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 825521128428.9836 - val_loss: 870008521966.7893\n",
      "Epoch 707/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 826261784473.4271 - val_loss: 913145094012.6515\n",
      "Epoch 708/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 827063776239.2887 - val_loss: 896808023190.0714\n",
      "Epoch 709/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 831767527709.8210 - val_loss: 980036280585.0015\n",
      "Epoch 710/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 829331698984.7698 - val_loss: 887741599570.0209\n",
      "Epoch 711/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 828000166077.0107 - val_loss: 897100325511.5251\n",
      "Epoch 712/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 827235623949.2538 - val_loss: 870738921885.0565\n",
      "Epoch 713/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 826770269778.1158 - val_loss: 880136631644.2465\n",
      "Epoch 714/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 824210509535.8739 - val_loss: 891107192204.0619\n",
      "Epoch 715/5000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 823239541215.4418 - val_loss: 874128244450.2594\n",
      "Epoch 716/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 826339728061.8751 - val_loss: 948590533575.2551\n",
      "Epoch 717/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 827922779493.8525 - val_loss: 887301712499.3621\n",
      "Epoch 718/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 825713662354.2240 - val_loss: 868482319045.7429\n",
      "Epoch 719/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 823860334810.9758 - val_loss: 871040176958.7218\n",
      "Epoch 720/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 826331821435.7501 - val_loss: 916203217617.2646\n",
      "Epoch 721/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 825441598483.0164 - val_loss: 872652331293.1646\n",
      "Epoch 722/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 827839397307.1379 - val_loss: 892313385694.5148\n",
      "Epoch 723/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 827374391911.4373 - val_loss: 871971430024.3893\n",
      "Epoch 724/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 824989330720.7024 - val_loss: 869173922131.3170\n",
      "Epoch 725/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 823183558428.9567 - val_loss: 887266279848.0022\n",
      "Epoch 726/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 825706586679.0321 - val_loss: 902617510356.9373\n",
      "Epoch 727/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 822851265549.2538 - val_loss: 907529897267.9202\n",
      "Epoch 728/5000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 827185269029.8887 - val_loss: 876637007843.1956\n",
      "Epoch 729/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 826143260459.9392 - val_loss: 890842051540.5052\n",
      "Epoch 730/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 836917720111.8289 - val_loss: 869667082761.9375\n",
      "Epoch 731/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 825679079814.6990 - val_loss: 868211503720.4163\n",
      "Epoch 732/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 825477705167.8831 - val_loss: 868137691122.7499\n",
      "Epoch 733/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 820892262008.1487 - val_loss: 868624903886.6722\n",
      "Epoch 734/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 826768491630.0641 - val_loss: 870095868163.2405\n",
      "Epoch 735/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 823392094031.6669 - val_loss: 870477382880.9631\n",
      "Epoch 736/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 824954761080.0045 - val_loss: 867967245352.0382\n",
      "Epoch 737/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 823987621009.7917 - val_loss: 873604372617.6855\n",
      "Epoch 738/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 824446962114.6293 - val_loss: 871252378802.8760\n",
      "Epoch 739/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 823345512540.2003 - val_loss: 868496634652.1564\n",
      "Epoch 740/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 824869102835.7546 - val_loss: 870767935621.6528\n",
      "Epoch 741/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 828497165063.6354 - val_loss: 872371745757.7227\n",
      "Epoch 742/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 826591273407.1716 - val_loss: 880559837692.1115\n",
      "Epoch 743/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 827030960276.6731 - val_loss: 870042727408.1575\n",
      "Epoch 744/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 827786396016.8013 - val_loss: 873893505098.3156\n",
      "Epoch 745/5000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 826644203039.4058 - val_loss: 909015476865.1882\n",
      "Epoch 746/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 830726663161.6613 - val_loss: 867894314900.2711\n",
      "Epoch 747/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 827636231382.9420 - val_loss: 867146161970.9120\n",
      "Epoch 748/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 823352996423.1672 - val_loss: 879810663064.8079\n",
      "Epoch 749/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 821775979922.8002 - val_loss: 890003986537.4244\n",
      "Epoch 750/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 827228971768.6528 - val_loss: 878159746297.1589\n",
      "Epoch 751/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 827764388091.2460 - val_loss: 873352664621.9432\n",
      "Epoch 752/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 828892137927.2391 - val_loss: 872735237338.0500\n",
      "Epoch 753/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 823063286762.6787 - val_loss: 883621992525.7721\n",
      "Epoch 754/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 824058090889.5802 - val_loss: 868931929741.5741\n",
      "Epoch 755/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 824206403688.8779 - val_loss: 873053967277.3311\n",
      "Epoch 756/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 111us/step - loss: 825853811666.4761 - val_loss: 866977555190.1344\n",
      "Epoch 757/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 823140591462.7169 - val_loss: 874820228529.5077\n",
      "Epoch 758/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 823419436724.0787 - val_loss: 870113188544.5581\n",
      "Epoch 759/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 823563742312.3016 - val_loss: 877542508671.3159\n",
      "Epoch 760/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 826320881307.8762 - val_loss: 867999295313.4447\n",
      "Epoch 761/5000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 817941876927.40 - 0s 85us/step - loss: 823807380579.6917 - val_loss: 880569668534.5486\n",
      "Epoch 762/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 826066797797.9247 - val_loss: 878173793971.0200\n",
      "Epoch 763/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 826765783826.0079 - val_loss: 872467244356.0507\n",
      "Epoch 764/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 823305782234.5436 - val_loss: 870610701576.7134\n",
      "Epoch 765/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 828495970184.1396 - val_loss: 868463679556.5547\n",
      "Epoch 766/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 824920496557.8842 - val_loss: 878507384119.9528\n",
      "Epoch 767/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 825600050664.0854 - val_loss: 868030770770.2368\n",
      "Epoch 768/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 823623941111.3562 - val_loss: 871298848712.1193\n",
      "Epoch 769/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 822443525589.6455 - val_loss: 937140860574.8568\n",
      "Epoch 770/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 825549526391.1401 - val_loss: 873403823553.6383\n",
      "Epoch 771/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 827639989477.9247 - val_loss: 890097727609.5551\n",
      "Epoch 772/5000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 824262610434.5931 - val_loss: 870801048501.3964\n",
      "Epoch 773/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 824621166243.9437 - val_loss: 928580812021.1263\n",
      "Epoch 774/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 829392327234.5571 - val_loss: 875623346806.2424\n",
      "Epoch 775/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 828683230913.9089 - val_loss: 869688841598.8118\n",
      "Epoch 776/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 829282910392.4008 - val_loss: 908356900494.7263\n",
      "Epoch 777/5000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 832173804957.1729 - val_loss: 870028355722.8376\n",
      "Epoch 778/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 826050147216.2072 - val_loss: 884074244571.2743\n",
      "Epoch 779/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 824752698729.3101 - val_loss: 898326239696.9047\n",
      "Epoch 780/5000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 826650266871.2122 - val_loss: 877359440796.0483\n",
      "Epoch 781/5000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 822191031175.5632 - val_loss: 899506898297.0509\n",
      "Epoch 782/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 829681206631.0050 - val_loss: 873586739046.1840\n",
      "Epoch 783/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 820851947475.0522 - val_loss: 924085994416.7876\n",
      "Epoch 784/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 832092123092.2048 - val_loss: 876155837221.9500\n",
      "Epoch 785/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 826111120381.1187 - val_loss: 880930566972.4175\n",
      "Epoch 786/5000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 828669643018.2285 - val_loss: 877528598374.1840\n",
      "Epoch 787/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 826661098216.5177 - val_loss: 868285205561.3209\n",
      "Epoch 788/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 824807746830.2622 - val_loss: 913416613015.7997\n",
      "Epoch 789/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 829793893441.1165 - val_loss: 886538373413.2299\n",
      "Epoch 790/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 828111817993.6522 - val_loss: 882238382833.5258\n",
      "Epoch 791/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 826643620407.0321 - val_loss: 904482861524.9373\n",
      "Epoch 792/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 823495633424.9994 - val_loss: 868670249931.8639\n",
      "Epoch 793/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 827635983502.3342 - val_loss: 872739266096.8236\n",
      "Epoch 794/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 826743021388.2094 - val_loss: 884860540743.0751\n",
      "Epoch 795/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 827151044900.7361 - val_loss: 869101926180.5098\n",
      "Epoch 796/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 823480783269.8165 - val_loss: 884685835888.1935\n",
      "Epoch 797/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 822758945899.7592 - val_loss: 890474202489.0509\n",
      "Epoch 798/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 827844336525.3258 - val_loss: 870252722412.7729\n",
      "Epoch 799/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 827037274674.4221 - val_loss: 886709279005.1646\n",
      "Epoch 800/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 825911078273.5127 - val_loss: 905492628322.4393\n",
      "Epoch 801/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 826643556419.9978 - val_loss: 876773063123.2090\n",
      "Epoch 802/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 827554831844.6281 - val_loss: 871759169594.1851\n",
      "Epoch 803/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 823468250809.8413 - val_loss: 867969316639.9010\n",
      "Epoch 804/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 828591376972.9297 - val_loss: 868598478886.5980\n",
      "Epoch 805/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 823037139917.8660 - val_loss: 916487297613.3401\n",
      "Epoch 806/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 823841121651.6826 - val_loss: 871081418662.1300\n",
      "Epoch 807/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 824097296787.3766 - val_loss: 869274606184.9924\n",
      "Epoch 808/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 827617581236.9432 - val_loss: 893154079142.8501\n",
      "Epoch 809/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 826659771029.5374 - val_loss: 881687325451.4498\n",
      "Epoch 810/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 826497353422.5863 - val_loss: 898622418025.7125\n",
      "Epoch 811/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 828020006718.3794 - val_loss: 873461966097.3547\n",
      "Epoch 812/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 824787709382.6630 - val_loss: 869098336393.1094\n",
      "Epoch 813/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 822641489280.3601 - val_loss: 866906512212.0371\n",
      "Epoch 814/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 820443527786.8948 - val_loss: 874032147732.2351\n",
      "Epoch 815/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 819959346491.2100 - val_loss: 907370574071.7188\n",
      "Epoch 816/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 826497944131.7096 - val_loss: 878200029829.2208\n",
      "Epoch 817/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 827525482872.8688 - val_loss: 872548215291.5353\n",
      "Epoch 818/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 823241850594.1790 - val_loss: 887897893030.4900\n",
      "Epoch 819/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 86us/step - loss: 828427244679.4193 - val_loss: 872643607317.8195\n",
      "Epoch 820/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 826859951829.5015 - val_loss: 908112597550.8074\n",
      "Epoch 821/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 830214444554.6608 - val_loss: 927437522250.9637\n",
      "Epoch 822/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 824940594369.0444 - val_loss: 870931259334.3910\n",
      "Epoch 823/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 823427887710.2173 - val_loss: 876242168873.1904\n",
      "Epoch 824/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 826425975867.3539 - val_loss: 879257738100.2982\n",
      "Epoch 825/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 824183900112.7473 - val_loss: 881615254691.8976\n",
      "Epoch 826/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 825021868588.6595 - val_loss: 893163158837.6484\n",
      "Epoch 827/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 824773537061.3123 - val_loss: 875882643004.3455\n",
      "Epoch 828/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 821590887818.7327 - val_loss: 869743646876.1204\n",
      "Epoch 829/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 820492218379.5250 - val_loss: 869683309954.8445\n",
      "Epoch 830/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 822914323517.6591 - val_loss: 869488054190.1952\n",
      "Epoch 831/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 824235514544.0450 - val_loss: 890461034527.6849\n",
      "Epoch 832/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 825138480357.9247 - val_loss: 892518149912.4119\n",
      "Epoch 833/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 826015484529.8098 - val_loss: 885709080592.7067\n",
      "Epoch 834/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 825043094102.7260 - val_loss: 867955687714.3494\n",
      "Epoch 835/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 822045969839.6128 - val_loss: 870068000191.3339\n",
      "Epoch 836/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 823481496679.1492 - val_loss: 876839397648.4906\n",
      "Epoch 837/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 824583828057.6072 - val_loss: 875082755145.4514\n",
      "Epoch 838/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 823019929175.8785 - val_loss: 868410897046.5035\n",
      "Epoch 839/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 824837202745.1930 - val_loss: 871650481557.8555\n",
      "Epoch 840/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 825062662471.3112 - val_loss: 887399368034.0073\n",
      "Epoch 841/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 823994409149.0107 - val_loss: 871167814614.2335\n",
      "Epoch 842/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 824434970727.7253 - val_loss: 870251315499.5668\n",
      "Epoch 843/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 823520578521.3911 - val_loss: 909520802138.8062\n",
      "Epoch 844/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 829607621025.2065 - val_loss: 873562963175.3002\n",
      "Epoch 845/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 827745776678.6089 - val_loss: 875544268764.2825\n",
      "Epoch 846/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 825905551909.7445 - val_loss: 866622391106.1783\n",
      "Epoch 847/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 826381425291.1649 - val_loss: 925612882046.1637\n",
      "Epoch 848/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 835943016847.9191 - val_loss: 882695016647.3271\n",
      "Epoch 849/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 823327098436.2859 - val_loss: 876180280730.4641\n",
      "Epoch 850/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 823935051973.0781 - val_loss: 893481649326.2672\n",
      "Epoch 851/5000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 825271594115.9618 - val_loss: 872920869431.4486\n",
      "Epoch 852/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 827078057333.9877 - val_loss: 882587588524.4669\n",
      "Epoch 853/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 824408856950.5638 - val_loss: 884327842566.2650\n",
      "Epoch 854/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 828941300285.9471 - val_loss: 872648203022.9064\n",
      "Epoch 855/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 823204897657.7333 - val_loss: 868641011142.2469\n",
      "Epoch 856/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 825096115667.3405 - val_loss: 871551093697.4943\n",
      "Epoch 857/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 823329868314.2195 - val_loss: 866911095786.9727\n",
      "Epoch 858/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 822680096175.6128 - val_loss: 875112454880.8191\n",
      "Epoch 859/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 823538799668.4390 - val_loss: 879465838257.2917\n",
      "Epoch 860/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 828256186536.2656 - val_loss: 884042945978.7252\n",
      "Epoch 861/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 823046799562.8407 - val_loss: 872256661536.8372\n",
      "Epoch 862/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 824573827492.6641 - val_loss: 901289031944.4253\n",
      "Epoch 863/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 826362775596.9478 - val_loss: 871515559285.5944\n",
      "Epoch 864/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 826999488779.3811 - val_loss: 921477211861.0093\n",
      "Epoch 865/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 823820557437.0466 - val_loss: 884601160942.7893\n",
      "Epoch 866/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 828176109473.4946 - val_loss: 875112044538.8152\n",
      "Epoch 867/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 823284496901.4744 - val_loss: 874177360096.6750\n",
      "Epoch 868/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 821886842069.7896 - val_loss: 871470365254.4270\n",
      "Epoch 869/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 823889970645.6455 - val_loss: 868795330356.0641\n",
      "Epoch 870/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 828048756254.2532 - val_loss: 873808670930.8490\n",
      "Epoch 871/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 826773788106.1204 - val_loss: 869057282209.3052\n",
      "Epoch 872/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 826630297430.5818 - val_loss: 869140031705.1859\n",
      "Epoch 873/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 822345662464.0000 - val_loss: 921621194453.0093\n",
      "Epoch 874/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 828793473290.2285 - val_loss: 871540574902.1885\n",
      "Epoch 875/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 821008567155.9707 - val_loss: 887148807185.5708\n",
      "Epoch 876/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 825333380070.0686 - val_loss: 874866370537.5325\n",
      "Epoch 877/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 828280617571.9797 - val_loss: 891902471103.1898\n",
      "Epoch 878/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 826157249759.0095 - val_loss: 872108911021.1870\n",
      "Epoch 879/5000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 823699196027.3179 - val_loss: 902955117023.8829\n",
      "Epoch 880/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 822812667058.0619 - val_loss: 880482355281.2286\n",
      "Epoch 881/5000\n",
      "3554/3554 [==============================] - 0s 132us/step - loss: 822202082234.2734 - val_loss: 886423229278.9828\n",
      "Epoch 882/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 124us/step - loss: 829786143265.1345 - val_loss: 867395656619.6028\n",
      "Epoch 883/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 824278355629.1638 - val_loss: 922328238778.7972\n",
      "Epoch 884/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 826342783170.7732 - val_loss: 919022914230.1885\n",
      "Epoch 885/5000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 828587001273.9854 - val_loss: 890218355254.2965\n",
      "Epoch 886/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 827314128885.6276 - val_loss: 869231480694.8906\n",
      "Epoch 887/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 824687560997.8887 - val_loss: 867082281128.2183\n",
      "Epoch 888/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 826841418971.5520 - val_loss: 866123008961.4943\n",
      "Epoch 889/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 826865469245.2268 - val_loss: 876099033087.4240\n",
      "Epoch 890/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 824842405997.4879 - val_loss: 878717737074.6420\n",
      "Epoch 891/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 822401831177.0759 - val_loss: 868571890332.2644\n",
      "Epoch 892/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 823158461278.0731 - val_loss: 869760271230.0917\n",
      "Epoch 893/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 825946931734.7620 - val_loss: 870915445746.4619\n",
      "Epoch 894/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 827908406316.3713 - val_loss: 867404771303.8042\n",
      "Epoch 895/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 820514286087.7794 - val_loss: 924533199360.7201\n",
      "Epoch 896/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 827528357845.3573 - val_loss: 876497303599.8154\n",
      "Epoch 897/5000\n",
      "3554/3554 [==============================] - 0s 130us/step - loss: 821505763561.9584 - val_loss: 866533523036.6064\n",
      "Epoch 898/5000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 825012831093.1232 - val_loss: 890930143501.6101\n",
      "Epoch 899/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 825046358077.0826 - val_loss: 867757030898.6060\n",
      "Epoch 900/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 822864472141.2178 - val_loss: 870961766185.6945\n",
      "Epoch 901/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 825773101920.3782 - val_loss: 941865239246.9603\n",
      "Epoch 902/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 827904607028.5830 - val_loss: 876180773310.4697\n",
      "Epoch 903/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 827559854587.1018 - val_loss: 885318070879.1989\n",
      "Epoch 904/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 826126883467.1649 - val_loss: 877033289305.7261\n",
      "Epoch 905/5000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 822571619878.3207 - val_loss: 866618398553.5100\n",
      "Epoch 906/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 821770918456.1846 - val_loss: 903515182923.6838\n",
      "Epoch 907/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 824362901480.9500 - val_loss: 987161452209.8678\n",
      "Epoch 908/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 829997210251.1649 - val_loss: 869692732759.6377\n",
      "Epoch 909/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 822432432801.0624 - val_loss: 869584605622.9806\n",
      "Epoch 910/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 824633429036.3713 - val_loss: 877844476068.7617\n",
      "Epoch 911/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 821470935622.0146 - val_loss: 871451889227.3237\n",
      "Epoch 912/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 830277944476.1644 - val_loss: 867344269316.6088\n",
      "Epoch 913/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 824005285395.8807 - val_loss: 866558247492.6987\n",
      "Epoch 914/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 822453970237.5149 - val_loss: 883129773585.7147\n",
      "Epoch 915/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 825931816983.0500 - val_loss: 868840619345.3007\n",
      "Epoch 916/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 825229948703.2617 - val_loss: 867237969519.0414\n",
      "Epoch 917/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 823314464039.6173 - val_loss: 875294368658.8309\n",
      "Epoch 918/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 824514938141.2448 - val_loss: 869420929472.1980\n",
      "Epoch 919/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 825248157970.2960 - val_loss: 877268240714.0996\n",
      "Epoch 920/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 829431753601.8008 - val_loss: 877041279388.4805\n",
      "Epoch 921/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 826095208151.8064 - val_loss: 884314321429.4594\n",
      "Epoch 922/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 825543678123.7231 - val_loss: 873632056775.3992\n",
      "Epoch 923/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 826832874065.5397 - val_loss: 912450229981.0746\n",
      "Epoch 924/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 827367432224.2701 - val_loss: 909877400327.4171\n",
      "Epoch 925/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 830876009858.6652 - val_loss: 870546285643.1797\n",
      "Epoch 926/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 826088291282.4761 - val_loss: 881245670254.5372\n",
      "Epoch 927/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 825294502128.8733 - val_loss: 872774841913.4650\n",
      "Epoch 928/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 822483179378.2419 - val_loss: 897661507329.9443\n",
      "Epoch 929/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 830007421493.8796 - val_loss: 868177828097.5122\n",
      "Epoch 930/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 820638602310.8790 - val_loss: 906059313081.7170\n",
      "Epoch 931/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 826412093428.4750 - val_loss: 869026665522.9840\n",
      "Epoch 932/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 824774212940.4974 - val_loss: 872567968044.7190\n",
      "Epoch 933/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 824209068352.3962 - val_loss: 868869132427.4138\n",
      "Epoch 934/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 822899172512.7743 - val_loss: 882145554711.9797\n",
      "Epoch 935/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 822264641712.3331 - val_loss: 873319125269.6754\n",
      "Epoch 936/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 826889041312.6304 - val_loss: 869144720358.9401\n",
      "Epoch 937/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 824009014567.6173 - val_loss: 867594435511.1246\n",
      "Epoch 938/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 824512165803.8671 - val_loss: 866427781336.6099\n",
      "Epoch 939/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 820395377820.1644 - val_loss: 941309509120.4320\n",
      "Epoch 940/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 832084377673.7603 - val_loss: 880478001331.1639\n",
      "Epoch 941/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 828337959873.1886 - val_loss: 873230663062.4315\n",
      "Epoch 942/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 821481688467.9528 - val_loss: 974648487418.6711\n",
      "Epoch 943/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 832170973337.2831 - val_loss: 867203522433.2603\n",
      "Epoch 944/5000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 825824527138.1429 - val_loss: 867371819065.6090\n",
      "Epoch 945/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 94us/step - loss: 824971371118.3522 - val_loss: 868319906458.5361\n",
      "Epoch 946/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 822702400543.6938 - val_loss: 879566632440.9429\n",
      "Epoch 947/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 824488577400.8688 - val_loss: 867050904740.4738\n",
      "Epoch 948/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 824857639789.0557 - val_loss: 913846454662.0129\n",
      "Epoch 949/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 828062872024.5267 - val_loss: 870315757942.4585\n",
      "Epoch 950/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 823123549147.6962 - val_loss: 867142842641.6427\n",
      "Epoch 951/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 825705284722.6742 - val_loss: 871760513976.2767\n",
      "Epoch 952/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 826571406032.3151 - val_loss: 869502027239.6602\n",
      "Epoch 953/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 820800731883.9752 - val_loss: 868557719163.1393\n",
      "Epoch 954/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 825138434589.6770 - val_loss: 887360212827.2383\n",
      "Epoch 955/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 825046967217.0535 - val_loss: 867367748773.0498\n",
      "Epoch 956/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 822292533900.3174 - val_loss: 869417531628.7729\n",
      "Epoch 957/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 822361864460.5334 - val_loss: 880244413827.4205\n",
      "Epoch 958/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 828644479407.0365 - val_loss: 877913527379.2450\n",
      "Epoch 959/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 823497263600.7294 - val_loss: 922109048474.2480\n",
      "Epoch 960/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 834499912634.2734 - val_loss: 885618850406.6880\n",
      "Epoch 961/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 828025693732.0157 - val_loss: 870492664511.9821\n",
      "Epoch 962/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 824512023628.6416 - val_loss: 866645347730.9750\n",
      "Epoch 963/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 823237381666.8632 - val_loss: 894585633147.6433\n",
      "Epoch 964/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 824257307937.8547 - val_loss: 943374404209.0576\n",
      "Epoch 965/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 828939161164.3534 - val_loss: 866983436248.8259\n",
      "Epoch 966/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 822341881106.8722 - val_loss: 968781826147.6636\n",
      "Epoch 967/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 833486347437.4519 - val_loss: 881395684536.6368\n",
      "Epoch 968/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 828181695523.1515 - val_loss: 871441494203.8053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f01a0b9c9e8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile model\n",
    "model11.compile(loss='mean_squared_error', optimizer='nadam')\n",
    "print(\"model11 loss:\",model11.loss)\n",
    "\n",
    "model_train11 = model11.fit(predictors,target, epochs=5000, validation_split=0.5, callbacks=[early_stopping_monitor], verbose=True)\n",
    "model_train11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model22 loss: mean_squared_error\n",
      "Train on 3554 samples, validate on 3555 samples\n",
      "Epoch 1/5000\n",
      "3554/3554 [==============================] - 1s 167us/step - loss: 133448740537555.4844 - val_loss: 132137526512135.0625\n",
      "Epoch 2/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 129155920309785.6406 - val_loss: 115730559470893.5781\n",
      "Epoch 3/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 74716719562042.0625 - val_loss: 21838191247042.0000\n",
      "Epoch 4/5000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 10329430445957.8340 - val_loss: 7418312209977.4648\n",
      "Epoch 5/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 7191865467908.0342 - val_loss: 6605413589584.2207\n",
      "Epoch 6/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 6416966374581.5195 - val_loss: 6036769265193.3340\n",
      "Epoch 7/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 5850097332290.8447 - val_loss: 5599106426534.9219\n",
      "Epoch 8/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 5411662124563.8809 - val_loss: 5260404841912.9971\n",
      "Epoch 9/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 5066138562092.0830 - val_loss: 4994588918087.2188\n",
      "Epoch 10/5000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 4792134139608.9590 - val_loss: 4775727081592.4023\n",
      "Epoch 11/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 4579314220106.3359 - val_loss: 4601102059329.3145\n",
      "Epoch 12/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 4382565077174.0957 - val_loss: 4495772794506.6934\n",
      "Epoch 13/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 4242204503006.0010 - val_loss: 4317407130889.2896\n",
      "Epoch 14/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 4081995417432.8867 - val_loss: 4203471753797.8511\n",
      "Epoch 15/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 3981103653643.0928 - val_loss: 4122929783012.1318\n",
      "Epoch 16/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 3865648096158.6138 - val_loss: 4030227607537.0215\n",
      "Epoch 17/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 3776306257528.1484 - val_loss: 3939496313832.0923\n",
      "Epoch 18/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 3688533571059.6108 - val_loss: 3895468418782.2266\n",
      "Epoch 19/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 3619623037005.2178 - val_loss: 3795833638240.2788\n",
      "Epoch 20/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 3544837861295.3247 - val_loss: 3736055962216.9922\n",
      "Epoch 21/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 3472022399163.8584 - val_loss: 3668244886337.0264\n",
      "Epoch 22/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 3426703139956.9790 - val_loss: 3609113843093.8555\n",
      "Epoch 23/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 3355415425422.7666 - val_loss: 3549208331498.1807\n",
      "Epoch 24/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 3297079611196.0742 - val_loss: 3496542046215.4893\n",
      "Epoch 25/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 3241920152151.3022 - val_loss: 3439367796954.3379\n",
      "Epoch 26/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 3192468733472.5586 - val_loss: 3385401101562.8872\n",
      "Epoch 27/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 3139258890305.6929 - val_loss: 3331763044232.1733\n",
      "Epoch 28/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 3082941218751.4595 - val_loss: 3291777887752.4976\n",
      "Epoch 29/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 3029045828548.6460 - val_loss: 3227931596191.0728\n",
      "Epoch 30/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2989736444872.1035 - val_loss: 3180703141833.8477\n",
      "Epoch 31/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2935360365037.2715 - val_loss: 3144021888057.3208\n",
      "Epoch 32/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2887118204902.6450 - val_loss: 3137148133912.9160\n",
      "Epoch 33/5000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 2839858362950.0146 - val_loss: 3057379365888.2881\n",
      "Epoch 34/5000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 2798234633888.4858 - val_loss: 2979835756290.5205\n",
      "Epoch 35/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2750879189857.5308 - val_loss: 2933111614191.7974\n",
      "Epoch 36/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2705643012022.2397 - val_loss: 2897289965506.9346\n",
      "Epoch 37/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 2666385688123.0659 - val_loss: 2845763682502.1748\n",
      "Epoch 38/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2618001979227.1919 - val_loss: 2805756592386.0884\n",
      "Epoch 39/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2580406261562.9219 - val_loss: 2755921873253.7520\n",
      "Epoch 40/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2543751174546.2236 - val_loss: 2729466087519.0547\n",
      "Epoch 41/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2508193242781.0288 - val_loss: 2709295812904.1104\n",
      "Epoch 42/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2486293222009.8774 - val_loss: 2667822289030.8052\n",
      "Epoch 43/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2434772438226.3320 - val_loss: 2598848717553.5259\n",
      "Epoch 44/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2406703091350.1138 - val_loss: 2614232633105.4985\n",
      "Epoch 45/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2376031027485.8213 - val_loss: 2546977895924.3340\n",
      "Epoch 46/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2346215060905.8506 - val_loss: 2503650040424.9922\n",
      "Epoch 47/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2312645769419.9932 - val_loss: 2465287876662.1523\n",
      "Epoch 48/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2294500704246.7803 - val_loss: 2436705689740.5659\n",
      "Epoch 49/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2265582003877.0962 - val_loss: 2428816916166.6069\n",
      "Epoch 50/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2235015578070.2217 - val_loss: 2381859055031.2686\n",
      "Epoch 51/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2218045782192.3330 - val_loss: 2358573743837.6504\n",
      "Epoch 52/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2192982888067.6736 - val_loss: 2345788457960.0923\n",
      "Epoch 53/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2174314389407.1895 - val_loss: 2309932123015.3091\n",
      "Epoch 54/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2156361685009.2876 - val_loss: 2308170906781.5605\n",
      "Epoch 55/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2142257153742.5864 - val_loss: 2268059069490.4077\n",
      "Epoch 56/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 2120731457149.9111 - val_loss: 2313017490054.9492\n",
      "Epoch 57/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2127744657171.7366 - val_loss: 2235016116935.4712\n",
      "Epoch 58/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 2089555821484.4434 - val_loss: 2236217060245.7114\n",
      "Epoch 59/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2073115963680.1260 - val_loss: 2243739645197.8979\n",
      "Epoch 60/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2061860546830.8386 - val_loss: 2179425803995.3462\n",
      "Epoch 61/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2045766567824.2070 - val_loss: 2166155895970.7454\n",
      "Epoch 62/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2041636366514.6382 - val_loss: 2154283683970.1963\n",
      "Epoch 63/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 75us/step - loss: 2023151792746.8948 - val_loss: 2134933314268.2104\n",
      "Epoch 64/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2008929146618.3816 - val_loss: 2135470039507.7852\n",
      "Epoch 65/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2008029347978.3005 - val_loss: 2107255753181.5786\n",
      "Epoch 66/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1991960485966.3704 - val_loss: 2149035725086.8928\n",
      "Epoch 67/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1971613082259.2322 - val_loss: 2084816513923.2766\n",
      "Epoch 68/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1967724551016.4458 - val_loss: 2087863210151.0662\n",
      "Epoch 69/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1947211308516.6279 - val_loss: 2057386411979.5759\n",
      "Epoch 70/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1940846596840.5178 - val_loss: 2051325193920.8462\n",
      "Epoch 71/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1934094640832.7563 - val_loss: 2070590599729.1116\n",
      "Epoch 72/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1920513221193.4722 - val_loss: 2030645722652.0845\n",
      "Epoch 73/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1904579136196.7903 - val_loss: 2015374020696.7178\n",
      "Epoch 74/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1898988084782.3884 - val_loss: 1999101819914.0815\n",
      "Epoch 75/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1893500520207.1265 - val_loss: 1983404972413.9478\n",
      "Epoch 76/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1881924082656.3062 - val_loss: 2025601751140.8157\n",
      "Epoch 77/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1883323352745.7061 - val_loss: 1975622131562.2166\n",
      "Epoch 78/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1858760365089.9988 - val_loss: 1950994752739.2676\n",
      "Epoch 79/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1853618516707.9077 - val_loss: 1931855179959.1965\n",
      "Epoch 80/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1827181557595.1919 - val_loss: 1924375638461.8936\n",
      "Epoch 81/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1818639503671.1760 - val_loss: 1907803714249.1995\n",
      "Epoch 82/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1807356617169.6116 - val_loss: 1893588690755.6187\n",
      "Epoch 83/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1793511681552.4233 - val_loss: 1894837176590.1863\n",
      "Epoch 84/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1791366334149.3665 - val_loss: 1914660132674.4663\n",
      "Epoch 85/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1798054131482.6516 - val_loss: 1880482039377.6606\n",
      "Epoch 86/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1762417812502.4739 - val_loss: 1862498939666.9390\n",
      "Epoch 87/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1751801952515.3135 - val_loss: 1830970877542.3999\n",
      "Epoch 88/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1732095223322.7959 - val_loss: 1819106421354.1445\n",
      "Epoch 89/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1721848459137.2244 - val_loss: 1807070106361.5911\n",
      "Epoch 90/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1710447797897.4363 - val_loss: 1797135630179.3035\n",
      "Epoch 91/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1706319205031.9775 - val_loss: 1781421326322.1738\n",
      "Epoch 92/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1686180739783.0950 - val_loss: 1766459878206.1458\n",
      "Epoch 93/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1669998547734.6179 - val_loss: 1773480298784.6211\n",
      "Epoch 94/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1673957177787.7141 - val_loss: 1744354777055.1628\n",
      "Epoch 95/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1651963003617.6025 - val_loss: 1726804358515.2900\n",
      "Epoch 96/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1636367436033.0085 - val_loss: 1717208274694.5530\n",
      "Epoch 97/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1627095710333.3350 - val_loss: 1713169868653.0972\n",
      "Epoch 98/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1615280555929.4272 - val_loss: 1701384858024.5784\n",
      "Epoch 99/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1609137533843.0884 - val_loss: 1687105744857.9780\n",
      "Epoch 100/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1586119992904.8960 - val_loss: 1665321703962.6440\n",
      "Epoch 101/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1582076701403.8403 - val_loss: 1650713934337.2961\n",
      "Epoch 102/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1566140686543.4507 - val_loss: 1651170795287.2595\n",
      "Epoch 103/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1550888037683.1423 - val_loss: 1646007458625.6023\n",
      "Epoch 104/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1540321006294.0776 - val_loss: 1613650455952.6707\n",
      "Epoch 105/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1524052575544.9050 - val_loss: 1599212702749.6687\n",
      "Epoch 106/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1514991144505.9133 - val_loss: 1607351248675.3574\n",
      "Epoch 107/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1498935107118.3884 - val_loss: 1572035035707.4812\n",
      "Epoch 108/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1482376411358.4333 - val_loss: 1569934991938.3943\n",
      "Epoch 109/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1487245217642.1743 - val_loss: 1551090996546.8984\n",
      "Epoch 110/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1467987752813.6318 - val_loss: 1536604564972.8450\n",
      "Epoch 111/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1446882585731.9617 - val_loss: 1532696158500.6538\n",
      "Epoch 112/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1438382047812.8623 - val_loss: 1530114203913.0015\n",
      "Epoch 113/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1424927819830.1677 - val_loss: 1498205268014.6633\n",
      "Epoch 114/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1419653695698.9082 - val_loss: 1484050566067.6680\n",
      "Epoch 115/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1408280426746.0933 - val_loss: 1468319942511.4014\n",
      "Epoch 116/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1387811312212.9971 - val_loss: 1462154039882.4597\n",
      "Epoch 117/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1370864951293.6948 - val_loss: 1449368110553.8340\n",
      "Epoch 118/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1365608996656.5493 - val_loss: 1433728926622.3528\n",
      "Epoch 119/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1348047088366.2803 - val_loss: 1415077135506.6150\n",
      "Epoch 120/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1339191869688.9409 - val_loss: 1413192607140.8337\n",
      "Epoch 121/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1330713945562.2556 - val_loss: 1400073981791.8469\n",
      "Epoch 122/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1314164424934.5007 - val_loss: 1388872229580.6560\n",
      "Epoch 123/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 1305070276863.8560 - val_loss: 1395680894402.2144\n",
      "Epoch 124/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1297112698140.0923 - val_loss: 1357872676195.7356\n",
      "Epoch 125/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1283653219495.6892 - val_loss: 1348544092187.0762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1270277268677.6543 - val_loss: 1345034002756.9148\n",
      "Epoch 127/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1266120814484.8171 - val_loss: 1338652123262.7397\n",
      "Epoch 128/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1253013027089.1436 - val_loss: 1326952831952.4727\n",
      "Epoch 129/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1243915004894.0012 - val_loss: 1308091583909.4099\n",
      "Epoch 130/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1236428387873.7107 - val_loss: 1300961983267.6455\n",
      "Epoch 131/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1219574534676.4570 - val_loss: 1291603675078.9670\n",
      "Epoch 132/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1213667989638.8430 - val_loss: 1298435533044.8381\n",
      "Epoch 133/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1210151899152.1350 - val_loss: 1274285897061.4639\n",
      "Epoch 134/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1200268521317.5645 - val_loss: 1263194874918.3101\n",
      "Epoch 135/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1189870392243.3584 - val_loss: 1254979486364.2644\n",
      "Epoch 136/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1180755861527.0500 - val_loss: 1254733407256.4839\n",
      "Epoch 137/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1170770436497.0715 - val_loss: 1249934412336.5356\n",
      "Epoch 138/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1163285621347.9797 - val_loss: 1240819280868.0596\n",
      "Epoch 139/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1158210535488.5403 - val_loss: 1222414877146.6982\n",
      "Epoch 140/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1147316111801.4092 - val_loss: 1230450760992.9092\n",
      "Epoch 141/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1140030518790.0505 - val_loss: 1219947256756.8203\n",
      "Epoch 142/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1137200998597.0781 - val_loss: 1207460372454.6521\n",
      "Epoch 143/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1129911782149.3303 - val_loss: 1196343109365.2703\n",
      "Epoch 144/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1119443280460.3533 - val_loss: 1202997420444.4805\n",
      "Epoch 145/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1115234561792.1440 - val_loss: 1188478767280.2834\n",
      "Epoch 146/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1115897189096.5178 - val_loss: 1185692794313.1274\n",
      "Epoch 147/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1103378159252.9612 - val_loss: 1180093383467.1348\n",
      "Epoch 148/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1101351180662.5637 - val_loss: 1163237343420.9575\n",
      "Epoch 149/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1092166701062.9150 - val_loss: 1158128303971.3035\n",
      "Epoch 150/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1085125078018.8813 - val_loss: 1154514385570.6013\n",
      "Epoch 151/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1084783722422.2397 - val_loss: 1146720177734.7151\n",
      "Epoch 152/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1073430630453.0151 - val_loss: 1141801382158.7622\n",
      "Epoch 153/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1074103164351.7479 - val_loss: 1135785501665.1792\n",
      "Epoch 154/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1063934303845.7085 - val_loss: 1132075570167.0706\n",
      "Epoch 155/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1060171993795.6377 - val_loss: 1127392590521.6450\n",
      "Epoch 156/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1054292548465.6658 - val_loss: 1141825505895.8403\n",
      "Epoch 157/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1054118546107.5701 - val_loss: 1116810417903.5095\n",
      "Epoch 158/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1047912736918.9780 - val_loss: 1124822033741.2681\n",
      "Epoch 159/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1044018370256.8915 - val_loss: 1111121306358.1345\n",
      "Epoch 160/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1036518206983.2031 - val_loss: 1123623600413.7407\n",
      "Epoch 161/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1038100254579.3945 - val_loss: 1108564184660.5413\n",
      "Epoch 162/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1035676861273.4631 - val_loss: 1095851468501.0093\n",
      "Epoch 163/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1027345346396.3444 - val_loss: 1094801221637.1848\n",
      "Epoch 164/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1026090827351.8785 - val_loss: 1092344034725.9860\n",
      "Epoch 165/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1022294100833.5306 - val_loss: 1116532524763.9224\n",
      "Epoch 166/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1019410372779.7231 - val_loss: 1091434902005.1984\n",
      "Epoch 167/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1014175637702.2307 - val_loss: 1115373823175.6152\n",
      "Epoch 168/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1014283503126.1858 - val_loss: 1075187170576.7786\n",
      "Epoch 169/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1003333315291.8401 - val_loss: 1071224744890.5812\n",
      "Epoch 170/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1004868695991.3923 - val_loss: 1069984580376.6998\n",
      "Epoch 171/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 997359639271.3651 - val_loss: 1065041911593.6945\n",
      "Epoch 172/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 992703644256.5222 - val_loss: 1082042545071.6355\n",
      "Epoch 173/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1000831022542.7305 - val_loss: 1075577240332.6019\n",
      "Epoch 174/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 984926386287.7928 - val_loss: 1056520245087.8469\n",
      "Epoch 175/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 988114770460.5244 - val_loss: 1049743014023.3811\n",
      "Epoch 176/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 981216594601.1300 - val_loss: 1076378089662.6858\n",
      "Epoch 177/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 984275268259.3674 - val_loss: 1047346133763.3845\n",
      "Epoch 178/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 979379696604.8485 - val_loss: 1043808934219.2517\n",
      "Epoch 179/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 973362425378.8632 - val_loss: 1044166502690.9254\n",
      "Epoch 180/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 970278687280.1169 - val_loss: 1035012248719.1583\n",
      "Epoch 181/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 968666349402.0394 - val_loss: 1040389341543.4802\n",
      "Epoch 182/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 963744176290.5031 - val_loss: 1032750636790.9985\n",
      "Epoch 183/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 958272623742.1992 - val_loss: 1024426659380.2802\n",
      "Epoch 184/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 964719843177.0220 - val_loss: 1022104643980.9260\n",
      "Epoch 185/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 955077748721.0175 - val_loss: 1018283239599.7074\n",
      "Epoch 186/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 953047931697.1256 - val_loss: 1015633677595.1482\n",
      "Epoch 187/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 950847248970.6246 - val_loss: 1013773281667.7086\n",
      "Epoch 188/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 76us/step - loss: 947328463062.3657 - val_loss: 1012639653139.0830\n",
      "Epoch 189/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 946730655988.3308 - val_loss: 1010292606047.9189\n",
      "Epoch 190/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 941421339965.5149 - val_loss: 1030253644290.4484\n",
      "Epoch 191/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 944168570140.0923 - val_loss: 1010914230659.1324\n",
      "Epoch 192/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 940940070577.7738 - val_loss: 1000045153378.7994\n",
      "Epoch 193/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 935686877269.2853 - val_loss: 997940696114.9840\n",
      "Epoch 194/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 933205610456.8148 - val_loss: 995884282583.0256\n",
      "Epoch 195/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 929494862947.6917 - val_loss: 1000548437265.9308\n",
      "Epoch 196/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 929382230185.4182 - val_loss: 1006813495402.0006\n",
      "Epoch 197/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 930537419667.0883 - val_loss: 1002694893759.2618\n",
      "Epoch 198/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 932175852379.7682 - val_loss: 988990954761.8656\n",
      "Epoch 199/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 922817024099.1154 - val_loss: 996086258340.9058\n",
      "Epoch 200/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 923871618282.5345 - val_loss: 981286443016.6414\n",
      "Epoch 201/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 919676649001.7783 - val_loss: 983339320922.8782\n",
      "Epoch 202/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 915200369585.0535 - val_loss: 978539028150.4766\n",
      "Epoch 203/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 910854541447.9955 - val_loss: 975530844637.0026\n",
      "Epoch 204/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 911787768998.5369 - val_loss: 974089547687.2821\n",
      "Epoch 205/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 909066444020.9072 - val_loss: 969403374272.5581\n",
      "Epoch 206/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 908432276157.8751 - val_loss: 973497307464.3713\n",
      "Epoch 207/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 907426021293.0197 - val_loss: 966636955035.6163\n",
      "Epoch 208/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 904696672470.3657 - val_loss: 964600781011.4250\n",
      "Epoch 209/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 899934186213.0602 - val_loss: 964885183101.7317\n",
      "Epoch 210/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 903591992251.4260 - val_loss: 958868203373.0970\n",
      "Epoch 211/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 903054921781.0151 - val_loss: 960697767036.7235\n",
      "Epoch 212/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 897921083081.9763 - val_loss: 967193891614.4608\n",
      "Epoch 213/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 897300866181.1141 - val_loss: 955712175547.3013\n",
      "Epoch 214/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 891762697192.3735 - val_loss: 953272465363.6411\n",
      "Epoch 215/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 889878351464.0135 - val_loss: 952022186847.5590\n",
      "Epoch 216/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 891130055539.9707 - val_loss: 950387728261.8689\n",
      "Epoch 217/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 888282275641.7693 - val_loss: 947690994034.4259\n",
      "Epoch 218/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 887214223297.7648 - val_loss: 943410049930.7656\n",
      "Epoch 219/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 884182785324.2274 - val_loss: 944574137933.0520\n",
      "Epoch 220/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 884489365203.1964 - val_loss: 940812420367.0503\n",
      "Epoch 221/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 878237201372.8485 - val_loss: 952835265692.9845\n",
      "Epoch 222/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 884923479871.5317 - val_loss: 938216557196.7100\n",
      "Epoch 223/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 888277985578.4985 - val_loss: 957574608234.0726\n",
      "Epoch 224/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 883743161464.4368 - val_loss: 939667443786.8917\n",
      "Epoch 225/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 870955724922.1655 - val_loss: 960317898092.9530\n",
      "Epoch 226/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 875743823585.0265 - val_loss: 930473486594.6644\n",
      "Epoch 227/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 871650031967.5138 - val_loss: 934283091269.7789\n",
      "Epoch 228/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 871010012739.1334 - val_loss: 934525500232.5154\n",
      "Epoch 229/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 864618622747.8041 - val_loss: 937653900993.4222\n",
      "Epoch 230/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 870283101552.2251 - val_loss: 923648974412.4760\n",
      "Epoch 231/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 864762073085.6951 - val_loss: 923275265336.5288\n",
      "Epoch 232/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 863079677555.5386 - val_loss: 924584914878.3257\n",
      "Epoch 233/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 864840839760.3872 - val_loss: 926475586704.8866\n",
      "Epoch 234/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 865414159125.4655 - val_loss: 922184492263.8762\n",
      "Epoch 235/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 871140799987.6105 - val_loss: 928145373618.9480\n",
      "Epoch 236/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 858755779268.7900 - val_loss: 929711442687.9280\n",
      "Epoch 237/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 860117379250.6382 - val_loss: 972689880587.3778\n",
      "Epoch 238/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 864147497351.8513 - val_loss: 913003356365.0880\n",
      "Epoch 239/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 858184947800.7428 - val_loss: 913756979347.4790\n",
      "Epoch 240/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 856336215374.8025 - val_loss: 914601051282.6149\n",
      "Epoch 241/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 859392709933.3799 - val_loss: 918881583090.1738\n",
      "Epoch 242/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 854688115198.5593 - val_loss: 917237271779.8436\n",
      "Epoch 243/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 854506163991.1942 - val_loss: 917667215260.3364\n",
      "Epoch 244/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 858610622929.6117 - val_loss: 909271233934.9424\n",
      "Epoch 245/5000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 854119342895.9730 - val_loss: 910974482516.6852\n",
      "Epoch 246/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 849049630324.6910 - val_loss: 907421373283.5916\n",
      "Epoch 247/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 852465277247.2437 - val_loss: 905436639323.0222\n",
      "Epoch 248/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 852228809243.3719 - val_loss: 900778933456.2566\n",
      "Epoch 249/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 855070577485.9381 - val_loss: 909919321577.3884\n",
      "Epoch 250/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 844828436538.7777 - val_loss: 922069582879.3969\n",
      "Epoch 251/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 77us/step - loss: 841850267291.8762 - val_loss: 915672028280.1147\n",
      "Epoch 252/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 845667873480.2476 - val_loss: 897974837453.0880\n",
      "Epoch 253/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 847367766422.2577 - val_loss: 896489425004.8810\n",
      "Epoch 254/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 839847161793.7648 - val_loss: 895083171601.4988\n",
      "Epoch 255/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 842337487824.1711 - val_loss: 894130958445.4572\n",
      "Epoch 256/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 837904676948.1329 - val_loss: 899806945683.2631\n",
      "Epoch 257/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 840314816676.8081 - val_loss: 891935214013.3176\n",
      "Epoch 258/5000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 835496731237.1323 - val_loss: 890716412520.9924\n",
      "Epoch 259/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 836305824641.8008 - val_loss: 890595922529.5033\n",
      "Epoch 260/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 840053720810.2465 - val_loss: 906246313209.1589\n",
      "Epoch 261/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 834993592630.0237 - val_loss: 896039687034.6351\n",
      "Epoch 262/5000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 835624942260.6550 - val_loss: 895040779524.6808\n",
      "Epoch 263/5000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 835355599235.2415 - val_loss: 906127660179.7671\n",
      "Epoch 264/5000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 838886727444.8892 - val_loss: 888118025265.2557\n",
      "Epoch 265/5000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 829793776678.6089 - val_loss: 896843764717.8531\n",
      "Epoch 266/5000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 837185105959.1852 - val_loss: 891902528159.1449\n",
      "Epoch 267/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 831823621897.3640 - val_loss: 884153481872.1665\n",
      "Epoch 268/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 830402463918.0281 - val_loss: 883606186625.1882\n",
      "Epoch 269/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 829045505248.1621 - val_loss: 884023308167.0211\n",
      "Epoch 270/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 829920236006.3567 - val_loss: 881309885284.7438\n",
      "Epoch 271/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 828532808077.6139 - val_loss: 881254592386.4124\n",
      "Epoch 272/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 830773300083.9707 - val_loss: 883521946558.6138\n",
      "Epoch 273/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 829855034945.1165 - val_loss: 886341387018.8737\n",
      "Epoch 274/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 828593291642.0214 - val_loss: 890654462787.3306\n",
      "Epoch 275/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 824378094363.2279 - val_loss: 876245047203.2495\n",
      "Epoch 276/5000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 823433325663.0815 - val_loss: 875287282014.2627\n",
      "Epoch 277/5000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 824948683455.0276 - val_loss: 879581643484.7865\n",
      "Epoch 278/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 824241752265.6882 - val_loss: 877391202048.7921\n",
      "Epoch 279/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 824690657785.9493 - val_loss: 878909202185.4335\n",
      "Epoch 280/5000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 819665271153.9539 - val_loss: 882716146412.3409\n",
      "Epoch 281/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 824280129402.3094 - val_loss: 873914126982.3730\n",
      "Epoch 282/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 818917228110.6584 - val_loss: 872912083680.8191\n",
      "Epoch 283/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 819518569297.3956 - val_loss: 870513139377.8678\n",
      "Epoch 284/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 815588099163.6240 - val_loss: 874674911270.5980\n",
      "Epoch 285/5000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 825363899943.38 - 0s 114us/step - loss: 825723408077.4340 - val_loss: 870883716920.6729\n",
      "Epoch 286/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 825180760841.9404 - val_loss: 869769046251.6208\n",
      "Epoch 287/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 819886608575.3157 - val_loss: 869679988450.2594\n",
      "Epoch 288/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 816291714201.8593 - val_loss: 870525388305.1387\n",
      "Epoch 289/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 820101628908.9836 - val_loss: 868244061359.9955\n",
      "Epoch 290/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 813785122409.1660 - val_loss: 877293254468.7708\n",
      "Epoch 291/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 816253840220.9207 - val_loss: 865310503569.8948\n",
      "Epoch 292/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 813748245003.2369 - val_loss: 874949066351.0414\n",
      "Epoch 293/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 812185522800.6573 - val_loss: 868343069019.3823\n",
      "Epoch 294/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 810079473043.9528 - val_loss: 864246156741.6709\n",
      "Epoch 295/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 818709017693.9291 - val_loss: 863799342626.4214\n",
      "Epoch 296/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 810831608841.7963 - val_loss: 870223202721.6653\n",
      "Epoch 297/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 818606745631.1176 - val_loss: 864330293923.1775\n",
      "Epoch 298/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 809545627741.3528 - val_loss: 904500936252.3455\n",
      "Epoch 299/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 814232054731.5610 - val_loss: 867091126220.7280\n",
      "Epoch 300/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 812153200773.6906 - val_loss: 867316343357.7856\n",
      "Epoch 301/5000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 814565916321.6388 - val_loss: 873523445861.3918\n",
      "Epoch 302/5000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 808397725682.1700 - val_loss: 864710460581.0498\n",
      "Epoch 303/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 807115104952.1124 - val_loss: 860713314207.7930\n",
      "Epoch 304/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 808999937793.2965 - val_loss: 860012916117.2793\n",
      "Epoch 305/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 807414990459.6060 - val_loss: 871857477981.6866\n",
      "Epoch 306/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 809112096111.0725 - val_loss: 857937853611.3867\n",
      "Epoch 307/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 811463815234.8452 - val_loss: 857975939189.5223\n",
      "Epoch 308/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 806399039659.7231 - val_loss: 860531681487.9685\n",
      "Epoch 309/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 805955203756.5874 - val_loss: 859939021788.5704\n",
      "Epoch 310/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 805085908584.0135 - val_loss: 862461211231.1989\n",
      "Epoch 311/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 807091869803.1830 - val_loss: 856376932307.6411\n",
      "Epoch 312/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 804214905861.1863 - val_loss: 875212123697.9758\n",
      "Epoch 313/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 803667052118.7260 - val_loss: 858919896422.6161\n",
      "Epoch 314/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 84us/step - loss: 805017028735.9280 - val_loss: 854446316445.7766\n",
      "Epoch 315/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 804693471054.5143 - val_loss: 853554820024.8529\n",
      "Epoch 316/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 801681374457.5172 - val_loss: 853443644422.6250\n",
      "Epoch 317/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 804387382672.4952 - val_loss: 854820237366.1525\n",
      "Epoch 318/5000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 802161245364.3668 - val_loss: 851492469668.6897\n",
      "Epoch 319/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 799319349604.1238 - val_loss: 853239044201.4244\n",
      "Epoch 320/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 801113525559.7524 - val_loss: 853592596367.0863\n",
      "Epoch 321/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 805853623694.1902 - val_loss: 863910375496.5874\n",
      "Epoch 322/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 804198151805.9111 - val_loss: 854743881308.0304\n",
      "Epoch 323/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 806106740230.0507 - val_loss: 849580935382.8816\n",
      "Epoch 324/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 800149811635.6466 - val_loss: 856697944724.7753\n",
      "Epoch 325/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 797388056809.9584 - val_loss: 849475160057.6630\n",
      "Epoch 326/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 804173620725.9156 - val_loss: 850884213332.2532\n",
      "Epoch 327/5000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 796806663166.2712 - val_loss: 848898387040.4951\n",
      "Epoch 328/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 795066833556.3850 - val_loss: 850003492154.2571\n",
      "Epoch 329/5000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 801398197135.6309 - val_loss: 848921180479.7300\n",
      "Epoch 330/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 798385952570.9219 - val_loss: 847221412596.9823\n",
      "Epoch 331/5000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 796558903894.1498 - val_loss: 853038070148.8607\n",
      "Epoch 332/5000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 802738756032.3241 - val_loss: 847097367733.7563\n",
      "Epoch 333/5000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 800690182988.7855 - val_loss: 850951920518.7330\n",
      "Epoch 334/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 796266124543.2797 - val_loss: 849892888623.2394\n",
      "Epoch 335/5000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 798725754628.7540 - val_loss: 850228043192.9969\n",
      "Epoch 336/5000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 796868699425.8547 - val_loss: 845174166260.9823\n",
      "Epoch 337/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 797219322299.7141 - val_loss: 856094695873.3502\n",
      "Epoch 338/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 801462872012.1373 - val_loss: 845682577625.7621\n",
      "Epoch 339/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 795316865511.5093 - val_loss: 845491139088.8506\n",
      "Epoch 340/5000\n",
      "3554/3554 [==============================] - 0s 130us/step - loss: 792058499493.8165 - val_loss: 871995340681.9015\n",
      "Epoch 341/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 803201178293.8075 - val_loss: 844619953186.8534\n",
      "Epoch 342/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 793946769711.1085 - val_loss: 850815390595.8527\n",
      "Epoch 343/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 802427021121.8368 - val_loss: 844001695264.1171\n",
      "Epoch 344/5000\n",
      "3554/3554 [==============================] - 1s 152us/step - loss: 794192052777.2020 - val_loss: 848551258453.6213\n",
      "Epoch 345/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 796780951516.2723 - val_loss: 842311567828.3612\n",
      "Epoch 346/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 794986561130.3185 - val_loss: 844990487416.9069\n",
      "Epoch 347/5000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 792107654960.5492 - val_loss: 866850580111.8785\n",
      "Epoch 348/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 795439685175.6083 - val_loss: 845167652996.5007\n",
      "Epoch 349/5000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 794344796355.9258 - val_loss: 839908485115.9674\n",
      "Epoch 350/5000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 795550870595.4215 - val_loss: 875523723126.8906\n",
      "Epoch 351/5000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 795450190518.9601 - val_loss: 841128078358.7556\n",
      "Epoch 352/5000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 793054069814.7439 - val_loss: 839795823690.0276\n",
      "Epoch 353/5000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 790787745463.5363 - val_loss: 839028840433.5978\n",
      "Epoch 354/5000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 795282569235.5925 - val_loss: 843472550687.0369\n",
      "Epoch 355/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 787806217923.0613 - val_loss: 841561742790.8231\n",
      "Epoch 356/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 787381854858.0123 - val_loss: 839250393813.2974\n",
      "Epoch 357/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 793237099286.6178 - val_loss: 843445556279.5927\n",
      "Epoch 358/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 788907896677.5645 - val_loss: 837330266458.2301\n",
      "Epoch 359/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 788559082958.7305 - val_loss: 837267414134.3865\n",
      "Epoch 360/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 793157466961.3956 - val_loss: 850619010662.9761\n",
      "Epoch 361/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 790234518506.6787 - val_loss: 840909690137.4199\n",
      "Epoch 362/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 788963969419.3090 - val_loss: 842211821584.7067\n",
      "Epoch 363/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 787590935931.7501 - val_loss: 855830764906.6487\n",
      "Epoch 364/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 789210692617.7963 - val_loss: 844466243338.0095\n",
      "Epoch 365/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 788649688820.6189 - val_loss: 842905176850.3629\n",
      "Epoch 366/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 791204543654.5369 - val_loss: 844797056696.2048\n",
      "Epoch 367/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 791148256454.8070 - val_loss: 858438897983.1538\n",
      "Epoch 368/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 789171624458.0844 - val_loss: 835900226777.4740\n",
      "Epoch 369/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 785869355479.3741 - val_loss: 843081746826.6217\n",
      "Epoch 370/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 790249689168.6753 - val_loss: 838653306313.7035\n",
      "Epoch 371/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 785629274282.5706 - val_loss: 833345102425.4380\n",
      "Epoch 372/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 786032844749.2898 - val_loss: 853639104095.4869\n",
      "Epoch 373/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 788564995471.3427 - val_loss: 832623745405.9476\n",
      "Epoch 374/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 782359200407.8424 - val_loss: 838860573214.1007\n",
      "Epoch 375/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 782841707234.7552 - val_loss: 832240638366.2087\n",
      "Epoch 376/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 784812592052.5110 - val_loss: 837660724576.2791\n",
      "Epoch 377/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 86us/step - loss: 784045589282.1429 - val_loss: 831922427460.9868\n",
      "Epoch 378/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 783143430958.8204 - val_loss: 838638388061.8307\n",
      "Epoch 379/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 782918984136.3917 - val_loss: 839827680158.9288\n",
      "Epoch 380/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 784278071479.2482 - val_loss: 831454726110.0107\n",
      "Epoch 381/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 782074212803.2054 - val_loss: 831334053050.9412\n",
      "Epoch 382/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 788287788480.9004 - val_loss: 847640846425.8700\n",
      "Epoch 383/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 787487308026.0934 - val_loss: 830759020092.9215\n",
      "Epoch 384/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 787078034270.0731 - val_loss: 829998504622.1232\n",
      "Epoch 385/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 786384228967.4373 - val_loss: 830497793412.5728\n",
      "Epoch 386/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 780915286767.4327 - val_loss: 831957246581.0903\n",
      "Epoch 387/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 788387973630.5593 - val_loss: 831440738533.8599\n",
      "Epoch 388/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 784824243851.7411 - val_loss: 833581654672.7427\n",
      "Epoch 389/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 782012153690.0394 - val_loss: 832994514542.4652\n",
      "Epoch 390/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 782304674050.1610 - val_loss: 827946385624.6099\n",
      "Epoch 391/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 783866222966.5638 - val_loss: 833339629081.7800\n",
      "Epoch 392/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 787236093011.5565 - val_loss: 834428014938.8062\n",
      "Epoch 393/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 779868345147.4980 - val_loss: 832033697855.3699\n",
      "Epoch 394/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 780123293538.1068 - val_loss: 837634006470.8231\n",
      "Epoch 395/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 781232969632.3420 - val_loss: 837885160249.5370\n",
      "Epoch 396/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 782281766765.6321 - val_loss: 830533255698.0028\n",
      "Epoch 397/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 778856881627.4081 - val_loss: 826741167099.6793\n",
      "Epoch 398/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 780300872006.1587 - val_loss: 825523799518.4427\n",
      "Epoch 399/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 779033898862.7844 - val_loss: 827834380673.9803\n",
      "Epoch 400/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 779776180214.7799 - val_loss: 833649934363.6523\n",
      "Epoch 401/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 779029546822.4469 - val_loss: 829956123882.7567\n",
      "Epoch 402/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 779068087043.0253 - val_loss: 825304531695.2214\n",
      "Epoch 403/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 778701577755.9482 - val_loss: 825156295005.6866\n",
      "Epoch 404/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 778516913498.3275 - val_loss: 825261503568.9407\n",
      "Epoch 405/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 782622577310.7574 - val_loss: 840006612887.7277\n",
      "Epoch 406/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 789781299780.8621 - val_loss: 826102667844.1227\n",
      "Epoch 407/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 778118890264.9230 - val_loss: 824761259464.5514\n",
      "Epoch 408/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 775797404609.1886 - val_loss: 824005494902.0985\n",
      "Epoch 409/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 777765623274.3906 - val_loss: 823513574275.2765\n",
      "Epoch 410/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 776219680754.1700 - val_loss: 833064665300.0011\n",
      "Epoch 411/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 775567676403.8988 - val_loss: 824549917662.8749\n",
      "Epoch 412/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 777489221059.2054 - val_loss: 825805985468.8135\n",
      "Epoch 413/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 776057547935.6218 - val_loss: 822230405664.9812\n",
      "Epoch 414/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 777767270834.4941 - val_loss: 831847190824.1102\n",
      "Epoch 415/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 774384657983.6759 - val_loss: 823901305658.6892\n",
      "Epoch 416/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 776271683140.8621 - val_loss: 821716303664.6075\n",
      "Epoch 417/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 777486653372.0022 - val_loss: 822734734017.1342\n",
      "Epoch 418/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 776541426519.1582 - val_loss: 823103774643.9562\n",
      "Epoch 419/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 773585819847.3833 - val_loss: 837037209680.0765\n",
      "Epoch 420/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 775939529880.7068 - val_loss: 841091463589.1218\n",
      "Epoch 421/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 775538038642.2419 - val_loss: 820584821204.9373\n",
      "Epoch 422/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 782563227584.6122 - val_loss: 835984264548.8878\n",
      "Epoch 423/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 774715420775.7253 - val_loss: 822104974286.7443\n",
      "Epoch 424/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 771387268469.9877 - val_loss: 852233184861.1826\n",
      "Epoch 425/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 776290332840.2656 - val_loss: 820673005856.6211\n",
      "Epoch 426/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 776375739893.9156 - val_loss: 822365132121.9420\n",
      "Epoch 427/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 775067886052.0518 - val_loss: 824827779205.0768\n",
      "Epoch 428/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 773318287816.3917 - val_loss: 823179853183.3879\n",
      "Epoch 429/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 774883714420.8351 - val_loss: 819502653405.4346\n",
      "Epoch 430/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 772536995763.9348 - val_loss: 822539762057.4695\n",
      "Epoch 431/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 773251846298.4355 - val_loss: 838461548466.2279\n",
      "Epoch 432/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 775503458573.6860 - val_loss: 822067003530.2616\n",
      "Epoch 433/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 772091015871.0276 - val_loss: 823897010515.8931\n",
      "Epoch 434/5000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 774006617218.8092 - val_loss: 822999103752.4253\n",
      "Epoch 435/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 775486898176.0000 - val_loss: 831407315496.4703\n",
      "Epoch 436/5000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 771863779361.4226 - val_loss: 820472482131.3170\n",
      "Epoch 437/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 772932454057.7063 - val_loss: 816779112465.2827\n",
      "Epoch 438/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 772466070986.1204 - val_loss: 819866574389.4324\n",
      "Epoch 439/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 773301804276.9072 - val_loss: 817609381523.3350\n",
      "Epoch 440/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 79us/step - loss: 770009121404.1824 - val_loss: 819650288020.9913\n",
      "Epoch 441/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 769539968284.0923 - val_loss: 818742969015.9167\n",
      "Epoch 442/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 773077826615.8965 - val_loss: 836942684618.5676\n",
      "Epoch 443/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 770811467920.0630 - val_loss: 817720087432.4613\n",
      "Epoch 444/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 774089173880.5807 - val_loss: 824571436634.3021\n",
      "Epoch 445/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 770108145009.3777 - val_loss: 824771561963.4048\n",
      "Epoch 446/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 768406641051.4441 - val_loss: 820959996296.3173\n",
      "Epoch 447/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 770472995225.1390 - val_loss: 820017737643.8909\n",
      "Epoch 448/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 767391998164.0608 - val_loss: 815035307718.0309\n",
      "Epoch 449/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 765661528460.4614 - val_loss: 824254211267.0065\n",
      "Epoch 450/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 768744043982.7305 - val_loss: 814797394211.5016\n",
      "Epoch 451/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 769304121701.2762 - val_loss: 814051519778.0613\n",
      "Epoch 452/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 769525580421.4025 - val_loss: 815442607330.6914\n",
      "Epoch 453/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 770662289470.2352 - val_loss: 816512691139.7986\n",
      "Epoch 454/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 773140660712.6619 - val_loss: 821825222302.8568\n",
      "Epoch 455/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 770267925576.0315 - val_loss: 821259806075.3552\n",
      "Epoch 456/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 769835380800.5402 - val_loss: 819760081984.2340\n",
      "Epoch 457/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 773493165736.5537 - val_loss: 814669650730.5586\n",
      "Epoch 458/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 765151720947.6105 - val_loss: 817668578846.3888\n",
      "Epoch 459/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 771761749951.4598 - val_loss: 821919304613.8419\n",
      "Epoch 460/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 768806014724.7540 - val_loss: 813781557517.6101\n",
      "Epoch 461/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 771242055455.2617 - val_loss: 815450234522.8242\n",
      "Epoch 462/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 767106776922.0394 - val_loss: 814156983682.8445\n",
      "Epoch 463/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 768265076192.0179 - val_loss: 812072248939.0087\n",
      "Epoch 464/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 768753252804.9342 - val_loss: 812160099163.5262\n",
      "Epoch 465/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 764631132410.0934 - val_loss: 815353941510.1930\n",
      "Epoch 466/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 768800181356.9117 - val_loss: 811911644481.7462\n",
      "Epoch 467/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 765461064540.9207 - val_loss: 813072530188.6019\n",
      "Epoch 468/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 769166676021.0151 - val_loss: 811074721113.9420\n",
      "Epoch 469/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 767904783973.7085 - val_loss: 812039729994.2437\n",
      "Epoch 470/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 764432265629.7490 - val_loss: 813642446739.1190\n",
      "Epoch 471/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 765109215522.4312 - val_loss: 811926216480.4771\n",
      "Epoch 472/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 766414130810.4536 - val_loss: 818788433615.8245\n",
      "Epoch 473/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 765682626202.7238 - val_loss: 813101510604.1519\n",
      "Epoch 474/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 764454091495.3651 - val_loss: 813784045544.3802\n",
      "Epoch 475/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 775100526133.3033 - val_loss: 827250107001.6990\n",
      "Epoch 476/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 771008569035.1289 - val_loss: 813591240485.0858\n",
      "Epoch 477/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 764931358784.5402 - val_loss: 817368822795.8098\n",
      "Epoch 478/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 763187274184.3917 - val_loss: 810507061776.2745\n",
      "Epoch 479/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 766438939966.6675 - val_loss: 818246283046.2379\n",
      "Epoch 480/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 767749262693.8525 - val_loss: 811854567271.3362\n",
      "Epoch 481/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 762568993545.9404 - val_loss: 815864815111.3451\n",
      "Epoch 482/5000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 766875605744.5852 - val_loss: 821977899549.5247\n",
      "Epoch 483/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 767318726597.2223 - val_loss: 809137786106.8872\n",
      "Epoch 484/5000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 767652766926.8744 - val_loss: 813964950252.3409\n",
      "Epoch 485/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 761474328219.8762 - val_loss: 809398433461.9004\n",
      "Epoch 486/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 761028207961.1750 - val_loss: 808805429297.5437\n",
      "Epoch 487/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 762353742988.0293 - val_loss: 808371076202.8647\n",
      "Epoch 488/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 763180734967.6444 - val_loss: 807967609174.1975\n",
      "Epoch 489/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 770819260637.2808 - val_loss: 809337062537.3975\n",
      "Epoch 490/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 763026310908.6866 - val_loss: 808964443082.7117\n",
      "Epoch 491/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 766881445861.4924 - val_loss: 807342384387.5286\n",
      "Epoch 492/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 761208202345.4541 - val_loss: 808293464065.7283\n",
      "Epoch 493/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 765580421409.2786 - val_loss: 807739134395.5894\n",
      "Epoch 494/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 769932733129.4001 - val_loss: 823449209655.2327\n",
      "Epoch 495/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 760960256791.7704 - val_loss: 809079554393.6541\n",
      "Epoch 496/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 765018338499.3494 - val_loss: 811494509205.9274\n",
      "Epoch 497/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 762511827658.5526 - val_loss: 814305422750.4967\n",
      "Epoch 498/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 765686799540.3668 - val_loss: 813023265182.7848\n",
      "Epoch 499/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 763476915423.0095 - val_loss: 807072595986.4349\n",
      "Epoch 500/5000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 762010404291.2054 - val_loss: 813952331834.7612\n",
      "Epoch 501/5000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 769065194557.6591 - val_loss: 806703720149.0093\n",
      "Epoch 502/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 759930981162.2104 - val_loss: 805935056046.2672\n",
      "Epoch 503/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 83us/step - loss: 762190180234.4446 - val_loss: 815648406833.0397\n",
      "Epoch 504/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 764539012049.3235 - val_loss: 805651870759.4622\n",
      "Epoch 505/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 763105964034.3049 - val_loss: 807477182381.0431\n",
      "Epoch 506/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 765188492360.0315 - val_loss: 812144905872.4546\n",
      "Epoch 507/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 758240611741.1729 - val_loss: 821240105843.1460\n",
      "Epoch 508/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 763371765953.6206 - val_loss: 817634148038.6071\n",
      "Epoch 509/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 759131426905.3191 - val_loss: 805122800650.0815\n",
      "Epoch 510/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 760540144330.5526 - val_loss: 806051990511.5814\n",
      "Epoch 511/5000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 763656006898.6021 - val_loss: 805361650049.4042\n",
      "Epoch 512/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 762822747760.0809 - val_loss: 804125752565.1263\n",
      "Epoch 513/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 759978632288.2341 - val_loss: 806178847542.0804\n",
      "Epoch 514/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 761278321919.2797 - val_loss: 819484803205.6528\n",
      "Epoch 515/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 759132575731.3224 - val_loss: 803731245828.5367\n",
      "Epoch 516/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 763870234871.7883 - val_loss: 817166924787.0380\n",
      "Epoch 517/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 757166920369.1975 - val_loss: 803850455904.7111\n",
      "Epoch 518/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 761193696295.7614 - val_loss: 807442465307.2202\n",
      "Epoch 519/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 755630682953.3280 - val_loss: 806663830699.3867\n",
      "Epoch 520/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 760724288652.0293 - val_loss: 806596117097.5685\n",
      "Epoch 521/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 757460201038.6584 - val_loss: 804845950214.9851\n",
      "Epoch 522/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 759839690417.7738 - val_loss: 808693290279.2461\n",
      "Epoch 523/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 759859941908.4570 - val_loss: 803002861303.5747\n",
      "Epoch 524/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 767439164818.8002 - val_loss: 805691659499.3328\n",
      "Epoch 525/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 760472983354.9219 - val_loss: 811220635699.8481\n",
      "Epoch 526/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 765646869620.9792 - val_loss: 808615404384.1350\n",
      "Epoch 527/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 765329365661.6049 - val_loss: 811013220453.9679\n",
      "Epoch 528/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 758535197204.4570 - val_loss: 805301426180.0326\n",
      "Epoch 529/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 759922235960.1846 - val_loss: 802426094858.4417\n",
      "Epoch 530/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 754568462889.2020 - val_loss: 803276182519.0706\n",
      "Epoch 531/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 761834091042.2870 - val_loss: 805552335862.4945\n",
      "Epoch 532/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 757485739326.6675 - val_loss: 808756545525.0543\n",
      "Epoch 533/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 756336431359.8558 - val_loss: 814593576209.9308\n",
      "Epoch 534/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 757272364363.3450 - val_loss: 807449941047.5927\n",
      "Epoch 535/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 762080302694.8610 - val_loss: 802619029671.6422\n",
      "Epoch 536/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 755078128579.4935 - val_loss: 821945315972.0686\n",
      "Epoch 537/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 758142733024.4502 - val_loss: 806142414429.7587\n",
      "Epoch 538/5000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 754561378805.3392 - val_loss: 801062816700.8855\n",
      "Epoch 539/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 761739402064.0990 - val_loss: 803661944172.3770\n",
      "Epoch 540/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 755891730654.4333 - val_loss: 800815586104.3848\n",
      "Epoch 541/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 756266504752.1169 - val_loss: 801998677399.0076\n",
      "Epoch 542/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 754788663300.6100 - val_loss: 808307896936.4163\n",
      "Epoch 543/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 756384655345.0175 - val_loss: 808486753953.1611\n",
      "Epoch 544/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 756921523343.4868 - val_loss: 801016302474.1896\n",
      "Epoch 545/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 758280381789.7850 - val_loss: 817204008198.9851\n",
      "Epoch 546/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 754608895051.4890 - val_loss: 799747211688.0022\n",
      "Epoch 547/5000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 755590067671.9506 - val_loss: 801815608601.9961\n",
      "Epoch 548/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 760119390118.1046 - val_loss: 807786188962.4574\n",
      "Epoch 549/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 772187219584.2161 - val_loss: 799657835663.7345\n",
      "Epoch 550/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 754599646858.5886 - val_loss: 800747061524.5232\n",
      "Epoch 551/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 756299656406.9420 - val_loss: 805068033514.5406\n",
      "Epoch 552/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 757131305112.1306 - val_loss: 810507386027.3867\n",
      "Epoch 553/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 754235673220.2499 - val_loss: 803551790378.7026\n",
      "Epoch 554/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 755468505094.9150 - val_loss: 800278118556.6965\n",
      "Epoch 555/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 754084978185.5082 - val_loss: 799101863653.1398\n",
      "Epoch 556/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 755496356945.2516 - val_loss: 807669889025.7283\n",
      "Epoch 557/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 756529904327.0951 - val_loss: 813644533936.2836\n",
      "Epoch 558/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 766205403223.5902 - val_loss: 798331120547.5376\n",
      "Epoch 559/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 757449861741.1998 - val_loss: 798255992132.6267\n",
      "Epoch 560/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 754730757445.5824 - val_loss: 799545625127.3181\n",
      "Epoch 561/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 757889063738.3455 - val_loss: 808648819697.3097\n",
      "Epoch 562/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 758771686165.4655 - val_loss: 798718344225.1251\n",
      "Epoch 563/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 756895046725.7266 - val_loss: 799048874478.8613\n",
      "Epoch 564/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 760706542668.6416 - val_loss: 836067759348.5502\n",
      "Epoch 565/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 765710111860.9792 - val_loss: 815888389498.2031\n",
      "Epoch 566/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 84us/step - loss: 761534084992.0720 - val_loss: 797247197092.9778\n",
      "Epoch 567/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 752654584212.5289 - val_loss: 803155624548.9597\n",
      "Epoch 568/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 754227249981.8030 - val_loss: 802103884017.3817\n",
      "Epoch 569/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 751344265468.3984 - val_loss: 798063152683.0627\n",
      "Epoch 570/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 753903888129.2965 - val_loss: 831736587689.4425\n",
      "Epoch 571/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 754940721383.6534 - val_loss: 799007477387.8458\n",
      "Epoch 572/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 753723077311.0276 - val_loss: 796574711771.1302\n",
      "Epoch 573/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 752401323456.9004 - val_loss: 798108544465.1926\n",
      "Epoch 574/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 757531628946.8002 - val_loss: 795097299305.2085\n",
      "Epoch 575/5000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 754650577229.0737 - val_loss: 798734121284.3386\n",
      "Epoch 576/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 754509290704.0270 - val_loss: 800517767329.3052\n",
      "Epoch 577/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 751696501811.2864 - val_loss: 796019146323.3890\n",
      "Epoch 578/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 750559488833.2605 - val_loss: 795926010394.6442\n",
      "Epoch 579/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 750442277641.9404 - val_loss: 795659100701.5247\n",
      "Epoch 580/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 756214182083.9258 - val_loss: 795585240744.6504\n",
      "Epoch 581/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 751253043228.8126 - val_loss: 801337053899.5038\n",
      "Epoch 582/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 753548078248.8418 - val_loss: 819651493376.4320\n",
      "Epoch 583/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 756781168170.9308 - val_loss: 811629128316.5795\n",
      "Epoch 584/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 753012685898.3364 - val_loss: 795913651715.3125\n",
      "Epoch 585/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 754316679275.1830 - val_loss: 799059269640.6414\n",
      "Epoch 586/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 751139202476.1554 - val_loss: 794556278480.4005\n",
      "Epoch 587/5000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 750933155153.1074 - val_loss: 801761285968.2926\n",
      "Epoch 588/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 753337958953.2020 - val_loss: 798787730036.5142\n",
      "Epoch 589/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 749725310662.5188 - val_loss: 803850579676.4984\n",
      "Epoch 590/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 758350065408.1442 - val_loss: 795261889955.1055\n",
      "Epoch 591/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 750085714410.9668 - val_loss: 797456824003.7266\n",
      "Epoch 592/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 751552409132.0833 - val_loss: 801627928872.6864\n",
      "Epoch 593/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 748766138321.8999 - val_loss: 798299408543.5769\n",
      "Epoch 594/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 750854275920.2432 - val_loss: 795707309314.9525\n",
      "Epoch 595/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 751102037220.7721 - val_loss: 797055030193.9398\n",
      "Epoch 596/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 750315653450.7687 - val_loss: 794205293417.9286\n",
      "Epoch 597/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 749314942306.3951 - val_loss: 795477426125.3041\n",
      "Epoch 598/5000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 752859052328.1936 - val_loss: 795001000282.8062\n",
      "Epoch 599/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 748737339350.5099 - val_loss: 794109625117.3086\n",
      "Epoch 600/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 750934749674.9668 - val_loss: 794203832969.8296\n",
      "Epoch 601/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 750122033009.0895 - val_loss: 798838813569.5482\n",
      "Epoch 602/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 745582890600.0135 - val_loss: 800795895513.6180\n",
      "Epoch 603/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 754865308404.0427 - val_loss: 793120099062.7106\n",
      "Epoch 604/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 749152995124.0067 - val_loss: 805349149744.1035\n",
      "Epoch 605/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 751566496126.6315 - val_loss: 846632827061.4684\n",
      "Epoch 606/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 757594570023.6173 - val_loss: 793608365965.3580\n",
      "Epoch 607/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 750611083884.0472 - val_loss: 794814021502.9558\n",
      "Epoch 608/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 750493236178.4761 - val_loss: 809263104525.3940\n",
      "Epoch 609/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 749216302715.6060 - val_loss: 795849862056.1462\n",
      "Epoch 610/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 756062348946.6562 - val_loss: 812526560690.6599\n",
      "Epoch 611/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 749582181841.0354 - val_loss: 799539535588.5637\n",
      "Epoch 612/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 759743241175.0861 - val_loss: 803425246197.3423\n",
      "Epoch 613/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 748998158025.9763 - val_loss: 800198367014.8141\n",
      "Epoch 614/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 750711417987.9618 - val_loss: 796476479174.0309\n",
      "Epoch 615/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 752956700783.7928 - val_loss: 804080111985.8497\n",
      "Epoch 616/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 746759919004.0203 - val_loss: 802073619520.2340\n",
      "Epoch 617/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 749595165667.1874 - val_loss: 799322641403.6793\n",
      "Epoch 618/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 748298363585.3325 - val_loss: 792951689507.5016\n",
      "Epoch 619/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 748617777382.5009 - val_loss: 791057718215.2551\n",
      "Epoch 620/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 748535101450.3724 - val_loss: 806303547249.1296\n",
      "Epoch 621/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 751889337554.3320 - val_loss: 795245249433.7440\n",
      "Epoch 622/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 745385430373.8525 - val_loss: 796020168989.1646\n",
      "Epoch 623/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 747712788388.9521 - val_loss: 793934335388.1924\n",
      "Epoch 624/5000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 747260387784.3917 - val_loss: 792444522211.4115\n",
      "Epoch 625/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 751008366287.7389 - val_loss: 795220592209.6608\n",
      "Epoch 626/5000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 747060510544.8193 - val_loss: 791038185592.9789\n",
      "Epoch 627/5000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 753003444179.0522 - val_loss: 790476405521.2107\n",
      "Epoch 628/5000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 756585255656.5177 - val_loss: 796866321890.4753\n",
      "Epoch 629/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 105us/step - loss: 748713346167.2842 - val_loss: 790595503066.2661\n",
      "Epoch 630/5000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 745980706216.6979 - val_loss: 789946380480.4141\n",
      "Epoch 631/5000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 746749921942.6899 - val_loss: 799338750747.0043\n",
      "Epoch 632/5000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 747476954912.4142 - val_loss: 793075775125.6394\n",
      "Epoch 633/5000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 748440194521.1029 - val_loss: 796488192489.6765\n",
      "Epoch 634/5000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 746440690086.9691 - val_loss: 789629148052.5592\n",
      "Epoch 635/5000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 751116793884.8126 - val_loss: 789964295229.9297\n",
      "Epoch 636/5000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 753426484812.3534 - val_loss: 791088837159.8943\n",
      "Epoch 637/5000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 751038913292.2454 - val_loss: 790947782967.0886\n",
      "Epoch 638/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 750270948060.9927 - val_loss: 805243146360.9789\n",
      "Epoch 639/5000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 753847966079.7839 - val_loss: 789098642294.6025\n",
      "Epoch 640/5000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 747431659730.9083 - val_loss: 791152411739.3103\n",
      "Epoch 641/5000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 745992886913.9448 - val_loss: 789900748906.5767\n",
      "Epoch 642/5000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 745903524438.1498 - val_loss: 803652281142.6565\n",
      "Epoch 643/5000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 745338651167.9821 - val_loss: 793897448621.1150\n",
      "Epoch 644/5000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 747236897609.3280 - val_loss: 792956937784.3127\n",
      "Epoch 645/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 751910359664.6573 - val_loss: 790207719143.4442\n",
      "Epoch 646/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 745115344163.0073 - val_loss: 789039328274.1469\n",
      "Epoch 647/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 748263551854.2083 - val_loss: 847448656713.6675\n",
      "Epoch 648/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 747843518376.4098 - val_loss: 802487501869.2230\n",
      "Epoch 649/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 747157579576.6167 - val_loss: 792084003172.5997\n",
      "Epoch 650/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 747380698474.4626 - val_loss: 789400421891.3125\n",
      "Epoch 651/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 745938935591.3291 - val_loss: 797789828997.2928\n",
      "Epoch 652/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 748392132951.4463 - val_loss: 792973971424.8911\n",
      "Epoch 653/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 750480981587.2684 - val_loss: 789054661900.7460\n",
      "Epoch 654/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 742906512475.6240 - val_loss: 787676147752.3263\n",
      "Epoch 655/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 745949375343.3607 - val_loss: 789244163212.8540\n",
      "Epoch 656/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 747172555124.2589 - val_loss: 787039714950.0850\n",
      "Epoch 657/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 745898638216.7158 - val_loss: 788915276239.7524\n",
      "Epoch 658/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 746971251029.1414 - val_loss: 789005122021.6439\n",
      "Epoch 659/5000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 748618701119.2437 - val_loss: 791292057816.0338\n",
      "Epoch 660/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 745800038991.2346 - val_loss: 791761518306.2594\n",
      "Epoch 661/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 744977981112.6888 - val_loss: 811668684813.8262\n",
      "Epoch 662/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 745836698435.5656 - val_loss: 793760132888.4119\n",
      "Epoch 663/5000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 746492859850.1204 - val_loss: 800720587003.7513\n",
      "Epoch 664/5000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 748749068856.1846 - val_loss: 796944699158.1074\n",
      "Epoch 665/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 745345151955.6287 - val_loss: 787866826555.5533\n",
      "Epoch 666/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 748050230754.3230 - val_loss: 786924718092.0979\n",
      "Epoch 667/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 745413372926.2712 - val_loss: 793153964039.4891\n",
      "Epoch 668/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 744084804955.4800 - val_loss: 785625078058.9907\n",
      "Epoch 669/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 746117217170.8002 - val_loss: 790101328452.6987\n",
      "Epoch 670/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 742374384459.6332 - val_loss: 790429346737.3638\n",
      "Epoch 671/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 743405155799.9506 - val_loss: 791723214477.5741\n",
      "Epoch 672/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 743430722953.5802 - val_loss: 786500016413.1646\n",
      "Epoch 673/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 742916311896.3105 - val_loss: 787913030523.2113\n",
      "Epoch 674/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 743765773135.0906 - val_loss: 786444637834.1176\n",
      "Epoch 675/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 750925425445.6003 - val_loss: 798413895207.0302\n",
      "Epoch 676/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 743783612019.5386 - val_loss: 804261362366.2538\n",
      "Epoch 677/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 747296348682.0844 - val_loss: 791575244218.1490\n",
      "Epoch 678/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 742745846979.3494 - val_loss: 785721830339.7986\n",
      "Epoch 679/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 743446835156.2048 - val_loss: 787142730499.9606\n",
      "Epoch 680/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 744689271871.9640 - val_loss: 789401177914.9772\n",
      "Epoch 681/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 743220797297.0895 - val_loss: 804301747539.0289\n",
      "Epoch 682/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 743363252295.4553 - val_loss: 784835339998.2267\n",
      "Epoch 683/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 744566433067.0748 - val_loss: 791337696782.2582\n",
      "Epoch 684/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 750546931294.7935 - val_loss: 796034258805.1624\n",
      "Epoch 685/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 745449528491.1470 - val_loss: 784680661921.8093\n",
      "Epoch 686/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 742502406804.3850 - val_loss: 795657153498.8422\n",
      "Epoch 687/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 743132434005.5734 - val_loss: 788020410355.9021\n",
      "Epoch 688/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 744644723545.4631 - val_loss: 785465048562.6060\n",
      "Epoch 689/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 743674866054.6990 - val_loss: 799792629878.0985\n",
      "Epoch 690/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 739221517193.8683 - val_loss: 785559577592.2228\n",
      "Epoch 691/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 743680589298.4581 - val_loss: 785188668511.9189\n",
      "Epoch 692/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 87us/step - loss: 745644252063.7659 - val_loss: 790278556111.7524\n",
      "Epoch 693/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 749811697589.0872 - val_loss: 783831738935.4486\n",
      "Epoch 694/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 750314411263.2797 - val_loss: 790040492904.7764\n",
      "Epoch 695/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 742256705314.7192 - val_loss: 783237492596.5862\n",
      "Epoch 696/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 744808403043.1154 - val_loss: 797927132751.9325\n",
      "Epoch 697/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 742635643981.7941 - val_loss: 787414549489.3097\n",
      "Epoch 698/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 743404026059.9933 - val_loss: 786683642358.3505\n",
      "Epoch 699/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 741086483711.2797 - val_loss: 783398668355.4026\n",
      "Epoch 700/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 744250531770.8497 - val_loss: 784071019084.1879\n",
      "Epoch 701/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 750457614504.2656 - val_loss: 788891087902.2448\n",
      "Epoch 702/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 742206385523.6826 - val_loss: 788074374546.3989\n",
      "Epoch 703/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 740100409121.5667 - val_loss: 786729133241.7891\n",
      "Epoch 704/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 744772594441.9404 - val_loss: 790289941563.0492\n",
      "Epoch 705/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 739595961841.3055 - val_loss: 784085942663.7412\n",
      "Epoch 706/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 743370527962.3997 - val_loss: 786120196455.4802\n",
      "Epoch 707/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 740669938130.7642 - val_loss: 784048424773.9230\n",
      "Epoch 708/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 741956890653.9651 - val_loss: 785540388112.2025\n",
      "Epoch 709/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 743545721484.3174 - val_loss: 783147118770.5879\n",
      "Epoch 710/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 742421740904.1576 - val_loss: 795304632377.6090\n",
      "Epoch 711/5000\n",
      "3554/3554 [==============================] - 0s 134us/step - loss: 740009629830.8429 - val_loss: 782562127299.3666\n",
      "Epoch 712/5000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 741813103065.6793 - val_loss: 787590360556.8450\n",
      "Epoch 713/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 737382867584.7924 - val_loss: 785965140007.7502\n",
      "Epoch 714/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 741718209445.5284 - val_loss: 786529988588.4130\n",
      "Epoch 715/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 746996442890.5166 - val_loss: 783259300548.5907\n",
      "Epoch 716/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 741468682582.2937 - val_loss: 781836854296.4838\n",
      "Epoch 717/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 743822816986.1113 - val_loss: 782629566447.2933\n",
      "Epoch 718/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 743610110069.5554 - val_loss: 783213741580.5299\n",
      "Epoch 719/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 744082595272.9679 - val_loss: 796452687965.3265\n",
      "Epoch 720/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 737755632148.4570 - val_loss: 793715767588.0776\n",
      "Epoch 721/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 739900134669.1096 - val_loss: 785738235931.6523\n",
      "Epoch 722/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 740674253420.0472 - val_loss: 783170490700.9800\n",
      "Epoch 723/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 740824150221.1458 - val_loss: 793385129485.6821\n",
      "Epoch 724/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 746342727286.9961 - val_loss: 785736872893.4615\n",
      "Epoch 725/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 736930241504.3062 - val_loss: 782815077497.2670\n",
      "Epoch 726/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 737314045454.1182 - val_loss: 781456583896.3218\n",
      "Epoch 727/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 742120164304.1711 - val_loss: 779798228331.8009\n",
      "Epoch 728/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 740732762242.2330 - val_loss: 791338744551.7322\n",
      "Epoch 729/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 740050960439.3202 - val_loss: 783954587909.5449\n",
      "Epoch 730/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 739353976560.0090 - val_loss: 780698697810.9569\n",
      "Epoch 731/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 737963928274.6201 - val_loss: 782332402732.6470\n",
      "Epoch 732/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 738662843345.3235 - val_loss: 778437585071.7074\n",
      "Epoch 733/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 740211434905.7152 - val_loss: 788413663419.2292\n",
      "Epoch 734/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 739081335330.2870 - val_loss: 788535563255.0706\n",
      "Epoch 735/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 740437234970.9398 - val_loss: 777810148094.7758\n",
      "Epoch 736/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 735917158139.5341 - val_loss: 779322419749.0138\n",
      "Epoch 737/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 736562335769.3550 - val_loss: 783062396346.1490\n",
      "Epoch 738/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 736962698955.1289 - val_loss: 782516387374.5193\n",
      "Epoch 739/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 737755476256.1261 - val_loss: 777790925395.1010\n",
      "Epoch 740/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 737575496900.5020 - val_loss: 780310449776.1935\n",
      "Epoch 741/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 741096874209.8909 - val_loss: 778100800213.2974\n",
      "Epoch 742/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 733485410869.8796 - val_loss: 777061757761.0261\n",
      "Epoch 743/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 740012212878.6223 - val_loss: 776193613328.5626\n",
      "Epoch 744/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 738804264316.9027 - val_loss: 783176933166.3032\n",
      "Epoch 745/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 737734104660.4210 - val_loss: 796936619984.1846\n",
      "Epoch 746/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 735626951210.3545 - val_loss: 780054476963.0334\n",
      "Epoch 747/5000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 734805002859.7592 - val_loss: 775161728043.4948\n",
      "Epoch 748/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 733188722224.6934 - val_loss: 787348407885.0520\n",
      "Epoch 749/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 739805215486.4154 - val_loss: 775388618307.2585\n",
      "Epoch 750/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 741745151343.0725 - val_loss: 776812864577.9623\n",
      "Epoch 751/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 737613941066.7687 - val_loss: 780612732520.7043\n",
      "Epoch 752/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 736459570858.8586 - val_loss: 784559491752.3623\n",
      "Epoch 753/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 735659819208.5358 - val_loss: 779905429373.8037\n",
      "Epoch 754/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 734848810513.5757 - val_loss: 779667713977.7170\n",
      "Epoch 755/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 96us/step - loss: 732395787851.2009 - val_loss: 777096340227.9606\n",
      "Epoch 756/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 734719622716.2184 - val_loss: 773865993301.5493\n",
      "Epoch 757/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 735133182794.4806 - val_loss: 773273433007.6355\n",
      "Epoch 758/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 735899070401.7648 - val_loss: 793386168853.4594\n",
      "Epoch 759/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 733208402875.4260 - val_loss: 788083896397.1960\n",
      "Epoch 760/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 733879824224.9545 - val_loss: 774361429441.6383\n",
      "Epoch 761/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 733899612883.7726 - val_loss: 778819337152.3420\n",
      "Epoch 762/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 735937353613.9021 - val_loss: 773397330649.9060\n",
      "Epoch 763/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 732989556956.1284 - val_loss: 772406784639.4600\n",
      "Epoch 764/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 729405895515.7682 - val_loss: 771182981764.0686\n",
      "Epoch 765/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 731740317524.2769 - val_loss: 786001353426.9929\n",
      "Epoch 766/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 730108938911.9100 - val_loss: 771505231290.7252\n",
      "Epoch 767/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 729603176874.4266 - val_loss: 771087539903.6940\n",
      "Epoch 768/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 730898190471.9955 - val_loss: 777811088070.8950\n",
      "Epoch 769/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 731570342292.5289 - val_loss: 770980386502.0309\n",
      "Epoch 770/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 729317524331.9033 - val_loss: 770187675922.7949\n",
      "Epoch 771/5000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 734205663459.0433 - val_loss: 775690117103.8695\n",
      "Epoch 772/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 729805664481.8909 - val_loss: 775206164972.5570\n",
      "Epoch 773/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 727247657622.6899 - val_loss: 771442277187.9066\n",
      "Epoch 774/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 732962814119.1130 - val_loss: 784346010223.3293\n",
      "Epoch 775/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 731366951740.6506 - val_loss: 769318581752.9429\n",
      "Epoch 776/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 731717239410.9623 - val_loss: 772663950571.9088\n",
      "Epoch 777/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 737523915919.4868 - val_loss: 768868784597.5133\n",
      "Epoch 778/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 731882297340.5425 - val_loss: 780167240361.5145\n",
      "Epoch 779/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 727442547485.5330 - val_loss: 771096444388.7798\n",
      "Epoch 780/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 731585247675.7141 - val_loss: 766953754721.9353\n",
      "Epoch 781/5000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 729413731032.3827 - val_loss: 770035663728.2655\n",
      "Epoch 782/5000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 728276707543.5183 - val_loss: 768295658778.5721\n",
      "Epoch 783/5000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 728687607863.3202 - val_loss: 767117516691.6951\n",
      "Epoch 784/5000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 724942966016.4323 - val_loss: 773270617402.2571\n",
      "Epoch 785/5000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 739517340308.3850 - val_loss: 792915271078.5620\n",
      "Epoch 786/5000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 729673509761.8008 - val_loss: 764358975711.5229\n",
      "Epoch 787/5000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 728175864862.5414 - val_loss: 765934928429.6552\n",
      "Epoch 788/5000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 726478264943.5048 - val_loss: 763763333607.9482\n",
      "Epoch 789/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 723294650119.0591 - val_loss: 764603489347.6906\n",
      "Epoch 790/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 721890328788.0608 - val_loss: 767713502509.0071\n",
      "Epoch 791/5000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 725451369742.2622 - val_loss: 767214281397.6124\n",
      "Epoch 792/5000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 729125310636.8757 - val_loss: 774564938331.7423\n",
      "Epoch 793/5000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 723030503887.3066 - val_loss: 763410332797.2996\n",
      "Epoch 794/5000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 721822999122.6923 - val_loss: 763460666486.9626\n",
      "Epoch 795/5000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 723663927426.2330 - val_loss: 764130370013.0026\n",
      "Epoch 796/5000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 720918665656.22 - 0s 130us/step - loss: 723381062575.9010 - val_loss: 764250455063.9077\n",
      "Epoch 797/5000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 722842343890.7642 - val_loss: 769051850988.7729\n",
      "Epoch 798/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 724208371369.7063 - val_loss: 767706971800.5198\n",
      "Epoch 799/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 725950969331.6105 - val_loss: 763752866540.9170\n",
      "Epoch 800/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 722278805948.8666 - val_loss: 763509924128.0450\n",
      "Epoch 801/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 724324450036.6189 - val_loss: 761236584611.0334\n",
      "Epoch 802/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 721473522446.5503 - val_loss: 772020277839.0684\n",
      "Epoch 803/5000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 722288180141.5959 - val_loss: 761579252993.8003\n",
      "Epoch 804/5000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 725144602807.2482 - val_loss: 760877950524.9215\n",
      "Epoch 805/5000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 725402576069.6545 - val_loss: 760706274350.3752\n",
      "Epoch 806/5000\n",
      "3554/3554 [==============================] - 0s 133us/step - loss: 720072025202.6742 - val_loss: 759325702343.9032\n",
      "Epoch 807/5000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 720750528169.7063 - val_loss: 760577057885.6146\n",
      "Epoch 808/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 722197864286.6494 - val_loss: 761122830923.0358\n",
      "Epoch 809/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 718728763254.8519 - val_loss: 765218075332.5907\n",
      "Epoch 810/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 719849124736.6483 - val_loss: 757497319549.5876\n",
      "Epoch 811/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 715634003606.1136 - val_loss: 757873424791.2957\n",
      "Epoch 812/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 721144165746.5300 - val_loss: 770073735337.3705\n",
      "Epoch 813/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 720633207942.2667 - val_loss: 756785092432.2926\n",
      "Epoch 814/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 718334945237.3573 - val_loss: 768207047138.1874\n",
      "Epoch 815/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 716706590749.9651 - val_loss: 756733371623.8762\n",
      "Epoch 816/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 717928858923.0748 - val_loss: 762284542517.1443\n",
      "Epoch 817/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 716687724108.3534 - val_loss: 756425134320.8057\n",
      "Epoch 818/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 81us/step - loss: 718280303343.4327 - val_loss: 762481597438.5598\n",
      "Epoch 819/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 719948501275.5160 - val_loss: 766459453797.1758\n",
      "Epoch 820/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 716801784039.6534 - val_loss: 768676383105.4042\n",
      "Epoch 821/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 717698472670.1453 - val_loss: 756538773661.8486\n",
      "Epoch 822/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 721300479525.1683 - val_loss: 759684743393.8273\n",
      "Epoch 823/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 719848347036.0203 - val_loss: 755657236233.4335\n",
      "Epoch 824/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 714743279913.3461 - val_loss: 773752314072.0338\n",
      "Epoch 825/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 718230246858.1204 - val_loss: 753764965148.7325\n",
      "Epoch 826/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 714654428439.4823 - val_loss: 758683975970.3494\n",
      "Epoch 827/5000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 714853218268.2723 - val_loss: 752733670323.6681\n",
      "Epoch 828/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 718987820558.1182 - val_loss: 751788131529.9196\n",
      "Epoch 829/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 715213325103.9730 - val_loss: 762762073632.1171\n",
      "Epoch 830/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 718213049392.9814 - val_loss: 758204364115.0289\n",
      "Epoch 831/5000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 711197213105.3416 - val_loss: 761992976498.6420\n",
      "Epoch 832/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 714967695313.8999 - val_loss: 751961917498.1851\n",
      "Epoch 833/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 715182679412.8351 - val_loss: 752003897523.1639\n",
      "Epoch 834/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 712772889455.3607 - val_loss: 760100079927.6647\n",
      "Epoch 835/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 711961952062.3794 - val_loss: 750161490342.8501\n",
      "Epoch 836/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 720685030395.9663 - val_loss: 756851582893.6191\n",
      "Epoch 837/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 711488805671.9055 - val_loss: 765326768913.2107\n",
      "Epoch 838/5000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 712894461036.9117 - val_loss: 751516381353.3705\n",
      "Epoch 839/5000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 715785509210.9038 - val_loss: 757512043147.5579\n",
      "Epoch 840/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 712553824993.6027 - val_loss: 758003759349.9905\n",
      "Epoch 841/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 712398179888.6934 - val_loss: 753136668050.9750\n",
      "Epoch 842/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 713069244040.2836 - val_loss: 768492100150.2965\n",
      "Epoch 843/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 716514666361.1571 - val_loss: 751780838741.9094\n",
      "Epoch 844/5000\n",
      "3554/3554 [==============================] - 0s 132us/step - loss: 709688401233.1074 - val_loss: 760219496027.4543\n",
      "Epoch 845/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 710984842572.4974 - val_loss: 751276252418.9525\n",
      "Epoch 846/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 711146025487.8469 - val_loss: 774899496281.9420\n",
      "Epoch 847/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 711892616228.3038 - val_loss: 747714241491.3530\n",
      "Epoch 848/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 713899798410.4446 - val_loss: 748331137288.4253\n",
      "Epoch 849/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 711545878547.5925 - val_loss: 757143402276.5098\n",
      "Epoch 850/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 715031435620.1238 - val_loss: 756869336669.7587\n",
      "Epoch 851/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 707782166443.8671 - val_loss: 754967517298.6420\n",
      "Epoch 852/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 708058837086.5054 - val_loss: 747608532144.5715\n",
      "Epoch 853/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 708212263537.8098 - val_loss: 747838332745.9556\n",
      "Epoch 854/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 711459085003.7052 - val_loss: 747764687758.2222\n",
      "Epoch 855/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 707550021575.5272 - val_loss: 767299682195.6951\n",
      "Epoch 856/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 708260183151.2167 - val_loss: 747658149281.9532\n",
      "Epoch 857/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 709949198112.4142 - val_loss: 743923166288.3645\n",
      "Epoch 858/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 711555527566.4784 - val_loss: 745530996760.7719\n",
      "Epoch 859/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 704478126038.5099 - val_loss: 744073627323.6614\n",
      "Epoch 860/5000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 708812777244.9567 - val_loss: 780591649654.0265\n",
      "Epoch 861/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 711357906565.9786 - val_loss: 744377533552.0496\n",
      "Epoch 862/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 706570037869.1998 - val_loss: 749316676521.2985\n",
      "Epoch 863/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 708375756166.1226 - val_loss: 746144976984.7179\n",
      "Epoch 864/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 705112474277.6725 - val_loss: 748184898073.4919\n",
      "Epoch 865/5000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 711378039984.9094 - val_loss: 744686315974.5350\n",
      "Epoch 866/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 704946298663.3291 - val_loss: 745298556346.7252\n",
      "Epoch 867/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 708298718319.2167 - val_loss: 742164998460.2734\n",
      "Epoch 868/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 703988008036.8441 - val_loss: 741585389531.7063\n",
      "Epoch 869/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 703341580589.9562 - val_loss: 741671225761.6653\n",
      "Epoch 870/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 708475587185.8098 - val_loss: 777407329725.0295\n",
      "Epoch 871/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 710823593918.3073 - val_loss: 748522981415.7502\n",
      "Epoch 872/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 702516636091.7141 - val_loss: 753845989052.2374\n",
      "Epoch 873/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 702442377250.5751 - val_loss: 741394241044.5952\n",
      "Epoch 874/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 702409574214.4469 - val_loss: 743179143348.3162\n",
      "Epoch 875/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 703738139921.7197 - val_loss: 740353446078.1097\n",
      "Epoch 876/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 702728537566.8655 - val_loss: 743584850993.8318\n",
      "Epoch 877/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 703808507957.0151 - val_loss: 740943908164.6267\n",
      "Epoch 878/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 703392591791.3247 - val_loss: 742085613694.1637\n",
      "Epoch 879/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 700351627605.1414 - val_loss: 742337981478.8861\n",
      "Epoch 880/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 700459593794.8452 - val_loss: 740231130127.8425\n",
      "Epoch 881/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 89us/step - loss: 701131947829.1593 - val_loss: 739311583208.9564\n",
      "Epoch 882/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 705249614797.8660 - val_loss: 749203785309.1826\n",
      "Epoch 883/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 701916772629.7535 - val_loss: 739903233075.5601\n",
      "Epoch 884/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 703380360711.2031 - val_loss: 741728544999.0121\n",
      "Epoch 885/5000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 706382498712.8508 - val_loss: 740698043214.8523\n",
      "Epoch 886/5000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 703234905463.1401 - val_loss: 738954714078.2987\n",
      "Epoch 887/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 699393160590.1902 - val_loss: 742843999551.4419\n",
      "Epoch 888/5000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 699529764730.3094 - val_loss: 737034482614.5486\n",
      "Epoch 889/5000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 698565088474.3997 - val_loss: 737832395272.7854\n",
      "Epoch 890/5000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 701764949800.4817 - val_loss: 736978914969.6720\n",
      "Epoch 891/5000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 698903087130.5076 - val_loss: 744059393296.2025\n",
      "Epoch 892/5000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 698356494946.8271 - val_loss: 740773244127.2349\n",
      "Epoch 893/5000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 701911476273.5576 - val_loss: 746458157907.4611\n",
      "Epoch 894/5000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 698006631619.3494 - val_loss: 734278787913.0914\n",
      "Epoch 895/5000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 698499962950.3027 - val_loss: 738133935536.3556\n",
      "Epoch 896/5000\n",
      "3554/3554 [==============================] - 0s 119us/step - loss: 698194876848.1891 - val_loss: 734694985413.4548\n",
      "Epoch 897/5000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 696560607312.6753 - val_loss: 734444684669.6597\n",
      "Epoch 898/5000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 697518451742.5414 - val_loss: 783453155133.2816\n",
      "Epoch 899/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 695515226328.6709 - val_loss: 734872537858.2323\n",
      "Epoch 900/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 694267955650.6293 - val_loss: 750965503780.5098\n",
      "Epoch 901/5000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 698499442590.0371 - val_loss: 733220743078.7061\n",
      "Epoch 902/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 700602393419.6332 - val_loss: 738190955188.4602\n",
      "Epoch 903/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 694452437425.3416 - val_loss: 733882810718.2627\n",
      "Epoch 904/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 698863260964.1599 - val_loss: 742501539724.7820\n",
      "Epoch 905/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 702472076897.0984 - val_loss: 749060317734.7421\n",
      "Epoch 906/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 695039415920.0809 - val_loss: 738116972181.0632\n",
      "Epoch 907/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 693978373540.0878 - val_loss: 734259769319.8042\n",
      "Epoch 908/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 695097007994.3094 - val_loss: 733007396781.0431\n",
      "Epoch 909/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 692788555722.9849 - val_loss: 732609374621.0565\n",
      "Epoch 910/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 698738738408.2296 - val_loss: 738128718829.2771\n",
      "Epoch 911/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 694512228210.2419 - val_loss: 729773479960.7719\n",
      "Epoch 912/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 693975685780.3850 - val_loss: 731716995379.0560\n",
      "Epoch 913/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 692802529218.9174 - val_loss: 729342469181.3536\n",
      "Epoch 914/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 691685550876.3805 - val_loss: 730890751169.2782\n",
      "Epoch 915/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 694884465673.7963 - val_loss: 729214591439.1764\n",
      "Epoch 916/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 696122131732.0248 - val_loss: 729372593582.6273\n",
      "Epoch 917/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 693642369038.9825 - val_loss: 744527275304.3983\n",
      "Epoch 918/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 693583139929.3191 - val_loss: 731143908877.1061\n",
      "Epoch 919/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 692630895731.8267 - val_loss: 728932926025.3075\n",
      "Epoch 920/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 692289611382.9961 - val_loss: 733770045137.5527\n",
      "Epoch 921/5000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 691491477279.2617 - val_loss: 730287229751.2327\n",
      "Epoch 922/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 692002100045.9381 - val_loss: 728661490071.2957\n",
      "Epoch 923/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 692633604351.8558 - val_loss: 729660824433.9938\n",
      "Epoch 924/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 694068497701.3123 - val_loss: 731389211148.2419\n",
      "Epoch 925/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 695123942773.9877 - val_loss: 733617192211.0830\n",
      "Epoch 926/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 692132202614.7080 - val_loss: 731890488882.5519\n",
      "Epoch 927/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 689322633993.9404 - val_loss: 753755106289.8857\n",
      "Epoch 928/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 698951101027.9797 - val_loss: 728576797059.7086\n",
      "Epoch 929/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 692436718211.0973 - val_loss: 731336565498.7432\n",
      "Epoch 930/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 689225488076.2814 - val_loss: 726059464710.3370\n",
      "Epoch 931/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 691152289496.9590 - val_loss: 737469742564.7798\n",
      "Epoch 932/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 693601489834.1385 - val_loss: 733569403071.8380\n",
      "Epoch 933/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 693980642758.6630 - val_loss: 729791208886.6925\n",
      "Epoch 934/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 689396395250.6021 - val_loss: 727142760132.3026\n",
      "Epoch 935/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 689179690822.4469 - val_loss: 724922760312.6909\n",
      "Epoch 936/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 686456099320.7969 - val_loss: 735479230651.8053\n",
      "Epoch 937/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 687523454777.7693 - val_loss: 725927754513.2107\n",
      "Epoch 938/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 688449633944.4187 - val_loss: 726959354606.0692\n",
      "Epoch 939/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 687791564766.5774 - val_loss: 724713804558.3302\n",
      "Epoch 940/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 688505688080.1351 - val_loss: 726932031295.0099\n",
      "Epoch 941/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 690001649013.9877 - val_loss: 726857908767.8290\n",
      "Epoch 942/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 690418669592.2026 - val_loss: 724877326952.9924\n",
      "Epoch 943/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 690001667527.8154 - val_loss: 726153071210.1445\n",
      "Epoch 944/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 82us/step - loss: 698146476472.2566 - val_loss: 723791415849.6226\n",
      "Epoch 945/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 686359448389.8705 - val_loss: 731122664834.2683\n",
      "Epoch 946/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 684711231478.7799 - val_loss: 728556811393.3322\n",
      "Epoch 947/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 687702563107.5835 - val_loss: 723653800411.8503\n",
      "Epoch 948/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 686640370786.5391 - val_loss: 724209684455.8042\n",
      "Epoch 949/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 686609852622.2982 - val_loss: 723320768083.9651\n",
      "Epoch 950/5000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 687513824132.1057 - val_loss: 723387761232.2206\n",
      "Epoch 951/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 687412123570.7822 - val_loss: 736640245568.7382\n",
      "Epoch 952/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 685023664769.9448 - val_loss: 724891696820.1721\n",
      "Epoch 953/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 684439392502.6360 - val_loss: 728201683637.6124\n",
      "Epoch 954/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 687755428614.4828 - val_loss: 725126378964.0731\n",
      "Epoch 955/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 685574690420.6910 - val_loss: 723897658872.3668\n",
      "Epoch 956/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 686493510041.1390 - val_loss: 722664196013.6191\n",
      "Epoch 957/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 687196312508.5785 - val_loss: 723378231092.6403\n",
      "Epoch 958/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 683999572133.9606 - val_loss: 730544575912.2903\n",
      "Epoch 959/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 682171909377.5846 - val_loss: 722668127263.3969\n",
      "Epoch 960/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 684610187948.5874 - val_loss: 770835985323.0267\n",
      "Epoch 961/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 699812471784.3735 - val_loss: 731821091252.1001\n",
      "Epoch 962/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 686435685520.6393 - val_loss: 721529637592.7539\n",
      "Epoch 963/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 691744683378.5300 - val_loss: 725404719142.5980\n",
      "Epoch 964/5000\n",
      "3554/3554 [==============================] - 0s 132us/step - loss: 685378879128.4187 - val_loss: 722700318790.8591\n",
      "Epoch 965/5000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 685646723543.3741 - val_loss: 722151813522.1108\n",
      "Epoch 966/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 683653393973.3033 - val_loss: 724318919528.7764\n",
      "Epoch 967/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 684651978378.5886 - val_loss: 720758512292.9058\n",
      "Epoch 968/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 686712904492.5155 - val_loss: 740157348567.6017\n",
      "Epoch 969/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 687260643468.6055 - val_loss: 722485955825.6698\n",
      "Epoch 970/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 682541446814.1813 - val_loss: 720640041234.2189\n",
      "Epoch 971/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 687958616491.5790 - val_loss: 722019566464.3961\n",
      "Epoch 972/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 679670992847.5947 - val_loss: 739722714527.6489\n",
      "Epoch 973/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 684867583704.9590 - val_loss: 726420963802.6981\n",
      "Epoch 974/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 683892369927.7794 - val_loss: 719283095418.9232\n",
      "Epoch 975/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 685252661365.5554 - val_loss: 722495856103.0841\n",
      "Epoch 976/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 681649434681.6252 - val_loss: 729898485905.7507\n",
      "Epoch 977/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 681379536577.9089 - val_loss: 736618065232.1486\n",
      "Epoch 978/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 685736168934.9331 - val_loss: 721592239577.8340\n",
      "Epoch 979/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 683054980387.0073 - val_loss: 719903438156.1158\n",
      "Epoch 980/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 682812971502.4243 - val_loss: 725839139803.4183\n",
      "Epoch 981/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 682697472554.3545 - val_loss: 718404737136.3375\n",
      "Epoch 982/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 682899096791.2302 - val_loss: 720972597253.1848\n",
      "Epoch 983/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 682353640346.0034 - val_loss: 719527575505.9128\n",
      "Epoch 984/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 682274877977.0669 - val_loss: 737009721834.8287\n",
      "Epoch 985/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 685340350230.0416 - val_loss: 718059377290.9817\n",
      "Epoch 986/5000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 678126375785.5981 - val_loss: 733631234520.3938\n",
      "Epoch 987/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 684607321587.6105 - val_loss: 722566360349.4526\n",
      "Epoch 988/5000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 681128098567.6354 - val_loss: 715361609016.5288\n",
      "Epoch 989/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 678936937499.0839 - val_loss: 719769830664.1373\n",
      "Epoch 990/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 681896688161.1345 - val_loss: 733021059771.9493\n",
      "Epoch 991/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 675837842217.0580 - val_loss: 714245998122.4867\n",
      "Epoch 992/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 675480066441.0039 - val_loss: 721954899558.4000\n",
      "Epoch 993/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 678737952076.4974 - val_loss: 711968489262.3032\n",
      "Epoch 994/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 674344780080.2611 - val_loss: 723901657911.8087\n",
      "Epoch 995/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 677946115421.7850 - val_loss: 712545305903.3114\n",
      "Epoch 996/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 683331620566.6539 - val_loss: 710337548567.9797\n",
      "Epoch 997/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 678728327665.8818 - val_loss: 731065757005.8441\n",
      "Epoch 998/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 671220248873.3461 - val_loss: 709066482961.3547\n",
      "Epoch 999/5000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 673977548643.2594 - val_loss: 735842039378.8130\n",
      "Epoch 1000/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 679709388166.1226 - val_loss: 713929365259.1617\n",
      "Epoch 1001/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 674640617873.0714 - val_loss: 715100467638.9806\n",
      "Epoch 1002/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 669326381606.8971 - val_loss: 707650903589.3019\n",
      "Epoch 1003/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 669726369040.5673 - val_loss: 709238922839.9978\n",
      "Epoch 1004/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 666727669027.0073 - val_loss: 705443619581.0475\n",
      "Epoch 1005/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 669510018254.8744 - val_loss: 707543763585.1882\n",
      "Epoch 1006/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 672911392177.9178 - val_loss: 705369798466.4664\n",
      "Epoch 1007/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 85us/step - loss: 667294387216.7113 - val_loss: 710544213631.7479\n",
      "Epoch 1008/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 667007261129.5442 - val_loss: 702081498359.4307\n",
      "Epoch 1009/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 670243544318.1272 - val_loss: 720107346460.9485\n",
      "Epoch 1010/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 666196829197.2538 - val_loss: 707562678150.4449\n",
      "Epoch 1011/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 664507287661.4879 - val_loss: 715110655465.9646\n",
      "Epoch 1012/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 663482977471.8920 - val_loss: 700384267874.3673\n",
      "Epoch 1013/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 668386287159.6083 - val_loss: 704625463746.5024\n",
      "Epoch 1014/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 663866984778.7687 - val_loss: 696716940101.6349\n",
      "Epoch 1015/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 656786852189.2089 - val_loss: 710415811262.8298\n",
      "Epoch 1016/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 656978195218.0079 - val_loss: 698166988727.4126\n",
      "Epoch 1017/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 656420329772.8036 - val_loss: 694916319145.0104\n",
      "Epoch 1018/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 656036466501.2943 - val_loss: 693879529064.1283\n",
      "Epoch 1019/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 653331183515.7322 - val_loss: 701253657041.4807\n",
      "Epoch 1020/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 655074809052.1284 - val_loss: 693403403120.2655\n",
      "Epoch 1021/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 652842533841.3235 - val_loss: 696534388386.8894\n",
      "Epoch 1022/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 654470682048.9004 - val_loss: 693643985969.8318\n",
      "Epoch 1023/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 651012459011.1694 - val_loss: 687265841788.0034\n",
      "Epoch 1024/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 648771734092.9297 - val_loss: 689735791590.9401\n",
      "Epoch 1025/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 650350870205.2988 - val_loss: 693430735492.0686\n",
      "Epoch 1026/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 650989457673.0759 - val_loss: 683248580462.2493\n",
      "Epoch 1027/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 648163219627.7231 - val_loss: 681544107186.8760\n",
      "Epoch 1028/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 644334570176.1802 - val_loss: 686818951029.7384\n",
      "Epoch 1029/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 642991315558.2848 - val_loss: 680493686659.5646\n",
      "Epoch 1030/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 644020607617.9448 - val_loss: 677378404433.8048\n",
      "Epoch 1031/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 642056232678.7889 - val_loss: 681110008191.6759\n",
      "Epoch 1032/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 639488564856.1487 - val_loss: 675735158790.9131\n",
      "Epoch 1033/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 635427256689.9539 - val_loss: 678244514715.4723\n",
      "Epoch 1034/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 636264359340.1554 - val_loss: 680130191636.5232\n",
      "Epoch 1035/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 633831380124.1644 - val_loss: 686559967457.2512\n",
      "Epoch 1036/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 636809845885.0466 - val_loss: 672725125731.2314\n",
      "Epoch 1037/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 634588988682.8047 - val_loss: 679174838444.2509\n",
      "Epoch 1038/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 628253649176.0585 - val_loss: 665110731931.2562\n",
      "Epoch 1039/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 627709005167.0726 - val_loss: 663551254528.0000\n",
      "Epoch 1040/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 625831064540.8486 - val_loss: 664863670868.8292\n",
      "Epoch 1041/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 627823449453.9200 - val_loss: 664550786989.6191\n",
      "Epoch 1042/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 623592731179.5071 - val_loss: 657772407081.8385\n",
      "Epoch 1043/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 623588144618.3905 - val_loss: 658957313133.7451\n",
      "Epoch 1044/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 621505110112.8103 - val_loss: 654024524870.5710\n",
      "Epoch 1045/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 615061450901.8256 - val_loss: 652531242523.5083\n",
      "Epoch 1046/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 615268468541.2268 - val_loss: 651225204713.5325\n",
      "Epoch 1047/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 611489705045.8616 - val_loss: 650024812073.9105\n",
      "Epoch 1048/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 614368462505.7063 - val_loss: 648064179652.5187\n",
      "Epoch 1049/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 608688146744.3286 - val_loss: 644920071599.2034\n",
      "Epoch 1050/5000\n",
      "3554/3554 [==============================] - 0s 110us/step - loss: 607697423561.1119 - val_loss: 652783636672.4141\n",
      "Epoch 1051/5000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 607125126900.6190 - val_loss: 646366249100.5659\n",
      "Epoch 1052/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 599893900362.9127 - val_loss: 642325756288.2521\n",
      "Epoch 1053/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 601297201828.5200 - val_loss: 635457745226.6757\n",
      "Epoch 1054/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 595631951897.3551 - val_loss: 644080993977.3569\n",
      "Epoch 1055/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 592801445465.0309 - val_loss: 634083893054.4337\n",
      "Epoch 1056/5000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 591967548486.8790 - val_loss: 627436319799.5927\n",
      "Epoch 1057/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 590009470236.0923 - val_loss: 632456784453.2748\n",
      "Epoch 1058/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 589565971085.4700 - val_loss: 633818838802.0748\n",
      "Epoch 1059/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 589282184222.5414 - val_loss: 625219019657.6135\n",
      "Epoch 1060/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 587273088021.3214 - val_loss: 618627458291.3981\n",
      "Epoch 1061/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 579408115144.9679 - val_loss: 617058827043.6456\n",
      "Epoch 1062/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 576561044789.4474 - val_loss: 620101299674.4102\n",
      "Epoch 1063/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 573406348877.5059 - val_loss: 619065194391.7277\n",
      "Epoch 1064/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 572371732441.9674 - val_loss: 608041056783.1223\n",
      "Epoch 1065/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 571384518440.4817 - val_loss: 604081956161.7462\n",
      "Epoch 1066/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 565905014732.1373 - val_loss: 610938769316.9778\n",
      "Epoch 1067/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 564320993906.9623 - val_loss: 615197997537.0352\n",
      "Epoch 1068/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 564203351955.6646 - val_loss: 597084322570.2976\n",
      "Epoch 1069/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 558541792693.3754 - val_loss: 593831938235.2292\n",
      "Epoch 1070/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 102us/step - loss: 555860908664.7249 - val_loss: 592036997141.3153\n",
      "Epoch 1071/5000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 557374770220.3715 - val_loss: 587075891733.4594\n",
      "Epoch 1072/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 547614031835.1199 - val_loss: 593848962785.1072\n",
      "Epoch 1073/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 547208840043.9032 - val_loss: 583642753386.3606\n",
      "Epoch 1074/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 542884421950.0912 - val_loss: 578461932888.2137\n",
      "Epoch 1075/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 545125758626.7912 - val_loss: 575916958163.7850\n",
      "Epoch 1076/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 539679480662.0056 - val_loss: 583098393712.0496\n",
      "Epoch 1077/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 534854143896.2746 - val_loss: 577814778956.3319\n",
      "Epoch 1078/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 533234779061.6635 - val_loss: 580430511708.6064\n",
      "Epoch 1079/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 529260903525.9966 - val_loss: 560172253743.9595\n",
      "Epoch 1080/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 522641904148.4570 - val_loss: 556809970085.6979\n",
      "Epoch 1081/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 522287471957.7175 - val_loss: 554643251619.3936\n",
      "Epoch 1082/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 514498219928.2746 - val_loss: 554856462422.9896\n",
      "Epoch 1083/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 513102680227.6556 - val_loss: 560066056045.6731\n",
      "Epoch 1084/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 513081916637.8571 - val_loss: 546308100680.1553\n",
      "Epoch 1085/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 512439301601.1705 - val_loss: 550445973075.3890\n",
      "Epoch 1086/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 505014325319.4553 - val_loss: 539683211414.3595\n",
      "Epoch 1087/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 503218104222.0371 - val_loss: 546994437761.4763\n",
      "Epoch 1088/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 498822047415.5363 - val_loss: 534648055764.7933\n",
      "Epoch 1089/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 496509636160.8284 - val_loss: 543935760886.9266\n",
      "Epoch 1090/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 494674322657.3146 - val_loss: 532861121833.5505\n",
      "Epoch 1091/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 493520514428.9026 - val_loss: 528918804875.7739\n",
      "Epoch 1092/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 488802061725.1727 - val_loss: 527833692039.5972\n",
      "Epoch 1093/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 490252587494.3568 - val_loss: 535491715055.8695\n",
      "Epoch 1094/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 485592175198.2172 - val_loss: 519963896686.5373\n",
      "Epoch 1095/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 481589668392.0495 - val_loss: 527308699612.8585\n",
      "Epoch 1096/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 478638558344.5718 - val_loss: 519744407250.7049\n",
      "Epoch 1097/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 477548308566.4379 - val_loss: 517935498955.7919\n",
      "Epoch 1098/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 474660461102.9645 - val_loss: 523304393874.0388\n",
      "Epoch 1099/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 478845867438.4603 - val_loss: 511429751197.6326\n",
      "Epoch 1100/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 470969084940.1013 - val_loss: 508773057039.6984\n",
      "Epoch 1101/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 470701265804.7496 - val_loss: 505830025753.4920\n",
      "Epoch 1102/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 472026095537.6297 - val_loss: 507433503312.7966\n",
      "Epoch 1103/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 465954091886.2083 - val_loss: 506806445751.0526\n",
      "Epoch 1104/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 467997826772.3489 - val_loss: 502667051229.2186\n",
      "Epoch 1105/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 462597318862.2982 - val_loss: 502213184693.7564\n",
      "Epoch 1106/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 464514646292.6010 - val_loss: 494857195811.5015\n",
      "Epoch 1107/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 462114951608.2566 - val_loss: 494252224183.6287\n",
      "Epoch 1108/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 458667129086.7034 - val_loss: 492281224374.9086\n",
      "Epoch 1109/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 455525940369.7917 - val_loss: 493745864033.4312\n",
      "Epoch 1110/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 455476590012.2903 - val_loss: 500690739859.0470\n",
      "Epoch 1111/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 456617391926.3117 - val_loss: 486922805807.9595\n",
      "Epoch 1112/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 457997219158.8700 - val_loss: 488706458805.1803\n",
      "Epoch 1113/5000\n",
      "3554/3554 [==============================] - 1s 141us/step - loss: 452814617388.5154 - val_loss: 490444345766.8501\n",
      "Epoch 1114/5000\n",
      "3554/3554 [==============================] - 0s 130us/step - loss: 447346877665.3146 - val_loss: 496778878835.4340\n",
      "Epoch 1115/5000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 449941645398.4379 - val_loss: 481316753402.2391\n",
      "Epoch 1116/5000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 444792148703.2977 - val_loss: 482028414513.3997\n",
      "Epoch 1117/5000\n",
      "3554/3554 [==============================] - 0s 129us/step - loss: 451302640843.4170 - val_loss: 479469558319.3834\n",
      "Epoch 1118/5000\n",
      "3554/3554 [==============================] - 1s 142us/step - loss: 445456878691.6917 - val_loss: 488425090835.8031\n",
      "Epoch 1119/5000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 445724104239.5408 - val_loss: 478320590414.7803\n",
      "Epoch 1120/5000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 442741969649.7378 - val_loss: 471873067426.8174\n",
      "Epoch 1121/5000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 437397905394.1699 - val_loss: 475141882088.7404\n",
      "Epoch 1122/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 442389260899.9797 - val_loss: 469216260514.2413\n",
      "Epoch 1123/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 436900681512.4818 - val_loss: 475189131586.0343\n",
      "Epoch 1124/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 434190840086.9060 - val_loss: 478192138032.0315\n",
      "Epoch 1125/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 432952296585.7242 - val_loss: 463843492238.6543\n",
      "Epoch 1126/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 433850329856.7203 - val_loss: 471275250295.3947\n",
      "Epoch 1127/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 431457478567.2571 - val_loss: 463764912240.3375\n",
      "Epoch 1128/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 428313366829.9561 - val_loss: 463527513108.4512\n",
      "Epoch 1129/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 427534081370.3275 - val_loss: 459943379075.3485\n",
      "Epoch 1130/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 427034148797.1547 - val_loss: 458341820098.5744\n",
      "Epoch 1131/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 424088642047.7119 - val_loss: 457151865947.3102\n",
      "Epoch 1132/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 423502642457.7872 - val_loss: 461199503838.1547\n",
      "Epoch 1133/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 104us/step - loss: 424716450710.5458 - val_loss: 459378333292.1609\n",
      "Epoch 1134/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 421084817660.3984 - val_loss: 468394640449.9623\n",
      "Epoch 1135/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 424770938883.4575 - val_loss: 455959037629.9657\n",
      "Epoch 1136/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 418353056700.5786 - val_loss: 456575274854.7601\n",
      "Epoch 1137/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 418525538657.8188 - val_loss: 450092473381.7339\n",
      "Epoch 1138/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 423556035991.4102 - val_loss: 450680266622.9558\n",
      "Epoch 1139/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 420304497510.1407 - val_loss: 447231873020.5435\n",
      "Epoch 1140/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 417918319699.5565 - val_loss: 455061780871.1651\n",
      "Epoch 1141/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 414116979881.9944 - val_loss: 445990264057.7350\n",
      "Epoch 1142/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 418050570619.1739 - val_loss: 452659329683.6230\n",
      "Epoch 1143/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 415049381133.1097 - val_loss: 447705308700.0844\n",
      "Epoch 1144/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 411335526546.3680 - val_loss: 443602048299.8549\n",
      "Epoch 1145/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 412589324927.6398 - val_loss: 449930612778.6307\n",
      "Epoch 1146/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 410157356868.1418 - val_loss: 440855348997.4008\n",
      "Epoch 1147/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 409209378720.3422 - val_loss: 441869981725.3806\n",
      "Epoch 1148/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 406688876220.1463 - val_loss: 449606779375.4374\n",
      "Epoch 1149/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 404413564382.8655 - val_loss: 458383804812.9260\n",
      "Epoch 1150/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 406156380232.6078 - val_loss: 444525341827.0605\n",
      "Epoch 1151/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 409990204658.6022 - val_loss: 447739971868.0124\n",
      "Epoch 1152/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 408516016046.1722 - val_loss: 453163333419.4228\n",
      "Epoch 1153/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 406179019656.7158 - val_loss: 439930196648.9384\n",
      "Epoch 1154/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 403653611734.3658 - val_loss: 438174405106.8940\n",
      "Epoch 1155/5000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 400802499573.0512 - val_loss: 437320404184.3218\n",
      "Epoch 1156/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 405538691063.9324 - val_loss: 432447836439.9797\n",
      "Epoch 1157/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 400004727088.2611 - val_loss: 432922016030.3167\n",
      "Epoch 1158/5000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 399562436372.8892 - val_loss: 432546979630.3032\n",
      "Epoch 1159/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 399003079792.3691 - val_loss: 443084531744.8372\n",
      "Epoch 1160/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 403021209659.9302 - val_loss: 435164079302.4630\n",
      "Epoch 1161/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 397809646693.9966 - val_loss: 431730472611.4655\n",
      "Epoch 1162/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 400139021084.3804 - val_loss: 429235892614.5891\n",
      "Epoch 1163/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 397455710232.2026 - val_loss: 441192615214.7353\n",
      "Epoch 1164/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 401835951776.4862 - val_loss: 437149697751.3137\n",
      "Epoch 1165/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 394204373890.9533 - val_loss: 425787064965.2208\n",
      "Epoch 1166/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 394043681407.6398 - val_loss: 432620075932.6245\n",
      "Epoch 1167/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 394817676015.4327 - val_loss: 442574973592.2318\n",
      "Epoch 1168/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 394586254285.8661 - val_loss: 426083591487.4419\n",
      "Epoch 1169/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 393880015546.4175 - val_loss: 431805723258.8512\n",
      "Epoch 1170/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 395056180770.8633 - val_loss: 423166030971.5713\n",
      "Epoch 1171/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 390346973658.8318 - val_loss: 421821196089.2490\n",
      "Epoch 1172/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 396560923904.4321 - val_loss: 423558122657.0172\n",
      "Epoch 1173/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 390800136854.6899 - val_loss: 425200473405.1376\n",
      "Epoch 1174/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 390339308122.7597 - val_loss: 420165108176.3286\n",
      "Epoch 1175/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 392219681122.9713 - val_loss: 423090843811.6096\n",
      "Epoch 1176/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 388025355437.4519 - val_loss: 420149313743.3924\n",
      "Epoch 1177/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 386551983383.4823 - val_loss: 422204514560.9362\n",
      "Epoch 1178/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 391434159306.2645 - val_loss: 418307828385.4492\n",
      "Epoch 1179/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 387602242592.8464 - val_loss: 415920700882.3448\n",
      "Epoch 1180/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 387293414611.4846 - val_loss: 421166201695.5590\n",
      "Epoch 1181/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 385572533222.0687 - val_loss: 420020130778.2661\n",
      "Epoch 1182/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 386223625637.2403 - val_loss: 415031784999.0301\n",
      "Epoch 1183/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 384655283805.6409 - val_loss: 430928124930.0163\n",
      "Epoch 1184/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 386103391620.9702 - val_loss: 422076923110.1479\n",
      "Epoch 1185/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 383378123695.9009 - val_loss: 413276994105.7531\n",
      "Epoch 1186/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 381804568257.9088 - val_loss: 419136984098.8535\n",
      "Epoch 1187/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 379577533614.6044 - val_loss: 421019719586.0974\n",
      "Epoch 1188/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 380988090943.0996 - val_loss: 411353374721.1522\n",
      "Epoch 1189/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 382367210711.5182 - val_loss: 413412143162.7612\n",
      "Epoch 1190/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 381667342005.2313 - val_loss: 409857446438.7421\n",
      "Epoch 1191/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 384613498981.4203 - val_loss: 411193310754.9975\n",
      "Epoch 1192/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 382491246840.9409 - val_loss: 410158110726.3370\n",
      "Epoch 1193/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 380600657526.9960 - val_loss: 410870120597.7834\n",
      "Epoch 1194/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 380234971911.6353 - val_loss: 409063815581.0565\n",
      "Epoch 1195/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 379111405247.6038 - val_loss: 406255862950.2020\n",
      "Epoch 1196/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 86us/step - loss: 377681036029.2628 - val_loss: 410374931636.0281\n",
      "Epoch 1197/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 378764277770.3726 - val_loss: 424816091394.0883\n",
      "Epoch 1198/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 379732987689.6342 - val_loss: 403519683522.6464\n",
      "Epoch 1199/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 376502960856.3827 - val_loss: 406041244335.8515\n",
      "Epoch 1200/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 375492917184.6123 - val_loss: 405650511507.3350\n",
      "Epoch 1201/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 373964407180.4615 - val_loss: 410395016606.4968\n",
      "Epoch 1202/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 376590407307.7411 - val_loss: 406136318647.3406\n",
      "Epoch 1203/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 376497456385.5847 - val_loss: 412110875848.1913\n",
      "Epoch 1204/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 375063405267.7726 - val_loss: 404188143278.4113\n",
      "Epoch 1205/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 373690384024.4186 - val_loss: 404555058149.7879\n",
      "Epoch 1206/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 371867783663.5768 - val_loss: 405935008376.5468\n",
      "Epoch 1207/5000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 373144941873.9899 - val_loss: 408932809854.4518\n",
      "Epoch 1208/5000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 372508782631.1851 - val_loss: 402373448533.7654\n",
      "Epoch 1209/5000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 373478792990.1092 - val_loss: 404761526831.9595\n",
      "Epoch 1210/5000\n",
      "3554/3554 [==============================] - 0s 130us/step - loss: 373128253631.3157 - val_loss: 400096461043.1100\n",
      "Epoch 1211/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 369152697827.4755 - val_loss: 401781667250.0838\n",
      "Epoch 1212/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 369642013317.4023 - val_loss: 400034875111.4442\n",
      "Epoch 1213/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 369826183604.7991 - val_loss: 406174993299.9831\n",
      "Epoch 1214/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 370408569109.7535 - val_loss: 398608222228.7393\n",
      "Epoch 1215/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 375300189528.0225 - val_loss: 404373015018.2526\n",
      "Epoch 1216/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 371798010080.7383 - val_loss: 419470634631.2371\n",
      "Epoch 1217/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 371545167606.9240 - val_loss: 411871553578.6307\n",
      "Epoch 1218/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 369606799463.7254 - val_loss: 406359924724.4782\n",
      "Epoch 1219/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 369327300068.6281 - val_loss: 396411551746.8804\n",
      "Epoch 1220/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 370206885527.2662 - val_loss: 400479306692.9507\n",
      "Epoch 1221/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 367827267823.7209 - val_loss: 398241296933.5898\n",
      "Epoch 1222/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 368548041844.9792 - val_loss: 398302208073.7395\n",
      "Epoch 1223/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 366410753719.5363 - val_loss: 402729270442.2346\n",
      "Epoch 1224/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 371924413037.1998 - val_loss: 400777574737.0126\n",
      "Epoch 1225/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 370094379909.2583 - val_loss: 396104654584.7269\n",
      "Epoch 1226/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 364476106988.2634 - val_loss: 414805512788.8293\n",
      "Epoch 1227/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 367393026391.4463 - val_loss: 398121291897.5550\n",
      "Epoch 1228/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 366405213373.5870 - val_loss: 398730754344.6863\n",
      "Epoch 1229/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 366489339063.8245 - val_loss: 394098651272.5333\n",
      "Epoch 1230/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 365553853630.7394 - val_loss: 398925850291.5961\n",
      "Epoch 1231/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 363944310467.0613 - val_loss: 393741257793.9623\n",
      "Epoch 1232/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 366935583894.4018 - val_loss: 400076403038.8388\n",
      "Epoch 1233/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 364810996559.0906 - val_loss: 401473929257.4785\n",
      "Epoch 1234/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 363265588077.0557 - val_loss: 399580732236.5480\n",
      "Epoch 1235/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 364576377439.3698 - val_loss: 391293111629.2681\n",
      "Epoch 1236/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 367321928313.8773 - val_loss: 393890817435.6163\n",
      "Epoch 1237/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 363632223521.8548 - val_loss: 391708106865.4897\n",
      "Epoch 1238/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 362564232491.0749 - val_loss: 397970922576.3646\n",
      "Epoch 1239/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 365188542549.2853 - val_loss: 390358594472.7224\n",
      "Epoch 1240/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 359601399018.5346 - val_loss: 392866200848.7786\n",
      "Epoch 1241/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 361924199275.9032 - val_loss: 389618571257.0869\n",
      "Epoch 1242/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 364029065502.9736 - val_loss: 393341902566.2920\n",
      "Epoch 1243/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 360095583866.4536 - val_loss: 406422443931.1843\n",
      "Epoch 1244/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 361179671656.3016 - val_loss: 403409492351.0999\n",
      "Epoch 1245/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 358524614767.7929 - val_loss: 392734965668.4017\n",
      "Epoch 1246/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 362761709055.1356 - val_loss: 396622320190.3618\n",
      "Epoch 1247/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 362839208159.5858 - val_loss: 403385383420.6875\n",
      "Epoch 1248/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 362186150660.1778 - val_loss: 387838700442.3201\n",
      "Epoch 1249/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 361607752642.3411 - val_loss: 393998566159.4824\n",
      "Epoch 1250/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 359547337543.0231 - val_loss: 390727555771.3733\n",
      "Epoch 1251/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 355298420661.0872 - val_loss: 387715419370.1806\n",
      "Epoch 1252/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 360059968019.3044 - val_loss: 394465813911.5837\n",
      "Epoch 1253/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 359019800800.7383 - val_loss: 392806885962.4597\n",
      "Epoch 1254/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 359673703915.5430 - val_loss: 394636362887.6692\n",
      "Epoch 1255/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 358218239075.6917 - val_loss: 396127904238.2852\n",
      "Epoch 1256/5000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 358183195294.7574 - val_loss: 386151820912.7696\n",
      "Epoch 1257/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 357627136718.0101 - val_loss: 389177904853.0093\n",
      "Epoch 1258/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 355021326519.2482 - val_loss: 387355484100.0866\n",
      "Epoch 1259/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 84us/step - loss: 357498971352.0945 - val_loss: 387467228504.2138\n",
      "Epoch 1260/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 356741647646.3973 - val_loss: 384601445072.6886\n",
      "Epoch 1261/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 356433181124.9341 - val_loss: 390510863753.1815\n",
      "Epoch 1262/5000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 358480210983.7614 - val_loss: 384435590658.7365\n",
      "Epoch 1263/5000\n",
      "3554/3554 [==============================] - 0s 131us/step - loss: 355670618612.1868 - val_loss: 388099428398.6633\n",
      "Epoch 1264/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 356056781401.6072 - val_loss: 388436668133.1398\n",
      "Epoch 1265/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 356186488370.9983 - val_loss: 383102644954.4821\n",
      "Epoch 1266/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 354967209872.2071 - val_loss: 385630407027.5781\n",
      "Epoch 1267/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 352242080312.1846 - val_loss: 392547669167.9955\n",
      "Epoch 1268/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 354095759779.5115 - val_loss: 384050007987.3800\n",
      "Epoch 1269/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 353275594741.6274 - val_loss: 383760020969.3885\n",
      "Epoch 1270/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 355673355754.3906 - val_loss: 382599384694.5305\n",
      "Epoch 1271/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 350231836258.2510 - val_loss: 382633803130.2031\n",
      "Epoch 1272/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 355381343777.7108 - val_loss: 386156717835.7379\n",
      "Epoch 1273/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 355962883964.6145 - val_loss: 384666327348.7842\n",
      "Epoch 1274/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 354504184635.4980 - val_loss: 382708631019.6928\n",
      "Epoch 1275/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 352318735617.5847 - val_loss: 384169819965.8577\n",
      "Epoch 1276/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 355424320152.9949 - val_loss: 381882694289.8948\n",
      "Epoch 1277/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 351348441613.5419 - val_loss: 383338167718.5620\n",
      "Epoch 1278/5000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 353687304468.75 - 0s 85us/step - loss: 353860734079.3517 - val_loss: 379238236030.3798\n",
      "Epoch 1279/5000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 354163622367.4418 - val_loss: 382195427643.6973\n",
      "Epoch 1280/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 352547325222.4648 - val_loss: 379728971238.5080\n",
      "Epoch 1281/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 350002683272.4277 - val_loss: 379024649984.7921\n",
      "Epoch 1282/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 355963611342.2982 - val_loss: 379828993962.1626\n",
      "Epoch 1283/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 349361979179.9393 - val_loss: 379463445747.1100\n",
      "Epoch 1284/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 350699020347.9302 - val_loss: 399124155208.5153\n",
      "Epoch 1285/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 350694397681.1615 - val_loss: 380462494572.2329\n",
      "Epoch 1286/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 349915521535.7119 - val_loss: 379858936051.1100\n",
      "Epoch 1287/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 352758159227.4620 - val_loss: 378325597287.4081\n",
      "Epoch 1288/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 352050569902.8925 - val_loss: 385424480764.6875\n",
      "Epoch 1289/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 350216753610.6967 - val_loss: 383400721135.2214\n",
      "Epoch 1290/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 348949678632.0495 - val_loss: 384059923114.3786\n",
      "Epoch 1291/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 350703334623.0096 - val_loss: 385348070254.5373\n",
      "Epoch 1292/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 350587643455.6758 - val_loss: 380606033301.8554\n",
      "Epoch 1293/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 347196206912.6843 - val_loss: 390681588598.0264\n",
      "Epoch 1294/5000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 349102313649.4857 - val_loss: 381916306783.1269\n",
      "Epoch 1295/5000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 352543961827.9077 - val_loss: 380557581513.3434\n",
      "Epoch 1296/5000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 347716202599.7254 - val_loss: 377765721016.5648\n",
      "Epoch 1297/5000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 347651890992.5492 - val_loss: 396382864005.2208\n",
      "Epoch 1298/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 350452456029.0648 - val_loss: 379154536963.0245\n",
      "Epoch 1299/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 348076592176.9814 - val_loss: 382287787171.3215\n",
      "Epoch 1300/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 347846211456.0721 - val_loss: 378599299654.4270\n",
      "Epoch 1301/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 347177642540.6595 - val_loss: 377556524878.5643\n",
      "Epoch 1302/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 347513627421.5329 - val_loss: 375033283108.4377\n",
      "Epoch 1303/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 346610045128.5357 - val_loss: 377459851603.8931\n",
      "Epoch 1304/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 344966652019.2504 - val_loss: 375107706635.4498\n",
      "Epoch 1305/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 344467648652.6055 - val_loss: 376207051904.7561\n",
      "Epoch 1306/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 345107251393.6207 - val_loss: 379994584076.3859\n",
      "Epoch 1307/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 346174373602.1789 - val_loss: 381676917488.3735\n",
      "Epoch 1308/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 346196651564.0833 - val_loss: 374710718230.1075\n",
      "Epoch 1309/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 350366895572.4930 - val_loss: 375081788761.3660\n",
      "Epoch 1310/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 348698658013.8571 - val_loss: 379292015599.8695\n",
      "Epoch 1311/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 343271233311.2617 - val_loss: 375714554185.5235\n",
      "Epoch 1312/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 346362666533.1682 - val_loss: 373598165173.4684\n",
      "Epoch 1313/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 355452585955.1874 - val_loss: 376579547301.3378\n",
      "Epoch 1314/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 344770512041.9944 - val_loss: 381229979766.0984\n",
      "Epoch 1315/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 346177748171.4170 - val_loss: 374557756821.8554\n",
      "Epoch 1316/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 344584538359.7884 - val_loss: 377011667904.9182\n",
      "Epoch 1317/5000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 341675352377.4811 - val_loss: 372341232039.4261\n",
      "Epoch 1318/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 344051405065.0760 - val_loss: 372444302680.2138\n",
      "Epoch 1319/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 344046124475.1379 - val_loss: 372496604131.4835\n",
      "Epoch 1320/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 346001729539.4575 - val_loss: 373970850082.9255\n",
      "Epoch 1321/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 344114210386.1159 - val_loss: 383561578258.0748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1322/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 345514005501.1187 - val_loss: 388033391558.1030\n",
      "Epoch 1323/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 343582902270.8475 - val_loss: 374850298962.0928\n",
      "Epoch 1324/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 341371210805.5915 - val_loss: 372214469514.1896\n",
      "Epoch 1325/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 341138966692.8080 - val_loss: 372834879282.9119\n",
      "Epoch 1326/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 343576773806.6044 - val_loss: 372913543950.3303\n",
      "Epoch 1327/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 340029167658.6426 - val_loss: 372342412119.4937\n",
      "Epoch 1328/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 340240185819.9843 - val_loss: 394149039959.7817\n",
      "Epoch 1329/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 344078977792.7203 - val_loss: 370188001424.5986\n",
      "Epoch 1330/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 340385608631.9685 - val_loss: 373488423553.1882\n",
      "Epoch 1331/5000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 341806107761.77 - 0s 115us/step - loss: 342178694281.7242 - val_loss: 373892290053.6169\n",
      "Epoch 1332/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 345061373445.0422 - val_loss: 369897020328.1463\n",
      "Epoch 1333/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 340603773347.5115 - val_loss: 371415314458.5001\n",
      "Epoch 1334/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 341083514551.5363 - val_loss: 377593352789.6934\n",
      "Epoch 1335/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 339644729425.8278 - val_loss: 370251656056.9069\n",
      "Epoch 1336/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 342262621386.2645 - val_loss: 369366725523.1190\n",
      "Epoch 1337/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 338068999691.8132 - val_loss: 372793457837.6912\n",
      "Epoch 1338/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 339536480291.7277 - val_loss: 403188804416.4501\n",
      "Epoch 1339/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 350335129158.5909 - val_loss: 369485078983.6872\n",
      "Epoch 1340/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 338787947664.6393 - val_loss: 376457500010.0726\n",
      "Epoch 1341/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 340245576603.1559 - val_loss: 369844562454.6115\n",
      "Epoch 1342/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 337354522780.7406 - val_loss: 370512301013.6574\n",
      "Epoch 1343/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 338134092623.0906 - val_loss: 367951434702.1682\n",
      "Epoch 1344/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 339944655842.6111 - val_loss: 370408139909.0768\n",
      "Epoch 1345/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 337522690397.2088 - val_loss: 371036949590.4135\n",
      "Epoch 1346/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 336849950467.6016 - val_loss: 398068034786.1154\n",
      "Epoch 1347/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 338208254434.8992 - val_loss: 380613882619.3193\n",
      "Epoch 1348/5000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 343667228533.6995 - val_loss: 367468553794.3943\n",
      "Epoch 1349/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 340639915492.6281 - val_loss: 369831511785.1724\n",
      "Epoch 1350/5000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 341271025734.3027 - val_loss: 373519434843.3102\n",
      "Epoch 1351/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 336428265677.1458 - val_loss: 401702145585.9758\n",
      "Epoch 1352/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 338844045858.2870 - val_loss: 367844857495.9437\n",
      "Epoch 1353/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 333207646975.5679 - val_loss: 369863456342.2695\n",
      "Epoch 1354/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 341139945841.9539 - val_loss: 370958072793.6900\n",
      "Epoch 1355/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 337584568385.6927 - val_loss: 369438789568.3420\n",
      "Epoch 1356/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 339412797743.1086 - val_loss: 369498977835.3508\n",
      "Epoch 1357/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 334426822117.7805 - val_loss: 369151485300.4422\n",
      "Epoch 1358/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 333804623730.2420 - val_loss: 366211266112.0900\n",
      "Epoch 1359/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 336698733744.9094 - val_loss: 379541527310.3303\n",
      "Epoch 1360/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 338181852351.8920 - val_loss: 367362946739.5961\n",
      "Epoch 1361/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 337176234277.8885 - val_loss: 366876363796.7393\n",
      "Epoch 1362/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 337491457956.9522 - val_loss: 364647918922.9637\n",
      "Epoch 1363/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 334887451906.7372 - val_loss: 367226804339.5060\n",
      "Epoch 1364/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 336501094822.9691 - val_loss: 375503674153.4065\n",
      "Epoch 1365/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 334618008396.7856 - val_loss: 367768606253.6552\n",
      "Epoch 1366/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 334669479161.5172 - val_loss: 371604539081.7755\n",
      "Epoch 1367/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 332553105313.4946 - val_loss: 364244578588.0124\n",
      "Epoch 1368/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 338818612464.2971 - val_loss: 374289362180.3927\n",
      "Epoch 1369/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 333937874350.4603 - val_loss: 362852674038.3505\n",
      "Epoch 1370/5000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 336344699071.3157 - val_loss: 367567314337.0892\n",
      "Epoch 1371/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 333682347771.5340 - val_loss: 389589440586.3156\n",
      "Epoch 1372/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 337008758357.5735 - val_loss: 374715571928.7538\n",
      "Epoch 1373/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 335129243668.7451 - val_loss: 367936714033.6157\n",
      "Epoch 1374/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 330862928300.7316 - val_loss: 365937255249.1567\n",
      "Epoch 1375/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 331904488823.1401 - val_loss: 363656519330.0253\n",
      "Epoch 1376/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 335141182469.1862 - val_loss: 364453888989.7227\n",
      "Epoch 1377/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 333414040123.6421 - val_loss: 363110937191.8402\n",
      "Epoch 1378/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 330595787282.1519 - val_loss: 362929119166.9019\n",
      "Epoch 1379/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 332736156318.7574 - val_loss: 374368659596.2779\n",
      "Epoch 1380/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 335026402056.7878 - val_loss: 366014957433.4830\n",
      "Epoch 1381/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 329830636530.7462 - val_loss: 384025007840.5311\n",
      "Epoch 1382/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 333688916907.2909 - val_loss: 374297636340.6222\n",
      "Epoch 1383/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 333150009515.7231 - val_loss: 364974496710.9671\n",
      "Epoch 1384/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 102us/step - loss: 331868156524.0472 - val_loss: 363285917156.2037\n",
      "Epoch 1385/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 331937874712.9229 - val_loss: 363448561980.2734\n",
      "Epoch 1386/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 331745021544.0135 - val_loss: 376364648530.0928\n",
      "Epoch 1387/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 331091616383.0276 - val_loss: 369747599542.9086\n",
      "Epoch 1388/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 328534955032.7788 - val_loss: 360376519393.6833\n",
      "Epoch 1389/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 328534835430.5009 - val_loss: 360530973959.2731\n",
      "Epoch 1390/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 334260727243.2729 - val_loss: 362166391492.5907\n",
      "Epoch 1391/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 330936857832.2296 - val_loss: 363182971702.0804\n",
      "Epoch 1392/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 331450929808.9274 - val_loss: 369229924886.0355\n",
      "Epoch 1393/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 328698238400.9004 - val_loss: 392711365306.7972\n",
      "Epoch 1394/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 334844429783.9505 - val_loss: 360972677568.1981\n",
      "Epoch 1395/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 330350766221.7580 - val_loss: 369642104675.8796\n",
      "Epoch 1396/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 333680242496.6843 - val_loss: 375232627452.4714\n",
      "Epoch 1397/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 333790330105.5172 - val_loss: 381957790902.9086\n",
      "Epoch 1398/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 338852846232.9949 - val_loss: 360459559469.6552\n",
      "Epoch 1399/5000\n",
      "3554/3554 [==============================] - 0s 131us/step - loss: 325646977502.2892 - val_loss: 361296771653.8509\n",
      "Epoch 1400/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 325518869116.1823 - val_loss: 389034220395.0807\n",
      "Epoch 1401/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 334135513666.5571 - val_loss: 358874736724.6852\n",
      "Epoch 1402/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 328019653638.3388 - val_loss: 357632091713.5302\n",
      "Epoch 1403/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 326831407807.0276 - val_loss: 358619528380.6695\n",
      "Epoch 1404/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 327976407895.1581 - val_loss: 358922026518.8996\n",
      "Epoch 1405/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 325358054135.5003 - val_loss: 358694088542.6948\n",
      "Epoch 1406/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 325704598711.8245 - val_loss: 360666427323.4453\n",
      "Epoch 1407/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 330019268892.6685 - val_loss: 379590601469.6237\n",
      "Epoch 1408/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 328514875836.8666 - val_loss: 361089433542.3910\n",
      "Epoch 1409/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 326592638770.8542 - val_loss: 357298471402.8287\n",
      "Epoch 1410/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 325001806046.1452 - val_loss: 364788389401.2039\n",
      "Epoch 1411/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 335453759703.5182 - val_loss: 440931174753.1432\n",
      "Epoch 1412/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 335103922819.0974 - val_loss: 358507278711.6107\n",
      "Epoch 1413/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 325226190943.6578 - val_loss: 359697845867.5848\n",
      "Epoch 1414/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 326727809486.1542 - val_loss: 358852778985.2444\n",
      "Epoch 1415/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 323720737655.4282 - val_loss: 355866403646.4338\n",
      "Epoch 1416/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 326508865078.4559 - val_loss: 355514510707.0020\n",
      "Epoch 1417/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 327357234047.4958 - val_loss: 361279834492.2194\n",
      "Epoch 1418/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 326196875971.6376 - val_loss: 356183345319.9302\n",
      "Epoch 1419/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 326319563844.5740 - val_loss: 363977022610.3268\n",
      "Epoch 1420/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 328999586058.2285 - val_loss: 360704432928.1890\n",
      "Epoch 1421/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 323581115561.9944 - val_loss: 357548262649.1589\n",
      "Epoch 1422/5000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 321475938210.05 - 0s 86us/step - loss: 322036350948.3399 - val_loss: 378641314014.3707\n",
      "Epoch 1423/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 328399732634.5797 - val_loss: 366348537340.3994\n",
      "Epoch 1424/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 324020102664.3557 - val_loss: 354455801813.6574\n",
      "Epoch 1425/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 322912287495.6353 - val_loss: 357251557588.8652\n",
      "Epoch 1426/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 324553072769.0805 - val_loss: 364158714193.0126\n",
      "Epoch 1427/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 328266455147.1829 - val_loss: 354911198690.4754\n",
      "Epoch 1428/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 323876704723.9167 - val_loss: 363167944254.6498\n",
      "Epoch 1429/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 326103014312.9860 - val_loss: 355344769908.5862\n",
      "Epoch 1430/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 324238562651.4800 - val_loss: 365032203682.5294\n",
      "Epoch 1431/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 326542175133.4609 - val_loss: 356461599923.1640\n",
      "Epoch 1432/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 323704935845.2403 - val_loss: 358958325228.8450\n",
      "Epoch 1433/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 327241049408.6843 - val_loss: 359338147098.2841\n",
      "Epoch 1434/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 321077435304.9860 - val_loss: 353490566333.5336\n",
      "Epoch 1435/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 328315443860.3849 - val_loss: 353321778847.7209\n",
      "Epoch 1436/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 324760199670.4918 - val_loss: 352779061150.9288\n",
      "Epoch 1437/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 326002566378.5346 - val_loss: 356181572270.1232\n",
      "Epoch 1438/5000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 325130981748.36 - 0s 85us/step - loss: 324663777783.6443 - val_loss: 359199347041.1432\n",
      "Epoch 1439/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 321525110974.1631 - val_loss: 360533526687.2889\n",
      "Epoch 1440/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 323062814202.3815 - val_loss: 353555022778.0051\n",
      "Epoch 1441/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 323709368049.1615 - val_loss: 375620864059.4813\n",
      "Epoch 1442/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 319711347573.1232 - val_loss: 376820375497.8475\n",
      "Epoch 1443/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 323356013938.5301 - val_loss: 353525780083.0740\n",
      "Epoch 1444/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 321449050231.8605 - val_loss: 367227202654.7668\n",
      "Epoch 1445/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 319934105893.8885 - val_loss: 352794223321.1859\n",
      "Epoch 1446/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 84us/step - loss: 321881223843.3675 - val_loss: 356004060679.3452\n",
      "Epoch 1447/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 322682781640.6797 - val_loss: 354581370256.0945\n",
      "Epoch 1448/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 328548598285.5419 - val_loss: 359216164257.9533\n",
      "Epoch 1449/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 324878674089.4181 - val_loss: 353808653809.4537\n",
      "Epoch 1450/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 320233499134.5593 - val_loss: 353668668783.1133\n",
      "Epoch 1451/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 320723191069.2448 - val_loss: 352222181276.3364\n",
      "Epoch 1452/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 319615496673.7468 - val_loss: 350838695018.5767\n",
      "Epoch 1453/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 322783369562.9037 - val_loss: 392557580597.9364\n",
      "Epoch 1454/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 321183766695.1131 - val_loss: 351158417091.4385\n",
      "Epoch 1455/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 322063631377.8638 - val_loss: 356484567802.1671\n",
      "Epoch 1456/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 322070831461.2763 - val_loss: 353508848083.7851\n",
      "Epoch 1457/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 324158534646.2037 - val_loss: 352770735690.7477\n",
      "Epoch 1458/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 320769560831.8560 - val_loss: 355369000056.4028\n",
      "Epoch 1459/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 319941182389.6635 - val_loss: 351428622826.2526\n",
      "Epoch 1460/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 319287423070.5054 - val_loss: 351597925336.8259\n",
      "Epoch 1461/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 318135205922.7192 - val_loss: 352032470384.9857\n",
      "Epoch 1462/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 325704935623.3832 - val_loss: 365765634930.8580\n",
      "Epoch 1463/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 318945344563.2864 - val_loss: 350827000117.7924\n",
      "Epoch 1464/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 318818001306.2915 - val_loss: 354578935919.7615\n",
      "Epoch 1465/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 320494361171.8447 - val_loss: 352810203463.7952\n",
      "Epoch 1466/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 317105813698.7732 - val_loss: 352691641810.3448\n",
      "Epoch 1467/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 319377253716.5650 - val_loss: 369511348830.0467\n",
      "Epoch 1468/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 319393405957.1862 - val_loss: 359137354160.0675\n",
      "Epoch 1469/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 318756919264.8824 - val_loss: 349186261688.2048\n",
      "Epoch 1470/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 318841785019.5701 - val_loss: 356647886748.3364\n",
      "Epoch 1471/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 323603039738.5256 - val_loss: 350407939378.4799\n",
      "Epoch 1472/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 315265165232.4772 - val_loss: 347412125120.4861\n",
      "Epoch 1473/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 318798418535.4372 - val_loss: 351707903607.9708\n",
      "Epoch 1474/5000\n",
      "3554/3554 [==============================] - 0s 125us/step - loss: 318616955160.0585 - val_loss: 354665688046.4293\n",
      "Epoch 1475/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 318201960997.7445 - val_loss: 356173379628.3589\n",
      "Epoch 1476/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 319336657626.6877 - val_loss: 353890200189.1556\n",
      "Epoch 1477/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 316508384111.3607 - val_loss: 368214897080.9969\n",
      "Epoch 1478/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 322793235284.8531 - val_loss: 349188479874.1243\n",
      "Epoch 1479/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 319313411026.4761 - val_loss: 357486264088.4118\n",
      "Epoch 1480/5000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 316446620727.8964 - val_loss: 349446104879.1674\n",
      "Epoch 1481/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 319944642520.8149 - val_loss: 363577031666.1738\n",
      "Epoch 1482/5000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 318248894989.5419 - val_loss: 350214887381.6574\n",
      "Epoch 1483/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 315785498280.5538 - val_loss: 356560667995.0942\n",
      "Epoch 1484/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 316241274699.0568 - val_loss: 363221157657.8521\n",
      "Epoch 1485/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 317462107926.0416 - val_loss: 347723698566.5891\n",
      "Epoch 1486/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 315409261894.7350 - val_loss: 349647841652.1542\n",
      "Epoch 1487/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 323491032555.5430 - val_loss: 351276472939.2968\n",
      "Epoch 1488/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 320272079453.0648 - val_loss: 349350706778.3021\n",
      "Epoch 1489/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 315248536818.6022 - val_loss: 347263802128.0585\n",
      "Epoch 1490/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 312744196862.4153 - val_loss: 359153663146.2346\n",
      "Epoch 1491/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 315054438816.0540 - val_loss: 348073710917.4908\n",
      "Epoch 1492/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 316230618349.9921 - val_loss: 352863605796.5817\n",
      "Epoch 1493/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 311630964545.8368 - val_loss: 349608923100.8585\n",
      "Epoch 1494/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 314319059267.8537 - val_loss: 347397322580.9012\n",
      "Epoch 1495/5000\n",
      "3554/3554 [==============================] - 1s 144us/step - loss: 316144338786.1069 - val_loss: 352289908937.0554\n",
      "Epoch 1496/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 316139602639.1627 - val_loss: 349726346312.8754\n",
      "Epoch 1497/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 315717596705.7108 - val_loss: 356806874503.4532\n",
      "Epoch 1498/5000\n",
      "3554/3554 [==============================] - 0s 127us/step - loss: 315823430181.7445 - val_loss: 351519166612.6312\n",
      "Epoch 1499/5000\n",
      "3554/3554 [==============================] - 0s 128us/step - loss: 316676900816.7473 - val_loss: 347076088760.8529\n",
      "Epoch 1500/5000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 311912838883.3314 - val_loss: 351235244500.9373\n",
      "Epoch 1501/5000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 316208378798.7485 - val_loss: 356368930051.5286\n",
      "Epoch 1502/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 318925138181.6185 - val_loss: 348866496023.0436\n",
      "Epoch 1503/5000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 313373648765.7670 - val_loss: 348448337031.3812\n",
      "Epoch 1504/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 311588876400.9454 - val_loss: 362172335565.7361\n",
      "Epoch 1505/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 315341507720.5717 - val_loss: 357217200176.1035\n",
      "Epoch 1506/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 315009975092.5830 - val_loss: 346946434508.8720\n",
      "Epoch 1507/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 312093050947.9977 - val_loss: 346814503024.9136\n",
      "Epoch 1508/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 313640817264.6573 - val_loss: 355551636264.8304\n",
      "Epoch 1509/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 83us/step - loss: 314458144947.7906 - val_loss: 346872545288.3533\n",
      "Epoch 1510/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 315046205279.8019 - val_loss: 352065185343.2259\n",
      "Epoch 1511/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 314297194750.7034 - val_loss: 350696718084.2487\n",
      "Epoch 1512/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 327348696863.2617 - val_loss: 345753697421.1420\n",
      "Epoch 1513/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 312076809134.7485 - val_loss: 347985433729.3322\n",
      "Epoch 1514/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 311639709978.3635 - val_loss: 347814452377.5280\n",
      "Epoch 1515/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 315250772851.9708 - val_loss: 345428746046.4338\n",
      "Epoch 1516/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 312164583071.3337 - val_loss: 348949071086.7893\n",
      "Epoch 1517/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 312275246140.5065 - val_loss: 353816716433.4627\n",
      "Epoch 1518/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 313591510437.2403 - val_loss: 345313941359.6895\n",
      "Epoch 1519/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 316749397370.5977 - val_loss: 351769408948.6762\n",
      "Epoch 1520/5000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 314094775918.9285 - val_loss: 348884316674.7365\n",
      "Epoch 1521/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 310903564033.2966 - val_loss: 349559411185.1657\n",
      "Epoch 1522/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 314911743746.4490 - val_loss: 356103130404.3657\n",
      "Epoch 1523/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 310720671561.9043 - val_loss: 345407540204.7010\n",
      "Epoch 1524/5000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 310441945770.66 - 0s 85us/step - loss: 310601191938.0168 - val_loss: 357491441331.0200\n",
      "Epoch 1525/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 312045305229.0377 - val_loss: 362887530735.3654\n",
      "Epoch 1526/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 313736648267.2009 - val_loss: 364034008633.4650\n",
      "Epoch 1527/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 317771610067.0523 - val_loss: 346538971709.2095\n",
      "Epoch 1528/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 310050082251.2729 - val_loss: 374533315103.2529\n",
      "Epoch 1529/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 312260464361.0940 - val_loss: 345092438370.8715\n",
      "Epoch 1530/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 315282993311.0456 - val_loss: 345672762256.5266\n",
      "Epoch 1531/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 311674989598.5414 - val_loss: 352146270470.6970\n",
      "Epoch 1532/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 315364340193.7468 - val_loss: 346479940779.0988\n",
      "Epoch 1533/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 309269902005.8076 - val_loss: 349149858166.4585\n",
      "Epoch 1534/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 312718745341.8391 - val_loss: 344691380001.6293\n",
      "Epoch 1535/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 311360335505.5037 - val_loss: 343773333884.7955\n",
      "Epoch 1536/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 310738077192.3557 - val_loss: 356684653880.5288\n",
      "Epoch 1537/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 309042204775.7254 - val_loss: 348409568991.0909\n",
      "Epoch 1538/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 309340013369.1930 - val_loss: 343011117255.9033\n",
      "Epoch 1539/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 309955816118.9600 - val_loss: 346132503343.1674\n",
      "Epoch 1540/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 310109710606.8385 - val_loss: 350059665191.9662\n",
      "Epoch 1541/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 309165595035.4440 - val_loss: 344239818181.0948\n",
      "Epoch 1542/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 311679862533.9066 - val_loss: 344975063585.8453\n",
      "Epoch 1543/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 312803557873.8818 - val_loss: 344202296880.8236\n",
      "Epoch 1544/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 313672045535.1536 - val_loss: 344646678433.2332\n",
      "Epoch 1545/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 309999845569.6207 - val_loss: 343971498124.5660\n",
      "Epoch 1546/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 309915659744.0180 - val_loss: 346680732198.1660\n",
      "Epoch 1547/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 312505307318.0957 - val_loss: 342797816020.0011\n",
      "Epoch 1548/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 312719870559.3698 - val_loss: 357590416399.8425\n",
      "Epoch 1549/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 308281202159.0005 - val_loss: 349460202881.1161\n",
      "Epoch 1550/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 310132067123.4305 - val_loss: 341059281801.3254\n",
      "Epoch 1551/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 308170101554.2780 - val_loss: 348816650761.9376\n",
      "Epoch 1552/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 306277630678.6539 - val_loss: 343984748265.7485\n",
      "Epoch 1553/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 308910285947.8942 - val_loss: 344326898516.0371\n",
      "Epoch 1554/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 307936862443.1108 - val_loss: 345154429094.4900\n",
      "Epoch 1555/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 310717579890.9623 - val_loss: 347296471689.2534\n",
      "Epoch 1556/5000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 312963476865.5126 - val_loss: 381901344784.4186\n",
      "Epoch 1557/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 311246026163.0703 - val_loss: 359618166857.7395\n",
      "Epoch 1558/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 314716417515.5431 - val_loss: 349222149026.9615\n",
      "Epoch 1559/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 320212379863.5182 - val_loss: 340972464944.3196\n",
      "Epoch 1560/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 306365492339.8987 - val_loss: 340563472090.7702\n",
      "Epoch 1561/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 305498676293.7265 - val_loss: 346550338967.5837\n",
      "Epoch 1562/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 308363833613.6860 - val_loss: 359478937222.6610\n",
      "Epoch 1563/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 308474230065.9899 - val_loss: 344442807343.8155\n",
      "Epoch 1564/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 311769878744.6708 - val_loss: 341851529547.5398\n",
      "Epoch 1565/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 308141918409.6882 - val_loss: 349481098568.0833\n",
      "Epoch 1566/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 308834973674.1024 - val_loss: 357688715968.5581\n",
      "Epoch 1567/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 307493728221.4249 - val_loss: 343157066205.8666\n",
      "Epoch 1568/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 308267972332.5515 - val_loss: 345834895936.9542\n",
      "Epoch 1569/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 308724700608.9004 - val_loss: 349124058853.1398\n",
      "Epoch 1570/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 306417461767.7794 - val_loss: 339855000571.1032\n",
      "Epoch 1571/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 308851460601.9493 - val_loss: 346838841024.5581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1572/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 308029226242.7372 - val_loss: 346485189169.1117\n",
      "Epoch 1573/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 309204494087.0591 - val_loss: 340905898543.3834\n",
      "Epoch 1574/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 304713192518.8790 - val_loss: 345915146952.3353\n",
      "Epoch 1575/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 306038698908.3084 - val_loss: 343502379068.4894\n",
      "Epoch 1576/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 307677030025.4362 - val_loss: 341065449375.7930\n",
      "Epoch 1577/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 308563795640.6888 - val_loss: 341533095866.2931\n",
      "Epoch 1578/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 313865436649.2380 - val_loss: 346979871155.5240\n",
      "Epoch 1579/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 307267195828.5110 - val_loss: 340356996286.9738\n",
      "Epoch 1580/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 302552859278.6224 - val_loss: 346894897601.3502\n",
      "Epoch 1581/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 319301236893.8931 - val_loss: 353887696541.4166\n",
      "Epoch 1582/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 311476674472.4097 - val_loss: 341449929916.0934\n",
      "Epoch 1583/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 303897445716.5650 - val_loss: 352831609969.7778\n",
      "Epoch 1584/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 306903267024.8914 - val_loss: 345406473196.7010\n",
      "Epoch 1585/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 303864348960.1260 - val_loss: 351098610333.7047\n",
      "Epoch 1586/5000\n",
      "3554/3554 [==============================] - 0s 136us/step - loss: 305670918307.6556 - val_loss: 339044742857.4875\n",
      "Epoch 1587/5000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 305848692285.3708 - val_loss: 343354754314.4417\n",
      "Epoch 1588/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 304373217792.8644 - val_loss: 339258488257.6382\n",
      "Epoch 1589/5000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 303474445549.9921 - val_loss: 338376959873.8363\n",
      "Epoch 1590/5000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 304611032198.2667 - val_loss: 348898226200.4838\n",
      "Epoch 1591/5000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 305991995836.8666 - val_loss: 339776104451.1685\n",
      "Epoch 1592/5000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 304097586192.7113 - val_loss: 348264860120.9699\n",
      "Epoch 1593/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 304395207730.1339 - val_loss: 345213120907.3418\n",
      "Epoch 1594/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 304757512663.3742 - val_loss: 342629651044.3837\n",
      "Epoch 1595/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 303222200611.5836 - val_loss: 342078885811.9561\n",
      "Epoch 1596/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 307573359041.4767 - val_loss: 338124899103.0369\n",
      "Epoch 1597/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 306402731399.2751 - val_loss: 342967408443.2653\n",
      "Epoch 1598/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 301750885805.3078 - val_loss: 372638784420.6898\n",
      "Epoch 1599/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 306920515430.7169 - val_loss: 341473090625.0981\n",
      "Epoch 1600/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 301451237105.1615 - val_loss: 342827192826.9592\n",
      "Epoch 1601/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 304706461672.9499 - val_loss: 342173346207.0729\n",
      "Epoch 1602/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 302382624336.9634 - val_loss: 337575677780.3252\n",
      "Epoch 1603/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 302920308861.6230 - val_loss: 337481485534.9468\n",
      "Epoch 1604/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 304352505876.7451 - val_loss: 355719940535.2686\n",
      "Epoch 1605/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 301586318197.1232 - val_loss: 340094513001.0644\n",
      "Epoch 1606/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 305409298411.2549 - val_loss: 337122222817.1072\n",
      "Epoch 1607/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 310048052460.8396 - val_loss: 352651566707.6501\n",
      "Epoch 1608/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 308447246161.9719 - val_loss: 338837566950.5080\n",
      "Epoch 1609/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 301010140141.5599 - val_loss: 345157516172.4940\n",
      "Epoch 1610/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 302492128077.9381 - val_loss: 339440722075.5443\n",
      "Epoch 1611/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 303582292275.7186 - val_loss: 343136004658.8400\n",
      "Epoch 1612/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 303045200783.6309 - val_loss: 338586530573.1780\n",
      "Epoch 1613/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 304859856481.0985 - val_loss: 340511421741.8712\n",
      "Epoch 1614/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 300393075589.2583 - val_loss: 338163492628.3792\n",
      "Epoch 1615/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 306586352548.3759 - val_loss: 337003225609.3615\n",
      "Epoch 1616/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 299844980522.7867 - val_loss: 346170859708.6695\n",
      "Epoch 1617/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 306286585324.6956 - val_loss: 340324148761.4920\n",
      "Epoch 1618/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 300796733143.8064 - val_loss: 341951912839.3091\n",
      "Epoch 1619/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 302582312888.5447 - val_loss: 336339200053.5764\n",
      "Epoch 1620/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 306692708800.3242 - val_loss: 338122934535.2731\n",
      "Epoch 1621/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 305581210866.6022 - val_loss: 338462142078.0197\n",
      "Epoch 1622/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 305123636115.0883 - val_loss: 335626311978.9907\n",
      "Epoch 1623/5000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 306071591037.6230 - val_loss: 339713458715.2203\n",
      "Epoch 1624/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 299187141710.9465 - val_loss: 336865059513.9330\n",
      "Epoch 1625/5000\n",
      "3554/3554 [==============================] - ETA: 0s - loss: 297132074002.61 - 0s 85us/step - loss: 299485048530.0439 - val_loss: 350492766933.8734\n",
      "Epoch 1626/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 305747094005.3393 - val_loss: 335718237421.3491\n",
      "Epoch 1627/5000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 302622795705.6973 - val_loss: 340661162802.0478\n",
      "Epoch 1628/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 300204868939.3450 - val_loss: 347121183011.5015\n",
      "Epoch 1629/5000\n",
      "3554/3554 [==============================] - 0s 104us/step - loss: 299298096069.7985 - val_loss: 341696560426.7027\n",
      "Epoch 1630/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 301545469316.9702 - val_loss: 345925177633.1972\n",
      "Epoch 1631/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 301199207620.5020 - val_loss: 336015718457.3210\n",
      "Epoch 1632/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 303697678047.8740 - val_loss: 353313261428.0101\n",
      "Epoch 1633/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 301116257088.1080 - val_loss: 339914375918.0692\n",
      "Epoch 1634/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 84us/step - loss: 299007266029.9921 - val_loss: 339490106235.7874\n",
      "Epoch 1635/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 302421196486.5189 - val_loss: 336336888126.0017\n",
      "Epoch 1636/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 300007011016.2476 - val_loss: 335068761319.3002\n",
      "Epoch 1637/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 300762639528.8419 - val_loss: 339860387100.5884\n",
      "Epoch 1638/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 301202887873.0445 - val_loss: 334088299221.8734\n",
      "Epoch 1639/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 301989360650.9488 - val_loss: 339826658406.2560\n",
      "Epoch 1640/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 300905817184.2341 - val_loss: 334533586103.1966\n",
      "Epoch 1641/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 304071357188.1779 - val_loss: 361864800381.0115\n",
      "Epoch 1642/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 300819637487.7209 - val_loss: 333757095417.5190\n",
      "Epoch 1643/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 298944121835.8312 - val_loss: 346383195801.6720\n",
      "Epoch 1644/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 301880963692.0473 - val_loss: 332262618144.5491\n",
      "Epoch 1645/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 295471288059.5341 - val_loss: 337315868321.7372\n",
      "Epoch 1646/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 303645016059.3900 - val_loss: 339092165915.7243\n",
      "Epoch 1647/5000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 295578992326.5189 - val_loss: 333845599367.6692\n",
      "Epoch 1648/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 296699200594.4041 - val_loss: 340404776890.8692\n",
      "Epoch 1649/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 300837364454.2127 - val_loss: 340039278688.7831\n",
      "Epoch 1650/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 299519779217.0715 - val_loss: 339574401064.9024\n",
      "Epoch 1651/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 298997694731.3810 - val_loss: 351663157570.0343\n",
      "Epoch 1652/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 296601623400.4457 - val_loss: 331936539667.2990\n",
      "Epoch 1653/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 293771562157.4519 - val_loss: 333877177751.0076\n",
      "Epoch 1654/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 298646847149.1638 - val_loss: 358419358225.7148\n",
      "Epoch 1655/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 298688611050.8228 - val_loss: 336545038524.9575\n",
      "Epoch 1656/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 295669264847.3067 - val_loss: 330714482162.0298\n",
      "Epoch 1657/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 294574157756.0023 - val_loss: 334387599359.4239\n",
      "Epoch 1658/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 294033789027.1154 - val_loss: 365713268473.3030\n",
      "Epoch 1659/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 293621071281.9178 - val_loss: 346123295290.9052\n",
      "Epoch 1660/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 298517020552.1395 - val_loss: 331736465461.2883\n",
      "Epoch 1661/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 294734444019.6106 - val_loss: 328402454707.7401\n",
      "Epoch 1662/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 295198627052.8396 - val_loss: 337424773847.3137\n",
      "Epoch 1663/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 294230616768.1801 - val_loss: 329713879510.0895\n",
      "Epoch 1664/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 293401110337.8368 - val_loss: 329662553706.4326\n",
      "Epoch 1665/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 293472497564.8846 - val_loss: 338163959689.9016\n",
      "Epoch 1666/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 290418981925.4564 - val_loss: 327774214890.0366\n",
      "Epoch 1667/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 290104688962.7012 - val_loss: 340096526199.4667\n",
      "Epoch 1668/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 296625835811.8717 - val_loss: 325475763397.3109\n",
      "Epoch 1669/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 285352147950.1362 - val_loss: 324138877483.3508\n",
      "Epoch 1670/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 285873159057.9359 - val_loss: 371541144964.5727\n",
      "Epoch 1671/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 286961328582.0867 - val_loss: 328331110914.7365\n",
      "Epoch 1672/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 288129406410.1204 - val_loss: 326202357385.2534\n",
      "Epoch 1673/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 282657289226.9488 - val_loss: 324002911325.0385\n",
      "Epoch 1674/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 286144634856.9499 - val_loss: 320924030784.4501\n",
      "Epoch 1675/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 282069140101.4023 - val_loss: 321463542402.9164\n",
      "Epoch 1676/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 282295099276.7496 - val_loss: 323809267252.5682\n",
      "Epoch 1677/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 278608391475.1424 - val_loss: 313094832759.9708\n",
      "Epoch 1678/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 272584652533.7715 - val_loss: 307278420908.7550\n",
      "Epoch 1679/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 270697342755.8717 - val_loss: 303450500766.2808\n",
      "Epoch 1680/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 264869412970.0304 - val_loss: 299008532121.6720\n",
      "Epoch 1681/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 259798876077.0197 - val_loss: 301667963695.7435\n",
      "Epoch 1682/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 256204358139.1019 - val_loss: 290952821279.2529\n",
      "Epoch 1683/5000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 254390995532.9297 - val_loss: 287524440884.9283\n",
      "Epoch 1684/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 251371126304.5583 - val_loss: 281516825430.3415\n",
      "Epoch 1685/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 249231044702.5053 - val_loss: 275880653830.0490\n",
      "Epoch 1686/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 239363765995.3990 - val_loss: 275450059641.4830\n",
      "Epoch 1687/5000\n",
      "3554/3554 [==============================] - 0s 117us/step - loss: 235069563806.6134 - val_loss: 289722253823.5679\n",
      "Epoch 1688/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 232617238846.0912 - val_loss: 263602843769.5550\n",
      "Epoch 1689/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 229937574425.0670 - val_loss: 265577755719.7232\n",
      "Epoch 1690/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 229953169448.3376 - val_loss: 260401399704.8799\n",
      "Epoch 1691/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 224897466755.2414 - val_loss: 254605912106.6307\n",
      "Epoch 1692/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 223393593870.6944 - val_loss: 259968637767.9392\n",
      "Epoch 1693/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 218229531329.3326 - val_loss: 256189253176.3128\n",
      "Epoch 1694/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 216700401563.7321 - val_loss: 249475665548.9980\n",
      "Epoch 1695/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 216519066448.2431 - val_loss: 252069470868.1992\n",
      "Epoch 1696/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 210931738249.4361 - val_loss: 244635534984.9654\n",
      "Epoch 1697/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 81us/step - loss: 210793887572.2769 - val_loss: 246465575686.8411\n",
      "Epoch 1698/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 210552922771.2324 - val_loss: 240316416841.0914\n",
      "Epoch 1699/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 207048570862.7124 - val_loss: 235626554235.7874\n",
      "Epoch 1700/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 206229292298.8047 - val_loss: 234641987730.9030\n",
      "Epoch 1701/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 206009613773.5779 - val_loss: 241470644931.4385\n",
      "Epoch 1702/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 207690853683.1424 - val_loss: 235048710495.4149\n",
      "Epoch 1703/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 203236741292.8756 - val_loss: 232306630475.1077\n",
      "Epoch 1704/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 202280518678.4738 - val_loss: 263987935344.3376\n",
      "Epoch 1705/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 203091794128.6033 - val_loss: 227724156191.7570\n",
      "Epoch 1706/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 200407501121.5487 - val_loss: 241265849301.6574\n",
      "Epoch 1707/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 197915527155.3224 - val_loss: 238809371147.0897\n",
      "Epoch 1708/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 196965283002.1294 - val_loss: 226870535306.5497\n",
      "Epoch 1709/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 197359763843.2414 - val_loss: 223046557162.5406\n",
      "Epoch 1710/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 198725790072.8689 - val_loss: 237127761759.8470\n",
      "Epoch 1711/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 198584292681.0400 - val_loss: 224449091422.1187\n",
      "Epoch 1712/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 195134973319.2752 - val_loss: 244371973152.5491\n",
      "Epoch 1713/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 196358380549.1863 - val_loss: 224639575739.6613\n",
      "Epoch 1714/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 192106062788.6460 - val_loss: 223088536015.7525\n",
      "Epoch 1715/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 192702685727.9820 - val_loss: 222431882679.8447\n",
      "Epoch 1716/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 191344972686.4783 - val_loss: 217951358100.3432\n",
      "Epoch 1717/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 195802504916.3489 - val_loss: 221772132307.0650\n",
      "Epoch 1718/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 196322657380.8441 - val_loss: 222642932372.7752\n",
      "Epoch 1719/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 191962028498.7642 - val_loss: 224512100509.2726\n",
      "Epoch 1720/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 195035469553.1615 - val_loss: 218514946802.1018\n",
      "Epoch 1721/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 190263074471.9775 - val_loss: 227874609530.4911\n",
      "Epoch 1722/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 189333374755.8717 - val_loss: 217306432886.7466\n",
      "Epoch 1723/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 192038439169.0084 - val_loss: 215882299802.7522\n",
      "Epoch 1724/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 190342185121.3506 - val_loss: 217366944653.6461\n",
      "Epoch 1725/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 189924386201.7152 - val_loss: 223514940764.2464\n",
      "Epoch 1726/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 192518231839.2617 - val_loss: 219338846445.3491\n",
      "Epoch 1727/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 190911017331.1064 - val_loss: 216403324150.2785\n",
      "Epoch 1728/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 189216914570.8768 - val_loss: 219240717697.6923\n",
      "Epoch 1729/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 190202620562.0799 - val_loss: 244377224953.8791\n",
      "Epoch 1730/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 190463485005.7940 - val_loss: 215605621580.5480\n",
      "Epoch 1731/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 189267265567.1176 - val_loss: 214200233769.6945\n",
      "Epoch 1732/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 187530582637.1998 - val_loss: 211793051712.5221\n",
      "Epoch 1733/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 186843086227.9527 - val_loss: 237832702952.6684\n",
      "Epoch 1734/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 188441494721.0445 - val_loss: 216575004637.4346\n",
      "Epoch 1735/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 188191588799.1717 - val_loss: 213750494537.8115\n",
      "Epoch 1736/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 186148121833.3821 - val_loss: 212029430564.7978\n",
      "Epoch 1737/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 188474807034.9578 - val_loss: 246289801146.8692\n",
      "Epoch 1738/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 186042353874.9083 - val_loss: 211217734600.4073\n",
      "Epoch 1739/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 187597899839.3877 - val_loss: 216574419755.1347\n",
      "Epoch 1740/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 185078481596.7226 - val_loss: 211625612534.8546\n",
      "Epoch 1741/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 186479289810.1880 - val_loss: 215084852958.2267\n",
      "Epoch 1742/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 183704063481.3731 - val_loss: 210480459815.1741\n",
      "Epoch 1743/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 185732836815.8829 - val_loss: 216657833293.8442\n",
      "Epoch 1744/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 186484074213.6365 - val_loss: 213116201421.4481\n",
      "Epoch 1745/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 187275412106.0124 - val_loss: 213288831421.3176\n",
      "Epoch 1746/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 186698611902.7394 - val_loss: 210086000209.6608\n",
      "Epoch 1747/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 187383111776.8104 - val_loss: 237022256442.2571\n",
      "Epoch 1748/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 187037211620.9162 - val_loss: 235444356862.4878\n",
      "Epoch 1749/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 182294606379.5070 - val_loss: 211180153401.7530\n",
      "Epoch 1750/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 182163308700.7406 - val_loss: 208588716047.5544\n",
      "Epoch 1751/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 181605865652.9431 - val_loss: 209935521881.2939\n",
      "Epoch 1752/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 183018002686.7034 - val_loss: 210528567040.2160\n",
      "Epoch 1753/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 184197342960.0090 - val_loss: 228843585098.1716\n",
      "Epoch 1754/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 182831782244.1238 - val_loss: 209558098589.4166\n",
      "Epoch 1755/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 184262978987.0028 - val_loss: 208906131341.3581\n",
      "Epoch 1756/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 180512889084.3984 - val_loss: 210926820131.6456\n",
      "Epoch 1757/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 180204653643.4890 - val_loss: 208304859989.1893\n",
      "Epoch 1758/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 182458860598.7440 - val_loss: 208763025955.8616\n",
      "Epoch 1759/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 180914059087.6669 - val_loss: 210585663998.9919\n",
      "Epoch 1760/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 77us/step - loss: 182084917314.2690 - val_loss: 206801605017.0239\n",
      "Epoch 1761/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 181510675774.6674 - val_loss: 226167032444.5795\n",
      "Epoch 1762/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 181778964171.1289 - val_loss: 206763497529.0329\n",
      "Epoch 1763/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 180050882304.1440 - val_loss: 207892723771.3373\n",
      "Epoch 1764/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 183978073784.6888 - val_loss: 204944428234.4956\n",
      "Epoch 1765/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 183785141839.8109 - val_loss: 206012734676.8653\n",
      "Epoch 1766/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 179295627866.7597 - val_loss: 205927325248.9542\n",
      "Epoch 1767/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 182691486416.3151 - val_loss: 211441851911.3452\n",
      "Epoch 1768/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 179182211890.2780 - val_loss: 208037740992.1980\n",
      "Epoch 1769/5000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 180399214479.0546 - val_loss: 216556014077.8397\n",
      "Epoch 1770/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 178437089818.2195 - val_loss: 210360367011.2495\n",
      "Epoch 1771/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 177370391929.4451 - val_loss: 210338192771.9966\n",
      "Epoch 1772/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 179473743692.2093 - val_loss: 232018507517.3356\n",
      "Epoch 1773/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 180987736301.4159 - val_loss: 203063249574.0580\n",
      "Epoch 1774/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 176363103992.0765 - val_loss: 203325101487.2034\n",
      "Epoch 1775/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 178134196332.3354 - val_loss: 216163131318.2605\n",
      "Epoch 1776/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 177660310276.1778 - val_loss: 205863205239.0346\n",
      "Epoch 1777/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 178378031570.7642 - val_loss: 209046409090.4124\n",
      "Epoch 1778/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 175686961823.9100 - val_loss: 202721330631.3992\n",
      "Epoch 1779/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 176852711010.2510 - val_loss: 202599810339.7896\n",
      "Epoch 1780/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 181320179255.6083 - val_loss: 203922777633.2692\n",
      "Epoch 1781/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 176626993464.3286 - val_loss: 206769292754.9210\n",
      "Epoch 1782/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 177189126614.2217 - val_loss: 201463770413.5831\n",
      "Epoch 1783/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 175569122471.6894 - val_loss: 205682409001.9106\n",
      "Epoch 1784/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 178089771386.0214 - val_loss: 206408204025.3029\n",
      "Epoch 1785/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 176668322786.6111 - val_loss: 204430827404.7820\n",
      "Epoch 1786/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 177209593779.9347 - val_loss: 210717303216.0675\n",
      "Epoch 1787/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 174160696722.8002 - val_loss: 201384879082.3966\n",
      "Epoch 1788/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 176327075104.7023 - val_loss: 201654912042.9187\n",
      "Epoch 1789/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 170039683951.3607 - val_loss: 200259922776.6458\n",
      "Epoch 1790/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 170669011905.7648 - val_loss: 203047948929.7643\n",
      "Epoch 1791/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 168857365449.2560 - val_loss: 194840524802.8805\n",
      "Epoch 1792/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 167301381424.8373 - val_loss: 192602078181.2118\n",
      "Epoch 1793/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 165485290178.4851 - val_loss: 187427629585.4267\n",
      "Epoch 1794/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 160781518561.0264 - val_loss: 190801577001.7665\n",
      "Epoch 1795/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 161401706824.4637 - val_loss: 186504323120.3916\n",
      "Epoch 1796/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 156203258273.2065 - val_loss: 187257102845.2636\n",
      "Epoch 1797/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 156556142696.8779 - val_loss: 205154030299.6343\n",
      "Epoch 1798/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 152603442065.9359 - val_loss: 173284138109.2996\n",
      "Epoch 1799/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 148463331485.8931 - val_loss: 174382675075.6366\n",
      "Epoch 1800/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 146035199642.7237 - val_loss: 169551799438.0062\n",
      "Epoch 1801/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 145351163701.1592 - val_loss: 167615733862.5440\n",
      "Epoch 1802/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 145282010488.2926 - val_loss: 164691212782.8613\n",
      "Epoch 1803/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 140264826045.0107 - val_loss: 189302148223.6039\n",
      "Epoch 1804/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 135479256789.5014 - val_loss: 162315174195.6321\n",
      "Epoch 1805/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 133099692433.0715 - val_loss: 160026171757.8172\n",
      "Epoch 1806/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 132508885588.9972 - val_loss: 162808242523.3823\n",
      "Epoch 1807/5000\n",
      "3554/3554 [==============================] - 0s 115us/step - loss: 130448688975.6669 - val_loss: 153783829087.7750\n",
      "Epoch 1808/5000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 131566965545.0580 - val_loss: 152863057421.1060\n",
      "Epoch 1809/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 126667946458.8317 - val_loss: 151497730687.4599\n",
      "Epoch 1810/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 123025441789.1187 - val_loss: 149877407420.2374\n",
      "Epoch 1811/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 122099100540.0383 - val_loss: 160342687833.8701\n",
      "Epoch 1812/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 122955049376.0540 - val_loss: 144644482798.3572\n",
      "Epoch 1813/5000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 120384352318.2352 - val_loss: 149907851286.4675\n",
      "Epoch 1814/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 120315844798.1632 - val_loss: 145687784438.4945\n",
      "Epoch 1815/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 119191976702.4153 - val_loss: 139955059945.0284\n",
      "Epoch 1816/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 118594753735.9595 - val_loss: 135834805628.7955\n",
      "Epoch 1817/5000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 114603283978.6607 - val_loss: 138043087167.7299\n",
      "Epoch 1818/5000\n",
      "3554/3554 [==============================] - 0s 135us/step - loss: 115447023605.6275 - val_loss: 133943602631.9753\n",
      "Epoch 1819/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 112523829330.9803 - val_loss: 140905960137.1994\n",
      "Epoch 1820/5000\n",
      "3554/3554 [==============================] - 0s 121us/step - loss: 110833968191.9640 - val_loss: 132316221791.1269\n",
      "Epoch 1821/5000\n",
      "3554/3554 [==============================] - 1s 164us/step - loss: 110148115713.5847 - val_loss: 129616754886.1750\n",
      "Epoch 1822/5000\n",
      "3554/3554 [==============================] - 0s 135us/step - loss: 107891101324.8936 - val_loss: 129887913507.5736\n",
      "Epoch 1823/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 130us/step - loss: 106656394316.6415 - val_loss: 127689097120.6571\n",
      "Epoch 1824/5000\n",
      "3554/3554 [==============================] - 0s 111us/step - loss: 107096948311.8784 - val_loss: 126220170735.1494\n",
      "Epoch 1825/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 104492984360.3376 - val_loss: 128795458697.9736\n",
      "Epoch 1826/5000\n",
      "3554/3554 [==============================] - 0s 120us/step - loss: 104206202636.8216 - val_loss: 126234126116.2217\n",
      "Epoch 1827/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 102519289580.5515 - val_loss: 141706451199.7840\n",
      "Epoch 1828/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 102461837452.6055 - val_loss: 124147424394.2616\n",
      "Epoch 1829/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 102405835082.7687 - val_loss: 122573208696.9789\n",
      "Epoch 1830/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 99469734014.7755 - val_loss: 124249354884.3567\n",
      "Epoch 1831/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 98331687272.7338 - val_loss: 118839640676.3837\n",
      "Epoch 1832/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 97434955932.7406 - val_loss: 116250430945.0352\n",
      "Epoch 1833/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 98241678709.9876 - val_loss: 116600662131.6501\n",
      "Epoch 1834/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 95513541843.4845 - val_loss: 120561462433.0172\n",
      "Epoch 1835/5000\n",
      "3554/3554 [==============================] - 0s 123us/step - loss: 94800514608.6933 - val_loss: 122502399082.2886\n",
      "Epoch 1836/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 96032799406.3163 - val_loss: 115183277709.7181\n",
      "Epoch 1837/5000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 90531300849.3056 - val_loss: 119216105243.2923\n",
      "Epoch 1838/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 94578995368.2656 - val_loss: 112204956402.9660\n",
      "Epoch 1839/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 94498466947.9617 - val_loss: 110340476977.5437\n",
      "Epoch 1840/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 89843389709.1097 - val_loss: 118092031061.8374\n",
      "Epoch 1841/5000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 91538711426.9533 - val_loss: 109149574235.8864\n",
      "Epoch 1842/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 89127381463.9505 - val_loss: 106518854208.9541\n",
      "Epoch 1843/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 86834498867.1424 - val_loss: 107084223475.3260\n",
      "Epoch 1844/5000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 85430623836.4885 - val_loss: 109081970448.9226\n",
      "Epoch 1845/5000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 89017773976.2746 - val_loss: 104561730292.9823\n",
      "Epoch 1846/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 86746170559.8920 - val_loss: 107386659563.1888\n",
      "Epoch 1847/5000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 85388447465.0940 - val_loss: 103990048144.3826\n",
      "Epoch 1848/5000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 83461883679.2617 - val_loss: 106729269685.5404\n",
      "Epoch 1849/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 85844316959.8379 - val_loss: 104653175368.7314\n",
      "Epoch 1850/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 84524947696.8734 - val_loss: 100943003443.7761\n",
      "Epoch 1851/5000\n",
      "3554/3554 [==============================] - 0s 137us/step - loss: 83247459553.0265 - val_loss: 103511056174.1592\n",
      "Epoch 1852/5000\n",
      "3554/3554 [==============================] - 0s 122us/step - loss: 82879604914.6382 - val_loss: 101388932433.0127\n",
      "Epoch 1853/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 81565280360.8779 - val_loss: 101221046485.7294\n",
      "Epoch 1854/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 82293951965.7130 - val_loss: 102699548474.1131\n",
      "Epoch 1855/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 81344313549.4339 - val_loss: 115907038585.6270\n",
      "Epoch 1856/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 82679637062.0146 - val_loss: 98621743597.9972\n",
      "Epoch 1857/5000\n",
      "3554/3554 [==============================] - 0s 118us/step - loss: 80698396480.6843 - val_loss: 106594636265.1004\n",
      "Epoch 1858/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 78650375945.3641 - val_loss: 97259344733.2546\n",
      "Epoch 1859/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 77760701589.2493 - val_loss: 105177058792.8124\n",
      "Epoch 1860/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 78422881164.1733 - val_loss: 96616745025.3862\n",
      "Epoch 1861/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 76828375027.3225 - val_loss: 96376089616.4186\n",
      "Epoch 1862/5000\n",
      "3554/3554 [==============================] - 0s 114us/step - loss: 78689107313.3776 - val_loss: 103600667527.8852\n",
      "Epoch 1863/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 78891521104.0990 - val_loss: 95501866966.8096\n",
      "Epoch 1864/5000\n",
      "3554/3554 [==============================] - 0s 113us/step - loss: 78382263935.0636 - val_loss: 94007991244.4399\n",
      "Epoch 1865/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 74728763652.4660 - val_loss: 94018522849.1072\n",
      "Epoch 1866/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 75734659631.5408 - val_loss: 94286830895.3114\n",
      "Epoch 1867/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 73605831271.4373 - val_loss: 92158364485.6349\n",
      "Epoch 1868/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 74221508000.6303 - val_loss: 95459201270.7106\n",
      "Epoch 1869/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 74228909193.7243 - val_loss: 92339267342.3302\n",
      "Epoch 1870/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 71842253651.7006 - val_loss: 92262835615.0729\n",
      "Epoch 1871/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 74053159710.6854 - val_loss: 90944106182.0309\n",
      "Epoch 1872/5000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 72671825548.8936 - val_loss: 92977136637.9117\n",
      "Epoch 1873/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 74423246336.2881 - val_loss: 96404657332.0281\n",
      "Epoch 1874/5000\n",
      "3554/3554 [==============================] - 0s 126us/step - loss: 72659081258.6427 - val_loss: 95548306110.3978\n",
      "Epoch 1875/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 70679562478.5684 - val_loss: 95484245537.2692\n",
      "Epoch 1876/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 75026538899.9527 - val_loss: 90457876148.7482\n",
      "Epoch 1877/5000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 70987598772.5110 - val_loss: 95665664325.7789\n",
      "Epoch 1878/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 71019648621.1998 - val_loss: 96137661579.1257\n",
      "Epoch 1879/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 69477435839.1716 - val_loss: 93964035330.5204\n",
      "Epoch 1880/5000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 73030813012.5650 - val_loss: 100089782990.3842\n",
      "Epoch 1881/5000\n",
      "3554/3554 [==============================] - 0s 116us/step - loss: 69996358953.9223 - val_loss: 89415386815.9820\n",
      "Epoch 1882/5000\n",
      "3554/3554 [==============================] - 0s 103us/step - loss: 72352458543.3967 - val_loss: 87301701452.2599\n",
      "Epoch 1883/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 71435220569.0309 - val_loss: 87147818569.0194\n",
      "Epoch 1884/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 68460538234.0214 - val_loss: 89498439401.1724\n",
      "Epoch 1885/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 68085011271.0231 - val_loss: 90907590494.6948\n",
      "Epoch 1886/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 86us/step - loss: 68951478281.2200 - val_loss: 87776017507.3755\n",
      "Epoch 1887/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 67952956048.9274 - val_loss: 96837273788.3814\n",
      "Epoch 1888/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 69244044029.2628 - val_loss: 92448677968.6526\n",
      "Epoch 1889/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 70957525862.1407 - val_loss: 89162604310.6835\n",
      "Epoch 1890/5000\n",
      "3554/3554 [==============================] - 0s 139us/step - loss: 68709251686.2847 - val_loss: 84818096577.7823\n",
      "Epoch 1891/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 68086066538.4626 - val_loss: 84915094755.5556\n",
      "Epoch 1892/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 67108814615.1941 - val_loss: 83734817760.7471\n",
      "Epoch 1893/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 66242026712.0945 - val_loss: 89261334318.8793\n",
      "Epoch 1894/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 67021635662.3703 - val_loss: 84519511753.7755\n",
      "Epoch 1895/5000\n",
      "3554/3554 [==============================] - 0s 140us/step - loss: 65084977927.6353 - val_loss: 82597228493.7361\n",
      "Epoch 1896/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 65505496024.2386 - val_loss: 83913665240.7539\n",
      "Epoch 1897/5000\n",
      "3554/3554 [==============================] - 0s 124us/step - loss: 65140772566.6539 - val_loss: 85129314423.8267\n",
      "Epoch 1898/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 66360486762.7507 - val_loss: 95753779339.9899\n",
      "Epoch 1899/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 65406196011.0748 - val_loss: 83303001982.9558\n",
      "Epoch 1900/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 63640162965.5374 - val_loss: 82172100354.8084\n",
      "Epoch 1901/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 62621117240.0405 - val_loss: 86598959659.3508\n",
      "Epoch 1902/5000\n",
      "3554/3554 [==============================] - 0s 109us/step - loss: 64489943730.2060 - val_loss: 81333489510.7601\n",
      "Epoch 1903/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 64458341401.9314 - val_loss: 84663165491.4160\n",
      "Epoch 1904/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 62725069075.4485 - val_loss: 82981289438.1547\n",
      "Epoch 1905/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 64005215127.6984 - val_loss: 88477156435.2450\n",
      "Epoch 1906/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 63012096768.7203 - val_loss: 82018506810.7612\n",
      "Epoch 1907/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 63625054741.6095 - val_loss: 97306879892.7032\n",
      "Epoch 1908/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 64857179116.9837 - val_loss: 80875566071.0706\n",
      "Epoch 1909/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 62261903618.1609 - val_loss: 80925366980.8788\n",
      "Epoch 1910/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 60999005476.1598 - val_loss: 85802146133.9094\n",
      "Epoch 1911/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 63047137158.9871 - val_loss: 81520486933.3153\n",
      "Epoch 1912/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 63072645917.5329 - val_loss: 84000630568.5423\n",
      "Epoch 1913/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 64280736020.6010 - val_loss: 83724067662.8523\n",
      "Epoch 1914/5000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 62480340730.3815 - val_loss: 80712536746.6667\n",
      "Epoch 1915/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 60234393042.4761 - val_loss: 78941835047.9662\n",
      "Epoch 1916/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 61462445314.7372 - val_loss: 81039744055.3046\n",
      "Epoch 1917/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 61348130205.1728 - val_loss: 77628775066.5361\n",
      "Epoch 1918/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 61785656069.3303 - val_loss: 78413569447.7142\n",
      "Epoch 1919/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 61845920487.1491 - val_loss: 78774028857.4650\n",
      "Epoch 1920/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 60008262216.3196 - val_loss: 79008786082.3134\n",
      "Epoch 1921/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 59783118170.3275 - val_loss: 78194840637.4976\n",
      "Epoch 1922/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 59093624492.0113 - val_loss: 79730279544.9789\n",
      "Epoch 1923/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 60751694818.6111 - val_loss: 84794622016.5221\n",
      "Epoch 1924/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 59512062143.6038 - val_loss: 78567223112.8034\n",
      "Epoch 1925/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 59806236436.8891 - val_loss: 78178148581.2838\n",
      "Epoch 1926/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 60661005471.6218 - val_loss: 76603674840.0338\n",
      "Epoch 1927/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 61516625964.3714 - val_loss: 75410972317.1286\n",
      "Epoch 1928/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 58077297600.0360 - val_loss: 89205804459.1707\n",
      "Epoch 1929/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 63323596605.2268 - val_loss: 85354669804.9170\n",
      "Epoch 1930/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 60634907257.8773 - val_loss: 83683946778.2841\n",
      "Epoch 1931/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 61351199688.1035 - val_loss: 74653744492.9530\n",
      "Epoch 1932/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 59670608265.0039 - val_loss: 77786846861.5741\n",
      "Epoch 1933/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 60652438513.5937 - val_loss: 92928064280.1238\n",
      "Epoch 1934/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 59290751675.5701 - val_loss: 74625914988.4489\n",
      "Epoch 1935/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 58122899084.8936 - val_loss: 85545830301.3446\n",
      "Epoch 1936/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 58361580166.5549 - val_loss: 77384154276.4737\n",
      "Epoch 1937/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 59080348536.0045 - val_loss: 79116442661.1578\n",
      "Epoch 1938/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 57486931102.4693 - val_loss: 75864751830.7375\n",
      "Epoch 1939/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 57304915128.9769 - val_loss: 79124129284.4647\n",
      "Epoch 1940/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 58671431775.6579 - val_loss: 73234995501.2951\n",
      "Epoch 1941/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 57274166469.5104 - val_loss: 73954456059.5353\n",
      "Epoch 1942/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 55453239769.6792 - val_loss: 73384405868.2329\n",
      "Epoch 1943/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 56559183796.5110 - val_loss: 73653448245.4323\n",
      "Epoch 1944/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 57019094653.9111 - val_loss: 72969437305.5550\n",
      "Epoch 1945/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 60013520871.7974 - val_loss: 73165637553.3637\n",
      "Epoch 1946/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 56672864506.0934 - val_loss: 73373570645.6934\n",
      "Epoch 1947/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 55825718568.4817 - val_loss: 72714078004.6402\n",
      "Epoch 1948/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 55522749378.3410 - val_loss: 84799416923.4543\n",
      "Epoch 1949/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 59179394756.2138 - val_loss: 79521897623.7997\n",
      "Epoch 1950/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 74us/step - loss: 59180560198.2307 - val_loss: 84097663284.4962\n",
      "Epoch 1951/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 55764220409.9494 - val_loss: 72050184974.7623\n",
      "Epoch 1952/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 53887705348.4660 - val_loss: 73954856368.4996\n",
      "Epoch 1953/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 55802586900.3129 - val_loss: 71218607558.8231\n",
      "Epoch 1954/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 54565890441.0039 - val_loss: 78225085033.0644\n",
      "Epoch 1955/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 56397090051.8897 - val_loss: 74056559108.4647\n",
      "Epoch 1956/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 55039975428.6100 - val_loss: 70136466111.4059\n",
      "Epoch 1957/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 55830558306.2510 - val_loss: 85868069844.6132\n",
      "Epoch 1958/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 55072677157.3123 - val_loss: 72507814308.0416\n",
      "Epoch 1959/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 54168555332.7181 - val_loss: 68730526489.8520\n",
      "Epoch 1960/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 53545777911.5003 - val_loss: 70096458576.7246\n",
      "Epoch 1961/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 55469633496.8149 - val_loss: 77998736822.1165\n",
      "Epoch 1962/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 53930087965.1007 - val_loss: 67778809505.7373\n",
      "Epoch 1963/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 54537618399.1536 - val_loss: 73429488794.0321\n",
      "Epoch 1964/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 52783046513.0895 - val_loss: 75364157040.2835\n",
      "Epoch 1965/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 52467965195.9572 - val_loss: 67603600204.6920\n",
      "Epoch 1966/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 52985025450.1384 - val_loss: 73383187622.2020\n",
      "Epoch 1967/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 55098071139.1154 - val_loss: 68440798013.5696\n",
      "Epoch 1968/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 52695123206.1947 - val_loss: 70044710534.3730\n",
      "Epoch 1969/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 51736117123.5295 - val_loss: 69175894189.4031\n",
      "Epoch 1970/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 50111359903.7659 - val_loss: 66925506153.8565\n",
      "Epoch 1971/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 51030249979.6781 - val_loss: 64600776505.2489\n",
      "Epoch 1972/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 50033809012.6910 - val_loss: 65746382919.4352\n",
      "Epoch 1973/5000\n",
      "3554/3554 [==============================] - 0s 96us/step - loss: 51455802332.8486 - val_loss: 70203029026.9975\n",
      "Epoch 1974/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 52019534299.9842 - val_loss: 67737370848.5311\n",
      "Epoch 1975/5000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 50090906335.8739 - val_loss: 66578798180.2397\n",
      "Epoch 1976/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 48934802734.5324 - val_loss: 63813133449.9736\n",
      "Epoch 1977/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 49956785016.5807 - val_loss: 64399115931.1122\n",
      "Epoch 1978/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 49450591678.5954 - val_loss: 64583162402.1333\n",
      "Epoch 1979/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 49489587290.4716 - val_loss: 65117094488.8619\n",
      "Epoch 1980/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 48714501424.2611 - val_loss: 75323791940.1227\n",
      "Epoch 1981/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 50245325073.1435 - val_loss: 65958763901.0835\n",
      "Epoch 1982/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 49878713459.2504 - val_loss: 62974958271.8380\n",
      "Epoch 1983/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 48774425386.2105 - val_loss: 64514020313.9781\n",
      "Epoch 1984/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 48473949863.6894 - val_loss: 65781298175.4239\n",
      "Epoch 1985/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 47693240462.1902 - val_loss: 63819821897.0914\n",
      "Epoch 1986/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 48244076984.2566 - val_loss: 64148068305.3367\n",
      "Epoch 1987/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 49720812330.2105 - val_loss: 62943398450.2639\n",
      "Epoch 1988/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 47584495357.8391 - val_loss: 66832048405.5314\n",
      "Epoch 1989/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 47700136908.7136 - val_loss: 62792194585.6360\n",
      "Epoch 1990/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 49496404171.9932 - val_loss: 61113007447.6377\n",
      "Epoch 1991/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 47854621570.9533 - val_loss: 61277752516.1587\n",
      "Epoch 1992/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 46766452310.7259 - val_loss: 61276431788.3229\n",
      "Epoch 1993/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 46255739501.1998 - val_loss: 61394429183.2079\n",
      "Epoch 1994/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 47888059860.4930 - val_loss: 60531660748.7280\n",
      "Epoch 1995/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 48435354490.7057 - val_loss: 66644751737.9150\n",
      "Epoch 1996/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 47129789642.2645 - val_loss: 60742981822.1097\n",
      "Epoch 1997/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 46512268084.5830 - val_loss: 68269938277.2478\n",
      "Epoch 1998/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 48073499677.3889 - val_loss: 60756972991.3339\n",
      "Epoch 1999/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 46229273022.0191 - val_loss: 69734360615.0841\n",
      "Epoch 2000/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 47673950290.9803 - val_loss: 62655094911.8920\n",
      "Epoch 2001/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 47821730974.4693 - val_loss: 61034876842.1626\n",
      "Epoch 2002/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 46708140706.2150 - val_loss: 59064922897.4987\n",
      "Epoch 2003/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 46177690614.2037 - val_loss: 70671732040.0112\n",
      "Epoch 2004/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 49761432328.7878 - val_loss: 66534759863.0706\n",
      "Epoch 2005/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 46285323703.6804 - val_loss: 59413067601.4447\n",
      "Epoch 2006/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 44708949469.7130 - val_loss: 62338671106.1243\n",
      "Epoch 2007/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 46195110788.8261 - val_loss: 58378025976.2228\n",
      "Epoch 2008/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 45523894014.9916 - val_loss: 65165979942.2380\n",
      "Epoch 2009/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 47683549583.9190 - val_loss: 62119955431.8762\n",
      "Epoch 2010/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 45503929489.7918 - val_loss: 58395252011.2788\n",
      "Epoch 2011/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 45568342800.8554 - val_loss: 58568432043.4588\n",
      "Epoch 2012/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 47006697164.2814 - val_loss: 63742180486.8051\n",
      "Epoch 2013/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 45694899061.1232 - val_loss: 62555287791.3654\n",
      "Epoch 2014/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 75us/step - loss: 43967157396.6730 - val_loss: 73621715927.3857\n",
      "Epoch 2015/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 47445057831.0411 - val_loss: 59335856038.3460\n",
      "Epoch 2016/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 46701447317.8256 - val_loss: 58913445118.0557\n",
      "Epoch 2017/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 45472401052.4524 - val_loss: 58339680491.1888\n",
      "Epoch 2018/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 44038870948.9522 - val_loss: 56680959754.0096\n",
      "Epoch 2019/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 44198904622.2442 - val_loss: 73341741277.7947\n",
      "Epoch 2020/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 45152945377.3146 - val_loss: 69611445576.7314\n",
      "Epoch 2021/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 47226289443.0073 - val_loss: 67905101068.6380\n",
      "Epoch 2022/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 45407640045.2718 - val_loss: 56746268035.1325\n",
      "Epoch 2023/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 44945216616.0135 - val_loss: 58283612397.4931\n",
      "Epoch 2024/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 43143669828.7181 - val_loss: 62954734128.2475\n",
      "Epoch 2025/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 42712792977.3596 - val_loss: 60686139989.9814\n",
      "Epoch 2026/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 44039125062.0146 - val_loss: 62599700099.9246\n",
      "Epoch 2027/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 43088455032.2926 - val_loss: 58997917673.5325\n",
      "Epoch 2028/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 42880161138.5301 - val_loss: 73840340089.8070\n",
      "Epoch 2029/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 43403095918.0642 - val_loss: 54654462942.2987\n",
      "Epoch 2030/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 43276884960.3061 - val_loss: 57833172175.3924\n",
      "Epoch 2031/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 42965114921.4902 - val_loss: 56603063213.0430\n",
      "Epoch 2032/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 43003602194.8723 - val_loss: 55886647088.4636\n",
      "Epoch 2033/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 42119061042.9983 - val_loss: 56903040929.0172\n",
      "Epoch 2034/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 42306213183.8199 - val_loss: 57410708276.0641\n",
      "Epoch 2035/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 42201930286.9645 - val_loss: 54823894153.8295\n",
      "Epoch 2036/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 42773055791.1086 - val_loss: 56666081160.1733\n",
      "Epoch 2037/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 41824835028.4930 - val_loss: 55074534113.3952\n",
      "Epoch 2038/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 41276331721.9764 - val_loss: 53154966877.8307\n",
      "Epoch 2039/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 40179314858.5706 - val_loss: 53771811300.0596\n",
      "Epoch 2040/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 43692613907.4485 - val_loss: 56243027485.7406\n",
      "Epoch 2041/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 41315886715.6061 - val_loss: 55559482770.9750\n",
      "Epoch 2042/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 41121235582.4873 - val_loss: 58788446309.9679\n",
      "Epoch 2043/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 40311380133.0962 - val_loss: 55259764477.6236\n",
      "Epoch 2044/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 40008204620.2814 - val_loss: 53575753248.6931\n",
      "Epoch 2045/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 38555128747.8672 - val_loss: 51390694139.8954\n",
      "Epoch 2046/5000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 38340549237.2673 - val_loss: 51255504434.8399\n",
      "Epoch 2047/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 37933726254.9645 - val_loss: 51932893220.2937\n",
      "Epoch 2048/5000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 38033969403.2459 - val_loss: 50989176334.4743\n",
      "Epoch 2049/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 37775499178.7147 - val_loss: 51603862125.0250\n",
      "Epoch 2050/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 37004770917.7085 - val_loss: 48909253221.2478\n",
      "Epoch 2051/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 38001105206.0236 - val_loss: 47809653864.4163\n",
      "Epoch 2052/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 35542380019.6106 - val_loss: 47491921465.4650\n",
      "Epoch 2053/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 35112863710.5774 - val_loss: 48362732377.2940\n",
      "Epoch 2054/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 35563509768.0675 - val_loss: 46282470761.4965\n",
      "Epoch 2055/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 34057197814.0597 - val_loss: 46633174079.6579\n",
      "Epoch 2056/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 34654975323.4800 - val_loss: 47756963270.5890\n",
      "Epoch 2057/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 34047563184.7653 - val_loss: 47678442232.6549\n",
      "Epoch 2058/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 33612240689.7017 - val_loss: 43860378939.5533\n",
      "Epoch 2059/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 33337875380.5110 - val_loss: 44102614373.7519\n",
      "Epoch 2060/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 32192352164.9522 - val_loss: 42915783021.0970\n",
      "Epoch 2061/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 32469314295.5003 - val_loss: 44011330307.3845\n",
      "Epoch 2062/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 31761665823.4057 - val_loss: 48586292735.2799\n",
      "Epoch 2063/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 31303645398.3658 - val_loss: 42643244634.0928\n",
      "Epoch 2064/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 30966869478.3568 - val_loss: 42601685214.8028\n",
      "Epoch 2065/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 31061311104.7923 - val_loss: 44687730461.3806\n",
      "Epoch 2066/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 30090555827.6466 - val_loss: 40478970972.1744\n",
      "Epoch 2067/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 29007299166.2172 - val_loss: 45954278106.4821\n",
      "Epoch 2068/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 28958373576.6798 - val_loss: 43182410293.1443\n",
      "Epoch 2069/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 28924592521.5802 - val_loss: 48969770098.0658\n",
      "Epoch 2070/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 29657387269.0422 - val_loss: 39593310197.4143\n",
      "Epoch 2071/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 28581877173.3754 - val_loss: 39626507703.9347\n",
      "Epoch 2072/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 28048705140.5470 - val_loss: 38914534530.0523\n",
      "Epoch 2073/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 27799357793.8188 - val_loss: 41862378967.8177\n",
      "Epoch 2074/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 27950901211.6961 - val_loss: 40044475499.7288\n",
      "Epoch 2075/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 26796213980.4164 - val_loss: 37040278305.3412\n",
      "Epoch 2076/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 27178245208.1666 - val_loss: 38184249679.0684\n",
      "Epoch 2077/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 28304645249.0805 - val_loss: 39058783303.7232\n",
      "Epoch 2078/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 76us/step - loss: 27765838066.0259 - val_loss: 37431153664.2880\n",
      "Epoch 2079/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 29797417753.0670 - val_loss: 38746237985.1252\n",
      "Epoch 2080/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 25391372173.3258 - val_loss: 38869121907.9381\n",
      "Epoch 2081/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 26125878174.6134 - val_loss: 36401785939.5331\n",
      "Epoch 2082/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 26132535008.4502 - val_loss: 48671880845.8622\n",
      "Epoch 2083/5000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 26849739308.6595 - val_loss: 42879529949.7226\n",
      "Epoch 2084/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 24826990676.4434 - val_loss: 41499577357.5381\n",
      "Epoch 2085/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 25700400224.2341 - val_loss: 36502666516.1631\n",
      "Epoch 2086/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 24265502471.0591 - val_loss: 36722941686.9986\n",
      "Epoch 2087/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 25188100931.5656 - val_loss: 43397598644.3882\n",
      "Epoch 2088/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 25865388289.0084 - val_loss: 37030684575.2169\n",
      "Epoch 2089/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 24470619741.0647 - val_loss: 34719783581.2726\n",
      "Epoch 2090/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 25518846814.0732 - val_loss: 40207137119.9910\n",
      "Epoch 2091/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 25124245937.3416 - val_loss: 35913816645.8509\n",
      "Epoch 2092/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 26177895755.3450 - val_loss: 34326804088.5468\n",
      "Epoch 2093/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 25600345660.7946 - val_loss: 33613357064.7854\n",
      "Epoch 2094/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 23555361453.1638 - val_loss: 32889064451.1685\n",
      "Epoch 2095/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 23968061492.4389 - val_loss: 33199132958.0287\n",
      "Epoch 2096/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 25626667071.3877 - val_loss: 32801319802.4191\n",
      "Epoch 2097/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 24500508580.9522 - val_loss: 36498315471.1044\n",
      "Epoch 2098/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 24453320581.8346 - val_loss: 34388072672.9632\n",
      "Epoch 2099/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 23576226073.2110 - val_loss: 33095087437.1241\n",
      "Epoch 2100/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 24631068223.6759 - val_loss: 36903841285.3288\n",
      "Epoch 2101/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 23997869589.6095 - val_loss: 31556740105.7935\n",
      "Epoch 2102/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 23031520410.1474 - val_loss: 33148137401.2850\n",
      "Epoch 2103/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 22867256974.0461 - val_loss: 32305352271.2124\n",
      "Epoch 2104/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 22859479498.6967 - val_loss: 48786333196.8180\n",
      "Epoch 2105/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 24341911525.4924 - val_loss: 31395144810.0006\n",
      "Epoch 2106/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 22393333756.5425 - val_loss: 31066506612.8743\n",
      "Epoch 2107/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 23281730262.0777 - val_loss: 35426544425.8385\n",
      "Epoch 2108/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 24068599175.8514 - val_loss: 32740439227.9494\n",
      "Epoch 2109/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 22509349017.2831 - val_loss: 36787985514.0006\n",
      "Epoch 2110/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 23447458741.6635 - val_loss: 32391522447.1584\n",
      "Epoch 2111/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 21220162180.1058 - val_loss: 29914287110.4810\n",
      "Epoch 2112/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 21183912854.9781 - val_loss: 30348079591.5162\n",
      "Epoch 2113/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 21830403668.7091 - val_loss: 32012013466.6802\n",
      "Epoch 2114/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 22808232740.4479 - val_loss: 30563076783.9955\n",
      "Epoch 2115/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 22274436712.0135 - val_loss: 31026357012.0911\n",
      "Epoch 2116/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 21349038368.5582 - val_loss: 32091886685.3266\n",
      "Epoch 2117/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 21471648943.7569 - val_loss: 32542289820.8405\n",
      "Epoch 2118/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 21780637992.1936 - val_loss: 30258259142.9671\n",
      "Epoch 2119/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 21349238213.5104 - val_loss: 33046660197.6799\n",
      "Epoch 2120/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 21722503614.0191 - val_loss: 35845055743.3519\n",
      "Epoch 2121/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 21885317201.8278 - val_loss: 28959373053.3356\n",
      "Epoch 2122/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 20726997994.1024 - val_loss: 31059901651.5691\n",
      "Epoch 2123/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 20645104900.1778 - val_loss: 32337201446.6700\n",
      "Epoch 2124/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 20627984483.1154 - val_loss: 43604972117.9814\n",
      "Epoch 2125/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 24432031783.7614 - val_loss: 30879486807.2056\n",
      "Epoch 2126/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 21302726023.2752 - val_loss: 28824052889.3840\n",
      "Epoch 2127/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 20235232131.5295 - val_loss: 29103607160.0428\n",
      "Epoch 2128/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 20135830873.1750 - val_loss: 31807858344.2183\n",
      "Epoch 2129/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 20712307563.9032 - val_loss: 34218087792.4096\n",
      "Epoch 2130/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 21281805083.2279 - val_loss: 36325298102.2605\n",
      "Epoch 2131/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 20213732769.7828 - val_loss: 35731245958.7331\n",
      "Epoch 2132/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 21157444900.1598 - val_loss: 28167027770.4731\n",
      "Epoch 2133/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 21915936668.8846 - val_loss: 36835125108.0101\n",
      "Epoch 2134/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 21722380950.6899 - val_loss: 27491432047.4734\n",
      "Epoch 2135/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 19436652874.7687 - val_loss: 28431743714.1873\n",
      "Epoch 2136/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 20041501975.4823 - val_loss: 26907844604.3994\n",
      "Epoch 2137/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 19859572627.9527 - val_loss: 26766638535.5432\n",
      "Epoch 2138/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 21034283970.9173 - val_loss: 27944158656.1980\n",
      "Epoch 2139/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 19690677081.7513 - val_loss: 30219397906.2188\n",
      "Epoch 2140/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 20123049914.8497 - val_loss: 28807212161.4762\n",
      "Epoch 2141/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 19627671291.5340 - val_loss: 27744596274.4799\n",
      "Epoch 2142/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 73us/step - loss: 18531456493.8481 - val_loss: 27994020200.2003\n",
      "Epoch 2143/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 18949831284.1148 - val_loss: 26305983519.8290\n",
      "Epoch 2144/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 18264624545.7828 - val_loss: 26759423034.0411\n",
      "Epoch 2145/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 18511710846.4873 - val_loss: 28145376865.3592\n",
      "Epoch 2146/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 18663200816.1171 - val_loss: 26230141227.2788\n",
      "Epoch 2147/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 19240467290.1835 - val_loss: 25367865482.1176\n",
      "Epoch 2148/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 17775833695.0816 - val_loss: 25314661649.3547\n",
      "Epoch 2149/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 18611826490.8497 - val_loss: 26733642554.6892\n",
      "Epoch 2150/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 18768655629.1097 - val_loss: 28058710978.3584\n",
      "Epoch 2151/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 17841368592.1351 - val_loss: 24106597276.6245\n",
      "Epoch 2152/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 17189864754.2780 - val_loss: 25327674596.4197\n",
      "Epoch 2153/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 17211332951.4463 - val_loss: 25336360073.8295\n",
      "Epoch 2154/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 17189687516.4164 - val_loss: 25188784438.6565\n",
      "Epoch 2155/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 17360378545.1975 - val_loss: 27507413234.2458\n",
      "Epoch 2156/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 16545103409.8998 - val_loss: 23054892836.2217\n",
      "Epoch 2157/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 16936640760.6528 - val_loss: 23056989748.4242\n",
      "Epoch 2158/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 16358053756.6145 - val_loss: 23625832863.7930\n",
      "Epoch 2159/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 16211954589.8931 - val_loss: 23793939165.5066\n",
      "Epoch 2160/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 16482295496.8239 - val_loss: 25098831417.3210\n",
      "Epoch 2161/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 16233305092.6100 - val_loss: 34888002015.8830\n",
      "Epoch 2162/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 16605689901.0917 - val_loss: 32702761502.6768\n",
      "Epoch 2163/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 15701537631.2257 - val_loss: 27764384590.2762\n",
      "Epoch 2164/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 14957815907.6916 - val_loss: 27260551990.6565\n",
      "Epoch 2165/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 15617568313.9133 - val_loss: 21518403898.6892\n",
      "Epoch 2166/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 15366331014.5549 - val_loss: 22268405378.6284\n",
      "Epoch 2167/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 14921329595.4260 - val_loss: 25610235385.6630\n",
      "Epoch 2168/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 15651632537.7153 - val_loss: 24146364846.4833\n",
      "Epoch 2169/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 15123073697.3506 - val_loss: 21287249886.8748\n",
      "Epoch 2170/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 13563742118.3928 - val_loss: 20960461527.6017\n",
      "Epoch 2171/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 13215029158.3928 - val_loss: 20179557910.7556\n",
      "Epoch 2172/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 14180173935.3607 - val_loss: 19706724499.6231\n",
      "Epoch 2173/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 14186166934.1137 - val_loss: 19389544202.1536\n",
      "Epoch 2174/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 13104983322.9398 - val_loss: 23580153763.5376\n",
      "Epoch 2175/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 13794718388.0788 - val_loss: 19341748458.9007\n",
      "Epoch 2176/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 12808739232.3421 - val_loss: 18694859440.5716\n",
      "Epoch 2177/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 12931921698.7192 - val_loss: 21017004929.6923\n",
      "Epoch 2178/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 14987974136.2206 - val_loss: 24494333668.5637\n",
      "Epoch 2179/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 12802391473.9178 - val_loss: 19201867293.6686\n",
      "Epoch 2180/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 12425937278.0551 - val_loss: 19448963911.3632\n",
      "Epoch 2181/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 12684405768.6438 - val_loss: 19059700216.0788\n",
      "Epoch 2182/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 12743506211.0073 - val_loss: 19204867169.7913\n",
      "Epoch 2183/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 11649269109.9876 - val_loss: 20108279821.6821\n",
      "Epoch 2184/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 12207054540.2814 - val_loss: 18656151600.2475\n",
      "Epoch 2185/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 12738486344.4637 - val_loss: 19181482753.8003\n",
      "Epoch 2186/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 11728645713.9719 - val_loss: 17225313462.7646\n",
      "Epoch 2187/5000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 11374909216.4142 - val_loss: 17361266660.9238\n",
      "Epoch 2188/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 11935004841.4181 - val_loss: 20183491562.3966\n",
      "Epoch 2189/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 12672781639.8875 - val_loss: 17262396209.9758\n",
      "Epoch 2190/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 11915970098.4221 - val_loss: 18087669946.2211\n",
      "Epoch 2191/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 11260939662.4783 - val_loss: 19053301391.7345\n",
      "Epoch 2192/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 12721179909.1863 - val_loss: 15989017426.8129\n",
      "Epoch 2193/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 10576710898.1700 - val_loss: 18225869918.3347\n",
      "Epoch 2194/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 10452334820.1958 - val_loss: 20919046452.7842\n",
      "Epoch 2195/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 10896038811.4800 - val_loss: 16398831041.6383\n",
      "Epoch 2196/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 10424006036.5290 - val_loss: 16351124704.5311\n",
      "Epoch 2197/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 10562387209.6522 - val_loss: 16925717425.4357\n",
      "Epoch 2198/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 10531003334.9510 - val_loss: 16483735678.4518\n",
      "Epoch 2199/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 10478227022.0822 - val_loss: 24398052969.5685\n",
      "Epoch 2200/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 10632358465.4046 - val_loss: 16808349452.7460\n",
      "Epoch 2201/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 10528916242.5841 - val_loss: 17658034473.1904\n",
      "Epoch 2202/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 10692957128.1396 - val_loss: 15030093195.2698\n",
      "Epoch 2203/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 9732740100.0338 - val_loss: 16396536263.2551\n",
      "Epoch 2204/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 11076772588.2003 - val_loss: 15664080870.5080\n",
      "Epoch 2205/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 10368940166.8430 - val_loss: 15044113617.9128\n",
      "Epoch 2206/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 73us/step - loss: 9689621659.2999 - val_loss: 14769202238.7938\n",
      "Epoch 2207/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 9760466595.2954 - val_loss: 14977163327.5859\n",
      "Epoch 2208/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 9481607641.1030 - val_loss: 14723952309.1803\n",
      "Epoch 2209/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 9295878472.7518 - val_loss: 15822618428.1294\n",
      "Epoch 2210/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 10054064562.4941 - val_loss: 14611058452.8113\n",
      "Epoch 2211/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 9679394189.0377 - val_loss: 14419634559.9640\n",
      "Epoch 2212/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 10105917553.8098 - val_loss: 16533901689.0509\n",
      "Epoch 2213/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 9577528928.2341 - val_loss: 14509246923.8639\n",
      "Epoch 2214/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 9465387508.6190 - val_loss: 13713414078.9018\n",
      "Epoch 2215/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 9460387670.5819 - val_loss: 16705279060.9733\n",
      "Epoch 2216/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 9503708613.2223 - val_loss: 13894038203.6613\n",
      "Epoch 2217/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 8877161581.9201 - val_loss: 14482483479.5477\n",
      "Epoch 2218/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 8746296557.9921 - val_loss: 15078631146.0366\n",
      "Epoch 2219/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 10775264593.3956 - val_loss: 16717411420.1744\n",
      "Epoch 2220/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 8965741226.4986 - val_loss: 15184021151.4329\n",
      "Epoch 2221/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 8680599253.7895 - val_loss: 13971275390.1637\n",
      "Epoch 2222/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 8360035707.2864 - val_loss: 13835566184.9924\n",
      "Epoch 2223/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 8530436023.8965 - val_loss: 14126384715.8999\n",
      "Epoch 2224/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 9409186540.9837 - val_loss: 14092249266.5879\n",
      "Epoch 2225/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 8640892478.6674 - val_loss: 15300129921.3322\n",
      "Epoch 2226/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 8618311033.6972 - val_loss: 13744376280.3938\n",
      "Epoch 2227/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 8330468785.9178 - val_loss: 12858456141.6281\n",
      "Epoch 2228/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 9842906490.5976 - val_loss: 15576344100.1496\n",
      "Epoch 2229/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 9989579035.5160 - val_loss: 15285443212.7100\n",
      "Epoch 2230/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 9137805503.0276 - val_loss: 13365550599.0571\n",
      "Epoch 2231/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 8065278149.6545 - val_loss: 13347077221.5359\n",
      "Epoch 2232/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 8085603751.6894 - val_loss: 12730385761.4312\n",
      "Epoch 2233/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 8452282148.3759 - val_loss: 14889534494.6768\n",
      "Epoch 2234/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 8931250161.0895 - val_loss: 14764180647.9302\n",
      "Epoch 2235/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 8356923650.0169 - val_loss: 13846200768.1980\n",
      "Epoch 2236/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 8190967085.3799 - val_loss: 13836584445.5516\n",
      "Epoch 2237/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 8515560106.2825 - val_loss: 12698177734.2470\n",
      "Epoch 2238/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 8516590971.1739 - val_loss: 11923066743.6107\n",
      "Epoch 2239/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 8406193124.3399 - val_loss: 15813118736.0585\n",
      "Epoch 2240/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 8456456434.3140 - val_loss: 13405596070.9941\n",
      "Epoch 2241/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 8095897651.8627 - val_loss: 12693979074.5024\n",
      "Epoch 2242/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 7926933118.3433 - val_loss: 12213658396.8045\n",
      "Epoch 2243/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 8078479057.1795 - val_loss: 11985323956.6042\n",
      "Epoch 2244/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 8280312055.7884 - val_loss: 16264126363.3283\n",
      "Epoch 2245/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 9506833852.2904 - val_loss: 15015961991.3091\n",
      "Epoch 2246/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 7894378588.2003 - val_loss: 18266298371.7446\n",
      "Epoch 2247/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 8735469735.6894 - val_loss: 15384172946.5429\n",
      "Epoch 2248/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 7832571016.4277 - val_loss: 11636714663.7862\n",
      "Epoch 2249/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 7454548796.8666 - val_loss: 12091060927.7660\n",
      "Epoch 2250/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 7185374259.2864 - val_loss: 16437492788.5682\n",
      "Epoch 2251/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 8329020474.4176 - val_loss: 11787002910.5328\n",
      "Epoch 2252/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 8063290931.5746 - val_loss: 11430665994.7297\n",
      "Epoch 2253/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 7280136070.9871 - val_loss: 11629663213.6371\n",
      "Epoch 2254/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 7367115590.5909 - val_loss: 12789475118.7353\n",
      "Epoch 2255/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 7454439120.0270 - val_loss: 11578225023.6759\n",
      "Epoch 2256/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 7489525958.8070 - val_loss: 11605642417.0037\n",
      "Epoch 2257/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 7679840689.3416 - val_loss: 18765286448.3916\n",
      "Epoch 2258/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 9279744868.1238 - val_loss: 11164505812.1451\n",
      "Epoch 2259/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 7208974773.6635 - val_loss: 12841123825.1657\n",
      "Epoch 2260/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 7571693600.2701 - val_loss: 12401405737.1184\n",
      "Epoch 2261/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 7916293904.8554 - val_loss: 11049927877.8149\n",
      "Epoch 2262/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 6903467128.7248 - val_loss: 10884763028.6312\n",
      "Epoch 2263/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 7067842907.0478 - val_loss: 11061925707.6118\n",
      "Epoch 2264/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 7382549505.7288 - val_loss: 12264283429.3018\n",
      "Epoch 2265/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 7810752056.7608 - val_loss: 11326137809.6248\n",
      "Epoch 2266/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 8120151224.1125 - val_loss: 10737110932.1632\n",
      "Epoch 2267/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 6928742921.2200 - val_loss: 12149043179.2608\n",
      "Epoch 2268/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 7018589972.3129 - val_loss: 13808845353.4785\n",
      "Epoch 2269/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 7696032522.5166 - val_loss: 15573557335.5657\n",
      "Epoch 2270/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 77us/step - loss: 7659202935.1401 - val_loss: 14224155017.0374\n",
      "Epoch 2271/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 6663358248.4817 - val_loss: 16158551967.3609\n",
      "Epoch 2272/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 7063488577.1165 - val_loss: 13573767135.4509\n",
      "Epoch 2273/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 6924990110.1812 - val_loss: 12413417804.2599\n",
      "Epoch 2274/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 7279445439.7479 - val_loss: 12127334991.5004\n",
      "Epoch 2275/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 7611102121.4181 - val_loss: 11915308353.8903\n",
      "Epoch 2276/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 7086153480.2116 - val_loss: 12513029502.0917\n",
      "Epoch 2277/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 6631073223.2392 - val_loss: 10981237424.5716\n",
      "Epoch 2278/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 6845155945.1660 - val_loss: 11924163204.3567\n",
      "Epoch 2279/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 6735039321.1750 - val_loss: 10116273372.8585\n",
      "Epoch 2280/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 6368939760.8734 - val_loss: 10975748342.5665\n",
      "Epoch 2281/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 6399178568.0315 - val_loss: 12373241008.3556\n",
      "Epoch 2282/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 6394831450.1835 - val_loss: 14528705627.8864\n",
      "Epoch 2283/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 6915705080.9409 - val_loss: 13077584403.2990\n",
      "Epoch 2284/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 6419699610.0034 - val_loss: 9972985430.2695\n",
      "Epoch 2285/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 6312559438.8205 - val_loss: 11236413108.8203\n",
      "Epoch 2286/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 6913599295.5318 - val_loss: 9882530520.8259\n",
      "Epoch 2287/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 6294473703.5093 - val_loss: 11165536256.7921\n",
      "Epoch 2288/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 6353992837.3844 - val_loss: 9735798027.8098\n",
      "Epoch 2289/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 6307135511.0501 - val_loss: 12724304818.6599\n",
      "Epoch 2290/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 6717201308.4524 - val_loss: 11409480783.8965\n",
      "Epoch 2291/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 6073292449.9268 - val_loss: 16890635906.3404\n",
      "Epoch 2292/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 6806704710.3028 - val_loss: 10444986761.3255\n",
      "Epoch 2293/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 6187853102.1632 - val_loss: 9844084545.6743\n",
      "Epoch 2294/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 6510321053.1728 - val_loss: 11970929087.9100\n",
      "Epoch 2295/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 6661697312.9904 - val_loss: 10343121079.7007\n",
      "Epoch 2296/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 5946347892.6911 - val_loss: 9779664600.3938\n",
      "Epoch 2297/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 5949202823.1626 - val_loss: 9691808552.8304\n",
      "Epoch 2298/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 6476614884.7721 - val_loss: 13257115773.1556\n",
      "Epoch 2299/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 6678067497.3461 - val_loss: 9641385124.9778\n",
      "Epoch 2300/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 6247852021.0512 - val_loss: 10167095153.4897\n",
      "Epoch 2301/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 7006355775.5318 - val_loss: 10895251759.4554\n",
      "Epoch 2302/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 6082457589.4114 - val_loss: 12312599401.0644\n",
      "Epoch 2303/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 5758168248.9769 - val_loss: 10098045551.6174\n",
      "Epoch 2304/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 6569515345.1075 - val_loss: 12621421693.1556\n",
      "Epoch 2305/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 6365358272.1801 - val_loss: 10167820627.3890\n",
      "Epoch 2306/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 6116702415.6488 - val_loss: 10800715464.1913\n",
      "Epoch 2307/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 6251550639.0366 - val_loss: 13730132063.9190\n",
      "Epoch 2308/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 6971906478.2442 - val_loss: 8991676986.5451\n",
      "Epoch 2309/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 5620829962.9488 - val_loss: 9393083389.8397\n",
      "Epoch 2310/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 6101349237.3393 - val_loss: 8954680436.0821\n",
      "Epoch 2311/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 5745038451.8267 - val_loss: 9918688954.9412\n",
      "Epoch 2312/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 6353365624.7248 - val_loss: 8999971642.6172\n",
      "Epoch 2313/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 5738451087.1986 - val_loss: 12541109753.1589\n",
      "Epoch 2314/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 5969997033.9584 - val_loss: 12049880233.6585\n",
      "Epoch 2315/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 6144855182.6224 - val_loss: 8932806834.4439\n",
      "Epoch 2316/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 5994934941.8931 - val_loss: 10636201272.0968\n",
      "Epoch 2317/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 5855940027.1379 - val_loss: 9863372334.8073\n",
      "Epoch 2318/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 6954513602.1970 - val_loss: 10123685496.2588\n",
      "Epoch 2319/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 5360070670.5504 - val_loss: 8677809223.5792\n",
      "Epoch 2320/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 5511871053.5059 - val_loss: 9826760326.9491\n",
      "Epoch 2321/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 5952825877.1052 - val_loss: 12593579826.3359\n",
      "Epoch 2322/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 5305927349.4474 - val_loss: 8654808313.2309\n",
      "Epoch 2323/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 5552130977.8458 - val_loss: 9678227888.9316\n",
      "Epoch 2324/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 5814339939.8357 - val_loss: 9097611664.2385\n",
      "Epoch 2325/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 5740238065.4496 - val_loss: 8854429551.6895\n",
      "Epoch 2326/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 5641913221.2583 - val_loss: 11008956303.5184\n",
      "Epoch 2327/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 5395498889.4361 - val_loss: 8971947351.7817\n",
      "Epoch 2328/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 5546895507.0163 - val_loss: 8595336193.0802\n",
      "Epoch 2329/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 5339631418.9218 - val_loss: 9174187279.7705\n",
      "Epoch 2330/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 6132559364.6820 - val_loss: 12188501532.5165\n",
      "Epoch 2331/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 5368146574.6224 - val_loss: 8393926016.6121\n",
      "Epoch 2332/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 5779746714.7237 - val_loss: 9295034192.5086\n",
      "Epoch 2333/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 5294869843.9887 - val_loss: 10803938600.3983\n",
      "Epoch 2334/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 5636218203.8402 - val_loss: 8901096727.0436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2335/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 5113124549.3663 - val_loss: 8138928975.3564\n",
      "Epoch 2336/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 5330084163.2774 - val_loss: 9786181353.6045\n",
      "Epoch 2337/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 5464040974.1182 - val_loss: 11416329745.7148\n",
      "Epoch 2338/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 5491203875.8717 - val_loss: 9183980259.9156\n",
      "Epoch 2339/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 5115333521.9358 - val_loss: 9075467063.0886\n",
      "Epoch 2340/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 5648847060.9252 - val_loss: 8403163942.5980\n",
      "Epoch 2341/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4913476624.5672 - val_loss: 8970941800.7764\n",
      "Epoch 2342/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 5497942953.1300 - val_loss: 9120954381.6821\n",
      "Epoch 2343/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 5275974456.3286 - val_loss: 8377249944.0878\n",
      "Epoch 2344/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 4845220784.1891 - val_loss: 8221089816.5558\n",
      "Epoch 2345/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 5146212501.2493 - val_loss: 8882941352.8664\n",
      "Epoch 2346/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 5617636248.2746 - val_loss: 8714602580.2532\n",
      "Epoch 2347/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 5172494999.5543 - val_loss: 8038295037.4076\n",
      "Epoch 2348/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 5583707821.1638 - val_loss: 19542614575.9595\n",
      "Epoch 2349/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 7102566194.6922 - val_loss: 8092221533.9027\n",
      "Epoch 2350/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 4817335418.7417 - val_loss: 10108788191.8830\n",
      "Epoch 2351/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 5196874726.1947 - val_loss: 7946938127.9145\n",
      "Epoch 2352/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 5074790551.8424 - val_loss: 7925282500.3747\n",
      "Epoch 2353/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 5475803923.1604 - val_loss: 12990151932.9035\n",
      "Epoch 2354/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 5222137017.5892 - val_loss: 9091277905.4447\n",
      "Epoch 2355/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 5509302453.5914 - val_loss: 9598867346.6149\n",
      "Epoch 2356/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 5039657359.1986 - val_loss: 7992371345.2467\n",
      "Epoch 2357/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 4845230570.1024 - val_loss: 8004402341.9859\n",
      "Epoch 2358/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 5249391632.1351 - val_loss: 8485459755.9989\n",
      "Epoch 2359/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 5016355807.4418 - val_loss: 8811574317.8712\n",
      "Epoch 2360/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 4774060615.3112 - val_loss: 8508357790.5688\n",
      "Epoch 2361/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 4892240494.2802 - val_loss: 8032444747.7558\n",
      "Epoch 2362/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 4585207054.8385 - val_loss: 11785349343.7390\n",
      "Epoch 2363/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 6165540648.1936 - val_loss: 8358906527.7570\n",
      "Epoch 2364/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 4707477123.6736 - val_loss: 8066256413.3806\n",
      "Epoch 2365/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 4737737421.5779 - val_loss: 10273465044.5772\n",
      "Epoch 2366/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 4805401788.7226 - val_loss: 8070828686.5823\n",
      "Epoch 2367/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 5069953440.6303 - val_loss: 10598671973.3918\n",
      "Epoch 2368/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 4839565119.5318 - val_loss: 10715313003.6568\n",
      "Epoch 2369/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 5524859714.4131 - val_loss: 9915314425.9511\n",
      "Epoch 2370/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 5249981460.4029 - val_loss: 10499701727.5949\n",
      "Epoch 2371/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 4908116701.7130 - val_loss: 9094124703.7930\n",
      "Epoch 2372/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 4669798637.9921 - val_loss: 7679190479.6084\n",
      "Epoch 2373/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 5058493193.1120 - val_loss: 9287224351.8290\n",
      "Epoch 2374/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 4564949941.8661 - val_loss: 7264281069.7091\n",
      "Epoch 2375/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 4478171199.0996 - val_loss: 8258034410.1806\n",
      "Epoch 2376/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4425560798.7214 - val_loss: 8533855973.1398\n",
      "Epoch 2377/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 4628357854.7214 - val_loss: 7568517013.2793\n",
      "Epoch 2378/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 4842696145.0355 - val_loss: 7961980935.4892\n",
      "Epoch 2379/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 4594828962.3590 - val_loss: 8033276571.4003\n",
      "Epoch 2380/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 4954724787.7546 - val_loss: 8269929593.9871\n",
      "Epoch 2381/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 4667401642.8588 - val_loss: 8683920987.4543\n",
      "Epoch 2382/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 4708740180.7091 - val_loss: 11209705455.8695\n",
      "Epoch 2383/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 5309688143.5228 - val_loss: 7271660578.3494\n",
      "Epoch 2384/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4882583010.8993 - val_loss: 9434051839.3519\n",
      "Epoch 2385/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4884301181.8391 - val_loss: 7276500307.7491\n",
      "Epoch 2386/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 4323513726.6314 - val_loss: 8197128669.4346\n",
      "Epoch 2387/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4573041469.8030 - val_loss: 7396942307.6996\n",
      "Epoch 2388/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4575574406.6449 - val_loss: 8344828763.1662\n",
      "Epoch 2389/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4405872758.1317 - val_loss: 8372511138.0613\n",
      "Epoch 2390/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 4445840371.8987 - val_loss: 8680598693.1938\n",
      "Epoch 2391/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 4417800015.8109 - val_loss: 8546479227.5713\n",
      "Epoch 2392/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 4885986457.7873 - val_loss: 7930921687.0256\n",
      "Epoch 2393/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 4682859313.1975 - val_loss: 8791800963.2045\n",
      "Epoch 2394/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 4433519188.1328 - val_loss: 7478441323.7288\n",
      "Epoch 2395/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 4215266059.4530 - val_loss: 7648311405.3131\n",
      "Epoch 2396/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 4292682945.0445 - val_loss: 8641516015.5814\n",
      "Epoch 2397/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 5421738992.9882 - val_loss: 12586773568.0900\n",
      "Epoch 2398/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 4468464004.0338 - val_loss: 6883980857.1769\n",
      "Epoch 2399/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 4425229766.8070 - val_loss: 10287562495.9280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2400/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 4561802639.7749 - val_loss: 6835670063.6714\n",
      "Epoch 2401/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 4334036975.0006 - val_loss: 8667241004.6830\n",
      "Epoch 2402/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 4506676326.8610 - val_loss: 12055129947.2383\n",
      "Epoch 2403/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 4427957501.2628 - val_loss: 9132419498.3066\n",
      "Epoch 2404/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 4378365224.6258 - val_loss: 7840264214.6835\n",
      "Epoch 2405/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3999408819.7907 - val_loss: 8898076398.2132\n",
      "Epoch 2406/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 4934866416.7293 - val_loss: 8058850186.7657\n",
      "Epoch 2407/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4694906971.6601 - val_loss: 10409667555.7716\n",
      "Epoch 2408/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 4837197549.7040 - val_loss: 10443322378.0816\n",
      "Epoch 2409/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 4584839123.9167 - val_loss: 7066167095.4847\n",
      "Epoch 2410/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 4375723505.1615 - val_loss: 7047543682.5564\n",
      "Epoch 2411/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 4593526769.0174 - val_loss: 8082385999.6444\n",
      "Epoch 2412/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 4375352056.2206 - val_loss: 6952503088.1755\n",
      "Epoch 2413/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 4930786023.9415 - val_loss: 10514414687.1989\n",
      "Epoch 2414/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 4492152221.7490 - val_loss: 8438804887.2956\n",
      "Epoch 2415/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4443785427.1244 - val_loss: 6607731404.6560\n",
      "Epoch 2416/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 4235072952.5087 - val_loss: 8116018687.5679\n",
      "Epoch 2417/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 4173041917.2988 - val_loss: 10144912862.8748\n",
      "Epoch 2418/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 4306673432.9229 - val_loss: 6915499950.8433\n",
      "Epoch 2419/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 4427760404.8891 - val_loss: 11055302255.6174\n",
      "Epoch 2420/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 4621240326.2667 - val_loss: 6806053725.9027\n",
      "Epoch 2421/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 4066922494.8475 - val_loss: 10887255028.3342\n",
      "Epoch 2422/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 4399316314.6697 - val_loss: 7547951518.1367\n",
      "Epoch 2423/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 4012097932.8216 - val_loss: 7293737028.9868\n",
      "Epoch 2424/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3874640478.6494 - val_loss: 6498569633.6653\n",
      "Epoch 2425/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 3862971312.3602 - val_loss: 6996303676.0574\n",
      "Epoch 2426/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4020362126.6224 - val_loss: 6657981093.7699\n",
      "Epoch 2427/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 4146004507.4440 - val_loss: 10796371983.5544\n",
      "Epoch 2428/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 4603348880.2071 - val_loss: 8041674234.5271\n",
      "Epoch 2429/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 4181120266.4446 - val_loss: 7149437583.6624\n",
      "Epoch 2430/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 4241090883.5656 - val_loss: 7209350379.2608\n",
      "Epoch 2431/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 4602326255.3247 - val_loss: 6806339643.1932\n",
      "Epoch 2432/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 4470655933.5869 - val_loss: 7852335644.9485\n",
      "Epoch 2433/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 4404296854.1137 - val_loss: 19935713591.6647\n",
      "Epoch 2434/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4640694894.9285 - val_loss: 7104104501.9004\n",
      "Epoch 2435/5000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 5121378534.3568 - val_loss: 6843860832.6391\n",
      "Epoch 2436/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 3690835164.4885 - val_loss: 6908989437.1916\n",
      "Epoch 2437/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 4240128712.8239 - val_loss: 6968285247.0819\n",
      "Epoch 2438/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 4511589343.1536 - val_loss: 13501854858.8377\n",
      "Epoch 2439/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 5136695251.1964 - val_loss: 6958034927.0053\n",
      "Epoch 2440/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 3983370623.7839 - val_loss: 8966605294.2852\n",
      "Epoch 2441/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 4086073266.3500 - val_loss: 6246354444.9620\n",
      "Epoch 2442/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 4076321308.5245 - val_loss: 7035735823.7705\n",
      "Epoch 2443/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 4418459523.6106 - val_loss: 7991167498.3696\n",
      "Epoch 2444/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 4070108151.3562 - val_loss: 8446931340.0619\n",
      "Epoch 2445/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3795743476.5830 - val_loss: 6646383488.9722\n",
      "Epoch 2446/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3945060549.9426 - val_loss: 7081548334.3752\n",
      "Epoch 2447/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3988120526.4423 - val_loss: 8201124195.8796\n",
      "Epoch 2448/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 4220633804.1373 - val_loss: 6081918342.3010\n",
      "Epoch 2449/5000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 4019284063.6579 - val_loss: 7705267748.8698\n",
      "Epoch 2450/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3606541050.0934 - val_loss: 7982309715.3170\n",
      "Epoch 2451/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3920270456.5357 - val_loss: 6776254940.0664\n",
      "Epoch 2452/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3613107382.8880 - val_loss: 6827961690.5902\n",
      "Epoch 2453/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3698950805.8886 - val_loss: 6513352667.4183\n",
      "Epoch 2454/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3580416615.4373 - val_loss: 8630993428.4512\n",
      "Epoch 2455/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 3864069286.8250 - val_loss: 6877714047.8920\n",
      "Epoch 2456/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 4052312201.1120 - val_loss: 6943736877.2231\n",
      "Epoch 2457/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3763814180.4209 - val_loss: 8281554383.7525\n",
      "Epoch 2458/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 4095008345.4631 - val_loss: 7339458017.1792\n",
      "Epoch 2459/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 3934451553.0985 - val_loss: 6474567824.5986\n",
      "Epoch 2460/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3608945602.0529 - val_loss: 8348344845.6821\n",
      "Epoch 2461/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 4024202172.5425 - val_loss: 8408095048.3713\n",
      "Epoch 2462/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 3816504392.4637 - val_loss: 7450970965.0453\n",
      "Epoch 2463/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 4432311863.5363 - val_loss: 9410334294.9896\n",
      "Epoch 2464/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3965473277.7569 - val_loss: 6345532276.4422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2465/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 3593904415.8379 - val_loss: 6889300296.5153\n",
      "Epoch 2466/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 4153001207.6443 - val_loss: 7032374465.8543\n",
      "Epoch 2467/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4144322688.5042 - val_loss: 16436303110.9851\n",
      "Epoch 2468/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 5198358556.5245 - val_loss: 9563771980.6200\n",
      "Epoch 2469/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3963119042.9173 - val_loss: 6980263512.5738\n",
      "Epoch 2470/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 4009280899.2414 - val_loss: 6932358506.5046\n",
      "Epoch 2471/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 3613917590.8340 - val_loss: 6173291705.3930\n",
      "Epoch 2472/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 3658854766.2082 - val_loss: 10068490516.9553\n",
      "Epoch 2473/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3904392456.0495 - val_loss: 6472548804.5187\n",
      "Epoch 2474/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 3708126286.3703 - val_loss: 8226611921.1207\n",
      "Epoch 2475/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 4060868858.5256 - val_loss: 5730212925.6416\n",
      "Epoch 2476/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3710490856.8059 - val_loss: 7424138857.9286\n",
      "Epoch 2477/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3844468652.1553 - val_loss: 6966511441.3007\n",
      "Epoch 2478/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3620283314.4941 - val_loss: 6671905798.6250\n",
      "Epoch 2479/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 3582115576.1486 - val_loss: 7780566996.1451\n",
      "Epoch 2480/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 3514779653.4744 - val_loss: 6220483562.9727\n",
      "Epoch 2481/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3939641041.2515 - val_loss: 6165944314.3831\n",
      "Epoch 2482/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 4061261719.1221 - val_loss: 8076505573.1398\n",
      "Epoch 2483/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 3730923450.4176 - val_loss: 8057060640.9091\n",
      "Epoch 2484/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3837657451.3270 - val_loss: 10143185821.2006\n",
      "Epoch 2485/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 3617760403.9527 - val_loss: 6619730494.8658\n",
      "Epoch 2486/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 3481085197.1097 - val_loss: 7453895693.6821\n",
      "Epoch 2487/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 3875201704.5537 - val_loss: 7111652693.7654\n",
      "Epoch 2488/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3374548100.0338 - val_loss: 6427300489.9736\n",
      "Epoch 2489/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 3297955253.0872 - val_loss: 6044594362.0771\n",
      "Epoch 2490/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 3702300893.8571 - val_loss: 10902676045.3401\n",
      "Epoch 2491/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 4173339014.6989 - val_loss: 19477649606.7511\n",
      "Epoch 2492/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 4866918074.1294 - val_loss: 6248203981.1241\n",
      "Epoch 2493/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 4183729461.1593 - val_loss: 6489001574.9761\n",
      "Epoch 2494/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3736241240.1666 - val_loss: 5609759657.5145\n",
      "Epoch 2495/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3215168147.2324 - val_loss: 5754473818.6622\n",
      "Epoch 2496/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 3337275125.6275 - val_loss: 6841726565.2478\n",
      "Epoch 2497/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3389226837.3573 - val_loss: 5786993373.3626\n",
      "Epoch 2498/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3358700249.9674 - val_loss: 5771973254.1570\n",
      "Epoch 2499/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3191975211.5070 - val_loss: 6503729774.8973\n",
      "Epoch 2500/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4033790695.5813 - val_loss: 10201926935.2596\n",
      "Epoch 2501/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3742589069.9021 - val_loss: 5991186951.4892\n",
      "Epoch 2502/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 3679335485.6590 - val_loss: 9838961813.4954\n",
      "Epoch 2503/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 3552511321.7513 - val_loss: 6772423044.5727\n",
      "Epoch 2504/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 3503878741.4474 - val_loss: 6170884162.5384\n",
      "Epoch 2505/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 3543465765.3776 - val_loss: 5841412927.8740\n",
      "Epoch 2506/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3181432950.2037 - val_loss: 11478371740.1924\n",
      "Epoch 2507/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 3984882407.3652 - val_loss: 9106877417.1004\n",
      "Epoch 2508/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3981563022.2622 - val_loss: 7046910619.9404\n",
      "Epoch 2509/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3720292857.2290 - val_loss: 5810452168.0473\n",
      "Epoch 2510/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3491518157.0017 - val_loss: 6026322464.9812\n",
      "Epoch 2511/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 3279998260.8441 - val_loss: 5960817443.2135\n",
      "Epoch 2512/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 3221970731.8852 - val_loss: 7334628137.9105\n",
      "Epoch 2513/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 3690289052.5245 - val_loss: 9085607120.5446\n",
      "Epoch 2514/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 4275499390.8475 - val_loss: 7877824009.0734\n",
      "Epoch 2515/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 3474372876.7946 - val_loss: 5946344664.3938\n",
      "Epoch 2516/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 3230256207.8109 - val_loss: 6360877114.5451\n",
      "Epoch 2517/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3190710174.5234 - val_loss: 7316668296.2453\n",
      "Epoch 2518/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3613878893.4339 - val_loss: 8124289425.8228\n",
      "Epoch 2519/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3316254585.7333 - val_loss: 14384170011.6523\n",
      "Epoch 2520/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 4604692905.2741 - val_loss: 5780630059.7828\n",
      "Epoch 2521/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 3407146720.7383 - val_loss: 10579058448.2025\n",
      "Epoch 2522/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3471959399.4373 - val_loss: 5881026712.9519\n",
      "Epoch 2523/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3007612025.0129 - val_loss: 7433683131.2293\n",
      "Epoch 2524/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 4046516998.7710 - val_loss: 6725915712.3781\n",
      "Epoch 2525/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3207114483.7546 - val_loss: 12620640361.1364\n",
      "Epoch 2526/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 4070735842.0349 - val_loss: 6087549351.4262\n",
      "Epoch 2527/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3430478277.2223 - val_loss: 6216293983.3429\n",
      "Epoch 2528/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3137753620.7451 - val_loss: 6569785406.6498\n",
      "Epoch 2529/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3417304163.7636 - val_loss: 7008862682.3381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2530/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 3089594089.9584 - val_loss: 6898143932.7415\n",
      "Epoch 2531/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3186763318.4558 - val_loss: 6171856194.6104\n",
      "Epoch 2532/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3401176447.7839 - val_loss: 8391082791.8222\n",
      "Epoch 2533/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3731068961.7468 - val_loss: 6185094943.7570\n",
      "Epoch 2534/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3213728242.2600 - val_loss: 5272504015.5364\n",
      "Epoch 2535/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 3202849210.3185 - val_loss: 6686383805.9657\n",
      "Epoch 2536/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 3099486410.5526 - val_loss: 6153809547.7738\n",
      "Epoch 2537/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3446081089.4046 - val_loss: 5799880554.7927\n",
      "Epoch 2538/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3507677173.0512 - val_loss: 9533968419.1415\n",
      "Epoch 2539/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 4424287374.0461 - val_loss: 6235460068.3477\n",
      "Epoch 2540/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 3901490600.6978 - val_loss: 5943214200.6909\n",
      "Epoch 2541/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3437133111.6624 - val_loss: 7026405467.7423\n",
      "Epoch 2542/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3158493063.8875 - val_loss: 6311295177.2714\n",
      "Epoch 2543/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 3021115118.6798 - val_loss: 5521462138.0591\n",
      "Epoch 2544/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2949695844.5560 - val_loss: 6539045995.7288\n",
      "Epoch 2545/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3034497729.6207 - val_loss: 7502745261.5471\n",
      "Epoch 2546/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3384402674.3140 - val_loss: 6319117475.9696\n",
      "Epoch 2547/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3760362516.1688 - val_loss: 5203539306.2886\n",
      "Epoch 2548/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2899785455.1446 - val_loss: 5889276772.0956\n",
      "Epoch 2549/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 4283452786.5301 - val_loss: 5555232976.1125\n",
      "Epoch 2550/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3206346055.4012 - val_loss: 5623819436.6830\n",
      "Epoch 2551/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3064470027.8132 - val_loss: 5727327318.1975\n",
      "Epoch 2552/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2915189244.6866 - val_loss: 4982737843.0200\n",
      "Epoch 2553/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2944909352.6258 - val_loss: 4993652951.8897\n",
      "Epoch 2554/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 3391449395.5746 - val_loss: 6342825264.1755\n",
      "Epoch 2555/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3255381168.9094 - val_loss: 8831426910.5508\n",
      "Epoch 2556/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3730687251.4485 - val_loss: 8545544061.2276\n",
      "Epoch 2557/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3513827968.2521 - val_loss: 7066491363.9156\n",
      "Epoch 2558/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3054536266.9128 - val_loss: 9047602718.1007\n",
      "Epoch 2559/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 3740961515.8312 - val_loss: 6326135773.1466\n",
      "Epoch 2560/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3056367730.0979 - val_loss: 7267643882.8287\n",
      "Epoch 2561/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3614808724.3849 - val_loss: 6747660760.3938\n",
      "Epoch 2562/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3630653456.4232 - val_loss: 5351514050.0703\n",
      "Epoch 2563/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3040009129.9944 - val_loss: 5840386885.2028\n",
      "Epoch 2564/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3024286521.6252 - val_loss: 5423137853.4976\n",
      "Epoch 2565/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3035920531.5926 - val_loss: 5190321157.5449\n",
      "Epoch 2566/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3092823952.8959 - val_loss: 9673678727.4532\n",
      "Epoch 2567/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3480876917.1232 - val_loss: 5893936388.3927\n",
      "Epoch 2568/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2908357943.7524 - val_loss: 10710993955.7176\n",
      "Epoch 2569/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3423995068.4344 - val_loss: 7988690228.9283\n",
      "Epoch 2570/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 3336182545.5037 - val_loss: 7607360984.2498\n",
      "Epoch 2571/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 3386706004.9252 - val_loss: 5359498998.7826\n",
      "Epoch 2572/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2977090806.0597 - val_loss: 8718555201.0982\n",
      "Epoch 2573/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 3494385833.8503 - val_loss: 9255897640.4703\n",
      "Epoch 2574/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 3020149814.4558 - val_loss: 5907195525.0768\n",
      "Epoch 2575/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2797100934.5549 - val_loss: 5671168987.1302\n",
      "Epoch 2576/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 3046036287.9640 - val_loss: 5293960058.5632\n",
      "Epoch 2577/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3098709421.3078 - val_loss: 8735278397.2096\n",
      "Epoch 2578/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3720471437.2178 - val_loss: 5424718042.9142\n",
      "Epoch 2579/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 2749632086.6359 - val_loss: 6624906514.5069\n",
      "Epoch 2580/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 3029895177.6522 - val_loss: 5893873036.9260\n",
      "Epoch 2581/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2723491705.9358 - val_loss: 5805766364.7145\n",
      "Epoch 2582/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2996682753.2606 - val_loss: 5426814796.2599\n",
      "Epoch 2583/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2952379617.2606 - val_loss: 5503613525.4053\n",
      "Epoch 2584/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3052480166.2847 - val_loss: 4953210676.7842\n",
      "Epoch 2585/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2842207400.8419 - val_loss: 6629402908.0124\n",
      "Epoch 2586/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3478112139.5971 - val_loss: 6098867838.4518\n",
      "Epoch 2587/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2864463166.6314 - val_loss: 5872670749.1646\n",
      "Epoch 2588/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3268868431.9550 - val_loss: 9778684348.3094\n",
      "Epoch 2589/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 3505300372.8531 - val_loss: 5068646208.9541\n",
      "Epoch 2590/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2952383519.0816 - val_loss: 5926263618.1063\n",
      "Epoch 2591/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2818468951.4463 - val_loss: 4871046144.6481\n",
      "Epoch 2592/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2646183841.2065 - val_loss: 5881313241.4020\n",
      "Epoch 2593/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3081635969.2966 - val_loss: 5236701445.1128\n",
      "Epoch 2594/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3040432725.7625 - val_loss: 5071838836.0821\n",
      "Epoch 2595/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 75us/step - loss: 2781552850.0439 - val_loss: 5852680177.8858\n",
      "Epoch 2596/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2969315977.4361 - val_loss: 5208069083.5623\n",
      "Epoch 2597/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3263349742.8565 - val_loss: 5218059403.1257\n",
      "Epoch 2598/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3042186829.0737 - val_loss: 5420811720.2633\n",
      "Epoch 2599/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2775754571.7051 - val_loss: 6577430715.3733\n",
      "Epoch 2600/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2860290389.5734 - val_loss: 5113270242.3314\n",
      "Epoch 2601/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2962808082.8723 - val_loss: 6669755960.0248\n",
      "Epoch 2602/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3094057535.0996 - val_loss: 7976091798.3595\n",
      "Epoch 2603/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3024343394.3950 - val_loss: 9974046949.2838\n",
      "Epoch 2604/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3304012094.4873 - val_loss: 5077795681.1432\n",
      "Epoch 2605/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2717955027.6286 - val_loss: 5388357425.7598\n",
      "Epoch 2606/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3471858226.9263 - val_loss: 5086072544.3150\n",
      "Epoch 2607/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2850103137.2155 - val_loss: 5296291121.0397\n",
      "Epoch 2608/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3068040128.5402 - val_loss: 6154341396.7392\n",
      "Epoch 2609/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2871736890.3455 - val_loss: 8366278673.2827\n",
      "Epoch 2610/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 3172392638.8835 - val_loss: 5243329287.7052\n",
      "Epoch 2611/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2948434477.7760 - val_loss: 5136723992.3398\n",
      "Epoch 2612/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2749944051.4665 - val_loss: 4971134939.6343\n",
      "Epoch 2613/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 3106042319.5228 - val_loss: 5818918011.5713\n",
      "Epoch 2614/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2913383929.8053 - val_loss: 4943158332.6335\n",
      "Epoch 2615/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2813488960.2521 - val_loss: 5446322728.7584\n",
      "Epoch 2616/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 3463303407.9640 - val_loss: 5014952021.9814\n",
      "Epoch 2617/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2751983413.5914 - val_loss: 4901468716.5030\n",
      "Epoch 2618/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2843818156.9477 - val_loss: 4741634252.0799\n",
      "Epoch 2619/5000\n",
      "3554/3554 [==============================] - 0s 106us/step - loss: 2790703105.7288 - val_loss: 4871768419.4475\n",
      "Epoch 2620/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3039354765.9021 - val_loss: 4729620955.6343\n",
      "Epoch 2621/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2912937329.3776 - val_loss: 7818266260.7752\n",
      "Epoch 2622/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 3659243987.9167 - val_loss: 4966971222.3415\n",
      "Epoch 2623/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2620879114.9488 - val_loss: 5386413894.4270\n",
      "Epoch 2624/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2818618085.4924 - val_loss: 6085607741.7136\n",
      "Epoch 2625/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2768155011.9617 - val_loss: 4665527339.3508\n",
      "Epoch 2626/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2614399633.6477 - val_loss: 4759668021.7924\n",
      "Epoch 2627/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2483143716.8441 - val_loss: 5230143128.5198\n",
      "Epoch 2628/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 3512950722.1970 - val_loss: 6429795957.2343\n",
      "Epoch 2629/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2724923391.1356 - val_loss: 10988237391.3564\n",
      "Epoch 2630/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 4108689188.6640 - val_loss: 4626799775.7210\n",
      "Epoch 2631/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2710625175.4102 - val_loss: 5736076661.6304\n",
      "Epoch 2632/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 3078269420.4795 - val_loss: 5077035179.6748\n",
      "Epoch 2633/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3248729789.2988 - val_loss: 10493600312.6008\n",
      "Epoch 2634/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 3211525404.3444 - val_loss: 5297421299.9021\n",
      "Epoch 2635/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2653784480.3421 - val_loss: 4860798852.5727\n",
      "Epoch 2636/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2487832007.2392 - val_loss: 5116957041.1297\n",
      "Epoch 2637/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2941710745.5082 - val_loss: 4614486525.2636\n",
      "Epoch 2638/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2900079544.8329 - val_loss: 5023088352.0990\n",
      "Epoch 2639/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 2427625874.3680 - val_loss: 4933107521.8903\n",
      "Epoch 2640/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3089405720.0225 - val_loss: 5390454658.6284\n",
      "Epoch 2641/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2539370787.5836 - val_loss: 7819503408.0315\n",
      "Epoch 2642/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 2933294363.3540 - val_loss: 5441133382.2110\n",
      "Epoch 2643/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2814411040.2701 - val_loss: 5248732967.5342\n",
      "Epoch 2644/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2789239227.4260 - val_loss: 4877270507.9809\n",
      "Epoch 2645/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2995414248.2656 - val_loss: 5376608909.1421\n",
      "Epoch 2646/5000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 2501401844.6190 - val_loss: 13406594446.0782\n",
      "Epoch 2647/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 4032223943.2392 - val_loss: 4623846368.0270\n",
      "Epoch 2648/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2708273647.0006 - val_loss: 6579023173.2028\n",
      "Epoch 2649/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2771748414.5954 - val_loss: 4551301119.8560\n",
      "Epoch 2650/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2551706806.5639 - val_loss: 6590873582.2852\n",
      "Epoch 2651/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2700936800.3061 - val_loss: 6604549017.0239\n",
      "Epoch 2652/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2683046895.8649 - val_loss: 6949973747.8301\n",
      "Epoch 2653/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2939225804.1733 - val_loss: 4742891056.5356\n",
      "Epoch 2654/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2787331535.8829 - val_loss: 4834759211.9269\n",
      "Epoch 2655/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2538704390.6269 - val_loss: 4978134540.9620\n",
      "Epoch 2656/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3633578687.8920 - val_loss: 5140062078.6678\n",
      "Epoch 2657/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2768218961.3776 - val_loss: 7104832756.1181\n",
      "Epoch 2658/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3422427599.8829 - val_loss: 5915114111.8200\n",
      "Epoch 2659/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 3142223863.0681 - val_loss: 4822633488.0585\n",
      "Epoch 2660/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 82us/step - loss: 3082564042.0664 - val_loss: 7956747798.8996\n",
      "Epoch 2661/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 3104520496.4772 - val_loss: 5348953744.1665\n",
      "Epoch 2662/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2443334161.5937 - val_loss: 4592874975.3069\n",
      "Epoch 2663/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2255020750.2622 - val_loss: 4734206960.5896\n",
      "Epoch 2664/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 2696063375.1986 - val_loss: 4987979247.7975\n",
      "Epoch 2665/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2747552060.6505 - val_loss: 4769456452.9868\n",
      "Epoch 2666/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2656500624.2071 - val_loss: 4839699148.0799\n",
      "Epoch 2667/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2794129613.8481 - val_loss: 4413885352.1463\n",
      "Epoch 2668/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2823185870.2983 - val_loss: 5404346180.4827\n",
      "Epoch 2669/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2457172235.6331 - val_loss: 4582008350.1727\n",
      "Epoch 2670/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2438612340.2589 - val_loss: 5169311257.0599\n",
      "Epoch 2671/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2821909005.1818 - val_loss: 5000825808.1845\n",
      "Epoch 2672/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2648224023.8604 - val_loss: 4518023722.9907\n",
      "Epoch 2673/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3276591920.8374 - val_loss: 4620812991.9100\n",
      "Epoch 2674/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3085370688.9724 - val_loss: 11385114159.9595\n",
      "Epoch 2675/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 3440238966.9961 - val_loss: 7691485738.7747\n",
      "Epoch 2676/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2829871321.2245 - val_loss: 4723907906.0343\n",
      "Epoch 2677/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2559984505.3731 - val_loss: 4451184110.7173\n",
      "Epoch 2678/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 2780990919.0231 - val_loss: 8839053200.2385\n",
      "Epoch 2679/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 2823376153.5712 - val_loss: 5217862241.0712\n",
      "Epoch 2680/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 2559255298.4491 - val_loss: 4979986062.2942\n",
      "Epoch 2681/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2483274729.2380 - val_loss: 6360881726.7938\n",
      "Epoch 2682/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2619338426.5627 - val_loss: 4537390816.2430\n",
      "Epoch 2683/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2266169634.5751 - val_loss: 5019727737.7710\n",
      "Epoch 2684/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2568070778.9308 - val_loss: 7970187089.8768\n",
      "Epoch 2685/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2544574570.4086 - val_loss: 5083308522.9727\n",
      "Epoch 2686/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2501163797.1773 - val_loss: 5864580098.5924\n",
      "Epoch 2687/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2574594377.8323 - val_loss: 5076304731.5263\n",
      "Epoch 2688/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2504317807.2527 - val_loss: 4577980122.3381\n",
      "Epoch 2689/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2686425866.2285 - val_loss: 4965122836.3792\n",
      "Epoch 2690/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2586425281.0895 - val_loss: 4098976005.7609\n",
      "Epoch 2691/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2281964417.5487 - val_loss: 4732004262.8501\n",
      "Epoch 2692/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2583688066.3770 - val_loss: 4551003710.4338\n",
      "Epoch 2693/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2631341193.7243 - val_loss: 4369661096.1463\n",
      "Epoch 2694/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2562785011.1379 - val_loss: 6182193659.6073\n",
      "Epoch 2695/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2254209832.7333 - val_loss: 5031387675.0762\n",
      "Epoch 2696/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2902181753.2290 - val_loss: 8749221701.6349\n",
      "Epoch 2697/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2761699222.1137 - val_loss: 7183618639.3564\n",
      "Epoch 2698/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2565506287.8649 - val_loss: 6262894528.7021\n",
      "Epoch 2699/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 2532739735.1221 - val_loss: 4240840042.5046\n",
      "Epoch 2700/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2715185573.2403 - val_loss: 11994286198.9626\n",
      "Epoch 2701/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 3049058268.3984 - val_loss: 4213743985.8498\n",
      "Epoch 2702/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2309827353.6342 - val_loss: 4951619425.1432\n",
      "Epoch 2703/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2768964798.2712 - val_loss: 5142168594.4349\n",
      "Epoch 2704/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2260003820.9837 - val_loss: 9850236171.5938\n",
      "Epoch 2705/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 4585598975.7119 - val_loss: 5437336756.3162\n",
      "Epoch 2706/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2410865882.9758 - val_loss: 4751638310.2380\n",
      "Epoch 2707/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2546137717.0512 - val_loss: 5392760612.9418\n",
      "Epoch 2708/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2677825465.1030 - val_loss: 5539412283.3373\n",
      "Epoch 2709/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2315058729.7783 - val_loss: 5327116614.4990\n",
      "Epoch 2710/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2595718581.0872 - val_loss: 5256560144.8506\n",
      "Epoch 2711/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2401510604.3894 - val_loss: 4528688756.3702\n",
      "Epoch 2712/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2516594052.0698 - val_loss: 5416880619.4048\n",
      "Epoch 2713/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2332580729.7333 - val_loss: 4832274450.7229\n",
      "Epoch 2714/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2572384843.8852 - val_loss: 4174020132.1496\n",
      "Epoch 2715/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2350037396.7091 - val_loss: 5460352199.9032\n",
      "Epoch 2716/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2458755806.5774 - val_loss: 7716346407.3181\n",
      "Epoch 2717/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2674972810.8768 - val_loss: 5367393001.8925\n",
      "Epoch 2718/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2216424796.6325 - val_loss: 7767357093.6259\n",
      "Epoch 2719/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2737886480.4232 - val_loss: 4273684554.1716\n",
      "Epoch 2720/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2302216629.0872 - val_loss: 4305258906.3921\n",
      "Epoch 2721/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2570058862.7845 - val_loss: 4513777296.1665\n",
      "Epoch 2722/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2149503019.7231 - val_loss: 4805666932.6582\n",
      "Epoch 2723/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2381706076.6775 - val_loss: 5167520240.4456\n",
      "Epoch 2724/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2490860207.2527 - val_loss: 4130151208.5423\n",
      "Epoch 2725/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 99us/step - loss: 2462618102.2037 - val_loss: 5710690342.1660\n",
      "Epoch 2726/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 2462823310.5143 - val_loss: 5561971847.3091\n",
      "Epoch 2727/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2490185521.8143 - val_loss: 5201826268.2824\n",
      "Epoch 2728/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2209750772.0428 - val_loss: 6577282728.3623\n",
      "Epoch 2729/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2851574200.9589 - val_loss: 4705029722.7342\n",
      "Epoch 2730/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2169716311.0141 - val_loss: 4328717027.9876\n",
      "Epoch 2731/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2439986276.3759 - val_loss: 4253800881.7238\n",
      "Epoch 2732/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 2277964230.0867 - val_loss: 4251559832.8799\n",
      "Epoch 2733/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2194458037.2313 - val_loss: 4699918519.3406\n",
      "Epoch 2734/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2556921338.5256 - val_loss: 6144643887.4554\n",
      "Epoch 2735/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2442729201.7378 - val_loss: 4381215922.5879\n",
      "Epoch 2736/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 2482681104.5222 - val_loss: 6402709868.8090\n",
      "Epoch 2737/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2841463269.9966 - val_loss: 3928942902.2245\n",
      "Epoch 2738/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2496645967.5948 - val_loss: 14653854300.6065\n",
      "Epoch 2739/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2562479665.4136 - val_loss: 5655607360.9541\n",
      "Epoch 2740/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2670165807.0816 - val_loss: 4995459664.5806\n",
      "Epoch 2741/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2377274761.0760 - val_loss: 4178213480.9924\n",
      "Epoch 2742/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2222350399.8514 - val_loss: 3998096542.7128\n",
      "Epoch 2743/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2191828903.7614 - val_loss: 4164800622.4653\n",
      "Epoch 2744/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2136532314.4716 - val_loss: 4102949752.7629\n",
      "Epoch 2745/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2242752638.7755 - val_loss: 4364678027.6298\n",
      "Epoch 2746/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2441529331.0343 - val_loss: 6464943333.5719\n",
      "Epoch 2747/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2426939186.2780 - val_loss: 4044187527.1651\n",
      "Epoch 2748/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2452132914.9263 - val_loss: 4620011281.6428\n",
      "Epoch 2749/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2415764545.4046 - val_loss: 4088254050.0073\n",
      "Epoch 2750/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2234758258.5301 - val_loss: 3986902139.2833\n",
      "Epoch 2751/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2462748666.3815 - val_loss: 5648572688.0585\n",
      "Epoch 2752/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 2933352645.6770 - val_loss: 4714155979.5038\n",
      "Epoch 2753/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2301748741.5464 - val_loss: 5327218323.9831\n",
      "Epoch 2754/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2053740381.4249 - val_loss: 3963536306.4439\n",
      "Epoch 2755/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2787641973.4091 - val_loss: 5668967578.3921\n",
      "Epoch 2756/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2122114796.8396 - val_loss: 5742768561.9398\n",
      "Epoch 2757/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2962361263.2347 - val_loss: 4539744065.3142\n",
      "Epoch 2758/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2279048915.0523 - val_loss: 5890586261.0633\n",
      "Epoch 2759/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2430734906.7777 - val_loss: 9078288898.1603\n",
      "Epoch 2760/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2324984227.5476 - val_loss: 4602828493.0880\n",
      "Epoch 2761/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2361356859.8582 - val_loss: 3921003322.8332\n",
      "Epoch 2762/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2128021463.5543 - val_loss: 7132978415.7975\n",
      "Epoch 2763/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 2561381765.6185 - val_loss: 8231452196.5817\n",
      "Epoch 2764/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2438640734.9375 - val_loss: 6581354708.0011\n",
      "Epoch 2765/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2503718965.6995 - val_loss: 8467971774.5418\n",
      "Epoch 2766/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2312818926.7124 - val_loss: 3713175062.7556\n",
      "Epoch 2767/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2241401530.5616 - val_loss: 6598627680.7111\n",
      "Epoch 2768/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2401104555.8593 - val_loss: 4498318077.5516\n",
      "Epoch 2769/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1982162636.2093 - val_loss: 4447511502.7443\n",
      "Epoch 2770/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1995857936.0833 - val_loss: 3950090148.8338\n",
      "Epoch 2771/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2001540011.3990 - val_loss: 4033463144.1283\n",
      "Epoch 2772/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2283295217.8818 - val_loss: 4026575160.3848\n",
      "Epoch 2773/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2419077126.9150 - val_loss: 4703996711.3902\n",
      "Epoch 2774/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2433308434.1880 - val_loss: 4622120403.2810\n",
      "Epoch 2775/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2260123233.8548 - val_loss: 4262703421.5696\n",
      "Epoch 2776/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2185770064.0990 - val_loss: 6718715976.0113\n",
      "Epoch 2777/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2557600961.6207 - val_loss: 5723892386.6014\n",
      "Epoch 2778/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2461372639.2977 - val_loss: 5747015158.4945\n",
      "Epoch 2779/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2151143623.4553 - val_loss: 4457554115.7266\n",
      "Epoch 2780/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2342247740.9387 - val_loss: 3999186768.7966\n",
      "Epoch 2781/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2796347321.1930 - val_loss: 4024012012.9170\n",
      "Epoch 2782/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1978222367.8379 - val_loss: 3933211869.5066\n",
      "Epoch 2783/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2627517720.4907 - val_loss: 8358602585.5100\n",
      "Epoch 2784/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2585114923.2819 - val_loss: 5458310592.5581\n",
      "Epoch 2785/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2515583931.8582 - val_loss: 3853656478.5688\n",
      "Epoch 2786/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2403188926.7394 - val_loss: 5281776807.6422\n",
      "Epoch 2787/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2142448509.1908 - val_loss: 4228314561.1342\n",
      "Epoch 2788/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2127675517.6230 - val_loss: 5388656585.8475\n",
      "Epoch 2789/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2393834192.0270 - val_loss: 3833036306.7229\n",
      "Epoch 2790/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 73us/step - loss: 2257963029.6095 - val_loss: 6713042406.9401\n",
      "Epoch 2791/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2624031410.3500 - val_loss: 6211063838.9648\n",
      "Epoch 2792/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2029177974.9961 - val_loss: 3990843178.1986\n",
      "Epoch 2793/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2340000610.8452 - val_loss: 4088902648.4388\n",
      "Epoch 2794/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2363789313.2966 - val_loss: 4215037358.6273\n",
      "Epoch 2795/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2473648969.9043 - val_loss: 5089012716.9890\n",
      "Epoch 2796/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2529027746.8813 - val_loss: 3940926706.7499\n",
      "Epoch 2797/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2127445264.6483 - val_loss: 4473491298.2954\n",
      "Epoch 2798/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2078114529.4586 - val_loss: 3760202791.6062\n",
      "Epoch 2799/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2257896367.3247 - val_loss: 3899129161.8115\n",
      "Epoch 2800/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1919889687.5723 - val_loss: 4087310111.4689\n",
      "Epoch 2801/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1995013136.7563 - val_loss: 4037784514.9345\n",
      "Epoch 2802/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2270685400.5267 - val_loss: 4287107059.5421\n",
      "Epoch 2803/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2128727038.9916 - val_loss: 4172450820.1767\n",
      "Epoch 2804/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2404852420.4299 - val_loss: 4676375886.4203\n",
      "Epoch 2805/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1880077358.1002 - val_loss: 11170835865.8880\n",
      "Epoch 2806/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2332424976.2791 - val_loss: 4857844337.4897\n",
      "Epoch 2807/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2535819125.2133 - val_loss: 6141392238.8253\n",
      "Epoch 2808/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2324494297.6072 - val_loss: 6102961346.7184\n",
      "Epoch 2809/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2293537490.3320 - val_loss: 3570774975.3339\n",
      "Epoch 2810/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1820426387.6646 - val_loss: 4595241060.2397\n",
      "Epoch 2811/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1875607799.9325 - val_loss: 4697198135.7367\n",
      "Epoch 2812/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2614248276.9612 - val_loss: 4545325240.3488\n",
      "Epoch 2813/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1842555427.1514 - val_loss: 3943492224.0360\n",
      "Epoch 2814/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2653285765.1953 - val_loss: 12220153541.1668\n",
      "Epoch 2815/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2769004617.1840 - val_loss: 5491377957.9499\n",
      "Epoch 2816/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2224097616.7608 - val_loss: 6949609663.4059\n",
      "Epoch 2817/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1937116225.4766 - val_loss: 5328553821.3986\n",
      "Epoch 2818/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2366713176.4547 - val_loss: 5109674167.3406\n",
      "Epoch 2819/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2160047429.0062 - val_loss: 3971628318.8928\n",
      "Epoch 2820/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2127076939.1469 - val_loss: 3550956316.4805\n",
      "Epoch 2821/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1914200387.8537 - val_loss: 4500513889.3592\n",
      "Epoch 2822/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2226279567.7029 - val_loss: 4209109880.0428\n",
      "Epoch 2823/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1976248116.7271 - val_loss: 4851495597.2591\n",
      "Epoch 2824/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 2793225645.3078 - val_loss: 3576764977.6158\n",
      "Epoch 2825/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2431266605.6680 - val_loss: 3813893940.4242\n",
      "Epoch 2826/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1951546994.9623 - val_loss: 3697231533.9792\n",
      "Epoch 2827/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1873481266.4221 - val_loss: 4802624769.8003\n",
      "Epoch 2828/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2630449387.6871 - val_loss: 5990748544.9722\n",
      "Epoch 2829/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2136648515.4755 - val_loss: 5794347346.3089\n",
      "Epoch 2830/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1923586296.9409 - val_loss: 4459022737.6788\n",
      "Epoch 2831/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2188302835.7546 - val_loss: 4493146778.6802\n",
      "Epoch 2832/5000\n",
      "3554/3554 [==============================] - 0s 102us/step - loss: 2009637301.0872 - val_loss: 9492982958.2672\n",
      "Epoch 2833/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2648902317.9921 - val_loss: 4562857757.3086\n",
      "Epoch 2834/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2128065859.3315 - val_loss: 3872761548.9440\n",
      "Epoch 2835/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1759357521.1075 - val_loss: 7358451547.5263\n",
      "Epoch 2836/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2280543851.5521 - val_loss: 4286322872.8529\n",
      "Epoch 2837/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1813968083.8987 - val_loss: 4007949385.7395\n",
      "Epoch 2838/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1933646305.4406 - val_loss: 6246246239.2709\n",
      "Epoch 2839/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2280546758.8070 - val_loss: 3891195098.6262\n",
      "Epoch 2840/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2419269573.9426 - val_loss: 3569371946.4146\n",
      "Epoch 2841/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1976661059.4215 - val_loss: 4010937447.4082\n",
      "Epoch 2842/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2243663242.2285 - val_loss: 9800572059.2563\n",
      "Epoch 2843/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2217679762.8002 - val_loss: 4367625149.1736\n",
      "Epoch 2844/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2084058155.5791 - val_loss: 3639123322.3471\n",
      "Epoch 2845/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1934348252.2003 - val_loss: 3883299610.3561\n",
      "Epoch 2846/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1907811475.8087 - val_loss: 3557973565.0655\n",
      "Epoch 2847/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2029089391.5048 - val_loss: 3390075220.0371\n",
      "Epoch 2848/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1917759558.7349 - val_loss: 4383463231.4419\n",
      "Epoch 2849/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1927965562.1654 - val_loss: 3671097081.8790\n",
      "Epoch 2850/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 2107193516.0113 - val_loss: 4701391905.7013\n",
      "Epoch 2851/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2115426703.1986 - val_loss: 3735797163.3868\n",
      "Epoch 2852/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2008647387.2639 - val_loss: 5188228870.4090\n",
      "Epoch 2853/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2286270812.6325 - val_loss: 4850062760.1463\n",
      "Epoch 2854/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2344467986.0799 - val_loss: 3654078756.8698\n",
      "Epoch 2855/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 80us/step - loss: 2053656264.9679 - val_loss: 4496950098.8850\n",
      "Epoch 2856/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 2547583884.2994 - val_loss: 5107540521.4785\n",
      "Epoch 2857/5000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 2111998723.3405 - val_loss: 3369760147.6951\n",
      "Epoch 2858/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1745223739.3540 - val_loss: 6256470377.6405\n",
      "Epoch 2859/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2100090691.2954 - val_loss: 4444181994.2526\n",
      "Epoch 2860/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1890872753.2696 - val_loss: 3557474629.7789\n",
      "Epoch 2861/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1878467226.8317 - val_loss: 3670741936.4996\n",
      "Epoch 2862/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2114886213.1142 - val_loss: 3781816715.6298\n",
      "Epoch 2863/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1788860213.6275 - val_loss: 5987364295.2551\n",
      "Epoch 2864/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2309314140.4344 - val_loss: 6737573132.7460\n",
      "Epoch 2865/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2331503235.6016 - val_loss: 4236387542.5935\n",
      "Epoch 2866/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 2205451167.1896 - val_loss: 9597409972.7482\n",
      "Epoch 2867/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2230943711.0096 - val_loss: 5284972809.5055\n",
      "Epoch 2868/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1848821090.0349 - val_loss: 3607201019.2473\n",
      "Epoch 2869/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1819944931.3315 - val_loss: 3490969473.1882\n",
      "Epoch 2870/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1904696486.6269 - val_loss: 3520636706.3494\n",
      "Epoch 2871/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1881187348.7451 - val_loss: 3437815817.2174\n",
      "Epoch 2872/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 2164037737.1221 - val_loss: 3465813216.9632\n",
      "Epoch 2873/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1660497179.3360 - val_loss: 3745105853.1015\n",
      "Epoch 2874/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1903868939.5250 - val_loss: 3815684617.5055\n",
      "Epoch 2875/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1806566175.2617 - val_loss: 5671671577.9961\n",
      "Epoch 2876/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 3279588506.1812 - val_loss: 5403107474.1108\n",
      "Epoch 2877/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 2053589032.7698 - val_loss: 3560275249.4717\n",
      "Epoch 2878/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1808771029.6455 - val_loss: 4130921135.7795\n",
      "Epoch 2879/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2017316350.4153 - val_loss: 4028416201.5595\n",
      "Epoch 2880/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1675806004.4389 - val_loss: 3939422425.1859\n",
      "Epoch 2881/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1958652761.3911 - val_loss: 4422687473.0217\n",
      "Epoch 2882/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2177856013.3979 - val_loss: 3553300263.8222\n",
      "Epoch 2883/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1954150175.2617 - val_loss: 5148268723.5961\n",
      "Epoch 2884/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 2041939141.5824 - val_loss: 3544049612.2959\n",
      "Epoch 2885/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1615706512.4952 - val_loss: 4300153157.6349\n",
      "Epoch 2886/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 2299523439.2887 - val_loss: 3505861240.7989\n",
      "Epoch 2887/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1976890400.1261 - val_loss: 3859514901.2433\n",
      "Epoch 2888/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1686063051.2729 - val_loss: 3647674335.5949\n",
      "Epoch 2889/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1949255703.6984 - val_loss: 4155930023.5702\n",
      "Epoch 2890/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1723800094.2532 - val_loss: 3952125900.1519\n",
      "Epoch 2891/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1738587945.0400 - val_loss: 3596016771.9246\n",
      "Epoch 2892/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1694213369.3011 - val_loss: 4434727999.8020\n",
      "Epoch 2893/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2045968483.2594 - val_loss: 3381411537.3367\n",
      "Epoch 2894/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1850827042.0709 - val_loss: 3952839422.7758\n",
      "Epoch 2895/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2209503150.7485 - val_loss: 3559058641.8408\n",
      "Epoch 2896/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1740717298.9623 - val_loss: 7049147275.0537\n",
      "Epoch 2897/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2191381705.6882 - val_loss: 3717048175.7615\n",
      "Epoch 2898/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1891474247.7794 - val_loss: 3540042464.0990\n",
      "Epoch 2899/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1757561248.0540 - val_loss: 6102549617.6338\n",
      "Epoch 2900/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2065723104.9544 - val_loss: 4031169313.7733\n",
      "Epoch 2901/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2182685768.8959 - val_loss: 4042486483.0650\n",
      "Epoch 2902/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2227679667.6466 - val_loss: 6892144747.4408\n",
      "Epoch 2903/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1998010768.8914 - val_loss: 4453751004.3544\n",
      "Epoch 2904/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1792431110.0506 - val_loss: 4342051166.8388\n",
      "Epoch 2905/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2016684867.6376 - val_loss: 4874399925.1803\n",
      "Epoch 2906/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2045374568.4457 - val_loss: 3580640046.5193\n",
      "Epoch 2907/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1626731866.2555 - val_loss: 3753663505.5707\n",
      "Epoch 2908/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1769229119.3877 - val_loss: 3321677675.6568\n",
      "Epoch 2909/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1885862283.2009 - val_loss: 3407948508.7145\n",
      "Epoch 2910/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2089391226.1654 - val_loss: 4640051531.8278\n",
      "Epoch 2911/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1819213441.3686 - val_loss: 3290702986.1896\n",
      "Epoch 2912/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1837387189.5194 - val_loss: 3924598993.0487\n",
      "Epoch 2913/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1720551321.9674 - val_loss: 3817774188.4489\n",
      "Epoch 2914/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1848056779.8852 - val_loss: 4116025300.0731\n",
      "Epoch 2915/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 2238675245.9561 - val_loss: 4174999385.7260\n",
      "Epoch 2916/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2521277365.4474 - val_loss: 3576667233.2152\n",
      "Epoch 2917/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1650819989.7535 - val_loss: 3247800834.9525\n",
      "Epoch 2918/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1897720330.6607 - val_loss: 7417064220.5885\n",
      "Epoch 2919/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1901253413.3123 - val_loss: 3944665702.3280\n",
      "Epoch 2920/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 77us/step - loss: 1983319892.7091 - val_loss: 3417443802.9862\n",
      "Epoch 2921/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1807130607.3967 - val_loss: 5923580289.2602\n",
      "Epoch 2922/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1814403370.7867 - val_loss: 6180953412.9148\n",
      "Epoch 2923/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2489593161.6500 - val_loss: 3813328791.0076\n",
      "Epoch 2924/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1664511284.2949 - val_loss: 3234808209.6428\n",
      "Epoch 2925/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2199785939.8717 - val_loss: 4276420416.4501\n",
      "Epoch 2926/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1687739892.1868 - val_loss: 3504314125.6821\n",
      "Epoch 2927/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2017369712.4952 - val_loss: 3782107625.8925\n",
      "Epoch 2928/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2034612643.6556 - val_loss: 3577705531.9134\n",
      "Epoch 2929/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1694858403.0253 - val_loss: 4132370348.8990\n",
      "Epoch 2930/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1607240026.6156 - val_loss: 3275194084.9238\n",
      "Epoch 2931/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1883614938.6877 - val_loss: 4878076581.5539\n",
      "Epoch 2932/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1745662210.5931 - val_loss: 3300971183.9955\n",
      "Epoch 2933/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1634289515.3495 - val_loss: 3466648445.2996\n",
      "Epoch 2934/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1698525585.3956 - val_loss: 3476142480.8866\n",
      "Epoch 2935/5000\n",
      "3554/3554 [==============================] - 0s 112us/step - loss: 1610274812.4705 - val_loss: 3228558309.7879\n",
      "Epoch 2936/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1939999514.7957 - val_loss: 11838807300.1046\n",
      "Epoch 2937/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2181717469.0917 - val_loss: 3438236598.2605\n",
      "Epoch 2938/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1550079875.8177 - val_loss: 3189033650.1558\n",
      "Epoch 2939/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1568327594.0664 - val_loss: 3180238763.1347\n",
      "Epoch 2940/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2126676534.8880 - val_loss: 3171320981.6394\n",
      "Epoch 2941/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1715890269.9831 - val_loss: 5738412928.3961\n",
      "Epoch 2942/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1719911409.0715 - val_loss: 3293824238.2132\n",
      "Epoch 2943/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1644413486.6764 - val_loss: 5181002208.3871\n",
      "Epoch 2944/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 2189901046.4918 - val_loss: 3610817091.6906\n",
      "Epoch 2945/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 2008112723.8807 - val_loss: 4708304532.7752\n",
      "Epoch 2946/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1865216918.0416 - val_loss: 3597759829.4053\n",
      "Epoch 2947/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1600337063.9775 - val_loss: 4593298186.1536\n",
      "Epoch 2948/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1721000719.6128 - val_loss: 3181979192.9609\n",
      "Epoch 2949/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 2007797061.7625 - val_loss: 3272688013.5021\n",
      "Epoch 2950/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1579324039.4192 - val_loss: 3168536763.5893\n",
      "Epoch 2951/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1810086128.8734 - val_loss: 3887615121.6788\n",
      "Epoch 2952/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1986826789.6005 - val_loss: 3915968041.3345\n",
      "Epoch 2953/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1781063320.2026 - val_loss: 3355260489.3075\n",
      "Epoch 2954/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1774774780.1823 - val_loss: 3826216999.3902\n",
      "Epoch 2955/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1870357719.8424 - val_loss: 3129853401.5460\n",
      "Epoch 2956/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1550943358.0551 - val_loss: 4039588163.6906\n",
      "Epoch 2957/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 2272084879.1626 - val_loss: 8512046970.4911\n",
      "Epoch 2958/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2654295351.0321 - val_loss: 6097340628.5772\n",
      "Epoch 2959/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2061452071.6894 - val_loss: 3241364198.0039\n",
      "Epoch 2960/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1655230090.9668 - val_loss: 4409759262.2447\n",
      "Epoch 2961/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1944816339.0523 - val_loss: 4358564327.5882\n",
      "Epoch 2962/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1941267856.1351 - val_loss: 3247953121.4672\n",
      "Epoch 2963/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1596930067.3405 - val_loss: 5324065724.0934\n",
      "Epoch 2964/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1819614984.9679 - val_loss: 3213496444.5075\n",
      "Epoch 2965/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1573982043.9302 - val_loss: 4228030526.6498\n",
      "Epoch 2966/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1932279903.1536 - val_loss: 4917741945.6270\n",
      "Epoch 2967/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2100079999.2797 - val_loss: 3057119752.2093\n",
      "Epoch 2968/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1500961181.3889 - val_loss: 3197450733.4211\n",
      "Epoch 2969/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1620444931.3134 - val_loss: 3855373808.9496\n",
      "Epoch 2970/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1621402789.7985 - val_loss: 3366175737.3030\n",
      "Epoch 2971/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1602157169.0895 - val_loss: 3504340082.4979\n",
      "Epoch 2972/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1843903318.6539 - val_loss: 3280262141.6596\n",
      "Epoch 2973/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1699846387.9347 - val_loss: 4517387305.1184\n",
      "Epoch 2974/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1739931494.9060 - val_loss: 3621587597.6461\n",
      "Epoch 2975/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1743010254.4423 - val_loss: 3298783455.7390\n",
      "Epoch 2976/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1779951191.6984 - val_loss: 4523192662.7736\n",
      "Epoch 2977/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 2093334073.5869 - val_loss: 3683576178.4619\n",
      "Epoch 2978/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1615819172.8081 - val_loss: 3967590900.6222\n",
      "Epoch 2979/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1720006518.9961 - val_loss: 3662513783.6827\n",
      "Epoch 2980/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1722464500.5470 - val_loss: 4125094187.8549\n",
      "Epoch 2981/5000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 1952176652.9657 - val_loss: 4399120496.3376\n",
      "Epoch 2982/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1855502579.5385 - val_loss: 3368042039.0166\n",
      "Epoch 2983/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1498280136.9679 - val_loss: 3534729219.2045\n",
      "Epoch 2984/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1593839962.3275 - val_loss: 13428666412.9350\n",
      "Epoch 2985/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 73us/step - loss: 2937317057.6207 - val_loss: 4136742892.7730\n",
      "Epoch 2986/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1641478520.7248 - val_loss: 3245029170.4799\n",
      "Epoch 2987/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1494705341.0107 - val_loss: 5104195579.2473\n",
      "Epoch 2988/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 2252910221.9741 - val_loss: 3222782886.2380\n",
      "Epoch 2989/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1551948412.0383 - val_loss: 3432757690.6532\n",
      "Epoch 2990/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1866486031.5588 - val_loss: 3296043605.3333\n",
      "Epoch 2991/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1530320220.4524 - val_loss: 3040462808.6819\n",
      "Epoch 2992/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1612225488.0990 - val_loss: 3213390877.0205\n",
      "Epoch 2993/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1775124523.4125 - val_loss: 3577490182.0489\n",
      "Epoch 2994/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1686377796.9342 - val_loss: 4302150570.1266\n",
      "Epoch 2995/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1799465978.6697 - val_loss: 3579144351.3609\n",
      "Epoch 2996/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1900918485.8346 - val_loss: 3529010752.5221\n",
      "Epoch 2997/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1574366527.3877 - val_loss: 5561377868.9800\n",
      "Epoch 2998/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1736947667.4845 - val_loss: 3091011925.8374\n",
      "Epoch 2999/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1426728639.4598 - val_loss: 3038613825.8903\n",
      "Epoch 3000/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1364409962.9668 - val_loss: 3132486277.5089\n",
      "Epoch 3001/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1901334256.5132 - val_loss: 4083290997.4504\n",
      "Epoch 3002/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1672516392.0855 - val_loss: 6129361175.9797\n",
      "Epoch 3003/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1544845418.2465 - val_loss: 3038325961.7755\n",
      "Epoch 3004/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1665029214.4333 - val_loss: 3000580929.1702\n",
      "Epoch 3005/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1630494256.7833 - val_loss: 3300454801.2467\n",
      "Epoch 3006/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1493277122.0529 - val_loss: 3132843617.0712\n",
      "Epoch 3007/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1708650563.4215 - val_loss: 3631245952.6121\n",
      "Epoch 3008/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1510498464.6303 - val_loss: 6642384037.9139\n",
      "Epoch 3009/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1749323196.2904 - val_loss: 3496889829.2838\n",
      "Epoch 3010/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1992695849.6342 - val_loss: 3686669799.6602\n",
      "Epoch 3011/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1865195554.5751 - val_loss: 5265139292.0304\n",
      "Epoch 3012/5000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 1798465517.6860 - val_loss: 3182983174.3730\n",
      "Epoch 3013/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1654748539.3900 - val_loss: 3635617814.6115\n",
      "Epoch 3014/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1671990491.7321 - val_loss: 3269350700.2869\n",
      "Epoch 3015/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1788455508.6370 - val_loss: 3249955531.7918\n",
      "Epoch 3016/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1618495068.9207 - val_loss: 4160464548.5457\n",
      "Epoch 3017/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1862683511.5273 - val_loss: 3862602963.2810\n",
      "Epoch 3018/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1591602311.6714 - val_loss: 3641588258.5654\n",
      "Epoch 3019/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1840765675.7839 - val_loss: 2953414091.4318\n",
      "Epoch 3020/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1508359377.9989 - val_loss: 3067394999.9167\n",
      "Epoch 3021/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1751093803.3630 - val_loss: 3535983712.4231\n",
      "Epoch 3022/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1733292611.5295 - val_loss: 3463823574.6655\n",
      "Epoch 3023/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1521814979.2369 - val_loss: 4841513694.6588\n",
      "Epoch 3024/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1495299715.9617 - val_loss: 3919446791.7052\n",
      "Epoch 3025/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1719232199.1491 - val_loss: 3936031750.6970\n",
      "Epoch 3026/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1672841199.5768 - val_loss: 4290588621.7361\n",
      "Epoch 3027/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1589346552.0045 - val_loss: 5980479210.0366\n",
      "Epoch 3028/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2249501752.8689 - val_loss: 3235278828.1969\n",
      "Epoch 3029/5000\n",
      "3554/3554 [==============================] - 0s 70us/step - loss: 1616821301.5914 - val_loss: 4113595609.7620\n",
      "Epoch 3030/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1928973453.8661 - val_loss: 3210516023.3046\n",
      "Epoch 3031/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1430462705.4496 - val_loss: 3397734777.6990\n",
      "Epoch 3032/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1727282170.3815 - val_loss: 9490310976.7381\n",
      "Epoch 3033/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2069391486.6674 - val_loss: 3826188222.3257\n",
      "Epoch 3034/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1848198882.2510 - val_loss: 6860975249.8948\n",
      "Epoch 3035/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2037950906.5616 - val_loss: 7988793906.1198\n",
      "Epoch 3036/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2395585679.4868 - val_loss: 9141175121.7328\n",
      "Epoch 3037/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 3029825311.1176 - val_loss: 3432329845.3063\n",
      "Epoch 3038/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1616452560.6753 - val_loss: 3791872360.3443\n",
      "Epoch 3039/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1646526473.8683 - val_loss: 2911764471.7547\n",
      "Epoch 3040/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1595880683.2099 - val_loss: 3849107711.0098\n",
      "Epoch 3041/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1650212068.4840 - val_loss: 3609451210.7117\n",
      "Epoch 3042/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1390079168.9004 - val_loss: 3150031767.6557\n",
      "Epoch 3043/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1470547241.3461 - val_loss: 2977936195.9066\n",
      "Epoch 3044/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1342319698.9803 - val_loss: 5585522518.3415\n",
      "Epoch 3045/5000\n",
      "3554/3554 [==============================] - 0s 101us/step - loss: 1749953742.7304 - val_loss: 3848115415.3136\n",
      "Epoch 3046/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1732301970.3680 - val_loss: 3947790393.3930\n",
      "Epoch 3047/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1653128821.6500 - val_loss: 3032553775.0954\n",
      "Epoch 3048/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1401879322.9398 - val_loss: 3055124498.2188\n",
      "Epoch 3049/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1730610245.0422 - val_loss: 6337604218.2751\n",
      "Epoch 3050/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 78us/step - loss: 1529013987.4575 - val_loss: 3049360068.9508\n",
      "Epoch 3051/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1836517757.1908 - val_loss: 6460911639.9077\n",
      "Epoch 3052/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2111492504.8509 - val_loss: 3403257807.8965\n",
      "Epoch 3053/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1926381788.2724 - val_loss: 6237584107.6208\n",
      "Epoch 3054/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1978917314.7732 - val_loss: 3628339488.1890\n",
      "Epoch 3055/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1457578391.4102 - val_loss: 3359461844.7572\n",
      "Epoch 3056/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1588531842.5234 - val_loss: 3228243191.4307\n",
      "Epoch 3057/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1475839082.4806 - val_loss: 3083081640.4343\n",
      "Epoch 3058/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1578912497.8098 - val_loss: 3049977448.2723\n",
      "Epoch 3059/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1843725148.9927 - val_loss: 3447360854.1255\n",
      "Epoch 3060/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1594555599.9550 - val_loss: 4329670768.7696\n",
      "Epoch 3061/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1491136327.3112 - val_loss: 3094433322.4866\n",
      "Epoch 3062/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1477844714.9308 - val_loss: 3913433533.1736\n",
      "Epoch 3063/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1663888998.1047 - val_loss: 4026487539.0380\n",
      "Epoch 3064/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1591280859.3360 - val_loss: 3389553050.3201\n",
      "Epoch 3065/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1650999336.8059 - val_loss: 4790345340.8675\n",
      "Epoch 3066/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1863828704.3061 - val_loss: 3107182416.8686\n",
      "Epoch 3067/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1409327444.4209 - val_loss: 3711676163.4565\n",
      "Epoch 3068/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1836278679.7704 - val_loss: 4523965457.5707\n",
      "Epoch 3069/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1531675379.4665 - val_loss: 5758064849.7328\n",
      "Epoch 3070/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1836969582.1362 - val_loss: 3033689556.2892\n",
      "Epoch 3071/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1340932013.5959 - val_loss: 6694306283.2608\n",
      "Epoch 3072/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2028477044.1080 - val_loss: 8379230250.3426\n",
      "Epoch 3073/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1741043677.6410 - val_loss: 2868607402.0906\n",
      "Epoch 3074/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1578582408.5718 - val_loss: 3059956970.6847\n",
      "Epoch 3075/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1445990945.7107 - val_loss: 3906094324.4782\n",
      "Epoch 3076/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1394306528.4502 - val_loss: 6351969441.5932\n",
      "Epoch 3077/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 2221480649.2560 - val_loss: 3528356946.0928\n",
      "Epoch 3078/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1388934913.0084 - val_loss: 3626067715.9966\n",
      "Epoch 3079/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1829201662.9195 - val_loss: 3842268821.4954\n",
      "Epoch 3080/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1542056578.3770 - val_loss: 3345687159.4667\n",
      "Epoch 3081/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1490014675.2954 - val_loss: 2983937765.1398\n",
      "Epoch 3082/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1479650857.6342 - val_loss: 2915956496.1845\n",
      "Epoch 3083/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1623796308.1148 - val_loss: 3037095531.5128\n",
      "Epoch 3084/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1965547516.8306 - val_loss: 9211018006.4675\n",
      "Epoch 3085/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 2175355664.3196 - val_loss: 3075133835.9899\n",
      "Epoch 3086/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1462638525.3708 - val_loss: 4016070542.5103\n",
      "Epoch 3087/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1766995338.7327 - val_loss: 3105840458.0636\n",
      "Epoch 3088/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1456063945.0129 - val_loss: 3898274037.7744\n",
      "Epoch 3089/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1503439593.7423 - val_loss: 2901753353.2895\n",
      "Epoch 3090/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1395859400.6798 - val_loss: 3007315428.4917\n",
      "Epoch 3091/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1554934624.9544 - val_loss: 3498330009.0959\n",
      "Epoch 3092/5000\n",
      "3554/3554 [==============================] - 0s 93us/step - loss: 1543989947.0658 - val_loss: 4680167532.7010\n",
      "Epoch 3093/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1568322825.0039 - val_loss: 3655776435.0200\n",
      "Epoch 3094/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1704331055.7569 - val_loss: 5375208661.6934\n",
      "Epoch 3095/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1729818407.3292 - val_loss: 3082939635.7941\n",
      "Epoch 3096/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1463340259.6196 - val_loss: 5622795941.6979\n",
      "Epoch 3097/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1546101962.6246 - val_loss: 4028855153.4177\n",
      "Epoch 3098/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1564281277.0827 - val_loss: 4200460698.7522\n",
      "Epoch 3099/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1429073405.9471 - val_loss: 3480822401.1162\n",
      "Epoch 3100/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 2107792510.9916 - val_loss: 3138682073.3300\n",
      "Epoch 3101/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1545144139.7231 - val_loss: 3021740390.8321\n",
      "Epoch 3102/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1514692516.7001 - val_loss: 3414767422.6498\n",
      "Epoch 3103/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1547739236.8441 - val_loss: 4641403323.2293\n",
      "Epoch 3104/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1668346387.7546 - val_loss: 3090301055.8920\n",
      "Epoch 3105/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1259438464.9904 - val_loss: 2944921724.8675\n",
      "Epoch 3106/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1270844496.6539 - val_loss: 3585102729.9376\n",
      "Epoch 3107/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1417128919.7344 - val_loss: 2900640925.5606\n",
      "Epoch 3108/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1538015288.6168 - val_loss: 3505594477.3131\n",
      "Epoch 3109/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1441316802.7012 - val_loss: 4088014891.9269\n",
      "Epoch 3110/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1563040229.9966 - val_loss: 2937254966.3685\n",
      "Epoch 3111/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1341441014.6269 - val_loss: 2989318705.6518\n",
      "Epoch 3112/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1690130430.6314 - val_loss: 2953907398.8231\n",
      "Epoch 3113/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1613990733.9381 - val_loss: 2991915106.6914\n",
      "Epoch 3114/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1762512541.0647 - val_loss: 4360670519.3767\n",
      "Epoch 3115/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 80us/step - loss: 1351006588.3264 - val_loss: 11812248924.2464\n",
      "Epoch 3116/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 3192139285.6095 - val_loss: 3305501815.0346\n",
      "Epoch 3117/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1338271204.3984 - val_loss: 2807444380.9125\n",
      "Epoch 3118/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1278089555.8447 - val_loss: 5510509609.9105\n",
      "Epoch 3119/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1757127720.9139 - val_loss: 3436285686.1345\n",
      "Epoch 3120/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1767603777.2606 - val_loss: 2752796861.7496\n",
      "Epoch 3121/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1470521680.5312 - val_loss: 3357490460.4084\n",
      "Epoch 3122/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1583016754.3320 - val_loss: 2818086591.1179\n",
      "Epoch 3123/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1406156625.0535 - val_loss: 3542551625.8835\n",
      "Epoch 3124/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1513168513.5847 - val_loss: 6035202554.2391\n",
      "Epoch 3125/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1684891200.8284 - val_loss: 4500901421.0790\n",
      "Epoch 3126/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1411954698.5166 - val_loss: 2991323888.0855\n",
      "Epoch 3127/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1463946082.7102 - val_loss: 2945386336.9632\n",
      "Epoch 3128/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1561767158.0597 - val_loss: 4783296971.7198\n",
      "Epoch 3129/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1820570407.0051 - val_loss: 3276315789.9342\n",
      "Epoch 3130/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1424070799.5588 - val_loss: 3501624516.1947\n",
      "Epoch 3131/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1329353755.7321 - val_loss: 2875387638.2785\n",
      "Epoch 3132/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1544248125.8030 - val_loss: 4062438350.1682\n",
      "Epoch 3133/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1737836191.5678 - val_loss: 4466956690.6869\n",
      "Epoch 3134/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1382877392.7833 - val_loss: 2699746003.8571\n",
      "Epoch 3135/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1279304516.1958 - val_loss: 3872675246.4833\n",
      "Epoch 3136/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1535212501.3573 - val_loss: 4895074914.8714\n",
      "Epoch 3137/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1511326949.0602 - val_loss: 4134605407.4869\n",
      "Epoch 3138/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1466850050.8813 - val_loss: 3017507948.8090\n",
      "Epoch 3139/5000\n",
      "3554/3554 [==============================] - 0s 92us/step - loss: 1281094446.1722 - val_loss: 3667358447.5094\n",
      "Epoch 3140/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1652746693.0782 - val_loss: 2769385773.2951\n",
      "Epoch 3141/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1380344891.4980 - val_loss: 5732028742.3550\n",
      "Epoch 3142/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1625288384.5402 - val_loss: 4375488592.2205\n",
      "Epoch 3143/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1577853729.7107 - val_loss: 3241542010.2211\n",
      "Epoch 3144/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1562118832.6753 - val_loss: 3282971183.3834\n",
      "Epoch 3145/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1330240211.7727 - val_loss: 7566222165.6214\n",
      "Epoch 3146/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 2070237605.9786 - val_loss: 3025365717.1893\n",
      "Epoch 3147/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1338522845.1007 - val_loss: 3284285653.1533\n",
      "Epoch 3148/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1319068493.1458 - val_loss: 3204142369.3412\n",
      "Epoch 3149/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1533545189.7805 - val_loss: 3228678105.1139\n",
      "Epoch 3150/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1317157255.3472 - val_loss: 4745010678.2065\n",
      "Epoch 3151/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1407145137.1975 - val_loss: 7865380762.4641\n",
      "Epoch 3152/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1949535500.8576 - val_loss: 3230175308.0799\n",
      "Epoch 3153/5000\n",
      "3554/3554 [==============================] - 0s 100us/step - loss: 1363066083.9797 - val_loss: 2778793819.1662\n",
      "Epoch 3154/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1365803375.9370 - val_loss: 2821233353.6135\n",
      "Epoch 3155/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1547851741.3168 - val_loss: 4375662181.1758\n",
      "Epoch 3156/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1642139374.8565 - val_loss: 3474278001.4897\n",
      "Epoch 3157/5000\n",
      "3554/3554 [==============================] - 0s 107us/step - loss: 1542773387.1649 - val_loss: 3299848854.7196\n",
      "Epoch 3158/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2598032142.3343 - val_loss: 3299684060.1204\n",
      "Epoch 3159/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1710406028.0293 - val_loss: 2703938328.1958\n",
      "Epoch 3160/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1578017614.0822 - val_loss: 3038249164.7280\n",
      "Epoch 3161/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1512811641.5892 - val_loss: 3110285959.7412\n",
      "Epoch 3162/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1425350142.0371 - val_loss: 2768975124.7392\n",
      "Epoch 3163/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1399018145.2786 - val_loss: 3283069222.3820\n",
      "Epoch 3164/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1286181996.7856 - val_loss: 2919004496.7966\n",
      "Epoch 3165/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1408285733.9606 - val_loss: 2935388742.4990\n",
      "Epoch 3166/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1343467999.4418 - val_loss: 3128914640.3286\n",
      "Epoch 3167/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1373758254.4603 - val_loss: 3265818210.4394\n",
      "Epoch 3168/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1291779042.9713 - val_loss: 2871161405.2816\n",
      "Epoch 3169/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1354221814.5999 - val_loss: 3566264083.9471\n",
      "Epoch 3170/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1304340433.8998 - val_loss: 2958133280.8731\n",
      "Epoch 3171/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1561062352.3692 - val_loss: 2947145395.1640\n",
      "Epoch 3172/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1387318607.2347 - val_loss: 3236926329.2669\n",
      "Epoch 3173/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1584539764.2589 - val_loss: 4179423189.2973\n",
      "Epoch 3174/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1542918115.7636 - val_loss: 2808667268.1046\n",
      "Epoch 3175/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1604740666.9848 - val_loss: 2944653527.4577\n",
      "Epoch 3176/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1439704116.1013 - val_loss: 4384136630.6925\n",
      "Epoch 3177/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1742550628.7361 - val_loss: 3122159545.4110\n",
      "Epoch 3178/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1189572640.1261 - val_loss: 3428707795.1370\n",
      "Epoch 3179/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1574562590.9961 - val_loss: 3494136544.0270\n",
      "Epoch 3180/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 76us/step - loss: 1269503601.5937 - val_loss: 2947070594.5564\n",
      "Epoch 3181/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1416438754.3230 - val_loss: 5684250745.4830\n",
      "Epoch 3182/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 2233401704.0495 - val_loss: 2903895228.2374\n",
      "Epoch 3183/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1330180395.0748 - val_loss: 3240129984.8461\n",
      "Epoch 3184/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1545999021.8841 - val_loss: 2875468832.8371\n",
      "Epoch 3185/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1360216566.0597 - val_loss: 2692786916.2397\n",
      "Epoch 3186/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1363926982.0506 - val_loss: 4345134849.9083\n",
      "Epoch 3187/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1569833964.7496 - val_loss: 3119522635.6838\n",
      "Epoch 3188/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1223689773.1277 - val_loss: 3508015450.2661\n",
      "Epoch 3189/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1240227751.9955 - val_loss: 2820695657.3885\n",
      "Epoch 3190/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1629586902.8700 - val_loss: 2880609362.2368\n",
      "Epoch 3191/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1366427823.4328 - val_loss: 4081107273.2354\n",
      "Epoch 3192/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1245581990.8610 - val_loss: 2901476485.8329\n",
      "Epoch 3193/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1280892381.5689 - val_loss: 2683097378.8174\n",
      "Epoch 3194/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1211722329.2110 - val_loss: 3352928489.0644\n",
      "Epoch 3195/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1571689738.9488 - val_loss: 3657070693.6079\n",
      "Epoch 3196/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 2043671533.1277 - val_loss: 2939041271.7907\n",
      "Epoch 3197/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1216575801.4451 - val_loss: 2857427993.7800\n",
      "Epoch 3198/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1725573920.7743 - val_loss: 2928495064.9699\n",
      "Epoch 3199/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1297222871.0141 - val_loss: 2832603305.8745\n",
      "Epoch 3200/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1454883238.6089 - val_loss: 2954702707.9381\n",
      "Epoch 3201/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1328931108.7361 - val_loss: 3240698856.0203\n",
      "Epoch 3202/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1262474954.1925 - val_loss: 3339492140.1789\n",
      "Epoch 3203/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1590455351.4541 - val_loss: 3006944092.2464\n",
      "Epoch 3204/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1393713642.1024 - val_loss: 6996680034.2954\n",
      "Epoch 3205/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 2311107234.5031 - val_loss: 4381653887.0278\n",
      "Epoch 3206/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1888106325.8616 - val_loss: 2902847408.9677\n",
      "Epoch 3207/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1228422337.4046 - val_loss: 2749759526.2740\n",
      "Epoch 3208/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1216000629.1052 - val_loss: 2852817518.7533\n",
      "Epoch 3209/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1208621316.5380 - val_loss: 4500009859.3485\n",
      "Epoch 3210/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1279319145.6702 - val_loss: 4369710816.6751\n",
      "Epoch 3211/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1502453175.8244 - val_loss: 4869307806.7848\n",
      "Epoch 3212/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1985740434.8002 - val_loss: 2689497875.5871\n",
      "Epoch 3213/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1280278271.0276 - val_loss: 2890485310.1457\n",
      "Epoch 3214/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1309927880.5729 - val_loss: 4119960011.6478\n",
      "Epoch 3215/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1214545508.2679 - val_loss: 3074002527.7030\n",
      "Epoch 3216/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1736845216.5222 - val_loss: 3459327347.3260\n",
      "Epoch 3217/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1320564739.7456 - val_loss: 2964013363.8121\n",
      "Epoch 3218/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1401275568.0450 - val_loss: 4595204202.0006\n",
      "Epoch 3219/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1451113436.8486 - val_loss: 3498401673.2534\n",
      "Epoch 3220/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1670725946.4536 - val_loss: 2816164625.1747\n",
      "Epoch 3221/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1191377156.1778 - val_loss: 3525933515.6118\n",
      "Epoch 3222/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1611263243.9572 - val_loss: 4642798623.9010\n",
      "Epoch 3223/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1294918050.0709 - val_loss: 3309420846.6453\n",
      "Epoch 3224/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1343695124.8171 - val_loss: 3242511633.1027\n",
      "Epoch 3225/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1808415326.1947 - val_loss: 2618711085.6551\n",
      "Epoch 3226/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1098734926.2622 - val_loss: 2915193430.0895\n",
      "Epoch 3227/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1254234680.7608 - val_loss: 2785240642.9345\n",
      "Epoch 3228/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1170758262.9961 - val_loss: 4669151432.3353\n",
      "Epoch 3229/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1457664705.9809 - val_loss: 2555336912.4726\n",
      "Epoch 3230/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1315654696.7698 - val_loss: 6144015192.5738\n",
      "Epoch 3231/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1778103670.9961 - val_loss: 2921164871.3271\n",
      "Epoch 3232/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1261555582.0551 - val_loss: 3328543850.1806\n",
      "Epoch 3233/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1625862113.9629 - val_loss: 4200535173.7969\n",
      "Epoch 3234/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1373188231.4192 - val_loss: 3835642018.4574\n",
      "Epoch 3235/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1561560963.5295 - val_loss: 5547837588.3432\n",
      "Epoch 3236/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 2705731352.9229 - val_loss: 3325515841.8183\n",
      "Epoch 3237/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1398848772.7541 - val_loss: 4361198263.1966\n",
      "Epoch 3238/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1344489460.5110 - val_loss: 2695629170.9300\n",
      "Epoch 3239/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1274823404.3354 - val_loss: 3676315749.8239\n",
      "Epoch 3240/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1492456658.3680 - val_loss: 2880277132.9620\n",
      "Epoch 3241/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1320910907.3540 - val_loss: 2969012995.3125\n",
      "Epoch 3242/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1359883371.4350 - val_loss: 3156323910.3550\n",
      "Epoch 3243/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1752617332.2521 - val_loss: 3061380464.5536\n",
      "Epoch 3244/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1081701932.5695 - val_loss: 3103523656.8034\n",
      "Epoch 3245/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 75us/step - loss: 1202758645.8841 - val_loss: 2663893411.5556\n",
      "Epoch 3246/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1258243930.9398 - val_loss: 2929120004.2847\n",
      "Epoch 3247/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1346534356.9612 - val_loss: 2508660775.6782\n",
      "Epoch 3248/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1305546484.5110 - val_loss: 2811820123.5083\n",
      "Epoch 3249/5000\n",
      "3554/3554 [==============================] - 0s 89us/step - loss: 1292732809.5982 - val_loss: 4690769678.4743\n",
      "Epoch 3250/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1427336502.3838 - val_loss: 3007596704.5851\n",
      "Epoch 3251/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1396930958.1677 - val_loss: 2694821202.5609\n",
      "Epoch 3252/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1276964002.0709 - val_loss: 2841151738.2931\n",
      "Epoch 3253/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1439742045.6410 - val_loss: 2961853210.8962\n",
      "Epoch 3254/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1465538554.9578 - val_loss: 3344019472.4186\n",
      "Epoch 3255/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1272147604.7811 - val_loss: 5314782805.9814\n",
      "Epoch 3256/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1902499354.7957 - val_loss: 2711845086.1187\n",
      "Epoch 3257/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1459242102.4378 - val_loss: 6826781175.7907\n",
      "Epoch 3258/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1473360919.7704 - val_loss: 7616273537.3322\n",
      "Epoch 3259/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1820530505.1840 - val_loss: 2657833949.4346\n",
      "Epoch 3260/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1335196720.3331 - val_loss: 2918882136.0698\n",
      "Epoch 3261/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1293603918.3703 - val_loss: 2975060957.0025\n",
      "Epoch 3262/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1550192428.4434 - val_loss: 3487584339.0020\n",
      "Epoch 3263/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1276325423.9820 - val_loss: 3015164060.0484\n",
      "Epoch 3264/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1155311406.4783 - val_loss: 2631307466.8737\n",
      "Epoch 3265/5000\n",
      "3554/3554 [==============================] - 0s 108us/step - loss: 1158123554.2150 - val_loss: 2813722322.3449\n",
      "Epoch 3266/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1436093186.5211 - val_loss: 4519042538.1086\n",
      "Epoch 3267/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1242524239.6669 - val_loss: 3505775072.6031\n",
      "Epoch 3268/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1365241023.6038 - val_loss: 3761495999.2619\n",
      "Epoch 3269/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1559959807.9460 - val_loss: 3641110360.4298\n",
      "Epoch 3270/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1477204602.8768 - val_loss: 2762498257.5527\n",
      "Epoch 3271/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1397032300.7316 - val_loss: 3013561784.5648\n",
      "Epoch 3272/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1317682612.0788 - val_loss: 3251602989.5831\n",
      "Epoch 3273/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1287812558.2983 - val_loss: 3355654088.7494\n",
      "Epoch 3274/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1219953227.7952 - val_loss: 2753720577.5482\n",
      "Epoch 3275/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1158817860.1418 - val_loss: 2825907558.1660\n",
      "Epoch 3276/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1462362757.7985 - val_loss: 3142932269.1511\n",
      "Epoch 3277/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1301249011.7907 - val_loss: 3008304227.6636\n",
      "Epoch 3278/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1229020690.6922 - val_loss: 2911532050.5789\n",
      "Epoch 3279/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1228475705.8413 - val_loss: 3361344902.3010\n",
      "Epoch 3280/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1142794188.4254 - val_loss: 9867363139.3305\n",
      "Epoch 3281/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 2364397519.2347 - val_loss: 2852373159.9662\n",
      "Epoch 3282/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1162292204.2454 - val_loss: 3177452582.5620\n",
      "Epoch 3283/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1470067321.0129 - val_loss: 8955344816.6436\n",
      "Epoch 3284/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1523546339.7096 - val_loss: 3353026160.8056\n",
      "Epoch 3285/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1394385332.9432 - val_loss: 3015362425.9150\n",
      "Epoch 3286/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1327195693.5239 - val_loss: 4119468507.9944\n",
      "Epoch 3287/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1586381819.5340 - val_loss: 7009100101.2028\n",
      "Epoch 3288/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1433725791.6849 - val_loss: 3338540067.0335\n",
      "Epoch 3289/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1293691575.3022 - val_loss: 2665642795.5308\n",
      "Epoch 3290/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1071746244.5740 - val_loss: 4058856699.0672\n",
      "Epoch 3291/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1627015515.7681 - val_loss: 4091728336.1485\n",
      "Epoch 3292/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1395961843.4665 - val_loss: 4255107350.6835\n",
      "Epoch 3293/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1285461338.0754 - val_loss: 4383082013.9567\n",
      "Epoch 3294/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1172878288.1711 - val_loss: 3341596401.1657\n",
      "Epoch 3295/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1275197330.5301 - val_loss: 2844698317.7722\n",
      "Epoch 3296/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1192305722.7417 - val_loss: 2499688446.0917\n",
      "Epoch 3297/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1087524978.6021 - val_loss: 3631220325.1398\n",
      "Epoch 3298/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1810052220.7586 - val_loss: 2878608115.9741\n",
      "Epoch 3299/5000\n",
      "3554/3554 [==============================] - 0s 72us/step - loss: 1250140195.7997 - val_loss: 5881723032.9519\n",
      "Epoch 3300/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1548541171.6826 - val_loss: 2638327261.5786\n",
      "Epoch 3301/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1292450773.4969 - val_loss: 2606681016.7449\n",
      "Epoch 3302/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1150146820.9387 - val_loss: 2552878967.7547\n",
      "Epoch 3303/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1105642222.0079 - val_loss: 4773998517.8284\n",
      "Epoch 3304/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1271824393.9403 - val_loss: 2483120477.9027\n",
      "Epoch 3305/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1372407518.8295 - val_loss: 2809959777.6473\n",
      "Epoch 3306/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1167774737.5757 - val_loss: 2803032237.4751\n",
      "Epoch 3307/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1292233554.9803 - val_loss: 2773274679.9077\n",
      "Epoch 3308/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1063985278.7034 - val_loss: 2543613527.9797\n",
      "Epoch 3309/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1268943288.5898 - val_loss: 2667849093.3108\n",
      "Epoch 3310/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 77us/step - loss: 1200235371.0388 - val_loss: 12573768964.5367\n",
      "Epoch 3311/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 2313554117.6905 - val_loss: 2784737791.9280\n",
      "Epoch 3312/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1055353507.1154 - val_loss: 3917129481.5775\n",
      "Epoch 3313/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1383123875.7997 - val_loss: 5717855307.7558\n",
      "Epoch 3314/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1656518080.8194 - val_loss: 2524583060.2712\n",
      "Epoch 3315/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1107792270.2802 - val_loss: 2413619254.4405\n",
      "Epoch 3316/5000\n",
      "3554/3554 [==============================] - 0s 98us/step - loss: 1071271633.8998 - val_loss: 5110169969.2737\n",
      "Epoch 3317/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 2052121680.6753 - val_loss: 3143091947.5128\n",
      "Epoch 3318/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1187033922.3095 - val_loss: 3347948966.5980\n",
      "Epoch 3319/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1132796199.7074 - val_loss: 2858819487.2349\n",
      "Epoch 3320/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1190546655.4418 - val_loss: 3975752871.6782\n",
      "Epoch 3321/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1314531013.7265 - val_loss: 2845538878.2897\n",
      "Epoch 3322/5000\n",
      "3554/3554 [==============================] - 0s 90us/step - loss: 1213542229.7175 - val_loss: 3519772294.3370\n",
      "Epoch 3323/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1695413279.9820 - val_loss: 3212838513.3817\n",
      "Epoch 3324/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1222720367.3967 - val_loss: 2664176712.0473\n",
      "Epoch 3325/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1184845822.0585 - val_loss: 3301534458.4191\n",
      "Epoch 3326/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1176024899.6376 - val_loss: 2875684107.4408\n",
      "Epoch 3327/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1135178904.4187 - val_loss: 3069405053.1556\n",
      "Epoch 3328/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1879337930.5526 - val_loss: 2909002341.2118\n",
      "Epoch 3329/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1327044353.1525 - val_loss: 2613314835.2990\n",
      "Epoch 3330/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1372720999.1806 - val_loss: 2701192978.7589\n",
      "Epoch 3331/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1160634691.9617 - val_loss: 3129155315.8661\n",
      "Epoch 3332/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1262508028.9747 - val_loss: 3846356935.4712\n",
      "Epoch 3333/5000\n",
      "3554/3554 [==============================] - 0s 83us/step - loss: 1373862250.0844 - val_loss: 4386336784.4186\n",
      "Epoch 3334/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1306170951.0951 - val_loss: 3598894517.3963\n",
      "Epoch 3335/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1143316703.0096 - val_loss: 3078849509.5719\n",
      "Epoch 3336/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1200322023.7344 - val_loss: 2635329694.4248\n",
      "Epoch 3337/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1144313745.6443 - val_loss: 2763701464.1058\n",
      "Epoch 3338/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1391559242.6246 - val_loss: 4182617444.1316\n",
      "Epoch 3339/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1334391217.3596 - val_loss: 3186347553.3412\n",
      "Epoch 3340/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1101378921.0940 - val_loss: 2626446766.4833\n",
      "Epoch 3341/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1388083870.2352 - val_loss: 2694715082.1356\n",
      "Epoch 3342/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1271912117.6635 - val_loss: 3309284739.2045\n",
      "Epoch 3343/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1220165142.6179 - val_loss: 2573061044.9643\n",
      "Epoch 3344/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1296405632.4322 - val_loss: 2917697092.0686\n",
      "Epoch 3345/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1138792689.8886 - val_loss: 3869512661.5134\n",
      "Epoch 3346/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1237432090.6337 - val_loss: 2782535249.9128\n",
      "Epoch 3347/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1130808985.1390 - val_loss: 3304483000.3488\n",
      "Epoch 3348/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1450503607.2842 - val_loss: 2854568973.4301\n",
      "Epoch 3349/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1055330639.8109 - val_loss: 2783019280.4546\n",
      "Epoch 3350/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1098455186.9263 - val_loss: 2655196262.9041\n",
      "Epoch 3351/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1463492656.5492 - val_loss: 2517540716.0169\n",
      "Epoch 3352/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1754790523.0298 - val_loss: 4463274244.2127\n",
      "Epoch 3353/5000\n",
      "3554/3554 [==============================] - 0s 77us/step - loss: 1255001139.6106 - val_loss: 2772468014.6003\n",
      "Epoch 3354/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1133394426.0304 - val_loss: 2914805976.6098\n",
      "Epoch 3355/5000\n",
      "3554/3554 [==============================] - 0s 94us/step - loss: 1245306301.4609 - val_loss: 2584423262.6948\n",
      "Epoch 3356/5000\n",
      "3554/3554 [==============================] - 0s 87us/step - loss: 1103975517.5509 - val_loss: 2862211324.2914\n",
      "Epoch 3357/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1360853274.5076 - val_loss: 5319640554.2526\n",
      "Epoch 3358/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1200644692.8531 - val_loss: 2749877301.4684\n",
      "Epoch 3359/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1124473301.9471 - val_loss: 2636785816.6999\n",
      "Epoch 3360/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1104919242.2105 - val_loss: 3592877173.9544\n",
      "Epoch 3361/5000\n",
      "3554/3554 [==============================] - 0s 71us/step - loss: 1142661250.4851 - val_loss: 2722801566.4788\n",
      "Epoch 3362/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1205543530.4626 - val_loss: 3012667232.8911\n",
      "Epoch 3363/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1636539841.1885 - val_loss: 2929815513.4020\n",
      "Epoch 3364/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1151234544.7293 - val_loss: 2954147543.5297\n",
      "Epoch 3365/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1202176169.5982 - val_loss: 2560903842.3854\n",
      "Epoch 3366/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1275561608.7518 - val_loss: 3017147763.4340\n",
      "Epoch 3367/5000\n",
      "3554/3554 [==============================] - 0s 73us/step - loss: 1791954127.4508 - val_loss: 3018366188.3409\n",
      "Epoch 3368/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1219303270.4288 - val_loss: 2623317507.8706\n",
      "Epoch 3369/5000\n",
      "3554/3554 [==============================] - 0s 91us/step - loss: 1063946111.5318 - val_loss: 2727225384.1103\n",
      "Epoch 3370/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1268611063.4806 - val_loss: 2822919171.1685\n",
      "Epoch 3371/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1245612111.2347 - val_loss: 2622986607.5094\n",
      "Epoch 3372/5000\n",
      "3554/3554 [==============================] - 0s 97us/step - loss: 1097589569.9268 - val_loss: 2566826772.0191\n",
      "Epoch 3373/5000\n",
      "3554/3554 [==============================] - 0s 95us/step - loss: 1302360937.6882 - val_loss: 2479317144.8799\n",
      "Epoch 3374/5000\n",
      "3554/3554 [==============================] - 0s 84us/step - loss: 1097189139.8807 - val_loss: 2938333883.0492\n",
      "Epoch 3375/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 0s 78us/step - loss: 1109029821.4429 - val_loss: 4854203867.8504\n",
      "Epoch 3376/5000\n",
      "3554/3554 [==============================] - 0s 80us/step - loss: 1699550467.6736 - val_loss: 2695683102.0287\n",
      "Epoch 3377/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1312519027.0523 - val_loss: 2546991235.4565\n",
      "Epoch 3378/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1163856599.3562 - val_loss: 2654113596.4174\n",
      "Epoch 3379/5000\n",
      "3554/3554 [==============================] - 0s 88us/step - loss: 1134313529.6252 - val_loss: 3754670986.0456\n",
      "Epoch 3380/5000\n",
      "3554/3554 [==============================] - 0s 85us/step - loss: 1675424705.4226 - val_loss: 2563828404.2802\n",
      "Epoch 3381/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1171681865.8323 - val_loss: 4285848314.3111\n",
      "Epoch 3382/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1365769073.1255 - val_loss: 2536123432.6864\n",
      "Epoch 3383/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1297741290.9668 - val_loss: 5852806916.5367\n",
      "Epoch 3384/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1450499911.5993 - val_loss: 2733462788.1767\n",
      "Epoch 3385/5000\n",
      "3554/3554 [==============================] - 0s 86us/step - loss: 1242702270.3073 - val_loss: 2797242199.9257\n",
      "Epoch 3386/5000\n",
      "3554/3554 [==============================] - 0s 82us/step - loss: 1205668779.8672 - val_loss: 3239425400.7269\n",
      "Epoch 3387/5000\n",
      "3554/3554 [==============================] - 0s 81us/step - loss: 1190436742.3028 - val_loss: 2717180828.5525\n",
      "Epoch 3388/5000\n",
      "3554/3554 [==============================] - 0s 79us/step - loss: 1129994357.7355 - val_loss: 2707617432.0878\n",
      "Epoch 3389/5000\n",
      "3554/3554 [==============================] - 0s 76us/step - loss: 1165785919.6849 - val_loss: 2436479478.6745\n",
      "Epoch 3390/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1474155991.2302 - val_loss: 2630234863.2934\n",
      "Epoch 3391/5000\n",
      "3554/3554 [==============================] - 0s 75us/step - loss: 1236290800.2971 - val_loss: 3004297446.3280\n",
      "Epoch 3392/5000\n",
      "3554/3554 [==============================] - 0s 74us/step - loss: 1167770399.3337 - val_loss: 3209586131.1370\n",
      "Epoch 3393/5000\n",
      "3554/3554 [==============================] - 0s 78us/step - loss: 1300701272.8149 - val_loss: 2875406385.2377\n",
      "Epoch 3394/5000\n",
      "3554/3554 [==============================] - 0s 105us/step - loss: 1502136517.9426 - val_loss: 2906216635.2923\n",
      "Epoch 3395/5000\n",
      "3554/3554 [==============================] - 0s 99us/step - loss: 1129949637.5104 - val_loss: 2986280727.6557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f01a0b9c7f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile model\n",
    "model22.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(\"model22 loss:\",model22.loss)\n",
    "\n",
    "model_train22 = model22.fit(predictors,target, epochs=5000, validation_split=0.5, callbacks=[early_stopping_monitor], verbose=True)\n",
    "model_train22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f019efc04e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the plot\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(model_train11.history['val_loss'], 'r',\n",
    "         model_train22.history['val_loss'], 'y',\n",
    "         )\n",
    "plt.title(\"red:nadam ,yellow:adam\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.savefig(\"Adam and Nadam neural network output in class final\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model11.save(\"mode1_nadam_5000_epoch.h5\")\n",
    "model22.save(\"mode2_nadam_5000_epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
